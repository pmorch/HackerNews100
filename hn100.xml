<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 29 May 2024 14:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google Search document leak reveals inner workings of ranking algorithm (152 pts)]]></title>
            <link>https://searchengineland.com/google-search-document-leak-ranking-442617</link>
            <guid>40510125</guid>
            <pubDate>Wed, 29 May 2024 09:36:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://searchengineland.com/google-search-document-leak-ranking-442617">https://searchengineland.com/google-search-document-leak-ranking-442617</a>, See on <a href="https://news.ycombinator.com/item?id=40510125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>A trove of leaked Google documents has given us an unprecedented look inside Google Search and revealed some of the most important elements Google uses to rank content.</p>



<p><strong>What happened.</strong> Thousands of documents, which appear to come from Google’s internal Content API Warehouse, were released <a href="https://github.com/yoshi-code-bot/elixir-google-api/commit/d7a637f4391b2174a2cf43ee11e6577a204a161e" target="_blank" rel="noopener">March 13 on Github</a> by an automated bot called yoshi-code-bot. These documents were shared with Rand Fishkin, SparkToro co-founder, earlier this month.</p>



<ul>
<li>Read on to discover what we’ve learned from Fishkin, as well as Michael King, iPullRank CEO, who also reviewed and analyzed the documents (and plans to provide further analysis for Search Engine Land soon).</li>
</ul>



<p><strong>Why we care.</strong> We have been given a glimpse into how Google’s ranking algorithm may work, which is invaluable for SEOs who can understand what it all means. In 2023, we got an <a href="https://searchengineland.com/yandex-leak-learnings-392393">unprecedented look at Yandex Search ranking factors</a> via a <a href="https://searchengineland.com/yandex-search-ranking-factors-leak-392323">leak</a>, which was one of the biggest stories of that year.</p><!-- /1038259/SEL_Post-text -->



<p>This Google document leak? It will likely be one of the biggest stories in the history of SEO and Google Search.</p>



<p><strong>What’s inside. </strong>Here’s what we know about the internal documents, thanks to Fishkin and King:</p>



<ul>
<li><strong>Current: </strong>The documentation indicates this information is accurate as of March.</li>



<li><strong>Ranking features:</strong> 2,596 modules are represented in the API documentation with 14,014 attributes.</li>



<li><strong>Weighting:</strong> The documents did not specify how any of the ranking features are weighted –&nbsp;just that they exist.</li>



<li><strong>Twiddlers:</strong> These are re-ranking functions that “can adjust the information retrieval score of a document or change the ranking of a document,” according to King.</li>



<li><strong>Demotions:</strong> Content can be demoted for a variety of reasons, such as:
<ul>
<li>A link doesn’t match the target site.</li>



<li>SERP signals indicate user dissatisfaction.</li>



<li>Product reviews.</li>



<li>Location.</li>



<li>Exact match domains.</li>



<li>Porn</li>
</ul>
</li>



<li><strong>Change history:</strong> Google apparently keeps a copy of every version of every page it has ever indexed. Meaning, Google can “remember” every change ever made to a page. However, Google only uses the last 20 changes of a URL when analyzing links.</li>
</ul>



<p><strong>Links matter.</strong> Shocking, I know. Link diversity and relevance remain key, the documents show. And PageRank is still very much alive within Google’s ranking features. PageRank for a website’s homepage is considered for every document.</p>



<ul>
<li>This doesn’t prove Google spokespeople have lied about <a href="https://searchengineland.com/links-google-search-ranking-factor-gary-illyes-432422">links not being a “top 3 ranking factor”</a> or <a href="https://searchengineland.com/links-may-be-less-important-to-the-google-search-ranking-algorithm-in-the-future-389364">links mattering less for ranking</a>. Two things can be true at once. Again, we don’t know how any of these features are weighted. </li>
</ul>



<p><strong>Successful clicks matter.</strong> This should not be a shocker, but if you want to rank well, you need to keep creating great content and user experiences, based on the documents. Google uses a variety of measurements, including&nbsp;<strong>badClicks</strong>, <strong>goodClicks</strong>, <strong>lastLongestClicks</strong> and <strong>unsquashedClicks</strong>.</p>



<p>Also, longer documents may get truncated, while shorter content gets a score (from 0-512) based on originality. Scores are also given to Your Money Your Life content, like health and news.</p>



<p>What does it all mean? According to King:</p>



<ul>
<li>“[Y]ou need to drive more&nbsp;<em>successful&nbsp;</em>clicks using a broader set of queries and earn more link diversity if you want to continue to rank. Conceptually, it makes sense because a very strong piece of content will do that. A focus on driving more qualified traffic to a better user experience will send signals to Google that your page deserves to rank.”</li>
</ul>



<p>Documents and testimony from the <a href="https://searchengineland.com/google-search-antirust-trial-hearing-updates-431977">U.S. vs. Google antitrust trial</a> confirmed that Google uses clicks in ranking – especially with its Navboost system, “one of the important signals” Google uses for ranking. See more from our coverage:</p>



<ul>
<li><a href="https://searchengineland.com/google-search-ranking-documents-434141">7 must-see Google Search ranking documents in antitrust trial exhibits</a></li>



<li><a href="https://searchengineland.com/how-google-search-ranking-works-pandu-nayak-435395">How Google Search and ranking works, according to Google’s Pandu Nayak</a></li>
</ul>



<p><strong>Brand matters.</strong> Fishkin’s big takeaway? Brand matters more than anything else:</p>



<ul>
<li>“If there was one universal piece of advice I had for marketers seeking to broadly improve their organic search rankings and traffic, it would be: ‘Build a notable, popular, well-recognized brand in your space, outside of Google search.'”</li>
</ul>



<p><strong>Entities matter.</strong> <a href="https://searchengineland.com/authorship-dead-long-live-authorship-217209">Authorship lives</a>. Google stores author information associated with content and tries to determine whether an entity is the author of the document.</p>



<p><strong>SiteAuthority:</strong> Google uses something called “siteAuthority”. </p>



<ul>
<li>Google told us something like this existed in 2011, after the <a href="https://searchengineland.com/google-panda-update-guide-381104">Panda update</a> launched, stating publicly that “low quality&nbsp;content&nbsp;on part of a site can impact a site’s ranking as a whole.” </li>



<li>However, <a href="https://www.seroundtable.com/google-no-website-authority-score-22874.html" target="_blank" rel="noopener">Google has denied having a website authority score</a> in the years since then.</li>
</ul>



<p><strong>Chrome data.</strong> A module called <strong>ChromeInTotal</strong> indicates that Google uses data from its Chrome browser for ranking.</p>



<p><strong>Whitelists.</strong> A couple of modules indicate Google whitelist certain domains related to elections and COVID – <strong>isElectionAuthority</strong> and <strong>isCovidLocalAuthority</strong>. Though we’ve long known <a href="https://searchengineland.com/google-bing-have-whitelistsexception-lists-for-algorithms-67732">Google (and Bing) have “exception lists”</a> when “specific algorithms inadvertently impact websites.”</p>



<p><strong>Small sites.</strong> Another feature is <strong>smallPersonalSite</strong> – for a small personal site or blog. King speculated that Google could boost or demote such sites via a Twiddler. However, that remains an open question. Again, we don’t know for certain how much these features are weighted.</p>



<p><strong>Other interesting findings. </strong>According to Google’s internal documents:</p>



<ul>
<li>Freshness matters – Google looks at dates in the byline (<strong>bylineDate</strong>), URL (<strong>syntacticDate</strong>) and on-page content (<strong>semanticDate</strong>).</li>



<li>To determine whether a document is or isn’t a core topic of the website, Google vectorizes pages and sites, then compares the page embeddings (<strong>siteRadius</strong>) to the site embeddings (<strong>siteFocusScore</strong>). </li>



<li>Google stores domain registration information (<strong>RegistrationInfo</strong>).</li>



<li>Page titles still matter. Google has a feature called <strong>titlematchScore</strong> that is believed to measure how well a page title matches a query. </li>



<li>Google measures the average weighted font size of terms in documents (<strong>avgTermWeight</strong>) and anchor text.</li>
</ul>



<p><strong>The articles. </strong></p>



<ul>
<li><a href="https://ipullrank.com/google-algo-leak" target="_blank" rel="noopener">Secrets from the Algorithm: Google Search’s Internal Engineering Documentation Has Leaked</a> by King on iPullRank</li>



<li><a href="https://sparktoro.com/blog/an-anonymous-source-shared-thousands-of-leaked-google-search-api-documents-with-me-everyone-in-seo-should-see-them/" target="_blank" rel="noopener">An Anonymous Source Shared Thousands of Leaked Google Search API Documents with Me; Everyone in SEO Should See Them</a> by Fishkin on SparkToro</li>
</ul>



<p><strong>Quick clarification. </strong>There is some dispute as to whether these documents were “leaked” or “discovered.” I’ve been told it’s likely the internal documents were accidentally included in a code review and pushed live from Google’s internal code base, where they were then discovered.</p>



<p><strong>The source.</strong> <a href="https://www.linkedin.com/in/erfanazimi/" target="_blank" rel="noopener">Erfan Azimi</a>, CEO and director of SEO for digital marketing agency EA Eagle Digital, posted <a href="https://www.youtube.com/watch?v=AEb8_rbfFVw">a video</a>, claiming responsibility for sharing the documents with Fishkin. Azimi is not employed by Google.</p>



<figure></figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three Laws of Software Complexity (137 pts)]]></title>
            <link>https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html</link>
            <guid>40509572</guid>
            <pubDate>Wed, 29 May 2024 07:58:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html">https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html</a>, See on <a href="https://news.ycombinator.com/item?id=40509572">Hacker News</a></p>
Couldn't get https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[You can force employees back to the office, but not the good ones (240 pts)]]></title>
            <link>https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/</link>
            <guid>40509409</guid>
            <pubDate>Wed, 29 May 2024 07:28:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/">https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/</a>, See on <a href="https://news.ycombinator.com/item?id=40509409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent">
<article>
<div data-equalizer-watch="" id="main" itemscope="" itemtype="http://schema.org/Article" data-equalizer="" data-equalize-on="large" data-equalize-by-row="">

<header>

</header>
<div>
<p><span>
Updated / Tuesday, 21 May 2024 <strong>09:31</strong>
</span>
</p>


</div>

<figure id="main-article-image">
<p><img itemprop="image" src="https://img.rasset.ie/002047a8-500.jpg" data-src="https://img.rasset.ie/002047a8-800.jpg" alt="Against all expectations, remote workers appear to work harder and more productively than workers in traditional office. Photo: Getty Images">
</p>
<figcaption data-epic-field="thumbnail_caption">Against all expectations, remote workers appear to work harder and more productively than workers in traditional office. Photo: Getty Images</figcaption>
</figure>

<section itemprop="articleBody" data-epic-field="content">
<p><b>Analysis: Organisations that impose return-to-office mandates face the catastrophic possibility of losing their most valuable workers</b></p>
<p>The <a href="https://www.rte.ie/brainstorm/covid-19/">COVID-19</a> pandemic upended the workplace in many surprising ways. Many organisations were forced to abandon the traditional arrangement of having employees come to the office five days a week in favour of a variety of schemes for <a href="https://www.rte.ie/brainstorm/2024/0216/1408426-learning-on-the-job-remote-working/">remote work</a> or working from home.</p>
<p>Against all expectations, remote workers appear to <a href="https://thehill.com/business/4110598-remote-employees-work-longer-and-harder-studies-show/">work harder and more productively</a> than workers in traditional offices. Remote workers were not only more productive they were <a href="https://www.apollotechnical.com/statistics-on-remote-workers/">more satisfied</a> with remote work than they had been with working in a traditional office. This finding is not unexpected. Once you let workers do away with the commute to and from the office, office politics, <a href="https://www.rte.ie/brainstorm/2024/0410/1442669-workplace-bullying-harrassment-toxic-behaviour-bystanders/">workplace bullying</a>, boring meetings, the need to wear and take care of business suits and other costly and often uncomfortable attire, you should not be surprised that they will feel happier.</p>
<p>Since the end of the pandemic, there has been a growing push to encourage, and sometimes compel workers to <a href="https://www.rte.ie/news/business/2024/0115/1426497-survey-remote-working/">return to the office</a>. This movement has become so widespread that it has generated the acronym RTO, or Return to the Office. As I have noted in <a href="https://www.rte.ie/brainstorm/2023/0904/1402957-offices-workers-bosses-managers-executives-psychology/">earlier columns</a>, the rationale for RTO mandates is often murky, and it is hard to resist the conclusion that the push to get people back to the office is in part an effort to reduce the embarrassment of executives sitting in near-empty office buildings (building they often purchased or built) with <a href="https://www.rte.ie/brainstorm/2024/0319/1438645-middle-managers-job-role-organisations-workplace/">nobody to manage</a>.</p>

<p><i><b>From RTÉ Radio 1's The Business, Is your boss watching you?</b></i></p>
<p>There is increasing evidence that RTO mandates can be counterproductive. In particular, several organisations that have attempted to coerce workers back to the office have found that they are <a href="https://www.washingtonpost.com/business/2024/05/12/rto-microsoft-apple-spacex">losing experienced managers</a> and top performers at disproportionate rates. The dynamic here is clear, and potentially alarming. Organisations that impose RTO mandates face the possibility of losing their most valuable workers. Turnover is often costly for organisations, but turnover of your most experienced and most valuable workers can be catastrophic.</p>
<p>I believe the pandemic shook things up in the world of work in ways that are still poorly understood. The great political philosopher Edmund Burke noted that "custom reconciles us to every thing", and I think this applies to all sorts of workplace norms and practices. If we were used to the way things were done in organisations, we were willing to put up with all sorts of organisational policies that were burdensome (e.g., dress codes) or even abusive (e.g., the expectation that we should work beyond normal working hours if asked to do this.)</p>
<h2><b>Read more: <a href="https://www.rte.ie/brainstorm/2023/0904/1402957-offices-workers-bosses-managers-executives-psychology/">Get back to the office or else! Why bosses want workers back at their desks</a></b></h2>
<p>A year or two away from the office has opened a lot of eyes, and things that were once widely accepted (e.g., office politics) are now barely tolerated, if they are accepted at all. More important, time away from the office seems to have upset the traditional balance of power between employers and employees. Once you realise that you do not need the office and that you do not need to be tightly monitored or supervised, it is hard to go back.</p>
<p>Some employees, of course, <i>do</i> go back. First, there are some employees who believe that being in the office will benefit their careers. They are probably right; workers who return to the office are more likely to <a href="https://www.inc.com/jessica-stillman/ceos-data-agree-workers-promotion-office-4-days-week.html">receive promotions</a>.<i> </i>Whether organisations <i>should</i> promote the careerists who come back to the office in hopes that their loyalty (or submissiveness to RTO mandates) will win them promotions that their performance and effectiveness would not, is an open question. Second, there are employees who are <a href="https://www.rte.ie/brainstorm/2024/0304/1435778-bad-jobs-workplace-change-inertia-organisations/">trapped in their jobs</a>, either because of family or community obligations or because they lack the <a href="https://www.rte.ie/brainstorm/2024/0108/1411961-ireland-2024-upskilling-reskilling-training-courses-new-jobs-career-development/">skills, knowledge, and abilities</a> to move to other jobs. Executives who force RTO mandates down the throats of their employees run the risk of changing their organisation into a set of lapdog careerists and people who are stuck working for you, and it is hard to believe that this will benefit their organisation.</p>
<h2><b>Read more: <a href="https://www.rte.ie/brainstorm/2024/0115/1426555-coffee-badging-return-to-office-work-from-home-employers-employees/">Is 'coffee badging' the new return to office/work from home trend?</a></b></h2>
<p>Executives who are pushing employees to come back to the office are most likely to succeed if they can make a convincing case for <i>why </i>coming back to the office benefits employees and the organisation. The typical explanation that coming back to the office is important for the culture of the organisation is unfounded at best, and hogwash at worse. Second, the carrot works better than the stick. If you want employees to come back to the office, recognise that this comes at considerable costs to employees and give them incentives that more than offset these costs.</p>
<p>It is time for executives to recognise that the old power balance is unlikely to come back, and that mandates from on high that don't seem to make sense or that impose significant costs on employees will not be accepted by employees who have the skills, knowledge, experience, and abilities that give them ample opportunities to seek employment elsewhere. The RTO movement has, in the end, provided opportunities to executives who are smart enough and willing enough to read the new world of work to poach talent from their competitors. If this trend continues, we could see the old breed of all-powerful executives push themselves toward extinction. I can hardly wait!</p>
<h3><b>Follow RTÉ Brainstorm on <a href="https://www.whatsapp.com/channel/0029VaJ6ugQ1HsptikZkfS1f">WhatsApp</a> and <a href="https://www.instagram.com/rte_brainstorm">Instagram</a> for more stories and updates</b></h3>
<hr>
<p><b>The views expressed here are those of the author and do not represent or reflect the views of RTÉ</b></p>
<hr>

</section>

<div>
<h4>More stories on</h4>

</div>
</div>
</article>

<div>
<p><a href="https://www.rte.ie/author/917131-kevin-r-murphy/" data-ati-tracking="{&quot;campaign&quot;:&quot;9[columnist]&quot;,&quot;generalPlacement&quot;:&quot;body&quot;,&quot;creation&quot;:&quot;body&quot;, &quot;variant&quot;:&quot;0&quot;, &quot;format&quot;:&quot;author&quot;, &quot;url&quot;:&quot;More by Professor Kevin Murphy&quot;, &quot;detailedPlacement&quot;:&quot;&quot;}">
<img src="https://img.rasset.ie/00129243-300.jpg" data-src="https://img.rasset.ie/00129243-300.jpg" alt="More by Professor Kevin Murphy" title="More by Professor Kevin Murphy">
</a>
</p>

</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Former OpenAI board member explains why they fired Sam Altman (191 pts)]]></title>
            <link>https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired</link>
            <guid>40509399</guid>
            <pubDate>Wed, 29 May 2024 07:26:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired">https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired</a>, See on <a href="https://news.ycombinator.com/item?id=40509399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On November 17th, 2023, OpenAI’s board shocked everyone by <a href="https://www.theverge.com/2023/11/17/23965982/openai-ceo-sam-altman-fired">suddenly ousting</a> co-founder and CEO Sam Altman. </p><p>He had been overseeing one of the fastest-growing app launches in history with ChatGPT, so what happened? Former board member Helen Toner is filling in blank spaces in an interview on <a href="https://www.ted.com/podcasts/the-ted-ai-show"><em>The TED AI Show</em></a> podcast, providing her perspective on the events that caused board members to stop trusting Altman, as well as how he <a href="https://www.theverge.com/2024/3/8/24094885/openai-sam-altman-investigation-board-results">eventually returned</a>. </p><p>In her telling, once the board decided they needed to bring in a new CEO, they felt the only way to make it happen was to <a href="https://www.theverge.com/2023/12/1/23984818/openai-microsoft-altman-nadella-firing-newyorker">go behind his back.</a> “[I]t was very clear to all of us that as soon as Sam had any inkling that we might do something that went against him, he would pull out all the stops, do everything in his power to undermine the board, to prevent us from even getting to the point of being able to fire him,” Toner said.</p><p>Toner says that one reason the board stopped trusting Altman was his failure to tell the board that he owned the OpenAI Startup Fund; another was how he gave inaccurate info about the company’s safety processes “on multiple occasions.” Additionally, Toner says she was personally targeted by the CEO after she published a research paper that angered him. “Sam started lying to other board members in order to try and push me off the board,” she says.</p><p>After two executives spoke directly to the board about their own experiences with Altman, describing a toxic atmosphere at OpenAI, accusing him of “psychological abuse,” and providing evidence of Altman “lying and being manipulative in different situations,” the board finally made its move.</p><p>Toner cites the <a href="https://www.theverge.com/23488017/openai-chatbot-chatgpt-ai-examples-web-demo">launch of ChatGPT</a> itself as an example of how the board didn’t have real oversight over the company. “[W]hen ChatGPT came out November 2022, the board was not informed in advance. We learned about ChatGPT on Twitter,” says Toner.</p><div><p>The podcast doesn’t go into the details of what happened in the days following Altman’s firing. OpenAI rapidly <a href="https://www.theverge.com/2023/11/20/23968848/openai-new-ceo-emmett-shear-twitch-co-founder-hiring">shuffled through</a> interim CEOs, employees <a href="https://twitter.com/ilyasut/status/1726590052392956028">including at least one of the board members who fired Altman</a> pushed for his return, and OpenAI’s lead investor, Microsoft, <a href="https://www.theverge.com/2023/12/1/23984818/openai-microsoft-altman-nadella-firing-newyorker">put its support behind Altman</a>, too. </p></div><p>However, Toner points out three reasons she believes the pressure to restore Altman was so strong. She claims employees were presented with only two options about how things could go (ditching the board to restore Altman or seeing the company destroyed), and since people didn’t want the company to fall apart, they supported the other one. She also says many people were scared of going against Altman after watching him retaliate against others.</p><p>Her last reason is Altman’s track record prior to OpenAI:</p><div><blockquote><p>And I guess the last thing I would say about this is that this actually isn’t a new problem for Sam. And if you look at some of the reporting that that has come out since November. It’s come out that he was actually fired from his previous job at Y Combinator, which was hushed up at the time. And then at, you know, his job before that, which was his only other job in Silicon Valley, his startup Loopt, apparently the management team went to the board there twice and asked the board to fire him for what they called deceptive and chaotic behavior. If you actually look at his track record, he doesn’t exactly have a glowing trail of references. This wasn’t a problem specific to the personalities on the board, as much as he would love to portray it that way.&nbsp;</p></blockquote></div><p>The podcast also includes a response from current OpenAI board chair Bret Taylor:</p><div><blockquote><p>We are disappointed that Ms. Toner continues to revisit these issues. An independent committee of the board worked with the law firm Wilmer Hale, to conduct an extensive review of the events of November. The review concluded that the prior board’s decision was not based on concerns regarding product safety or security, the pace of development, OpenAI’s finances, or its statements to investors, customers, or business partners. Additionally, over 95 percent of employees, including senior leadership, asked for Sam’s reinstatement as CEO and the resignation of the prior board. Our focus remains on moving forward and pursuing OpenAI’s mission to ensure AGI benefits all of humanity.</p></blockquote></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NSA Ghidra open-source reverse engineering framework (107 pts)]]></title>
            <link>https://ghidra-sre.org/</link>
            <guid>40508777</guid>
            <pubDate>Wed, 29 May 2024 05:28:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ghidra-sre.org/">https://ghidra-sre.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40508777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <div>
            <h2>Getting Help</h2>
            <p>Ghidra provides context-sensitive help on menu items, dialogs, buttons and tool windows.  To access the help, press <kbd>F1</kbd> or <kbd>Help</kbd> on any menu item or dialog. </p>
            <p><a href="https://github.com/NationalSecurityAgency/ghidra/wiki" role="button">Visit our Wiki</a></p>
            <p><a href="https://github.com/NationalSecurityAgency/ghidra/issues" role="button">Issue Tracker</a></p>
          </div>
          <div>
            <h2>Join the Community</h2>
            <p>Ghidra is one of many open source software (OSS) projects developed within the <a href="https://code.nsa.gov/">National Security Agency</a>. Complete source code for Ghidra along with build instructions have been added to the repository.  Please read the updated CONTRIBUTING guide to find out more about how you can join the community.</p>
            <p><a href="https://github.com/NationalSecurityAgency/ghidra" role="button">GitHub Repository</a></p>
          </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-OpenAI board member provides her first detailed account of CEO ouster (106 pts)]]></title>
            <link>https://www.reuters.com/technology/ex-openai-board-member-provides-her-first-detailed-account-ceo-ouster-2024-05-29/</link>
            <guid>40508719</guid>
            <pubDate>Wed, 29 May 2024 05:17:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/ex-openai-board-member-provides-her-first-detailed-account-ceo-ouster-2024-05-29/">https://www.reuters.com/technology/ex-openai-board-member-provides-her-first-detailed-account-ceo-ouster-2024-05-29/</a>, See on <a href="https://news.ycombinator.com/item?id=40508719">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/ex-openai-board-member-provides-her-first-detailed-account-ceo-ouster-2024-05-29/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[What We Learned from a Year of Building with LLMs (210 pts)]]></title>
            <link>https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</link>
            <guid>40508390</guid>
            <pubDate>Wed, 29 May 2024 04:14:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/">https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</a>, See on <a href="https://news.ycombinator.com/item?id=40508390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

              
              
              
              
              
              




<div itemscope="" itemtype="http://schema.org/Product" id="trial-cta">
  <p><a href="https://www.oreilly.com/online-learning/">
      <img itemprop="image" src="https://d3ansictanv2wj.cloudfront.net/safari-topic-cta-1f60e6f96856da19ba3cb25660472ca5.jpg">
    </a>
  </p>
  <p>
    <h2>
      Learn faster. Dig deeper. See farther.
    </h2>
  </p>
   
</div>



<p>It’s an exciting time to build with large language models (LLMs). Over the past year, LLMs have become “good enough” for real-world applications. The pace of improvements in LLMs, coupled with a parade of demos on social media, will fuel an estimated $200B investment in AI by 2025. LLMs are also broadly accessible, allowing everyone, not just ML engineers and scientists, to build intelligence into their products. While the barrier to entry for building AI products has been lowered, creating those effective beyond a demo remains a deceptively difficult endeavor.</p>



<p>We’ve identified some crucial, yet often neglected, lessons and methodologies informed by machine learning that are essential for developing products based on LLMs. Awareness of these concepts can give you a competitive advantage against most others in the field without requiring ML expertise! Over the past year, the six of us have been building real-world applications on top of LLMs. We realized that there was a need to distill these lessons in one place for the benefit of the community.</p>



<p>We come from a variety of backgrounds and serve in different roles, but we’ve all experienced firsthand the challenges that come with using this new technology. Two of us are independent consultants who’ve helped numerous clients take LLM projects from initial concept to successful product, seeing the patterns determining success or failure. One of us is a researcher studying how ML/AI teams work and how to improve their workflows. Two of us are leaders on applied AI teams: one at a tech giant and one at a startup. Finally, one of us has taught deep learning to thousands and now works on making AI tooling and infrastructure easier to use. Despite our different experiences, we were struck by the consistent themes in the lessons we’ve learned, and we’re surprised that these insights aren’t more widely discussed.</p>



<p>Our goal is to make this a practical guide to building successful products around LLMs, drawing from our own experiences and pointing to examples from around the industry. We’ve spent the past year getting our hands dirty and gaining valuable lessons, often the hard way. While we don’t claim to speak for the entire industry, here we share some advice and lessons for anyone building products with LLMs.</p>



<p>This work is organized into three sections: tactical, operational, and strategic. This is the first of three pieces. It dives into the tactical nuts and bolts of working with LLMs. We share best practices and common pitfalls around prompting, setting up retrieval-augmented generation, applying flow engineering, and evaluation and monitoring. Whether you’re a practitioner building with LLMs or a hacker working on weekend projects, this section was written for you. Look out for the operational and strategic sections in the coming weeks.</p>



<p>Ready to <s>dive</s> delve in? Let’s go.</p>



<h2><strong>Tactical</strong></h2>



<p>In this section, we share best practices for the core components of the emerging LLM stack: prompting tips to improve quality and reliability, evaluation strategies to assess output, retrieval-augmented generation ideas to improve grounding, and more. We also explore how to design human-in-the-loop workflows. While the technology is still rapidly developing, we hope these lessons, the by-product of countless experiments we’ve collectively run, will stand the test of time and help you build and ship robust LLM applications.</p>



<h3><strong>Prompting</strong></h3>



<p>We recommend starting with prompting when developing new applications. It’s easy to both underestimate <em>and</em> overestimate its importance. It’s underestimated because the right prompting techniques, when used correctly, can get us very far. It’s overestimated because even prompt-based applications require significant engineering around the prompt to work well.</p>



<h4><strong>Focus on getting the most out of fundamental prompting techniques</strong></h4>



<p>A few prompting techniques have consistently helped improve performance across various models and tasks: n-shot prompts + in-context learning, chain-of-thought, and providing relevant resources.</p>



<p>The idea of in-context learning via n-shot prompts is to provide the LLM with a few examples that demonstrate the task and align outputs to our expectations. A few tips: </p>



<ul><li>If n is too low, the model may over-anchor on those specific examples, hurting its ability to generalize. As a rule of thumb, aim for n ≥ 5. Don’t be afraid to go as high as a few dozen.</li><li>Examples should be representative of the expected input distribution. If you’re building a movie summarizer, include samples from different genres in roughly the proportion you expect to see in practice.</li><li>You don’t necessarily need to provide the full input-output pairs. In many cases, examples of desired outputs are sufficient.</li><li>If you are using an LLM that supports tool use, your n-shot examples should also use the tools you want the agent to use.</li></ul>



<p>In chain-of-thought (CoT) prompting, we encourage the LLM to explain its thought process before returning the final answer. Think of it as providing the LLM with a sketchpad so it doesn’t have to do it all in memory. The original approach was to simply add the phrase “Let’s think step-by-step” as part of the instructions. However, we’ve found it helpful to make the CoT more specific, where adding specificity via an extra sentence or two often reduces hallucination rates significantly. For example, when asking an LLM to summarize a meeting transcript, we can be explicit about the steps, such as:</p>



<ul><li>First, list the key decisions, follow-up items, and associated owners in a sketchpad.</li><li>Then, check that the details in the sketchpad are factually consistent with the transcript.</li><li>Finally, synthesize the key points into a concise summary.</li></ul>



<p>Recently, <a href="https://arxiv.org/abs/2405.04776" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">some doubt</a> has been cast on whether this technique is as powerful as believed. Additionally, there’s significant debate about exactly what happens during inference when chain-of-thought is used. Regardless, this technique is one to experiment with when possible.</p>



<p>Providing relevant resources is a powerful mechanism to expand the model’s knowledge base, reduce hallucinations, and increase the user’s trust. Often accomplished via retrieval augmented generation (RAG), providing the model with snippets of text that it can directly utilize in its response is an essential technique. When providing the relevant resources, it’s not enough to merely include them; don’t forget to tell the model to prioritize their use, refer to them directly, and sometimes to mention when none of the resources are sufficient. These help “ground” agent responses to a corpus of resources. </p>



<h4><strong>Structure your inputs and outputs</strong></h4>



<p>Structured input and output help models better understand the input as well as return output that can reliably integrate with downstream systems. Adding serialization formatting to your inputs can help provide more clues to the model as to the relationships between tokens in the context, additional metadata to specific tokens (like types), or relate the request to similar examples in the model’s training data. </p>



<p>As an example, many questions on the internet about writing SQL begin by specifying the SQL schema. Thus, you may expect that effective prompting for Text-to-SQL should include structured schema definitions; <a href="https://www.researchgate.net/publication/371223615_SQL-PaLM_Improved_Large_Language_ModelAdaptation_for_Text-to-SQL" target="_blank" rel="noreferrer noopener" aria-label="indeed (opens in a new tab)">indeed</a>.</p>



<p>Structured output serves a similar purpose, but it also simplifies integration into downstream components of your system. <a rel="noreferrer noopener" aria-label="Instructor (opens in a new tab)" href="https://github.com/jxnl/instructor" target="_blank">Instructor</a> and <a href="https://github.com/outlines-dev/outlines" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Outlines</a> work well for structured output. (If you’re importing an LLM API SDK, use Instructor; if you’re importing Huggingface for a self-hosted model, use Outlines.) Structured input expresses tasks clearly and resembles how the training data is formatted, increasing the probability of better output.</p>



<p>When using structured input, be aware that each LLM family has their own preferences. Claude prefers <code>xml</code> while GPT favors Markdown and JSON. With XML, you can even pre-fill Claude’s responses by providing a <code>response</code> tag like so.</p>



<pre>                                                     <code>&lt;/&gt; python
messages=[     
    {         
        "role": "user",         
        "content": """Extract the &lt;name&gt;, &lt;size&gt;, &lt;price&gt;, and &lt;color&gt; </code>
                   <code>from this product description into your &lt;response&gt;.   
                &lt;description&gt;The SmartHome Mini </code>
                   <code>is a compact smart home assistant </code>
                   <code>available in black or white for only $49.99. </code>
                   <code>At just 5 inches wide, it lets you control   </code>
                   <code>lights, thermostats, and other connected </code>
                   <code>devices via voice or app—no matter where you</code>
<code>                   place it in your home. This affordable little hub</code>
                  <code> brings convenient hands-free control to your</code>
                  <code> smart devices.             
                &lt;/description&gt;"""     
   },     
   {         
        "role": "assistant",         
        "content": "&lt;response&gt;&lt;name&gt;"     
   } 
]</code></pre>



<h4><strong>Have small prompts that do one thing, and only one thing, well</strong></h4>



<p>A common anti-pattern/code smell in software is the “<a rel="noreferrer noopener" aria-label="God Object (opens in a new tab)" href="https://en.wikipedia.org/wiki/God_object" target="_blank">God Object</a>,” where we have a single class or function that does everything. The same applies to prompts too.</p>



<p>A prompt typically starts simple: A few sentences of instruction, a couple of examples, and we’re good to go. But as we try to improve performance and handle more edge cases, complexity creeps in. More instructions. Multi-step reasoning. Dozens of examples. Before we know it, our initially simple prompt is now a 2,000 token frankenstein. And to add injury to insult, it has worse performance on the more common and straightforward inputs! GoDaddy shared this challenge as their <a href="https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough" target="_blank" rel="noreferrer noopener" aria-label="No. 1 lesson from building with LLMs (opens in a new tab)">No. 1 lesson from building with LLMs</a>.</p>



<p>Just like how we strive (read: struggle) to keep our systems and code simple, so should we for our prompts. Instead of having a single, catch-all prompt for the meeting transcript summarizer, we can break it into steps to:</p>



<ul><li>Extract key decisions, action items, and owners into structured format</li><li>Check extracted details against the original transcription for consistency</li><li>Generate a concise summary from the structured details</li></ul>



<p>As a result, we’ve split our single prompt into multiple prompts that are each simple, focused, and easy to understand. And by breaking them up, we can now iterate and eval each prompt individually.</p>



<h4><strong>Craft your context tokens</strong></h4>



<p>Rethink, and challenge your assumptions about how much context you actually need to send to the agent. Be like Michaelangelo, do not build up your context sculpture—chisel away the superfluous material until the sculpture is revealed. RAG is a popular way to collate all of the potentially relevant blocks of marble, but what are you doing to extract what’s necessary?</p>



<p>We’ve found that taking the final prompt sent to the model—with all of the context construction, and meta-prompting, and RAG results—putting it on a blank page and just reading it, really helps you rethink your context. We have found redundancy, self-contradictory language, and poor formatting using this method. </p>



<p>The other key optimization is the structure of your context. Your bag-of-docs representation isn’t helpful for humans, don’t assume it’s any good for agents. Think carefully about how you structure your context to underscore the relationships between parts of it, and make extraction as simple as possible.</p>



<h3><strong>Information Retrieval/RAG</strong></h3>



<p>Beyond prompting, another effective way to steer an LLM is by providing knowledge as part of the prompt. This grounds the LLM on the provided context which is then used for in-context learning. This is known as retrieval-augmented generation (RAG). Practitioners have found RAG effective at providing knowledge and improving output, while requiring far less effort and cost compared to finetuning.RAG is only as good as the retrieved documents’ relevance, density, and detail</p>



<h4><strong>The quality of your RAG’s output is dependent on the quality of retrieved documents, which in turn can be considered along a few factors.</strong></h4>



<p>The first and most obvious metric is relevance. This is typically quantified via ranking metrics such as <a rel="noreferrer noopener" aria-label="Mean Reciprocal Rank (MRR) (opens in a new tab)" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank" target="_blank">Mean Reciprocal Rank (MRR)</a> or <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain" target="_blank" rel="noreferrer noopener" aria-label="Normalized Discounted Cumulative Gain (NDCG) (opens in a new tab)">Normalized Discounted Cumulative Gain (NDCG)</a>. MRR evaluates how well a system places the first relevant result in a ranked list while NDCG considers the relevance of all the results and their positions. They measure how good the system is at ranking relevant documents higher and irrelevant documents lower. For example, if we’re retrieving user summaries to generate movie review summaries, we’ll want to rank reviews for the specific movie higher while excluding reviews for other movies.</p>



<p>Like traditional recommendation systems, the rank of retrieved items will have a significant impact on how the LLM performs on downstream tasks. To measure the impact, run a RAG-based task but with the retrieved items shuffled—how does the RAG output perform?</p>



<p>Second, we also want to consider information density. If two documents are equally relevant, we should prefer one that’s more concise and has lesser extraneous details. Returning to our movie example, we might consider the movie transcript and all user reviews to be relevant in a broad sense. Nonetheless, the top-rated reviews and editorial reviews will likely be more dense in information.</p>



<p>Finally, consider the level of detail provided in the document. Imagine we’re building a RAG system to generate SQL queries from natural language. We could simply provide table schemas with column names as context. But, what if we include column descriptions and some representative values? The additional detail could help the LLM better understand the semantics of the table and thus generate more correct SQL.</p>



<h4><strong>Don’t forget keyword search; use it as a baseline and in hybrid search.</strong></h4>



<p>Given how prevalent the embedding-based RAG demo is, it’s easy to forget or overlook the decades of research and solutions in information retrieval.</p>



<p>Nonetheless, while embeddings are undoubtedly a powerful tool, they are not the be all and end all. First, while they excel at capturing high-level semantic similarity, they may struggle with more specific, keyword-based queries, like when users search for names (e.g., Ilya), acronyms (e.g., RAG), or IDs (e.g., claude-3-sonnet). Keyword-based search, such as BM25, are explicitly designed for this. And after years of keyword-based search, users have likely taken it for granted and may get frustrated if the document they expect to retrieve isn’t being returned. </p>



<blockquote><p>Vector embeddings <em>do not</em> magically solve search. In fact, the heavy lifting is in the step before you re-rank with semantic similarity search. Making a genuine improvement over BM25 or full-text search is hard. </p><cite>— <a href="https://x.com/AravSrinivas/status/1737886080555446552" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Aravind Srinivas, CEO Perplexity.ai</a></cite></blockquote>



<blockquote><p>We’ve been communicating this to our customers and partners for months now. Nearest Neighbor Search with naive embeddings yields very noisy results and you’re likely better off starting with a keyword-based approach.</p><cite>— <a href="https://twitter.com/beyang/status/1767330006999720318" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Beyang Liu, CTO Sourcegraph</a></cite></blockquote>



<p>Second, it’s more straightforward to understand why a document was retrieved with keyword search—we can look at the keywords that match the query. In contrast, embedding-based retrieval is less interpretable. Finally, thanks to systems like Lucene and OpenSearch that have been optimized and battle-tested over decades, keyword search is usually more computationally efficient.</p>



<p>In most cases, a hybrid will work best: keyword matching for the obvious matches, and embeddings for synonyms, hypernyms, and spelling errors, as well as multimodality (e.g., images and text). <a href="https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/" target="_blank" rel="noreferrer noopener" aria-label="Shortwave shared how they built their RAG pipeline (opens in a new tab)">Shortwave shared how they built their RAG pipeline</a>, including query rewriting, keyword + embedding retrieval, and ranking.</p>



<h4><strong>Prefer RAG over fine-tuning for new knowledge</strong></h4>



<p>Both RAG and fine-tuning can be used to incorporate new information into LLMs and increase performance on specific tasks. Thus, which should we try first?</p>



<p>Recent research suggests that RAG may have an edge. <a rel="noreferrer noopener" aria-label="One study (opens in a new tab)" href="https://arxiv.org/abs/2312.05934" target="_blank">One study</a> compared RAG against unsupervised fine-tuning (a.k.a. continued pre-training), evaluating both on a subset of MMLU and current events. They found that RAG consistently outperformed fine-tuning for knowledge encountered during training as well as entirely new knowledge. In <a rel="noreferrer noopener" aria-label="another paper (opens in a new tab)" href="https://arxiv.org/abs/2401.08406" target="_blank">another paper</a>, they compared RAG against supervised fine-tuning on an agricultural dataset. Similarly, the performance boost from RAG was greater than fine-tuning, especially for GPT-4 (see Table 20 of the paper).</p>



<p>Beyond improved performance, RAG comes with several practical advantages too. First, compared to continuous pretraining or fine-tuning, it’s easier—and cheaper!—to keep retrieval indices up-to-date. Second, if our retrieval indices have problematic documents that contain toxic or biased content, we can easily drop or modify the offending documents.</p>



<p>In addition, the R in RAG provides finer grained control over how we retrieve documents. For example, if we’re hosting a RAG system for multiple organizations, by partitioning the retrieval indices, we can ensure that each organization can only retrieve documents from their own index. This ensures that we don’t inadvertently expose information from one organization to another.</p>



<h4><strong>Long-context models won’t make RAG obsolete</strong></h4>



<p>With Gemini 1.5 providing context windows of up to 10M tokens in size, some have begun to question the future of RAG. </p>



<blockquote><p>I tend to believe that Gemini 1.5 is significantly overhyped by Sora. A context window of 10M tokens effectively makes most of existing RAG frameworks unnecessary—you simply put whatever your data into the context and talk to the model like usual. Imagine how it does to all the startups/agents/LangChain projects where most of the engineering efforts goes to RAG 😅 Or in one sentence: the 10m context kills RAG. Nice work Gemini.</p><cite>— <a href="https://x.com/Francis_YAO_/status/1758935954189115714" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Yao Fu</a></cite></blockquote>



<p>While it’s true that long contexts will be a game-changer for use cases such as analyzing multiple documents or chatting with PDFs, the rumors of RAG’s demise are greatly exaggerated.</p>



<p>First, even with a context window of 10M tokens, we’d still need a way to select information to feed into the model. Second, beyond the narrow needle-in-a-haystack eval, we’ve yet to see convincing data that models can effectively reason over such a large context. Thus, without good retrieval (and ranking), we risk overwhelming the model with distractors, or may even fill the context window with completely irrelevant information.</p>



<p>Finally, there’s cost. The Transformer’s inference cost scales quadratically (or linearly in both space and time) with context length. Just because there exists a model that could read your organization’s entire Google Drive contents before answering each question doesn’t mean that’s a good idea. Consider an analogy to how we use RAM: we still read and write from disk, even though there exist compute instances with <a href="https://aws.amazon.com/ec2/instance-types/high-memory/" target="_blank" rel="noreferrer noopener" aria-label="RAM running into the tens of terabytes (opens in a new tab)">RAM running into the tens of terabytes</a>.</p>



<p>So don’t throw your RAGs in the trash just yet. This pattern will remain useful even as context windows grow in size.</p>



<h3><strong>Tuning and optimizing workflows</strong></h3>



<p>Prompting an LLM is just the beginning. To get the most juice out of them, we need to think beyond a single prompt and embrace workflows. For example, how could we split a single complex task into multiple simpler tasks? When is finetuning or caching helpful with increasing performance and reducing latency/cost? In this section, we share proven strategies and real-world examples to help you optimize and build reliable LLM workflows.</p>



<h4><strong>Step-by-step, multi-turn “flows” can give large boosts.</strong></h4>



<p>We already know that by decomposing a single big prompt into multiple smaller prompts, we can achieve better results. An example of this is <a href="https://arxiv.org/abs/2401.08500" target="_blank" rel="noreferrer noopener" aria-label="AlphaCodium (opens in a new tab)">AlphaCodium</a>: By switching from a single prompt to a multi-step workflow, they increased GPT-4 accuracy (pass@5) on CodeContests from 19% to 44%. The workflow includes:</p>



<ul><li>Reflecting on the problem</li><li>Reasoning on the public tests</li><li>Generating possible solutions</li><li>Ranking possible solutions</li><li>Generating synthetic tests</li><li>Iterating on the solutions on public and synthetic tests.</li></ul>



<p>Small tasks with clear objectives make for the best agent or flow prompts. It’s not required that every agent prompt requests structured output, but structured outputs help a lot to interface with whatever system is orchestrating the agent’s interactions with the environment.</p>



<p>Some things to try</p>



<ul><li>An explicit planning step, as tightly specified as possible. Consider having predefined plans to choose from (c.f. https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del).</li><li>Rewriting the original user prompts into agent prompts. Be careful, this process is lossy!</li><li>Agent behaviors as linear chains, DAGs, and State-Machines; different dependency and logic relationships can be more and less appropriate for different scales. Can you squeeze performance optimization out of different task architectures?</li><li>Planning validations; your planning can include instructions on how to evaluate the responses from other agents to make sure the final assembly works well together.</li><li>Prompt engineering with fixed upstream state—make sure your agent prompts are evaluated against a collection of variants of what may happen before.</li></ul>



<h4><strong>Prioritize deterministic workflows for now</strong></h4>



<p>While AI agents can dynamically react to user requests and the environment, their non-deterministic nature makes them a challenge to deploy. Each step an agent takes has a chance of failing, and the chances of recovering from the error are poor. Thus, the likelihood that an agent completes a multi-step task successfully decreases exponentially as the number of steps increases. As a result, teams building agents find it difficult to deploy reliable agents.</p>



<p>A promising approach is to have agent systems that produce deterministic plans which are then executed in a structured, reproducible way. In the first step, given a high-level goal or prompt, the agent generates a plan. Then, the plan is executed deterministically. This allows each step to be more predictable and reliable. Benefits include:</p>



<ul><li>Generated plans can serve as few-shot samples to prompt or finetune an agent.</li><li>Deterministic execution makes the system more reliable, and thus easier to test and debug. Furthermore, failures can be traced to the specific steps in the plan.</li><li>Generated plans can be represented as directed acyclic graphs (DAGs) which are easier, relative to a static prompt, to understand and adapt to new situations.</li></ul>



<p>The most successful agent builders may be those with strong experience managing junior engineers because the process of generating plans is similar to how we instruct and manage juniors. We give juniors clear goals and concrete plans, instead of vague open-ended directions, and we should do the same for our agents too. </p>



<p>In the end, the key to reliable, working agents will likely be found in adopting more structured, deterministic approaches, as well as collecting data to refine prompts and finetune models. Without this, we’ll build agents that may work exceptionally well some of the time, but on average, disappoint users which leads to poor retention.</p>



<h4><strong>Getting more diverse outputs beyond temperature</strong></h4>



<p>Suppose your task requires diversity in an LLM’s output. Maybe you’re writing an LLM pipeline to suggest products to buy from your catalog given a list of products the user bought previously. When running your prompt multiple times, you might notice that the resulting recommendations are too similar—so you might increase the temperature parameter in your LLM requests.</p>



<p>Briefly, increasing the temperature parameter makes LLM responses more varied. At sampling time, the probability distributions of the next token become flatter, meaning that tokens which are usually less likely get chosen more often. Still, when increasing temperature, you may notice some failure modes related to output diversity. For example,Some products from the catalog that could be a good fit may never be output by the LLM.The same handful of products might be overrepresented in outputs, if they are highly likely to follow the prompt based on what the LLM has learned at training time.If the temperature is too high, you may get outputs that reference nonexistent products (or gibberish!)</p>



<p>In other words, increasing temperature does not guarantee that the LLM will sample outputs from the probability distribution you expect (e.g., uniform random). Nonetheless, we have other tricks to increase output diversity. The simplest way is to adjust elements within the prompt. For example, if the prompt template includes a list of items, such as historical purchases, shuffling the order of these items each time they’re inserted into the prompt can make a significant difference. </p>



<p>Additionally, keeping a short list of recent outputs can help prevent redundancy. In our recommended products example, by instructing the LLM to avoid suggesting items from this recent list, or by rejecting and resampling outputs that are similar to recent suggestions, we can further diversify the responses. Another effective strategy is to vary the phrasing used in the prompts. For instance, incorporating phrases like “pick an item that the user would love using regularly” or “select a product that the user would likely recommend to friends” can shift the focus and thereby influence the variety of recommended products.</p>



<h4><strong>Caching is underrated.</strong></h4>



<p>Caching saves cost and eliminates generation latency by removing the need to recompute responses for the same input. Furthermore, if a response has previously been guardrailed, we can serve these vetted responses and reduce the risk of serving harmful or inappropriate content.</p>



<p>One straightforward approach to caching is to use unique IDs for the items being processed, such as if we’re summarizing new articles or <a href="https://www.cnbc.com/2023/06/12/amazon-is-using-generative-ai-to-summarize-product-reviews.html" target="_blank" rel="noreferrer noopener" aria-label="product reviews (opens in a new tab)">product reviews</a>. When a request comes in, we can check to see if a summary already exists in the cache. If so, we can return it immediately; if not, we generate, guardrail, and serve it, and then store it in the cache for future requests.</p>



<p>For more open-ended queries, we can borrow techniques from the field of search, which also leverages caching for open-ended inputs. Features like autocomplete and spelling correction also help normalize user input and thus increase the cache hit rate.</p>



<h4><strong>When to fine-tune</strong></h4>



<p>We may have some tasks where even the most cleverly designed prompts fall short. For example, even after significant prompt engineering, our system may still be a ways from returning reliable, high-quality output. If so, then it may be necessary to finetune a model for your specific task. </p>



<p>Successful examples include:</p>



<ul><li><a rel="noreferrer noopener" aria-label="Honeycomb's Natural Language Query Assistant (opens in a new tab)" href="https://www.honeycomb.io/blog/introducing-query-assistant" target="_blank">Honeycomb’s Natural Language Query Assistant</a>: Initially, the “programming manual” was provided in the prompt together with n-shot examples for in-context learning. While this worked decently, fine-tuning the model led to better output on the syntax and rules of the domain-specific language.</li><li><a href="https://www.youtube.com/watch?v=B_DMMlDuJB0" target="_blank" rel="noreferrer noopener" aria-label="ReChat's Lucy (opens in a new tab)">ReChat’s Lucy</a>: The LLM needed to generate responses in a very specific format that combined structured and unstructured data for the frontend to render correctly. Fine-tuning was essential to get it to work consistently.</li></ul>



<p>Nonetheless, while fine-tuning can be effective, it comes with significant costs. We have to annotate fine-tuning data, finetune and evaluate models, and eventually self-host them. Thus, consider if the higher upfront cost is worth it. If prompting gets you 90% of the way there, then fine-tuning may not be worth the investment. However, if we do decide to fine-tune, to reduce the cost of collecting human annotated data, we can <a rel="noreferrer noopener" aria-label="generate and finetune on synthetic data (opens in a new tab)" href="https://eugeneyan.com/writing/synthetic/" target="_blank">generate and finetune on synthetic data</a>, or <a rel="noreferrer noopener" aria-label="bootstrap on open-source data (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">bootstrap on open-source data</a>.</p>



<h3><strong> Evaluation &amp; Monitoring</strong></h3>



<p>Evaluating LLMs can be a minefield. The inputs and the outputs of LLMs are arbitrary text, and the tasks we set them to are varied. Nonetheless, rigorous and thoughtful evals are critical—it’s no coincidence that technical leaders at OpenAI <a rel="noreferrer noopener" aria-label="work on evaluation and give feedback on individual evals (opens in a new tab)" href="https://twitter.com/eugeneyan/status/1701692908074873036" target="_blank">work on evaluation and give feedback on individual evals</a>. </p>



<p>Evaluating LLM applications invites a diversity of definitions and reductions: it’s simply unit testing, or it’s more like observability, or maybe it’s just data science. We have found all of these perspectives useful. In the following section, we provide some lessons we’ve learned about what is important in building evals and monitoring pipelines.</p>



<h4><strong>Create a few assertion-based unit tests from real input/output samples</strong></h4>



<p>Create <a rel="noreferrer noopener" aria-label="unit tests (i.e., assertions) (opens in a new tab)" href="https://hamel.dev/blog/posts/evals/#level-1-unit-tests" target="_blank">unit tests (i.e., assertions)</a> consisting of samples of inputs and outputs from production, with expectations for outputs based on at least three criteria. While three criteria might seem arbitrary, it’s a practical number to start with; fewer might indicate that your task isn’t sufficiently defined or is too open-ended, like a general-purpose chatbot. These unit tests, or assertions, should be triggered by any changes to the pipeline, whether it’s editing a prompt, adding new context via RAG, or other modifications. This <a rel="noreferrer noopener" aria-label="write-up has an example (opens in a new tab)" href="https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests" target="_blank">write-up has an example</a> of an assertion-based test for an actual use case.</p>



<p>Consider beginning with assertions that specify phrases or ideas to either include or exclude in all responses. Also consider checks to ensure that word, item, or sentence counts lie within a range. For other kinds of generation, assertions can look different. <a rel="noreferrer noopener" aria-label="Execution-evaluation (opens in a new tab)" href="https://www.semanticscholar.org/paper/Execution-Based-Evaluation-for-Open-Domain-Code-Wang-Zhou/1bed34f2c23b97fd18de359cf62cd92b3ba612c3" target="_blank">Execution-evaluation</a> is a powerful method for evaluating code-generation, wherein you run the generated code and determine that the state of runtime is sufficient for the user-request. </p>



<p>As an example, if the user asks for a new function named foo; then after executing the agent’s generated code, foo should be callable! One challenge in execution-evaluation is that the agent code frequently leaves the runtime in slightly different form than the target code. It can be effective to “relax” assertions to the absolute most weak assumptions that any viable answer would satisfy.</p>



<p>Finally, using your product as intended for customers (i.e., “dogfooding”) can provide insight into failure modes on real-world data. This approach not only helps identify potential weaknesses, but also provides a useful source of production samples that can be converted into evals.</p>



<h4><strong>LLM-as-Judge can work (somewhat), but it’s not a silver bullet</strong></h4>



<p>LLM-as-Judge, where we use a strong LLM to evaluate the output of other LLMs, has been met with skepticism by some. (Some of us were initially huge skeptics.) Nonetheless, when implemented well, LLM-as-Judge achieves decent correlation with human judgements, and can at least help build priors about how a new prompt or technique may perform. Specifically, when doing pairwise comparisons (e.g., control vs. treatment), LLM-as-Judge typically gets the direction right though the magnitude of the win/loss may be noisy.</p>



<p>Here are some suggestions to get the most out of LLM-as-Judge:</p>



<ul><li>Use pairwise comparisons: Instead of asking the LLM to score a single output on a <a rel="noreferrer noopener" aria-label="Likert (opens in a new tab)" href="https://en.wikipedia.org/wiki/Likert_scale" target="_blank">Likert</a> scale, present it with two options and ask it to select the better one. This tends to lead to more stable results.</li><li>Control for position bias: The order of options presented can bias the LLM’s decision. To mitigate this, do each pairwise comparison twice, swapping the order of pairs each time. Just be sure to attribute wins to the right option after swapping!</li><li>Allow for ties: In some cases, both options may be equally good. Thus, allow the LLM to declare a tie so it doesn’t have to arbitrarily pick a winner.</li><li>Use Chain-of-Thought: Asking the LLM to explain its decision before giving a final preference can increase eval reliability. As a bonus, this allows you to use a weaker but faster LLM and still achieve similar results. Because frequently this part of the pipeline is in batch mode, the extra latency from CoT isn’t a problem.</li><li>Control for response length: LLMs tend to bias toward longer responses. To mitigate this, ensure response pairs are similar in length.</li></ul>



<p>One particularly powerful application of LLM-as-Judge is checking a new prompting strategy against regression. If you have tracked a collection of production results, sometimes you can rerun those production examples with a new prompting strategy, and use LLM-as-Judge to quickly assess where the new strategy may suffer.</p>



<p>Here’s an example of a <a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">simple but effective approach</a> to iterate on LLM-as-Judge, where we simply log the LLM response, judge’s critique (i.e., CoT), and final outcome. They are then reviewed with stakeholders to identify areas for improvement. Over three iterations, agreement with human and LLM improved from 68% to 94%!</p>



<figure><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2024/05/Picture1.png" alt="" width="800" height="229"></figure>



<p>LLM-as-Judge is not a silver bullet though. There are subtle aspects of language where even the strongest models fail to evaluate reliably. In addition, we’ve found that <a rel="noreferrer noopener" aria-label="conventional classifiers (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">conventional classifiers</a> and reward models can achieve higher accuracy than LLM-as-Judge, and with lower cost and latency. For code generation, LLM-as-Judge can be weaker than more direct evaluation strategies like execution-evaluation.</p>



<h4><strong>The “intern test” for evaluating generations</strong></h4>



<p>We like to use the following “intern test” when evaluating generations: If you took the exact input to the language model, including the context, and gave it to an average college student in the relevant major as a task, could they succeed? How long would it take?</p>



<p>If the answer is no because the LLM lacks the required knowledge, consider ways to enrich the context.</p>



<p>If the answer is no and we simply can’t improve the context to fix it, then we may have hit a task that’s too hard for contemporary LLMs.</p>



<p>If the answer is yes, but it would take a while, we can try to reduce the complexity of the task. Is it decomposable? Are there aspects of the task that can be made more templatized?</p>



<p>If the answer is yes, they would get it quickly, then it’s time to dig into the data. What’s the model doing wrong? Can we find a pattern of failures? Try asking the model to explain itself before or after it responds, to help you build a theory of mind. </p>



<h4><strong>Overemphasizing certain evals can hurt overall performance</strong></h4>



<blockquote><p>“When a measure becomes a target, it ceases to be a good measure.” </p><cite>— Goodhart’s Law</cite></blockquote>



<p>An example of this is the Needle-in-a-Haystack (NIAH) eval. The original eval helped quantify model recall as context sizes grew, as well as how recall is affected by needle position. However, it’s been so overemphasized that it’s featured as <a rel="noreferrer noopener" aria-label="Figure 1 for Gemini 1.5's report (opens in a new tab)" href="https://arxiv.org/abs/2403.05530" target="_blank">Figure 1 for Gemini 1.5’s report</a>. The eval involves inserting a specific phrase (“The special magic {city} number is: {number}”) into a long document which repeats the essays of Paul Graham, and then prompting the model to recall the magic number.</p>



<p>While some models achieve near-perfect recall, it’s questionable whether NIAH truly reflects the reasoning and recall abilities needed in real-world applications. Consider a more practical scenario: Given the transcript of an hour-long meeting, can the LLM summarize the key decisions and next steps, as well as correctly attribute each item to the relevant person? This task is more realistic, going beyond rote memorization and also considering the ability to parse complex discussions, identify relevant information, and synthesize summaries.</p>



<p>Here’s an example of a <a rel="noreferrer noopener" aria-label="practical NIAH eval (opens in a new tab)" href="https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments" target="_blank">practical NIAH eval</a>. Using <a rel="noreferrer noopener" aria-label="transcripts of doctor-patient video calls (opens in a new tab)" href="https://github.com/wyim/aci-bench/tree/main/data/challenge_data" target="_blank">transcripts of doctor-patient video calls</a>, the LLM is queried about the patient’s medication. It also includes a more challenging NIAH, inserting a phrase for random ingredients for pizza toppings, such as “<em>The secret ingredients needed to build the perfect pizza are: Espresso-soaked dates, Lemon and Goat cheese.</em>” Recall was around 80% on the medication task and 30% on the pizza task.</p>



<figure><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2024/05/Picture2.png" alt=""></figure>



<p>Tangentially, an overemphasis on NIAH evals can lead to lower performance on extraction and summarization tasks. Because these LLMs are so finetuned to attend to every sentence, they may start to treat irrelevant details and distractors as important, thus including them in the final output (when they shouldn’t!)</p>



<p>This could also apply to other evals and use cases. For example, summarization. An emphasis on factual consistency could lead to summaries that are less specific (and thus less likely to be factually inconsistent) and possibly less relevant. Conversely, an emphasis on writing style and eloquence could lead to more flowery, marketing-type language that could introduce factual inconsistencies.</p>



<h4><strong>Simplify annotation to binary tasks or pairwise comparisons</strong></h4>



<p>Providing open-ended feedback or ratings for model output on a <a rel="noreferrer noopener" aria-label="Likert scale (opens in a new tab)" href="https://en.wikipedia.org/wiki/Likert_scale" target="_blank">Likert scale</a> is cognitively demanding. As a result, the data collected is more noisy—due to variability among human raters—and thus less useful. A more effective approach is to simplify the task and reduce the cognitive burden on annotators. Two tasks that work well are binary classifications and pairwise comparisons.</p>



<p>In binary classifications, annotators are asked to make a simple yes-or-no judgment on the model’s output. They might be asked whether the generated summary is factually consistent with the source document, or whether the proposed response is relevant, or if it contains toxicity. Compared to the Likert scale, binary decisions are more precise, have higher consistency among raters, and lead to higher throughput. This was how <a rel="noreferrer noopener" aria-label="Doordash setup their labeling queues (opens in a new tab)" href="https://doordash.engineering/2020/08/28/overcome-the-cold-start-problem-in-menu-item-tagging/" target="_blank">Doordash setup their labeling queues</a> for tagging menu items though a tree of yes-no questions.</p>



<p>In pairwise comparisons, the annotator is presented with a pair of model responses and asked which is better. Because it’s easier for humans to say “A is better than B” than to assign an individual score to either A or B individually, this leads to faster and more reliable annotations (over Likert scales). At a <a rel="noreferrer noopener" aria-label="Llama2 meetup (opens in a new tab)" href="https://www.youtube.com/watch?v=CzR3OrOkM9w" target="_blank">Llama2 meetup</a>, Thomas Scialom, an author on the Llama2 paper, confirmed that pairwise-comparisons were faster and cheaper than collecting supervised finetuning data such as written responses. The former’s cost is $3.5 per unit while the latter’s cost is $25 per unit.</p>



<p>If you’re starting to write labeling guidelines, here are some <a rel="noreferrer noopener" aria-label="reference guidelines (opens in a new tab)" href="https://eugeneyan.com/writing/labeling-guidelines/" target="_blank">reference guidelines</a> from Google and Bing Search.</p>



<h4><strong>(Reference-free) evals and guardrails can be used interchangeably </strong></h4>



<p>Guardrails help to catch inappropriate or harmful content while evals help to measure the quality and accuracy of the model’s output. In the case of reference-free evals, they may be considered two sides of the same coin. Reference-free evals are evaluations that don’t rely on a “golden” reference, such as a human-written answer, and can assess the quality of output based solely on the input prompt and the model’s response.</p>



<p>Some examples of these are <a rel="noreferrer noopener" aria-label="summarization evals (opens in a new tab)" href="https://eugeneyan.com/writing/evals/#summarization-consistency-relevance-length" target="_blank">summarization evals</a>, where we only have to consider the input document to evaluate the summary on factual consistency and relevance. If the summary scores poorly on these metrics, we can choose not to display it to the user, effectively using the eval as a guardrail. Similarly, reference-free <a rel="noreferrer noopener" aria-label="translation evals (opens in a new tab)" href="https://eugeneyan.com/writing/evals/#translation-statistical--learned-evals-for-quality" target="_blank">translation evals</a> can assess the quality of a translation without needing a human-translated reference, again allowing us to use it as a guardrail.</p>



<h4><strong>LLMs will return output even when they shouldn’t</strong></h4>



<p>A key challenge when working with LLMs is that they’ll often generate output even when they shouldn’t. This can lead to harmless but nonsensical responses, or more egregious defects like toxicity or dangerous content. For example, when asked to extract specific attributes or metadata from a document, an LLM may confidently return values even when those values don’t actually exist. Alternatively, the model may respond in a language other than English because we provided non-English documents in the context.</p>



<p>While we can try to prompt the LLM to return a “not applicable” or “unknown” response, it’s not foolproof. Even when the log probabilities are available, they’re a poor indicator of output quality. While log probs indicate the likelihood of a token appearing in the output, they don’t necessarily reflect the correctness of the generated text. On the contrary, for instruction-tuned models that are trained to respond to queries and generate coherent response, log probabilities may not be well-calibrated. Thus, while a high log probability may indicate that the output is fluent and coherent, it doesn’t mean it’s accurate or relevant.</p>



<p>While careful prompt engineering can help to some extent, we should complement it with robust guardrails that detect and filter/regenerate undesired output. For example, OpenAI provides a <a rel="noreferrer noopener" aria-label="content moderation API (opens in a new tab)" href="https://platform.openai.com/docs/guides/moderation" target="_blank">content moderation API</a> that can identify unsafe responses such as hate speech, self-harm, or sexual output. Similarly, there are numerous packages for <a rel="noreferrer noopener" aria-label="detecting personally identifiable information (opens in a new tab)" href="https://github.com/topics/pii-detection" target="_blank">detecting personally identifiable information</a> (PII). One benefit is that guardrails are largely agnostic of the use case and can thus be applied broadly to all output in a given language. In addition, with precise retrieval, our system can deterministically respond “I don’t know” if there are no relevant documents.</p>



<p>A corollary here is that LLMs may fail to produce outputs when they are expected to. This can happen for various reasons, from straightforward issues like long tail latencies from API providers to more complex ones such as outputs being blocked by content moderation filters. As such, it’s important to consistently log inputs and (potentially a lack of) outputs for debugging and monitoring.</p>



<h4><strong>Hallucinations are a stubborn problem.</strong></h4>



<p>Unlike content safety or PII defects which have a lot of attention and thus seldom occur, factual inconsistencies are stubbornly persistent and more challenging to detect. They’re more common and occur at a baseline rate of 5 – 10%, and from what we’ve learned from LLM providers, it can be challenging to get it below 2%, even on simple tasks such as summarization.</p>



<p>To address this, we can combine prompt engineering (upstream of generation) and factual inconsistency guardrails (downstream of generation). For prompt engineering, techniques like CoT help reduce hallucination by getting the LLM to explain its reasoning before finally returning the output. Then, we can apply a <a rel="noreferrer noopener" aria-label="factual inconsistency guardrail (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">factual inconsistency guardrail</a> to assess the factuality of summaries and filter or regenerate hallucinations. In some cases, hallucinations can be deterministically detected. When using resources from RAG retrieval, if the output is structured and identifies what the resources are, you should be able to manually verify they’re sourced from the input context.</p>



<h2><strong>About the authors</strong></h2>



<p><strong>Eugene Yan</strong> designs, builds, and operates machine learning systems that serve customers at scale. He’s currently a Senior Applied Scientist at Amazon where he builds RecSys serving millions of customers worldwide <a rel="noreferrer noopener" aria-label="RecSys 2022 keynote (opens in a new tab)" href="https://eugeneyan.com/speaking/recsys2022-keynote/" target="_blank">RecSys 2022 keynote</a> and applies LLMs to serve customers better <a rel="noreferrer noopener" aria-label="AI Eng Summit 2023 keynote (opens in a new tab)" href="https://eugeneyan.com/speaking/ai-eng-summit/" target="_blank">AI Eng Summit 2023 keynote</a>. Previously, he led machine learning at Lazada (acquired by Alibaba) and a Healthtech Series A. He writes &amp; speaks about ML, RecSys, LLMs, and engineering at <a rel="noreferrer noopener" aria-label="eugeneyan.com (opens in a new tab)" href="https://eugeneyan.com/" target="_blank">eugeneyan.com</a> and <a rel="noreferrer noopener" aria-label="ApplyingML.com (opens in a new tab)" href="https://applyingml.com/" target="_blank">ApplyingML.com</a>.</p>



<p><strong>Bryan Bischof</strong> is the Head of AI at Hex, where he leads the team of engineers building Magic—the data science and analytics copilot. Bryan has worked all over the data stack leading teams in analytics, machine learning engineering, data platform engineering, and AI engineering. He started the data team at Blue Bottle Coffee, led several projects at Stitch Fix, and built the data teams at Weights and Biases. Bryan previously co-authored the book Building Production Recommendation Systems with O’Reilly, and teaches Data Science and Analytics in the graduate school at Rutgers. His Ph.D. is in pure mathematics. </p>



<p><strong>Charles Frye</strong> teaches people to build AI applications. After publishing research in <a rel="noreferrer noopener" aria-label="psychopharmacology (opens in a new tab)" href="https://pubmed.ncbi.nlm.nih.gov/24316346/" target="_blank">psychopharmacology</a> and <a rel="noreferrer noopener" aria-label="neurobiology (opens in a new tab)" href="https://journals.physiology.org/doi/full/10.1152/jn.00172.2016" target="_blank">neurobiology</a>, he got his Ph.D. at the University of California, Berkeley, for dissertation work on <a rel="noreferrer noopener" aria-label="neural network optimization (opens in a new tab)" href="https://arxiv.org/abs/2003.10397" target="_blank">neural network optimization</a>. He has taught thousands the entire stack of AI application development, from linear algebra fundamentals to GPU arcana and building defensible businesses, through educational and consulting work at Weights and Biases, <a rel="noreferrer noopener" aria-label="Full Stack Deep Learning (opens in a new tab)" href="https://fullstackdeeplearning.com/" target="_blank">Full Stack Deep Learning</a>, and Modal.</p>



<p><strong>Hamel Husain</strong> is a machine learning engineer with over 25 years of <a rel="noreferrer noopener" aria-label="experience (opens in a new tab)" href="https://www.linkedin.com/in/hamelhusain/" target="_blank">experience</a>. He has worked with innovative companies such as Airbnb and GitHub, which included <a rel="noreferrer noopener" aria-label="early LLM research used by OpenAI (opens in a new tab)" href="https://openai.com/index/introducing-text-and-code-embeddings#:~:text=models%20on%20the-,CodeSearchNet,),-evaluation%20suite%20where" target="_blank">early LLM research used by OpenAI</a> for code understanding. He has also led and contributed to numerous popular <a rel="noreferrer noopener" aria-label="open-source machine-learning tools (opens in a new tab)" href="https://hamel.dev/oss/opensource.html" target="_blank">open-source machine-learning tools</a>. Hamel is currently an <a rel="noreferrer noopener" aria-label="independent consultant (opens in a new tab)" href="https://hamel.dev/hire.html" target="_blank">independent consultant</a> helping companies operationalize Large Language Models (LLMs) to accelerate their AI product journey.</p>



<p><strong>Jason Liu</strong> is a distinguished machine learning <a rel="noreferrer noopener" aria-label="consultant (opens in a new tab)" href="https://jxnl.co/services/" target="_blank">consultant</a> known for leading teams to successfully ship AI products. Jason’s technical expertise covers personalization algorithms, search optimization, synthetic data generation, and MLOps systems. His experience includes companies like Stitchfix, where he created a recommendation framework and observability tools that handled 350 million daily requests. Additional roles have included Meta, NYU, and startups such as Limitless AI and Trunk Tools. </p>



<p><strong>Shreya Shankar</strong> is an ML engineer and PhD student in computer science at UC Berkeley. She was the first ML engineer at 2 startups, building AI-powered products from scratch that serve thousands of users daily. As a researcher, her work focuses on addressing data challenges in production ML systems through a human-centered approach. Her work has appeared in top data management and human-computer interaction venues like VLDB, SIGMOD, CIDR, and CSCW.</p>



<h2><strong>Contact Us</strong></h2>



<p>We would love to hear your thoughts on this post. You can contact us at <a rel="noreferrer noopener" aria-label="contact@applied-llms.org (opens in a new tab)" href="mailto:contact@applied-llms.org" target="_blank">contact@applied-llms.org</a>. Many of us are open to various forms of consulting and advisory. We will route you to the correct expert(s) upon contact with us if appropriate.</p>



<h2><strong>Acknowledgements</strong></h2>



<p>This series started as a conversation in a group chat, where Bryan quipped that he was inspired to write “A Year of AI Engineering.” Then, ✨magic✨ happened in the group chat, and we were all inspired to chip in and share what we’ve learned so far. </p>



<p>The authors would like to thank Eugene for leading the bulk of the document integration and overall structure in addition to a large proportion of the lessons. Additionally, for primary editing responsibilities and document direction. The authors would like to thank Bryan for the spark that led to this writeup, restructuring the write-up into tactical, operational, and strategic sections and their intros, and for pushing us to think bigger on how we could reach and help the community. The authors would like to thank Charles for his deep dives on cost and LLMOps, as well as weaving the lessons to make them more coherent and tighter—you have him to thank for this being 30 instead of 40 pages! The authors appreciate Hamel and Jason for their insights from advising clients and being on the front lines, for their broad generalizable learnings from clients, and for deep knowledge of tools. And finally, thank you Shreya for reminding us of the importance of evals and rigorous production practices and for bringing her research and original results to this piece.</p>



<p>Finally, the authors would like to thank all the teams who so generously shared your challenges and lessons in your own write-ups which we’ve referenced throughout this series, along with the AI communities for your vibrant participation and engagement with this group.</p>

                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI headphones let you listen to a single person in crowd, by looking at them (620 pts)]]></title>
            <link>https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/</link>
            <guid>40508278</guid>
            <pubDate>Wed, 29 May 2024 03:52:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/">https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/</a>, See on <a href="https://news.ycombinator.com/item?id=40508278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_content" tabindex="-1">

  			<p>
    <a href="http://www.washington.edu/news/category/engineering/" rel="category tag">Engineering</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/news-releases/" rel="category tag">News releases</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/research/" rel="category tag">Research</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/technology/" rel="category tag">Technology</a>  </p>
  
<p>May 23, 2024</p>

  


  


<nav id="mobile-relative" aria-label="mobile menu"></nav>
<p><iframe title="AI headphones filter out noise so you hear one voice in a crowd" width="750" height="422" src="https://www.youtube.com/embed/ArGKgodEUSo?feature=oembed&amp;enablejsapi=1&amp;origin=https://www.washington.edu" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Noise-canceling headphones have gotten very good at creating an auditory blank slate. But allowing certain sounds from a wearer’s environment through the erasure still challenges researchers. The latest edition of Apple’s AirPods Pro, for instance, <a href="https://www.cnbc.com/2023/09/18/airpods-pro-usb-c-hands-on-adaptive-audio-and-conversation-awareness.html">automatically adjusts sound levels</a> for wearers — sensing when they’re in conversation, for instance — but the user has little control over whom to listen to or when this happens.</p>
<p>A University of Washington team has developed an artificial intelligence system that lets a user wearing headphones look at a person speaking for three to five seconds to “enroll” them. The system, called “Target Speech Hearing,” then cancels all other sounds in the environment and plays just the enrolled speaker’s voice in real time even as the listener moves around in noisy places and no longer faces the speaker.</p>
<p>The team presented <a href="https://programs.sigchi.org/chi/2024/program/content/147319">its findings</a> May 14 in Honolulu at the ACM CHI Conference on Human Factors in Computing Systems. The <a href="https://github.com/vb000/LookOnceToHear">code for the proof-of-concept device</a> is available for others to build on. The system is not commercially available.</p>
<p>“We tend to think of AI now as web-based chatbots that answer questions,” said senior author <a href="https://homes.cs.washington.edu/~gshyam/">Shyam Gollakota</a>, a UW professor in the Paul G. Allen School of Computer Science &amp; Engineering. “But in this project, we develop AI to modify the auditory perception of anyone wearing headphones, given their preferences. With our devices you can now hear a single speaker clearly even if you are in a noisy environment with lots of other people talking.”</p>
<p>To use the system, a person wearing off-the-shelf headphones fitted with microphones taps a button while directing their head at someone talking. The sound waves from that speaker’s voice then should reach the microphones on both sides of the headset simultaneously; there’s a 16-degree margin of error. The headphones send that signal to an on-board embedded<a href="https://en.wikipedia.org/wiki/Single-board_computer"> computer</a>, where the team’s machine learning software learns the desired speaker’s vocal patterns. The system latches onto that speaker’s voice and continues to play it back to the listener, even as the pair moves around. The system’s ability to focus on the enrolled voice improves as the speaker keeps talking, giving the system more training data.</p>
<div>
<p><strong>Related:</strong></p>
<ul>
<li>For more information, see <a href="https://tsh.cs.washington.edu/">the team’s website</a></li>
<li>Stories from <a href="https://www.technologyreview.com/2024/05/23/1092832/noise-canceling-headphones-use-ai-to-let-a-single-voice-through/">MIT Technology Review </a>and <a href="https://www.geekwire.com/2024/look-and-listen-ai-headphones-cancel-background-noise-and-focus-on-one-speaker-after-a-glance/">GeekWire</a></li>
</ul>
</div>
<p>The team tested its system on 21 subjects, who rated the clarity of the enrolled speaker’s voice nearly twice as high as the unfiltered audio on average.</p>
<p>This work builds on the <a href="https://www.washington.edu/news/2023/11/09/ai-noise-canceling-headphones/">team’s previous “semantic hearing” research</a>, which allowed users to select specific sound classes — such as birds or voices — that they wanted to hear and canceled other sounds in the environment.</p>
<p>Currently the TSH system can enroll only one speaker at a time, and it’s only able to enroll a speaker when there is not another loud voice coming from the same direction as the target speaker’s voice. If a user isn’t happy with the sound quality, they can run another enrollment on the speaker to improve the clarity.</p>
<p>The team is working to expand the system to earbuds and hearing aids in the future.</p>
<p>Additional co-authors on the paper were <a href="https://homes.cs.washington.edu/~bandhav/">Bandhav Veluri</a>, <a href="https://www.linkedin.com/in/malek-itani-9311ba197/?originalSubdomain=lb">Malek Itani</a> and <a href="https://staff.washington.edu/tuochao/">Tuochao Chen</a>, UW doctoral students in the Allen School, and <a href="https://www.linkedin.com/in/ty274/">Takuya Yoshioka</a>, director of research at AssemblyAI. This research was funded by a <a href="https://www.washington.edu/news/2021/10/04/uws-shyam-gollakota-named-2021-moore-inventor-fellow/">Moore Inventor Fellow</a> award, a <a href="https://www.cs.washington.edu/supportcse/faculty/wrf-cable_professorship">Thomas J. Cabel Endowed Professorship</a> and a <a href="https://comotion.uw.edu/funding-and-competitions/programs/comotion-innovation-gap-fund/">UW CoMotion Innovation Gap Fund</a>.</p>
<p><em>For more information, contact </em><a href="mailto:tsh@cs.washington.edu"><em>tsh@cs.washington.edu</em></a><em>.</em></p>


<p><small>Tag(s): <a href="https://www.washington.edu/news/tag/bandhav-veluri/" rel="tag">Bandhav Veluri</a> • <a href="https://www.washington.edu/news/tag/college-of-engineering/" rel="tag">College of Engineering</a> • <a href="https://www.washington.edu/news/tag/department-of-electrical-computer-engineering/" rel="tag">Department of Electrical &amp; Computer Engineering</a> • <a href="https://www.washington.edu/news/tag/malek-itani/" rel="tag">Malek Itani</a> • <a href="https://www.washington.edu/news/tag/paul-g-allen-school-of-computer-science-engineering/" rel="tag">Paul G. Allen School of Computer Science &amp; Engineering</a> • <a href="https://www.washington.edu/news/tag/shyam-gollakota/" rel="tag">Shyam Gollakota</a> • <a href="https://www.washington.edu/news/tag/tuochao-chen/" rel="tag">Tuochao Chen</a></small></p><hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatTTS-Best open source TTS Model (153 pts)]]></title>
            <link>https://github.com/2noise/ChatTTS</link>
            <guid>40507039</guid>
            <pubDate>Wed, 29 May 2024 00:37:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/2noise/ChatTTS">https://github.com/2noise/ChatTTS</a>, See on <a href="https://news.ycombinator.com/item?id=40507039">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ChatTTS</h2><a id="user-content-chattts" aria-label="Permalink: ChatTTS" href="#chattts"></a></p>
<p dir="auto"><a href="https://github.com/2noise/ChatTTS/blob/main/README.md"><strong>English</strong></a> | <a href="https://github.com/2noise/ChatTTS/blob/main/README_CN.md"><strong>中文简体</strong></a></p>
<p dir="auto">ChatTTS is a text-to-speech model designed specifically for dialogue scenario such as LLM assistant. It supports both English and Chinese languages. Our model is trained with 100,000+ hours composed of chinese and english. The open-source version on HuggingFace is a 40,000 hours pre trained model without SFT.</p>
<p dir="auto">For formal inquiries about model and roadmap, please contact us at <a href="mailto:open-source@2noise.com">open-source@2noise.com</a>. You could join our QQ group: 808364215 for discussion. Adding github issues is always welcomed.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlights</h2><a id="user-content-highlights" aria-label="Permalink: Highlights" href="#highlights"></a></p>
<ol dir="auto">
<li><strong>Conversational TTS</strong>: ChatTTS is optimized for dialogue-based tasks, enabling natural and expressive speech synthesis. It supports multiple speakers, facilitating interactive conversations.</li>
<li><strong>Fine-grained Control</strong>: The model could predict and control fine-grained prosodic features, including laughter, pauses, and interjections.</li>
<li><strong>Better Prosody</strong>: ChatTTS surpasses most of open-source TTS models in terms of prosody. We provide pretrained models to support further research and development.</li>
</ol>
<p dir="auto">For the detailed description of the model, you can refer to <a href="https://www.bilibili.com/video/BV1zn4y1o7iV" rel="nofollow">video on Bilibili</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This repo is for academic purposes only. It is intended for educational and research use, and should not be used for any commercial or legal purposes. The authors do not guarantee the accuracy, completeness, or reliability of the information. The information and data used in this repo, are for academic and research purposes only. The data obtained from publicly available sources, and the authors do not claim any ownership or copyright over the data.</p>
<p dir="auto">ChatTTS is a powerful text-to-speech system. However, it is very important to utilize this technology responsibly and ethically. To limit the use of ChatTTS, we added a small amount of high-frequency noise during the training of the 40,000-hour model, and compressed the audio quality as much as possible using MP3 format, to prevent malicious actors from potentially using it for criminal purposes. At the same time, we have internally trained a detection model and plan to open-source it in the future.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">basic usage</h4><a id="user-content-basic-usage" aria-label="Permalink: basic usage" href="#basic-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import ChatTTS
from IPython.display import Audio

chat = ChatTTS.Chat()
chat.load_models()

texts = [&quot;<PUT YOUR TEXT HERE>&quot;,]

wavs = chat.infer(texts, use_decoder=True)
Audio(wavs[0], rate=24_000, autoplay=True)"><pre><span>import</span> <span>ChatTTS</span>
<span>from</span> <span>IPython</span>.<span>display</span> <span>import</span> <span>Audio</span>

<span>chat</span> <span>=</span> <span>ChatTTS</span>.<span>Chat</span>()
<span>chat</span>.<span>load_models</span>()

<span>texts</span> <span>=</span> [<span>"&lt;PUT YOUR TEXT HERE&gt;"</span>,]

<span>wavs</span> <span>=</span> <span>chat</span>.<span>infer</span>(<span>texts</span>, <span>use_decoder</span><span>=</span><span>True</span>)
<span>Audio</span>(<span>wavs</span>[<span>0</span>], <span>rate</span><span>=</span><span>24_000</span>, <span>autoplay</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">advanced usage</h4><a id="user-content-advanced-usage" aria-label="Permalink: advanced usage" href="#advanced-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="###################################
# Sample a speaker from Gaussian.
import torch
std, mean = torch.load('ChatTTS/asset/spk_stat.pt').chunk(2)
rand_spk = torch.randn(768) * std + mean

params_infer_code = {
  'spk_emb': rand_spk, # add sampled speaker 
  'temperature': .3, # using custom temperature
  'top_P': 0.7, # top P decode
  'top_K': 20, # top K decode
}

###################################
# For sentence level manual control.

# use oral_(0-9), laugh_(0-2), break_(0-7) 
# to generate special token in text to synthesize.
params_refine_text = {
  'prompt': '[oral_2][laugh_0][break_6]'
} 

wav = chat.infer(&quot;<PUT YOUR TEXT HERE>&quot;, params_refine_text=params_refine_text, params_infer_code=params_infer_code)

###################################
# For word level manual control.
text = 'What is [uv_break]your favorite english food?[laugh][lbreak]'
wav = chat.infer(text, skip_refine_text=True, params_infer_code=params_infer_code)
"><pre><span>###################################</span>
<span># Sample a speaker from Gaussian.</span>
<span>import</span> <span>torch</span>
<span>std</span>, <span>mean</span> <span>=</span> <span>torch</span>.<span>load</span>(<span>'ChatTTS/asset/spk_stat.pt'</span>).<span>chunk</span>(<span>2</span>)
<span>rand_spk</span> <span>=</span> <span>torch</span>.<span>randn</span>(<span>768</span>) <span>*</span> <span>std</span> <span>+</span> <span>mean</span>

<span>params_infer_code</span> <span>=</span> {
  <span>'spk_emb'</span>: <span>rand_spk</span>, <span># add sampled speaker </span>
  <span>'temperature'</span>: <span>.3</span>, <span># using custom temperature</span>
  <span>'top_P'</span>: <span>0.7</span>, <span># top P decode</span>
  <span>'top_K'</span>: <span>20</span>, <span># top K decode</span>
}

<span>###################################</span>
<span># For sentence level manual control.</span>

<span># use oral_(0-9), laugh_(0-2), break_(0-7) </span>
<span># to generate special token in text to synthesize.</span>
<span>params_refine_text</span> <span>=</span> {
  <span>'prompt'</span>: <span>'[oral_2][laugh_0][break_6]'</span>
} 

<span>wav</span> <span>=</span> <span>chat</span>.<span>infer</span>(<span>"&lt;PUT YOUR TEXT HERE&gt;"</span>, <span>params_refine_text</span><span>=</span><span>params_refine_text</span>, <span>params_infer_code</span><span>=</span><span>params_infer_code</span>)

<span>###################################</span>
<span># For word level manual control.</span>
<span>text</span> <span>=</span> <span>'What is [uv_break]your favorite english food?[laugh][lbreak]'</span>
<span>wav</span> <span>=</span> <span>chat</span>.<span>infer</span>(<span>text</span>, <span>skip_refine_text</span><span>=</span><span>True</span>, <span>params_infer_code</span><span>=</span><span>params_infer_code</span>)</pre></div>
<details open="">
  <summary><p dir="auto"><h4 tabindex="-1" dir="auto">Example: self introduction</h4><a id="user-content-example-self-introduction" aria-label="Permalink: Example: self introduction" href="#example-self-introduction"></a></p></summary>
<div dir="auto" data-snippet-clipboard-copy-content="inputs_en = &quot;&quot;&quot;
chat T T S is a text to speech model designed for dialogue applications. 
[uv_break]it supports mixed language input [uv_break]and offers multi speaker 
capabilities with precise control over prosodic elements [laugh]like like 
[uv_break]laughter[laugh], [uv_break]pauses, [uv_break]and intonation. 
[uv_break]it delivers natural and expressive speech,[uv_break]so please
[uv_break] use the project responsibly at your own risk.[uv_break]
&quot;&quot;&quot;.replace('\n', '') # English is still experimental.

params_refine_text = {
  'prompt': '[oral_2][laugh_0][break_4]'
} 
audio_array_cn = chat.infer(inputs_cn, params_refine_text=params_refine_text)
audio_array_en = chat.infer(inputs_en, params_refine_text=params_refine_text)"><pre><span>inputs_en</span> <span>=</span> <span>"""</span>
<span>chat T T S is a text to speech model designed for dialogue applications. </span>
<span>[uv_break]it supports mixed language input [uv_break]and offers multi speaker </span>
<span>capabilities with precise control over prosodic elements [laugh]like like </span>
<span>[uv_break]laughter[laugh], [uv_break]pauses, [uv_break]and intonation. </span>
<span>[uv_break]it delivers natural and expressive speech,[uv_break]so please</span>
<span>[uv_break] use the project responsibly at your own risk.[uv_break]</span>
<span>"""</span>.<span>replace</span>(<span>'<span>\n</span>'</span>, <span>''</span>) <span># English is still experimental.</span>

<span>params_refine_text</span> <span>=</span> {
  <span>'prompt'</span>: <span>'[oral_2][laugh_0][break_4]'</span>
} 
<span>audio_array_cn</span> <span>=</span> <span>chat</span>.<span>infer</span>(<span>inputs_cn</span>, <span>params_refine_text</span><span>=</span><span>params_refine_text</span>)
<span>audio_array_en</span> <span>=</span> <span>chat</span>.<span>infer</span>(<span>inputs_en</span>, <span>params_refine_text</span><span>=</span><span>params_refine_text</span>)</pre></div>
<details open="">
  <summary>
    
    <span aria-label="Video description intro_en_m.webm">intro_en_m.webm</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/130631963/334550151-e0f51251-db7f-4d39-a0e9-3e095bb65de1.webm?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5NzUzMDIsIm5iZiI6MTcxNjk3NTAwMiwicGF0aCI6Ii8xMzA2MzE5NjMvMzM0NTUwMTUxLWUwZjUxMjUxLWRiN2YtNGQzOS1hMGU5LTNlMDk1YmI2NWRlMS53ZWJtP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MjlUMDkzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTRiOTA5ZGU3ODU1YjhkNDdiNTQ5NDEyYmM0ZDM5ZTU2Mjc0Zjk1YzMzZGQ5MmYwNGM5MGU2OTAwZTYxMGEwMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.OycyeXc0nm2ao_AEgM71pEQObeEocV8vqqKD8qdOrm0" data-canonical-src="https://private-user-images.githubusercontent.com/130631963/334550151-e0f51251-db7f-4d39-a0e9-3e095bb65de1.webm?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5NzUzMDIsIm5iZiI6MTcxNjk3NTAwMiwicGF0aCI6Ii8xMzA2MzE5NjMvMzM0NTUwMTUxLWUwZjUxMjUxLWRiN2YtNGQzOS1hMGU5LTNlMDk1YmI2NWRlMS53ZWJtP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MjlUMDkzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTRiOTA5ZGU3ODU1YjhkNDdiNTQ5NDEyYmM0ZDM5ZTU2Mjc0Zjk1YzMzZGQ5MmYwNGM5MGU2OTAwZTYxMGEwMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.OycyeXc0nm2ao_AEgM71pEQObeEocV8vqqKD8qdOrm0" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description intro_en_f.webm">intro_en_f.webm</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/130631963/334550275-f5dcdd01-1091-47c5-8241-c4f6aaaa8bbd.webm?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5NzUzMDIsIm5iZiI6MTcxNjk3NTAwMiwicGF0aCI6Ii8xMzA2MzE5NjMvMzM0NTUwMjc1LWY1ZGNkZDAxLTEwOTEtNDdjNS04MjQxLWM0ZjZhYWFhOGJiZC53ZWJtP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MjlUMDkzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGRlYWRjYTE0MGIzMzRjMDBkMDZiZTkzMjcxYjYwMGNiNDE2MmY0YWM0NjQ1ODY2OGM4MTQ4OTM3OTkyMTAyNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.3m-dRvXxujXwd7QixpQ7yQkIMK5E7gvl6jMNpqmxHZg" data-canonical-src="https://private-user-images.githubusercontent.com/130631963/334550275-f5dcdd01-1091-47c5-8241-c4f6aaaa8bbd.webm?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5NzUzMDIsIm5iZiI6MTcxNjk3NTAwMiwicGF0aCI6Ii8xMzA2MzE5NjMvMzM0NTUwMjc1LWY1ZGNkZDAxLTEwOTEtNDdjNS04MjQxLWM0ZjZhYWFhOGJiZC53ZWJtP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MjlUMDkzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGRlYWRjYTE0MGIzMzRjMDBkMDZiZTkzMjcxYjYwMGNiNDE2MmY0YWM0NjQ1ODY2OGM4MTQ4OTM3OTkyMTAyNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.3m-dRvXxujXwd7QixpQ7yQkIMK5E7gvl6jMNpqmxHZg" controls="controls" muted="muted">

  </video>
</details>

</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul>
<li> Open-source the 40k hour base model and spk_stats file</li>
<li> Open-source VQ encoder and Lora training code</li>
<li> Streaming audio generation without refining the text*</li>
<li> Open-source the 40k hour version with multi-emotion control</li>
<li> ChatTTS.cpp maybe? (PR or new repo are welcomed.)</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h5 tabindex="-1" dir="auto">How much VRAM do I need? How about infer speed?</h5><a id="user-content-how-much-vram-do-i-need-how-about-infer-speed" aria-label="Permalink: How much VRAM do I need? How about infer speed?" href="#how-much-vram-do-i-need-how-about-infer-speed"></a></p>
<p dir="auto">For a 30-second audio clip, at least 4GB of GPU memory is required. For the 4090D GPU, it can generate audio corresponding to approximately 7 semantic tokens per second. The Real-Time Factor (RTF) is around 0.65.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">model stability is not good enough, with issues such as multi speakers or poor audio quality.</h5><a id="user-content-model-stability-is-not-good-enough-with-issues-such-as-multi-speakers-or-poor-audio-quality" aria-label="Permalink: model stability is not good enough, with issues such as multi speakers or poor audio quality." href="#model-stability-is-not-good-enough-with-issues-such-as-multi-speakers-or-poor-audio-quality"></a></p>
<p dir="auto">This is a problem that typically occurs with autoregressive models(for bark and valle). It's generally difficult to avoid. One can try multiple samples to find a suitable result.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Besides laughter, can we control anything else? Can we control other emotions?</h5><a id="user-content-besides-laughter-can-we-control-anything-else-can-we-control-other-emotions" aria-label="Permalink: Besides laughter, can we control anything else? Can we control other emotions?" href="#besides-laughter-can-we-control-anything-else-can-we-control-other-emotions"></a></p>
<p dir="auto">In the current released model, the only token-level control units are [laugh], [uv_break], and [lbreak]. In future versions, we may open-source models with additional emotional control capabilities.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/suno-ai/bark">bark</a>, <a href="https://github.com/coqui-ai/TTS">XTTSv2</a> and <a href="https://arxiv.org/abs/2301.02111" rel="nofollow">valle</a> demostrate a remarkable TTS result by a autoregressive-style system.</li>
<li><a href="https://github.com/fishaudio/fish-speech">fish-speech</a> reveals capability of GVQ as audio tokenizer for LLM modeling.</li>
<li><a href="https://github.com/gemelo-ai/vocos">vocos</a> which is used as a pretrained vocoder.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special Appreciation</h2><a id="user-content-special-appreciation" aria-label="Permalink: Special Appreciation" href="#special-appreciation"></a></p>
<ul dir="auto">
<li><a href="https://audio.westlake.edu.cn/" rel="nofollow">wlu-audio lab</a> for early algorithm experiments.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-OpenAI board member reveals what led to Sam Altman's brief ousting (670 pts)]]></title>
            <link>https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5</link>
            <guid>40506582</guid>
            <pubDate>Tue, 28 May 2024 23:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5">https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5</a>, See on <a href="https://news.ycombinator.com/item?id=40506582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>She said that Altman was "withholding information" and "misrepresenting things that were happening in the company" for years.</p><div><p>Toner — one of the board members who voted to kick Altman out — alleged Altman also lied to the board by keeping them in the dark about the company's ownership structure. </p><p>"Sam didn't inform the board that he owned the OpenAI startup fund, even though he constantly was claiming to be an independent board member with no financial interest in the company," she said.</p></div><section data-component-type="content-recommendations" data-component-location="" data-delay-third-party-scripts="true" data-provider="dad" data-excluded-verticals="bi-video" data-premium-state="" data-renderer="three-related-posts" data-size="3" data-container-name="content-recommendations-three-related-posts-in-content" data-theme-class="" data-recommendations-placement="" data-author="" data-root-margin="250px 0px" data-track-view="{&quot;event&quot;: &quot;module_in_view&quot;, &quot;eventCategory&quot;: &quot;in_content_recirc&quot;, &quot;eventAction&quot;: &quot;module_in_view&quot;, &quot;eventLabel&quot;: &quot;module_in_view&quot;, &quot;element_name&quot;: &quot;in_content_recirc&quot;, &quot;subscription_experience&quot;: &quot;bi_value_unassigned&quot;, &quot;product_field&quot;: &quot;bi_value_unassigned&quot;}">
                            <p>
                                Related stories
                              </p>
                        
                          
                        </section><p>Altman keeping that from the board "really damaged our ability to trust him" and that the board was "already talking pretty seriously about whether we needed to fire him" in October, she said.</p><p>OpenAI didn't immediately respond to a request for comment from Business Insider. </p><p>Toner — currently a director of strategy at the Centre for Security and Emerging Technology at Georgetown — alleges the OpenAI chief also gave board members "inaccurate information about the small number of formal safety processes" OpenAI had in place.  </p><p>She said that made it "basically impossible" for the board to understand if the safety measures were sufficient or if any changes were needed.</p><div><p>She said there were other individual examples, but ultimately, the board concluded that "we just couldn't believe things that Sam was telling us, and that's a completely unworkable place to be in as a board." </p><p>Toner added that it was "totally impossible" for the board to trust Altman's word. The board, she said, had a role to have independent oversight of OpenAI and "not just helping the CEO to raise more money."</p><p>But then, last October, the board had a number of conversations where two executives detailed their own experiences with Altman in which they used the phrase "psychological abuse," according to Toner. </p><p>She said the executives told the board they "didn't think he was the right person to lead the company to AGI, telling us they had no belief that he could or would change, no point in giving him feedback, no point in trying to work through these issues."&nbsp;</p><p>By the time the board realized Altman needed replacing, Toner says it was clear that Altman would "pull out all the stops" to block the board from going against him if he found out. She claims he "started lying to other board members in order to try and push me off the board."</p><p>She said, "We were very careful, very deliberate about who we told, which was essentially almost no one in advance, other than obviously our legal team and so that's kind of what took us to to November 17." </p></div><p>But Altman's ouster didn't last long.</p><p>As staff threatened to quit and speculation swirled that Microsoft may poach Altman's team from OpenAI and hire him directly, the company's board brought back Altman as CEO less than a week later.</p><div><p>Toner resigned from her role as an OpenAI board member less than two weeks after Altman returned as CEO. </p><p><em>Do you work for OpenAI? Do you have insights to share? Contact the reporter at </em><a target="_blank" href="mailto:jmann@businessinsider.com" data-analytics-product-module="body_link" rel=" nofollow"><em>jmann@businessinsider.com</em></a> <em>or reach out via Signal</em> <em>at</em> <em>jyotimann.11</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google won’t comment on a leak of its search algorithm documentation (151 pts)]]></title>
            <link>https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo</link>
            <guid>40505310</guid>
            <pubDate>Tue, 28 May 2024 20:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo">https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo</a>, See on <a href="https://news.ycombinator.com/item?id=40505310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Google’s search algorithm is perhaps the most consequential system on the internet, dictating <a href="https://www.theverge.com/2024/5/2/24147152/google-search-seo-publishing-housefresh-product-reviews">what sites live and die</a> and <a href="https://www.theverge.com/c/23998379/google-search-seo-algorithm-webpage-optimization">what content on the web looks like</a>. But how exactly Google ranks websites has long been a mystery, pieced together by journalists, researchers, and people working in search engine optimization.</p><p>Now, an explosive leak that purports to show <a href="https://sparktoro.com/blog/an-anonymous-source-shared-thousands-of-leaked-google-search-api-documents-with-me-everyone-in-seo-should-see-them/">thousands of pages of internal documents</a> appears to offer an unprecedented look under the hood of how Search works — and suggests that Google hasn’t been entirely truthful about it for years. So far, Google hasn’t responded to multiple requests for comment on the legitimacy of the documents.</p><p>Rand Fishkin, who worked in SEO for more than a decade, says a source shared 2,500 pages of documents with him with the hopes that reporting on the leak would counter the “lies” that Google employees had shared about how the search algorithm works. The documents outline Google’s search API and break down what information is available to employees, according to Fishkin.</p><p>The details shared by Fishkin are dense and technical, likely more legible to developers and SEO experts than the layperson. The contents of the leak are also not necessarily proof that Google uses the specific data and signals it mentions for search rankings. Rather, the leak outlines what data Google collects from webpages, sites, and searchers and offers indirect hints to SEO experts about what Google seems to care about, as SEO expert Mike King <a href="https://ipullrank.com/google-algo-leak">wrote</a> in his overview of the documents.</p><p>The leaked documents touch on topics like what kind of data Google collects and uses, which sites Google elevates for sensitive topics like elections, how Google handles small websites, and more. Some information in the documents appears to be in conflict with public statements by Google representatives, according to Fishkin and King. </p><p>“‘Lied’ is harsh, but it’s the only accurate word to use here,” King writes. “While I don’t necessarily fault Google’s public representatives for protecting their proprietary information, I do take issue with their efforts to actively discredit people in the marketing, tech, and journalism worlds who have presented reproducible discoveries.”</p><p>Google has not responded to <em>The Verge’</em>s requests for comment<em> </em>regarding the documents, including a direct request to refute their legitimacy. Fishkin told <em>The Verge </em>in an email that the company has not disputed the veracity of the leak, but that an employee asked him to change some language in the post regarding how an event was characterized.</p><p>Google’s secretive search algorithm has <a href="https://www.theverge.com/features/23931789/seo-search-engine-optimization-experts-google-results">birthed an entire industry</a> of marketers who closely follow Google’s public guidance and execute it for millions of companies around the world. The pervasive, often annoying tactics have led to a general narrative that Google Search results are getting worse, crowded with junk that website operators <a href="https://www.theverge.com/23753963/google-seo-shopify-small-business-ai">feel required to produce</a> to have their sites seen. In response to <em>The Verge</em>’s past reporting on the SEO-driven tactics, Google representatives often fall back to a familiar defense: that’s not what the <a href="https://developers.google.com/search/docs/fundamentals/seo-starter-guide">Google guidelines</a> say. </p><p>But some details in the leaked documents call into question the accuracy of Google’s public statements regarding how Search works. </p><p>One example cited by Fishkin and King is whether Google Chrome data is used in ranking at all. Google representatives have <a href="https://www.seroundtable.com/google-chrome-search-usage-15618.html">repeatedly</a> <a href="https://iloveseo.com/seo/google-does-not-use-anything-from-google-chrome-for-ranking/">indicated</a> that it doesn’t use Chrome data to rank pages, but Chrome is <a href="https://hexdocs.pm/google_api_content_warehouse/0.4.0/GoogleApi.ContentWarehouse.V1.Model.QualitySitemapTargetGroup.html#module-attributes">specifically mentioned in sections</a> about how websites appear in Search. In the screenshot below, which I captured as an example, the links appearing below the main vogue.com URL may be created in part using Chrome data, according to the documents.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A Google Search screenshot of the Vogue.com result, with sublinks below the main homepage. The links direct to sections like “Met Gala 2024” and “Beauty.”" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/376x308/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/384x315/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/415x340/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/480x393/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/540x442/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/640x524/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/750x614/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/828x678/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1080x885/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1200x983/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1440x1180/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1920x1573/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2048x1678/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2400x1966/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2400x1966/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Chrome is mentioned in a section about how additional links are created.</em></figcaption> <p><cite>Image: Google</cite></p></div></div><div><p>Another question raised is what role, if any, E-E-A-T plays in ranking. E-E-A-T stands for experience, expertise, authoritativeness, and trustworthiness, <a href="https://developers.google.com/search/blog/2022/12/google-raters-guidelines-e-e-a-t">a Google metric used to evaluate the quality of results</a>. Google representatives have <a href="https://x.com/searchliaison/status/1755283334631231514">previously said E-E-A-T isn’t a ranking factor</a>. Fishkin notes that he hasn’t found much in the documents mentioning E-E-A-T by name.</p></div><p>King, however, detailed how Google appears to collect author data from a page and has a field for whether an entity on the page is the author. A portion of the documents shared by King reads that the field was “mainly developed and tuned for news articles... but is also populated for other content (e.g., scientific articles).” Though this doesn’t confirm that bylines are an explicit ranking metric, it does show that Google is at least keeping track of this attribute. Google representatives have <a href="https://x.com/searchliaison/status/1744379351297081637">previously insisted</a> that author bylines are something website owners should do for readers, not Google, because it doesn’t impact rankings.</p><p>Though the documents aren’t exactly a smoking gun, they provide a deep, unfiltered look at a tightly guarded black box system. The <a href="https://www.theverge.com/23869483/us-v-google-search-antitrust-case-updates">US government’s antitrust case against Google</a> — which revolves around Search — has also led to internal documentation becoming public, offering further insights into how the company’s main product works. </p><p>Google’s general caginess on how Search works has led to <a href="https://www.theverge.com/c/23998379/google-search-seo-algorithm-webpage-optimization">websites looking the same</a> as SEO marketers try to outsmart Google based on hints the company offers. Fishkin also calls out the publications credulously propping up Google’s public claims as truth without much further analysis.</p><p>“Historically, some of the search industry’s loudest voices and most prolific publishers have been happy to uncritically repeat Google’s public statements. They write headlines like ‘Google says XYZ is true,’ rather than ‘Google Claims XYZ; Evidence Suggests Otherwise,’” Fishkin writes. “Please, do better. If this leak and the DOJ trial can create just one change, I hope this is it.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shadama: A particle simulation programming environment for everyone (127 pts)]]></title>
            <link>https://tinlizzie.org/~ohshima/shadama2/live2017/</link>
            <guid>40505213</guid>
            <pubDate>Tue, 28 May 2024 20:25:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tinlizzie.org/~ohshima/shadama2/live2017/">https://tinlizzie.org/~ohshima/shadama2/live2017/</a>, See on <a href="https://news.ycombinator.com/item?id=40505213">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      
      <p>Yoshiki Ohshima, Dan Amelang and Bert Freudenberg<br>
      HARC/Y Combinator Research</p>

      <section id="abstract">
        <p>
We present a prototype of a programming system called Shadama.
Shadama is designed for writing programs that create, control and visualize large numbers of objects.
The basic execution model follows the tradition of StarLogo and its "turtles and patches" abstraction.
<label for="sn-starlogo">
</label>

<span>
<a href="#starlogo">
<i>Turtles, Termites, and Traffic Jams: Explorations in Massively Parallel Microworlds</i>
<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/starlogo-book.jpg" width="50%" height="50%">
</a>
</span>
&nbsp; This abstraction has been proven to be effective and easy to use.
The primary goal of the language is to facilitate the writing of scientific simulations by students
at the high school level.
        </p>

        <p>
The Shadama environment supports <i>liveness</i>.
Once changes to the program are saved, the effect on the running simulation is immediate;
there is no need to restart the simulation.
        </p>
        <p>
Shadama programs are run on the GPU by means of code translation to the OpenGL Shading Language.
<label for="sn-glsl">
</label>

<span>
<a href="#glsl">The OpenGL Shading Language</a>
</span> &nbsp;
Program data resides entirely on the GPU, which enables high performance.
        </p>

        <p>
A prototype of Shadama can be found <a href="http://tinlizzie.org/~ohshima/shadama2">here</a>.
Be aware that Shadama requires WebGL 2 and is affected by the floating point precision provided
by your graphics card. Thus, it only works on certain computer systems.
From our experience, it seems to work better on computers with an AMD Radeon graphics
card and on Chrome or Firefox browsers.
</p>
      </section>
      <section>
        <h2>Introduction</h2>
        <p>
The computing power available to us today is astounding.  Achieving
one teraflop of performance was a milestone for a building-sized supercomputer in
the late '90s, but now we expect smart phones to reach this same milestone soon.
Computing performance will only continue to increase in the future.
        </p>
        <p>
But what are people using this power for?  Not to be critical, but
people are generally more interested in watching cat videos and
playing games than trying to invent self-piloting personal airplanes
or discover the graviton.

All joking aside, one of the big problems we face today is our
struggle to advance science literacy, even within a
technologically-advanced society.  We need the next
generation to embrace science more, not less.
        </p>
        <p>
We think now is a good time to redouble our efforts to provide
environments where students and even professional
programmers can more easily tap into the computing power that is available.
To this end, we have been working on a prototype of a
programming language intended for high school students to explore
scientific concepts.
        </p>
        <p>
  Science is about making the invisible visible.  One notable example
of an invisible yet important concept is molecules in a gas.  We would
like students to learn about this, not by rote memorization, but
through actual experiments and model-building.  With the help of
computers, students can make a dynamic model and understand it more
deeply.  This kind of environment will help students construct
knowledge by doing, in line with the constructivism philosophy of
education.
        </p>
</section>

<section>
        <h2 id="a-science-experiment">A Science Experiment</h2>
        <p>
Before introducing the Shadama programming environment, we first
give an example of a physics experiment that could also be modeled
and simulated on a computer.
</p>
<iframe width="640" height="360" src="https://www.youtube.com/embed/07D0nB3mgLA" frameborder="0" allowfullscreen=""></iframe>
<p>
This movie demonstrates a vacuum cannon.  The cannon is a six foot PVC
pipe connected to a vacuum pump.  We put a ping pong ball inside the pipe,
cover the ends with sturdy but breakable material (such as plastic plates),
and pump the air out.
        </p>
        <p>
The pump reduces the pressure inside the tube to about 20% of full atmospheric pressure.
        </p>
        <p>
When the end near the ping pong ball is broken open by a box cutter, the
air molecules that rush into the pipe move into the
low pressure space and the ping pong ball is pushed out the other end.
Our crude setup can accelerate the ball to a speed of over 200 meters per second
(about 60% of the speed of sound).  Others have built similar setups
that can achieve supersonic speed.
        </p>
        <p>
An interesting point to understand is that it is just movement of
molecules that is causing the ball to shoot out. It is not that the
vacuum is sucking molecules into the pipe.
</p>
<p>
The invisible molecules that cause the ball to shoot out can
be made “visible” in a sense not only through this physical experiment,
but also through a computer simulation that reproduces the same phenomenon.
Creating such simulations is the purpose of our programming environment.
          </p>
</section>

<section>
        <h2 id="language-goals">Language Goals</h2>

<p>
We had the following goals when designing Shadama:
</p><ul>
<li> Easy to learn</li>
<li> Openness</li>
<li> Support for large numbers of particles</li>
<li> Liveness</li>
</ul>


<p>
To make learning Shadama easy, we based our language on StarLogo,
whose turtles and patches approach has proved intuitive to young learners.
In addition, we expect students familiar with Scratch to
learn Shadama easily because of similarites in how object behavior
is programmed and how objects can sense values near them spatially.
</p>

<p>
To encourage openness, we designed Shadama to be capable of implementing
complex behavior in the language itself, with as few primitives as possible.
We think that a learning environment should be open
in the sense that a student should be able to see, change and understand
how the various parts of the system work.
Although many sophisticated scientific software packages and simulation environments
exist, they are presented as immutable black boxes,
which limits understanding and stifles curiousity.
When additional software support is required, it should be provided in the
end-user's programming language, and it should be capable of modification
within the end-user's environment.
</p>

<p>
To support large numbers of particles, we designed the language
to execute on graphics hardware. Graphics processors today
are capable of computing on massive amounts of data.
Unfortunately, this requires a trade-off between ease of use and
high performance because there are fundamental limitations in
the execution model of today's graphics hardware.
Although Shadama has some features to mitigate these limitations,
certain behaviors cannot be implemented.
</p>

<p>
To support liveness, we designed the Shadama environment to show
the effects of code changes immediately. Of course,
a running simulation should not be updated for each and every key stroke.
Instead, the user submits a batch of code changes for the environment
to apply.
</p>

</section>

<section>
        <h2 id="shadama-in-Action">Shadama in Action</h2>
        <p>
The following movie introduces our prototype programming environment through several examples.
For details on the language, see the appendix.
The script for the narration of the movie is included below.
You can pause the movie at any time to scroll through and read the script.
        </p>
  
  
  <hr>
</section>
<section>
        <h2 id="implementation">Implementation</h2>
</section>
<p>
Shadama is built on web technologies, including WebGL 2.0 and OpenGL
Shading Language version 3.0.
Our code translator is written in Ohm
<label for="sn-ohm">
</label>

<span>
<a href="#ohm">Ohm: A library and language for building parsers, interpreters, compilers, etc.</a>
</span>
and generates vertex shader, fragment shader and JavaScript code from the Shadama program.
All the values for a given breed and property are stored in a single OpenGL texture.
These textures are created with the OpenGL type "R32F", to match
their use as an array of floating-point scalar values.
The values for a given patch and property are similarly represented.
</p>
<p>
Shadama static functions are translated to Javascript code that
runs OpenGL shaders derived from the Shadama methods.
For each method, a vertex shader is generated to fetch property values
from textures and perform the computation required for that method.
A generated fragment shader stores the property values back
into textures, using the multiple render targets feature of OpenGL.
</p>

<section>
        
        <p>
Previously, one of the authors implemented a particle system called Kedama as an extension of Etoys.
<label for="sn-kedama">
</label>

<span>
<a href="#kedama">
Kedama: A GUI-Based Interactive Massively Parallel Particle Programming System.<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/kedama.png" width="50%" height="50%" alt="Kedama screenshot"></a><br>

</span> &nbsp;    Shadama can be considered an attempt to give the same idea new life.
Kedama's target audience was middle school children, while Shadama's target audience is high school students.
        </p>
        <p>
The biggest inspiration for Shadama (and Kedama) was Resnick's StarLogo.
As such, it provided the basis for the basic organization of objects in Shadama.
However, StarLogo has certain features that Shadama does not, as mentioned in the introduction.
        </p>
        <p>
Based on Extempore, Swift et al. created a live programming environment for physics.
<label for="sn-extempore-pic">
</label>

<span>
<a href="#extempore">Live Programming in Scientific Simulation<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/extempore-pic.png" width="50%" height="50%" alt="Extempore PIC demo screenshot"></a><br>
</span> &nbsp;
This environment brings dynamic code swapping and interactive data
inspection to a sophisticated and optimized particle-in-cell
simulation engine. The spirit of this work is much in line with ours,
although their environment uses a third-party engine that cannot be modified from this same environment.
This is a reflection of their focus on empowering scientific researchers.
Such users are already familiar with the concepts behind the simulation and
value the tight interaction offered by this approach.
While it is possible to rewrite parts of the third-party engine in Extempore,
this is beyond the ability of most users, especially our target audience.
</p>
<p>
Nicky Case's simulation construction environment represents an interesting point in the design space.
<label for="sn-emoji">
</label>

<span>
<a href="#emoji">Simulating the World (in Emoji)<br>
  <img src="https://tinlizzie.org/~ohshima/shadama2/live2017/emoji.png" width="50%" height="50%" alt="Simulation in Emoji screenshot"></a>
</span>  &nbsp;
The system features a user-friendly design for creating many types of open-ended models.
However, it is only designed to handle a few hundred particles and cells.
</p>
<p>
Programming the GPU from a high-level language is a hot topic.
<label for="sn-ikra">
</label>

<span>
<a href="#ikra">Object Support in an Array-based GPGPU Extension for Ruby</a>
</span>&nbsp;  Researchers in this area aim for better performance through
increasingly sophisticated compilation techniques and the use of the CUDA API to more directly access the GPU.
Ease of use is given little consideration.
The authors think that Shadama can occupy a unique position
by striking a better balance between performance and ease of use.
        </p>
        <p>
Some languages for programming massively parallel particle simulations
are based on visual programming blocks.
StarLogo Nova is a notable example.
<label for="sn-slnova">
</label>

<span>
<a href="#slnova">
StarLogo Nova: A Programming Environment For Students and Teachers to
Create 3D Games and Simulations for Understanding Complex Systems
</a>
</span>
Shadama is currently text-based because we feel that scientific simulations
can be naturally expressed with concise text.
However, we have not ruled out other possiblities for syntax,
including a visual representation of the program.
        </p>

        <p>
Although many simulation environments such as Liquid Fun
<label for="sn-liquidfun">
</label>

<span>
<a href="#liquidfun">LiquidFun: A 2D Rigid-body and Fluid Simulation C++ Library for Games Based Upon Box2D<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/liquidfun.png" width="50%" height="50%" alt="LiquidFun screenshot"></a>
</span>
are available today, they do not provide an end-user language.
</p>

</section>

<section>
        <h2 id="conclusions-and-future-work">Conclusions and Future Work</h2>
        <p>
We have presented an early prototype of a language in
which users can make enlightening simulations and intricate visualizations.
The liveliness of the environment encourages an
exploratory style of programming that enables trying out different ideas quickly.
We have also discovered that such an interactive and graphical environment
can be motivating even as bugs appear because of the spectacular
unintentional visual effects that are produced.
        </p>
        <p>
We are considering various improvements to the system.  One major
addition would be to fully support simulations in 3D, not just 2D.
While computation in Shadama only uses scalar values and is agnostic to dimensionality,
the primitives and concepts the system currently provides only work well for 2D applications.
We will need new ideas to manage 3D spatial data.
        </p>
        <p>
We also plan to support more mathematical concepts, such as vectors and matrices.
While first-time users may not initially have use for such abstractions,
we would like them to eventually learn and use these powerful concepts.
Ideally, the environment would gradually introduce the user to new, more difficult approaches.
        </p>
        <p>
We would like to conclude this paper by stressing the importance of
education. Education raises our awareness and enables us to see our world from new perspectives.
In this way, we are empowered with new approaches to solve problems.
For the next generation to solve the challenges of the future, their science literacy
is imperative. Our aim with Shadama is to leverage the power and ubiquity of
computing devices to improve science literacy for high school students by providing an engaging, open
environment in which to explore scientific concepts.
        </p>
</section>

      <section>
        <h2>References</h2>
        <ol type="1">
          <li id="starlogo">
            Mitchel Resnick. <i>Turtles, Termites, and Traffic Jams: Explorations
            in Massively Parallel Microworlds</i>. MIT Press, Cambridge, MA, USA, 1994.
          </li>
          <li id="glsl">
            The OpenGL Shading Language
            (<a href="https://www.khronos.org/registry/OpenGL/index_gl.php">Khronos OpenGL Registry</a>)
          </li>
          <li id="ohm">
            Ohm: A library and language for building parsers, interpreters, compilers, etc.
            (<a href="https://ohmlang.github.io/">project page</a>)
          </li>
          <li id="kedama">
            Yoshiki Ohshima. Kedama: A GUI-based Interactive Massively Parallel Particle Programming System.
            In <i>2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC’05)</i>, pages 91–98, Sept 2005.
          </li>
          <li id="extempore">
            Ben Swift, Andrew Sorensen, Henry Gardner, Peter Davis, and Viktor K Decyk.
            Live Programming in Scientific Simulation. <i>Supercomputing Frontiers and Innovations</i>, 2(4):4–15, March 2015.
            (<a href="http://dx.doi.org/10.14529/jsfi150401">DOI</a>)
          </li>
          <li id="liquidfun">
            LiquidFun: A 2D Rigid-body and Fluid Simulation C++ Library for Games Based Upon Box2D
            (<a href="http://google.github.io/liquidfun/">project page</a>)
          </li>
          <li id="emoji">
            Nicky Case. Simulating the World (in Emoji)
            (<a href="http://ncase.me/simulating">project page</a>)
          </li>
          <li id="ikra">
            Matthias Springer and Hidehiko Masuhara. Object Support in an Array-based GPGPU Extension for Ruby.
            In <i>Proceedings of the 3rd ACM SIGPLAN International Workshop on
            Libraries, Languages, and Compilers for Array Programming</i>,
            ARRAY 2016, pages 25–31, New York, NY, USA, 2016.
          </li>
          <li id="slnova">
            StarLogo Nova: A Programming Environment For Students and Teachers to
            Create 3D Games and Simulations for Understanding Complex Systems
            (<a href="http://education.mit.edu/portfolio_page/starlogonova/">project page</a>)
          </li>
        </ol>
      </section>
<section>
        <h2 id="language">Appendix: A Primer for the Shadama Language</h2>

<p>
The Shadama language uses a turtles and patches abstraction, drawn from the tradition of StarLogo.
</p>

        <h3 id="breeds">Breeds</h3>
<p>
Turtles are organized into
"breeds".  Each breed has its own set of properties.
A breed is declared in a program with the "breed" statement.  For example:
</p>
<pre>breed MyBreed (x, y)
</pre>
<p>
The above creates a breed of turtle called <code>MyBreed</code>, and declares that each
turtle in the breed has individual properties <code>x</code> and <code>y</code>.
</p>
<p>
Currently, properties in Shadama can only be scalar floating-point numbers.
</p>
<p>
Methods provide turtle behavior. The <code>def</code> statement is used to define
methods, as follows:
</p>
<pre>def move() {
  this.x = this.x + 1;
  this.y = this.y + 1;
}
</pre>
<p>
As expected, when this method is invoked on a turtle, the
turtle's x and y properties are incremented by one.
</p>
<p>
Methods can only be invoked from static functions. Methods calls are made
by first specifying a breed, then the method name.
The method is applied to all turtles in the breed concurrently.
For example:
</p>
<pre>static step() {
  MyBreed.move();
}
</pre>
<p>
The <code>step</code> function above calls the <code>move</code> method on all turtles of the <code>MyBreed</code> breed.
</p>

<p>
Shadama provides many built-in features made available through primitive methods:
</p>
<ul>

<li> <pre>aBreed.setCount(count);</pre>
  <span>
  The <code>setCount</code> primitive sets the number of turtles in the breed.
For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
}
</pre>
<span>
Invoking this static function will set the number of <code>MyBreed</code> turtles to 10,000.
In the current implementation, the number of turtles in a breed is limited to
1024 × 1024, or about 1 million.
</span>
</li>

<li> <pre>aBreed.fillRandom(name, min, max);</pre>
<span>
  The <code>fillRandom</code> primitive sets the property specified by <code>name</code>
  to be a random number between <code>min</code>
  (inclusive) and <code>max</code> (exclusive) for each turtle in the breed.
  For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
  MyBreed.fillRandom("x", 0, 100);
}
</pre>
<span>
  The above will set each of the 10,000 turtles <code>x</code> property to be a
  random floating-point number between 0 and 100.
</span>
</li>

<li> <pre>aBreed.fillRandomDir(dxName, dyName);</pre>
<span>
  The <code>fillRandomDir</code> primitive generates random 2D unit vectors.
  This is done for each turtle, and the x and y components of the result are stored
  in the <code>dxName</code> and <code>dyName</code> properties of the turtles.
  For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
  MyBreed.fillRandomDir("dx", "dy");
}
</pre>
<span>
The above sets the <code>dx</code> and <code>dy</code> properties of the turtles with the x and y components of the randomly generated unit vectors.
</span>
</li>

<li> <pre>aBreed.fillSpace(xName, yName, xDim, yDim);</pre>
        <span>
The fillSpace primitive first sets the number of turtles in the breed
to be <code>xDim</code> × <code>yDim</code>.  Then, it places the turtles on integral 2D grid points
within the (0..<code>xDim</code>, 0..<code>yDim</code>) area, storing into the <code>xName</code> and <code>yName</code> turtle properties.
For example:
</span>
<pre>static setup() {
  MyBreed.fillSpace("x", "y", 100, 100);
}
</pre>
<span>
The above creates 10,000 turtles of the MyBreed breed, setting the turtle's <code>x</code> and <code>y</code> properties
to be the integral grid points spanning (0, 0) to (99, 99), inclusive.
</span>
</li>

<li> <pre>aBreed.fillImage(xName, yName, rName, gName, bName, aName, anImageData);</pre>
        <span>
  The fillImage primitive converts a 2D image into a breed of turtles.
  The <code>anImageData</code> argument is a Javascript ImageData object containing the data used
  to populate the breed. The turtle count is set to be <code>anImageData.width</code> × <code>anImageData.height</code>.
  Similar to <code>fillSpace</code>, the turtles are placed on the 2D grid points within the image extent.
  The turtle properties given by <code>rName</code>, <code>gName</code>, <code>bName</code>, and <code>aName</code> are populated with the RGBA
  color component values of the image. Note that while the color components in <code>anImageData</code> range
  from 0 and 255 (integral values), those values in Shadama will be normalized to range from 0.0 and 1.0,
  inclusive (floating-point).
  For example:
<pre>breed MyBreed (x, y, r, g, b, a)
static setup() {
  MyBreed.fillImage("x", "y", "r", "g", "b", "a", anImage);
}
</pre>
</span>
<span>
Static function variables, such as <code>anImage</code>, are described below.
</span>
</li></ul>

<h3 id="patches">Patches</h3>

<p>
A patch is a 2D set of cells that store values.
Patches are fixed size, 512 × 512 by default.
The following declares a patch:
</p><pre>patch Field (nx, ny)
</pre>

<p>
Each cell in this patch stores two values, <code>nx</code> and <code>ny</code>.
</p>

<p>
A patch can be manipulated by passing it as an argument to a method on a breed.
As the method is executed for each turtle, turtles can access the patch cell
nearest them. No other patch cells are available to them.
For example:
</p><pre>breed MyBreed (x, y, r, g, b, a)
patch Field (r, g, b, a)

def store(field) {
  field.r = this.r;
}

static setup() {
  MyBreed.fillImage("x", "y", "r", "g", "b", "a", anImage);
  MyBreed.store(Field);
}
</pre>

<p>
The above declares a patch called Field which is used as an argument to <code>store</code>.
When <code>store</code> is executed for each turtle in <code>MyBreed</code>, the turtle's <code>r</code> property
is stored in the <code>r</code> property of the nearest cell in Field.
</p>

<p>
A turtle can read values from patch cells as well.  For example:
</p><pre>def load(field) {
   this.r = field.r;
}
</pre>

<p>
When the above method is executed, each turtle reads the <code>r</code> property of the nearest patch cell
and stores the value into its own <code>r</code> property.
</p>
<p>
Methods can receive multiple patches as arguments.
For example:
</p><pre>patch Field1 (nx, ny, r, g, b, a)
patch Field2 (nx, ny, r, g, b, a)
def transfer(f1, f2) {
  f2.r = f1.r;
  f2.a = f1.a;
}
</pre>

<p>
The following code is also valid, and correctly swaps values between patches.
</p><pre>def swap(f1, f2) {
  f2.r = f1.r;
  f1.r = f2.r
}
</pre>


<h3 id="local-variables">Local Variables</h3>

<p>
The <code>var</code> statement declares a local variable within a method.
The scope of a local variables is the whole method,
regardless of where in the method it is declared.
In the same method, there can be no more than one declaration for a given variable name.
This is in contrast to variable declarations in JavaScript.
For example:
</p><pre>def average() {
  var avg = (this.x + this.y) / 2.0;
  this.x = avg;
  this.y = avg;
}
</pre>
<p>
The above code properly defines and uses a local variable called <code>avg</code>.
However, the following code would raise an error because the variable <code>diff</code> is declared in two places:
</p><pre>def gcd() {
  if (this.a &gt; this.b) {
    var diff = this.a - this.b;
    this.a = diff;
  } else {
    var diff = this.b - this.a;
    this.b = diff;
  }
</pre>

<p>
The variable declaration has to be manually hoisted, as follows:
</p><pre>def gcd() {
  var diff;
  if (this.a &gt; this.b) {
    diff = this.a - this.b;
    this.a = diff;
  } else {
    diff = this.b - this.a;
    this.b = diff;
  }
</pre>


<h3 id="static-function-variables">Static Function Variables</h3>

<p>
Static function variables are declared within static functions, also using the "var" statement.
Static function variables are not available to methods, but are visible to all static functions.
For example:
</p><pre>static setup() {
  var begin = 1;
}

static loop() {
  if (begin) {
    begin = 0;
  }
}
</pre>

<p>
The two static functions above refer to the same <code>begin</code> variable.
</p>

<p>
Shadama provides the following built-in static function variables:
</p><ul>
  <li>
    <code>mousemove</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most recent mouse cursor location.
  </li>
  <li>
    <code>mousedown</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most
    recent location where the user pressed the mouse button down.
  </li>
  <li>
    <code>mouseup</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most
    recent location where the user lifted the mouse button up.
  </li>
  <li>
    <code>time</code>:
    The number of seconds elapsed since the last time the <code>setup</code> function was called (in floating-point).
  </li>
  <li>
    <code>width, height</code>:
    The width and height of the Shadama canvas.
  </li>
</ul>

<p>
Be aware that mouse event objects are JavaScript objects. Thus, they can't be passed to methods because
methods can only take scalar arguments.
</p>

<p>
There is one additional variable called <code>Display</code>
for invoking certain system primitives.

For example:
</p><pre>static loop() {
  Display.clear();
  MyPatch.draw();
}
</pre>
<p>
The above code clears the canvas and then draws <code>MyPatch</code> by calling the <code>draw</code> primitive.  <code>Display</code> has <code>loadProgram</code>, and <code>clear</code>.
</p>

<h3 id="parallelism-considerations">Parallelism Considerations</h3>
<p>
It's possible for two or more nearby turtles to write into the same patch cell.
Which value gets stored in the patch is non-deterministic.
</p>
<p>
Also, updates to turtle properties and patch properties are not visible until after the method is run.
Consider the following method:
</p><pre>def test() {
  if (this.r &gt; 0) {
     this.r = 0;
  } else {
     this.r = 1;
  }
  this.b = this.r;
}
</pre>

<p>
Even though the last line reads <code>this.b = this.r;</code>, the <code>r</code> property and <code>b</code> property will
not be equal after the invocation. This is because the update to the <code>r</code> property seen earlier does not take effect
until after the method call is finished. Thus, the <code>b</code> property will have the previous <code>r</code> value.
</p>

<p>
The properties <code>this.b</code> and <code>this.r</code> can have the same value
through the following use of a local variable:
</p><pre>def test() {
  var r = this.r;
  if (r &gt; 0) {
     r = 0;
  } else {
     r = 1;
  }
  this.r = r;
  this.b = r;
}
</pre>


<p>
A script can be started by calling <code>start</code> on it. Likewise, you can stop it <code>stop</code>, and execute it once with <code>step</code>.
</p>

<h3 id="control-structures">Control Structures</h3>
<p>
The <code>if</code> statement is the only control structure that Shadama supports.
Loops may be supported in a future version of Shadama because the OpenGL shader language version 3.0
does support variable-count loops.
</p>
<h3 id="primitive-functions">Primitive Functions</h3>
<p>

There are a number of primitive functions that can be called from methods.
Most of them actually result in a direct call to a GLSL built-in function.
For example:
</p><pre>def prims(x) {
  var c = cos(x);
  var s = step(0.5, x);
  var a = abs(x);
  var f = fract(x); // the fraction part of x

  this.r = c * s * a * f;
}
</pre>

<p>
The above code uses several primitive functions to compute a contrived value which
is then stored into the turtle's <code>r</code> property.
</p>

<h3 id="method-binding">Method Binding</h3>
<p>
Methods are not defined for any particular breed, but a given
method can only be applied to breeds that have the properties referenced
in the method.
For example:
</p><pre>breed A (x, r)
breed B (x, y, r, g)
breed C (r)

def set() {
  this.r = 1;
  this.x = 0;
}

static test() {
  A.set();
  B.set();
}
</pre>

<p>
The <code>set</code> method above can be called for both breed <code>A</code> and breed <code>B</code>.
This is the not the case for breed C because it does not have an <code>x</code> property, which is
referenced in <code>set</code>.
</p>

<h3 id="limitations">Limitations</h3>

<p>
The following are important limitations of the Shadama language.
</p>

<p>
Methods can not take breeds as arguments.
For example, the following code is invalid:
</p><pre>breed A (x, y)
breed B (x, y)

def hit(other) {
  var diff = other.x - this.x;
  ...
}

static step() {
  A.hit(B);
}
</pre>


<p>
The <code>step</code> function passes breed B as an argument to the <code>hit</code> method, which is not allowed.
Even if it were, it is not clear which turtle from breed <code>B</code> should
be bound to the argument <code>other</code>.
</p>

<p>
Another limitation is that a given method can either update the turtle's properties or
the patch's properties, but not both.
For example, the following code is invalid:
</p><pre>def test(field) {
  field.r = 1;
  this.r = 1;
}
</pre>


<p>
This limitation arises from limitations in WebGL itself. Future
versions of WebGL, and thus Shadama, may no longer have this restriction.
In the meantime, a workaround is to split the method into two methods — one
for updating the patch and one for updating the turtle.
It is also possible that a future version of Shadama will automatically
perform this code transformation.
</p>

</section>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing an NVMe Driver in Rust [pdf] (196 pts)]]></title>
            <link>https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf</link>
            <guid>40505167</guid>
            <pubDate>Tue, 28 May 2024 20:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf">https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40505167">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars (438 pts)]]></title>
            <link>https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee</link>
            <guid>40505099</guid>
            <pubDate>Tue, 28 May 2024 20:16:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee">https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee</a>, See on <a href="https://news.ycombinator.com/item?id=40505099">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://aksh-garg.medium.com/?source=post_page-----7dd8f1f6c9ee--------------------------------"><div aria-hidden="false"><p><img alt="Aksh Garg" src="https://miro.medium.com/v2/resize:fill:88:88/1*OY2kCIbiKHX3y9S-JEZQJg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="216d"><strong>Overview</strong></h2><p id="14b9">Llama3 took the world by storm, outperforming GPT3.5 in almost all benchmarks and GPT4 on several. And then GPT4o came out, reclaiming the throne with its multimodal finesse. Today, we’re releasing something to change that: Llama3-V, the first-ever multimodal model built on top of Llama3. As a bonus, we train everything in under $500.</p><p id="9c85">How are the benchmarks you ask? We’ll let the tables speak for themselves. We have a 10–20% boost over Llava, the current SOTA and most popular model for multimodal understanding. Additionally, we fair very comparably to the closed source models of 100x the size on all metrics except MMMU.</p><figure></figure><h2 id="b6f7"><strong>Check us out on:</strong></h2><p id="9871">• 🤗: <a href="https://huggingface.co/mustafaaljadery/llama3v/tree/main" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/mustafaaljadery/llama3v/</a></p><p id="9c17">• Github: <a href="https://github.com/mustafaaljadery/llama3v" rel="noopener ugc nofollow" target="_blank">https://github.com/mustafaaljadery/llama3v</a></p><h2 id="7795">The rest of the article covers</h2><ul><li id="ce14">Model Architecture</li><li id="422f">Training Framework</li><li id="ca98">Systems Optimizations</li><li id="68e8">Summary</li></ul><h2 id="5f28"><strong>Model Architecture</strong></h2><p id="2a6d">The bulk of our engineering efforts go into making Llama3 understand visual information. To do so, we take an input image and embed it into a series of patch embeddings using the SigLIP model. These embeddings are then aligned with the textual tokens via a projection block, which applies two self-attention blocks to put the textual and visual embeddings in the same plane. Finally, the visual tokens from the projection block are prepended to the textual tokens and the joint representation is passed into Llama3, just as it normally would.</p><figure><figcaption>Llama3-V Architecture: We use SigLIP to embed our input image in patches. Then we train a projection block with two self-attention blocks to align our textual and visual tokens.</figcaption></figure><p id="93cc">The diagram above illustrates at a high-level how everything works. Now, let’s dive into each stage in detail.</p><p id="66fa"><strong>SigLIP</strong>: SigLIP (Sigmoid Loss for Language Image Pre-Training) is an image embedding model that is similar to CLIP as we see in the figure below. However, unlike CLIP which uses a contrastive loss with softmax normalization, SigLIP utilizes a pairwise sigmoid loss, which allows the model to operate independently on each image-text pair, without requiring a global view across all pairs in a batch. At a high-level, SigLIP’s vision encoder splits the image into a sequence of non-overlapping image patches and projects them into a lower-dimensional linear embedding space, producing a sequence of patch embeddings. These patch embeddings then go through a vision encoder, which applies self-attention to capture long-range dependencies and extract higher-level visual features. For our purposes, we directly use the original SigLIP model trained by Google DeepMind.</p><figure><figcaption>Illustration of how SigLIP embeddings work. We train an image and text decoder concurrently but in our case the text encoding module is kept fixed. Unlike CLIP, we minimize a sigmoid loss instead of a softmax loss but most other things stay the same. Image from <a href="https://x.com/mervenoyann/status/1745476609686089800/photo/1" rel="noopener ugc nofollow" target="_blank">twitter post </a>by Merve</figcaption></figure><p id="a1f8"><strong>Alignment with textual embeddings: </strong>To save computational resources, we keep SigLIP fixed. However, to align the output image embeddings with the textual embeddings used in Llama3, we use an extra projection module. Unlike Llava, which applies a single linear layer to the original image embeddings, we instead train two self-attention blocks to better capture patterns in the input embeddings, producing the final image embedding vector.</p><p id="fcd5"><strong>Prepending image tokens:</strong> For the textual inputs, we first tokenize the text using a Byte Pair Encoding (BPE) vocabulary, producing a sequence of textual tokens. We demarcate these tokens by enclosing them within special &lt;text&gt; and &lt;/text&gt; tags. As for the image embeddings from the projection block, we treat each vector as a separate “visual token” and demarcate them using &lt;image&gt; and &lt;/image&gt; tags. Finally, we prepend the sequence of visual tokens to the sequence of textual tokens, forming the joint input representation that is passed into Llama3 for processing.</p><h2 id="75f6">Inference Optimizations</h2><p id="a1bb">Training these models is expensive. To optimize for computation resources, we make two major optimizations. The first is a simple caching mechanism and the second is on the MPS/MLX front.</p><p id="a391"><strong>Caching: </strong>The SigLIP model is much smaller than Llama3. Therefore, if we run everything serially, we have very little GPU utilization when SigLIP is running. Moreover, we can’t push the utilization up by increasing the batch size up on SigLIP as then Llama runs into OOM errors. Instead we observed that our SigLIP model stays the same and instead pre-compute the image embeddings. Then, for both pre-training and SFT, we directly pass in these precomputed image embeddings instead of re-running the SigLIP module. Not only does this allow us to increase the batch size and maximally use our GPUs for running the SigLIP modules, it also saves us training/inference time as the two parts of the pipeline can occur separately.</p><p id="df3e"><strong>MPS/MLX Optimizations: </strong>Our second optimization was again driven by SigLIP’s smaller size relative to Llama. Specifically, since SigLIP fit on our Macbooks, we ran inference on an MPS optimized SigLIP model, which allowed us to attain a throughput of 32 images/second — allowing our caching step happen relatively quickly.</p><h2 id="8756"><strong>How it was trained</strong></h2><p id="0e19"><strong>Precompute the embeddings from SigLIP: </strong>let’s now dive into the first step of our pre-training process: <em>precomputing the image embeddings via SigLIP</em>. In this step, our goal is to essentially pass in images into the SigLIP embedding model to obtain a vector representation or embedding of the image. One technical detail: due to higher resolutions, we follow the approach taken by LLaVA-UHD and perform image-splitting. The purpose of image-splitting is to divide the image into variable-sized patches or segments for more efficient encoding. These split images are processed concurrently in batches.</p><p id="b746">Now let’s dive into how exactly we use the SigLIP embedding. We first load the SigLIP model and processor/tokenizer. We then preprocess the provided input image using the processor. We then pass the preprocessed image to the model. Following this, the model outputs logits for the image-text pairs. We now proceed to apply the sigmoid activation function to the logits to get the probabilities. We now see that the image embedding is contained within these probabilities. So far this embedding captures the visual information in the image.</p><p id="7ba6">Following the computation of the image embedding via SigLIP, we now proceed to learn a projection matrix — you can also think of this as the <em>projection layer</em>, which is typically a linear or feed-forward layer. As described above in the ingredients section, the projection layer maps the vision embedding from its original space into a joint multimodal embedding space. Specifically, the projection layer applies a learned weight matrix W_v to the vision embedding v to get the projected multimodal vision embedding W_v * v. So after this projection step, the vision and text embeddings are essentially aligned into a common multimodal embedding space, allowing their representations to interact and be combined for multimodal modeling tasks like visual question answering, image captioning, etc. More specifically, the result of the projection layer is the generated “latents.”</p><p id="07a9">Once the latents are computed, we then prepend them as image tokens before the text tokens. The reason for the prepending is that having the image before the text makes it easier for the model to learn during pretraining. Think of it as having tokens representing the actual image and then tokens representing the contents of the image in text: almost like a caption paired with an image. Our architecture is nearly identical to that of LLaVA-UHD (they choose CLIP-ViT while we use SigLIP and they work with Vicuna-13B) so we provide their illustration as reference below:</p><figure></figure><p id="8bdb">Now that we’ve established the data needed for pretraining, we can dive into what that actually looks like. In pre-training, we then use 600,000 examples of prepended images to text. In this step we keep the main weights of the Llama-3 architecture frozen. The key is that we want to only update the gradients of the projection matrix. Crucially, we keep the rest of the weights frozen. And with that, we’ve wrapped up our intuition and process for the pretraining step. The key here was aligning the embedded images (latents) with their text in a joint representation and then pretraining LLaMA-3 to focus on updating the projection matrix based on the examples encountered.</p><p id="7888"><strong>Supervised Finetuning</strong></p><p id="f3f5">Following pretraining, we perform supervised finetuning to enhance the performance of our model. In this step, we are freezing our computed embeddings (from the projection layer) and we keep everything except the vision and projection matrices frozen. In other words, if you look at the image below, the red components are unfrozen while the blue components are frozen. This is meant to serve as “instruction” finetuning — in other words making the model stronger for a multimodal text output. In this stage, we use 1M examples (7M split images).</p><figure></figure><h2 id="f170"><strong>In Summary</strong></h2><ul><li id="4f32">We add a vision encoder to Llama3 8B</li><li id="0665">Our model offers 10–20% performance boosts over Llava the current open-source SOTA vision language model.</li><li id="6423">We offer comparable vision abilities of models close to 100x* larger in size like GPT4v, Gemini Ultra, and Claude Opus.</li><li id="792d">We describe an efficient pipeline to pretrain and instruction finetune the model in under $500.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[API Shouldn't Redirect HTTP to HTTPS (567 pts)]]></title>
            <link>https://jviide.iki.fi/http-redirects</link>
            <guid>40504756</guid>
            <pubDate>Tue, 28 May 2024 19:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jviide.iki.fi/http-redirects">https://jviide.iki.fi/http-redirects</a>, See on <a href="https://news.ycombinator.com/item?id=40504756">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <h2>Background</h2>
      <p>
        When an user directs their web browser to an HTTP URL, it's a common practice for the service to redirect the
        request to a corresponding HTTPS page. This unencrypted part of the communication flow has its flaws. Third
        parties in shared networks, as well as network intermediaries, could
        <a href="https://en.wikipedia.org/wiki/Sniffing_attack" target="_blank" rel="noopener noreferrer">sniff</a>
        passwords and other secrets from the initial HTTP traffic
        or even impersonate the web server with a <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack" target="_blank" rel="noopener noreferrer">MITM</a> attack.
        Nevertheless, redirection has been an useful first step in the transition from the largely unencrypted early web
        to the <a href="https://transparencyreport.google.com/https/overview" target="_blank" rel="noopener noreferrer">largely encrypted</a> web of today.
      </p>
      <p>
        Later techniques tightened the security story further. Servers can now send <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security" target="_blank" rel="noopener noreferrer">HSTS</a> along with the initial HTTP-to-HTTPS redirection response, telling the
        user's browser to use only HTTPS for that domain from
        then on. This limits the window of opportunity for trivial sniffing and MITM attacks to the first request.
        Browsers then added <a href="https://hstspreload.org/" target="_blank" rel="noopener noreferrer">HSTS preload
          lists</a> and <a href="https://support.mozilla.org/en-US/kb/https-only-prefs" target="_blank" rel="noopener noreferrer">HTTPS-Only modes</a> that allow skipping the initial unencrypted request altogether.
      </p>
      <p>
        From the perspective of usability-security tradeoff it all makes sense for user-facing sites. But interestingly,
        the redirection approach also appears to be widely adopted for APIs. APIs are mostly consumed by other software
        so the same usability arguments don't apply there. Moreover, many programmatic API clients don't tend to keep
        browser-like state of things like HSTS headers they have seen.
      </p>
      <p>
        This post argues that, due to these factors, the common practice of redirecting API calls from HTTP to
        HTTPS should be reconsidered. While the post mostly refers to REST APIs, its points also apply to other styles
        of APIs that use HTTP(S) as a transport mechanism.
      </p>

      <h2>A Simple Typo Is Enugh</h2>
      <p>
        At <a href="https://badrap.io/" target="_blank" rel="noopener noreferrer">work</a>, we were building a new
        integration against a third-party API. The initial code commit contained a mistyped API base URL
        <code>"http://..."</code> instead of <code>"https://..."</code>. A pretty easy mistake to make.
      </p>
      <p>
        The error was essentially masked during runtime: The third-party API responded to every request with a 301
        redirect to their HTTPS side. Node.js's built-in <a href="https://nodejs.org/docs/latest/api/globals.html#fetch" target="_blank" rel="noopener noreferrer">fetch</a>
        happily and <em>quietly</em> followed those redirects to the HTTPS endpoint.
      </p>
      <p>
        <strong>Every single one of our API requests now sent the API keys over the network in plaintext</strong>,
        before then sending them again to the encrypted endpoint. The one letter omission could have exposed the used
        API keys to third parties without us realizing it. As the integration would have worked, there's a good
        chance that code would have leaked any secrets in the API calls for years. In the long run, the
        probabilities for malice tend to accumulate.
      </p>
      <p>
        Luckily we spotted the error during the code review before the error could propagate to production or even
        testing. We also realized that our <em>own</em> API also did similar HTTP-to-HTTPS redirects.
      </p>

      <h2>The Fail-fast Principle</h2>
      <p>
        When an API redirect HTTP requests to HTTPS - and the API client silently follows those redirects - it tends to
        hide mistyped URLs like in the case described above. A simple one-letter omission can easily be ignored, end up
        in production, and compromise the entire system's confidentiality.
      </p>
      <p>
        In most cases, it's better to adhere to the <a href="https://en.wikipedia.org/wiki/Fail-fast_system" target="_blank" rel="noopener noreferrer">fail-fast principle</a>: unencrypted API calls should fail in a
        spectacular and visible way so that the developer can easily spot and fix the typo as early as possible during
        the development process.
      </p>
      <p>
        A great solution for failing fast would be to disable the API server's HTTP interface altogether and not even
        answer to connections attempts to port 80. If the initial unencrypted connection is never established then the
        API keys aren't sent, mitigating sniffing attacks and limiting the window of opportunity for MITM attacks to an
        extremely small time window. This approach is viable for APIs hosted under their own domains like
        <code>api.example.com</code>.
      </p>
      <p>
        Our own API was served under the <code>/api</code> path from the same domain as our service's web UI. We
        didn't have the guts to disable the HTTP interface for that domain altogether, so we picked next best
        option: all unencrypted HTTP requests made under <code>/api</code> now return a descriptive error message along
        with the HTTP status code 403. Some initial plaintext requests might be made during development, but they're
        much easier for developers to notice.
      </p>

      <h2>Who Else?</h2>
      <p>
        That took care of our own API. We also pinged the third-party API provider and a couple of friends that they
        might want to check their APIs. And who knows, maybe there were some commonly used APIs that accept API keys (or
        other credentials) and also redirect from HTTP to HTTPS?
      </p>
      <p>
        I listed a bunch of well known APIs from the top of my head and did a little surveys. Several of them returned
        HTTP errors or declined to connections altogether. They're listed here with cURL spells for checking out their
        detailed responses:
      </p>

      <ol>
        <li>
          <strong>Stripe API</strong>: Responds with <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403" target="_blank" rel="nofollow noreferrer">403</a> ("Forbidden") and a descriptive error message.
          <br>
          <code>curl -i http://api.stripe.com</code>
        </li>
        <li>
          <strong>Google Cloud API</strong>: Responds with 403 and a descriptive error message.
          <br>
          <code>curl -i http://compute.googleapis.com/compute/v1/projects/project/regions/region/addresses</code>
        </li>
        <li>
          <strong>Shopify API</strong>: Responds with 403 and a descriptive error message.
          <br>
          <code>curl -i http://shop.myshopify.com/admin/api/2021-07/shop.json</code>
        </li>
        <li>
          <strong>NPM Registry API</strong>: Responds with <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/426" target="_blank" rel="nofollow noreferrer">426</a> ("Upgrade Required") and a descriptive error message.
          <br>
          <code>curl -i -X PUT -H 'content-type: application/json' -d '{}' 'http://registry.npmjs.org/-/user/org.couchdb.user:npm'</code>
        </li>
        <li>
          <a href="https://www.fastmail.com/for-developers/integrating-with-fastmail/" target="_blank" rel="nofollow noreferrer">Fastmail JMAP API</a>: The whole HTTP interface seems to be disabled.
          <br>
          <code>curl -i -H 'Authorization: Bearer foo' http://api.fastmail.com/jmap/session</code>
        </li>
        <li>
          <strong>Mailjet</strong>: The socket responds with completely empty payload.
          <br>
          <code>curl -i -X POST --user "user:pass" http://api.mailjet.com/v3.1/send -H 'Content-Type: application/json' -d '{}'</code>
        </li>
      </ol>

      <p>However, the following APIs <em>did</em> respond with HTTP-to-HTTPS redirects:</p>

      <ol>
        <li>
          <a href="https://developers.activecampaign.com/reference/list-all-accounts" target="_blank" rel="nofollow noreferrer">ActiveCampaign
            API</a>
          <br>
          <code>curl -i -H "Api-Token: 123abc-def-ghi" http://123456demo.api-us1.com/api/3/accounts</code>
        </li>
        <li>
          <a href="https://developer.atlassian.com/server/jira/platform/rest-apis/" target="_blank" rel="nofollow noreferrer">Atlassian Jira
            REST API</a>
          <br>
          <code>curl -i http://jira.atlassian.com/rest/api/latest/issue/JRA-9</code>
        </li>
        <li>
          <a href="https://docs.anthropic.com/en/api/messages" target="_blank" rel="nofollow noreferrer">Anthropic
            API</a>
          <br>
          <code>curl -i http://api.anthropic.com/v1/messages --header "x-api-key: 1" --header "anthropic-version: 2023-06-01" --header "content-type: application/json" --data '{}'</code>
        </li>
        <li>
          <a href="https://auth0.com/docs/api/management/v2/introduction" target="_blank" rel="nofollow noreferrer">Auth0</a>
          <br>
          <code>curl -i 'http://login.auth0.com/api/v2/organizations' -H 'Accept: application/json' -H 'Authorization: Bearer foo'</code>
        </li>
        <li>
          <a href="https://developers.cloudflare.com/api/operations/listAccountRulesets" target="_blank" rel="nofollow noreferrer">Cloudflare
            API</a>
          <br>
          <code>curl -i http://api.cloudflare.com/client/v4/accounts/abf9b32d38c5f572afde3336ec0ce302/rulesets</code>
        </li>
        <li>
          <a href="https://docs.datadoghq.com/api/latest/gcp-integration/" target="_blank" rel="nofollow noreferrer">Datadog</a>
          <br>
          <code>curl -i http://api.datadoghq.com/api/v2/integration/gcp/accounts</code>
        </li>
        <li>
          <a href="https://docs.deno.com/subhosting/api/" target="_blank" rel="nofollow noreferrer">Deno Subhosting
            API</a>
          <br>
          <code>curl -i http://api.deno.com/v1/organizations/11111111-2222-3333-4444-555555555555/projects</code>
        </li>
        <li>
          <a href="https://docs.digitalocean.com/reference/api/example-usage/" target="_blank" rel="nofollow noreferrer">DigitalOcean</a>
          <br>
          <code>curl -i -X GET "http://api.digitalocean.com/v2/actions" -H "Authorization: Bearer foo"</code>
        </li>
        <li>
          <a href="https://developers.facebook.com/docs/graph-api/overview/#me" target="_blank" rel="nofollow noreferrer">Facebook Graph API</a>

          <br>
          <code>curl -i 'http://graph.facebook.com/me?access_token=foo</code>
        </li>
        <li>
          <a href="https://www.fastly.com/documentation/reference/api/account/customer/" target="_blank" rel="nofollow noreferrer">Fastly
            API</a>
          <br>
          <code>curl -i -H "Fastly-Key: foo" "http://api.fastly.com/current_customer"</code>
        </li>
        <li>
          <a href="https://www.figma.com/developers/api#users" target="_blank" rel="nofollow noreferrer">Figma
            API</a>
          <br>
          <code>curl -i -H 'X-FIGMA-TOKEN: 123' 'http://api.figma.com/v1/me'</code>
        </li>
        <li>
          <a href="https://docs.github.com/en/rest/users/users?apiVersion=2022-11-28#get-the-authenticated-user" target="_blank" rel="nofollow noreferrer">GitHub
            API</a>
          <br>
          <code>curl -i http://api.github.com/user</code>
        </li>
        <li>
          <a href="https://docs.gitlab.com/ee/api/audit_events.html" target="_blank" rel="nofollow noreferrer">Gitlab
            API</a>
          <br>
          <code>curl -i http://gitlab.com/api/v4/audit_events</code>
        </li>
        <li>
          <a href="https://api.hackerone.com/customer-resources/#organizations-get-your-organizations" target="_blank" rel="nofollow noreferrer">HackerOne API</a>
          <br>
          <code>curl -i "http://api.hackerone.com/v1/me/organizations" -X GET -u "user:token" -H 'Accept: application/json'</code>
        </li>
        <li>
          <a href="https://docs.hetzner.cloud/#certificates-get-all-certificates" target="_blank" rel="nofollow noreferrer">Hetzner Cloud
            API</a>
          <br>
          <code>curl -i -H "Authorization: Bearer 123" "http://api.hetzner.cloud/v1/certificates"</code>
        </li>
        <li>
          <a href="https://developers.hubspot.com/docs/api/settings/account-activity-api" target="_blank" rel="nofollow noreferrer">Hubspot
            API</a>
          <br>
          <code>curl -i --request GET --url http://api.hubapi.com/account-info/v3/api-usage/daily/private-apps  --header 'authorization: Bearer YOUR_ACCESS_TOKEN'</code>
        </li>
        <li>
          <a href="https://cloud.ibm.com/apidocs/factsheets#authentication" target="_blank" rel="nofollow noreferrer">IBM Cloud API</a>
          <br>
          <code>curl -i "http://iam.cloud.ibm.com/identity/token" -d "apikey=YOUR_API_KEY_HERE&amp;grant_type=urn%3Aibm%3Aparams%3Aoauth%3Agrant-type%3Aapikey" -H "Content-Type: application/x-www-form-urlencoded" -H "Authorization: Basic Yng6Yng="</code>
        </li>
        <li>
          <a href="https://developers.facebook.com/docs/instagram-basic-display-api/getting-started" target="_blank" rel="nofollow noreferrer">Instagram Basic Display API</a>
          <br>
          <code>curl -i 'http://graph.instagram.com/me/media?fields=id,caption&amp;access_token=foo'</code>
        </li>
        <li>
          <a href="https://developers.linear.app/docs/graphql/working-with-the-graphql-api" target="_blank" rel="nofollow noreferrer">Linear
            API</a>
          <br>
          <code>curl -i -X POST -H "Content-Type: application/json" http://api.linear.app/graphql</code>
        </li>
        <li>
          <a href="https://docs.joinmastodon.org/api/" target="_blank" rel="nofollow noreferrer">Mastodon API</a> (on
          mastodon.social)
          <br>
          <code>curl -i http://mastodon.social/api/v1/timelines/home</code>
        </li>
        <li>
          <a href="https://learn.microsoft.com/en-us/graph/api/user-list-messages" target="_blank" rel="nofollow noreferrer">Microsoft Graph
            API</a>
          <br>
          <code>curl -i http://graph.microsoft.com/v1.0/me/messages</code>
        </li>
        <li>
          <a href="https://docs.netlify.com/api/get-started/" target="_blank" rel="nofollow noreferrer">Netlify
            API</a>
          <br>
          <code>curl -i -H "User-Agent: foo" -H "Authorization: Bearer foo" http://api.netlify.com/api/v1/sites</code>
        </li>
        <li>
          <a href="https://platform.openai.com/docs/api-reference/making-requests" target="_blank" rel="nofollow noreferrer">OpenAI API</a>
          <br>
          <code>curl -i -H "Content-Type: application/json" -H "Authorization: Bearer 123" -d '{}' http://api.openai.com/v1/chat/completions</code>
        </li>
        <li>
          <a href="https://api.us.ovhcloud.com/console/#/auth/details~GET" target="_blank" rel="nofollow noreferrer">OVHCloud API</a>
          <br>
          <code>curl -i http://api.us.ovhcloud.com/1.0/auth/details</code>
        </li>
        <li>
          <a href="https://resend.com/docs/api-reference/domains/list-domains" target="_blank" rel="nofollow noreferrer">Resend</a>
          <br>
          <code>curl -i -X GET 'http://api.resend.com/domains' -H 'Authorization: Bearer re_123456789' -H 'Content-Type: application/json'</code>
        </li>
        <li>
          <a href="https://developer.shodan.io/api" target="_blank" rel="nofollow noreferrer">Shodan API</a>
          <br>
          <code>curl -i 'http://api.shodan.io/org?key=12345'</code>
        </li>
        <li>
          <a href="https://api.slack.com/web#posting_json" target="_blank" rel="nofollow noreferrer">Slack API</a>
          <br>
          <code>curl -i -X POST -H "Content-Type: application/json" http://slack.com/api/conversations.create</code>
        </li>
        <li>
          <a href="https://github.com/tailscale/tailscale/blob/main/publicapi/readme.md">Tailscale API</a>
          <br>
          <code>curl -i -H "Authorization: Bearer tskey-api-xxxxx" http://api.tailscale.com/api/v2/user-invites/1</code>
        </li>
        <li>
          Twitter
          <br>
          <code>curl -i http://api.twitter.com/2/users/by/username/jack</code>
        </li>
        <li>
          <a href="https://developer.uber.com/docs/drivers/guides/authentication#step-3:-get-an-access-token" target="_blank" rel="nofollow noreferrer">Uber API</a>
          <br>
          <code>curl -F client_secret=1 -F client_id=1 -F grant_type=authorization_code -F redirect_uri=1 -F code=1 https://auth.uber.com/oauth/v2/token</code>
        </li>
        <li>
          <a href="https://developers.upcloud.com/1.3/3-accounts/#get-account-information" target="_blank" rel="nofollow noreferrer">UpCloud
            API</a>
          <br>
          <code>curl -i -H 'Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=' http://api.upcloud.com/1.3/account</code>
        </li>
        <li>
          <a href="https://vercel.com/docs/rest-api/endpoints/authentication#get-auth-token-metadata" target="_blank" rel="nofollow noreferrer">Vercel API</a>
          <br>
          <code>curl -i -H 'Authorization: Bearer foo' http://api.vercel.com/v5/user/tokens/5d9f2ebd38ddca62e5d51e9c1704c72530bdc8bfdd41e782a6687c48399e8391</code>
        </li>
        <li>
          <a href="https://www.vultr.com/api/#tag/account/operation/get-account" target="_blank" rel="nofollow noreferrer">Vultr API</a>
          <br>
          <code>curl -i "http://api.vultr.com/v2/account" -H "Authorization: Bearer 123"</code>
        </li>
      </ol>
      <p>
        I didn't report these findings separately to all of these API providers. There were some outliers not listed
        here that I did contact, with varying results. More on that later.
      </p>
      <p>
        Take each individual result with a grain of salt: I had to test some of these APIs without valid
        credentials, or with credentials used in documentation examples. But the overall pattern indicates that the
        habit of APIs redirecting HTTP requests to HTTPS is quite widespread. Why is that?
      </p>

      <h2>Best Practices Need Practice Too</h2>
      <p>
        When speaking with people about this topic, many have noted that HTTP-to-HTTPS redirects from APIs have obvious
        downsides - in hindsight.
      </p>
      <p>Redirects for user-facing applications are often mentioned in lists best practices and cheat sheets, <a href="https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Security_Cheat_Sheet.html#use-tls-for-all-pages" target="_blank" rel="nofollow noreferrer">like the ones published by OWASP (The Open Worldwide Application
          Security Project)</a>.
        Recommendations specifically aimed for APIs seem rare in contrast. I found just few mentions, for example an
        excellent PDF slideset called <a href="https://owasp.org/www-chapter-belgium/assets/2018/2018-10-23/OWASP_20181023_CommonAPISecurityPitfalls.pdf" target="_blank" rel="nofollow noreferrer">"Common API Security Pitfalls"</a> by <a href="https://infosec.exchange/@PhilippeDeRyck" target="_blank" rel="nofollow noreferrer">Philippe De
          Ryck</a>,
        buried deep within the OWASP website:
      </p>

      <figure>
        <img alt="Slide 8 of &quot;Common API Security Pitfalls&quot;: &quot;API-only endpoints should disable HTTP and only need to support HTTPS.&quot;" src="https://jviide.iki.fi/deryck-slide-8.png">
        <figcaption>
          <small>
            Slide 8 of "Common API Security Pitfalls". Emphasis added to highlight the relevant
            section.
          </small>
        </figcaption>
      </figure>

      <p>
        My Google-fu might just be bad. But maybe each best practice item recommending HTTP-to-HTTPS redirects
        for user-facing sites should have an explicit caveat attached, prominently advising against such redirects for
        APIs. Therefore I opened <a href="https://github.com/OWASP/CheatSheetSeries/issues/1407" target="_blank" rel="nofollow noreferrer">an issue</a> that suggests amending OWASP's Transport Layer Security Cheat Sheet
        accordingly.
      </p>

      <h2>Bonus Round: Popular APIs That Respond In Plaintext</h2>
      <p>
        While reviewing the list of APIs, I bumped into some popular ones that neither redirected nor failed
        unencrypted requests. They just responded to unencrypted HTTP requests with unencrypted HTTP responses, without
        enforcing HTTPS at any stage.
      </p>
      <p>
        Maybe they had their reasons, or maybe they had just accidentally misconfigured their reverse proxies.
        Regardless, seeing that they all handle potentially sensitive data, I contacted these API providers through
        their respective security channels and explained the problem. The providers are listed below in the order of
        reporting. I'll unredact their names and details when they've given a definite response, or otherwise after
        a reasonable amount of time has passed.
      </p>
      <ul>
        <li>
          <strong>Provider A</strong>: Reported on <time datetime="2024-05-17">2024-05-17</time> through their
          vulnerability reporting email address. Awaiting response.
        </li>
        <li>
          <strong>Provider B</strong>: Reported on <time datetime="2024-05-21">2024-05-21</time> through their HackerOne
          program. Got a prompt triage response, stating that attacks requiring MITM (or physical access to a user's
          device) are outside the scope of the program. Sent back a response explaining that MITM or physical access was
          not required for sniffing. Awaiting response.
        </li>
        <li>
          <strong>Provider C</strong>: Reported on <time datetime="2024-05-21">2024-05-21</time> through their security
          email address. Awaiting response.
        </li>
        <li id="virustotal">
          <a href="https://docs.virustotal.com/reference/overview" target="_blank" rel="noopener noreferrer">VirusTotal
            API</a>: Reported on <time datetime="2024-05-21">2024-05-21</time> through Google's <a href="https://bughunters.google.com/" target="_blank" rel="noopener noreferrer">Bug Hunters</a> site
          (VirusTotal is owned by a Google subsidiary that got merged into Google Cloud). The
          API responds in plaintext to requests like for example this (where <code>$API_KEY</code> is a valid API key):

          <p>
            <code>curl -i -H 'x-apikey: $API_KEY' http://www.virustotal.com/api/v3/ip_addresses/1.1.1.1</code>
          </p>

          <p>
            The report got promptly triaged. Received a response on <time datetime="2024-05-24">2024-05-24</time>, cited
            in part below:
          </p>

          
          
        </li>
      </ul>

      <h2>Conclusion</h2>
      <p>
        Redirecting HTTP to HTTPS for APIs can be more harmful than helpful due to the nature of APIs. Unlike
        user-facing web pages, APIs are primarily consumed by other software. API clients often follow redirects
        automatically and do not maintain state or support security headers like HSTS. This can lead to silent failures
        where sensitive data in each API request is initially transmitted in plaintext over the network, unencrypted.
      </p>
      <p>
        Let's adopt a fail-fast approach and disable the HTTP interface entirely or return clear
        error responses for unencrypted requests. This ensures that developers can quickly notice and fix accidental
        use <code>http://</code> URLs to <code>https://</code>.
      </p>
      <p>
        Several well-known and popular APIs also redirect HTTP requests to HTTPS. This behavior seems to be
        widespread. Maybe it's time we amend best practices to explicitly recommend that APIs flat our reject
        unencrypted requests.
      </p>
      <p>
        <em>Huge thanks to Juhani Eronen (<a href="https://www.kyberturvallisuuskeskus.fi/en/homepage" target="_blank" rel="noopener noreferrer">NCSC-FI</a>) and Marko Laakso (<a href="https://www.oulu.fi/en/research-groups/oulu-university-secure-programming-group-ouspg" target="_blank" rel="noopener noreferrer">OUSPG</a>) for their help and guidance during writing this
          post.</em>
      </p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Speech-to-Text on the '10 Cents' CH32V003 Microcontroller (107 pts)]]></title>
            <link>https://github.com/brian-smith-github/ch32v003_stt</link>
            <guid>40504481</guid>
            <pubDate>Tue, 28 May 2024 19:20:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/brian-smith-github/ch32v003_stt">https://github.com/brian-smith-github/ch32v003_stt</a>, See on <a href="https://news.ycombinator.com/item?id=40504481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Simple Speech-To-Text on the '10 cents' CH32V003 Microcontroller</h2><a id="user-content-simple-speech-to-text-on-the-10-cents-ch32v003-microcontroller" aria-label="Permalink: Simple Speech-To-Text on the '10 cents' CH32V003 Microcontroller" href="#simple-speech-to-text-on-the-10-cents-ch32v003-microcontroller"></a></p>
<p dir="auto">This program will read audio from an analog microphone
and distinguish between the spoken digits 'zero' to 'nine',
logging the results over a serial link.</p>
<p dir="auto">I use a MAX4466 electret microphone amplifier board connected to
a CH32V003 development board, along with a WCH-LinkE adaptor for both programming
the chip and acting as a UART-to-USB converter to read the output.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling</h2><a id="user-content-compiling" aria-label="Permalink: Compiling" href="#compiling"></a></p>
<p dir="auto">The code is based on the excellent <a href="https://github.com/cnlohr/ch32v003fun">ch32v003fun</a>
library, and should be compiled in a similar way to the examples there.
(i.e. this directory should be added to the 'examples/' directory
alongside the others)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pin Connections</h2><a id="user-content-pin-connections" aria-label="Permalink: Pin Connections" href="#pin-connections"></a></p>
<table>
<thead>
<tr>
<th>Link-E Adaptor</th>
<th>CH32V003 Dev Board</th>
</tr>
</thead>
<tbody>
<tr>
<td>3V3</td>
<td>VCC</td>
</tr>
<tr>
<td>GND</td>
<td>GND</td>
</tr>
<tr>
<td>SWDIO/TMS</td>
<td>PD1</td>
</tr>
<tr>
<td>RX</td>
<td>PD5</td>
</tr>
<tr>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>MAX4466 Microphone</td>
<td>CH32V003 Dev Board</td>
</tr>
<tr>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>VCC</td>
<td>VCC</td>
</tr>
<tr>
<td>GND</td>
<td>GND</td>
</tr>
<tr>
<td>OUT</td>
<td>PD4</td>
</tr>
</tbody>
</table>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/brian-smith-github/ch32v003_stt/blob/main/ch32v003_with_max4466_mic.jpg"><img src="https://github.com/brian-smith-github/ch32v003_stt/raw/main/ch32v003_with_max4466_mic.jpg" alt="test"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Accuracy</h2><a id="user-content-accuracy" aria-label="Permalink: Accuracy" href="#accuracy"></a></p>
<p dir="auto">I'm getting about 90% accuracy identifying spoken digits with the code
as it stands. As with all R&amp;D, there's always scope for improvement.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Training / Development</h2><a id="user-content-training--development" aria-label="Permalink: Training / Development" href="#training--development"></a></p>
<p dir="auto">In training/ there is a stripped-down ch32v003 program to just dump
8-bit raw audio samples over the serial link, and a desktop-linux program
to read that data and do training of spoken words, simulating the
integer-pipeline used in the main code for the audio processing.</p>
<p dir="auto">In misc/ are C programs that generate:</p>
<ul dir="auto">
<li>the FFT 'twiddles' integer sin/cos tables used in the FFT function
(twiddles_RES13.h)</li>
<li>the FFT-to-Mel matrix, (mel_mx.h)</li>
<li>the discrete-cosine-transform matrix  (dctm_20x8_8bit.h)</li>
<li>the  codebook.h spoken-numbers codebook. (codebook.h)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Challenges</h2><a id="user-content-challenges" aria-label="Permalink: Challenges" href="#challenges"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Only have 16K storage and 2K RAM available, not much room for lookup tables,
codebooks and matrices for processing. (the binary is currenty about 10K)</p>
</li>
<li>
<p dir="auto">The ADC on the CH32V003 is only 10-bit as opposed to the usual 16-bit
(or even 12-bit) minimum for good quality audio.
This is compensated for somewhat  by 8x oversampling/averaging.
I can feed the sampled audio into the 'Whisper' STT application
and get accurate general transcription done, so the quality is certainly
'good enough'.</p>
</li>
<li>
<p dir="auto">No I2S support so using a higher-quality digital microphone is not an option.</p>
</li>
<li>
<p dir="auto">No floating-point support, all code must use integer/fixed-point math</p>
</li>
<li>
<p dir="auto">No hardware-multiply or hardware-divide - so audio processing routines have
to be lean and fast to run within the 48MHz / 100fps timing constraints</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">The code uses traditional (allbeit pared down)  MFCC feature extraction,
and simply compares buffered tensors of samples against pre-recorded
spoken digits to get a 'best match'.</p>
<p dir="auto">A timer is set up to generate an interrupt around 50,000/sec. On receiving
an interrupt, the ADC is read and the next sample convertion started.
8 consecutive samples are averaged to generate a ~6400 samples/sec audio stream.</p>
<p dir="auto">Every 64 samples (10ms), a 128-wide FFT of a buffer of the last 128 samples is
performed and 20 mel-scale frequency bins are calculated from that. The
mel bin energies  are converted to log2-scale.
Finally an 8-bin cepstrum is calculated via a DCT of the 20 log-mel bins.</p>
<p dir="auto">When the 'energy' of a frame (sum of all mel levels) is above a threshold, it is added to a 'word'
buffer, otherwise a count of 'silence' frames is increased.</p>
<p dir="auto">When enough 'silence' frames have passed to signify the end of a spoken
sample, its length is warped to exactly 16 frames and compared to a
lookup table of previously stored word samples, and the closest match
is reported.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it compares to more common speech-to-text systems</h2><a id="user-content-how-it-compares-to-more-common-speech-to-text-systems" aria-label="Permalink: How it compares to more common speech-to-text systems" href="#how-it-compares-to-more-common-speech-to-text-systems"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Usually 16,000 samples/sec audio is used (high fidelity), however to
reduce the audio processing required, only 6400 samples/sec audio is used here.
This is still high enough quality for accurate transcription
(the top speech formants are at around 3200Hz, everything above that is redundant
in terms of recognition).
This makes each 10ms slice of audio exactly 64 samples.</p>
</li>
<li>
<p dir="auto">Heavy pre-emphasis used (1.0 i.e. subtract the previous sample from
the current one. This mostly removes spectral tilt, and completely removes
any DC level in the signal.</p>
</li>
<li>
<p dir="auto">20ms frames are used, compared to 25ms found elsewhere (Vosk,Whisper).  Standard 10ms
step/100fps processing is maintained though. This allows for 128-sample FFT
to be used - FFT alogrithm is optimal at power-of-2 widths, and potentially would
allow for 100% faster FFT by taking advantage of the symmetry of the algo.
The narrow-framesize is compensated for by:</p>
</li>
<li>
<p dir="auto">no windowing used. Usually the signal has a Hann window applied to  the signal before FFT, this step is skipped to avoid 'bookending' the  narrow signal.
Not windowing raises the noise-floor of the FFT output, but noise-floor removal
of the output mel bins is done to compensate.</p>
</li>
<li>
<p dir="auto">Only 20 mel bins calculated. Usually 40 (Vosk) or even 80 mel-scale bins
(Whisper) are used these days.</p>
</li>
<li>
<p dir="auto">extreme (probably overly so) compression via DCT to 8 cepstrum bins to
minimise the final frame dimensions.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Applications</h2><a id="user-content-applications" aria-label="Permalink: Applications" href="#applications"></a></p>
<p dir="auto">Maybe the basis for a low-complexity/low-power/low-cost/always-on wakeword engine?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Future</h2><a id="user-content-future" aria-label="Permalink: Future" href="#future"></a></p>
<p dir="auto">New versions of the CH32 line of chips is due soon, improving the ADC to 12-bit and adding hardware-multiply instructions which would speed up the FFT and
matrix-multiply routines in the code significantly, and improve
accuracy in the processing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">I dunno, I like a challenge. 😀  Doing something traditionally associated with
high-end processing on a 10-cent low-end microcontroller is always going to be
a stretch.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Former FTX Executive Ryan Salame Sentenced to 90 Months in Prison (136 pts)]]></title>
            <link>https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison</link>
            <guid>40504228</guid>
            <pubDate>Tue, 28 May 2024 19:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison">https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison</a>, See on <a href="https://news.ycombinator.com/item?id=40504228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Damian Williams, the United States Attorney for the Southern District of New York, announced that RYAN SALAME was sentenced today to 90&nbsp;months in prison. &nbsp;SALAME previously pled guilty to conspiracy to make unlawful political contributions and defraud the Federal Election Commission and conspiracy to operate an unlicensed money transmitting business before U.S. District Judge Lewis A. Kaplan, who imposed today’s sentence.&nbsp;</p>

<blockquote>
<p>U.S. Attorney Damian Williams said: “Ryan Salame agreed to advance the interests of FTX, Alameda Research, and his co-conspirators through an unlawful political influence campaign and through an unlicensed money transmitting business, which helped FTX grow faster and larger by operating outside of the law.&nbsp; Salame’s involvement in two serious federal crimes undermined public trust in American elections and the integrity of the financial system.&nbsp; Today’s sentence underscores the substantial consequences for such offenses.”&nbsp;</p>
</blockquote>

<p>According to the filings and statements made during court proceedings:</p>

<p>RYAN SALAME was a high-ranking official at Alameda Research, the quantitative cryptocurrency trading firm founded by Samuel Bankman-Fried, from 2019 to 2021.&nbsp; In or about October 2021, SALAME was named co-CEO of FTX’s Bahamian affiliate FTX Digital Markets Ltd.</p>

<p>While working at Alameda Research and FTX, SALAME conspired with Bankman-Fried and other employees of FTX and Alameda Research to operate an unlicensed money transmitting business, unlawfully using FTX, Alameda Research, and an entity called “North Dimension” to transmit FTX customer funds without a license.&nbsp; The conspirators and others at Alameda Research and FTX also made false statements to U.S. banks in order to maintain their unlawful businesses.</p>

<p>Additionally, beginning in or around 2020, SALAME conspired with Bankman-Fried and FTX executive Nishad Singh to donate campaign contributions in a manner that obscured Bankman-Fried’s association with certain of the contributions.&nbsp; These donations were made to improve Bankman-Fried’s personal standing in Washington, D.C., increase FTX’s profile, and curry favor with candidates that could help pass legislation favorable to FTX, Alameda, or Bankman-Fried’s personal agenda. &nbsp;In total, SALAME and his co-conspirators made over 300 political contributions, totaling tens of millions of dollars, that were unlawful because they were made in the name of a straw donor or paid for with corporate funds and caused false information to be reported by campaigns and political action committees to the Federal Election Commission.</p>

<p>* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*</p>

<p>In addition to the prison term, SALAME, 30, of Potomac, Maryland, was sentenced to three&nbsp;years of supervised release and ordered to pay more than $6 million in forfeiture and more than $5 million in restitution.</p>

<p>Mr. Williams praised the outstanding investigative work of the Federal Bureau of Investigation.&nbsp;</p>

<p>This case is being handled by the Office’s Securities and Commodities Fraud Task Force, with assistance from the Office’s Illicit Finance and Money Laundering and Complex Frauds and Cybercrime Units. &nbsp;Assistant U.S. Attorneys Danielle Kudla, Samuel Raymond, Thane Rehn, Nicolas Roos, and Danielle Sassoon are in charge of the prosecution.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tinygrad 0.9.0 (218 pts)]]></title>
            <link>https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0</link>
            <guid>40504212</guid>
            <pubDate>Tue, 28 May 2024 18:58:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0">https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0</a>, See on <a href="https://news.ycombinator.com/item?id=40504212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>Close to the new line limit of 8000 lines, sitting at 7958 lines.<br>
tinygrad is <em><strong>much</strong></em> more usable now.</p>
<p>Just over 1200 commits since <code>0.8.0</code>.</p>
<h2>Release Highlights</h2>
<ul>
<li>New documentation: <a href="https://docs.tinygrad.org/" rel="nofollow">https://docs.tinygrad.org</a></li>
<li><code>gpuctypes</code> has been brought in tree and is no longer an external dependency. [<a data-error-text="Failed to load title" data-id="2102609199" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3253" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3253/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3253">#3253</a>]</li>
<li><code>AMD=1</code> and <code>NV=1</code> experimental backends for not requiring any userspace runtime components like ROCm or CUDA.
<ul>
<li>These backends should reduce the amount of python time, and specifically with multi-gpu use cases.</li>
</ul>
</li>
<li><code>PTX=1</code> for rendering directly to ptx instead of cuda. [<a data-error-text="Failed to load title" data-id="2082842526" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3139" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3139/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3139">#3139</a>] [<a data-error-text="Failed to load title" data-id="2170097313" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3623" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3623/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3623">#3623</a>] [<a data-error-text="Failed to load title" data-id="2190196107" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3775" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3775/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3775">#3775</a>]</li>
<li>Nvidia tensor core support. [<a data-error-text="Failed to load title" data-id="2162090889" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3544" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3544/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3544">#3544</a>]</li>
<li><code>THREEFRY=1</code> for numpy-less random number generation using threefry2x32. [<a data-error-text="Failed to load title" data-id="2023226416" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/2601" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/2601/hovercard" href="https://github.com/tinygrad/tinygrad/pull/2601">#2601</a>] [<a data-error-text="Failed to load title" data-id="2190830121" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3785" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3785/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3785">#3785</a>]</li>
<li>More stabilized <a href="https://github.com/tinygrad/tinygrad/blob/v0.9.0/tinygrad/multi.py">multi-tensor API</a>.
<ul>
<li>With ring all-reduce: [<a data-error-text="Failed to load title" data-id="2064844412" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3000" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3000/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3000">#3000</a>] [<a data-error-text="Failed to load title" data-id="2199791227" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3852" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3852/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3852">#3852</a>]</li>
</ul>
</li>
<li>Core tinygrad has been refactored into 4 pieces, read more about it <a href="https://docs.tinygrad.org/developer/" rel="nofollow">here</a>.</li>
<li>Linearizer and codegen has support for generating kernels with multiple outputs.</li>
<li>Lots of progress towards greater kernel fusion in the scheduler.
<ul>
<li>Fusing of ReduceOps with their elementwise children. This trains mnist and gpt2 with ~20% less kernels and makes llama inference faster.</li>
<li>New LoadOps.ASSIGN allows fusing optimizer updates with grad.</li>
<li>Schedule kernels in BFS order. This improves resnet and llama speed.</li>
<li>W.I.P. for fusing multiple reduces: [<a data-error-text="Failed to load title" data-id="2257858300" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4259" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4259/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4259">#4259</a>] [<a data-error-text="Failed to load title" data-id="2250170563" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4208" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4208/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4208">#4208</a>]</li>
</ul>
</li>
<li>MLPerf <a href="https://github.com/tinygrad/tinygrad/blob/0b58203cbe9ac67de3ae598c8e6552c2935fcb1e/examples/mlperf/model_train.py#L14">ResNet</a> and <a href="https://github.com/tinygrad/tinygrad/blob/0b58203cbe9ac67de3ae598c8e6552c2935fcb1e/examples/mlperf/model_train.py#L392">BERT</a> with a W.I.P. <a href="https://github.com/tinygrad/tinygrad/pull/3470" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3470/hovercard">UNet3D</a></li>
<li>Llama 3 support with a new <a href="https://github.com/tinygrad/tinygrad/blob/v0.9.0/examples/llama3.py"><code>llama3.py</code></a> that provides an OpenAI compatible API. [<a data-error-text="Failed to load title" data-id="2294318726" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4576" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4576/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4576">#4576</a>]</li>
<li><a href="https://arxiv.org/pdf/2305.14314" rel="nofollow">NF4</a> quantization support in Llama examples. [<a data-error-text="Failed to load title" data-id="2291150932" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4540" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4540/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4540">#4540</a>]</li>
<li><code>label_smoothing</code> has been added to <code>sparse_categorical_crossentropy</code>. [<a data-error-text="Failed to load title" data-id="2164382442" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3568" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3568/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3568">#3568</a>]</li>
</ul>
<h2>Known Issues</h2>
<ul>
<li>Using tinygrad in a conda env on macOS is known to cause problems with the <code>METAL</code> backend. See <a data-error-text="Failed to load title" data-id="1979764563" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/2226" data-hovercard-type="issue" data-hovercard-url="/tinygrad/tinygrad/issues/2226/hovercard" href="https://github.com/tinygrad/tinygrad/issues/2226">#2226</a>.</li>
</ul>
<h3>See the full changelog: <a href="https://github.com/tinygrad/tinygrad/compare/v0.8.0...v0.9.0"><tt>v0.8.0...v0.9.0</tt></a></h3>
<h3>See the known issues: <a href="https://github.com/tinygrad/tinygrad/issues?q=is%3Aissue+is%3Aopen+label%3Abug+sort%3Aupdated-desc">https://github.com/tinygrad/tinygrad/issues?q=is%3Aissue+is%3Aopen+label%3Abug+sort%3Aupdated-desc</a></h3>
<h3>Join the <a href="https://discord.gg/beYbxwxVdx" rel="nofollow">Discord</a>!</h3></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Revealed: Israeli spy chief 'threatened' ICC prosecutor over war crimes inquiry (118 pts)]]></title>
            <link>https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry</link>
            <guid>40504006</guid>
            <pubDate>Tue, 28 May 2024 18:41:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry">https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry</a>, See on <a href="https://news.ycombinator.com/item?id=40504006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The former head of the<strong> </strong>Mossad, Israel’s foreign intelligence agency, allegedly threatened a chief prosecutor of the international criminal court in a series of secret meetings in which he tried to pressure her into abandoning a war crimes investigation, the Guardian can reveal.</p><p>Yossi Cohen’s covert contacts with the ICC’s then prosecutor, Fatou Bensouda, took place in the years leading up to her decision to <a href="https://www.theguardian.com/law/2021/mar/03/icc-open-formal-investigation-war-crimes-palestine#:~:text=Bensouda%20has%20said%20her%20probe,war%20crimes%20against%20our%20people." data-link-name="in body link">open a formal investigation</a> into alleged war crimes and crimes against humanity in occupied Palestinian territories.</p><p>That investigation, launched in 2021, culminated last week when <a href="https://www.theguardian.com/law/2021/feb/12/karim-khan-international-criminal-court-prosecutor" data-link-name="in body link">Bensouda’s successor</a>, Karim Khan, announced that he was seeking an arrest warrant for the Israeli prime minister, Benjamin Netanyahu, over the country’s conduct in its war in Gaza.</p><p>The prosecutor’s decision to apply to the ICC’s pre-trial chamber <a href="https://www.theguardian.com/law/article/2024/may/20/icc-prosecutor-seeks-arrest-warrants-israeli-pm-netanyahu-hamas-officials-war-crimes" data-link-name="in body link">for arrest warrants</a> for Netanyahu and his defence minister, Yoav Gallant, alongside three Hamas leaders, is an outcome Israel’s military and political establishment has long feared.</p><figure id="76e585de-e601-4cc2-a7ee-c9738a064d7c" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Netanyahu and Cohen" src="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.02037545787545" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Cohen (right) was appointed as director of the Mossad by Netanyahu in 2016 after working for several years as his national security adviser.</span> Photograph: Gali Tibbon/AFP/Getty Images</figcaption></figure><p>Cohen’s personal involvement in the operation against the ICC took place when he was the director of the Mossad. His activities were authorised at a high level and justified on the basis the court posed a threat of prosecutions against military personnel, according to a senior Israeli official.</p><p>Another Israeli source briefed on the operation against Bensouda said the Mossad’s objective was to compromise the prosecutor or enlist her as someone who would cooperate with Israel’s demands.</p><p>A third source familiar with the operation said Cohen was acting as Netanyahu’s “unofficial messenger”.</p><p>Cohen, who was one of Netanyahu’s closest allies at the time and is emerging as a political force in his own right in Israel, personally led the Mossad’s involvement in an almost decade-long campaign by the country to undermine the court.</p><p>Four sources confirmed that Bensouda had briefed a small group of senior ICC officials about Cohen’s attempts to sway her, amid concerns about the increasingly persistent and threatening nature of his behaviour.</p><figure id="17cd9167-3bb2-4833-9378-83f3db1aae0b" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.YoutubeBlockElement"><gu-island name="YoutubeBlockComponent" priority="critical" deferuntil="visible" props="{&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;isMainMedia&quot;:false,&quot;id&quot;:&quot;6f1692ab-ea89-4b79-acfb-c6605a283771&quot;,&quot;assetId&quot;:&quot;jPWM4reuB6U&quot;,&quot;expired&quot;:false,&quot;posterImage&quot;:[{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/1000.jpg&quot;,&quot;width&quot;:1000},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/500.jpg&quot;,&quot;width&quot;:500},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/140.jpg&quot;,&quot;width&quot;:140},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/1920.jpg&quot;,&quot;width&quot;:1920}],&quot;duration&quot;:317,&quot;mediaTitle&quot;:&quot;ICC prosecutor requests arrest warrants for Netanyahu, Gallant and three Hamas leaders – video&quot;,&quot;origin&quot;:&quot;https://www.theguardian.com&quot;,&quot;stickyVideos&quot;:false,&quot;switches&quot;:{&quot;lightbox&quot;:true,&quot;prebidAppnexusUkRow&quot;:true,&quot;mastheadWithHighlights&quot;:false,&quot;abSignInGateMainVariant&quot;:true,&quot;commercialMetrics&quot;:true,&quot;prebidTrustx&quot;:true,&quot;scAdFreeBanner&quot;:false,&quot;adaptiveSite&quot;:true,&quot;prebidPermutiveAudience&quot;:true,&quot;compareVariantDecision&quot;:false,&quot;enableSentryReporting&quot;:true,&quot;lazyLoadContainers&quot;:true,&quot;ampArticleSwitch&quot;:true,&quot;remarketing&quot;:true,&quot;articleEndSlot&quot;:true,&quot;keyEventsCarousel&quot;:true,&quot;updateLogoAdPartner&quot;:true,&quot;registerWithPhone&quot;:false,&quot;darkModeWeb&quot;:true,&quot;targeting&quot;:true,&quot;remoteHeader&quot;:true,&quot;slotBodyEnd&quot;:true,&quot;prebidImproveDigitalSkins&quot;:true,&quot;ampPrebidOzone&quot;:true,&quot;extendedMostPopularFronts&quot;:true,&quot;emailInlineInFooter&quot;:true,&quot;showNewPrivacyWordingOnEmailSignupEmbeds&quot;:true,&quot;abDeeplyReadRightColumn&quot;:true,&quot;prebidAnalytics&quot;:true,&quot;extendedMostPopular&quot;:true,&quot;ampContentAbTesting&quot;:false,&quot;prebidCriteo&quot;:true,&quot;okta&quot;:true,&quot;imrWorldwide&quot;:true,&quot;acast&quot;:true,&quot;automaticFilters&quot;:true,&quot;twitterUwt&quot;:true,&quot;updatedHeaderDesign&quot;:true,&quot;prebidAppnexusInvcode&quot;:true,&quot;ampPrebidPubmatic&quot;:true,&quot;a9HeaderBidding&quot;:true,&quot;prebidAppnexus&quot;:true,&quot;enableDiscussionSwitch&quot;:true,&quot;prebidXaxis&quot;:true,&quot;stickyVideos&quot;:true,&quot;interactiveFullHeaderSwitch&quot;:true,&quot;discussionAllPageSize&quot;:true,&quot;prebidUserSync&quot;:true,&quot;audioOnwardJourneySwitch&quot;:true,&quot;brazeTaylorReport&quot;:false,&quot;externalVideoEmbeds&quot;:true,&quot;abSignInGateAlternativeWording&quot;:false,&quot;callouts&quot;:true,&quot;sentinelLogger&quot;:true,&quot;geoMostPopular&quot;:true,&quot;weAreHiring&quot;:false,&quot;relatedContent&quot;:true,&quot;thirdPartyEmbedTracking&quot;:true,&quot;prebidOzone&quot;:true,&quot;ampLiveblogSwitch&quot;:true,&quot;ampAmazon&quot;:true,&quot;prebidAdYouLike&quot;:true,&quot;mostViewedFronts&quot;:true,&quot;discussionInApps&quot;:false,&quot;optOutAdvertising&quot;:true,&quot;abSignInGateMainControl&quot;:true,&quot;googleSearch&quot;:true,&quot;brazeSwitch&quot;:true,&quot;darkModeInApps&quot;:true,&quot;prebidKargo&quot;:true,&quot;consentManagement&quot;:true,&quot;personaliseSignInGateAfterCheckout&quot;:true,&quot;redplanetForAus&quot;:true,&quot;prebidSonobi&quot;:true,&quot;idProfileNavigation&quot;:true,&quot;confiantAdVerification&quot;:true,&quot;discussionAllowAnonymousRecommendsSwitch&quot;:false,&quot;dcrTagPages&quot;:true,&quot;absoluteServerTimes&quot;:false,&quot;permutive&quot;:true,&quot;comscore&quot;:true,&quot;ampPrebidCriteo&quot;:true,&quot;tagLinkDesign&quot;:false,&quot;abMpuWhenNoEpic&quot;:false,&quot;newsletterOnwards&quot;:false,&quot;youtubeIma&quot;:true,&quot;webFonts&quot;:true,&quot;prebidImproveDigital&quot;:true,&quot;abAdBlockAsk&quot;:false,&quot;ophan&quot;:true,&quot;crosswordSvgThumbnails&quot;:true,&quot;prebidTriplelift&quot;:true,&quot;weather&quot;:true,&quot;prebidPubmatic&quot;:true,&quot;serverShareCounts&quot;:false,&quot;autoRefresh&quot;:true,&quot;enhanceTweets&quot;:true,&quot;prebidIndexExchange&quot;:true,&quot;prebidOpenx&quot;:true,&quot;prebidHeaderBidding&quot;:true,&quot;idCookieRefresh&quot;:true,&quot;discussionPageSize&quot;:true,&quot;smartAppBanner&quot;:false,&quot;boostGaUserTimingFidelity&quot;:false,&quot;historyTags&quot;:true,&quot;brazeContentCards&quot;:true,&quot;surveys&quot;:true,&quot;remoteBanner&quot;:true,&quot;emailSignupRecaptcha&quot;:true,&quot;prebidSmart&quot;:true,&quot;shouldLoadGoogletag&quot;:true,&quot;inizio&quot;:true}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"><div data-chromatic="ignore" data-component="youtube-atom"><figcaption><span><svg width="36" height="23" viewBox="0 0 36 23"><path d="M3.2 0l-3.2 3.3v16.4l3.3 3.3h18.7v-23h-18.8m30.4 1l-8.6 8v5l8.6 8h2.4v-21h-2.4"></path></svg></span><span>ICC prosecutor requests arrest warrants for Netanyahu, Gallant and three Hamas leaders – video</span></figcaption></div></gu-island></figure><p>Three of those sources were familiar with Bensouda’s formal disclosures to the ICC about the matter. They said she revealed Cohen had put pressure on her on several occasions not to proceed with a criminal investigation in the ICC’s Palestine case.</p><p>According to accounts shared with ICC officials, he is alleged to have told her: “You should help us and let us take care of you. You don’t want to be getting into things that could compromise your security or that of your family.”</p><p>One individual briefed on Cohen’s activities said he had used “despicable tactics” against Bensouda as part of an ultimately unsuccessful effort to intimidate and influence her. They likened his behaviour to “stalking”.</p><p>The Mossad also took a keen interest in Bensouda’s family members and obtained transcripts of secret recordings of her husband, according to two sources with direct knowledge of the situation. Israeli officials then attempted to use the material to discredit the prosecutor.</p><p>The revelations about Cohen’s operation form part of a forthcoming investigation by the Guardian, the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call, revealing how multiple Israel intelligence agencies ran a covert “war” against the ICC for almost a decade.</p><p>Contacted by the Guardian, a spokesperson for Israel’s prime minister’s office said: “The questions forwarded to us are replete with many false and unfounded allegations meant to hurt the state of Israel.” Cohen did not respond to a request for comment. Bensouda declined to comment.</p><figure id="c590efc5-ec49-4a9f-a008-a8059949407c" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Fatou Bensouda stands next to various national flags at a lectern that features the UN logo." src="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9439546599496" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The ICC case dates back to 2015, when Fatou Bensouda decided to open a preliminary examination into the situation in Palestine.</span> Photograph: Pacific Press Media Production Corp/Alamy</figcaption></figure><p>In the Mossad’s efforts to influence Bensouda, Israel received support from an unlikely ally: Joseph Kabila, the former president of the Democratic Republic of the Congo, who played a supporting role in the plot.</p><p>Revelations about the Mossad’s efforts to influence Bensouda come as the current chief prosecutor, Khan, warned in recent days that he would not hesitate to prosecute “attempts to impede, intimidate or improperly influence” ICC officials.</p><p>According to legal experts and former ICC officials, efforts by the Mossad to threaten or put pressure on Bensouda could amount to offences against the administration of justice under article 70 of the Rome statute, the treaty that established the court.</p><p>A spokesperson for the ICC would not say whether Khan had reviewed his predecessor’s disclosures about her contacts with Cohen, but said Khan had never met or spoken to the head of the Mossad.</p><p>While the spokesperson declined to comment on specific allegations, they said Khan’s office had been subjected to “several forms of threats and communications that could be viewed as attempts to unduly influence its activities”.</p><h2 id="bensouda-sparks-ire-of-israel">Bensouda sparks ire of Israel</h2><p>Khan’s decision to seek arrest warrants against Netanyahu and Gallant last week marked the first time the court had taken action against leaders of a country closely allied with the US and Europe. Their alleged crimes – which include directing attacks on civilians and using starvation as a method of warfare – relate to the eight-month war in Gaza.</p><p>The ICC case, however, dates back to 2015, when Bensouda decided <a href="https://www.theguardian.com/law/2015/jan/16/icc-possible-war-crimes-palestinian-territories" data-link-name="in body link">to open a preliminary examination</a> into the situation in Palestine. Short of a full investigation, her inquiry was tasked with making an initial assessment of allegations of crimes by individuals in Gaza, the West Bank and East Jerusalem.</p><p>Bensouda’s decision sparked the ire of Israel, which feared its citizens could be prosecuted for their involvement in operations in <a href="https://www.theguardian.com/world/palestinian-territories" data-link-name="in body link" data-component="auto-linked-tag">Palestinian territories</a>. Israel had long been open about its opposition to the ICC, refusing to recognise its authority. Israeli ministers intensified their attacks on the court and even vowed to try to dismantle it.</p><p>Soon after commencing the preliminary examination, Bensouda and her senior prosecutors began to receive warnings that Israeli intelligence was taking a close interest in their work.</p><figure id="701b7240-95b2-408b-938f-e7376eee1fce" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Differential focus image that centres Yossi Cohen among a crowd of suited men" src="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Yossi Cohen during a reception held at the Israeli foreign ministry in Jerusalem, in May 2018.</span> Photograph: Amir Cohen/Reuters</figcaption></figure><p>According to two sources, there were even suspicions among senior ICC officials that Israel had cultivated sources within the court’s prosecution division, known as the office of the prosecutor. Another later recalled that although the Mossad “didn’t leave its signature”, it was an assumption the agency was behind some of the activity officials had been made aware of.</p><p>Only a small group of senior figures at the ICC, however, were informed that the director of the Mossad had personally approached the chief prosecutor.</p><p>A career spy, Cohen enjoys a reputation in Israel’s intelligence community as an effective recruiter of foreign agents. He was a loyal and powerful ally of the prime minister at the time, having been appointed as director of the Mossad by Netanyahu in 2016 after working for several years at his side as his national security adviser.</p><p>As the head of the national security council between 2013 and 2016, Cohen oversaw the body that, according to multiple sources, began to coordinate a multiagency effort against the ICC once Bensouda opened the preliminary inquiry in 2015.</p><p>Cohen’s first interaction with Bensouda appears to have taken place at the Munich security conference in 2017, when the Mossad director introduced himself to the prosecutor in a brief exchange. After this encounter, Cohen subsequently “ambushed” Bensouda in a bizarre episode in a Manhattan hotel suite, according to multiple sources familiar with the incident.</p><figure id="eabefa5b-5c0e-453c-906e-007ca2300738" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Bensouda shaking hands with a bearded Joseph Kabila" src="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Bensouda with Joseph Kabila in New York. Sources claim the then DRC leader played an important supporting role in the Mossad’s plot against the ICC’s chief prosecutor.</span> Photograph: ICC</figcaption></figure><p>Bensouda was in New York in 2018 on an official visit, and was meeting Kabila, then the president of the DRC, at his hotel. The pair had met several times before in relation to the ICC’s ongoing investigation into alleged crimes committed in his country.</p><p>The meeting, however, appears to have been a setup. At a certain point, after Bensouda’s staff were asked to leave the room, Cohen entered, according to three sources familiar with the meeting. The surprise appearance, they said, caused alarm to Bensouda and a group of ICC officials travelling with her.</p><p>Why Kabila helped Cohen is unclear, but ties between the two men were revealed in 2022 by the Israeli publication TheMarker, which reported on a series of secretive trips the Mossad director made to the DRC throughout 2019.</p><gu-island name="InteractiveBlockComponent" priority="critical" deferuntil="idle" props="{&quot;url&quot;:&quot;https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false&quot;,&quot;scriptUrl&quot;:&quot;https://interactive.guim.co.uk/embed/iframe-wrapper/0.1/boot.js&quot;,&quot;alt&quot;:&quot;Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.&quot;,&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;elementId&quot;:&quot;43e668f7-c6da-422b-b6a3-945ffad8a4c0&quot;,&quot;isMainMedia&quot;:false}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"><figure id="43e668f7-c6da-422b-b6a3-945ffad8a4c0" data-alt="Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348." data-testid="interactive-element-Do%20you%20have%20information%20about%20this%20story?%20Email%20harry.davies@theguardian.com,%20or%20(using%20a%20non-work%20phone)%20use%20Signal%20or%20WhatsApp%20to%20message%20+44%207721%20857348." data-spacefinder-role="inline"><a data-name="placeholder" href="https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false">Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.</a></figure></gu-island><p>According to the publication, Cohen’s trips, during which he sought Kabila’s advice “on an issue of interest to Israel”, and which were almost certainly approved by Netanyahu, were highly unusual and had astonished senior figures within the intelligence community.</p><p>Reporting on the DRC meetings in 2022, the Israeli broadcaster Kan 11 said Cohen’s trips related to an “extremely controversial plan” and cited official sources who described it as “one of Israel’s most sensitive secrets”.</p><p>Multiple sources have confirmed to the Guardian the trips were partly related to the ICC operation, and Kabila, who left office in January 2019, played an important supporting role in the Mossad’s plot against Bensouda. Kabila did not respond to a request for comment.</p><h2 id="threats-and-manipulation">‘Threats and manipulation’</h2><p>After the surprise meeting with Kabila and Bensouda in New York, Cohen repeatedly phoned the chief prosecutor and sought meetings with her, three sources recalled. According to two people familiar with the situation, at one stage Bensouda asked Cohen how he had obtained her phone number, to which he replied: “Did you forget what I do for a living?”</p><p>Initially, the sources explained, the intelligence chief “tried to build a relationship” with the prosecutor and played “good cop” in an attempt to charm her. The initial objective, they said, appeared to have been to enlist Bensouda into cooperating with Israel.</p><p>Over time, however, the tone of Cohen’s contact changed and he began to use a range of tactics, including “threats and manipulation”, an individual briefed on the meetings said. This prompted Bensouda to inform a small group of senior ICC officials about his behaviour.</p><p>In December 2019, <a href="https://www.theguardian.com/law/2019/dec/20/icc-to-investigate-alleged-israeli-and-palestinian-war-crimes" data-link-name="in body link">the prosecutor announced</a> that she had grounds to open a full criminal investigation into allegations of war crimes in Gaza, the West Bank and East Jerusalem. However, she held off launching it, deciding first to request a ruling from the ICC’s pre-trial chamber to confirm the court did indeed have jurisdiction over Palestine.</p><figure id="77bb2be5-5a34-4bfb-96e5-520fb0a3429f" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Demonstrators carry banners outside the ICC" src="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Protesters gather outside the ICC to call for the court to prosecute Israel for war crimes.</span> Photograph: Peter Dejong/AP</figcaption></figure><p>Multiple sources said it was at this stage, as the judges considered the case, that Cohen escalated his attempts to persuade Bensouda not to pursue a full investigation in the event the judges gave her the green light.</p><p>Between late 2019 and early 2021, the sources said, there were at least three encounters between Cohen and Bensouda, all initiated by the spy chief. His behaviour is said to have become increasingly concerning to ICC officials.</p><p>A source familiar with Bensouda’s accounts of the final two meetings with Cohen said he had raised questions about her security, and that of her family, in a manner that led her to believe he was threatening her.</p><p>On one occasion, Cohen is said to have shown Bensouda copies of photographs of her husband, which were taken covertly when the couple were visiting London. On another, according to sources, Cohen suggested to the prosecutor that a decision to open a full investigation would be detrimental to her career.</p><p>Four sources familiar with the situation said it was around the same time that Bensouda and other ICC officials discovered that information was circulating among diplomatic channels relating to her husband, who worked as an international affairs consultant.</p><p>Between 2019 and 2020, the Mossad had been actively seeking compromising information on the prosecutor and took an interest in her family members.</p><figure id="06390ceb-982e-4fe7-83d2-31bea22196f0" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-7"><picture><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="The international criminal court in The Hague" src="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9837353801169" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>In February 2021, it was confirmed that the ICC had jurisdiction in occupied Palestinian territories.</span> Photograph: Peter Dejong/AP</figcaption></figure><p>The spy agency obtained a cache of material, including transcripts of an apparent sting operation against her husband.</p><p>It is unclear who conducted the operation, or precisely what he is alleged to have said in the recordings. One possibility is that he had been targeted by the intelligence agency or by private actors of another country that wanted leverage over the ICC. Another possibility is the information was fabricated.</p><div><p>Once in the possession of Israel, however, the material was used by its diplomats in an unsuccessful attempt to undermine the chief prosecutor. But according to multiple sources, Israel failed to convince its allies of the significance of the material.</p><p>
 Three sources briefed on the information shared by Israel at a diplomatic level described the efforts as part of an unsuccessful “smear campaign” against Bensouda. “They went after Fatou,” one source said, but it had “no impact” on the prosecutor’s work.</p></div><figure id="b252e0f2-65b5-4458-83d8-cab4d4b3992d" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-8"><picture><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Trump and Netanyahu shake hands" src="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.1805273833671" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Trump and Netanyahu. The Trump administration imposed visa restrictions and sanctions on Bensouda in 2019-20.</span> Photograph: Ronen Zvulun/Reuters</figcaption></figure><p>The diplomatic efforts were part of a coordinated effort by the governments of Netanyahu and <a href="https://www.theguardian.com/us-news/donaldtrump" data-link-name="in body link" data-component="auto-linked-tag">Donald Trump</a> in the US to place public and private pressure on the prosecutor and her staff.</p><p>Between 2019 and 2020, in an unprecedented decision, the Trump administration imposed visa restrictions and sanctions <a href="https://www.theguardian.com/law/2020/sep/02/us-sanctions-international-criminal-court-fatou-bensouda" data-link-name="in body link">on the chief prosecutor</a>. The move was in retaliation to Bensouda’s pursuit of a separate investigation into war crimes in Afghanistan, allegedly committed by the Taliban and both Afghan and US military personnel.</p><p>However, Mike Pompeo, then US secretary of state, linked the sanctions package to the Palestine case. “It’s clear the ICC is only putting Israel in [its] crosshairs for nakedly political purposes,” he said.</p><p>Months later, he accused Bensouda, without citing any evidence, of having “engaged in corrupt acts for her personal benefit”.</p><p>The <a href="https://www.theguardian.com/law/2021/apr/02/us-lifts-sanctions-icc-prosecutor-fatou-bensouda-pompeo-blinken" data-link-name="in body link">US sanctions were rescinded</a> after President Joe Biden entered the White House.</p><p>In February 2021, the ICC’s pre-trial chamber issued a ruling <a href="https://www.theguardian.com/law/2021/feb/05/icc-rules-it-can-investigate-war-crimes-in-palestine-despite-israeli-objections" data-link-name="in body link">confirming the ICC had jurisdiction</a> in occupied Palestinian territories. The following month, Bensouda <a href="https://www.theguardian.com/law/2021/mar/03/icc-open-formal-investigation-war-crimes-palestine" data-link-name="in body link">announced the opening</a> of the criminal investigation.</p><p>“In the end, our central concern must be for the victims of crimes, both Palestinian and Israeli, arising from the long cycle of violence and insecurity that has caused deep suffering and despair on all sides,” she said at the time.</p><p>Bensouda completed her nine-year term at the ICC three months later, leaving it to her successor, Khan, to take up the investigation. It was only after the Hamas attacks on Israel on 7 October and the ensuing war on Gaza that the ICC’s investigation gained renewed urgency, culminating in last week’s request for arrest warrants.</p><p>It was the conclusion Israel’s political, military and intelligence establishment had feared. “The fact they chose the head of Mossad to be the prime minister’s unofficial messenger to [Bensouda] was to intimidate, by definition,” said a source briefed on Cohen’s operation. “It failed.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers cracked an 11-year-old password to a $3M crypto wallet (227 pts)]]></title>
            <link>https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/</link>
            <guid>40503925</guid>
            <pubDate>Tue, 28 May 2024 18:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/">https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/</a>, See on <a href="https://news.ycombinator.com/item?id=40503925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Two years ago</span> when “Michael,” an owner of <a href="https://www.wired.com/tag/cryptocurrency/">cryptocurrency</a>, contacted Joe Grand to help recover access to about $2 million worth of <a href="https://www.wired.com/tag/bitcoin/">bitcoin</a> he stored in encrypted format on his computer, Grand turned him down.</p><p>Michael, who is based in Europe and asked to remain anonymous, stored the cryptocurrency in a password-protected digital wallet. He generated a password using the RoboForm password manager and stored that password in a file encrypted with a tool called TrueCrypt. At some point, that file got corrupted and Michael lost access to the 20-character password he had generated to secure his 43.6 BTC (worth a total of about €4,000, or $5,300, in 2013). Michael used the RoboForm password manager to generate the password but did not store it in his manager. He worried that someone would hack his computer and obtain the password.</p><p>“At [that] time, I was really paranoid with my security,” he laughs.</p><p>Grand is a famed hardware hacker who in 2022 helped another crypto wallet owner <a href="https://www.theverge.com/2022/1/24/22898712/crypto-hardware-wallet-hacking-lost-bitcoin-ethereum-nft">recover access to $2 million in cryptocurrency</a> he thought he’d lost forever after forgetting the PIN to his Trezor wallet. Since then, dozens of people have contacted Grand to help them recover their treasure. But Grand, known by the hacker handle “Kingpin,” turns down most of them, for various reasons.</p><p>Grand is an <a data-offer-url="http://www.grandideastudio.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.grandideastudio.com/&quot;}" href="http://www.grandideastudio.com/" rel="nofollow noopener" target="_blank">electrical engineer</a> who began hacking computing hardware at age 10 and in 2008 cohosted the Discovery Channel’s <em>Prototype This</em> show. He now consults with companies that build complex digital systems to help them understand how hardware hackers like him might subvert their systems. He cracked the Trezor wallet in 2022 using complex hardware techniques that forced the USB-style wallet to reveal its password.</p><figure data-testid="IframeEmbed"><div data-testid="IframeEmbedContainer"><p><iframe height="300px" sandbox="allow-scripts allow-popups allow-same-origin" title="Embedded Frame" src="https://www.youtube-nocookie.com/embed/o5IySpAkThg" allow="autoplay *; encrypted-media *; clipboard-write; autoplay; fullscreen; picture-in-picture"></iframe></p></div></figure><p>But Michael stored his cryptocurrency in a software-based wallet, which meant none of Grand’s hardware skills were relevant this time. He considered brute-forcing Michael’s password—writing a script to automatically guess millions of possible passwords to find the correct one—but determined this wasn’t feasible. He briefly considered that the RoboForm password manager Michael used to generate his password might have a flaw in the way it generated passwords, which would allow him to guess the password more easily. Grand, however, doubted such a flaw existed.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Michael contacted multiple people who specialize in cracking cryptography; they all told him “there’s no chance” of retrieving his money. But last June he approached Grand again, hoping to convince him to help, and this time Grand agreed to give it a try, working with a friend named Bruno in Germany who also hacks digital wallets.</p><p>Grand and Bruno spent months reverse engineering the version of the RoboForm program that they thought Michael had used in 2013 and found that the pseudo-random number generator used to generate passwords in that version—and subsequent versions until 2015—did indeed have a significant flaw that made the random number generator not so random. The RoboForm program unwisely tied the random passwords it generated to the date and time on the user’s computer—it determined the computer’s date and time, and then generated passwords that were predictable. If you knew the date and time and other parameters, you could compute any password that would have been generated on a certain date and time in the past.</p><p>If Michael knew the day or general time frame in 2013 when he generated it, as well as the parameters he used to generate the password (for example, the number of characters in the password, including lower- and upper-case letters, figures, and special characters), this would narrow the possible password guesses to a manageable number. Then they could hijack the RoboForm function responsible for checking the date and time on a computer and get it to travel back in time, believing the current date was a day in the 2013 time frame when Michael generated his password. RoboForm would then spit out the same passwords it generated on the days in 2013.</p><p>There was one problem: Michael couldn’t remember when he created the password.</p><p>According to the log on his software wallet, Michael moved bitcoin into his wallet for the first time on April 14, 2013. But he couldn’t remember if he generated the password the same day or some time before or after this. So, looking at the parameters of other passwords he generated using RoboForm, Grand and Bruno configured RoboForm to generate 20-character passwords with upper- and lower-case letters, numbers, and eight special characters from March 1 to April 20, 2013.</p><p>It failed to generate the right password. So Grand and Bruno lengthened the time frame from April 20 to June 1, 2013, using the same parameters. Still no luck.</p><p>Michael says they kept coming back to him, asking if he was sure about the parameters he’d used. He stuck to his first answer.</p><p>“They really annoyed me, because who knows what I did 10 years ago,” he recalls. He found other passwords he generated with RoboForm in 2013, and two of them did not use special characters, so Grand and Bruno adjusted. Last November, they reached out to Michael to set up a meeting in person. “I thought, ‘Oh my God, they will ask me again for the settings.”</p><p>Instead, they revealed that they had finally found the correct password—no special characters. It was generated on May 15, 2013, at 4:10:40 pm GMT.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“We ultimately got lucky that our parameters and time range was right. If either of those were wrong, we would have … continued to take guesses/shots in the dark,” Grand says in an email to WIRED. “It would have taken significantly longer to precompute all the possible passwords.”</p><p>Grand and Bruno <a href="https://www.youtube.com/watch?v=o5IySpAkThg">created a video</a> to explain the technical details more thoroughly.</p><p>RoboForm, made by US-based Siber Systems, was one of the first password managers on the market, and <a data-offer-url="https://earthweb.com/roboform-users/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://earthweb.com/roboform-users/&quot;}" href="https://earthweb.com/roboform-users/" rel="nofollow noopener" target="_blank">currently has more than 6 million users</a> worldwide, according to a company report. In 2015, Siber seemed to fix the RoboForm password manager. In a cursory glance, Grand and Bruno couldn’t find any sign that the pseudo-random number generator in the 2015 version used the computer’s time, which makes them think they removed it to fix the flaw, though Grand says they would need to examine it more thoroughly to be certain.</p><p>Siber Systems confirmed to WIRED that it did fix the issue with version 7.9.14 of RoboForm, released June 10, 2015, but a spokesperson wouldn’t answer questions about how it did so. In a <a data-offer-url="https://www.roboform.com/news-windows" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.roboform.com/news-windows&quot;}" href="https://www.roboform.com/news-windows" rel="nofollow noopener" target="_blank">changelog</a> on the company’s website, it mentions only that Siber programmers made changes to&nbsp;“increase randomness of generated passwords,” but it doesn’t say how they did this. Siber spokesman Simon Davis says that “RoboForm 7 was discontinued in 2017.”</p><p>Grand says that, without knowing how Siber fixed the issue, attackers may still be able to regenerate passwords generated by versions of RoboForm released before the fix in 2015. He’s also not sure if current versions contain the problem.</p><p>“I'm still not sure I would trust it without knowing how they actually improved the password generation in more recent versions,” he says. “I'm not sure if RoboForm knew how bad this particular weakness was.”</p><p>Customers may also still be using passwords that were generated with the early versions of the program before the fix. It doesn’t appear that Siber ever notified customers when it released the fixed version 7.9.14 in 2015 that they should generate new passwords for critical accounts or data. The company didn’t respond to a question about this.</p><p>If Siber didn’t inform customers, this would mean that anyone like Michael who used RoboForm to generate passwords prior to 2015—and are still using those passwords—may have vulnerable passwords that hackers can regenerate.</p><p>“We know that most people don't change passwords unless they're prompted to do so,” Grand says. “Out of 935 passwords in my password manager (not RoboForm), 220 of them are from 2015 and earlier, and most of them are [for] sites I still use.”</p><p>Depending on what the company did to fix the issue in 2015, newer passwords may also be vulnerable.</p><p>Last November, Grand and Bruno deducted a percentage of bitcoins from Michael’s account for the work they did, then gave him the password to access the rest. The bitcoin was worth $38,000 per coin at the time. Michael waited until it rose to $62,000 per coin and sold some of it. He now has 30 BTC, now worth $3 million, and is waiting for the value to rise to $100,000 per coin.</p><p>Michael says he was lucky that he lost the password years ago because, otherwise, he would have sold off the bitcoin when it was worth $40,000 a coin and missed out on a greater fortune.</p><p>“That I lost the password was financially a good thing.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A robot will soon try to remove melted nuclear fuel from Fukushima reactor (134 pts)]]></title>
            <link>https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58</link>
            <guid>40503648</guid>
            <pubDate>Tue, 28 May 2024 18:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58">https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58</a>, See on <a href="https://news.ycombinator.com/item?id=40503648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>TOKYO (AP) — The operator of Japan’s destroyed Fukushima Daiichi nuclear power plant demonstrated Tuesday how a remote-controlled robot would retrieve tiny bits of melted fuel debris from one of three damaged reactors later this year for the first time since the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/japan-fukushima-quake-tsunami-anniversary-0089f053d670c78dafd9578c242e1fb3">2011 meltdown</a></span>.</p><p>Tokyo Electric Power Company Holdings plans to deploy a “telesco-style” extendable pipe robot into Fukushima Daiichi No. 2 reactor to test the removal of debris from its primary containment vessel by October.</p><p>That work is more than two years behind schedule. The removal of melted fuel was supposed to begin in late 2021 but has been plagued with delays, underscoring the difficulty of recovering from the magnitude 9.0 quake and tsunami in 2011.</p><p>During the demonstration at the Mitsubishi Heavy Industries’ shipyard in Kobe, western Japan, where the robot has been developed, a device equipped with tongs slowly descended from the telescopic pipe to a heap of gravel and picked up a granule.</p>
    

<p>TEPCO plans to remove less than 3 grams (0.1 ounce) of debris in the test at the Fukushima plant.</p><p>“We believe the upcoming test removal of fuel debris from Unit 2 is an extremely important step to steadily carry out future decommissioning work,” said Yusuke Nakagawa, a TEPCO group manager for the fuel debris retrieval program. “It is important to proceed with the test removal safely and steadily.”</p>



<p>About 880 tons of highly radioactive melted nuclear fuel remain inside the three damaged reactors. Critics say the 30- to 40-year cleanup target set by the government and TEPCO for Fukushima Daiichi is overly optimistic. The damage in each reactor is different, and plans must accommodate their conditions.</p>
    
<p>Better understanding the melted fuel debris from inside the reactors is key to their decommissioning. TEPCO deployed four mini drones into the No. 1 reactor’s primary containment vessel earlier this year to capture images from the areas where robots had not reached.</p><h2>___</h2><p>AP video journalist Ayaka McGill contributed to this report.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California is about to side with PG&E – again – to kill community solar projects (146 pts)]]></title>
            <link>https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php</link>
            <guid>40503592</guid>
            <pubDate>Tue, 28 May 2024 18:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php">https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php</a>, See on <a href="https://news.ycombinator.com/item?id=40503592">Hacker News</a></p>
Couldn't get https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[TTE: Terminal Text Effects (1357 pts)]]></title>
            <link>https://chrisbuilds.github.io/terminaltexteffects/showroom/</link>
            <guid>40503202</guid>
            <pubDate>Tue, 28 May 2024 17:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrisbuilds.github.io/terminaltexteffects/showroom/">https://chrisbuilds.github.io/terminaltexteffects/showroom/</a>, See on <a href="https://news.ycombinator.com/item?id=40503202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  

  
  



<p>The effects shown below represent the built-in library of effects and their default configuration.</p>
<h2 id="beams">Beams</h2>
<p>Creates beams which travel over the canvas illuminating the characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/beams_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/beams/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/beams/#terminaltexteffects.effects.effect_beams.BeamsConfig">Config</a></p>
<details>
<summary>Beams Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>--beam-row-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>                    Symbols to use for the beam effect when moving along a row. Strings will be used in sequence to create an animation. (default: ('▂', '▁', '_'))
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>--beam-column-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>                    Symbols to use for the beam effect when moving along a column. Strings will be used in sequence to create an animation. (default: ('▌', '▍', '▎', '▏'))
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>--beam-delay (int &gt; 0)
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                    Number of frames to wait before adding the next group of beams. Beams are added in groups of size random(1, 5). (default: 10)
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>--beam-row-speed-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                    Minimum speed of the beam when moving along a row. (default: (10, 40))
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>--beam-column-speed-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>                    Minimum speed of the beam when moving along a column. (default: (6, 10))
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>--beam-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>                    Space separated, unquoted, list of colors for the beam, a gradient will be created between the colors. (default: ('ffffff', '00D1FF', '8A008A'))
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>--beam-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>                    Space separated, unquoted, numbers for the of gradient steps to use. More steps will create a smoother and longer gradient animation. Steps are paired with the colors in final-gradient-
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>                    stops. (default: (2, 8))
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>--beam-gradient-frames (int &gt; 0)
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 2)
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>                    Space separated, unquoted, list of colors for the wipe gradient. (default: ('8A008A', '00D1FF', 'ffffff'))
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>                    Space separated, unquoted, numbers for the of gradient steps to use. More steps will create a smoother and longer gradient animation. Steps are paired with the colors in final-gradient-
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>                    stops. (default: (12,))
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>--final-wipe-speed (int &gt; 0)
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>                    Speed of the final wipe as measured in diagonal groups activated per frame. (default: 1)
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>Example: terminaltexteffects beams --beam-row-symbols ▂ ▁ _ --beam-column-symbols ▌ ▍ ▎ ▏ --beam-delay 10 --beam-row-speed-range 10-40 --beam-column-speed-range 6-10 --beam-gradient-stops ffffff 00D1FF 8A008A --beam-gradient-steps 2 8 --beam-gradient-frames 2 --final-gradient-stops 8A008A 00D1FF ffffff --final-gradient-steps 12 --final-gradient-frames 5 --final-gradient-direction vertical --final-wipe-speed 1
</span></code></pre></div>
</details>
<hr>
<h2 id="binarypath">Binarypath</h2>
<p>Decodes characters into their binary form. Characters travel from outside the canvas towards their input coordinate, moving at right angles.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/binarypath_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/binarypath/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/binarypath/#terminaltexteffects.effects.effect_binarypath.BinaryPathConfig">Config</a></p>
<details>
<summary>Binarypath Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>                    (default: ('00d500', '007500'))
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>                    Direction of the final gradient. (default: Direction.CENTER)
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>--binary-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>                    Space separated, unquoted, list of colors for the binary characters. Character color is randomly assigned from this list. (default: ('044E29', '157e38', '45bf55', '95ed87'))
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>                    Speed of the binary groups as they travel around the terminal. (default: 1.0)
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>--active-binary-groups (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>                    Maximum number of binary groups that are active at any given time. Lower this to improve performance. (default: 0.05)
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>Example: terminaltexteffects binarypath --final-gradient-stops 00d500 007500 --final-gradient-steps 12 --final-gradient-direction vertical --binary-colors 044E29 157e38 45bf55 95ed87 --movement-speed 1.0 --active-binary-groups 0.05
</span></code></pre></div>
</details>
<hr>
<h2 id="blackhole">Blackhole</h2>
<p>Creates a blackhole in a starfield, consumes the stars, explodes the input data back into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/blackhole_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/blackhole/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/blackhole/#terminaltexteffects.effects.effect_blackhole.BlackholeConfig">Config</a></p>
<details>
<summary>Blackhole Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>--blackhole-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>                    Color for the stars that comprise the blackhole border. (default: ffffff)
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>--star-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>                    List of colors from which character colors will be chosen and applied after the explosion, but before the cooldown to final color. (default: ('ffcc0d', 'ff7326', 'ff194d', 'bf2669',
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>                    '702a8c', '049dbf'))
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>                    (default: ('8A008A', '00D1FF', 'ffffff'))
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>Example: terminaltexteffects blackhole --star-colors ffcc0d ff7326 ff194d bf2669 702a8c 049dbf --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-direction vertical
</span></code></pre></div>
</details>
<hr>
<h2 id="bouncyballs">BouncyBalls</h2>
<p>Characters fall from the top of the canvas as bouncy balls before settling into place.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/bouncyballs_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bouncyballs/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bouncyballs/#terminaltexteffects.effects.effect_bouncyballs.BouncyBallsConfig">Config</a></p>
<details>
<summary>Bouncyballs Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>--ball-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>                    Space separated list of colors from which ball colors will be randomly selected. If no colors are provided, the colors are random. (default: ('d1f4a5', '96e2a4', '5acda9'))
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>--ball-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>                    Space separated list of symbols to use for the balls. (default: ('*', 'o', 'O', '0', '.'))
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>                    (default: ('f8ffae', '43c6ac'))
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>--ball-delay (int &gt;= 0)
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>                    Number of frames between ball drops, increase to reduce ball drop rate. (default: 7)
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>--movement-speed (float &gt; 0)
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>                    Movement speed of the characters.  (default: 0.25)
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>--easing EASING       Easing function to use for character movement. (default: out_bounce)
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>Easing
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>------
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>Note: A prefix must be added to the function name.
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>All easing functions support the following prefixes:
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    IN_  - Ease in
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>    OUT_ - Ease out
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>Easing Functions
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>----------------
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>SINE   - Sine easing
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>QUAD   - Quadratic easing
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>CUBIC  - Cubic easing
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>QUART  - Quartic easing
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>QUINT  - Quintic easing
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>EXPO   - Exponential easing
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>CIRC   - Circular easing
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>BACK   - Back easing
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>ELASTIC - Elastic easing
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>BOUNCE - Bounce easing
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-3-41"><a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>
</span><span id="__span-3-42"><a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>Example: terminaltexteffects bouncyballs --ball-colors d1f4a5 96e2a4 5acda9 --ball-symbols o "*" O 0 . --final-gradient-stops f8ffae 43c6ac --final-gradient-steps 12 --final-gradient-direction diagonal --ball-delay 7 --movement-speed 0.25 --easing OUT_BOUNCE
</span></code></pre></div>
</details>
<hr>
<h2 id="bubbles">Bubbles</h2>
<p>Forms bubbles with the characters. Bubbles float down and pop.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/bubbles_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bubbles/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bubbles/#terminaltexteffects.effects.effect_bubbles.BubblesConfig">Config</a></p>
<details>
<summary>Bubbles Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>--rainbow             If set, the bubbles will be colored with a rotating rainbow gradient. (default: False)
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>--bubble-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>                    Space separated, unquoted, list of colors for the bubbles. Ignored if --no-rainbow is left as default False. (default: ('d33aff', '7395c4', '43c2a7', '02ff7f'))
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>--pop-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>                    Color for the spray emitted when a bubble pops. (default: ffffff)
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>                    (default: ('d33aff', '02ff7f'))
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>--bubble-speed (float &gt; 0)
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>                    Speed of the floating bubbles.  (default: 0.1)
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>--bubble-delay (int &gt; 0)
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>                    Number of frames between bubbles. (default: 50)
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>--pop-condition {row,bottom,anywhere}
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>                    Condition for a bubble to pop. 'row' will pop the bubble when it reaches the the lowest row for which a character in the bubble originates. 'bottom' will pop the bubble at the bottom
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>                    row of the terminal. 'anywhere' will pop the bubble randomly, or at the bottom of the terminal. (default: row)
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>--easing (Easing Function)
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>                    Easing function to use for character movement after a bubble pops. (default: in_out_sine)
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>Easing
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>------
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>Note: A prefix must be added to the function name.
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>All easing functions support the following prefixes:
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>    IN_  - Ease in
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>    OUT_ - Ease out
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>Easing Functions
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>----------------
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>SINE   - Sine easing
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>QUAD   - Quadratic easing
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a>CUBIC  - Cubic easing
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a>QUART  - Quartic easing
</span><span id="__span-4-38"><a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a>QUINT  - Quintic easing
</span><span id="__span-4-39"><a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a>EXPO   - Exponential easing
</span><span id="__span-4-40"><a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a>CIRC   - Circular easing
</span><span id="__span-4-41"><a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a>BACK   - Back easing
</span><span id="__span-4-42"><a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a>ELASTIC - Elastic easing
</span><span id="__span-4-43"><a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a>BOUNCE - Bounce easing
</span><span id="__span-4-44"><a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a>
</span><span id="__span-4-45"><a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-4-46"><a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a>
</span><span id="__span-4-47"><a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a>Example: terminaltexteffects bubbles --bubble-colors d33aff 7395c4 43c2a7 02ff7f --pop-color ffffff --final-gradient-stops d33aff 02ff7f --final-gradient-steps 12 --final-gradient-direction diagonal --bubble-speed 0.1 --bubble-delay 50 --pop-condition row --easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="burn">Burn</h2>
<p>Characters are ignited and burn up the screen.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/burn_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/burn/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/burn/#terminaltexteffects.effects.effect_burn.BurnConfig">Config</a></p>
<details>
<summary>Burn Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>                    Color of the characters before they start to burn. (default: 837373)
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>--burn-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>                    Colors transitioned through as the characters burn. (default: ('ffffff', 'fff75d', 'fe650d', '8A003C', '510100'))
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>                    (default: ('00c3ff', 'ffff1c'))
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>Example: terminaltexteffects burn --starting-color 837373 --burn-colors ffffff fff75d fe650d 8a003c 510100 --final-gradient-stops 00c3ff ffff1c --final-gradient-steps 12
</span></code></pre></div>
</details>
<hr>
<h2 id="colorshift">ColorShift</h2>
<p>Display a gradient that shifts colors across the terminal.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/colorshift_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/colorshift/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/colorshift/#terminaltexteffects.effects.effect_colorshift.ColorShiftConfig">Config</a></p>
<details>
<summary>ColorShift Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>--gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>                    Space separated, unquoted, list of colors for the gradient. (default: (Color(e81416), Color(ffa500), Color(faeb36), Color(79c314), Color(487de7), Color(4b369d), Color(70369d)))
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>--gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>                    Number of gradient steps to use. More steps will create a smoother gradient animation. (default: 12)
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>--gradient-frames (int &gt; 0)
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>--travel              Display the gradient as a traveling wave (default: False)
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>--travel-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>                    Direction the gradient travels across the canvas. (default: Direction.HORIZONTAL)
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>--reverse-travel-direction
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>                    Reverse the gradient travel direction. (default: False)
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>--loop-gradient       Loop the gradient. This causes the final gradient color to transition back to the first gradient color. (default: False)
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>--cycles (int &gt; 0)    Number of times to cycle the gradient. (default: 3)
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>--skip-final-gradient
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>                    Skip the final gradient. (default: False)
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>                    (default: (Color(e81416), Color(ffa500), Color(faeb36), Color(79c314), Color(487de7), Color(4b369d), Color(70369d)))
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>Example: terminaltexteffects colorshift --gradient-stops 0000ff ffffff 0000ff --gradient-steps 12
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>        --gradient-frames 10 --cycles 3 --travel --travel-direction radial --loop --final-gradient-stops 00c3ff ffff1c --final-gradient-steps 12
</span></code></pre></div>
</details>
<hr>
<h2 id="crumble">Crumble</h2>
<p>Characters crumble into dust before being vacuumed up and reformed.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/crumble_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/crumble/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/crumble/#terminaltexteffects.effects.effect_crumble.CrumbleConfig">Config</a></p>
<details>
<summary>Crumble Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>                    (default: ('5CE1FF', 'FF8C00'))
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>Example: terminaltexteffects crumble --final-gradient-stops 5CE1FF FF8C00 --final-gradient-steps 12 --final-gradient-direction diagonal
</span></code></pre></div>
</details>
<hr>
<h2 id="decrypt">Decrypt</h2>
<p>Movie style text decryption effect.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/decrypt_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/decrypt/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/decrypt/#terminaltexteffects.effects.effect_decrypt.DecryptConfig">Config</a></p>
<details>
<summary>Decrypt Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>--typing-speed (int &gt; 0)
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>                    Number of characters typed per keystroke. (default: 1)
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>--ciphertext-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>                    Space separated, unquoted, list of colors for the ciphertext. Color will be randomly selected for each character. (default: ('008000', '00cb00', '00ff00'))
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>                    (default: ('eda000',))
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>Example: terminaltexteffects decrypt --typing-speed 2 --ciphertext-colors 008000 00cb00 00ff00 --final-gradient-stops eda000 --final-gradient-steps 12 --final-gradient-direction vertical
</span></code></pre></div>
</details>
<hr>
<h2 id="errorcorrect">ErrorCorrect</h2>
<p>Swaps characters from an incorrect initial position to the correct position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/errorcorrect_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/errorcorrect/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/errorcorrect/#terminaltexteffects.effects.effect_errorcorrect.ErrorCorrectConfig">Config</a></p>
<details>
<summary>ErrorCorrect Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>--error-pairs (int &gt; 0)
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>                        Percent of characters that are in the wrong position. This is a float between 0 and 1.0. 0.2 means 20 percent of the characters will be in the wrong position. (default: 0.1)
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>--swap-delay (int &gt; 0)
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>                        Number of frames between swaps. (default: 10)
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>--error-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>                        Color for the characters that are in the wrong position. (default: e74c3c)
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>--correct-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>                        Color for the characters once corrected, this is a gradient from error-color and fades to final-color. (default: 45bf55)
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>                        Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>                        (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>                        Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>                        Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a>--movement-speed (float &gt; 0)
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>                        Speed of the characters while moving to the correct position. Valid values are n &gt; 0. Adjust speed and animation rate separately to fine tune the
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>                        effect. (default: 0.5)
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>    Easing
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>    ------
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>    Note: A prefix must be added to the function name.
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>    All easing functions support the following prefixes:
</span><span id="__span-9-25"><a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>        IN_  - Ease in
</span><span id="__span-9-26"><a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a>        OUT_ - Ease out
</span><span id="__span-9-27"><a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>        IN_OUT_ - Ease in and out
</span><span id="__span-9-28"><a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>
</span><span id="__span-9-29"><a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a>    Easing Functions
</span><span id="__span-9-30"><a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a>    ----------------
</span><span id="__span-9-31"><a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a>    SINE   - Sine easing
</span><span id="__span-9-32"><a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a>    QUAD   - Quadratic easing
</span><span id="__span-9-33"><a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a>    CUBIC  - Cubic easing
</span><span id="__span-9-34"><a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a>    QUART  - Quartic easing
</span><span id="__span-9-35"><a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a>    QUINT  - Quintic easing
</span><span id="__span-9-36"><a id="__codelineno-9-36" name="__codelineno-9-36" href="#__codelineno-9-36"></a>    EXPO   - Exponential easing
</span><span id="__span-9-37"><a id="__codelineno-9-37" name="__codelineno-9-37" href="#__codelineno-9-37"></a>    CIRC   - Circular easing
</span><span id="__span-9-38"><a id="__codelineno-9-38" name="__codelineno-9-38" href="#__codelineno-9-38"></a>    BACK   - Back easing
</span><span id="__span-9-39"><a id="__codelineno-9-39" name="__codelineno-9-39" href="#__codelineno-9-39"></a>    ELASTIC - Elastic easing
</span><span id="__span-9-40"><a id="__codelineno-9-40" name="__codelineno-9-40" href="#__codelineno-9-40"></a>    BOUNCE - Bounce easing
</span><span id="__span-9-41"><a id="__codelineno-9-41" name="__codelineno-9-41" href="#__codelineno-9-41"></a>
</span><span id="__span-9-42"><a id="__codelineno-9-42" name="__codelineno-9-42" href="#__codelineno-9-42"></a>    Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-9-43"><a id="__codelineno-9-43" name="__codelineno-9-43" href="#__codelineno-9-43"></a>
</span><span id="__span-9-44"><a id="__codelineno-9-44" name="__codelineno-9-44" href="#__codelineno-9-44"></a>
</span><span id="__span-9-45"><a id="__codelineno-9-45" name="__codelineno-9-45" href="#__codelineno-9-45"></a>Example: terminaltexteffects errorcorrect --error-pairs 0.1 --swap-delay 10 --error-color e74c3c --correct-color 45bf55 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --movement-speed 0.5
</span></code></pre></div>
</details>
<hr>
<h2 id="expand">Expand</h2>
<p>Characters expand from the center.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/expand_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/expand/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/expand/#terminaltexteffects.effects.effect_expand.ExpandConfig">Config</a></p>
<details>
<summary>Expand Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>                    Movement speed of the characters.  (default: 0.35)
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a>--expand-easing EXPAND_EASING
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a>                    Easing function to use for character movement. (default: in_out_quart)
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a>
</span><span id="__span-10-15"><a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a>Easing
</span><span id="__span-10-16"><a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a>------
</span><span id="__span-10-17"><a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-10-18"><a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a>
</span><span id="__span-10-19"><a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a>All easing functions support the following prefixes:
</span><span id="__span-10-20"><a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a>    IN_  - Ease in
</span><span id="__span-10-21"><a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a>    OUT_ - Ease out
</span><span id="__span-10-22"><a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-10-23"><a id="__codelineno-10-23" name="__codelineno-10-23" href="#__codelineno-10-23"></a>
</span><span id="__span-10-24"><a id="__codelineno-10-24" name="__codelineno-10-24" href="#__codelineno-10-24"></a>Easing Functions
</span><span id="__span-10-25"><a id="__codelineno-10-25" name="__codelineno-10-25" href="#__codelineno-10-25"></a>----------------
</span><span id="__span-10-26"><a id="__codelineno-10-26" name="__codelineno-10-26" href="#__codelineno-10-26"></a>SINE   - Sine easing
</span><span id="__span-10-27"><a id="__codelineno-10-27" name="__codelineno-10-27" href="#__codelineno-10-27"></a>QUAD   - Quadratic easing
</span><span id="__span-10-28"><a id="__codelineno-10-28" name="__codelineno-10-28" href="#__codelineno-10-28"></a>CUBIC  - Cubic easing
</span><span id="__span-10-29"><a id="__codelineno-10-29" name="__codelineno-10-29" href="#__codelineno-10-29"></a>QUART  - Quartic easing
</span><span id="__span-10-30"><a id="__codelineno-10-30" name="__codelineno-10-30" href="#__codelineno-10-30"></a>QUINT  - Quintic easing
</span><span id="__span-10-31"><a id="__codelineno-10-31" name="__codelineno-10-31" href="#__codelineno-10-31"></a>EXPO   - Exponential easing
</span><span id="__span-10-32"><a id="__codelineno-10-32" name="__codelineno-10-32" href="#__codelineno-10-32"></a>CIRC   - Circular easing
</span><span id="__span-10-33"><a id="__codelineno-10-33" name="__codelineno-10-33" href="#__codelineno-10-33"></a>BACK   - Back easing
</span><span id="__span-10-34"><a id="__codelineno-10-34" name="__codelineno-10-34" href="#__codelineno-10-34"></a>ELASTIC - Elastic easing
</span><span id="__span-10-35"><a id="__codelineno-10-35" name="__codelineno-10-35" href="#__codelineno-10-35"></a>BOUNCE - Bounce easing
</span><span id="__span-10-36"><a id="__codelineno-10-36" name="__codelineno-10-36" href="#__codelineno-10-36"></a>
</span><span id="__span-10-37"><a id="__codelineno-10-37" name="__codelineno-10-37" href="#__codelineno-10-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-10-38"><a id="__codelineno-10-38" name="__codelineno-10-38" href="#__codelineno-10-38"></a>
</span><span id="__span-10-39"><a id="__codelineno-10-39" name="__codelineno-10-39" href="#__codelineno-10-39"></a>
</span><span id="__span-10-40"><a id="__codelineno-10-40" name="__codelineno-10-40" href="#__codelineno-10-40"></a>Example: terminaltexteffects expand --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-frames 5 --movement-speed 0.35 --expand-easing IN_OUT_QUART
</span></code></pre></div>
</details>
<hr>
<h2 id="fireworks">Fireworks</h2>
<p>Launches characters up the screen where they explode like fireworks and fall into place.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/fireworks_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/fireworks/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/fireworks/#terminaltexteffects.effects.effect_fireworks.FireworksConfig">Config</a></p>
<details>
<summary>Fireworks Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>--explode-anywhere    If set, fireworks explode anywhere in the canvas. Otherwise, fireworks explode above highest settled row of text. (default: False)
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>--firework-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>                    Space separated list of colors from which firework colors will be randomly selected. (default: ('88F7E2', '44D492', 'F5EB67', 'FFA15C', 'FA233E'))
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>--firework-symbol (ASCII/UTF-8 character)
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>                    Symbol to use for the firework shell. (default: o)
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>--firework-volume (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>                    Percent of total characters in each firework shell. (default: 0.02)
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>                    Direction of the final gradient. (default: Direction.HORIZONTAL)
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>--launch-delay (int &gt;= 0)
</span><span id="__span-11-16"><a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>                    Number of frames to wait between launching each firework shell. +/- 0-50 percent randomness is applied to this value. (default: 60)
</span><span id="__span-11-17"><a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>--explode-distance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-11-18"><a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>                    Maximum distance from the firework shell origin to the explode waypoint as a percentage of the total canvas width. (default: 0.1)
</span><span id="__span-11-19"><a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>
</span><span id="__span-11-20"><a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>Example: terminaltexteffects fireworks --firework-colors 88F7E2 44D492 F5EB67 FFA15C FA233E --firework-symbol o --firework-volume 0.02 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --launch-delay 60 --explode-distance 0.1 --explode-anywhere
</span></code></pre></div>
</details>
<hr>
<h2 id="middleout">MiddleOut</h2>
<p>Text expands in a single row or column in the middle of the canvas then out.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/middleout_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/middleout/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/middleout/#terminaltexteffects.effects.effect_middleout.MiddleOutConfig">Config</a></p>
<details>
<summary>MiddleOut Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>                    Color for the initial text in the center of the canvas. (default: ffffff)
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>--expand-direction {vertical,horizontal}
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>                    Direction the text will expand. (default: vertical)
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>--center-movement-speed (float &gt; 0)
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>                    Speed of the characters during the initial expansion of the center vertical/horiztonal line. Note: Speed effects the number of steps in the easing function. Adjust speed and animation
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>                    rate separately to fine tune the effect. (default: 0.35)
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>--full-movement-speed (float &gt; 0)
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>                    Speed of the characters during the final full expansion. Note: Speed effects the number of steps in the easing function. Adjust speed and animation rate separately to fine tune the
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>                    effect. (default: 0.35)
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>--center-easing CENTER_EASING
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>                    Easing function to use for initial expansion. (default: in_out_sine)
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>--full-easing FULL_EASING
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>                    Easing function to use for full expansion. (default: in_out_sine)
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>Easing
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>------
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>Note: A prefix must be added to the function name.
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>
</span><span id="__span-12-27"><a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>All easing functions support the following prefixes:
</span><span id="__span-12-28"><a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>    IN_  - Ease in
</span><span id="__span-12-29"><a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>    OUT_ - Ease out
</span><span id="__span-12-30"><a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-12-31"><a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a>
</span><span id="__span-12-32"><a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>Easing Functions
</span><span id="__span-12-33"><a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>----------------
</span><span id="__span-12-34"><a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>SINE   - Sine easing
</span><span id="__span-12-35"><a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>QUAD   - Quadratic easing
</span><span id="__span-12-36"><a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>CUBIC  - Cubic easing
</span><span id="__span-12-37"><a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a>QUART  - Quartic easing
</span><span id="__span-12-38"><a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a>QUINT  - Quintic easing
</span><span id="__span-12-39"><a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a>EXPO   - Exponential easing
</span><span id="__span-12-40"><a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a>CIRC   - Circular easing
</span><span id="__span-12-41"><a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a>BACK   - Back easing
</span><span id="__span-12-42"><a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a>ELASTIC - Elastic easing
</span><span id="__span-12-43"><a id="__codelineno-12-43" name="__codelineno-12-43" href="#__codelineno-12-43"></a>BOUNCE - Bounce easing
</span><span id="__span-12-44"><a id="__codelineno-12-44" name="__codelineno-12-44" href="#__codelineno-12-44"></a>
</span><span id="__span-12-45"><a id="__codelineno-12-45" name="__codelineno-12-45" href="#__codelineno-12-45"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-12-46"><a id="__codelineno-12-46" name="__codelineno-12-46" href="#__codelineno-12-46"></a>
</span><span id="__span-12-47"><a id="__codelineno-12-47" name="__codelineno-12-47" href="#__codelineno-12-47"></a>Example: terminaltexteffects middleout --starting-color 8A008A --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --expand-direction vertical --center-movement-speed 0.35 --full-movement-speed 0.35 --center-easing IN_OUT_SINE --full-easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="orbittingvolley">OrbittingVolley</h2>
<p>Four launchers orbit the canvas firing volleys of characters inward to build the input text from the center out.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/orbittingvolley_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/orbittingvolley/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/orbittingvolley/#terminaltexteffects.effects.effect_orbittingvolley.OrbittingVolleyConfig">Config</a></p>
<details>
<summary>OrbittingVolley Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>--top-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>                    Symbol for the top launcher. (default: █)
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>--right-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>                    Symbol for the right launcher. (default: █)
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>--bottom-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>                    Symbol for the bottom launcher. (default: █)
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>--left-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>                    Symbol for the left launcher. (default: █)
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-13-10"><a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-13-11"><a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>                    (default: ('FFA15C', '44D492'))
</span><span id="__span-13-12"><a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-13-13"><a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-13-14"><a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-13-15"><a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>                    Direction of the final gradient. (default: Direction.RADIAL)
</span><span id="__span-13-16"><a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>--launcher-movement-speed (float &gt; 0)
</span><span id="__span-13-17"><a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>                    Orbitting speed of the launchers. (default: 0.5)
</span><span id="__span-13-18"><a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a>--character-movement-speed (float &gt; 0)
</span><span id="__span-13-19"><a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>                    Speed of the launched characters. (default: 1)
</span><span id="__span-13-20"><a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a>--volley-size (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-13-21"><a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a>                    Percent of total input characters each launcher will fire per volley. Lower limit of one character. (default: 0.03)
</span><span id="__span-13-22"><a id="__codelineno-13-22" name="__codelineno-13-22" href="#__codelineno-13-22"></a>--launch-delay (int &gt;= 0)
</span><span id="__span-13-23"><a id="__codelineno-13-23" name="__codelineno-13-23" href="#__codelineno-13-23"></a>                    Number of animation ticks to wait between volleys of characters. (default: 50)
</span><span id="__span-13-24"><a id="__codelineno-13-24" name="__codelineno-13-24" href="#__codelineno-13-24"></a>--character-easing (Easing Function)
</span><span id="__span-13-25"><a id="__codelineno-13-25" name="__codelineno-13-25" href="#__codelineno-13-25"></a>                    Easing function to use for launched character movement. (default: out_sine)
</span><span id="__span-13-26"><a id="__codelineno-13-26" name="__codelineno-13-26" href="#__codelineno-13-26"></a>
</span><span id="__span-13-27"><a id="__codelineno-13-27" name="__codelineno-13-27" href="#__codelineno-13-27"></a>Easing
</span><span id="__span-13-28"><a id="__codelineno-13-28" name="__codelineno-13-28" href="#__codelineno-13-28"></a>------
</span><span id="__span-13-29"><a id="__codelineno-13-29" name="__codelineno-13-29" href="#__codelineno-13-29"></a>Note: A prefix must be added to the function name.
</span><span id="__span-13-30"><a id="__codelineno-13-30" name="__codelineno-13-30" href="#__codelineno-13-30"></a>
</span><span id="__span-13-31"><a id="__codelineno-13-31" name="__codelineno-13-31" href="#__codelineno-13-31"></a>All easing functions support the following prefixes:
</span><span id="__span-13-32"><a id="__codelineno-13-32" name="__codelineno-13-32" href="#__codelineno-13-32"></a>    IN_  - Ease in
</span><span id="__span-13-33"><a id="__codelineno-13-33" name="__codelineno-13-33" href="#__codelineno-13-33"></a>    OUT_ - Ease out
</span><span id="__span-13-34"><a id="__codelineno-13-34" name="__codelineno-13-34" href="#__codelineno-13-34"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-13-35"><a id="__codelineno-13-35" name="__codelineno-13-35" href="#__codelineno-13-35"></a>
</span><span id="__span-13-36"><a id="__codelineno-13-36" name="__codelineno-13-36" href="#__codelineno-13-36"></a>Easing Functions
</span><span id="__span-13-37"><a id="__codelineno-13-37" name="__codelineno-13-37" href="#__codelineno-13-37"></a>----------------
</span><span id="__span-13-38"><a id="__codelineno-13-38" name="__codelineno-13-38" href="#__codelineno-13-38"></a>SINE   - Sine easing
</span><span id="__span-13-39"><a id="__codelineno-13-39" name="__codelineno-13-39" href="#__codelineno-13-39"></a>QUAD   - Quadratic easing
</span><span id="__span-13-40"><a id="__codelineno-13-40" name="__codelineno-13-40" href="#__codelineno-13-40"></a>CUBIC  - Cubic easing
</span><span id="__span-13-41"><a id="__codelineno-13-41" name="__codelineno-13-41" href="#__codelineno-13-41"></a>QUART  - Quartic easing
</span><span id="__span-13-42"><a id="__codelineno-13-42" name="__codelineno-13-42" href="#__codelineno-13-42"></a>QUINT  - Quintic easing
</span><span id="__span-13-43"><a id="__codelineno-13-43" name="__codelineno-13-43" href="#__codelineno-13-43"></a>EXPO   - Exponential easing
</span><span id="__span-13-44"><a id="__codelineno-13-44" name="__codelineno-13-44" href="#__codelineno-13-44"></a>CIRC   - Circular easing
</span><span id="__span-13-45"><a id="__codelineno-13-45" name="__codelineno-13-45" href="#__codelineno-13-45"></a>BACK   - Back easing
</span><span id="__span-13-46"><a id="__codelineno-13-46" name="__codelineno-13-46" href="#__codelineno-13-46"></a>ELASTIC - Elastic easing
</span><span id="__span-13-47"><a id="__codelineno-13-47" name="__codelineno-13-47" href="#__codelineno-13-47"></a>BOUNCE - Bounce easing
</span><span id="__span-13-48"><a id="__codelineno-13-48" name="__codelineno-13-48" href="#__codelineno-13-48"></a>
</span><span id="__span-13-49"><a id="__codelineno-13-49" name="__codelineno-13-49" href="#__codelineno-13-49"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-13-50"><a id="__codelineno-13-50" name="__codelineno-13-50" href="#__codelineno-13-50"></a>
</span><span id="__span-13-51"><a id="__codelineno-13-51" name="__codelineno-13-51" href="#__codelineno-13-51"></a>
</span><span id="__span-13-52"><a id="__codelineno-13-52" name="__codelineno-13-52" href="#__codelineno-13-52"></a>Example: terminaltexteffects orbittingvolley --top-launcher-symbol █ --right-launcher-symbol █ --bottom-launcher-symbol █ --left-launcher-symbol █ --final-gradient-stops FFA15C 44D492 --final-gradient-steps 12 --launcher-movement-speed 0.5 --character-movement-speed 1 --volley-size 0.03 --launch-delay 50 --character-easing OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="overflow">Overflow</h2>
<p>Input text overflows ands scrolls the terminal in a random order until eventually appearing ordered.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/overflow_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/overflow/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/overflow/#terminaltexteffects.effects.effect_overflow.OverflowConfig">Config</a></p>
<details>
<summary>Overflow Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>--overflow-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>                    Space separated, unquoted, list of colors for the overflow gradient. (default: ('f2ebc0', '8dbfb3', 'f2ebc0'))
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>--overflow-cycles-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>                    Number of cycles to overflow the text. (default: (2, 4))
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>--overflow-speed (int &gt; 0)
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>                    Speed of the overflow effect. (default: 3)
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>Example: terminaltexteffects overflow --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --overflow-gradient-stops f2ebc0 8dbfb3 f2ebc0 --overflow-cycles-range 2-4 --overflow-speed 3
</span></code></pre></div>
</details>
<hr>
<h2 id="pour">Pour</h2>
<p>Pours the characters back and forth from the top, bottom, left, or right.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/pour_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/pour/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/pour/#terminaltexteffects.effects.effect_pour.PourConfig">Config</a></p>
<details>
<summary>Pour Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>--pour-direction {up,down,left,right}
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>                    Direction the text will pour. (default: down)
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>--pour-speed (int &gt; 0)
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>                    Number of characters poured in per tick. Increase to speed up the effect. (default: 1)
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>--movement-speed (float &gt; 0)
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>                    Movement speed of the characters.  (default: 0.2)
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>--gap (int &gt;= 0)      Number of frames to wait between each character in the pour effect. Increase to slow down effect and create a more defined back and forth motion. (default: 1)
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>                    Color of the characters before the gradient starts. (default: ffffff)
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('8A008A', '00D1FF',
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>                    'FFFFFF'))
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-15-15"><a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-15-16"><a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 10)
</span><span id="__span-15-17"><a id="__codelineno-15-17" name="__codelineno-15-17" href="#__codelineno-15-17"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-15-18"><a id="__codelineno-15-18" name="__codelineno-15-18" href="#__codelineno-15-18"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-15-19"><a id="__codelineno-15-19" name="__codelineno-15-19" href="#__codelineno-15-19"></a>--easing EASING       Easing function to use for character movement. (default: in_quad)
</span><span id="__span-15-20"><a id="__codelineno-15-20" name="__codelineno-15-20" href="#__codelineno-15-20"></a>
</span><span id="__span-15-21"><a id="__codelineno-15-21" name="__codelineno-15-21" href="#__codelineno-15-21"></a>Easing
</span><span id="__span-15-22"><a id="__codelineno-15-22" name="__codelineno-15-22" href="#__codelineno-15-22"></a>------
</span><span id="__span-15-23"><a id="__codelineno-15-23" name="__codelineno-15-23" href="#__codelineno-15-23"></a>Note: A prefix must be added to the function name.
</span><span id="__span-15-24"><a id="__codelineno-15-24" name="__codelineno-15-24" href="#__codelineno-15-24"></a>
</span><span id="__span-15-25"><a id="__codelineno-15-25" name="__codelineno-15-25" href="#__codelineno-15-25"></a>All easing functions support the following prefixes:
</span><span id="__span-15-26"><a id="__codelineno-15-26" name="__codelineno-15-26" href="#__codelineno-15-26"></a>    IN_  - Ease in
</span><span id="__span-15-27"><a id="__codelineno-15-27" name="__codelineno-15-27" href="#__codelineno-15-27"></a>    OUT_ - Ease out
</span><span id="__span-15-28"><a id="__codelineno-15-28" name="__codelineno-15-28" href="#__codelineno-15-28"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-15-29"><a id="__codelineno-15-29" name="__codelineno-15-29" href="#__codelineno-15-29"></a>
</span><span id="__span-15-30"><a id="__codelineno-15-30" name="__codelineno-15-30" href="#__codelineno-15-30"></a>Easing Functions
</span><span id="__span-15-31"><a id="__codelineno-15-31" name="__codelineno-15-31" href="#__codelineno-15-31"></a>----------------
</span><span id="__span-15-32"><a id="__codelineno-15-32" name="__codelineno-15-32" href="#__codelineno-15-32"></a>SINE   - Sine easing
</span><span id="__span-15-33"><a id="__codelineno-15-33" name="__codelineno-15-33" href="#__codelineno-15-33"></a>QUAD   - Quadratic easing
</span><span id="__span-15-34"><a id="__codelineno-15-34" name="__codelineno-15-34" href="#__codelineno-15-34"></a>CUBIC  - Cubic easing
</span><span id="__span-15-35"><a id="__codelineno-15-35" name="__codelineno-15-35" href="#__codelineno-15-35"></a>QUART  - Quartic easing
</span><span id="__span-15-36"><a id="__codelineno-15-36" name="__codelineno-15-36" href="#__codelineno-15-36"></a>QUINT  - Quintic easing
</span><span id="__span-15-37"><a id="__codelineno-15-37" name="__codelineno-15-37" href="#__codelineno-15-37"></a>EXPO   - Exponential easing
</span><span id="__span-15-38"><a id="__codelineno-15-38" name="__codelineno-15-38" href="#__codelineno-15-38"></a>CIRC   - Circular easing
</span><span id="__span-15-39"><a id="__codelineno-15-39" name="__codelineno-15-39" href="#__codelineno-15-39"></a>BACK   - Back easing
</span><span id="__span-15-40"><a id="__codelineno-15-40" name="__codelineno-15-40" href="#__codelineno-15-40"></a>ELASTIC - Elastic easing
</span><span id="__span-15-41"><a id="__codelineno-15-41" name="__codelineno-15-41" href="#__codelineno-15-41"></a>BOUNCE - Bounce easing
</span><span id="__span-15-42"><a id="__codelineno-15-42" name="__codelineno-15-42" href="#__codelineno-15-42"></a>
</span><span id="__span-15-43"><a id="__codelineno-15-43" name="__codelineno-15-43" href="#__codelineno-15-43"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-15-44"><a id="__codelineno-15-44" name="__codelineno-15-44" href="#__codelineno-15-44"></a>
</span><span id="__span-15-45"><a id="__codelineno-15-45" name="__codelineno-15-45" href="#__codelineno-15-45"></a>Example: terminaltexteffects pour --pour-direction down --movement-speed 0.2 --gap 1 --starting-color FFFFFF --final-gradient-stops 8A008A 00D1FF FFFFFF --easing IN_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="print">Print</h2>
<p>Prints the input data one line at at time with a carriage return and line feed.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/print_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/print/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/print/#terminaltexteffects.effects.effect_print.PrintConfig">Config</a></p>
<details>
<summary>Print Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>                    (default: ('02b8bd', 'c1f0e3', '00ffa0'))
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>--print-head-return-speed (float &gt; 0)
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a>                    Speed of the print head when performing a carriage return. (default: 1.25)
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a>--print-speed (int &gt; 0)
</span><span id="__span-16-11"><a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>                    Speed of the print head when printing characters. (default: 1)
</span><span id="__span-16-12"><a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a>--print-head-easing PRINT_HEAD_EASING
</span><span id="__span-16-13"><a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a>                    Easing function to use for print head movement. (default: in_out_quad)
</span><span id="__span-16-14"><a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>
</span><span id="__span-16-15"><a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>Easing
</span><span id="__span-16-16"><a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a>------
</span><span id="__span-16-17"><a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-16-18"><a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>
</span><span id="__span-16-19"><a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a>All easing functions support the following prefixes:
</span><span id="__span-16-20"><a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a>    IN_  - Ease in
</span><span id="__span-16-21"><a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>    OUT_ - Ease out
</span><span id="__span-16-22"><a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-16-23"><a id="__codelineno-16-23" name="__codelineno-16-23" href="#__codelineno-16-23"></a>
</span><span id="__span-16-24"><a id="__codelineno-16-24" name="__codelineno-16-24" href="#__codelineno-16-24"></a>Easing Functions
</span><span id="__span-16-25"><a id="__codelineno-16-25" name="__codelineno-16-25" href="#__codelineno-16-25"></a>----------------
</span><span id="__span-16-26"><a id="__codelineno-16-26" name="__codelineno-16-26" href="#__codelineno-16-26"></a>SINE   - Sine easing
</span><span id="__span-16-27"><a id="__codelineno-16-27" name="__codelineno-16-27" href="#__codelineno-16-27"></a>QUAD   - Quadratic easing
</span><span id="__span-16-28"><a id="__codelineno-16-28" name="__codelineno-16-28" href="#__codelineno-16-28"></a>CUBIC  - Cubic easing
</span><span id="__span-16-29"><a id="__codelineno-16-29" name="__codelineno-16-29" href="#__codelineno-16-29"></a>QUART  - Quartic easing
</span><span id="__span-16-30"><a id="__codelineno-16-30" name="__codelineno-16-30" href="#__codelineno-16-30"></a>QUINT  - Quintic easing
</span><span id="__span-16-31"><a id="__codelineno-16-31" name="__codelineno-16-31" href="#__codelineno-16-31"></a>EXPO   - Exponential easing
</span><span id="__span-16-32"><a id="__codelineno-16-32" name="__codelineno-16-32" href="#__codelineno-16-32"></a>CIRC   - Circular easing
</span><span id="__span-16-33"><a id="__codelineno-16-33" name="__codelineno-16-33" href="#__codelineno-16-33"></a>BACK   - Back easing
</span><span id="__span-16-34"><a id="__codelineno-16-34" name="__codelineno-16-34" href="#__codelineno-16-34"></a>ELASTIC - Elastic easing
</span><span id="__span-16-35"><a id="__codelineno-16-35" name="__codelineno-16-35" href="#__codelineno-16-35"></a>BOUNCE - Bounce easing
</span><span id="__span-16-36"><a id="__codelineno-16-36" name="__codelineno-16-36" href="#__codelineno-16-36"></a>
</span><span id="__span-16-37"><a id="__codelineno-16-37" name="__codelineno-16-37" href="#__codelineno-16-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-16-38"><a id="__codelineno-16-38" name="__codelineno-16-38" href="#__codelineno-16-38"></a>
</span><span id="__span-16-39"><a id="__codelineno-16-39" name="__codelineno-16-39" href="#__codelineno-16-39"></a>
</span><span id="__span-16-40"><a id="__codelineno-16-40" name="__codelineno-16-40" href="#__codelineno-16-40"></a>Example: terminaltexteffects print --final-gradient-stops 02b8bd c1f0e3 00ffa0 --final-gradient-steps 12 --print-head-return-speed 1.25 --print-speed 1 --print-head-easing IN_OUT_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="rain">Rain</h2>
<p>Rain characters from the top of the canvas.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/rain_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rain/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rain/#terminaltexteffects.effects.effect_rain.RainConfig">Config</a></p>
<details>
<summary>Rain Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>--rain-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>                    List of colors for the rain drops. Colors are randomly chosen from the list. (default: ('00315C', '004C8F', '0075DB', '3F91D9', '78B9F2', '9AC8F5', 'B8D8F8', 'E3EFFC'))
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>--movement-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>                    Falling speed range of the rain drops. (default: (0.1, 0.2))
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>--rain-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>                    Space separated list of symbols to use for the rain drops. Symbols are randomly chosen from the list. (default: ('o', '.', ',', '*', '|'))
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a>                    (default: ('488bff', 'b2e7de', '57eaf7'))
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-17-13"><a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-17-14"><a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a>--easing (Easing Function)
</span><span id="__span-17-15"><a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a>                    Easing function to use for character movement. (default: in_quart)
</span><span id="__span-17-16"><a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a>
</span><span id="__span-17-17"><a id="__codelineno-17-17" name="__codelineno-17-17" href="#__codelineno-17-17"></a>Easing
</span><span id="__span-17-18"><a id="__codelineno-17-18" name="__codelineno-17-18" href="#__codelineno-17-18"></a>------
</span><span id="__span-17-19"><a id="__codelineno-17-19" name="__codelineno-17-19" href="#__codelineno-17-19"></a>Note: A prefix must be added to the function name.
</span><span id="__span-17-20"><a id="__codelineno-17-20" name="__codelineno-17-20" href="#__codelineno-17-20"></a>
</span><span id="__span-17-21"><a id="__codelineno-17-21" name="__codelineno-17-21" href="#__codelineno-17-21"></a>All easing functions support the following prefixes:
</span><span id="__span-17-22"><a id="__codelineno-17-22" name="__codelineno-17-22" href="#__codelineno-17-22"></a>    IN_  - Ease in
</span><span id="__span-17-23"><a id="__codelineno-17-23" name="__codelineno-17-23" href="#__codelineno-17-23"></a>    OUT_ - Ease out
</span><span id="__span-17-24"><a id="__codelineno-17-24" name="__codelineno-17-24" href="#__codelineno-17-24"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-17-25"><a id="__codelineno-17-25" name="__codelineno-17-25" href="#__codelineno-17-25"></a>
</span><span id="__span-17-26"><a id="__codelineno-17-26" name="__codelineno-17-26" href="#__codelineno-17-26"></a>Easing Functions
</span><span id="__span-17-27"><a id="__codelineno-17-27" name="__codelineno-17-27" href="#__codelineno-17-27"></a>----------------
</span><span id="__span-17-28"><a id="__codelineno-17-28" name="__codelineno-17-28" href="#__codelineno-17-28"></a>SINE   - Sine easing
</span><span id="__span-17-29"><a id="__codelineno-17-29" name="__codelineno-17-29" href="#__codelineno-17-29"></a>QUAD   - Quadratic easing
</span><span id="__span-17-30"><a id="__codelineno-17-30" name="__codelineno-17-30" href="#__codelineno-17-30"></a>CUBIC  - Cubic easing
</span><span id="__span-17-31"><a id="__codelineno-17-31" name="__codelineno-17-31" href="#__codelineno-17-31"></a>QUART  - Quartic easing
</span><span id="__span-17-32"><a id="__codelineno-17-32" name="__codelineno-17-32" href="#__codelineno-17-32"></a>QUINT  - Quintic easing
</span><span id="__span-17-33"><a id="__codelineno-17-33" name="__codelineno-17-33" href="#__codelineno-17-33"></a>EXPO   - Exponential easing
</span><span id="__span-17-34"><a id="__codelineno-17-34" name="__codelineno-17-34" href="#__codelineno-17-34"></a>CIRC   - Circular easing
</span><span id="__span-17-35"><a id="__codelineno-17-35" name="__codelineno-17-35" href="#__codelineno-17-35"></a>BACK   - Back easing
</span><span id="__span-17-36"><a id="__codelineno-17-36" name="__codelineno-17-36" href="#__codelineno-17-36"></a>ELASTIC - Elastic easing
</span><span id="__span-17-37"><a id="__codelineno-17-37" name="__codelineno-17-37" href="#__codelineno-17-37"></a>BOUNCE - Bounce easing
</span><span id="__span-17-38"><a id="__codelineno-17-38" name="__codelineno-17-38" href="#__codelineno-17-38"></a>
</span><span id="__span-17-39"><a id="__codelineno-17-39" name="__codelineno-17-39" href="#__codelineno-17-39"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-17-40"><a id="__codelineno-17-40" name="__codelineno-17-40" href="#__codelineno-17-40"></a>
</span><span id="__span-17-41"><a id="__codelineno-17-41" name="__codelineno-17-41" href="#__codelineno-17-41"></a>Example: terminaltexteffects rain --rain-symbols o . , "*" "|" --rain-colors 00315C 004C8F 0075DB 3F91D9 78B9F2 9AC8F5 B8D8F8 E3EFFC --final-gradient-stops 488bff b2e7de 57eaf7 --final-gradient-steps 12 --movement-speed 0.1-0.2 --easing IN_QUART
</span></code></pre></div>
</details>
<hr>
<h2 id="randomsequence">RandomSequence</h2>
<p>Prints the input data in a random sequence, one character at a time.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/randomsequence_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/randomsequence/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/randomsequence/#terminaltexteffects.effects.effect_random_sequence.RandomSequenceConfig">Config</a></p>
<details>
<summary>RandomSequence Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>                    Color of the characters at spawn. (default: 000000)
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 12)
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a>--speed (float &gt; 0)   Speed of the animation as a percentage of the total number of characters. (default: 0.004)
</span><span id="__span-18-13"><a id="__codelineno-18-13" name="__codelineno-18-13" href="#__codelineno-18-13"></a>
</span><span id="__span-18-14"><a id="__codelineno-18-14" name="__codelineno-18-14" href="#__codelineno-18-14"></a>Example: terminaltexteffects randomsequence --starting-color 000000 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-frames 12 --speed 0.004
</span></code></pre></div>
</details>
<hr>
<h2 id="rings">Rings</h2>
<p>Characters are dispersed and form into spinning rings.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/rings_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rings/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rings/#terminaltexteffects.effects.effect_rings.RingsConfig">Config</a></p>
<details>
<summary>Rings Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>--ring-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>                    Space separated, unquoted, list of colors for the rings. (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-19-6"><a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-19-7"><a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-19-8"><a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-19-9"><a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-19-10"><a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>--ring-gap RING_GAP   Distance between rings as a percent of the smallest canvas dimension. (default: 0.1)
</span><span id="__span-19-11"><a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a>--spin-duration SPIN_DURATION
</span><span id="__span-19-12"><a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a>                    Number of frames for each cycle of the spin phase. (default: 200)
</span><span id="__span-19-13"><a id="__codelineno-19-13" name="__codelineno-19-13" href="#__codelineno-19-13"></a>--spin-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-19-14"><a id="__codelineno-19-14" name="__codelineno-19-14" href="#__codelineno-19-14"></a>                    Range of speeds for the rotation of the rings. The speed is randomly selected from this range for each ring. (default: (0.25, 1.0))
</span><span id="__span-19-15"><a id="__codelineno-19-15" name="__codelineno-19-15" href="#__codelineno-19-15"></a>--disperse-duration DISPERSE_DURATION
</span><span id="__span-19-16"><a id="__codelineno-19-16" name="__codelineno-19-16" href="#__codelineno-19-16"></a>                    Number of frames spent in the dispersed state between spinning cycles. (default: 200)
</span><span id="__span-19-17"><a id="__codelineno-19-17" name="__codelineno-19-17" href="#__codelineno-19-17"></a>--spin-disperse-cycles SPIN_DISPERSE_CYCLES
</span><span id="__span-19-18"><a id="__codelineno-19-18" name="__codelineno-19-18" href="#__codelineno-19-18"></a>                    Number of times the animation will cycles between spinning rings and dispersed characters. (default: 3)
</span><span id="__span-19-19"><a id="__codelineno-19-19" name="__codelineno-19-19" href="#__codelineno-19-19"></a>
</span><span id="__span-19-20"><a id="__codelineno-19-20" name="__codelineno-19-20" href="#__codelineno-19-20"></a>Example: terminaltexteffects rings --ring-colors ab48ff e7b2b2 fffebd --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --ring-gap 0.1 --spin-duration 200 --spin-speed 0.25-1.0 --disperse-duration 200 --spin-disperse-cycles 3
</span></code></pre></div>
</details>
<hr>
<h2 id="scattered">Scattered</h2>
<p>Text is scattered across the canvas and moves into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/scattered_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/scattered/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/scattered/#terminaltexteffects.effects.effect_scattered.ScatteredConfig">Config</a></p>
<details>
<summary>Scattered Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('ff9048', 'ab9dff',
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>                    'bdffea'))
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 12)
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-20-9"><a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-20-10"><a id="__codelineno-20-10" name="__codelineno-20-10" href="#__codelineno-20-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-20-11"><a id="__codelineno-20-11" name="__codelineno-20-11" href="#__codelineno-20-11"></a>                    Movement speed of the characters.  (default: 0.5)
</span><span id="__span-20-12"><a id="__codelineno-20-12" name="__codelineno-20-12" href="#__codelineno-20-12"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-20-13"><a id="__codelineno-20-13" name="__codelineno-20-13" href="#__codelineno-20-13"></a>                    Easing function to use for character movement. (default: in_out_back)
</span><span id="__span-20-14"><a id="__codelineno-20-14" name="__codelineno-20-14" href="#__codelineno-20-14"></a>
</span><span id="__span-20-15"><a id="__codelineno-20-15" name="__codelineno-20-15" href="#__codelineno-20-15"></a>Easing
</span><span id="__span-20-16"><a id="__codelineno-20-16" name="__codelineno-20-16" href="#__codelineno-20-16"></a>------
</span><span id="__span-20-17"><a id="__codelineno-20-17" name="__codelineno-20-17" href="#__codelineno-20-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-20-18"><a id="__codelineno-20-18" name="__codelineno-20-18" href="#__codelineno-20-18"></a>
</span><span id="__span-20-19"><a id="__codelineno-20-19" name="__codelineno-20-19" href="#__codelineno-20-19"></a>All easing functions support the following prefixes:
</span><span id="__span-20-20"><a id="__codelineno-20-20" name="__codelineno-20-20" href="#__codelineno-20-20"></a>    IN_  - Ease in
</span><span id="__span-20-21"><a id="__codelineno-20-21" name="__codelineno-20-21" href="#__codelineno-20-21"></a>    OUT_ - Ease out
</span><span id="__span-20-22"><a id="__codelineno-20-22" name="__codelineno-20-22" href="#__codelineno-20-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-20-23"><a id="__codelineno-20-23" name="__codelineno-20-23" href="#__codelineno-20-23"></a>
</span><span id="__span-20-24"><a id="__codelineno-20-24" name="__codelineno-20-24" href="#__codelineno-20-24"></a>Easing Functions
</span><span id="__span-20-25"><a id="__codelineno-20-25" name="__codelineno-20-25" href="#__codelineno-20-25"></a>----------------
</span><span id="__span-20-26"><a id="__codelineno-20-26" name="__codelineno-20-26" href="#__codelineno-20-26"></a>SINE   - Sine easing
</span><span id="__span-20-27"><a id="__codelineno-20-27" name="__codelineno-20-27" href="#__codelineno-20-27"></a>QUAD   - Quadratic easing
</span><span id="__span-20-28"><a id="__codelineno-20-28" name="__codelineno-20-28" href="#__codelineno-20-28"></a>CUBIC  - Cubic easing
</span><span id="__span-20-29"><a id="__codelineno-20-29" name="__codelineno-20-29" href="#__codelineno-20-29"></a>QUART  - Quartic easing
</span><span id="__span-20-30"><a id="__codelineno-20-30" name="__codelineno-20-30" href="#__codelineno-20-30"></a>QUINT  - Quintic easing
</span><span id="__span-20-31"><a id="__codelineno-20-31" name="__codelineno-20-31" href="#__codelineno-20-31"></a>EXPO   - Exponential easing
</span><span id="__span-20-32"><a id="__codelineno-20-32" name="__codelineno-20-32" href="#__codelineno-20-32"></a>CIRC   - Circular easing
</span><span id="__span-20-33"><a id="__codelineno-20-33" name="__codelineno-20-33" href="#__codelineno-20-33"></a>BACK   - Back easing
</span><span id="__span-20-34"><a id="__codelineno-20-34" name="__codelineno-20-34" href="#__codelineno-20-34"></a>ELASTIC - Elastic easing
</span><span id="__span-20-35"><a id="__codelineno-20-35" name="__codelineno-20-35" href="#__codelineno-20-35"></a>BOUNCE - Bounce easing
</span><span id="__span-20-36"><a id="__codelineno-20-36" name="__codelineno-20-36" href="#__codelineno-20-36"></a>
</span><span id="__span-20-37"><a id="__codelineno-20-37" name="__codelineno-20-37" href="#__codelineno-20-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-20-38"><a id="__codelineno-20-38" name="__codelineno-20-38" href="#__codelineno-20-38"></a>
</span><span id="__span-20-39"><a id="__codelineno-20-39" name="__codelineno-20-39" href="#__codelineno-20-39"></a>Example: terminaltexteffects scattered --final-gradient-stops ff9048 ab9dff bdffea --final-gradient-steps 12 --final-gradient-frames 12 --movement-speed 0.5 --movement-easing IN_OUT_BACK
</span></code></pre></div>
</details>
<hr>
<h2 id="slice">Slice</h2>
<p>Slices the input in half and slides it into place from opposite directions.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/slice_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slice/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slice/#terminaltexteffects.effects.effect_slice.SliceConfig">Config</a></p>
<details>
<summary>Slice Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>                    (default: (Color(8A008A), Color(00D1FF), Color(FFFFFF)))
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-21-8"><a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a>--slice-direction {vertical,horizontal,diagonal}
</span><span id="__span-21-9"><a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a>                    Direction of the slice. (default: vertical)
</span><span id="__span-21-10"><a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-21-11"><a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a>                    Movement speed of the characters. (default: 0.15)
</span><span id="__span-21-12"><a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-21-13"><a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a>                    Easing function to use for character movement. (default: in_out_expo)
</span><span id="__span-21-14"><a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a>
</span><span id="__span-21-15"><a id="__codelineno-21-15" name="__codelineno-21-15" href="#__codelineno-21-15"></a>Easing
</span><span id="__span-21-16"><a id="__codelineno-21-16" name="__codelineno-21-16" href="#__codelineno-21-16"></a>------
</span><span id="__span-21-17"><a id="__codelineno-21-17" name="__codelineno-21-17" href="#__codelineno-21-17"></a>Note: A prefix must be added to the function name (except LINEAR).
</span><span id="__span-21-18"><a id="__codelineno-21-18" name="__codelineno-21-18" href="#__codelineno-21-18"></a>
</span><span id="__span-21-19"><a id="__codelineno-21-19" name="__codelineno-21-19" href="#__codelineno-21-19"></a>All easing functions support the following prefixes:
</span><span id="__span-21-20"><a id="__codelineno-21-20" name="__codelineno-21-20" href="#__codelineno-21-20"></a>    IN_  - Ease in
</span><span id="__span-21-21"><a id="__codelineno-21-21" name="__codelineno-21-21" href="#__codelineno-21-21"></a>    OUT_ - Ease out
</span><span id="__span-21-22"><a id="__codelineno-21-22" name="__codelineno-21-22" href="#__codelineno-21-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-21-23"><a id="__codelineno-21-23" name="__codelineno-21-23" href="#__codelineno-21-23"></a>
</span><span id="__span-21-24"><a id="__codelineno-21-24" name="__codelineno-21-24" href="#__codelineno-21-24"></a>Easing Functions
</span><span id="__span-21-25"><a id="__codelineno-21-25" name="__codelineno-21-25" href="#__codelineno-21-25"></a>----------------
</span><span id="__span-21-26"><a id="__codelineno-21-26" name="__codelineno-21-26" href="#__codelineno-21-26"></a>LINEAR - Linear easing
</span><span id="__span-21-27"><a id="__codelineno-21-27" name="__codelineno-21-27" href="#__codelineno-21-27"></a>SINE   - Sine easing
</span><span id="__span-21-28"><a id="__codelineno-21-28" name="__codelineno-21-28" href="#__codelineno-21-28"></a>QUAD   - Quadratic easing
</span><span id="__span-21-29"><a id="__codelineno-21-29" name="__codelineno-21-29" href="#__codelineno-21-29"></a>CUBIC  - Cubic easing
</span><span id="__span-21-30"><a id="__codelineno-21-30" name="__codelineno-21-30" href="#__codelineno-21-30"></a>QUART  - Quartic easing
</span><span id="__span-21-31"><a id="__codelineno-21-31" name="__codelineno-21-31" href="#__codelineno-21-31"></a>QUINT  - Quintic easing
</span><span id="__span-21-32"><a id="__codelineno-21-32" name="__codelineno-21-32" href="#__codelineno-21-32"></a>EXPO   - Exponential easing
</span><span id="__span-21-33"><a id="__codelineno-21-33" name="__codelineno-21-33" href="#__codelineno-21-33"></a>CIRC   - Circular easing
</span><span id="__span-21-34"><a id="__codelineno-21-34" name="__codelineno-21-34" href="#__codelineno-21-34"></a>BACK   - Back easing
</span><span id="__span-21-35"><a id="__codelineno-21-35" name="__codelineno-21-35" href="#__codelineno-21-35"></a>ELASTIC - Elastic easing
</span><span id="__span-21-36"><a id="__codelineno-21-36" name="__codelineno-21-36" href="#__codelineno-21-36"></a>BOUNCE - Bounce easing
</span><span id="__span-21-37"><a id="__codelineno-21-37" name="__codelineno-21-37" href="#__codelineno-21-37"></a>
</span><span id="__span-21-38"><a id="__codelineno-21-38" name="__codelineno-21-38" href="#__codelineno-21-38"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-21-39"><a id="__codelineno-21-39" name="__codelineno-21-39" href="#__codelineno-21-39"></a>
</span><span id="__span-21-40"><a id="__codelineno-21-40" name="__codelineno-21-40" href="#__codelineno-21-40"></a>
</span><span id="__span-21-41"><a id="__codelineno-21-41" name="__codelineno-21-41" href="#__codelineno-21-41"></a>Example: terminaltexteffects slice --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12
</span><span id="__span-21-42"><a id="__codelineno-21-42" name="__codelineno-21-42" href="#__codelineno-21-42"></a>--slice-direction vertical--movement-speed 0.15 --movement-easing IN_OUT_EXPO
</span></code></pre></div>
</details>
<hr>
<h2 id="slide">Slide</h2>
<p>Slide characters into view from outside the terminal.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/slide_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slide/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slide/#terminaltexteffects.effects.effect_slide.SlideConfig">Config</a></p>
<details>
<summary>Slide Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>--movement-speed (float &gt; 0)
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>                    Speed of the characters. (default: 0.5)
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>--grouping {row,column,diagonal}
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>                    Direction to group characters. (default: row)
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('833ab4', 'fd1d1d',
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>                    'fcb045'))
</span><span id="__span-22-8"><a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-22-9"><a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-22-10"><a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-22-11"><a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 10)
</span><span id="__span-22-12"><a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a>--final-gradient-direction FINAL_GRADIENT_DIRECTION
</span><span id="__span-22-13"><a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a>                    Direction of the gradient (vertical, horizontal, diagonal, center). (default: Direction.VERTICAL)
</span><span id="__span-22-14"><a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a>--gap (int &gt;= 0)      Number of frames to wait before adding the next group of characters. Increasing this value creates a more staggered effect. (default: 3)
</span><span id="__span-22-15"><a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a>--reverse-direction   Reverse the direction of the characters. (default: False)
</span><span id="__span-22-16"><a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a>--merge               Merge the character groups originating from either side of the terminal. (--reverse-direction is ignored when merging) (default: False)
</span><span id="__span-22-17"><a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a>--movement-easing (Easing Function)
</span><span id="__span-22-18"><a id="__codelineno-22-18" name="__codelineno-22-18" href="#__codelineno-22-18"></a>                    Easing function to use for character movement. (default: in_out_quad)
</span><span id="__span-22-19"><a id="__codelineno-22-19" name="__codelineno-22-19" href="#__codelineno-22-19"></a>
</span><span id="__span-22-20"><a id="__codelineno-22-20" name="__codelineno-22-20" href="#__codelineno-22-20"></a>Easing
</span><span id="__span-22-21"><a id="__codelineno-22-21" name="__codelineno-22-21" href="#__codelineno-22-21"></a>------
</span><span id="__span-22-22"><a id="__codelineno-22-22" name="__codelineno-22-22" href="#__codelineno-22-22"></a>Note: A prefix must be added to the function name.
</span><span id="__span-22-23"><a id="__codelineno-22-23" name="__codelineno-22-23" href="#__codelineno-22-23"></a>
</span><span id="__span-22-24"><a id="__codelineno-22-24" name="__codelineno-22-24" href="#__codelineno-22-24"></a>All easing functions support the following prefixes:
</span><span id="__span-22-25"><a id="__codelineno-22-25" name="__codelineno-22-25" href="#__codelineno-22-25"></a>    IN_  - Ease in
</span><span id="__span-22-26"><a id="__codelineno-22-26" name="__codelineno-22-26" href="#__codelineno-22-26"></a>    OUT_ - Ease out
</span><span id="__span-22-27"><a id="__codelineno-22-27" name="__codelineno-22-27" href="#__codelineno-22-27"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-22-28"><a id="__codelineno-22-28" name="__codelineno-22-28" href="#__codelineno-22-28"></a>
</span><span id="__span-22-29"><a id="__codelineno-22-29" name="__codelineno-22-29" href="#__codelineno-22-29"></a>Easing Functions
</span><span id="__span-22-30"><a id="__codelineno-22-30" name="__codelineno-22-30" href="#__codelineno-22-30"></a>----------------
</span><span id="__span-22-31"><a id="__codelineno-22-31" name="__codelineno-22-31" href="#__codelineno-22-31"></a>SINE   - Sine easing
</span><span id="__span-22-32"><a id="__codelineno-22-32" name="__codelineno-22-32" href="#__codelineno-22-32"></a>QUAD   - Quadratic easing
</span><span id="__span-22-33"><a id="__codelineno-22-33" name="__codelineno-22-33" href="#__codelineno-22-33"></a>CUBIC  - Cubic easing
</span><span id="__span-22-34"><a id="__codelineno-22-34" name="__codelineno-22-34" href="#__codelineno-22-34"></a>QUART  - Quartic easing
</span><span id="__span-22-35"><a id="__codelineno-22-35" name="__codelineno-22-35" href="#__codelineno-22-35"></a>QUINT  - Quintic easing
</span><span id="__span-22-36"><a id="__codelineno-22-36" name="__codelineno-22-36" href="#__codelineno-22-36"></a>EXPO   - Exponential easing
</span><span id="__span-22-37"><a id="__codelineno-22-37" name="__codelineno-22-37" href="#__codelineno-22-37"></a>CIRC   - Circular easing
</span><span id="__span-22-38"><a id="__codelineno-22-38" name="__codelineno-22-38" href="#__codelineno-22-38"></a>BACK   - Back easing
</span><span id="__span-22-39"><a id="__codelineno-22-39" name="__codelineno-22-39" href="#__codelineno-22-39"></a>ELASTIC - Elastic easing
</span><span id="__span-22-40"><a id="__codelineno-22-40" name="__codelineno-22-40" href="#__codelineno-22-40"></a>BOUNCE - Bounce easing
</span><span id="__span-22-41"><a id="__codelineno-22-41" name="__codelineno-22-41" href="#__codelineno-22-41"></a>
</span><span id="__span-22-42"><a id="__codelineno-22-42" name="__codelineno-22-42" href="#__codelineno-22-42"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-22-43"><a id="__codelineno-22-43" name="__codelineno-22-43" href="#__codelineno-22-43"></a>
</span><span id="__span-22-44"><a id="__codelineno-22-44" name="__codelineno-22-44" href="#__codelineno-22-44"></a>Example: terminaltexteffects slide --movement-speed 0.5 --grouping row --final-gradient-stops 833ab4 fd1d1d fcb045 --final-gradient-steps 12 --final-gradient-frames 10 --final-gradient-direction vertical --gap 3 --reverse-direction --merge --movement-easing OUT_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="spotlights">Spotlights</h2>
<p>Spotlights search the text area, illuminating characters, before converging in the center and expanding.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/spotlights_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spotlights/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spotlights/#terminaltexteffects.effects.effect_spotlights.SpotlightsConfig">Config</a></p>
<details>
<summary>Spotlights Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>--beam-width-ratio (float &gt; 0)
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a>                    Width of the beam of light as min(width, height) // n of the input text. (default: 2.0)
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a>--beam-falloff (float &gt;= 0)
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a>                    Distance from the edge of the beam where the brightness begins to fall off, as a percentage of total beam width. (default: 0.3)
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a>--search-duration (int &gt; 0)
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a>                    Duration of the search phase, in frames, before the spotlights converge in the center. (default: 750)
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a>--search-speed-range (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-23-15"><a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a>                    Range of speeds for the spotlights during the search phase. The speed is a random value between the two provided values. (default: (0.25, 0.5))
</span><span id="__span-23-16"><a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a>--spotlight-count (int &gt; 0)
</span><span id="__span-23-17"><a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a>                    Number of spotlights to use. (default: 3)
</span><span id="__span-23-18"><a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a>
</span><span id="__span-23-19"><a id="__codelineno-23-19" name="__codelineno-23-19" href="#__codelineno-23-19"></a>Easing
</span><span id="__span-23-20"><a id="__codelineno-23-20" name="__codelineno-23-20" href="#__codelineno-23-20"></a>------
</span><span id="__span-23-21"><a id="__codelineno-23-21" name="__codelineno-23-21" href="#__codelineno-23-21"></a>Note: A prefix must be added to the function name.
</span><span id="__span-23-22"><a id="__codelineno-23-22" name="__codelineno-23-22" href="#__codelineno-23-22"></a>
</span><span id="__span-23-23"><a id="__codelineno-23-23" name="__codelineno-23-23" href="#__codelineno-23-23"></a>All easing functions support the following prefixes:
</span><span id="__span-23-24"><a id="__codelineno-23-24" name="__codelineno-23-24" href="#__codelineno-23-24"></a>    IN_  - Ease in
</span><span id="__span-23-25"><a id="__codelineno-23-25" name="__codelineno-23-25" href="#__codelineno-23-25"></a>    OUT_ - Ease out
</span><span id="__span-23-26"><a id="__codelineno-23-26" name="__codelineno-23-26" href="#__codelineno-23-26"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-23-27"><a id="__codelineno-23-27" name="__codelineno-23-27" href="#__codelineno-23-27"></a>
</span><span id="__span-23-28"><a id="__codelineno-23-28" name="__codelineno-23-28" href="#__codelineno-23-28"></a>Easing Functions
</span><span id="__span-23-29"><a id="__codelineno-23-29" name="__codelineno-23-29" href="#__codelineno-23-29"></a>----------------
</span><span id="__span-23-30"><a id="__codelineno-23-30" name="__codelineno-23-30" href="#__codelineno-23-30"></a>SINE   - Sine easing
</span><span id="__span-23-31"><a id="__codelineno-23-31" name="__codelineno-23-31" href="#__codelineno-23-31"></a>QUAD   - Quadratic easing
</span><span id="__span-23-32"><a id="__codelineno-23-32" name="__codelineno-23-32" href="#__codelineno-23-32"></a>CUBIC  - Cubic easing
</span><span id="__span-23-33"><a id="__codelineno-23-33" name="__codelineno-23-33" href="#__codelineno-23-33"></a>QUART  - Quartic easing
</span><span id="__span-23-34"><a id="__codelineno-23-34" name="__codelineno-23-34" href="#__codelineno-23-34"></a>QUINT  - Quintic easing
</span><span id="__span-23-35"><a id="__codelineno-23-35" name="__codelineno-23-35" href="#__codelineno-23-35"></a>EXPO   - Exponential easing
</span><span id="__span-23-36"><a id="__codelineno-23-36" name="__codelineno-23-36" href="#__codelineno-23-36"></a>CIRC   - Circular easing
</span><span id="__span-23-37"><a id="__codelineno-23-37" name="__codelineno-23-37" href="#__codelineno-23-37"></a>BACK   - Back easing
</span><span id="__span-23-38"><a id="__codelineno-23-38" name="__codelineno-23-38" href="#__codelineno-23-38"></a>ELASTIC - Elastic easing
</span><span id="__span-23-39"><a id="__codelineno-23-39" name="__codelineno-23-39" href="#__codelineno-23-39"></a>BOUNCE - Bounce easing
</span><span id="__span-23-40"><a id="__codelineno-23-40" name="__codelineno-23-40" href="#__codelineno-23-40"></a>
</span><span id="__span-23-41"><a id="__codelineno-23-41" name="__codelineno-23-41" href="#__codelineno-23-41"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-23-42"><a id="__codelineno-23-42" name="__codelineno-23-42" href="#__codelineno-23-42"></a>
</span><span id="__span-23-43"><a id="__codelineno-23-43" name="__codelineno-23-43" href="#__codelineno-23-43"></a>Example: terminaltexteffects spotlights --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --beam-width-ratio 2.0 --beam-falloff 0.3 --search-duration 750 --search-speed-range 0.25-0.5 --spotlight-count 3
</span></code></pre></div>
</details>
<hr>
<h2 id="spray">Spray</h2>
<p>Sprays the characters from a single point.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/spray_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spray/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spray/#terminaltexteffects.effects.effect_spray.SprayConfig">Config</a></p>
<details>
<summary>Spray Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>--spray-position {n,ne,e,se,s,sw,w,nw,center}
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>                    Position for the spray origin. (default: e)
</span><span id="__span-24-10"><a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>--spray-volume (float &gt; 0)
</span><span id="__span-24-11"><a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>                    Number of characters to spray per tick as a percent of the total number of characters. (default: 0.005)
</span><span id="__span-24-12"><a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>--movement-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-24-13"><a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>                    Movement speed of the characters. (default: (0.4, 1.0))
</span><span id="__span-24-14"><a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-24-15"><a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a>                    Easing function to use for character movement. (default: out_expo)
</span><span id="__span-24-16"><a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>
</span><span id="__span-24-17"><a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a>Easing
</span><span id="__span-24-18"><a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>------
</span><span id="__span-24-19"><a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a>Note: A prefix must be added to the function name.
</span><span id="__span-24-20"><a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a>
</span><span id="__span-24-21"><a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a>All easing functions support the following prefixes:
</span><span id="__span-24-22"><a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a>    IN_  - Ease in
</span><span id="__span-24-23"><a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a>    OUT_ - Ease out
</span><span id="__span-24-24"><a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-24-25"><a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a>
</span><span id="__span-24-26"><a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a>Easing Functions
</span><span id="__span-24-27"><a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a>----------------
</span><span id="__span-24-28"><a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a>SINE   - Sine easing
</span><span id="__span-24-29"><a id="__codelineno-24-29" name="__codelineno-24-29" href="#__codelineno-24-29"></a>QUAD   - Quadratic easing
</span><span id="__span-24-30"><a id="__codelineno-24-30" name="__codelineno-24-30" href="#__codelineno-24-30"></a>CUBIC  - Cubic easing
</span><span id="__span-24-31"><a id="__codelineno-24-31" name="__codelineno-24-31" href="#__codelineno-24-31"></a>QUART  - Quartic easing
</span><span id="__span-24-32"><a id="__codelineno-24-32" name="__codelineno-24-32" href="#__codelineno-24-32"></a>QUINT  - Quintic easing
</span><span id="__span-24-33"><a id="__codelineno-24-33" name="__codelineno-24-33" href="#__codelineno-24-33"></a>EXPO   - Exponential easing
</span><span id="__span-24-34"><a id="__codelineno-24-34" name="__codelineno-24-34" href="#__codelineno-24-34"></a>CIRC   - Circular easing
</span><span id="__span-24-35"><a id="__codelineno-24-35" name="__codelineno-24-35" href="#__codelineno-24-35"></a>BACK   - Back easing
</span><span id="__span-24-36"><a id="__codelineno-24-36" name="__codelineno-24-36" href="#__codelineno-24-36"></a>ELASTIC - Elastic easing
</span><span id="__span-24-37"><a id="__codelineno-24-37" name="__codelineno-24-37" href="#__codelineno-24-37"></a>BOUNCE - Bounce easing
</span><span id="__span-24-38"><a id="__codelineno-24-38" name="__codelineno-24-38" href="#__codelineno-24-38"></a>
</span><span id="__span-24-39"><a id="__codelineno-24-39" name="__codelineno-24-39" href="#__codelineno-24-39"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-24-40"><a id="__codelineno-24-40" name="__codelineno-24-40" href="#__codelineno-24-40"></a>
</span><span id="__span-24-41"><a id="__codelineno-24-41" name="__codelineno-24-41" href="#__codelineno-24-41"></a>Example: terminaltexteffects spray --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --spray-position e --spray-volume 0.005 --movement-speed 0.4-1.0 --movement-easing OUT_EXPO
</span></code></pre></div>
</details>
<hr>
<h2 id="swarm">Swarm</h2>
<p>Characters are grouped into swarms and move around the terminal before settling into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/swarm_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/swarm/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/swarm/#terminaltexteffects.effects.effect_swarm.SwarmConfig">Config</a></p>
<details>
<summary>Swarm Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>--base-color (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>                    Space separated, unquoted, list of colors for the swarms (default: ('31a0d4',))
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>--flash-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>                    Color for the character flash. Characters flash when moving. (default: f2ea79)
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>                    (default: ('31b900', 'f0ff65'))
</span><span id="__span-25-8"><a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-25-9"><a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-25-10"><a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-25-11"><a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a>                    Direction of the final gradient. (default: Direction.HORIZONTAL)
</span><span id="__span-25-12"><a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a>--swarm-size (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-25-13"><a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a>                    Percent of total characters in each swarm. (default: 0.1)
</span><span id="__span-25-14"><a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a>--swarm-coordination (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-25-15"><a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a>                    Percent of characters in a swarm that move as a group. (default: 0.8)
</span><span id="__span-25-16"><a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a>--swarm-area-count (hyphen separated int range e.g. '1-10')
</span><span id="__span-25-17"><a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a>                    Range of the number of areas where characters will swarm. (default: (2, 4))
</span><span id="__span-25-18"><a id="__codelineno-25-18" name="__codelineno-25-18" href="#__codelineno-25-18"></a>
</span><span id="__span-25-19"><a id="__codelineno-25-19" name="__codelineno-25-19" href="#__codelineno-25-19"></a>Example: terminaltexteffects swarm --base-color 31a0d4 --flash-color f2ea79 --final-gradient-stops 31b900 f0ff65 --final-gradient-steps 12 --swarm-size 0.1 --swarm-coordination 0.80 --swarm-area-count 2-4
</span></code></pre></div>
</details>
<hr>
<h2 id="synthgrid">SynthGrid</h2>
<p>Create a grid which fills with characters dissolving into the final text.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/synthgrid_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/synthgrid/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/synthgrid/#terminaltexteffects.effects.effect_synthgrid.SynthGridConfig">Config</a></p>
<details>
<summary>SynthGrid Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>--grid-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>                    Space separated, unquoted, list of colors for the grid gradient. (default: ('CC00CC', 'ffffff'))
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>--grid-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>--grid-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-26-6"><a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>                    Direction of the gradient for the grid color. (default: Direction.DIAGONAL)
</span><span id="__span-26-7"><a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>--text-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-26-8"><a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>                    Space separated, unquoted, list of colors for the text gradient. (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-26-9"><a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a>--text-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-26-10"><a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-26-11"><a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a>--text-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-26-12"><a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a>                    Direction of the gradient for the text color. (default: Direction.VERTICAL)
</span><span id="__span-26-13"><a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a>--grid-row-symbol (ASCII/UTF-8 character)
</span><span id="__span-26-14"><a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a>                    Symbol to use for grid row lines. (default: ─)
</span><span id="__span-26-15"><a id="__codelineno-26-15" name="__codelineno-26-15" href="#__codelineno-26-15"></a>--grid-column-symbol (ASCII/UTF-8 character)
</span><span id="__span-26-16"><a id="__codelineno-26-16" name="__codelineno-26-16" href="#__codelineno-26-16"></a>                    Symbol to use for grid column lines. (default: │)
</span><span id="__span-26-17"><a id="__codelineno-26-17" name="__codelineno-26-17" href="#__codelineno-26-17"></a>--text-generation-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-26-18"><a id="__codelineno-26-18" name="__codelineno-26-18" href="#__codelineno-26-18"></a>                    Space separated, unquoted, list of characters for the text generation animation. (default: ('░', '▒', '▓'))
</span><span id="__span-26-19"><a id="__codelineno-26-19" name="__codelineno-26-19" href="#__codelineno-26-19"></a>--max-active-blocks (float &gt; 0)
</span><span id="__span-26-20"><a id="__codelineno-26-20" name="__codelineno-26-20" href="#__codelineno-26-20"></a>                    Maximum percentage of blocks to have active at any given time. For example, if set to 0.1, 10 percent of the blocks will be active at any given time. (default: 0.1)
</span><span id="__span-26-21"><a id="__codelineno-26-21" name="__codelineno-26-21" href="#__codelineno-26-21"></a>
</span><span id="__span-26-22"><a id="__codelineno-26-22" name="__codelineno-26-22" href="#__codelineno-26-22"></a>Example: terminaltexteffects synthgrid --grid-gradient-stops CC00CC ffffff --grid-gradient-steps 12 --text-gradient-stops 8A008A 00D1FF FFFFFF --text-gradient-steps 12 --grid-row-symbol ─ --grid-column-symbol "│" --text-generation-symbols ░ ▒ ▓ --max-active-blocks 0.1
</span></code></pre></div>
</details>
<hr>
<h2 id="unstable">Unstable</h2>
<p>Spawns characters jumbled, explodes them to the edge of the canvas, then reassembles them.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/unstable_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/unstable/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/unstable/#terminaltexteffects.effects.effect_unstable.UnstableConfig">Config</a></p>
<details>
<summary>Unstable Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>--unstable-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>                        Color transitioned to as the characters become unstable. (default: ff9200)
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>                        Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>                        (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>                        Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-27-9"><a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>                        Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-27-10"><a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>--explosion-ease EXPLOSION_EASE
</span><span id="__span-27-11"><a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>                        Easing function to use for character movement during the explosion. (default: out_expo)
</span><span id="__span-27-12"><a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>--explosion-speed (float &gt; 0)
</span><span id="__span-27-13"><a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>                        Speed of characters during explosion. (default: 0.75)
</span><span id="__span-27-14"><a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>--reassembly-ease REASSEMBLY_EASE
</span><span id="__span-27-15"><a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>                        Easing function to use for character reassembly. (default: out_expo)
</span><span id="__span-27-16"><a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a>--reassembly-speed (float &gt; 0)
</span><span id="__span-27-17"><a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a>                        Speed of characters during reassembly. (default: 0.75)
</span><span id="__span-27-18"><a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a>
</span><span id="__span-27-19"><a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a>    Easing
</span><span id="__span-27-20"><a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a>    ------
</span><span id="__span-27-21"><a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a>    Note: A prefix must be added to the function name.
</span><span id="__span-27-22"><a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a>
</span><span id="__span-27-23"><a id="__codelineno-27-23" name="__codelineno-27-23" href="#__codelineno-27-23"></a>    All easing functions support the following prefixes:
</span><span id="__span-27-24"><a id="__codelineno-27-24" name="__codelineno-27-24" href="#__codelineno-27-24"></a>        IN_  - Ease in
</span><span id="__span-27-25"><a id="__codelineno-27-25" name="__codelineno-27-25" href="#__codelineno-27-25"></a>        OUT_ - Ease out
</span><span id="__span-27-26"><a id="__codelineno-27-26" name="__codelineno-27-26" href="#__codelineno-27-26"></a>        IN_OUT_ - Ease in and out
</span><span id="__span-27-27"><a id="__codelineno-27-27" name="__codelineno-27-27" href="#__codelineno-27-27"></a>
</span><span id="__span-27-28"><a id="__codelineno-27-28" name="__codelineno-27-28" href="#__codelineno-27-28"></a>    Easing Functions
</span><span id="__span-27-29"><a id="__codelineno-27-29" name="__codelineno-27-29" href="#__codelineno-27-29"></a>    ----------------
</span><span id="__span-27-30"><a id="__codelineno-27-30" name="__codelineno-27-30" href="#__codelineno-27-30"></a>    SINE   - Sine easing
</span><span id="__span-27-31"><a id="__codelineno-27-31" name="__codelineno-27-31" href="#__codelineno-27-31"></a>    QUAD   - Quadratic easing
</span><span id="__span-27-32"><a id="__codelineno-27-32" name="__codelineno-27-32" href="#__codelineno-27-32"></a>    CUBIC  - Cubic easing
</span><span id="__span-27-33"><a id="__codelineno-27-33" name="__codelineno-27-33" href="#__codelineno-27-33"></a>    QUART  - Quartic easing
</span><span id="__span-27-34"><a id="__codelineno-27-34" name="__codelineno-27-34" href="#__codelineno-27-34"></a>    QUINT  - Quintic easing
</span><span id="__span-27-35"><a id="__codelineno-27-35" name="__codelineno-27-35" href="#__codelineno-27-35"></a>    EXPO   - Exponential easing
</span><span id="__span-27-36"><a id="__codelineno-27-36" name="__codelineno-27-36" href="#__codelineno-27-36"></a>    CIRC   - Circular easing
</span><span id="__span-27-37"><a id="__codelineno-27-37" name="__codelineno-27-37" href="#__codelineno-27-37"></a>    BACK   - Back easing
</span><span id="__span-27-38"><a id="__codelineno-27-38" name="__codelineno-27-38" href="#__codelineno-27-38"></a>    ELASTIC - Elastic easing
</span><span id="__span-27-39"><a id="__codelineno-27-39" name="__codelineno-27-39" href="#__codelineno-27-39"></a>    BOUNCE - Bounce easing
</span><span id="__span-27-40"><a id="__codelineno-27-40" name="__codelineno-27-40" href="#__codelineno-27-40"></a>
</span><span id="__span-27-41"><a id="__codelineno-27-41" name="__codelineno-27-41" href="#__codelineno-27-41"></a>    Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-27-42"><a id="__codelineno-27-42" name="__codelineno-27-42" href="#__codelineno-27-42"></a>
</span><span id="__span-27-43"><a id="__codelineno-27-43" name="__codelineno-27-43" href="#__codelineno-27-43"></a>
</span><span id="__span-27-44"><a id="__codelineno-27-44" name="__codelineno-27-44" href="#__codelineno-27-44"></a>    Example: terminaltexteffects unstable --unstable-color ff9200 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --explosion-ease OUT_EXPO --explosion-speed 0.75 --reassembly-ease OUT_EXPO --reassembly-speed 0.75&lt;/details&gt;
</span></code></pre></div>
</details>
<hr>
<h2 id="vhstape">VHSTape</h2>
<p>Lines of characters glitch left and right and lose detail like an old VHS tape.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/vhstape_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/vhstape/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/vhstape/#terminaltexteffects.effects.effect_vhstape.VHSTapeConfig">Config</a></p>
<details>
<summary>VHSTape Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>--glitch-line-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>                    Space separated, unquoted, list of colors for the characters when a single line is glitching. Colors are applied in order as an animation. (default: ('ffffff', 'ff0000', '00ff00',
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>                    '0000ff', 'ffffff'))
</span><span id="__span-28-11"><a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a>--glitch-wave-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-12"><a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a>                    Space separated, unquoted, list of colors for the characters in lines that are part of the glitch wave. Colors are applied in order as an animation. (default: ('ffffff', 'ff0000',
</span><span id="__span-28-13"><a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a>                    '00ff00', '0000ff', 'ffffff'))
</span><span id="__span-28-14"><a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>--noise-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-15"><a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a>                    Space separated, unquoted, list of colors for the characters during the noise phase. (default: ('1e1e1f', '3c3b3d', '6d6c70', 'a2a1a6', 'cbc9cf', 'ffffff'))
</span><span id="__span-28-16"><a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>--glitch-line-chance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-28-17"><a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a>                    Chance that a line will glitch on any given frame. (default: 0.05)
</span><span id="__span-28-18"><a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a>--noise-chance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-28-19"><a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a>                    Chance that all characters will experience noise on any given frame. (default: 0.004)
</span><span id="__span-28-20"><a id="__codelineno-28-20" name="__codelineno-28-20" href="#__codelineno-28-20"></a>--total-glitch-time (int &gt; 0)
</span><span id="__span-28-21"><a id="__codelineno-28-21" name="__codelineno-28-21" href="#__codelineno-28-21"></a>                    Total time, frames, that the glitching phase will last. (default: 1000)
</span><span id="__span-28-22"><a id="__codelineno-28-22" name="__codelineno-28-22" href="#__codelineno-28-22"></a>
</span><span id="__span-28-23"><a id="__codelineno-28-23" name="__codelineno-28-23" href="#__codelineno-28-23"></a>Example: terminaltexteffects vhstape --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --glitch-line-colors ffffff ff0000 00ff00 0000ff ffffff --glitch-wave-colors ffffff ff0000 00ff00 0000ff ffffff --noise-colors 1e1e1f 3c3b3d 6d6c70 a2a1a6 cbc9cf ffffff --glitch-line-chance 0.05 --noise-chance 0.004 --total-glitch-time 1000
</span></code></pre></div>
</details>
<hr>
<h2 id="waves">Waves</h2>
<p>Waves travel across the terminal leaving behind the characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/waves_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/waves/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/waves/#terminaltexteffects.effects.effect_waves.WavesConfig">Config</a></p>
<details>
<summary>Waves Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>--wave-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>                    Symbols to use for the wave animation. Multi-character strings will be used in sequence to create an animation. (default: ('▁', '▂', '▃', '▄', '▅', '▆', '▇', '█', '▇', '▆', '▅', '▄',
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>                    '▃', '▂', '▁'))
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>--wave-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>                    (default: (Color(#f0ff65), Color(#ffb102), Color(#31a0d4), Color(#ffb102), Color(#f0ff65)))
</span><span id="__span-29-7"><a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>--wave-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-29-8"><a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (6,))
</span><span id="__span-29-9"><a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-29-10"><a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-29-11"><a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>                    (default: (Color(#ffb102), Color(#31a0d4), Color(#f0ff65)))
</span><span id="__span-29-12"><a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-29-13"><a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-29-14"><a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-29-15"><a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-29-16"><a id="__codelineno-29-16" name="__codelineno-29-16" href="#__codelineno-29-16"></a>--wave-count WAVE_COUNT
</span><span id="__span-29-17"><a id="__codelineno-29-17" name="__codelineno-29-17" href="#__codelineno-29-17"></a>                    Number of waves to generate. n &gt; 0. (default: 7)
</span><span id="__span-29-18"><a id="__codelineno-29-18" name="__codelineno-29-18" href="#__codelineno-29-18"></a>--wave-length (int &gt; 0)
</span><span id="__span-29-19"><a id="__codelineno-29-19" name="__codelineno-29-19" href="#__codelineno-29-19"></a>                    The number of frames for each step of the wave. Higher wave-lengths will create a slower wave. (default: 2)
</span><span id="__span-29-20"><a id="__codelineno-29-20" name="__codelineno-29-20" href="#__codelineno-29-20"></a>--wave-direction {column_left_to_right,column_right_to_left,row_top_to_bottom,row_bottom_to_top,center_to_outside,outside_to_center}
</span><span id="__span-29-21"><a id="__codelineno-29-21" name="__codelineno-29-21" href="#__codelineno-29-21"></a>                    Direction of the wave. (default: column_left_to_right)
</span><span id="__span-29-22"><a id="__codelineno-29-22" name="__codelineno-29-22" href="#__codelineno-29-22"></a>--wave-easing WAVE_EASING
</span><span id="__span-29-23"><a id="__codelineno-29-23" name="__codelineno-29-23" href="#__codelineno-29-23"></a>                    Easing function to use for wave travel. (default: in_out_sine)
</span><span id="__span-29-24"><a id="__codelineno-29-24" name="__codelineno-29-24" href="#__codelineno-29-24"></a>
</span><span id="__span-29-25"><a id="__codelineno-29-25" name="__codelineno-29-25" href="#__codelineno-29-25"></a>Easing
</span><span id="__span-29-26"><a id="__codelineno-29-26" name="__codelineno-29-26" href="#__codelineno-29-26"></a>------
</span><span id="__span-29-27"><a id="__codelineno-29-27" name="__codelineno-29-27" href="#__codelineno-29-27"></a>Note: A prefix must be added to the function name (except LINEAR).
</span><span id="__span-29-28"><a id="__codelineno-29-28" name="__codelineno-29-28" href="#__codelineno-29-28"></a>
</span><span id="__span-29-29"><a id="__codelineno-29-29" name="__codelineno-29-29" href="#__codelineno-29-29"></a>All easing functions support the following prefixes:
</span><span id="__span-29-30"><a id="__codelineno-29-30" name="__codelineno-29-30" href="#__codelineno-29-30"></a>    IN_  - Ease in
</span><span id="__span-29-31"><a id="__codelineno-29-31" name="__codelineno-29-31" href="#__codelineno-29-31"></a>    OUT_ - Ease out
</span><span id="__span-29-32"><a id="__codelineno-29-32" name="__codelineno-29-32" href="#__codelineno-29-32"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-29-33"><a id="__codelineno-29-33" name="__codelineno-29-33" href="#__codelineno-29-33"></a>
</span><span id="__span-29-34"><a id="__codelineno-29-34" name="__codelineno-29-34" href="#__codelineno-29-34"></a>Easing Functions
</span><span id="__span-29-35"><a id="__codelineno-29-35" name="__codelineno-29-35" href="#__codelineno-29-35"></a>----------------
</span><span id="__span-29-36"><a id="__codelineno-29-36" name="__codelineno-29-36" href="#__codelineno-29-36"></a>LINEAR - Linear easing
</span><span id="__span-29-37"><a id="__codelineno-29-37" name="__codelineno-29-37" href="#__codelineno-29-37"></a>SINE   - Sine easing
</span><span id="__span-29-38"><a id="__codelineno-29-38" name="__codelineno-29-38" href="#__codelineno-29-38"></a>QUAD   - Quadratic easing
</span><span id="__span-29-39"><a id="__codelineno-29-39" name="__codelineno-29-39" href="#__codelineno-29-39"></a>CUBIC  - Cubic easing
</span><span id="__span-29-40"><a id="__codelineno-29-40" name="__codelineno-29-40" href="#__codelineno-29-40"></a>QUART  - Quartic easing
</span><span id="__span-29-41"><a id="__codelineno-29-41" name="__codelineno-29-41" href="#__codelineno-29-41"></a>QUINT  - Quintic easing
</span><span id="__span-29-42"><a id="__codelineno-29-42" name="__codelineno-29-42" href="#__codelineno-29-42"></a>EXPO   - Exponential easing
</span><span id="__span-29-43"><a id="__codelineno-29-43" name="__codelineno-29-43" href="#__codelineno-29-43"></a>CIRC   - Circular easing
</span><span id="__span-29-44"><a id="__codelineno-29-44" name="__codelineno-29-44" href="#__codelineno-29-44"></a>BACK   - Back easing
</span><span id="__span-29-45"><a id="__codelineno-29-45" name="__codelineno-29-45" href="#__codelineno-29-45"></a>ELASTIC - Elastic easing
</span><span id="__span-29-46"><a id="__codelineno-29-46" name="__codelineno-29-46" href="#__codelineno-29-46"></a>BOUNCE - Bounce easing
</span><span id="__span-29-47"><a id="__codelineno-29-47" name="__codelineno-29-47" href="#__codelineno-29-47"></a>
</span><span id="__span-29-48"><a id="__codelineno-29-48" name="__codelineno-29-48" href="#__codelineno-29-48"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-29-49"><a id="__codelineno-29-49" name="__codelineno-29-49" href="#__codelineno-29-49"></a>
</span><span id="__span-29-50"><a id="__codelineno-29-50" name="__codelineno-29-50" href="#__codelineno-29-50"></a>Example: terminaltexteffects waves --wave-symbols ▁ ▂ ▃ ▄ ▅ ▆ ▇ █ ▇ ▆ ▅ ▄ ▃ ▂ ▁ --wave-gradient-stops f0ff65 ffb102 31a0d4 ffb102 f0ff65 --wave-gradient-steps 6 --final-gradient-stops ffb102 31a0d4 f0ff65 --final-gradient-steps 12 --wave-count 7 --wave-length 2 --wave-easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="wipe">Wipe</h2>
<p>Performs a wipe across the terminal to reveal characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/wipe_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/wipe/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/wipe/#terminaltexteffects.effects.effect_wipe.WipeConfig">Config</a></p>
<details>
<summary>Wipe Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>--wipe-direction {column_left_to_right,column_right_to_left,row_top_to_bottom,row_bottom_to_top,diagonal_top_left_to_bottom_right,diagonal_bottom_left_to_top_right,diagonal_top_right_to_bottom_left,diagonal_bottom_right_to_top_left,outside_to_center,center_to_outside}
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>                    Direction the text will wipe. (default: diagonal_bottom_left_to_top_right)
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>                    Space separated, unquoted, list of colors for the wipe gradient. (default: (Color(#833ab4), Color(#fd1d1d), Color(#fcb045)))
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-30-11"><a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>--wipe-delay (int &gt;= 0)
</span><span id="__span-30-12"><a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a>                    Number of frames to wait before adding the next character group. Increase, to slow down the effect. (default: 0)
</span><span id="__span-30-13"><a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a>
</span><span id="__span-30-14"><a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a>Example: terminaltexteffects wipe --wipe-direction diagonal_bottom_left_to_top_right --final-gradient-stops 833ab4 fd1d1d fcb045 --final-gradient-steps 12 --final-gradient-frames 5 --wipe-delay 0
</span></code></pre></div>
</details>












                
              </article>
            </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Openkoda – Open–source, private, Salesforce alternative (269 pts)]]></title>
            <link>https://github.com/openkoda/openkoda</link>
            <guid>40502956</guid>
            <pubDate>Tue, 28 May 2024 17:11:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openkoda/openkoda">https://github.com/openkoda/openkoda</a>, See on <a href="https://news.ycombinator.com/item?id=40502956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311209030-698c333f-4791-4c6b-95d4-aa6eff7dc6d3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDkwMzAtNjk4YzMzM2YtNDc5MS00YzZiLTk1ZDQtYWE2ZWZmN2RjNmQzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNDdiM2UwNDIzN2M5OWU5YzRjNDRkYmJiOTgyODA3NjhmZWIzN2EyYzJkNzk2NzQxNjYxNjhhNWI4ZWRkMjImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.1u0a3wf6OoZqus-IQnw8RRkCdnrefFx85vsOL4kXJqg"><img alt="Openkoda Logo" src="https://private-user-images.githubusercontent.com/14223954/311209030-698c333f-4791-4c6b-95d4-aa6eff7dc6d3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDkwMzAtNjk4YzMzM2YtNDc5MS00YzZiLTk1ZDQtYWE2ZWZmN2RjNmQzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNDdiM2UwNDIzN2M5OWU5YzRjNDRkYmJiOTgyODA3NjhmZWIzN2EyYzJkNzk2NzQxNjYxNjhhNWI4ZWRkMjImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.1u0a3wf6OoZqus-IQnw8RRkCdnrefFx85vsOL4kXJqg" width="70%"></a>
</p>
<div dir="auto">
  <p dir="auto"><h3 tabindex="-1" dir="auto">Ready-to-use development platform that accelerates the process of building business applications and internal tools.</h3><a id="user-content-ready-to-use-development-platform-that-accelerates-the-process-of-building-business-applications-and-internal-tools" aria-label="Permalink: Ready-to-use development platform that accelerates the process of building business applications and internal tools." href="#ready-to-use-development-platform-that-accelerates-the-process-of-building-business-applications-and-internal-tools"></a></p>
</div>
<p><a href="https://opensource.org/licenses/MIT" rel="nofollow"><img alt="License: MIT" src="https://camo.githubusercontent.com/efc2f3907feb90b733c9fa4fe158637fd40ee1cfe834cad6b46cf8e3e75de8c9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d3138423243362e737667" data-canonical-src="https://img.shields.io/badge/License-MIT-18B2C6.svg"></a>
    <a href="https://openkoda.com/product/" rel="nofollow"><img alt="Openkoda: 1.5.1" src="https://camo.githubusercontent.com/58bc75c5b47caa6bc4757689919f005f4ef9fef128b0196b74052809860b4057/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4f70656e6b6f6461266d6573736167653d312e352e3126636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Openkoda&amp;message=1.5.1&amp;color=18B2C6"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8729903294ca978fe85f10d43fe3dad9e7a0e015e14ba5b0705ee8f4e39dca48/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4a617661266d6573736167653d31372e302e3226636f6c6f723d313842324336"><img alt="Java: 17.0.2" src="https://camo.githubusercontent.com/8729903294ca978fe85f10d43fe3dad9e7a0e015e14ba5b0705ee8f4e39dca48/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4a617661266d6573736167653d31372e302e3226636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Java&amp;message=17.0.2&amp;color=18B2C6"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9d06407a13551712cbd371caa6f26014b0bbf0fde10cba37b667b2759042aa15/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d537072696e67253230426f6f74266d6573736167653d332e302e3526636f6c6f723d313842324336"><img alt="Spring Boot: 3.0.5" src="https://camo.githubusercontent.com/9d06407a13551712cbd371caa6f26014b0bbf0fde10cba37b667b2759042aa15/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d537072696e67253230426f6f74266d6573736167653d332e302e3526636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Spring%20Boot&amp;message=3.0.5&amp;color=18B2C6"></a>
</p>
<br>
<ul dir="auto">
<li><strong>Reduce development time and effort</strong>. Use pre-built functionalities and out-of-the-box features.</li>
<li><strong>Adopt a flexible and scalable approach</strong>. Build applications with dynamic entities. Choose from multiple multi-tenancy models.</li>
<li><strong>Use technology you already know</strong>: Java, Spring Boot, JavaScript, HTML, Hibernate, PostgreSQL</li>
<li><strong>Extend as you wish</strong>. Openkoda offers unlimited customization and integration options.</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312075569-9acded2e-a3e6-4480-805e-7ac38ebdafc0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzU1NjktOWFjZGVkMmUtYTNlNi00NDgwLTgwNWUtN2FjMzhlYmRhZmMwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFjMjY5NGU3NGI5OGU4MGZkYTA4M2E1YWZlZDRkYWQwNDljZGJlOWM3YjliMTAxODEzYTVkMjE5M2YwN2JmODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lVSNQM1OT2siE2xaSYaRyG44Xw4FxFaRXmyYAA8WE0c"><img src="https://private-user-images.githubusercontent.com/14223954/312075569-9acded2e-a3e6-4480-805e-7ac38ebdafc0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzU1NjktOWFjZGVkMmUtYTNlNi00NDgwLTgwNWUtN2FjMzhlYmRhZmMwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFjMjY5NGU3NGI5OGU4MGZkYTA4M2E1YWZlZDRkYWQwNDljZGJlOWM3YjliMTAxODEzYTVkMjE5M2YwN2JmODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lVSNQM1OT2siE2xaSYaRyG44Xw4FxFaRXmyYAA8WE0c" alt="openkoda admin"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📌Contents</h3><a id="user-content-contents" aria-label="Permalink: 📌Contents" href="#contents"></a></p>
<p dir="auto">🧩 <a href="#-integrations">Integrations</a><br>
🚀 <a href="#-getting-started">How to start</a><br>
✅ <a href="#-out-of-the-box-features">Out-of-the-box features</a><br>
👨‍💻 <a href="#-tech-stack">Tech stack</a><br>
💡 <a href="#-sample-applications">Sample applications</a><br>
💡 <a href="#-application-screenshots">Application screenshots</a><br>
💙 <a href="#-contribution">Contribution</a><br>
📜 <a href="#%EF%B8%8F-release-notes">Release notes</a><br>
🤝 <a href="#-partners">Partners</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧩 Integrations</h3><a id="user-content--integrations" aria-label="Permalink: 🧩 Integrations" href="#-integrations"></a></p>
<p dir="auto">Enhance your application by adding integrations.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Open Source</h4><a id="user-content-open-source" aria-label="Permalink: Open Source" href="#open-source"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230132-bffafc23-6a72-4a8b-86cf-4a073cfe9c3b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxMzItYmZmYWZjMjMtNmE3Mi00YThiLTg2Y2YtNGEwNzNjZmU5YzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFkNWYyODViMzU0NzE3NWE5YTlkYjFkNWVmMmM3OWE4MzkyZDE5MDBjOThmNmY0ZGZkMjU5NmI2OWQ3ZTFkNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.gNYKJm2drHOk3UxIKrND4C42fWDv0iF3vyyM9F2Juq4"><img height="60" alt="logo-slack" src="https://private-user-images.githubusercontent.com/14223954/311230132-bffafc23-6a72-4a8b-86cf-4a073cfe9c3b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxMzItYmZmYWZjMjMtNmE3Mi00YThiLTg2Y2YtNGEwNzNjZmU5YzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFkNWYyODViMzU0NzE3NWE5YTlkYjFkNWVmMmM3OWE4MzkyZDE5MDBjOThmNmY0ZGZkMjU5NmI2OWQ3ZTFkNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.gNYKJm2drHOk3UxIKrND4C42fWDv0iF3vyyM9F2Juq4"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230162-f3b72e42-04c1-42c1-b268-76ef524a805c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxNjItZjNiNzJlNDItMDRjMS00MmMxLWIyNjgtNzZlZjUyNGE4MDVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTIyOTBlNjU3OTE4MTQ0NWRhOWEyMjU4YTQ1YWEwMGI3MDZmOWM1OGY0OWMwY2VmZTVlMzlhZDZjMDFlZjk5ZTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.NjxSw5u4eQVKqIxAW94t1AeIMSyrM74DxoiElmF3tB8"><img height="60" alt="logo-discord" src="https://private-user-images.githubusercontent.com/14223954/311230162-f3b72e42-04c1-42c1-b268-76ef524a805c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxNjItZjNiNzJlNDItMDRjMS00MmMxLWIyNjgtNzZlZjUyNGE4MDVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTIyOTBlNjU3OTE4MTQ0NWRhOWEyMjU4YTQ1YWEwMGI3MDZmOWM1OGY0OWMwY2VmZTVlMzlhZDZjMDFlZjk5ZTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.NjxSw5u4eQVKqIxAW94t1AeIMSyrM74DxoiElmF3tB8"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230221-d26eccd9-39f2-4cc5-af86-e3e74bad95cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMjEtZDI2ZWNjZDktMzlmMi00Y2M1LWFmODYtZTNlNzRiYWQ5NWNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwMDNmMTNlZWM3MTFlNjg0Y2JhMTFhYzBlNDUzYjVmY2I3NDk3MGVjNzA4NGE0NWNkOTdlNzQzNGIyYzE0YmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.WGoDLep9jJRSUF1ngHa4JsJRxRVtIWnhWtz1VJFreYM"><img height="60" alt="logo-basecamp" src="https://private-user-images.githubusercontent.com/14223954/311230221-d26eccd9-39f2-4cc5-af86-e3e74bad95cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMjEtZDI2ZWNjZDktMzlmMi00Y2M1LWFmODYtZTNlNzRiYWQ5NWNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwMDNmMTNlZWM3MTFlNjg0Y2JhMTFhYzBlNDUzYjVmY2I3NDk3MGVjNzA4NGE0NWNkOTdlNzQzNGIyYzE0YmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.WGoDLep9jJRSUF1ngHa4JsJRxRVtIWnhWtz1VJFreYM"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230238-ba648de4-4cbf-4007-aff4-82c94942a65d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMzgtYmE2NDhkZTQtNGNiZi00MDA3LWFmZjQtODJjOTQ5NDJhNjVkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThlYTU5NmI3NTZhMzE5NmEwNmEyNGRhMjY2MTg0ZTAyMDliZmE0Zjk2YjEzOGJjNWI0NmU3NjliMGI5NTRjMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RiuoFjiAMFIkKKKdIhut7k8d9Dbm2Omngw5kiCYXGmw"><img height="60" alt="logo-github" src="https://private-user-images.githubusercontent.com/14223954/311230238-ba648de4-4cbf-4007-aff4-82c94942a65d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMzgtYmE2NDhkZTQtNGNiZi00MDA3LWFmZjQtODJjOTQ5NDJhNjVkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThlYTU5NmI3NTZhMzE5NmEwNmEyNGRhMjY2MTg0ZTAyMDliZmE0Zjk2YjEzOGJjNWI0NmU3NjliMGI5NTRjMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RiuoFjiAMFIkKKKdIhut7k8d9Dbm2Omngw5kiCYXGmw"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230298-e45c0174-e07e-49dc-bdf5-2c1415538682.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyOTgtZTQ1YzAxNzQtZTA3ZS00OWRjLWJkZjUtMmMxNDE1NTM4NjgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdjZWNmYWU1YWY1NzEwYzI4MjI2YjgzZDMyMjg1M2EzNTc5YWZiNmI0NGI4NDE1NjVlMmUxZGYxZTRiZWFjY2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QZgrx7YzsleoANv6JiSaUfAyeOpIcGVsE1Rpyh8XbSA"><img height="40" alt="logo-jira" src="https://private-user-images.githubusercontent.com/14223954/311230298-e45c0174-e07e-49dc-bdf5-2c1415538682.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyOTgtZTQ1YzAxNzQtZTA3ZS00OWRjLWJkZjUtMmMxNDE1NTM4NjgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdjZWNmYWU1YWY1NzEwYzI4MjI2YjgzZDMyMjg1M2EzNTc5YWZiNmI0NGI4NDE1NjVlMmUxZGYxZTRiZWFjY2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QZgrx7YzsleoANv6JiSaUfAyeOpIcGVsE1Rpyh8XbSA"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230327-f18841b5-e6ad-4807-9b9c-f0d5622300f7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAzMjctZjE4ODQxYjUtZTZhZC00ODA3LTliOWMtZjBkNTYyMjMwMGY3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMyYjc3MWUzOWViYjE5MmJhZDllYjgwMThlNjBmMGEzMTMxNmYyYzlmOGJlMjUzM2JlYWZjZDNkNzg2N2Q5YzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lBTlU1ibHGNoMY-1PDvzGTx0krrlL3E_ihv5rSTklss"><img height="60" alt="logo-trello" src="https://private-user-images.githubusercontent.com/14223954/311230327-f18841b5-e6ad-4807-9b9c-f0d5622300f7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAzMjctZjE4ODQxYjUtZTZhZC00ODA3LTliOWMtZjBkNTYyMjMwMGY3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMyYjc3MWUzOWViYjE5MmJhZDllYjgwMThlNjBmMGEzMTMxNmYyYzlmOGJlMjUzM2JlYWZjZDNkNzg2N2Q5YzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lBTlU1ibHGNoMY-1PDvzGTx0krrlL3E_ihv5rSTklss"></a>&nbsp;&nbsp;
</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Enterprise</h4><a id="user-content-enterprise" aria-label="Permalink: Enterprise" href="#enterprise"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231535-ae5cb4fd-4fb2-43ab-9a4a-3ca1deaf1aaf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1MzUtYWU1Y2I0ZmQtNGZiMi00M2FiLTlhNGEtM2NhMWRlYWYxYWFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg2OTZhNmY3ZGIxOWE4NGZkNzdiN2YyYTMyOGZlMjNlZWZmY2UzZmJiMzA3OTUwMDVmMGE0Zjk5MWRkN2U3OTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.odOEvQrdxSRFkAeBdvWVcUJxDsYoSnGWcsrMXs9HFqg"><img height="60" alt="logo-google" src="https://private-user-images.githubusercontent.com/14223954/311231535-ae5cb4fd-4fb2-43ab-9a4a-3ca1deaf1aaf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1MzUtYWU1Y2I0ZmQtNGZiMi00M2FiLTlhNGEtM2NhMWRlYWYxYWFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg2OTZhNmY3ZGIxOWE4NGZkNzdiN2YyYTMyOGZlMjNlZWZmY2UzZmJiMzA3OTUwMDVmMGE0Zjk5MWRkN2U3OTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.odOEvQrdxSRFkAeBdvWVcUJxDsYoSnGWcsrMXs9HFqg"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231552-42620407-eb57-4a04-a67e-6bc7bbbb4e7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1NTItNDI2MjA0MDctZWI1Ny00YTA0LWE2N2UtNmJjN2JiYmI0ZTdjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4ZmM3Yjk3NmQ5OWViY2U4MDJjNjlmZTBiMzAyNmNhZmQ3NGUzYjNjZjJlZmY2NThmNDJkMDQ4M2NlNDcwOGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.nr1_y4ggB_QWAuvGxvPPabtayHTO5k_KLRsIaEInbHw"><img height="60" alt="logo-facebook" src="https://private-user-images.githubusercontent.com/14223954/311231552-42620407-eb57-4a04-a67e-6bc7bbbb4e7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1NTItNDI2MjA0MDctZWI1Ny00YTA0LWE2N2UtNmJjN2JiYmI0ZTdjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4ZmM3Yjk3NmQ5OWViY2U4MDJjNjlmZTBiMzAyNmNhZmQ3NGUzYjNjZjJlZmY2NThmNDJkMDQ4M2NlNDcwOGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.nr1_y4ggB_QWAuvGxvPPabtayHTO5k_KLRsIaEInbHw"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231593-33594d22-07f6-4a20-ad71-f18cbb428fc4.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1OTMtMzM1OTRkMjItMDdmNi00YTIwLWFkNzEtZjE4Y2JiNDI4ZmM0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwNDA0YTViMmIxYzJmZTM4YzIxNWM3MWQ4NDM1YzAyYWEyMTkwNzhhOWJmNGYwMjYxYTNhY2M5NzEzYzdiNzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pgBfSqbDoaJKiqc2Cp5q6ICD48X9SAk3wrMSyrWcm_8"><img height="60" alt="logo-stripe" src="https://private-user-images.githubusercontent.com/14223954/311231593-33594d22-07f6-4a20-ad71-f18cbb428fc4.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1OTMtMzM1OTRkMjItMDdmNi00YTIwLWFkNzEtZjE4Y2JiNDI4ZmM0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwNDA0YTViMmIxYzJmZTM4YzIxNWM3MWQ4NDM1YzAyYWEyMTkwNzhhOWJmNGYwMjYxYTNhY2M5NzEzYzdiNzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pgBfSqbDoaJKiqc2Cp5q6ICD48X9SAk3wrMSyrWcm_8"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231611-61b60851-b821-4f94-8fe5-e7af910017ce.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE2MTEtNjFiNjA4NTEtYjgyMS00Zjk0LThmZTUtZTdhZjkxMDAxN2NlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ1MDA5MmNmMTM0ODNmY2UzNGQwMGI1YjRlZmE3MTExYWQ1NTU5NDhiOTIzOTNjZDhiOGUxNGIxMjllNDM0MjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.JZstw8nqQny7Up83Iq1bGMGBFhKnRo0D4gwuTbFn6No"><img height="60" alt="logo-ms-teams" src="https://private-user-images.githubusercontent.com/14223954/311231611-61b60851-b821-4f94-8fe5-e7af910017ce.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE2MTEtNjFiNjA4NTEtYjgyMS00Zjk0LThmZTUtZTdhZjkxMDAxN2NlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ1MDA5MmNmMTM0ODNmY2UzNGQwMGI1YjRlZmE3MTExYWQ1NTU5NDhiOTIzOTNjZDhiOGUxNGIxMjllNDM0MjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.JZstw8nqQny7Up83Iq1bGMGBFhKnRo0D4gwuTbFn6No"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231859-47058144-3584-4059-9239-42d7192b475a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE4NTktNDcwNTgxNDQtMzU4NC00MDU5LTkyMzktNDJkNzE5MmI0NzVhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5YjBlMjFkODYyZGY0YjZkMGI3OGE5OTgxZTBlZTQwMDQ4Yjg3YmY5ODkwNmU1OWUyOGZmODUwMGFlYTBjNjgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.heYud7QgsngADvYL8eBw5OCXoIDgMHvCaTpPruocdo4"><img height="60" alt="logo-ldap" src="https://private-user-images.githubusercontent.com/14223954/311231859-47058144-3584-4059-9239-42d7192b475a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE4NTktNDcwNTgxNDQtMzU4NC00MDU5LTkyMzktNDJkNzE5MmI0NzVhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5YjBlMjFkODYyZGY0YjZkMGI3OGE5OTgxZTBlZTQwMDQ4Yjg3YmY5ODkwNmU1OWUyOGZmODUwMGFlYTBjNjgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.heYud7QgsngADvYL8eBw5OCXoIDgMHvCaTpPruocdo4"></a>&nbsp;&nbsp;
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">👨‍💻 Tech stack</h3><a id="user-content--tech-stack" aria-label="Permalink: 👨‍💻 Tech stack" href="#-tech-stack"></a></p>
<ul dir="auto">
<li>Java (17+)</li>
<li>Spring Boot 3.x</li>
<li>Hibernate</li>
<li>PostgreSQL</li>
<li>GraalVM</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">🚀 Getting started</h3><a id="user-content--getting-started" aria-label="Permalink: 🚀 Getting started" href="#-getting-started"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">There are two installation options to start application development with Openkoda:</p>
<ul dir="auto">
<li>Building from sources</li>
<li>Running as a Docker container</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option #1: Build from Source</h4><a id="user-content-option-1-build-from-source" aria-label="Permalink: Option #1: Build from Source" href="#option-1-build-from-source"></a></p>
<p dir="auto">Prerequisites:</p>
<p dir="auto">Git, Java 17+, Maven 3.8+, PostgreSQL 14+</p>
<ol dir="auto">
<li><a href="https://github.com/openkoda/openkoda.git">Create an empty database</a></li>
<li>Clone or download this Git repository</li>
<li>Build application with maven:</li>
</ol>
<div data-snippet-clipboard-copy-content="mvn -f openkoda/pom.xml clean install spring-boot:repackage -DskipTests"><pre><code>mvn -f openkoda/pom.xml clean install spring-boot:repackage -DskipTests
</code></pre></div>
<ol start="4" dir="auto">
<li>Initialize the database in a first run:</li>
</ol>
<div data-snippet-clipboard-copy-content="java -Dloader.path=/BOOT-INF/classes -Dspring.profiles.active=openkoda,drop_and_init_database -jar openkoda.jar --server.port=<http port>"><pre><code>java -Dloader.path=/BOOT-INF/classes -Dspring.profiles.active=openkoda,drop_and_init_database -jar openkoda.jar --server.port=&lt;http port&gt;
</code></pre></div>
<ol start="5" dir="auto">
<li>Run Openkoda</li>
</ol>
<div data-snippet-clipboard-copy-content="java -Dloader.path=/BOOT-INF/classes -Dsecure.cookie=false -jar openkoda.jar --spring.profiles.active=openkoda --server.port=<http port>"><pre><code>java -Dloader.path=/BOOT-INF/classes -Dsecure.cookie=false -jar openkoda.jar --spring.profiles.active=openkoda --server.port=&lt;http port&gt;
</code></pre></div>
<p dir="auto">Detailed instructions can be found in the <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/installation.md">Installation</a> manual.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option #2: Run as a Docker Container</h4><a id="user-content-option-2-run-as-a-docker-container" aria-label="Permalink: Option #2: Run as a Docker Container" href="#option-2-run-as-a-docker-container"></a></p>
<p dir="auto">Docker images are available at Docker Hub : <a href="https://hub.docker.com/r/openkoda/openkoda" rel="nofollow">https://hub.docker.com/r/openkoda/openkoda</a></p>
<p dir="auto">It can be launched via simple:</p>
<div data-snippet-clipboard-copy-content="docker pull openkoda/openkoda:latest"><pre><code>docker pull openkoda/openkoda:latest
</code></pre></div>
<p dir="auto">Please note that in that case Postgres needs to be already in place and <code>SPRING_DATASOURCE_URL</code>, <code>SPRING_DATASOURCE_USERNAME</code>, <code>SPRING_DATASOURCE_PASSWORD</code> env variables needs to be adjusted when running docker (<a href="https://hub.docker.com/r/openkoda/openkoda" rel="nofollow">see Docker Hub for detailed options</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Docker compose</h5><a id="user-content-docker-compose" aria-label="Permalink: Docker compose" href="#docker-compose"></a></p>
<p dir="auto">A simpler option may be to use the Docker Compose scripts located in the: <code>./docker/docker-compose.yaml</code> and <code>./docker/docker-compose-no-db.yaml</code> - depending on your preference, with or without Postgres as a part of the docker service. Here is a useful one-liner :</p>
<div data-snippet-clipboard-copy-content="curl https://raw.githubusercontent.com/openkoda/openkoda/main/docker/docker-compose.yaml | docker compose -f - up"><pre><code>curl https://raw.githubusercontent.com/openkoda/openkoda/main/docker/docker-compose.yaml | docker compose -f - up
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">✅ Out-of-the-box features</h3><a id="user-content--out-of-the-box-features" aria-label="Permalink: ✅ Out-of-the-box features" href="#-out-of-the-box-features"></a></p>
<p dir="auto">To significantly reduce development time and effort, Openkoda offers pre-built functionality and out-of-the-box features.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔀 Dynamic entities:</h4><a id="user-content--dynamic-entities" aria-label="Permalink: 🔀 Dynamic entities:" href="#-dynamic-entities"></a></p>
<p dir="auto">Create database table, CRUD functionality, form, and overview with no need of re-compilation</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🛠️ Application admin panel:</h4><a id="user-content-️-application-admin-panel" aria-label="Permalink: 🛠️ Application admin panel:" href="#️-application-admin-panel"></a></p>
<ul dir="auto">
<li><strong>App Configurations</strong>: Manage email settings, roles, privileges, and HTML templates.</li>
<li><strong>Audit Screen</strong>: Track changes to data for accountability.</li>
<li><strong>System Logs</strong>: Review logs for activity insights and troubleshooting.</li>
<li><strong>System Health</strong>: Get a quick overview of system performance and status.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">👤User Management</h4><a id="user-content-user-management" aria-label="Permalink: 👤User Management" href="#user-management"></a></p>
<ul dir="auto">
<li>Invite users to the organization</li>
<li>Set roles globally and within the organization context</li>
<li>Access user profile settings</li>
<li>Spoof user (available in admin mode)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔑 Roles and Privileges</h4><a id="user-content--roles-and-privileges" aria-label="Permalink: 🔑 Roles and Privileges" href="#-roles-and-privileges"></a></p>
<ul dir="auto">
<li>Create global or organization-specific roles</li>
<li>Assign privileges from a list to each role</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🏢 Organization management</h4><a id="user-content--organization-management" aria-label="Permalink: 🏢 Organization management" href="#-organization-management"></a></p>
<ul dir="auto">
<li>Separate organization data</li>
<li>Implement security rules for data access</li>
<li>Customize your own dashboard</li>
<li>Assign organizational roles, such as member or admin, to users.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">📝 CMS</h4><a id="user-content--cms" aria-label="Permalink: 📝 CMS" href="#-cms"></a></p>
<ul dir="auto">
<li>Modify HTML templates</li>
<li>Edit draft versions of resources</li>
<li>Introduce new public resources</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🗂️ Resource Management</h4><a id="user-content-️-resource-management" aria-label="Permalink: 🗂️ Resource Management" href="#️-resource-management"></a></p>
<ul dir="auto">
<li>Manage file overview</li>
<li>Resize images</li>
<li>Set files to public access</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔊 Event Listeners:</h4><a id="user-content--event-listeners" aria-label="Permalink: 🔊 Event Listeners:" href="#-event-listeners"></a></p>
<p dir="auto">Respond to application events (e.g., user creation, login, application start) with built-in Openkoda handlers (e.g., messaging, push notifications).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">💾 Backups:</h4><a id="user-content--backups" aria-label="Permalink: 💾 Backups:" href="#-backups"></a></p>
<p dir="auto">Embedded database backup routines</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">📥 Import and export:</h4><a id="user-content--import-and-export" aria-label="Permalink: 📥 Import and export:" href="#-import-and-export"></a></p>
<p dir="auto">Export components from current app and easily import them into another Openkoda Core instance</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🗄️ Multiple Multi-tenancy models:</h4><a id="user-content-️-multiple-multi-tenancy-models" aria-label="Permalink: 🗄️ Multiple Multi-tenancy models:" href="#️-multiple-multi-tenancy-models"></a></p>
<p dir="auto">Openkoda supports the following multi-tenancy setups:</p>
<ul dir="auto">
<li>Single Database / Single Schema</li>
<li>Single Database / Many Schemas</li>
<li>Multiple Databases / Many Schemas</li>
</ul>
<p dir="auto">See <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/installation.md#multitenancy-setup">multitenancy setup</a> for more details</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔄 Job Requests</h4><a id="user-content--job-requests" aria-label="Permalink: 🔄 Job Requests" href="#-job-requests"></a></p>
<p dir="auto">Schedule jobs to be performed in time intervals
Process jobs with event listeners</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔔 Notifications</h4><a id="user-content--notifications" aria-label="Permalink: 🔔 Notifications" href="#-notifications"></a></p>
<p dir="auto">Synchronize your application with notifications channels:
Email
Slack
Jira
GitHub
Trello
Basecamp</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">✉️ Email Sender</h4><a id="user-content-️-email-sender" aria-label="Permalink: ✉️ Email Sender" href="#️-email-sender"></a></p>
<p dir="auto">Customize email templates via CMS
Schedule emails</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">💡 Sample applications</h3><a id="user-content--sample-applications" aria-label="Permalink: 💡 Sample applications" href="#-sample-applications"></a></p>
<p dir="auto">Openkoda Application Templates are sample applications built with Openkoda.</p>
<p dir="auto">They represent a standard set of functions for a traditional web application provided by Openkoda Core, as well as business functionalities created specifically for these examples.</p>
<p dir="auto">Application Templates can be easily extended, taking into account both the data storage schema and any custom functionality.</p>
<p dir="auto">Learn more in our <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/5-minute-guide.md">5-minute guide</a>.</p>
<p dir="auto"><strong>Timelog</strong></p>
<p dir="auto">Timelog is a time tracking solution for companies of all sizes. It allows employees to record hours spent on specific tasks, while managers generate monthly performance reports. <a href="https://openkoda.com/time-tracking-software/" rel="nofollow">Learn more</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076431-ecaf54d2-6112-4c45-a67f-15ac7b150452.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0MzEtZWNhZjU0ZDItNjExMi00YzQ1LWE2N2YtMTVhYzdiMTUwNDUyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTcxN2ZjNzk5ZmVjOGQ2MWQ5MWEzYzg0ODJkYTEyYmIxOWMzYjA0MjUzOWRiY2MyYzZkOTYzNWZkY2I0Zjc5YWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.igno7rI81UjPz-rib7ISwiXYdJHnlswwrvRjNl3H4O8"><img src="https://private-user-images.githubusercontent.com/14223954/312076431-ecaf54d2-6112-4c45-a67f-15ac7b150452.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0MzEtZWNhZjU0ZDItNjExMi00YzQ1LWE2N2YtMTVhYzdiMTUwNDUyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTcxN2ZjNzk5ZmVjOGQ2MWQ5MWEzYzg0ODJkYTEyYmIxOWMzYjA0MjUzOWRiY2MyYzZkOTYzNWZkY2I0Zjc5YWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.igno7rI81UjPz-rib7ISwiXYdJHnlswwrvRjNl3H4O8" alt="timelog user"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076469-e9669bef-5929-4fd6-92e8-8e35865a9261.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0NjktZTk2NjliZWYtNTkyOS00ZmQ2LTkyZTgtOGUzNTg2NWE5MjYxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmOGZmODBhZjg4ZWFlODAxMTIzMzgwNzJjMTA4YjFmZDlkMGIxOTJmYjQ5MzY1NTUzYzA4Y2IyZDA1NjRiZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.0EPTOm1B4aHcoyuwOwyNvaaBUL9NM2ej5lJI55GbtXI"><img src="https://private-user-images.githubusercontent.com/14223954/312076469-e9669bef-5929-4fd6-92e8-8e35865a9261.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0NjktZTk2NjliZWYtNTkyOS00ZmQ2LTkyZTgtOGUzNTg2NWE5MjYxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmOGZmODBhZjg4ZWFlODAxMTIzMzgwNzJjMTA4YjFmZDlkMGIxOTJmYjQ5MzY1NTUzYzA4Y2IyZDA1NjRiZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.0EPTOm1B4aHcoyuwOwyNvaaBUL9NM2ej5lJI55GbtXI" alt="timelog admin"></a></p>
<p dir="auto"><strong>Insurance Policy Management</strong></p>
<p dir="auto">Insurance Policy Management is a dynamic policy data storage tool with a variety of embeddable widgets for personalized customer and policy dashboards.
Widgets include: message senders, email schedulers, attachment and task lists, notes, and detailed customer/policy information to improve operational efficiency and customer engagement. <a href="https://openkoda.com/insurance-policy-management-software/" rel="nofollow">Learn more</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076544-cb2f4065-59a4-42da-915d-4fd3d810fc19.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1NDQtY2IyZjQwNjUtNTlhNC00MmRhLTkxNWQtNGZkM2Q4MTBmYzE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYmJlNTAzNjRlNGRhYTMyNGMzYzdjYjExODg5ZDViNWI5MWI5MmM2YzBjNTlmYWE2OWYxMjdhNDBjZTc2MmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zNr0TBPgYiAro0GEsSp3LdqhWWSPmyHM-fgcPoPNUXQ"><img src="https://private-user-images.githubusercontent.com/14223954/312076544-cb2f4065-59a4-42da-915d-4fd3d810fc19.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1NDQtY2IyZjQwNjUtNTlhNC00MmRhLTkxNWQtNGZkM2Q4MTBmYzE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYmJlNTAzNjRlNGRhYTMyNGMzYzdjYjExODg5ZDViNWI5MWI5MmM2YzBjNTlmYWE2OWYxMjdhNDBjZTc2MmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zNr0TBPgYiAro0GEsSp3LdqhWWSPmyHM-fgcPoPNUXQ" alt="insurance user"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076583-ac47b4ba-246e-4772-b47c-69bbfe8512fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1ODMtYWM0N2I0YmEtMjQ2ZS00NzcyLWI0N2MtNjliYmZlODUxMmZlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4NTlhNWE0NjY1NThmMzJkNTE1OTQ1N2JjMjNmMmMxZDM0ZDUyMjE3MDgxNzM3Nzk4MzcwNjQ4NzkyYTQ3NzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M1rbI3qt_wiQx4bEtRl6CFd7sZUDcfu2wZUbogmt6Fo"><img src="https://private-user-images.githubusercontent.com/14223954/312076583-ac47b4ba-246e-4772-b47c-69bbfe8512fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1ODMtYWM0N2I0YmEtMjQ2ZS00NzcyLWI0N2MtNjliYmZlODUxMmZlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4NTlhNWE0NjY1NThmMzJkNTE1OTQ1N2JjMjNmMmMxZDM0ZDUyMjE3MDgxNzM3Nzk4MzcwNjQ4NzkyYTQ3NzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M1rbI3qt_wiQx4bEtRl6CFd7sZUDcfu2wZUbogmt6Fo" alt="insurance admin"></a></p>
<p dir="auto"><strong>Weather App</strong></p>
<p dir="auto">A sample application that provides weather forecast for selected vacation spots.</p>
<p dir="auto">Watch the short video to see the building process:
<a href="https://youtu.be/gob4j072Isg" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/10715247/316587497-19c670f1-281f-463c-b93c-0715ebef6402.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xMDcxNTI0Ny8zMTY1ODc0OTctMTljNjcwZjEtMjgxZi00NjNjLWI5M2MtMDcxNWViZWY2NDAyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmNzExNGM5N2NjM2E0Y2YzYzU0OTY2ZTkwMmRjOTg3M2FjNmExODIzYWQ3NDUxMWE4N2QyYzc4YjQxYTI1MmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ip79AyNEbKHF-Sz1W5e3D8KVZnFvTL4En0l87tNCpiQ" alt="How to build a weather app in less than 20 minutes?" secured-asset-link="" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">💡 Application screenshots</h3><a id="user-content--application-screenshots" aria-label="Permalink: 💡 Application screenshots" href="#-application-screenshots"></a></p>
<p dir="auto">CMS</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311207985-3e4e5563-53d3-4e7b-9ccf-8a69ea346bc1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDc5ODUtM2U0ZTU1NjMtNTNkMy00ZTdiLTljY2YtOGE2OWVhMzQ2YmMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBhNDNlNWZiNmIxOTY3YjI3MzExM2I4MWQzZTgzNmMxZDZmYzA1MGE3NzgxY2IyMTlmN2Q4N2FmMThlOWExMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5mTkTjOq5Yew2yQCCZPKCfEZaObfrKHk0b5JJFjVjyY"><img alt="openkoda-frontendresource-all" src="https://private-user-images.githubusercontent.com/14223954/311207985-3e4e5563-53d3-4e7b-9ccf-8a69ea346bc1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDc5ODUtM2U0ZTU1NjMtNTNkMy00ZTdiLTljY2YtOGE2OWVhMzQ2YmMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBhNDNlNWZiNmIxOTY3YjI3MzExM2I4MWQzZTgzNmMxZDZmYzA1MGE3NzgxY2IyMTlmN2Q4N2FmMThlOWExMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5mTkTjOq5Yew2yQCCZPKCfEZaObfrKHk0b5JJFjVjyY"></a>
<p dir="auto">Organization Settings</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311208029-275135d1-6c99-48fa-9224-008183d02085.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDgwMjktMjc1MTM1ZDEtNmM5OS00OGZhLTkyMjQtMDA4MTgzZDAyMDg1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MDE3YjhlOTU4MjkzNTM3ZTM4NGZmOThhNTc4NjAzYzMzOWIwMzZkZTUyNDE3ZjdkNmFlODA3YWFmZjJlNmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.kETK4acUfnKlUvWCMqNOIZWgAce9MjNfZBaQoulEj5c"><img alt="openkoda-organization-settings" src="https://private-user-images.githubusercontent.com/14223954/311208029-275135d1-6c99-48fa-9224-008183d02085.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDgwMjktMjc1MTM1ZDEtNmM5OS00OGZhLTkyMjQtMDA4MTgzZDAyMDg1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MDE3YjhlOTU4MjkzNTM3ZTM4NGZmOThhNTc4NjAzYzMzOWIwMzZkZTUyNDE3ZjdkNmFlODA3YWFmZjJlNmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.kETK4acUfnKlUvWCMqNOIZWgAce9MjNfZBaQoulEj5c"></a>
<p dir="auto">Job Request</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232624-2d26ddfd-3bee-4cc3-a4e0-be08d522bc96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2MjQtMmQyNmRkZmQtM2JlZS00Y2MzLWE0ZTAtYmUwOGQ1MjJiYzk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM1OTliMjA5YzVlMjY3MmJiODJkMDUzYWIwNTE3Yjg0ZjNlZDE2ZDNiZDQwZDhjZGViYTk5YTFiMzJmNzRjMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.muDj1R_hne1QGz9sFK5HhhspMDHmdwma_OgN3f492lY"><img alt="openkoda-job-request" src="https://private-user-images.githubusercontent.com/14223954/311232624-2d26ddfd-3bee-4cc3-a4e0-be08d522bc96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2MjQtMmQyNmRkZmQtM2JlZS00Y2MzLWE0ZTAtYmUwOGQ1MjJiYzk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM1OTliMjA5YzVlMjY3MmJiODJkMDUzYWIwNTE3Yjg0ZjNlZDE2ZDNiZDQwZDhjZGViYTk5YTFiMzJmNzRjMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.muDj1R_hne1QGz9sFK5HhhspMDHmdwma_OgN3f492lY"></a>
<p dir="auto">Event Litener</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232682-ac5d52b5-5509-4f37-b5b2-b7a3d9aaa631.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2ODItYWM1ZDUyYjUtNTUwOS00ZjM3LWI1YjItYjdhM2Q5YWFhNjMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0ZGFiZGYzZmM5MjVlODkyZTdkOGFkNzEzM2Y2OTkwYmYyYzFhZjdlYTNmODJlNzI3N2JjYTNkNDUxMzk1NGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bwjdE3L0nNuj-_CILjO89ZgrRAg4ec7KlQfW1jKqd7M"><img alt="openkoda-event-listener" src="https://private-user-images.githubusercontent.com/14223954/311232682-ac5d52b5-5509-4f37-b5b2-b7a3d9aaa631.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2ODItYWM1ZDUyYjUtNTUwOS00ZjM3LWI1YjItYjdhM2Q5YWFhNjMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0ZGFiZGYzZmM5MjVlODkyZTdkOGFkNzEzM2Y2OTkwYmYyYzFhZjdlYTNmODJlNzI3N2JjYTNkNDUxMzk1NGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bwjdE3L0nNuj-_CILjO89ZgrRAg4ec7KlQfW1jKqd7M"></a>
<p dir="auto">Forgot Password</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232707-f4c78aca-dc1d-4f42-8ba2-903d641a4229.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI3MDctZjRjNzhhY2EtZGMxZC00ZjQyLThiYTItOTAzZDY0MWE0MjI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4MmRjNzYwN2NmZDkzZjUzYTg0NjRmOWVkODk2NjA5MDc3NWY2MmRjODFhODM1OGMyMGRiMzE0OTg1NDJjNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.V5i5nqZt1gL0qNpqcXj28UOzD5vnX8JLbBpZjn3CZnY"><img alt="openkoda-forgot-password" src="https://private-user-images.githubusercontent.com/14223954/311232707-f4c78aca-dc1d-4f42-8ba2-903d641a4229.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI3MDctZjRjNzhhY2EtZGMxZC00ZjQyLThiYTItOTAzZDY0MWE0MjI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4MmRjNzYwN2NmZDkzZjUzYTg0NjRmOWVkODk2NjA5MDc3NWY2MmRjODFhODM1OGMyMGRiMzE0OTg1NDJjNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.V5i5nqZt1gL0qNpqcXj28UOzD5vnX8JLbBpZjn3CZnY"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">💙 Contribution</h3><a id="user-content--contribution" aria-label="Permalink: 💙 Contribution" href="#-contribution"></a></p>
<p dir="auto">Openkoda is an open source project under <a href="https://github.com/openkoda/openkoda/blob/main/LICENSE">MIT license</a>. It’s built by developers for developers.</p>
<p dir="auto">If you have ideas for improvement, contribute and let's innovate together.</p>
<p dir="auto">How to contribute:</p>
<ol dir="auto">
<li>Create a fork</li>
<li>Create a feature branch from main branch</li>
<li>Push</li>
<li>Create a Pull Request to an upstream main branch</li>
</ol>
<p dir="auto"><a href="https://github.com/openkoda/openkoda/blob/main/openkoda/CONTRIBUTING.md"><strong>Detailed contribution rules</strong></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📢 Follow, learn, and spread the word</h3><a id="user-content--follow-learn-and-spread-the-word" aria-label="Permalink: 📢 Follow, learn, and spread the word" href="#-follow-learn-and-spread-the-word"></a></p>
<p dir="auto"><a href="https://github.com/orgs/openkoda/repositories">Openkoda Community</a>: Become a part of Openkoda<br>
<a href="https://www.youtube.com/channel/UCN0LzuxOYIDdKDX9W0sGFlg" rel="nofollow">YouTube</a>: Learn how to use Openkoda<br>
<a href="https://www.linkedin.com/company/openkoda" rel="nofollow">LinkedIn</a>: Stay up to date<br>
<a href="https://openkoda.com/about-us/" rel="nofollow">About us</a>: Let us introduce ourselves</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🗃️ Release notes</h3><a id="user-content-️-release-notes" aria-label="Permalink: 🗃️ Release notes" href="#️-release-notes"></a></p>
<p dir="auto">Openkoda is constantly evolving. Check out the changelog:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Openkoda 1.5. 🚀</h4><a id="user-content-openkoda-15-" aria-label="Permalink: Openkoda 1.5. 🚀" href="#openkoda-15-"></a></p>
<ul dir="auto">
<li><strong>Dynamic Entities</strong>: Now create database tables, perform full CRUD operations and generate forms.</li>
<li><strong>New Dashboard UI</strong>: Enhanced for better readability and smoother navigation flow.</li>
<li><strong>Files Assignment</strong>: Support for dynamically registered entities.</li>
<li><strong>Organization-Level Email Configuration</strong>: Customize email settings at the organization level.</li>
<li><strong>Bug Fixes</strong>: Various fixes for improved app stability and performance.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Openkoda 1.4.3.</h4><a id="user-content-openkoda-143" aria-label="Permalink: Openkoda 1.4.3." href="#openkoda-143"></a></p>
<ul dir="auto">
<li><strong>Page Builder</strong>: Introducing a tool for creating custom dashboards.</li>
<li><strong>Web Forms Assistance</strong>: Streamlined web form creation based on your data model definitions.</li>
<li><strong>YAML Components Import/Export</strong>: Easily manage components such as web forms, endpoints, server code, event listeners, schedulers, and frontend resources.</li>
<li><strong>Dashboard UI</strong>: Upgrades for an improved dashboard interface.</li>
<li><strong>Updates &amp; Security</strong>: Minor adjustments and security fixes.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">🤝 Partners</h3><a id="user-content--partners" aria-label="Permalink: 🤝 Partners" href="#-partners"></a></p>
<p dir="auto"><strong>Openkoda source code is completely free and is available under the <a href="https://github.com/openkoda/openkoda/blob/main/LICENSE">MIT license</a>.​</strong></p>
<p dir="auto">Join us as a partner in transforming the software development market by delivering maximum value to your clients using Openkoda. The goal is to simplify the process of building enterprise applications, allowing developers to focus on core business logic.</p>
<p dir="auto">Learn more about <a href="https://openkoda.com/partners/" rel="nofollow">Openkoda Partner Program</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">☁️ Managed Cloud</h4><a id="user-content-️-managed-cloud" aria-label="Permalink: ☁️ Managed Cloud" href="#️-managed-cloud"></a></p>
<p dir="auto">Our enterprise managed cloud allows for easy deployment and scaling of your Openkoda applications. <a href="https://openkoda.com/contact/" rel="nofollow">Contact us</a> for more information.</p>

<p><a href="https://www.facebook.com/Openkoda/" rel="nofollow"><img alt="Openkoda Facebook" src="https://github.com/openkoda/openkoda/raw/main/openkoda/src/main/resources/public/vendor/fontawesome-free/svgs/brands/facebook.svg" width="20px"></a>
    <a href="https://www.linkedin.com/company/openkoda" rel="nofollow"><img alt="Openkoda Facebook" src="https://github.com/openkoda/openkoda/raw/main/openkoda/src/main/resources/public/vendor/fontawesome-free/svgs/brands/linkedin.svg" width="20px"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Jurvetson's personal collection of Apollo Lunar Module parts (113 pts)]]></title>
            <link>https://www.flickr.com/photos/jurvetson/albums/72157623704246792/</link>
            <guid>40502877</guid>
            <pubDate>Tue, 28 May 2024 17:03:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flickr.com/photos/jurvetson/albums/72157623704246792/">https://www.flickr.com/photos/jurvetson/albums/72157623704246792/</a>, See on <a href="https://news.ycombinator.com/item?id=40502877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-view-signature="album-header-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true">

	
	


	<div data-view-signature="album-title-desc-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true">
	<p>
		Space Collection 🚀
	</p>


	<div><p>
			2021 Video Tour: <a href="https://youtu.be/4FOF0f70Hoc" rel="noreferrer nofollow">youtu.be/4FOF0f70Hoc</a> at Future Ventures' HQ — with a focus on Apollo and flown spacecraft.  The museum includes a part of every Lunar Module that has been to the moon and some of the largest displays of Moon and Mars rock. </p><p>I try to be a good curator, gathering as much info as I can on the items which I have on display at the office.  If you have additional information on any of these, please add to the comments, or send me documents (steve at future dot ventures).</p></div>

	<p><span data-action="showMore">
			Show more
		</span>
	</p>

	</div>
	<div data-view-signature="album-stats-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true"><p><span>559 photos</span>
			<span>·</span>
		<span>4 videos</span>
		<span>·</span>
		<span>51,947 views</span>
</p>
</div>
	
	

	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reproduce GPT-2 in llm.c (484 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1795484547267834137</link>
            <guid>40502090</guid>
            <pubDate>Tue, 28 May 2024 15:58:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1795484547267834137">https://twitter.com/karpathy/status/1795484547267834137</a>, See on <a href="https://news.ycombinator.com/item?id=40502090">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Leaked OpenAI Docs Show Sam Altman Clearly Aware of Silencing Former Employees (156 pts)]]></title>
            <link>https://futurism.com/sam-altman-silencing-former-employees</link>
            <guid>40501739</guid>
            <pubDate>Tue, 28 May 2024 15:33:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/sam-altman-silencing-former-employees">https://futurism.com/sam-altman-silencing-former-employees</a>, See on <a href="https://news.ycombinator.com/item?id=40501739">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="incArticle"><p>OpenAI's credibility — and the credibility of its CEO, Sam Altman — is crumbling.</p><p>Last week, amid a surprise string of high-profile executive and safety team departures, <a href="https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release"><em>V</em><em>ox</em> revealed that</a> the ChatGPT creator had pressured employees into signing draconian non-disclosure and non-disparagement agreements by threatening to claw back exiting OpenAI employees' vested equity in the multibillion-dollar AI company.</p><p>Clawing back vested equity — in short, the amount of company ownership that an employee has gained through their months or years of working there — is a highly unusual practice to begin with. This is especially true in the startup-powered Silicon Valley, where tech workers often forgo high salaries in favor of equity agreements based on the hope that they'll get rich later when a successful startup like OpenAI eventually goes public. For OpenAI to play bizarre contractual take-backsies in exchange for narrative control over former employees would be an <a href="https://futurism.com/the-byte/openai-nda-criticism">awful look</a> for any company — let alone a supposedly "open" venture claiming it's the best one to build the imagined all-knowing AI that OpenAI's leaders say will power humanity's future.</p><p>In response to the <em>Vox</em> report, Altman apologetically took to X-formerly-Twitter to admit that yes, "there was a provision about potential equity cancellation in our previous exit docs." But according to the CEO, though the clause was there, the company never <em>actually&nbsp;</em>clawed anything back. Most importantly, he further <a href="https://futurism.com/the-byte/sam-altman-nda-superintelligent">claimed</a> that he had no knowledge of the provision.</p><p>"This is on me and one of the few times I've been genuinely embarrassed running OpenAI," Altman continued in a tone that can only be described as sheepish, "I did not know this was happening and I should have."</p><p>But <a href="https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees">according to <em>Vox's</em> latest follow-up</a>, Altman wasn't in the dark about the equity clauses, as he claimed in his tail-between-legs tweet.</p><p>Documentation reviewed by <em>Vox</em> reveals that several company leaders — including OpenAI chief strategy officer Jason Kwon, who reportedly told staffers following the initial <em>Vox </em>report that OpenAI leadership "caught" the provision "~month ago" — signed documents that plainly outlined the stifling clawback provision. The list of executives includes Altman, whose signature, according to <em>Vox</em>'s reporting, is on "incorporation documents" for the holding company that manages OpenAI equity; these documents contain "multiple passages with language that gives the company near-arbitrary authority to claw back equity from former employees" or, if employees choose not to actually return the equity, "block them from selling it" altogether.</p><p>In other words, unless someone forged the CEO's signature, he gave express permission for these clauses to exist. Outside of forgery, there are only two plausible reasons for Altman's alleged lack of knowledge: either he didn't fully read the employment contracts he was signing or he was lying.</p><p>Complicating the denials further is the way employees were reportedly treated on their way out. According to the <em>Vox</em> report, the equity provisions were no secret to OpenAI representatives handling departures, who in some cases gave outgoing employees just seven days to make the incredibly complicated decision about their future — all the while, in instances reviewed by <em>Vox</em>, emphasizing possible clawbacks.</p><p>"We want to make sure you understand that if you don't sign, it could impact your equity," one rep told an outgoing employee, according to <em>Vox</em>. "That's true for everyone, and we're just doing things by the book."</p><p>But again, as the report reiterates, this is <em>not </em>"by-the-book" behavior.</p><p>"For a company to threaten to claw back already-vested equity is egregious and unusual," Chambord Benton-Hayes, a California employment law attorney, told <em>Vox.</em></p><p>When <em>Vox</em> asked OpenAI to explain how the provisions could have possibly wound up in documents signed by Altman without Altman actually knowing about them, Kwon non-answered that "we are sorry for the distress this has caused great people who have worked hard for us."</p><p>"We have been working to fix this as quickly as possible," Kwon — who, again, also signed papers delineating this provision — continued in his statement. "We will work even harder to be better."</p><p>But that's getting harder and harder to believe. Last year, when Altman was briefly forced out of OpenAI in what was pretty much a corporate coup, those who voted to oust the CEO — many of whom departed after losing said coup — claimed that Altman had been "inconsistently candid" in his communications with the board. Altman and OpenAI are also caught up in a <a href="https://futurism.com/the-byte/law-experts-scarlett-johansson-strong-case-openai">brewing legal storm</a> with actress Scarlett Johansson, who claims that Altman copycatted her voice for OpenAI's new "Sky" AI assistant after she had explicitly turned Altman and OpenAI down. (Altman chalked Johansson's allegations up to <a href="https://www.businessinsider.com/openai-scarlett-johansson-voice-defense-sam-altman-washington-post-chatgpt-2024-5">simple miscommunication</a>.)</p><p>Meanwhile, <a href="https://futurism.com/openai-safety-worker-quit-confidence-agi">recent departures</a> have <a href="https://futurism.com/the-byte/openai-researcher-quits-criticism-superallignment">ground</a> OpenAI's "Superalignment" safety team — the ones tasked with making sure a killer AI doesn't obliterate humankind — <a href="https://www.cnbc.com/2024/05/17/openai-superalignment-sutskever-leike.html">into dust</a>. Great stuff.</p><p>On its website, OpenAI features a "<a href="https://openai.com/charter/">charter</a>" declaring that "OpenAI's mission is to ensure that artificial general intelligence (AGI) — by which we mean highly autonomous systems that outperform humans at most economically valuable work — benefits all of humanity."</p><p>"We will attempt to directly build safe and beneficial AGI," it continues, "but will also consider our mission fulfilled if our work aids others to achieve this outcome."</p><p>The document then lists a series of "principles," which the company claims it'll follow to achieve this mission. The word "transparency" is notably absent.</p><p><strong>More on OpenAI: </strong><a href="https://futurism.com/sam-altman-openai-scarlett-johansson"><em>Sam Altman Ignoring Scarlett Johansson's Lack of Consent Shows Us Exactly What Type of Person He Really Is</em></a></p><br></section></div>]]></description>
        </item>
    </channel>
</rss>