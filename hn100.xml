<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 18 Apr 2025 04:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Intuit, Owner of TurboTax, Wins Battle Against America's Taxpayers (235 pts)]]></title>
            <link>https://prospect.org/power/2025-04-17-intuit-turbotax-wins-battle-against-taxpayers-irs-direct-file/</link>
            <guid>43724267</guid>
            <pubDate>Fri, 18 Apr 2025 02:13:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prospect.org/power/2025-04-17-intuit-turbotax-wins-battle-against-taxpayers-irs-direct-file/">https://prospect.org/power/2025-04-17-intuit-turbotax-wins-battle-against-taxpayers-irs-direct-file/</a>, See on <a href="https://news.ycombinator.com/item?id=43724267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" data-transition="content" data-loop="false" itemprop="articleBody">

    <p>For nearly three decades, a cold war has raged through the halls of Congress and in high-end shellfish restaurants perched precariously on Washington, D.C.’s southern coast. The battle lines have shifted between successive administrations, sometimes tilting toward proletariat victory, and sometimes cutting fast toward total surrender to corporate America.</p>

<p>This month, thanks to the whims of the president and hefty sums of cash, Donald Trump has amended an old axiom to guarantee that nothing in life is certain but death, and paying money to file your taxes.</p>

<p>According to a <u><a href="https://apnews.com/article/irs-direct-file-tax-returns-free-trump-4bb0bca02fab9b3d06ae6f45ac67b7ab" target="_blank" aria-label="Link opens in new window (report)">report</a></u> by the Associated Press this week, the IRS is moving to shut down its free tax filing program known as <u><a href="https://directfile.irs.gov/" target="_blank" aria-label="Link opens in new window (Direct File)">Direct File</a></u>, with employees working on the program told to stall work on future iterations. The news comes after Intuit, the maker of TurboTax and the biggest player in tax preparation software, spent years tirelessly fighting any attempt by the government to bring the nightmarish American system of tax collection into line with European nations that have streamlined most citizens’ filing process down to the click of a button.</p>

<p><a href="https://prospect.org/topics/daniel-boguslaw/"><em><strong>More from Daniel Boguslaw</strong></em></a></p>

<p>Even when the Biden administration broke through in the Inflation Reduction Act to fund a pilot program for Direct File, which expanded to 25 states this tax season, Intuit didn’t stop fighting. Instead, it continued cajoling lawmakers and the White House into forcing millions of Americans to shell out hundreds, sometimes thousands, of dollars to file with expensive and confusing tax prep software.</p>

<p>A glance at Intuit’s 2025 first-quarter lobbying disclosures gets at this continued, quarter-century saga. The company <u><a href="https://disclosurespreview.house.gov/?index=%22lobbying-disclosures%22&amp;size=10&amp;keyword=%22intuit%22&amp;filters=%7B%22reportYear%22:%5B%222025%22%5D%7D&amp;sort=%5B%7B%22_score%22:true%7D,%7B%22field%22:%22registrant.name%22,%22order%22:%22asc%22%7D%5D" target="_blank" aria-label="Link opens in new window (shelled out $240,000)">shelled out $240,000</a></u> to lobby members of Congress on tax-related issues. Forty thousand dollars was doled out to <u><a href="https://disclosurespreview.house.gov/ld/ldxmlrelease/2025/Q1/301711402.xml" target="_blank" aria-label="Link opens in new window (Raffaniello &amp; Associates)">Raffaniello &amp; Associates</a></u> to curry favor on issues like “Tax Administration &amp; tax system integrity” and “Regulation of tax return preparers.” It also lobbied on implementation of Public Law 117-169, which is the <u><a href="https://www.congress.gov/117/plaws/publ169/PLAW-117publ169.pdf" target="_blank" aria-label="Link opens in new window (statute that created IRS Direct File)">statute that created IRS Direct File</a></u>.</p>

<p><u><a href="https://disclosurespreview.house.gov/ld/ldxmlrelease/2025/Q1/301696911.xml" target="_blank" aria-label="Link opens in new window (Jake Perry + Partners)">Jake Perry + Partners</a></u> received $30,000 to lobby on the same issues, including personal outreach to Elon Musk’s lackeys in Congress. According to the firm’s filing, at least part of that money was spent on “Communications with DOGE Caucus members regarding tax simplification, waste, fraud and abuse.”</p>

<p><u><a href="https://disclosurespreview.house.gov/ld/ldxmlrelease/2025/Q1/301696545.xml" target="_blank" aria-label="Link opens in new window (Wilmer Cutler Pickering Hale and Dorr LLP)">Wilmer Cutler Pickering Hale and Dorr LLP</a></u>, a law firm targeted with legal sanction by the Trump administration for employing special counsel Robert Mueller, received $60,000 for its work on behalf of Intuit. Its services included advocacy to “Enhance tax administration and tax system integrity” and “support tax simplification and voluntary compliance.” WilmerHale is <u><a href="https://www.cnn.com/2025/03/28/politics/law-firms-challenge-trump-executive-order/index.html" target="_blank" aria-label="Link opens in new window (suing the Trump administration)">suing the Trump administration</a></u> over attacks on their firm, while also cozying up to Republicans to make tax filing more expensive. Money talks.</p>

<blockquote><p>Intuit shelled out $240,000 to lobby members of Congress on tax-related issues in the first quarter of 2025.</p>
</blockquote>

<p>This work has paid off. In December, 29 House Republicans <u><a href="https://adriansmith.house.gov/sites/evo-subsites/adriansmith.house.gov/files/evo-media-document/Letter%20to%20President-Elect%20Trump%20re%20IRS%20Direct%20File%20-%20Version%20%232%20-%2012-10-2024%20%40%2005-22%20PM.pdf" target="_blank" aria-label="Link opens in new window (wrote)">wrote</a></u> to then-President-elect Trump at Mar-a-Lago, asking him to end Direct File on day one. A <u><a href="https://www.citizen.org/article/house-republicans-do-the-bidding-of-big-tax-prep/" target="_blank" aria-label="Link opens in new window (report from Public Citizen)">report from Public Citizen</a></u> showed that these lawmakers have received $1.8 million in campaign contributions from opponents of Direct File over their political careers.</p>

<p>The relatively paltry first-quarter lobbying sum pales in comparison to the big kahuna spend that Intuit made last year: a direct payment to Trump’s inaugural committee. As Politico <u><a href="https://www.politico.com/newsletters/playbook/2024/12/21/shutdown-averted-crisis-delayed-00195800" target="_blank" aria-label="Link opens in new window (reported in December)">reported in December</a></u>, Intuit handed Trump $1 million for inaugural festivities that were eventually sent indoors due to bad weather. This was a common bribe-like substance from corporate America intended to show fealty to Washington’s new overlords.</p>

<p>A company spokesperson told Politico that the donation was “part of our decades-long commitment to bipartisan advocacy … Intuit is committed to ensuring our customers’ voices are heard on important issues, and our expanded participation in the democratic process reflects our growth as a company and the variety of policy issues that impact the approximately 100 million diverse consumers and businesses we serve.”</p>

<p>“Congratulations to President <a href="https://x.com/realDonaldTrump" target="_blank" aria-label="Link opens in new window (@realDonaldTrump)">@realDonaldTrump</a> and Vice President <a href="https://x.com/JDVance" target="_blank" aria-label="Link opens in new window (@JDVance)">@JDVance</a> on your inauguration,” Intuit CEO Sasan Goodarzi, who <u><a href="https://aflcio.org/paywatch/highest-paid-ceos?industry=All&amp;state=All&amp;sp500=1&amp;combine=&amp;page=2" target="_blank" aria-label="Link opens in new window (made $27 million)">made $27 million</a></u> last year, <u><a href="https://x.com/sasan_goodarzi/status/1881796616010731688" target="_blank" aria-label="Link opens in new window (tweeted)">tweeted</a></u> on January 21st. “We encourage Washington to promote innovation to strengthen small businesses that are the backbone of the economy and to simplify the tax code to help Americans prosper.”</p>

<p>Intuit certainly knew the importance of persuading Trump to ditch the IRS free filing program. In its <u><a href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000896878/000089687825000015/intu-20250131.htm#i3a88bc58bc1b4166afb68013b05313fe_139" target="_blank" aria-label="Link opens in new window (quarterly financial statement to investors)">quarterly financial statement to investors</a></u>, Intuit listed among its risk factors “increasing competition from the public sector,” specifically IRS Direct File, which “could expand with increased awareness of and government support for the program … federal and state governments are or could become publicly funded direct competitors of the U.S. tax services industry and of Intuit. Government funded services that curtail or eliminate the role of taxpayers in preparing their own taxes could potentially have material and adverse revenue implications on us.”</p>

<p>They should have been scared. Customer satisfaction with Direct File was high, with <u><a href="https://thehill.com/opinion/finance/5248523-irs-direct-file-is-a-government-success-story/" target="_blank" aria-label="Link opens in new window (over 90 percent of users)">over 90 percent of users</a></u> ranking it as excellent or above average in surveys.</p>

<p>In 2019, ProPublica published an extensive <u><a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank" aria-label="Link opens in new window (investigation)">investigation</a></u> into Intuit’s efforts to safeguard a business model it long marketed as consumer-friendly, despite the millions of dollars lifted off of everyday Americans attempting to file their taxes on time. Intuit focused on carrying out two simultaneous objectives to ensure a maximum windfall: “stoking innovation in Silicon Valley while stifling it in Washington.” In a confidential <u><a href="https://embed.documentcloud.org/documents/6483065-Intuit-board-of-directors-presentation-2007/" target="_blank" aria-label="Link opens in new window (document)">document</a></u> obtained by ProPublica, Intuit outlines the maneuvers it undertook from 1997 to 2006 to block any attempt at making tax filing cheaper and easier for consumers. “For a decade proposals have sought to create IRS tax software or a ReturnFree Tax System; All were stopped,” the title slide reads.</p>

<p>Since 2002, Intuit and other tax preparation services have been legally required to offer a free private-sector version of what the government should have built and provided all along. But Intuit’s playbook has been to create a booby-trapped version of its expensive software, with embedded code that once hid the free offering from search engines like Google, making it exceedingly difficult for those seeking free filing to discover.</p>

<p>In 2023, Intuit was forced <u><a href="https://www.attorneygeneral.gov/taking-action/attorney-general-henry-announces-141-million-settlement-for-millions-of-americans-decieved-by-turbotax-owner-intuit/" target="_blank" aria-label="Link opens in new window (to pay out)">to pay out</a></u> over $100 million in a multistate class action lawsuit that accused the firm of tricking customers into overpaying for services that the firm is legally required to offer for free. 4.4 million consumers nationwide received checks as the result of the multistate settlement. “By requiring consumers to pay for tax-return services that should have been available for free, Intuit cheated taxpayers out of their hard earned money,” then-Pennsylvania Attorney General Michelle Henry said at the time. “Intuit’s deceptive practices and aggressive advertising campaign were unnecessary and illegal; especially when the IRS offers free tax-return services for eligible consumers.”</p>

<p>On April 15, tax filing day, Sen. Elizabeth Warren (D-MA), long a sworn foe of for-profit tax filing companies, slammed the Trump administration for its failures to simplify the filing process.</p>

<p>“Despite Treasury Secretary Bessent’s promise to keep Direct File going through the 2025 tax filing season, the long-term future of the program continues to be threatened, in no small part due to Intuit’s lobbying,” Warren wrote. “Intuit has spent nearly $4 million in 2023 and again in 2024 attempting to kill the program. During the 2024 election cycle, Intuit joined other commercial tax preparation companies to make large donations to Republican congressmembers who later worked to eliminate Direct File.”</p>

<p>Yet after tens of millions in lobbying, hundreds of millions in lawsuits, and a cool million for Trump’s inauguration, it seems that Intuit’s ceaseless spending has paid off.</p>


    
    

    </div><p><span><span><strong>I’m writing to you today</strong> with a sense of urgency that I haven’t felt since I began my journalism career. As executive editor of <i><span>The American Prospect</span></i><span>, I’ve witnessed firsthand how independent journalism serves as a crucial bulwark against the erosion of our democratic institutions. Today, that role is more vital than ever. </span><u><a href="https://secure.actblue.com/donate/tap-spring-2025?refcode=articlebottom_041625"><span><span><span><span>Can you step up today and show your support?</span></span></span></span></a></u><p>

The winds of authoritarianism are blowing stronger. We’re seeing alarming signs of a coordinated effort to silence critical voices and undermine the very foundations that support progressive causes. As Bob Kuttner presciently wrote in our August 2024 issue, </p><u><a href="https://prospect.org/power/2024-07-30-lefts-fragile-foundations/"><span>a weaponized IRS could attack the very foundations of the progressive movement</span></a></u>.&nbsp;We need readers to step up and help us dig in for the long haul.<p>

We’re falling behind in our spring fundraising campaign, and with so much at stake we can’t afford to come up short. If you value fearless, independent journalism that holds the powerful accountable and defends democracy, now is the time to step up. <i><span>The American Prospect </span></i><span>depends on reader support to stay in the fight. Pitch in today and help us close the gap. </span></p><u><a href="https://secure.actblue.com/donate/tap-spring-2025?refcode=articlebottom_041625"><span>Please consider making a donation today.</span></a></u><p>

<em>–David Dayen, Executive Editor</em></p></span></span></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DHL suspends B2C shipments over 800 USD until further notice (124 pts)]]></title>
            <link>https://www.dhl.com/au-en/home/important-information/2025/shipments-to-the-united-states-with-a-customs-value-exceeding-usd-800.html</link>
            <guid>43724123</guid>
            <pubDate>Fri, 18 Apr 2025 01:45:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dhl.com/au-en/home/important-information/2025/shipments-to-the-united-states-with-a-customs-value-exceeding-usd-800.html">https://www.dhl.com/au-en/home/important-information/2025/shipments-to-the-united-states-with-a-customs-value-exceeding-usd-800.html</a>, See on <a href="https://news.ycombinator.com/item?id=43724123">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text-ba122cfe75">
     
<ul>
 <li><span><strong>As a result of recent U.S. Customs regulatory updates, we are experiencing multi-day transit delays to the U.S from any origin for shipments with a declared customs value exceeding USD 800.<br></strong></span></li>
 <li><span><strong>Effective Monday, April 21st, 2025, and until further notice, we will temporarily suspend the collection and shipping of business-to-consumer (B2C) shipments to private individuals in the United States where the declared customs value exceeds USD 800.<br>
     Shipments – both B2B &amp; B2C - with a declarable customs value below USD 800 are not affected by the suspension. </strong></span></li>
 <li><span><strong>Business-to-business (B2B) shipments to U.S. companies with a declarable value above USD 800 are not affected by the suspension, though they may also face delays.</strong></span></li>
</ul>
<p><span>Effective April 5, 2025, all shipments to the U.S. with a declared customs value over USD 800 require formal entry processing - down from the previous USD 2,500 threshold due to new U.S. Customs regulations.</span></p>
<p><span>This change has caused a surge in formal customs clearances, which we are handling around the clock.</span></p>
<p><span>While we are working diligently to scale up and manage this increase, shipments over USD 800—regardless of origin—may experience multi-day delays.</span></p>
<p><span>To manage this, starting Monday, April 21, 2025, and until further notice, we will temporarily suspend B2C shipments to private individuals in the U.S. where the declared value exceeds USD 800.</span></p>
<p><span>Business-to-business (B2B) shipments to U.S. companies with a declarable value above USD 800 are not affected by the temporary suspension, though they may also face delays.</span></p>
<p><span>This is a temporary measure, and we will share updates as the situation evolves.</span></p>     
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Potatoes in the Mail (219 pts)]]></title>
            <link>https://facts.usps.com/mailing-potatoes/</link>
            <guid>43722486</guid>
            <pubDate>Thu, 17 Apr 2025 21:35:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://facts.usps.com/mailing-potatoes/">https://facts.usps.com/mailing-potatoes/</a>, See on <a href="https://news.ycombinator.com/item?id=43722486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
        <p>
          <h3>Postal Facts - U.S. Postal Service</h3>
        </p>
  <div data-animate-down="ha-header-show" data-animate-up="ha-header-hide">
  	<p><a href="https://facts.usps.com/"><img src="https://facts.usps.com/wp-content/themes/pfacts/images/usps_postalfacts_head_dark.png?20180320" alt="Postal Facts - United States Postal Service"></a>
  	</p>
  </div>


	<div id="primary">
		<main id="main" role="main">

		
<article id="post-1077">
	<!-- .entry-header -->

	<div>
    	<div id="fact1077">
			<div>
					<p><span>SPUDTACULAR!</span></p><p>potatoes in the mail</p>
            	</div>
         	<p>It's SPUDTACULAR! As with coconuts, potatoes can be mailed without a box. Simply write the address it's going to and  your return addresses on the spud, have it weighed for appropriate postage, and it can be shipped as-is. Let someone know they are special. Send a tater! </p>
         	
			
			
			
		</div>
		   		<div>
			<figure id="attachment_1078" aria-describedby="caption-attachment-1078"><img decoding="async" src="https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-scaled.jpg" alt="" width="380" height="257" srcset="https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-scaled.jpg 2560w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-300x203.jpg 300w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-850x575.jpg 850w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-150x101.jpg 150w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-768x520.jpg 768w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-1536x1039.jpg 1536w, https://facts.usps.com/wp-content/uploads/POTATO-IN-THE-MAIL-2048x1385.jpg 2048w" sizes="(max-width: 380px) 100vw, 380px"><figcaption id="caption-attachment-1078">SPUDTACULAR!</figcaption></figure>
   		</div>
			
		</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

		</main><!-- #main -->
	</div><!-- #primary -->


	</div><div>
            	
                <p><strong>Trademarks</strong></p>
                <p>The Sonic Eagle Logo, the trade dress of USPS packaging, the Letter Carrier Uniform and the Postal Truck and the following marks are among the many trademarks owned by the United States Postal Service: Click-N-Ship®, Deliver The Win®, EDDM®, ePostage®, Every Door Direct Mail®, Express Mail®, First-Class™, First-Class Mail®, First-Class Package International Service®, Forever®, Global Express Guaranteed®, IMb®, Informed Delivery®, Intelligent Mail®, Label Broker™, Parcel Select®, P.O. Box™, Post Office®, Pony Express®, Postal Inspection Service™, PostalOne!®, Postal Police®, #PostalProud®, Priority Mail Express International®, Priority Mail Flat Rate®, Priority Mail International®, Priority: You®, Registered Mail™, Standard Mail®, The Postal Store®, United States Postal Inspection Service®, United States Postal Service®, U.S. Mail®, U.S. Postal Inspector™, U.S. Postal Service®, USPS®, USPS BlueEarth®, USPS Mobile®, USPS Operation Santa®, USPS Tracking®, usps.com®,&nbsp;We are people delivering to people™, ZIP+4® and ZIP Code™. This is not a comprehensive list of all Postal Service trademarks.</p>
<p>Non-Postal Trademarks</p>
<p>Dollar General®, Forest Stewardship Council®, How2Recycle®, McDonald’s®, National Dog Bite Prevention Week®, Starbucks®, Subway®, Sustainable Forestry Initiative®, The Climate Registry®.</p>
<p>Postal Facts 2024 provides the public with information about the U.S. Postal Service. The facts in this publication may be reproduced for the purpose of stating the fact itself, in a business, informational or academic context and the like, and in the body of text discussing factual subject matter relevant to the fact being presented. However, these facts may become outdated after publication and seeking the latest information is advised.</p>
<p>Produced by U.S. Postal Service Corporate Communications</p>
<p>© 2024 United States Postal Service. All rights reserved.</p>
<p><a href="https://www.facts.usps.com/">facts.usps.com</a></p>
				<p>© 2016-2025 United States Postal Service. All rights reserved.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S.-born man from Georgia held for ICE under Florida's new anti-immigration law (220 pts)]]></title>
            <link>https://georgiarecorder.com/2025/04/17/georgia-born-man-held-for-ice-under-floridas-new-anti-immigration-law/</link>
            <guid>43721170</guid>
            <pubDate>Thu, 17 Apr 2025 19:35:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://georgiarecorder.com/2025/04/17/georgia-born-man-held-for-ice-under-floridas-new-anti-immigration-law/">https://georgiarecorder.com/2025/04/17/georgia-born-man-held-for-ice-under-floridas-new-anti-immigration-law/</a>, See on <a href="https://news.ycombinator.com/item?id=43721170">Hacker News</a></p>
Couldn't get https://georgiarecorder.com/2025/04/17/georgia-born-man-held-for-ice-under-floridas-new-anti-immigration-law/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 2.5 Flash (622 pts)]]></title>
            <link>https://developers.googleblog.com/en/start-building-with-gemini-25-flash/</link>
            <guid>43720845</guid>
            <pubDate>Thu, 17 Apr 2025 19:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/start-building-with-gemini-25-flash/">https://developers.googleblog.com/en/start-building-with-gemini-25-flash/</a>, See on <a href="https://news.ycombinator.com/item?id=43720845">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
      
    

    

    

    <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Tulsee+Doshi">Tulsee Doshi</a>
            
              <span>Director of Product Management</span>
            
            
              <span>Gemini</span>
            
          </p>
        

      
      </section>

    
    <div>
          

<div>
    <p data-block-key="w22bj">Today we are rolling out an early version of <b>Gemini 2.5 Flash</b> in <b>preview</b> through the Gemini API via <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-04-17">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a>. Building upon the popular foundation of 2.0 Flash, this new version delivers a major upgrade in reasoning capabilities, while still prioritizing speed and cost. Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off. The model also allows developers to set thinking budgets to find the right tradeoff between quality, cost, and latency. Even with <b>thinking off,</b> developers can maintain the fast speeds of 2.0 Flash, and improve performance.</p><p data-block-key="b171q">Our Gemini 2.5 models are thinking models, capable of reasoning through their thoughts before responding. Instead of immediately generating an output, the model can perform a "thinking" process to better understand the prompt, break down complex tasks, and plan a response. On complex tasks that require multiple steps of reasoning (like solving math problems or analyzing research questions), the thinking process allows the model to arrive at more accurate and comprehensive answers. In fact, Gemini 2.5 Flash performs strongly on <a href="https://lmarena.ai/?leaderboard">Hard Prompts in LMArena</a>, second only to 2.5 Pro.</p>
</div>   

<div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/comparison-table-LLM.original.png" alt="Comparison table showing price and performance metrics for LLMs"></p><p>
                    2.5 Flash has comparable metrics to other leading models for a fraction of the cost and size.
                </p>
            
        
    </div>
  <div>
    <h2 data-block-key="w22bj">Our most cost-efficient thinking model</h2><p data-block-key="15dd0">2.5 Flash continues to lead as the model with the best price-to-performance ratio.</p>
</div>   

<div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2.5-Flash-price-to-performance-compariso.original.png" alt="Gemini 2.5 Flash price-to-performance comparison"></p><p>
                    Gemini 2.5 Flash adds another model to Google’s pareto frontier of cost to quality.*
                </p>
            
        
    </div>
  <div>
    <h2 data-block-key="hippi">Fine-grained controls to manage thinking</h2><p data-block-key="4g2lu">We know that different use cases have different tradeoffs in quality, cost, and latency. To give developers flexibility, we’ve enabled setting a <b>thinking budget</b> that offers fine-grained control over the maximum number of tokens a model can generate while thinking. A higher budget allows the model to reason further to improve quality. Importantly, though, the budget sets a cap on how much 2.5 Flash can think, but the model does not use the full budget if the prompt does not require it.</p>
</div>   

<div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_s_b_s_scaling_graphs.original.png" alt="Plot graphs show improvements in reasoning quality as thinking budget increases"></p><p>
                    Improvements in reasoning quality as thinking budget increases.
                </p>
            
        
    </div>
  <div>
    <p data-block-key="hippi">The model is trained to know how long to think for a given prompt, and therefore automatically decides how much to think based on the perceived task complexity.</p><p data-block-key="c6ud">If you want to keep the lowest cost and latency while still improving performance over 2.0 Flash, <b>set the thinking budget to 0.</b> You can also choose to <b>set a specific token budget</b> for the thinking phase using a parameter in the API or the slider in Google AI Studio and in Vertex AI. The budget can range from 0 to 24576 tokens for 2.5 Flash.</p><p data-block-key="bm9va">The following prompts demonstrate how much reasoning may be used in the 2.5 Flash’s default mode.</p><h3 data-block-key="4qsi3"><b><br>Prompts requiring low reasoning:</b></h3><p data-block-key="ee1fc"><b>Example 1:</b> “Thank you” in Spanish</p><p data-block-key="dfdib"><b>Example 2:</b> How many provinces does Canada have?</p><h3 data-block-key="5r2iv"><b><br>Prompts requiring medium reasoning:</b></h3><p data-block-key="2hnrv"><b>Example 1:</b> You roll two dice. What’s the probability they add up to 7?</p><p data-block-key="t908"><b>Example 2:</b> My gym has pickup hours for basketball between 9-3pm on MWF and between 2-8pm on Tuesday and Saturday. If I work 9-6pm 5 days a week and want to play 5 hours of basketball on weekdays, create a schedule for me to make it all work.</p><h3 data-block-key="6ooqr"><b><br>Prompts requiring high reasoning:</b></h3><p data-block-key="99tu"><b>Example 1:</b> A cantilever beam of length L=3m has a rectangular cross-section (width b=0.1m, height h=0.2m) and is made of steel (E=200 GPa). It is subjected to a uniformly distributed load w=5 kN/m along its entire length and a point load P=10 kN at its free end. Calculate the maximum bending stress (σ_max).</p><p data-block-key="c8ugt"><b>Example 2:</b> Write a function <code>evaluate_cells(cells: Dict[str, str]) -&gt; Dict[str, float]</code> that computes the values of spreadsheet cells.</p><p data-block-key="4reqs">Each cell contains:</p><ul><li data-block-key="52odg">A number (e.g., <code>"3"</code>)</li></ul><ul><li data-block-key="7pvlf">Or a formula like <code>"=A1 + B1 * 2"</code> using <code>+</code>, <code>-</code>, <code>*</code>,<code>/</code> and other cells.</li></ul><p data-block-key="2b2uc">Requirements:</p><ul><li data-block-key="p7co">Resolve dependencies between cells.</li></ul><ul><li data-block-key="b35hd">Handle operator precedence (<code>*/</code> before <code>+-</code>).</li></ul><ul><li data-block-key="b432o">Detect cycles and raise <code>ValueError("Cycle detected at &lt;cell&gt;")</code>.</li></ul><ul><li data-block-key="2884i">No <code>eval()</code>. Use only built-in libraries.</li></ul><h2 data-block-key="nq6j"><br>Start building with Gemini 2.5 Flash today</h2><p data-block-key="erb39">Gemini 2.5 Flash with thinking capabilities is now available in preview via the <a href="https://ai.google.dev/gemini-api/docs/thinking">Gemini API</a> in <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-04-17">Google AI Studio</a> and in <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a>, and in a dedicated dropdown in the <a href="http://gemini.google.com/">Gemini app</a>. We encourage you to experiment with the <code>thinking_budget</code> parameter and explore how controllable reasoning can help you solve more complex problems.</p>
</div>   

<div><pre><span></span><span>from</span> <span>google</span> <span>import</span> <span>genai</span>

<span>client</span> <span>=</span> <span>genai</span><span>.</span><span>Client</span><span>(</span><span>api_key</span><span>=</span><span>"GEMINI_API_KEY"</span><span>)</span>

<span>response</span> <span>=</span> <span>client</span><span>.</span><span>models</span><span>.</span><span>generate_content</span><span>(</span>
  <span>model</span><span>=</span><span>"gemini-2.5-flash-preview-04-17"</span><span>,</span>
  <span>contents</span><span>=</span><span>"You roll two dice. What’s the probability they add up to 7?"</span><span>,</span>
  <span>config</span><span>=</span><span>genai</span><span>.</span><span>types</span><span>.</span><span>GenerateContentConfig</span><span>(</span>
    <span>thinking_config</span><span>=</span><span>genai</span><span>.</span><span>types</span><span>.</span><span>ThinkingConfig</span><span>(</span>
      <span>thinking_budget</span><span>=</span><span>1024</span>
    <span>)</span>
  <span>)</span>
<span>)</span>

<span>print</span><span>(</span><span>response</span><span>.</span><span>text</span><span>)</span>
</pre></div>  <div>
    <p data-block-key="hippi">Find detailed API references and thinking guides in our <a href="https://ai.google.dev/gemini-api/docs/thinking#set-budget">developer docs</a> or get started with <a href="https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_thinking.ipynb">code examples</a> from the <a href="https://github.com/google-gemini/cookbook/">Gemini Cookbook</a>.</p><p data-block-key="637cu">We will continue to improve Gemini 2.5 Flash, with more coming soon, before we make it generally available for full production use.</p><p data-block-key="7esdg"><br><sup>*</sup><sub><sup>Model pricing is sourced from Artificial Analysis &amp; Company Documentation</sup></sub></p>
</div> 
      </div>
    

    

    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AgentAPI – HTTP API for Claude Code, Goose, Aider, and Codex (108 pts)]]></title>
            <link>https://github.com/coder/agentapi</link>
            <guid>43719447</guid>
            <pubDate>Thu, 17 Apr 2025 16:54:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/coder/agentapi">https://github.com/coder/agentapi</a>, See on <a href="https://news.ycombinator.com/item?id=43719447">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">AgentAPI</h2><a id="user-content-agentapi" aria-label="Permalink: AgentAPI" href="#agentapi"></a></p>
<p dir="auto">Control <a href="https://github.com/anthropics/claude-code">Claude Code</a>, <a href="https://github.com/block/goose">Goose</a>, <a href="https://github.com/Aider-AI/aider">Aider</a>, and <a href="https://github.com/openai/codex">Codex</a> with an HTTP API.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/28019628/434359775-11685cf3-324b-4e72-b8e9-5bb8ceede785.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDQ5NDM3MDEsIm5iZiI6MTc0NDk0MzQwMSwicGF0aCI6Ii8yODAxOTYyOC80MzQzNTk3NzUtMTE2ODVjZjMtMzI0Yi00ZTcyLWI4ZTktNWJiOGNlZWRlNzg1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDE4VDAyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQxZmNmMDQwMDMwYzk4MjU2ZTIwNTlmZDczMWExZGY2MTkxMGIyMTJmYTFmODgwOWExYmQ3Y2UwNzYwODY2ZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uOfa3XZaOYaL6-DMgZkb0YAkBf0XOnV7QtRN-7mMyBM"><img src="https://private-user-images.githubusercontent.com/28019628/434359775-11685cf3-324b-4e72-b8e9-5bb8ceede785.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDQ5NDM3MDEsIm5iZiI6MTc0NDk0MzQwMSwicGF0aCI6Ii8yODAxOTYyOC80MzQzNTk3NzUtMTE2ODVjZjMtMzI0Yi00ZTcyLWI4ZTktNWJiOGNlZWRlNzg1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDE4VDAyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQxZmNmMDQwMDMwYzk4MjU2ZTIwNTlmZDczMWExZGY2MTkxMGIyMTJmYTFmODgwOWExYmQ3Y2UwNzYwODY2ZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uOfa3XZaOYaL6-DMgZkb0YAkBf0XOnV7QtRN-7mMyBM" alt="chat demo" data-animated-image=""></a></p>
<p dir="auto">You can use AgentAPI:</p>
<ul dir="auto">
<li>to build a unified chat interface for coding agents</li>
<li>as a backend in an MCP server that lets one agent control another coding agent</li>
<li>to create a tool that submits pull request reviews to an agent</li>
<li>and much more!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Install <code>agentapi</code> by either:</p>
<ul dir="auto">
<li>Downloading the latest release binary from the <a href="https://github.com/coder/agentapi/releases">releases page</a></li>
<li>Or building from source:
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/coder/agentapi@latest"><pre>go install github.com/coder/agentapi@latest</pre></div>
</li>
</ul>
</li>
<li>
<p dir="auto">Verify the installation:</p>

<blockquote>
<p dir="auto">On macOS, if you're prompted that the system was unable to verify the binary, go to <code>System Settings -&gt; Privacy &amp; Security</code>, click "Open Anyway", and run the command again.</p>
</blockquote>
</li>
<li>
<p dir="auto">Run a Claude Code server (assumes <code>claude</code> is installed on your system and in the <code>PATH</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="agentapi server -- claude"><pre>agentapi server -- claude</pre></div>
<blockquote>
<p dir="auto">If you're getting an error that <code>claude</code> is not in the <code>PATH</code> but you can run it from your shell, try <code>which claude</code> to get the full path and use that instead.</p>
</blockquote>
</li>
<li>
<p dir="auto">Send a message to the agent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -X POST localhost:3284/message \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;content&quot;: &quot;Hello, agent!&quot;, &quot;type&quot;: &quot;user&quot;}'"><pre>curl -X POST localhost:3284/message \
  -H <span><span>"</span>Content-Type: application/json<span>"</span></span> \
  -d <span><span>'</span>{"content": "Hello, agent!", "type": "user"}<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto">Get the conversation history:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl localhost:3284/messages"><pre>curl localhost:3284/messages</pre></div>
</li>
<li>
<p dir="auto">Try the demo web chat interface at <a href="https://coder.github.io/agentapi/chat" rel="nofollow">https://coder.github.io/agentapi/chat</a>. Even though it's hosted on GitHub Pages, the chat will connect to your AgentAPI server running on <code>localhost:3284</code>.</p>
<blockquote>
<p dir="auto">If you're having trouble connecting to the demo chat on Safari, it's likely because it's blocking an HTTP-only connection to localhost. The demo may work in a different browser.</p>
</blockquote>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI Commands</h2><a id="user-content-cli-commands" aria-label="Permalink: CLI Commands" href="#cli-commands"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>agentapi server</code></h3><a id="user-content-agentapi-server" aria-label="Permalink: agentapi server" href="#agentapi-server"></a></p>
<p dir="auto">Run an HTTP server that lets you control an agent. If you'd like to start an agent with additional arguments, pass the full agent command after the <code>--</code> flag.</p>
<div dir="auto" data-snippet-clipboard-copy-content="agentapi server -- claude --allowedTools &quot;Bash(git*) Edit Replace&quot;"><pre>agentapi server -- claude --allowedTools <span><span>"</span>Bash(git*) Edit Replace<span>"</span></span></pre></div>
<p dir="auto">You may also use <code>agentapi</code> to run the Aider and Goose agents:</p>
<div dir="auto" data-snippet-clipboard-copy-content="agentapi server -- aider --model sonnet --api-key anthropic=sk-ant-apio3-XXX
agentapi server -- goose"><pre>agentapi server -- aider --model sonnet --api-key anthropic=sk-ant-apio3-XXX
agentapi server -- goose</pre></div>
<p dir="auto">An OpenAPI schema is available in <a href="https://github.com/coder/agentapi/blob/main/openapi.json">openapi.json</a>.</p>
<p dir="auto">By default, the server runs on port 3284. Additionally, the server exposes the same OpenAPI schema at <a href="http://localhost:3284/openapi.json" rel="nofollow">http://localhost:3284/openapi.json</a> and the available endpoints in a documentation UI at <a href="http://localhost:3284/docs" rel="nofollow">http://localhost:3284/docs</a>.</p>
<p dir="auto">There are 4 endpoints:</p>
<ul dir="auto">
<li>GET <code>/messages</code> - returns a list of all messages in the conversation with the agent</li>
<li>POST <code>/message</code> - sends a message to the agent. When a 200 response is returned, AgentAPI has detected that the agent started processing the message</li>
<li>GET <code>/status</code> - returns the current status of the agent, either "stable" or "running"</li>
<li>GET <code>/events</code> - an SSE stream of events from the agent: message and status updates</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>agentapi attach</code></h3><a id="user-content-agentapi-attach" aria-label="Permalink: agentapi attach" href="#agentapi-attach"></a></p>
<p dir="auto">Attach to a running agent's terminal session.</p>
<div dir="auto" data-snippet-clipboard-copy-content="agentapi attach --url localhost:3284"><pre>agentapi attach --url localhost:3284</pre></div>
<p dir="auto">Press <code>ctrl+c</code> to detach from the session.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">AgentAPI runs an in-memory terminal emulator. It translates API calls into appropriate terminal keystrokes and parses the agent's outputs into individual messages.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Splitting terminal output into messages</h3><a id="user-content-splitting-terminal-output-into-messages" aria-label="Permalink: Splitting terminal output into messages" href="#splitting-terminal-output-into-messages"></a></p>
<p dir="auto">There are 2 types of messages:</p>
<ul dir="auto">
<li>User messages: sent by the user to the agent</li>
<li>Agent messages: sent by the agent to the user</li>
</ul>
<p dir="auto">To parse individual messages from the terminal output, we take the following steps:</p>
<ol dir="auto">
<li>The initial terminal output, before any user messages are sent, is treated as the agent's first message.</li>
<li>When the user sends a message through the API, a snapshot of the terminal is taken before any keystrokes are sent.</li>
<li>The user message is then submitted to the agent. From this point on, any time the terminal output changes, a new snapshot is taken. It's diffed against the initial snapshot, and any new text that appears below the initial content is treated as the agent's next message.</li>
<li>If the terminal output changes again before a new user message is sent, the agent message is updated.</li>
</ol>
<p dir="auto">This lets us split the terminal output into a sequence of messages.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Removing TUI elements from agent messages</h3><a id="user-content-removing-tui-elements-from-agent-messages" aria-label="Permalink: Removing TUI elements from agent messages" href="#removing-tui-elements-from-agent-messages"></a></p>
<p dir="auto">Each agent message contains some extra bits that aren't useful to the end user:</p>
<ul dir="auto">
<li>The user's input at the beginning of the message. Coding agents often echo the input back to the user to make it visible in the terminal.</li>
<li>An input box at the end of the message. This is where the user usually types their input.</li>
</ul>
<p dir="auto">AgentAPI automatically removes these.</p>
<ul dir="auto">
<li>For user input, we strip the lines that contain the text from the user's last message.</li>
<li>For the input box, we look for lines at the end of the message that contain common TUI elements, like <code>&gt;</code> or <code>------</code>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What will happen when Claude Code, Goose, Aider, or Codex update their TUI?</h3><a id="user-content-what-will-happen-when-claude-code-goose-aider-or-codex-update-their-tui" aria-label="Permalink: What will happen when Claude Code, Goose, Aider, or Codex update their TUI?" href="#what-will-happen-when-claude-code-goose-aider-or-codex-update-their-tui"></a></p>
<p dir="auto">Splitting the terminal output into a sequence of messages should still work, since it doesn't depend on the TUI structure. The logic for removing extra bits may need to be updated to account for new elements. AgentAPI will still be usable, but some extra TUI elements may become visible in the agent messages.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto">Pending feedback, we're considering the following features:</p>
<ul dir="auto">
<li><a href="https://github.com/coder/agentapi/issues/1" data-hovercard-type="issue" data-hovercard-url="/coder/agentapi/issues/1/hovercard">Support the MCP protocol</a></li>
<li><a href="https://github.com/coder/agentapi/issues/2" data-hovercard-type="issue" data-hovercard-url="/coder/agentapi/issues/2/hovercard">Support the Agent2Agent Protocol</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Long-term vision</h2><a id="user-content-long-term-vision" aria-label="Permalink: Long-term vision" href="#long-term-vision"></a></p>
<p dir="auto">In the short term, AgentAPI solves the problem of how to programmatically control coding agents. As time passes, we hope to see the major agents release proper SDKs. One might wonder whether AgentAPI will still be needed then. We think that depends on whether agent vendors decide to standardize on a common API, or each sticks with a proprietary format.</p>
<p dir="auto">In the former case, we'll deprecate AgentAPI in favor of the official SDKs. In the latter case, our goal will be to make AgentAPI a universal adapter to control any coding agent, so a developer using AgentAPI can switch between agents without changing their code.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AGI Is Still 30 Years Away – Ege Erdil and Tamay Besiroglu (147 pts)]]></title>
            <link>https://www.dwarkesh.com/p/ege-tamay</link>
            <guid>43719280</guid>
            <pubDate>Thu, 17 Apr 2025 16:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dwarkesh.com/p/ege-tamay">https://www.dwarkesh.com/p/ege-tamay</a>, See on <a href="https://news.ycombinator.com/item?id=43719280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><a href="https://www.lesswrong.com/users/ege-erdil" rel="">Ege Erdil</a><span> and </span><a href="https://tamaybesiroglu.com/" rel="">Tamay Besiroglu</a><span> have 2045+ timelines, think the whole "alignment" framing is wrong, don't think an intelligence explosion is plausible, but are convinced we'll see explosive economic growth.</span></p><p><span>This discussion offers a totally different scenario than </span><a href="https://www.dwarkesh.com/p/scott-daniel" rel="">my recent interview with Scott and Daniel</a><span>.</span></p><p><span>Ege and Tamay are the co-founders of </span><a href="https://www.mechanize.work/" rel="">Mechanize</a><span>, a startup dedicated to fully automating work. Before founding Mechanize, Ege and Tamay worked on AI forecasts at </span><a href="https://epoch.ai/" rel="">Epoch AI</a><span>.</span></p><p><span>Watch on </span><a href="https://youtu.be/WLBsUarvWTw" rel="">Youtube</a><span>; listen on </span><a href="https://podcasts.apple.com/us/podcast/agi-is-still-30-years-away-ege-erdil-tamay-besiroglu/id1516093381?i=1000703894255" rel="">Apple Podcasts</a><span> or </span><a href="https://open.spotify.com/episode/68eeIiy3mT6PRlrTej9dtq?si=8bd51bdc846e47f6" rel="">Spotify</a><span>.</span></p><ul><li><p><a href="https://workos.com/" rel="">WorkOS</a><span> makes it easy to become enterprise-ready. With simple APIs for essential enterprise features like SSO and SCIM, WorkOS helps companies like Vercel, Plaid, and OpenAI meet the requirements of their biggest customers. To learn more about how they can help you do the same, visit </span><a href="https://workos.com/" rel="">workos.com</a></p></li><li><p><a href="https://scale.com/dwarkesh" rel="">Scale’s</a><span> Data Foundry gives major AI labs access to high-quality data to fuel post-training, including advanced reasoning capabilities. If you’re an AI researcher or engineer, learn about how Scale’s Data Foundry and research lab, SEAL, can help you go beyond the current frontier at </span><a href="https://scale.com/dwarkesh" rel="">scale.com/dwarkesh</a></p></li><li><p><a href="http://aistudio.google.com/" rel="">Google's</a><span> Gemini Pro 2.5 is </span><em>the </em><span>model we use the most at Dwarkesh Podcast: </span><a href="https://huggingface.co/spaces/dwarkesh/transcriber" rel="">it helps us generate transcripts</a><span>, </span><a href="https://huggingface.co/spaces/dwarkesh/producer" rel="">identify interesting clips</a><span>, and code up new tools. If you want to try it for yourself, it's now available in Preview with higher rate limits! Start building with it today at </span><a href="http://aistudio.google.com/" rel="">aistudio.google.com</a><span>.</span></p></li></ul><p><span>To sponsor a future episode, visit </span><a href="https://www.dwarkesh.com/p/advertise" rel="">dwarkesh.com/advertise</a><span>.</span></p><p>(00:00:00) - AGI will take another 3 decades</p><p>(00:22:27) - Even reasoning models lack animal intelligence</p><p>(00:45:04) - Intelligence explosion</p><p>(01:00:57) - Ege &amp; Tamay’s story</p><p>(01:06:24) - Explosive economic growth</p><p>(01:33:00) - Will there be a separate AI economy?</p><p>(01:47:08) - Can we predictably influence the future?</p><p>(02:19:48) - Arms race dynamic</p><p>(02:29:48) - Is superintelligence a real thing?</p><p>(02:35:45) - Reasons not to expect explosive growth</p><p>(02:49:00) - Fully automated firms</p><p>(02:54:43) - Will central planning work after AGI?</p><p>(02:58:20) - Career advice</p><p><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:00:00</em><br><span>Today, I’m chatting with </span><a href="https://tamaybesiroglu.com/" rel="">Tamay Besiroglu</a><span> and </span><a href="https://twitter.com/EgeErdil2?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" rel="">Ege Erdil</a><span>. They were previously running </span><a href="https://epoch.ai/" rel="">Epoch AI</a><span> and are now launching Mechanize, which is a company dedicated to automating all work. One of the interesting points you made recently, Tamay, is that the whole idea of the intelligence explosion is mistaken or misleading. Why don’t you explain what you’re talking about there?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:00:22</em><br><span>Yeah, I think it’s not a very useful concept. It’s kind of like calling the Industrial Revolution a horsepower explosion. Sure, during the Industrial Revolution, we saw this drastic acceleration in raw physical power, but there are many other things that were maybe equally important in explaining the acceleration of growth and technological change that we saw during the Industrial Revolution.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:00:42</em><br><span>What is a way to characterize the broader set of things that the horsepower perspective would miss about the Industrial Revolution?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:00:50</em><br><span>So I think in the case of the Industrial Revolution, it was a bunch of these complementary changes to many different sectors in the economy. So you had agriculture, you had transportation, you had law and finance, you had urbanization and moving from rural areas into cities. There were just many different innovations that happened simultaneously that gave rise to this change in the way of economically organizing our society.</span><br><span>It wasn’t just that we had more horsepower. I mean, that was part of it, but that’s not the kind of central thing to focus on when thinking about the Industrial Revolution. And I think similarly, for the development of AI, sure, we’ll get a lot of very smart AI systems, but that will be one part among very many different moving parts that explain why we expect to get this transition and this acceleration and growth and technological change.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:01:46</em><br><span>I want to better understand how you think about that broader transformation. Before we do, the other really interesting part of your worldview is that you have longer timelines to get to AGI than most of the people in San Francisco who think about AI. When do you expect a drop-in remote worker replacement?</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:02:05</em><br><span>Maybe for me, that would be around 2045.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:02:10</span></em><br><span>Wow. Wait, and you?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:02:11</em><br><span>Again, I’m a little bit more bullish. I mean, it depends what you mean by “drop in remote worker“ and whether it’s able to do literally everything that can be done remotely, or do most things.</span><br><em><strong>Ege Erdil</strong><span> 00:02:21</span></em><br><span>I’m saying literally everything.</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:02:22</em><br><span>For literally everything. Just shade Ege’s predictions by five years or by 20% or something.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:02:27</em><br><span>Why? Because we’ve seen so much progress over even the last few years. We’ve gone from Chat GPT two years ago to now we have models that can literally do reasoning, are better coders than me, and I studied software engineering in college. I mean, I did become a podcaster, I’m not saying I’m the best coder in the world.</span><br><span>But if you made this much progress in the last two years, why would it take another 30 to get to full automation of remote work?</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:03:01</em><br><span>So I think that a lot of people have this intuition that progress has been very fast. They look at the trend lines and just extrapolate; obviously, it’s going to happen in, I don’t know, 2027 or 2030 or whatever. They’re just very bullish. And obviously, that’s not a thing you can literally do.</span><br><span>There isn’t a trend you can literally extrapolate of “when do we get to full automation?”. Because if you look at the fraction of the economy that is actually automated by AI, it’s very small. So if you just extrapolate that trend, which is something, say, </span><a href="https://en.wikipedia.org/wiki/Robin_Hanson" rel="">Robin Hanson</a><span> likes to do, you’re going to say, “well, it’s going to take centuries” or something.</span><br><span>Now, we don’t agree with that view. But I think one way of thinking about this is how many big things are there? How many core capabilities, competences are there that the AI systems need to be good at in order to have this very broad economic impact, maybe 10x acceleration and growth or something? How many things have you gotten over the past 10 years, 15 years? And we also have this compute-centric view…</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:04:05</em><br><span>So just to double click on that, I think what Ege is referring to is, if you look at the past 10 years of AI progress, we’ve gone through about nine or 10 orders of magnitude of compute, and we got various capabilities that were unlocked. So in the early period, people were solving gameplay on specific games, on very complex games. And that happened from 2015 to 2020, Go and Chess and Dota and other games. And then you had maybe sophisticated language capabilities that were unlocked with these large language models, and maybe advanced abstract reasoning and coding and maybe math. That was maybe another big capability that got unlocked.</span><br><span>And so maybe there are a couple of these big unlocks that happened over the past 10 years, but that happened on the order of once every three years or so, or maybe one every three orders of magnitude of compute scaling. And then you might ask the question, “how many more such competencies might we need to unlock in order to be able to have an AI system that can match the capabilities of humans across the board?” Maybe specifically just on remote work tasks. And so then you might ask, well, maybe you need kind of coherence over very long horizons, or you need agency and autonomy, or maybe you need full multimodal understanding, just like a human would.</span><br><span>And then you ask the question, “okay, how long might that take?” And so you can think about, well, just in terms of calendar years, the previous unlocks took about, you get one every three years or so. But of course, that previous period coincided with this rapid scale-up of the amount of compute that we use for training. So we went through maybe 9 or 10 orders of magnitude since </span><a href="https://en.wikipedia.org/wiki/AlexNet" rel="">AlexNet</a><span> compared to the biggest models we have today. And we’re getting to a level where it’s becoming harder and harder to scale up compute. And we’ve done some extrapolations and some analysis looking at specific constraints, like energy or GPU production.</span><br><span>And based on that, it looks like we might have maybe three or four orders of magnitude of scaling left. And then you’re really spending a pretty sizable fraction or a non-trivial fraction of world output on just building up data centers, energy infrastructure, fabs, and so on.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:06:40</em><br><span>Which is already like 2% of GDP, right?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:06:42</em><br><span>I mean, currently it’s less than 2%.</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:06:44</em><br><span>Yeah, but also currently most of it is actually not going towards AI chips. But even most TSMC capacity currently is going towards mobile phone chips or something like that, right?</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:06:52</em><br><span>Even leading edge. It’s like 5% of leading edge.</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:06:55</em><br><span>Yeah, even leading edge is pretty small. But yeah, so that suggests that we might need a lot more compute scaling to get these additional capabilities to be unlocked. And then there’s a question of do we really have that in us as an economy to be able to sustain that scaling?</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:07:14</em><br><span>But it seems like you have this intuition that there’s just a lot left to intelligence. When you play with these models, they’re almost there. You forget you’re often talking to an AI.</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:07:26</em><br><span>What do you mean they’re almost there? I don’t know. I can’t ask Claude to pick up this cup and put it over there.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:07:31</em><br><span>Remote work, you know?</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:07:32</em><br><span>Okay. But even for remote work, I can’t ask Claude to… I think the current computer use systems can’t even book a flight properly.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:07:38</em><br><span>How much of an update would it be if by the end of 2026, they could book a flight?</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:07:43</em><br><span>I probably think by the end of this year, they’re going to be able to do that. But that’s a very simple… Nobody gets a job where they’re paid to book flights. That’s not a task.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:07:54</em><br><span>I think some people do.</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:07:56</em><br><span>If it’s literally just a book flight job, and without-</span><br><em><strong>Ege Erdil</strong><span> 00:08:00</span></em><br><span>But I think that’s an important point, because a lot of people look at jobs in the economy, and then they’re like, “oh, that person, their job is to just do X”. But then that’s not true. That’s </span><em>something</em><span> they do in their job. But if you look at the fraction of their time on the job that they spend on doing that, it’s a very small fraction of what they actually do. It’s just this popular conception people have. Or travel agents, they just book hotels and flights. But that’s not actually most of their job. So automating that actually wouldn’t automate their job, and it wouldn’t have that much of an impact on the economy.</span><br><span>So I think this is actually an important thing, that important worldview difference that separates us from people who are much more bullish, because they think jobs in the economy are much simpler in some sense, and they’re going to take much fewer competences to actually fully automate.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:08:47</em><br><span>So our friend Leopold has this perspective of, quote unquote, ‘unhobblings’, where the way to characterize it might be, they’re basically like baby AGIs already. And then because of the constraints we artificially impose upon them by, for example, only training them on text and not giving them the training data that is necessary for them to understand a Slack environment or a Gmail environment, or previously before inference time scaling, not giving them the chance to meditate upon what they’re saying and really think it through, and not giving them the context about what is actually involved in this job, only giving them this piecemeal, a couple of minutes worth of context in the prompt, we’re holding back what is fundamentally a little intelligence from being as productive as it could be, which implies that unhobblings just seem easier to solve for than entirely new capabilities of intelligence. What do you make of that framework?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:09:46</em><br><span>I mean, I guess you could have made similar points five years ago and say “you look at AlphaZero and there’s this mini AGI there, and if only you unhobbled it by training it on text and giving it all your context” and so on, that just wouldn’t really have worked. I think you do really need to rethink how you train these models in order to get these capabilities.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:10:08</em><br><span>But I think the surprising thing over the last few years has been that you can start off with this pre-trained corpus of the internet, and it’s actually quite easy. ChatGPT is an example of this unhobbling, where 1% of additional compute spent on getting it to talk in a chatbot-like fashion with post training is enough to make it competent- really competent- at that capability.</span><br><span>Reasoning is another example where it seems like the amount of compute that is spent on RL right now in these models is a small fraction of total compute. Again, reasoning seems complicated, and then you just do 1% of compute and it gets you that. Why not think that computer use, or long-term agency on computer use, is a similar thing?</span><br><em><strong>Tamay Besiroglu</strong></em><span> </span><em>00:10:55</em><br><span>So when you say “reasoning is easy” and “it only took this much compute” and “it wasn’t very much”, and maybe “you look at the sheer number of tokens and it wasn’t very much, and so it looks easy”, well, that’s true from our position today. But I think if you ask someone to build a reasoning model in 2015, then it would have looked insurmountable. You would have had to train a model on tens of thousands of GPUs, you would have had to solve that problem, and each order of magnitude of scaling from where they were would pose new challenges that they would need to solve.</span><br><span>You would need to produce internet scale, or tens of trillions of tokens of data in order to actually train a model that has the knowledge that you can then unlock and access by way of training it to be a reasoning model. You need to maybe make the model more efficient at doing inference and maybe distill it, because if it’s very slow then you have a reasoning model that’s not particularly useful, so you also need to make various innovations to get the model to be distilled so that you can train it more quickly, because these rollouts take very long.</span><br><span>It actually becomes a product that’s valuable if it’s a couple tokens a second, as a reasoning model that would have been very difficult to work with. So in some sense, it looks easy from our point of view, standing on this huge stack of technology that we’ve built up over the past five years or so, but at the time, it would have been very hard.</span><br><span>And so my claim would be something like; I think the agency part might be easy in a similar sense, that in five years or three years time or whatever we will look at what unlocked agency and it’ll look fairly simple. But the amount of work that, in terms of these complementary innovations that enable the model to be able to learn how to become a competent agent, that might have just been very difficult and taken years of innovation and a bunch of improvements in kind of hardware and scaling and various other things.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:12:54</em><br><span>Yeah, I feel like what’s dissimilar between 2015 and now… in 2015 if you were trying to solve reasoning, you just didn’t have a base to start on. Maybe if you tried formal proof methods or something, but there was no leg to stand on, where now you’d actually have the thing- you have the pre-trained base model, you have these techniques of scaffolding, of post-training, of RL. And so it seems like you think that those will look to the future as, say, AlphaGo looks to us now in terms of the basis of a broader intelligence.</span><br><span>I’m curious if you have intuitions on why not think that language models as we have them now are like, we got the big missing piece right and now we’re just like plugging things on top of it?</span><br><em><strong>Ege Erdil</strong></em><span> </span><em>00:13:51</em><br><span>Well, I mean, I guess what is the reason for believing that? I mean, you could have looked at AlphaGo or AlphaGo Zero, AlphaZero, those seemed very impressive at the time. I mean, you’re just learning to play this game with no human knowledge, you’re just learning to play it from scratch. And I think at the time it did impress a lot of people. But then people tried to apply it to math, they tried to apply it to other domains, and it didn’t work very well, they weren’t able to get competent agents at math.</span><br><span>So it’s very possible that these models, at least the way we have them right now, you’re going to try to do the same thing people did for reasoning, but for agency, it’s not going to work very well. And then you’re not going to-</span><br><em><strong>Dwarkesh Patel</strong><span> 00:14:32</span></em><br><span>I’m sorry, you’re saying by the end of 2026, we will have agentic computer use.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:14:36</span></em><br><span>I think Ege said you’d be able to book a flight, which is very different from having full agentic computer use.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:14:44</span></em><br><span>I mean, the other things you need to do on a computer are just made up of things like booking a flight.</span><br><em><strong>Ege Erdil</strong><span> 00:14:49</span></em><br><span>I mean, sure, but they are not disconnected tasks. That’s like saying everything you do in the world is just like you just move parts of your body, and then you move your mouth and your tongue, and then you roll your head. Yeah, individually those things are simple, but then how do you put them together, right?</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>00:15:09</em><br><span>Yeah. Okay. So there’s two pieces of evidence that you can have that are quite dissimilar.</span><br><span>One, the METR eval, which we’ve been talking about privately, which shows that the task length over certain kinds of tasks- I can already see you getting ready. AI’s ability to do the kind of thing that it takes a human 10 minutes to do, or an hour to do, or four hours to do, the length of time for corresponding human tasks, it seems like these models seem to be doubling their task length every seven months. The idea being that by 2030, if you extrapolate this curve, they could be doing tasks that take humans one month to do, or one year to do. And then this long-term coherency in executing on tasks is fundamentally what intelligence is. So this curve suggests that we’re getting there.</span><br><span>The other piece of evidence- I kind of feel like my own mind works this way. I get distracted easily, and it’s hard to keep a long-term plan in my head at the same time. And I’m slightly better at it than these models. But they don’t seem that dissimilar to me. I would have guessed reasoning is just a really complicated thing, and then it seems like, “oh, it’s just something like learning 10 tokens worth of </span><a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" rel="">MCTS</a><span>” of “wait, let’s go back, let’s think about this another way”.</span><br><span>Chain of thought alone just gets you this boost. And it just seems like intelligence is simpler than we thought. Maybe agency is also simpler in this way.</span><br><em><strong>Ege Erdil</strong><span> 00:16:39</span></em><br><span>Yeah. I mean, I think there’s a reason to expect complex reasoning to not be as difficult as people might have thought, even in advance, because a lot of the tasks that AI solved very early on were tasks of various kinds of complex reasoning. So it wasn’t the kind of reasoning that goes into when a human solves a math problem.</span><br><span>But if you look at the major AI milestones over, I don’t know, since 1950, a lot of them are for complex reasoning. Like chess is, you can say, a complex reasoning task. Go is, you could say, a complex reasoning task.</span><br><strong>Dwarkesh Patel</strong><span> </span><em>00:17:14</em><br><span>But I think there are also examples of long-term agency. Like winning at Starcraft is an example of being agentic over a meaningful period of time.</span><br><strong>Ege Erdil</strong><span> </span><em>00:17:24</em><br><span>That’s right. So the problem in that case is that it’s a very specific, narrow environment. You can say that playing Go or playing chess, that also requires a certain amount of agency. And that’s true. But it’s a very narrow task. So that’s like saying if you construct a software system that is able to react to a very specific, very particular kind of image, or very specific video feeds or whatever, then you’re getting close to general sensor motor skill automation.</span><br><span>But the general skill is something that’s very different. And I think we’re seeing that. We still are very far, it seems like, from an AI model that can take a generic game off Steam. Let’s say you just download a game released this year. You don’t know how to play this game. And then you just have to play it. And then most games are actually not that difficult for a human.</span><br><strong>Dwarkesh Patel</strong><span> </span><em>00:18:21</em><br><span>I mean, what about </span><a href="https://www.theverge.com/news/619482/anthropics-claude-ai-is-playing-pokemon" rel="">Claude Plays Pokemon</a><span>? I don’t think it was trained on Pokemon.</span><br><strong>Ege Erdil</strong><span> </span><em>00:18:25</em><br><span>Right, so that’s an interesting example. First of all, I find the example very interesting, because yeah, it was not trained explicitly. They didn’t do some RL on playing Pokemon Red. But obviously, the model knows how it’s supposed to play Pokemon Red, because there’s tons of material about Pokemon Red on the internet.</span><br><span>In fact, if you were playing Pokemon Red, and you got stuck somewhere, you didn’t know what to do, you could probably go to Claude and ask “I’m stuck in Mount Moon, and what am I supposed to do?” And then it’s probably able to give you a fairly decent answer. But that doesn’t stop it from getting stuck in Mount Moon for 48 hours. So that’s a very interesting thing, where it has explicit knowledge, but then when it’s actually playing the game, it doesn’t behave in a way which reflects that it has that knowledge.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:19:09</span></em><br><span>All it’s got to do is plug the explicit knowledge to its actions.</span><br><em><strong>Ege Erdil</strong><span> 00:19:13</span></em><br><span>Yeah, but is that easy?</span><br><em><strong>Dwarkesh Patel</strong><span> 00:19:15</span></em><br><span>Okay, if you can leverage your knowledge from pre-training about these games in order to be somewhat competent at them, okay, they’re going to be leveraging a different base of skills. But with that same leverage, they’re going to have a similar repertoire of abilities. If you’ve read everything about whatever skill that every human has ever seen.</span><br><em><strong>Ege Erdil</strong><span> 00:19:43</span></em><br><span>A lot of the skills that people have, they don’t have very good training data for them.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:19:48</span></em><br><span>That’s right. What would you want to see over the next few years that would make you think, “oh, no, I’m actually wrong and this was the last unlock, and it was now just a matter of ironing out the kinks”. And then we get the thing that will kick off the, dare I say, intelligence explosion.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:20:04</span></em><br><span>I think something that would reveal its ability to do very long context things, use multimodal capabilities in a meaningful way, and integrate that with reasoning and other types of systems. And also agency and being able to take action over a long horizon and accomplish some tasks that takes very long for humans to do, not just in specific software environments, but just very broadly; say downloading an arbitrary game from Steam, something that it’s never seen before,</span><br><span>it doesn’t really have much training data, maybe it was released after a training cutoff and so there’s no tutorials or maybe there’s no earlier versions of the game that has been discussed on the Internet, and then accomplishing that game and actually playing that game to the end and accomplishing these various milestones that are challenging for humans. That would be a substantial update. I mean, there are other things that would update me, too, like OpenAI making a lot more revenue than it’s currently doing.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:21:11</span></em><br><span>Is the hundred billion in revenue that would, according to their contract, mark them as AGI enough?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:21:15</span></em><br><span>I think that’s not a huge update to me if that were to happen. So I think the update would come if it was, in fact, $500 billion in revenue or something like that. But then I would certainly update quite a lot. But a hundred billion, that seems pretty kind of likely to me. I would assign that maybe a 40 percent chance or something.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:21:37</span></em><br><span>If you’ve got a system that is, in producer surplus terms, worth a hundred billion. And the difference between this and AlphaZero is AlphaZero is never going to make a hundred billion dollars in the marketplace. So just what is intelligence? It’s like something able to usefully accomplish its goals, or your goals. If people are willing to pay a hundred billion dollars for it, that’s pretty good evidence that it’s like accomplishing some goals.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:22:05</span></em><br><span>I mean, people pay a hundred billion dollars for all sorts of things. That itself is not a very strong piece of evidence that it’s going to be transformative, I think.</span><br><em><strong>Ege Erdil</strong><span> 00:22:13</span></em><br><span>People pay trillions of dollars for oil. I don’t know, it seems like a very basic point. But the fact that people pay a lot of money for something doesn’t mean it’s going to transform the world economy if only we manage to unhobble it. Like that’s a very different claim.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 00:22:27</span></em><br><span>So then this brings us to the intelligence explosion, because what people will say is, we don’t need to automate literally everything that is needed for automating remote work, let alone all human labor in general. We just need to automate the things which are necessary to fully close the R&amp;D cycle needed to make smarter intelligences.</span><br><span>And if you do this, you get a very rapid intelligence explosion. And the end product of that explosion is not only an AGI, but something that is superhuman potentially. These things are extremely good at coding, and reasoning. It seems like the kinds of things that would be necessary to automate R&amp;D at AI labs. What do you make of that logic?</span><br><em><strong>Ege Erdil</strong><span> 00:24:14</span></em><br><span>I think if you look at their capability profile, if you compare it to a random job in the economy, I agree they are better at doing coding tasks that will be involved in R&amp;D compared to a random job in the economy. But in absolute terms, I don’t think they’re that good. I think they are good at things that maybe impress us about human coders. If you wanted to see what makes a person a really impressive coder, you might look at their competitive programming performance. In fact, companies often hire people, if they’re relatively junior, based on their performance on these kinds of problems. But that is just impressive in the human distribution.</span><br><span>So if you look in absolute terms at what are the skills you need to actually automate the process of being a researcher, then what fraction of those skills do the AI systems actually have? Even in coding, a lot of coding is, you have a very large code base you have to work with, the instructions are very kind of vague. For example you mentioned METR eval, in which, because they needed to make it an eval, all the tasks have to be compact and closed and have clear evaluation metrics: “here’s a model, get its loss on this data set as low as possible”. Or “here’s another model and its embedding matrix has been scrambled, just fix it to recover like most of its original performance”, etc.</span><br><span>Those are not problems that you actually work on in AI R&amp;D. They’re very artificial problems. Now, if a human was good at doing those problems, you would infer, I think logically, that that human is likely to actually be a good researcher. But if an AI is able to do them, the AI lacks so many other competences that a human would have- not just the researcher, just an ordinary human- that we don’t think about in the process of research. So our view would be that automating research is, first of all, more difficult than people give it credit for. I think you need more skills to do it and definitely more than models are displaying right now.</span><br><span>And on top of that, even if you did automate the process of research, we think a lot of the software progress has been driven not by cognitive effort- that has played a part- but it has been driven by compute scaling. We just have more GPUs, you can do more experiments, to figure out more things, your experiments can be done at larger scales. And that is just a very important driver. If you’re 10 years ago, 15 years ago, you’re trying to figure out what software innovations are going to be important in 10 or 15 years, you would have had a very difficult time. In fact, you probably wouldn’t even have conceived of the right kind of innovations to be looking at, because you would be so far removed from the context of that time with much more abundant compute and all the things that people would have learned by that point.</span><br><span>So these are two components of our view: Research is harder than people think, and depends a lot on compute scale.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:27:17</span></em><br><span>Can you put a finer point on what is an example of the kind of task which is very dissimilar from ‘train a classifier’ or ‘debug a classifier’ that is relevant to AI R&amp;D?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:27:30</span></em><br><span>Examples might be introducing novel innovations that are very useful for unlocking innovations in the future. So that might be introducing some novel way of thinking about a problem. A good example might be in mathematics, where we have these reasoning models that are extremely good at solving math problems.</span><br><em><strong>Ege Erdil</strong><span> 00:27:57</span></em><br><span>Very short horizon.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:28:00</span></em><br><span>Sure. Maybe not extremely good, but certainly better than I can and better than maybe most undergrads can. And so they can do that very well, but they’re not very good at coming up with novel conceptual schemes that are useful for making progress in mathematics. So it’s able to solve these problems that you can kind of neatly excise out of some very messy context, and it’s able to make a lot of progress there.</span><br><span>But within some much messier context, it’s not very good at figuring out what directions are especially useful for you to build things or make incremental progress on that enables you to have a big kind of innovation later down the line. So thinking about both this larger context, as well as maybe much longer horizon, much fuzzier things that you’re optimizing for, I think it’s much worse at those types of things.</span><br><em><strong>Ege Erdil</strong><span> 00:28:54</span></em><br><span>Right. So I think one interesting thing is if you just look at these reasoning models, they know so much, especially the larger ones, because they know in literal terms more than any human does in some sense. And we have unlocked these reasoning capabilities on top of that knowledge, and I think that is actually what’s enabling them to solve a lot of these problems. But if you actually look at the way they approach problems, the reason what they do looks impressive to us is because we have so much less knowledge.</span><br><span>And the model is approaching the problems in a fundamentally different way compared to how a human would. A human would have much more limited knowledge, and they would usually have to be much more creative in solving problems because they have this lack of knowledge, while the model knows so much. But you’d ask it some obscure math question where you need some specific theorem from 1850 or something, and then it would just know that, if it’s a large model. So that makes the difficulty profile very different.</span><br><span>And if you look at the way they approach problems, the reasoning models, they are usually not creative. They are very effectively able to leverage the knowledge they have, which is extremely vast. And that makes them very effective in a bunch of ways. But you might ask the question, has a reasoning model ever come up with a math concept that even seems slightly interesting to a human mathematician? And I’ve never seen that.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:30:19</span></em><br><span>I mean, they’ve been around for all of six months,</span><br><em><strong>Tamay Besiroglu</strong><span> 00:30:23</span></em><br><span>I mean, that’s a long time. One mathematician might have been able to do a bunch of work over that time, and they have produced orders of magnitude fewer tokens on math.</span><br><em><strong>Ege Erdil</strong><span> 00:30:34</span></em><br><span>And then I just want to emphasize it, because just think about the sheer scale of knowledge that these models have. It’s enormous from a human point of view. So it is actually quite remarkable that there is no interesting recombination, no interesting, “oh, this thing in this field looks kind of like this thing in this other field”. There’s no innovation that comes out of that. And it doesn’t have to be a big math concept, it could be just a small thing that maybe you could add to a Sunday magazine on math that people used to have. But there isn’t even an example of that.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:31:09</span></em><br><span>I think it’s useful for us to explain a very important framework for our thinking about what AI is good at and what AI is lagging in, which is this idea of </span><a href="https://en.wikipedia.org/wiki/Moravec%27s_paradox" rel="">Moravec’s paradox</a><span>, that things that seem very hard for humans, AI systems tend to make much faster progress on, whereas things that look a bunch easier for us, AI systems totally struggle or are often totally incapable of doing that thing. And so this kind of abstract reasoning, playing chess, playing Go, playing Jeopardy, doing kind of advanced math and solving math problems.</span><br><em><strong>Ege Erdil</strong><span> 00:31:49</span></em><br><span>There are even stronger examples, like multiplying 100 digit numbers in your head, which is just the one that got solved first out of almost any other problem. Or following very complex symbolic logic arguments, like deduction arguments, which people actually struggle with a lot. Like how do premises logically follow from conclusions? People have a very hard time with that. Very easy for formal proof systems.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:32:12</span></em><br><span>An insight that is related and is quite important here is that the tasks that humans seem to struggle on and AI systems seem to make much faster progress on are things that have emerged fairly recently in evolutionary time. So, advanced language use emerged in humans maybe 100,000 years ago, and certainly playing chess and Go and so on are very recent innovations. And so evolution has had much less time to optimize for them, in part because they’re very new, but also in part because when they emerged, there was a lot less pressure because it conferred kind of small fitness gains to humans and so evolution didn’t optimize for these things very strongly.</span><br><span>And so it’s not surprising that on these specific tasks that humans find very impressive when other humans are able to do it, that AI systems are able to make a lot of fast progress. In humans, these things are often very strongly correlated with other competencies, like being good at achieving your goals, or being a good coder is often very strongly correlated with solving coding problems, or being a good engineer is often correlated with solving competitive coding problems.</span><br><span>But in AI systems, the correlation isn’t quite as strong. And even within AI systems, it’s the case that the strongest systems on competitive programming are not even the ones that are best at actually helping you code. So o3 mini’s high seems to be maybe the best at solving competitive code problems, but it isn’t the best at actually helping you write code.</span><br><em><strong>Ege Erdil</strong><span> 00:33:54</span></em><br><span>And it isn’t getting most of the enterprise revenue from places like </span><a href="https://www.coursera.org/" rel="">Coursera</a><span> or whatever, that’s just Claude, right?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:33:59</span></em><br><span>But an important insight here is that the things that we find very impressive when humans are able to do it, we should expect that AI systems are able to make a lot more progress on that. But we shouldn’t update too strongly about just their general competence or something, because we should recognize that this is a very narrow subset of relevant tasks that humans do in order to be a competent, economically valuable agent.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:34:26</span></em><br><span>Yeah. First of all, I actually just really appreciate that there is an AI organization out there where- because there’s other people who take the compute perspective seriously, or try to think empirically about scaling laws and data and whatever. And taking that perspective seriously leads people to just be like, “okay, 2027 AGI”, which might be correct, but it is just interesting to get, “no, we’ve also looked at the exact same arguments, the same papers, the same numbers. And we’ve come to a totally different conclusion”.</span><br><span>So I asked Dario this exact question two years ago, when I interviewed him, and it went viral.</span><br><em><strong>Ege Erdil</strong><span> 00:35:11</span></em><br><span>Didn’t he say AGI in two years?</span><br><em><strong>Dwarkesh Patel</strong><span> 00:35:13</span></em><br><span>That, but Dario’s always had short timelines.</span><br><em><strong>Ege Erdil</strong><span> 00:35:15</span></em><br><span>Okay, but we are two years later.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:35:18</span></em><br><span>Did he say two years? I think he actually did say two years.</span><br><em><strong>Ege Erdil</strong><span> 00:35:20</span></em><br><span>Did he say three years?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:35:21</span></em><br><span>So we have one more year.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:35:22</span></em><br><span>One more year.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:35:23</span></em><br><span>Better work hard.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:35:27</span></em><br><span>But he’s, I mean, I think he’s like, he in particular has not been that well calibrated. In 2018, he had like…</span><br><em><strong>Tamay Besiroglu</strong><span> 00:35:33</span></em><br><span>I remember talking to a very senior person who’s now at Anthropic, in 2017. And then he told various people that they shouldn’t do a PhD because by the time they completed it everyone will be automated.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:35:49</span></em><br><span>So anyways, I asked him this exact same question because he has short timelines, which is that if a human knew the amount of things these models know, they would be finding all these different connections. And in fact, I was asking Scott about this the other day </span><a href="https://www.dwarkesh.com/p/scott-daniel" rel="">when I interviewed him</a><span>, Scott Alexander, and he said, “look, humans also don’t have this kind of logical omniscience”.</span><br><span>I’m not saying we’re omniscient, but we have examples of humans finding these kinds of connections. This is not an uncommon thing, right? I think his response was that these things are just not trained in order to find these kinds of connections, but their view is that it would not take that much extra compute in order to build some RL environment in which they’re incentivized to find these connections. Next token prediction just isn’t incentivizing them to do this, but the RL required to do this would not be- that or set up some sort of scaffolds. I think actually Google DeepMind did do some similar scaffold to make new discoveries. And I didn’t look into how impressive the new discovery was, they claim that some new discovery was made by an LLM as a result.</span><br><span>On the Moravec paradox thing, this is actually a super interesting way to think about AI progress. But I would also say that if you compare animals to humans, long term intelligent planning… an animal is not gonna help you book a flight either. An animal is not gonna do remote work for you.</span><br><span>I think what separates humans from other animals is that we can hold long-term, we can come up with a plan and execute on it. Whereas other animals often had to go by instinct, or within the kinds of environments that they have evolutionary knowledge of, rather than, “I’m put in the middle of the savanna, or I’m put in the middle of the desert, or I’m put in the middle of tundra, and I’ll learn how to make use of the tools and whatever there”. I actually think there’s a huge discontinuity between humans and animals and their ability to survive in different environments, just based on their knowledge. And so it’s a recently optimized thing as well. And then I’d be like, “okay, well, we got it soon. AIs will optimize for it fast”.</span><br><strong>Ege Erdil</strong><span> </span><em>00:37:50</em><br><span>Right. So I would say if you’re comparing animals to humans, it’s kind of a different thing.</span><br><span>I think if you could put the competences that the animals have into AI systems, that might just already get you to AGI already. I think the reason why there is such a big discontinuity between animals and humans is because animals have to rely entirely on natural world data, basically, to train themselves. Imagine that the only thing as a human that you saw was nobody talked to you, you didn’t read anything, you just had to learn by experience, maybe to some extent by imitating other people, but you have no explicit communication. It would be very inefficient.</span><br><span>What’s actually happening is that you have this- I think some other people have made this point as well- is that evolution is sort of this outer optimizer that’s improving the software efficiency of the brain in a bunch of ways. There’s some genetic knowledge that you inherit, not that much because there isn’t that much space in the genome. And then you have this lifetime learning, which is, you don’t actually see that much data during lifetime learning. A lot of this is redundant and so on.</span><br><span>So what seems to have changed with humans compared to other animals is that humans became able to have culture and they have language, which enables them to have a much more efficient training data modality compared to animals. They also have, I think, stronger ways in which they tend to imitate other humans and learn from their skills, so that also enables this knowledge to be passed on. I think animals are pretty bad at that compared to humans. So basically as a human, you’re just being trained on much more efficient data and that creates further insights to be then efficient at learning from it, and then that creates this feedback loop where the selection pressure gets much more intense.</span><br><span>So I think that’s roughly what happened with humans. But a lot of the capabilities that you need to be a good worker in the human economy, animals already have. So they have quite sophisticated sensory motor skills. I think they are actually able to pursue long-term goals.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:40:03</span></em><br><span>But ones that have been instilled by evolution. I think a lion will find a gazelle and that is a complicated thing to do and requires stalking and blah, blah, blah-</span><br><em><strong>Ege Erdil</strong><span> 00:40:12</span></em><br><span>But when you say it’s been instilled by evolution, there isn’t that much information in the genome.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:40:16</span></em><br><span>But I think if you put the lion in the Sahara and you’re like, “go find lizards instead”.</span><br><em><strong>Ege Erdil</strong><span> 00:40:22</span></em><br><span>Okay. So suppose you put a human and they haven’t seen the relevant training data.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:40:27</span></em><br><span>I think they’d be slightly better.</span><br><em><strong>Ege Erdil</strong><span> 00:40:29</span></em><br><span>Slightly better, but not that much better. Again, didn’t you recently have an interview?</span><br><em><strong>Dwarkesh Patel</strong><span> 00:40:36</span></em><br><a href="https://www.dwarkesh.com/p/joseph-henrich" rel="">Joseph Henrich.</a><br><em><strong>Ege Erdil</strong><span> 00:40:37</span></em><br><span>Yeah. So he would probably tell you that.</span><br><strong>Dwarkesh Patel</strong><span> </span><em>00:40:40</em><br><span>I think what you’re making is actually a very interesting and subtle point that has an interesting implication. So often people say that ASI will be this huge discontinuity, because while we have this huge discontinuity in the animal-to-human transition, not that much changed between pre-human primates and humans genetically, but it resulted in this humongous change in capabilities. And so they say, “well, why not expect something similar between human level intelligence and superhuman intelligence?”</span><br><span>And one implication of the point you’re making is actually it wasn’t that we just gained this incredible intelligence. Because of biological constraints, animals have just been held back in this really weird way that no AI system has been arbitrarily held back from not being able to communicate with other copies or with other knowledge sources. And so since AIs are not held back artificially in this way, there’s not going to be a point where we should take away that hobbling. And then now they explode.</span><br><span>Now, actually, I think I would disagree with that. The implication that I made, I would actually disagree with- I’m like a sort of unsteerable chain of thought.</span><br><span>We wrote a </span><a href="https://www.dwarkesh.com/p/ai-firm" rel="">blog post together</a><span> about AI corporations where we discuss actually there will be a similar unhobbling with future AIs, which is not about the intelligence, but a similar level of bandwidth and communication and collaboration with other AIs, which is a similar magnitude of change from non-human animals to humans, in terms of their social collaboration, that AIs will have with each other because of their ability to copy all their knowledge exactly, to merge, to distill themselves.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:42:28</span></em><br><span>Maybe before we talk about that, I think just a very important point to make here, which I think underlies some of this disagreement that we have with others about both this argument from the transition from kind of non-human animals to humans, is this focus on intelligence and reasoning and R&amp;D, which is enabled by that intelligence as being enormously important. And so if you think that you get this very important difference from this transition from non-human primates to humans, then you think that in some sense you get this enormously important unlock from fairly small scaling and, say, brain size or something.</span><br><span>And so then you might think, “well, if we scale beyond the size of training runs, the amount of training compute that the human brain uses, which is maybe on the order of 1E24 flop or whatever, which we’ve recently surpassed, then maybe surpassing it just a little bit more enables us to unlock very sophisticated intelligence in the same way that humans have much more sophisticated intelligence compared to non-human primates”. And I think part of our disagreement is that intelligence is kind of important, but just having a lot more intelligence and reasoning and good reasoning isn’t something that will kind of accelerate technological change and economic growth very substantially.</span><br><span>It isn’t the case that the world today is totally bottlenecked by not having enough good reasoning, that’s not really what’s bottlenecking the world’s ability to grow much more substantially. I think that we might have some disagreement about this particular argument, but I think what’s also really important is just that we have a different view as to how this acceleration happens, that it’s not just having a bunch of really good reasoners that give you this technology that then accelerates things very drastically. Because that alone is not sufficient. You need kind of complementary innovations in other industries. You need the economy as a whole growing and supporting the development of these various technologies. You need the various supply chains to be upgraded. You might need demand for the various products that are being built.</span><br><span>And so we have this view where actually this very broad upgrading of your technology and your economy is important rather than just having very good reasoners and very, very, very good reasoning tokens that gives us this acceleration.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 00:45:04</span></em><br><span>All right. So this brings us back to the intelligence explosion. Here’s the argument for the intelligence explosion:</span><br><span>You’re right that certain kinds of things might take longer to come about, but this core loop of software R&amp;D that’s required, if you just look at what kinds of progress is needed to make a more general intelligence, you might be right that it needs more experimental compute, but as you guys have documented, we’re just getting a shit-ton more compute every single year for the next few years. So you can imagine an intelligence explosion in the next few years where in 2027, there’ll be like 10 X more compute than there is now for AI.</span><br><span>And you’ll have this effect where the AIs that are doing software R&amp;D are finding ways to make running copies of them more efficient, which has two effects. One, you’re increasing the population of AIs who are doing this research, so more of that in parallel can find these different optimizations. And a subtle point that they’d often make here is software R&amp;D in AI is not just </span><a href="https://en.wikipedia.org/wiki/Ilya_Sutskever" rel="">Ilya</a><span>-type coming up with new transformer-like architectures.</span><br><span>To your point, it actually is a lot of- I mean, I’m not an AI researcher, but I assume there’s, from the lowest level libraries to the kernels, to making RL environments, to finding the best optimizer, to… there’s just so much to do, and in parallel you can be doing all these things or finding optimizations across them. And so you have two effects, going back to this. One is, if you look at the original GPT-4 compared to the current GPT-4o, I think it’s, what, how much cheaper is it to run?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:46:57</span></em><br><span>It’s like, maybe a hundred times for the same capability or something.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:47:03</span></em><br><span>Right. So they’re finding ways in which to run more copies of them at a hundred X cheaper or something, which means that the population of them is increasing and the higher populations are helping you find more efficiencies.</span><br><span>And not only does that mean you have more researchers, but to the extent that the complementary input is experimental compute, it’s not the compute itself, it’s the experiments.</span><br><span>And the more efficient it is to run a copy or to develop a copy, the more parallel experiments you can run, because now you can do a GPT-4 scale training run for much cheaper than you could do it in 2024 or 2023. And so for that reason, also this software-only singularity sees more researcher copies who can run experiments for cheaper, dot, dot, dot. They initially are maybe handicapped in certain ways that you mentioned, but through this process, they are rapidly becoming much more capable. What is wrong with this logic?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:47:57</span></em><br><span>So I think the logic seems fine. I think this is like a decent way to think about this problem, but I think that it’s useful to draw on a bunch of work that, say, economists have done for studying the returns to R&amp;D and what happens if you 10X your inputs, the number of researchers, what happens to innovation or the rate of innovation.</span><br><span>And there, they point out these two effects where, as you do more innovation and you get to stand on top of the shoulders of giants and you get the benefit from past discoveries and it makes you as a scientist more productive. But then there’s also kind of diminishing returns, that the low hanging fruit has been picked, and it becomes harder to make progress. And overall, you can summarize those estimates as thinking about the kind of returns to research effort.</span><br><span>And we’ve looked into the returns to research effort in software specifically. And we look at a bunch of domains in traditional software or linear integer solvers or SAT solvers, but also in AI; computer vision and RL and language modeling. And there, if this model is true, that all you need is just cognitive effort, it seems like the estimates are a bit ambiguous about whether this results in this acceleration or whether it results in just merely exponential growth.</span><br><span>And then you might also think about, well, it isn’t just your research effort that you have to scale up to make these innovations, because you might have complementary inputs. So as you mentioned, experiments are the thing that might kind of bottleneck you. And I think there’s a lot of evidence that in fact, these experiments and scaling up hardware, it’s just very important for getting progress in the algorithms and the architecture and so on. So in AI- this is true for software in general- where if you look at progress in software, it often matches very closely the rate of progress we see in hardware. So for traditional software, we see about a 30% roughly increase per year, which kind of basically matches </span><a href="https://en.wikipedia.org/wiki/Moore%27s_law" rel="">Moore’s law</a><span>. And in AI, we’ve seen the same until you get to the deep learning era, and then you get this acceleration, which in fact coincides with the acceleration we see in compute scaling, which gives you a hint that actually the compute scaling might have been very important.</span><br><span>Other pieces of evidence besides this coincidental rate of progress, other pieces of evidence are the fact that innovation and algorithms and architectures are often concentrated in GPU-rich labs and not in the GPU-poor parts of the world, like academia or maybe smaller research institutes. That also suggests that having a lot of hardware is very important. If you look at specific innovations that seem very important, the big innovations over the past five years, many of them have some kind of scaling or hardware-related motivation. So you might look at how the transformer itself was about how to harness more parallel compute. Things like flash attention was literally about how to implement the attention mechanism more efficiently, or things like the </span><a href="https://en.wikipedia.org/wiki/Neural_scaling_law" rel="">chinchilla scaling law</a><span>.</span><br><span>And so many of these big innovations were just about how to harness your compute more effectively. That also tells you that actually the scaling of compute might be very important. And I think there’s just many pieces of evidence that point towards this complementarity picture.</span><br><span>So I would say that even if you assume that experiments are not particularly important, the evidence we have, both from estimates of AI and other software- although the data is not great- suggests that maybe you don’t get this kind of hyperbolic, faster-than-exponential super-growth in the overall algorithmic efficiency of systems.</span><br><strong>Dwarkesh Patel</strong><span> </span><em>00:51:56</em><br><span>I’m not sure I buy the argument that because these two things compute and AI progress have risen so concomitantly that this is a sort of causal relationship.</span><br><span>So broadly, the industry as a whole has been getting more compute and as a result, making more progress. But if you look at the top players, there’s been multiple examples of a company with much less compute, but a more coherent vision, more concentrated research effort, being able to beat an incumbent who has much more compute. So OpenAI initially beating Google DeepMind. And if you remember, there were these emails that were released between Elon and Sam and so forth like, “we got to start this company because they’ve got this bottleneck on the compute” and, “look how much more compute Google DeepMind has”. And then OpenAI made a lot of progress. Similarly now with OpenAI versus Anthropic and so forth. And then I think just generally, your argument is just too ‘outside view’. And we actually do know a lot about this very macro economic argument that I’m like, well, why don’t we just ask the AI researchers?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:53:01</span></em><br><span>I mean, AI researchers will often kind of overstate the extent to which just cognitive effort and doing research is important for driving these innovations, because that’s often convenient or useful. They will say the insight was derived from some nice idea about statistical mechanics or some nice equation in physics that says that we should do it this way. But often that’s an ad hoc story that they tell to make it a bit more compelling to reviewers.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:53:35</span></em><br><span>So </span><a href="https://www.lesswrong.com/users/daniel-kokotajlo" rel="">Daniel Kokotajlo</a><span> mentioned this survey he did where he asked a bunch of AI researchers, “if you had one thirtieth the amount of compute”- and he did one thirtieth because AI’s will be, they suppose, 30 times faster- “If you had one thirtieth the amount of compute, how much would your progress slow down?” And they say, “I make a third of the amount of progress I normally do”. So that’s just a pretty good substitution effect of, you get one tenth the compute, your progress only goes down one third.</span><br><span>And then I was talking to an AI researcher the other day, one of these cracked people, gets paid tens of millions of dollars a year, probably. And we asked him, how much does the AI models help you in AI research? And he said, “in domains that I’m already quite familiar with, where it’s closer to autocomplete, it saves me four to eight hours a week”. And then he said, “but in domains where I’m actually less familiar, where I need to drive new connections, I need to understand how these different parts relate to each other, and so forth. It saves me close to 24 to 36 hours a week”.</span><br><span>And that’s the current models. And I’m just like, “he didn’t get more computed, but it still saved him like a shit ton more time”. Just draw that forward. That’s a crazy implication or crazy trend, right?</span><br><em><strong>Ege Erdil</strong><span> 00:54:58</span></em><br><span>I mean, I’m skeptical of the claims that we have actually seen that much of an acceleration in the process of R&amp;D. These claims seem to me, like they’re not borne out by the actual data I’m seeing. So I’m not sure how much to trust them.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:55:18</span></em><br><span>I mean, on the general intuition that cognitive effort alone can give you a lot of AI progress, it seems like a big important thing the labs do is this science of deep learning. Scaling laws… I mean, it ultimately netted out in an experiment, but the experiment is motivated by cognitive effort.</span><br><em><strong>Ege Erdil</strong><span> 00:55:36</span></em><br><span>So for what it’s worth, when you say that A and B are complementary, you’re not saying, just as A can bottleneck you, B can also bottleneck you. So when you say you need compute and experiments and data, but you also need cognitive effort, that doesn’t mean the lab which has the most compute is going to win, right? That’s a very simple point, either one can be the bottleneck.</span><br><span>I mean, if you just have a really dysfunctional culture and you don’t actually prioritize using your computer very well and you just waste it, well then you’re not going to make a lot of progress, right? So it doesn’t contradict the picture that someone with a much better vision, a much better team, much better prioritization can make better use of their compute if someone else was just bottlenecked heavily on that part of the equation. The question here is, once you get these automated AI researchers and you start this software singularity, your software efficiency is going to improve by many orders of magnitude, while your compute stock, at least in the short run, is going to remain fairly fixed. So how many OOMs of improvement can you get before you become bottlenecked by the second priority equation? And once you actually factor that in, like how much progress should you expect?</span><br><span>That’s the kind of question I think people don’t have. I think it’s hard for people to have good intuitions about this because people usually don’t run the experiments. So you don’t get to see at a company level, or at an industry level, what would have happened if the entire industry had 30 times less compute. Maybe as an individual, what would happen if you had 30 times less compute? You might have a better idea about that, but that’s a very local experiment and you might be benefiting a lot from spillovers from other people who actually have more compute. So because this experiment was never run, it’s sort of hard to get direct evidence about the strength of complementarity.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:57:27</span></em><br><span>Actually, what is your probability of, if we live in the world where we get AGI in 2027, that there is a software-only singularity?</span><br><em><strong>Tamay Besiroglu</strong><span> 00:57:35</span></em><br><span>Quite high, because you’re conditioning on compute not being very large. So it must be that you get a bunch of software progress.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:57:44</span></em><br><span>Yeah, right, right. Like you just have a bunch of leverage from algorithmic progress in that world.</span><br><em><strong>Tamay Besiroglu</strong><span> 00:57:50</span></em><br><span>OK, that’s right.</span><br><em><strong>Dwarkesh Patel</strong><span> 00:57:51</span></em><br><span>So then maybe, because I was thinking these are independent questions-</span><br><em><strong>Tamay Besiroglu</strong><span> 00:57:54</span></em><br><span>I think a call that I want to make is, I know that some labs do have multiple pre-training teams and they give people different amounts of resources for doing the training and different amounts of cognitive effort, different size of teams. But none of that, I think, has been published. And I’d love to see the results of some of those experiments.</span><br><span>I think even that won’t update you very strongly just because it is often just very inefficient to do this very imbalanced scaling of your factor inputs. And in order to really get an estimate of how strong these complementarities are, you need to observe these very imbalanced scale-ups. And so that rarely happens.</span><br><span>And so I think the data that bears on this is just really quite poor. And then the intuitions that people have also don’t seem clearly relevant to the thing that matters about what happens if you do this very imbalanced scaling and where does this net out?</span><br><em><strong>Dwarkesh Patel</strong><span> 00:58:53</span></em><br><span>One question I have, which it would be really interesting if somebody can provide an example of: maybe through history, there was some point at which because of a war or some other kind of supply shock, you had to ramp up production or ramp up some key output that people really cared about, while for some weird historical reason, many of the key inputs were not accessible to a ramp-up, but you could ramp-up one key input.</span><br><span>I’m talking in very abstract terms. You see what I’m saying, right? You need to make more bombers, but you ran out of aluminum and you need to figure out something else to do. And how successful these efforts have been or whether you just keep getting bottlenecked?</span><br><em><strong>Ege Erdil</strong><span> 00:59:35</span></em><br><span>Well, I think that is not quite the right way to do it. Because I think if you’re talking about materials, then I think there’s a lot of sense in which different materials can be substitutable for one another in different ways. You can use aluminum. I mean, aluminum is a great metal for making aircraft because it’s light and durable and so on. But you can imagine that you make aircraft with worse metals and then it just takes more fuel and it’s less efficient to </span><a href="http://fly.so/" rel="">fly.So</a><span> there’s a sense in which you can compensate and just cost more.</span><br><span>I think it’s much harder if you’re talking about something like complementarity between labor and capital, complementarity between remote work and in-person work or skilled or unskilled work. There are input pairs for which I would expect it to be much more difficult. For example, you’re looking at the complementarity between the quality of leadership of an army and its number of soldiers. There is some effect there, but if you just scale up, you have excellent leadership, but your army only has 100 people. You’re not going to get very far.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:00:40</span></em><br><span>King Leonidas and </span><a href="https://en.wikipedia.org/wiki/Battle_of_Thermopylae" rel="">Thermopylae</a><span>?</span><br><em><strong>Ege Erdil</strong><span> 01:00:44</span></em><br><span>Well, they lost, right?</span><br><em><strong>Dwarkesh Patel</strong><span> 01:00:47</span></em><br><span>It would be funny if we’re building models and software-only singularity and we’re like, “what exactly happened in Thermopylae?” It’s somehow relevant.</span><br><em><strong>Ege Erdil</strong><span> 01:00:53</span></em><br><span>I can actually talk about that, but we probably shouldn’t.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 01:00:57</span></em><br><span>Okay, sure. So the audience should know, my most popular guest by far is Sarah Paine. Not only is she my most popular guest, she’s my most popular four guests. Because all four of those episodes that I’ve done with her are, from a viewer-minute adjusted basis, I host the Sarah Paine Podcast where I occasionally talk about AI.</span><br><span>Anyways, we did this three-part lecture series where one of them was about </span><a href="https://www.dwarkesh.com/p/sarah-paine-india" rel="">India-Pakistan wars</a><span> through history. One of them was about </span><a href="https://www.dwarkesh.com/p/sarah-paine-japan" rel="">Japanese culture before World War II</a><span>. The third one was about </span><a href="https://www.dwarkesh.com/p/sarah-paine-china" rel="">the Chinese Civil War</a><span>. And for all of them, my history tutor was Ege. And, why does he know so much about fucking random 20th century conflicts? But he did, and he suggested a bunch of the good questions I asked her. We’ll get into that in a second. Ege, what’s going on there?</span><br><em><strong>Ege Erdil</strong><span> 01:01:56</span></em><br><span>I don’t know. I mean, I don’t really have a good question. I think it’s interesting. I mean, I read a bunch of stuff, but it’s a kind of boring answer. I don’t know. Imagine you ask a top AI researcher, “What’s going on? How are you so good?” And then they will probably give you a boring answer. Like, I don’t know.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:02:13</span></em><br><span>That itself is interesting that often these kinds of questions elicit boring answers. It tells you about the nature of the skill. How’d you find him?</span><br><em><strong>Tamay Besiroglu</strong><span> 01:02:22</span></em><br><span>We connected on a Discord for </span><a href="https://www.metaculus.com/" rel="">Metaculus</a><span>, which is this forecasting platform. And I was a graduate student at Cambridge at the time doing research in economics. And I was having conversations with my peers there. And I was occasionally having conversations with Ege. And I was like, “this guy knows a lot more about economics”. And at the time he was a computer science undergrad in Ankara. And he knows more about economics and about these big trends in economic growth and economic history than almost any of my peers at the university. And so like, what the hell is up with that?</span><br><span>And then we started having frequent collaborations and ended up hiring Ege for Epoch because it clearly makes sense for him to work on these types of questions.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:03:17</span></em><br><span>And it seems like at Epoch, you’ve just collected this group of internet misfits and weirdos.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:03:23</span></em><br><span>Yeah, that’s right.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:03:24</span></em><br><span>How did you start Epoch? And then how did you accomplish this?</span><br><em><strong>Tamay Besiroglu</strong><span> (01:03:27</span></em><br><span>So I was at MIT doing more research, and I was pretty unhappy with the bureaucracy there where it was very hard for me to scale projects up, hire people. And I was pretty excited about a bunch of work that my PI wasn’t excited about because it’s maybe hard to publish or it doesn’t confer the same prestige. And so I was chatting with </span><a href="https://jsevillamol.github.io/" rel="">Jaime Sevilla</a><span>, one of the co-founders, and we just collaborated on projects and then thought we should just start our own org, because we can just hire people and work on the projects we were excited about. And then I just hired a bunch of the insightful misfits that like…</span><br><em><strong>Dwarkesh Patel</strong><span> 01:04:12</span></em><br><span>But was the thesis like, “oh, there’s a bunch of underutilized internet misfits and therefore this org was successful”? Or you started the org and then you were like…</span><br><em><strong>Tamay Besiroglu</strong><span> 01:04:20</span></em><br><span>I think it’s more of the latter. So it was more like we can make a bunch of progress because clearly academia and industry is kind of dropping the ball on a bunch of important questions that academia is unable to publish interesting papers on. Industry is not really focused on producing useful insights. And so it seemed very good for us to just do that. And also the timing was very good. So we started just before ChatGPT and we wanted to have much more grounded discussions of the future of AI.</span><br><span>And I was frustrated with the quality of discussion that was happening on the internet about the future of AI. And to some extent or to a very large extent, I still am. And that’s a large part of what motivates me to do this. It’s just born out of frustration with bad thinking and arguments about where AI is going to go.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 01:06:24</span></em><br><span>OK, so let me ask you about this: So just to set the scene for the audience, we’re going to talk about the possibility of this explosive economic growth and greater than 30 percent economic growth rates. So I want to poke you both from a perspective of “maybe suggesting that this isn’t aggressive enough in the right kind of way, because it’s maybe it’s too broad”, and then I’ll poke you from the more normal perspective that, “hey, this is fucking crazy”.</span><br><em><strong>Ege Erdil</strong><span> 01:06:54</span></em><br><span>I imagine it would be difficult for you to do the second thing.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:06:57</span></em><br><span>No, I mean, I think it might be fucking crazy, let’s see. The big question I have about this broad automation, I get what you’re saying about the Industrial Revolution, but in this case, we can just make this argument that you get this intelligence and then what you do next is you go to the desert and you build this Shenzhen of robot factories which are building more robot factories, which are building… If you need to do experiments then you build bio labs and you build chemistry labs and whatever.</span><br><em><strong>Ege Erdil</strong><span> 01:07:30</span></em><br><span>Or you can build Shenzhen in the desert. I agree that looks much more plausible than a software-only singularity.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:07:35</span></em><br><span>But the way you’re framing it, it sounds like McDonald’s and Home Depot and fucking whatever are growing at 30 percent a year as well. The aliens’ level view of the economy is that there’s a robot economy in the desert that’s growing at 10,000 percent a year and everything else is the same-old-same-old, or is it like-</span><br><em><strong>Ege Erdil</strong><span> 01:07:57</span></em><br><span>No, I mean, there is a question about what would be possible, or physically possible, and what would be the thing that would actually be efficient. So it might be the case, and again, once you’re scaling up the hardware part of the equation as well as the software part, then I think the case for this feedback loop gets a lot stronger. If you scale up data collection as well, I think it gets even stronger, real world data collection by deployment and so on.</span><br><span>But building Shenzhen in a desert… if you think about the pipeline; so far we have relied first on the entire semiconductor supply chain. That industry depends on tons of inputs and materials. And it gets from probably tons of random places in the world. And creating that infrastructure, doubling, or tripling, whatever, that infrastructure, the entire thing. That’s very hard work. So probably you couldn’t even do it, even if you just have Shenzhen in a desert, that will be even more expensive than that.</span><br><span>And on top of that, so far, we have been drawing heavily on the fact that we have built up this huge stock of data, over the past 30 years or something, on the internet. Imagine you were trying to train a state-of-the-art model, but you only have 100 billion tokens to train on. That would be very difficult. So in a certain sense, our entire economy has produced this huge amount of data on the internet that we are now using to train the models. It’s plausible that in the future, when you need to get new competencies added to these systems, the most efficient way to do that will be to try to leverage similar kinds of modalities of data, which will also require this… you would want to deploy the systems broadly because that’s going to give you more data. And maybe you can get where you want to be without that, but it would just be less efficient if you’re starting from scratch compared to if you’re collecting a lot of data.</span><br><span>I think this is actually a motivation for why labs want their LLMs to be deployed widely, because sometimes when you talk to ChatGPT, it’s going to give you two responses and it’s going to say, well, which one was good? Or it’s going to give you one response and it’s going to ask you, was this good or not? Well, why are they doing that, right? That’s a way in which they are getting user data through this extremely broad deployment. So I think you should just imagine that thing to continue to be efficient and continue to increase in the future because it just makes sense.</span><br><span>And then there’s a separate question of, well, suppose you didn’t do any of that. Suppose you just tried to imagine the most rudimentary, the narrowest possible kind of infrastructure build-out and deployment that would be sufficient to get this positive feedback loop that leads to much more efficient AIs. I agree that loop could, in principle, be much smaller than the entire world. I think it probably couldn’t be as small as Shenzhen in the desert, but it could be much smaller than the entire world. But then there’s a separate question of, would you actually do that? Would that be efficient? I think some people have the intuition that there are just these extremely strong constraints, maybe regulatory constraints, maybe social political constraints, to doing this broad deployment. They just think it’s going to be very hard.</span><br><span>So I think that’s part of the reason why they imagine these narrower scenarios where they think it’s going to be easier. But I think that’s overstated. I think people’s intuitions for how hard this kind of deployment is comes from cases where the deployment of the technology wouldn’t be that valuable. So it might come from housing. We have a lot of regulations on housing. Maybe it comes from nuclear power. Maybe it comes from supersonic flights. I mean, those are all technologies that would be useful if they were maybe less regulated. But they wouldn’t double.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:11:52</span></em><br><span>I think the core point here is the value of AI automation and deployment is just extremely large, even just for workers. There might be some kind of displacement and there might be some transition that you need to do in order to find a job that works for you, but otherwise the wages could still be very high for a while at least.</span><br><span>And on top of that, the gains from owning capital might be very enormous. And in fact, a large share of the US population would benefit… They benefit, they own housing, they have 401ks. Those would do enormously better when you have this process of broad automation and AI deployment. And so I think there could just be a very deep support for some of this, even when it’s totally changing the nature of labor markets and the skills and occupations that are in demand.</span><br><em><strong>Ege Erdil</strong><span> 01:12:55</span></em><br><span>So I would just say it’s complicated. I think what the political reaction to it will be when this starts actually happening, I think the easy thing to say is that, yeah, this will become a big issue and then it will be maybe controversial or something. But what is the actual nature of the reaction in different countries? I think that’s kind of hard to forecast. I think the default view is like, “well, people are going to become unemployed, so it will just be very unpopular”. I think that’s very far from obvious.</span><br><span>And I just expect heterogeneity in how different countries respond. And some of them are going to be more liberal about this and going to have a much broader deployment. And those countries probably end up doing better. So just like during the Industrial Revolution, some countries were just ahead of others. I mean, eventually almost the entire world adopted the sort of norms and culture and values of the Industrial Revolution in various ways.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:13:44</span></em><br><span>And actually, you say they might be more liberal about it, but they might actually be less liberal in many ways. In fact, that might be more functional in this world in which you have broad AI deployment. We might adopt the kind of values and norms that get developed in, say, the UAE or something, which is maybe focused a lot more on making an environment that is very conducive for AI deployment. And we might start emulating and adopting various norms like that. And they might not be classical liberal norms, but norms that are just more conducive to AI being functional and producing a lot of value.</span><br><em><strong>Ege Erdil</strong><span> 01:14:27</span></em><br><span>This is not meant to be a strong prediction, this is just an illustrative. It might just be the freedom to deploy AI in the economy and build out lots of physical things at scale, maybe that ends up being more important in the future. Maybe that is still missing something, maybe there are some other things that are also important. The generic prediction that you should expect variance and some countries do better than others, I think that’s much easier to predict than the specific countries that end up doing better.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:14:55</span></em><br><span>Yeah. Or the norms that that country wants.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:14:56</span></em><br><span>That’s right.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:14:57</span></em><br><span>One thing I’m confused about is, if you look at the world of today versus the world of 1750, the big difference is just we’ve got crazy tech that they didn’t have back then. We’ve got these cameras, we’ve got these screens, and we’ve got rockets and so forth. And that just seems like the result of technological growth and R&amp;D and so forth.</span><br><em><strong>Ege Erdil</strong><span> 01:15:22</span></em><br><span>It’s a capital accumulation.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:15:23</span></em><br><span>Well, explain that to me because you’re just talking about this infrastructure build out and blah, blah, blah. I’m like, but why won’t they just fucking invent the kinds of shit that humans would have invented by 2050?</span><br><em><strong>Ege Erdil</strong><span> 01:15:37</span></em><br><span>Producing this stuff takes a lot of infrastructure build-out.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:15:40</span></em><br><span>But that infrastructure is built out once you make the technology, right?</span><br><em><strong>Tamay Besiroglu</strong><span> 01:15:45</span></em><br><span>I don’t think that’s right. There isn’t this temporal difference where it’s first you do the invention… often there’s this interplay between the actual capital buildup and the innovation.</span><br><em><strong>Ege Erdil</strong><span> 01:15:57</span></em><br><span>Learning curves are about this, right, fundamentally? What has driven the increase in the efficiency of solar panels over the past 20, 30 years?</span><br><em><strong>Tamay Besiroglu</strong><span> 01:16:05</span></em><br><span>It isn’t just like people had the idea of 2025 solar panels. Nobody 20 years ago had the sketch for the 2025 solar panel. It’s this kind of interplay between having ideas, building, learning, producing, and-</span><br><em><strong>Ege Erdil</strong><span> 01:16:24</span></em><br><span>Other complementary inputs also becoming more efficient at the same time, like you might get better materials. For example, the fact that smelting processes got a lot better towards the end of the 19th century, so it became a lot easier to work with metal, maybe that was a crucial reason why aircraft technology later became more popular.</span><br><span>It’s not like someone came up with the idea of, “oh, you can just use something that just has wings and has a lot of thrust, and then that might be able to fly”. That basic idea is not that difficult, but then, well, how do you make it actually a viable thing? Well, that’s much more difficult.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:17:04</span></em><br><span>Have you seen the meme where two beavers are talking to each other and they’re looking at the Hoover Dam? One of them’s like, “</span><a href="https://pbs.twimg.com/media/FYspuNGXwAEWwXw.jpg" rel="">well, I didn’t build that, but it’s based on an idea of mine</a><span>”. The point you’re making is that this invention-focused look on tech history underplays the work that goes into making specific innovations practicable and to deploy them widely.</span><br><em><strong>Ege Erdil</strong><span> 01:17:33</span></em><br><span>It’s just hard, I think. Suppose you want to write a history of this, you want to write the history of how the light bulb was developed or something. It’s just really hard. Because to understand why specific things happen at specific times, you probably need to understand so much about the economic conditions of the time.</span><br><span>For example, Edison spent a ton of time experimenting with different filaments to be using the light bulb. The basic idea is very simple. You make something hot and it glows, but then what filament actually works well for that in a product? What is durable? What has the highest ratio of light output versus heat so that you have less waste, it’s more efficient. And even after you have the product, then you’re facing the problem, well, it’s 1880 or something and US homes don’t have electricity, so then nobody can use it. So now you have to build power plants and build power lines to the houses so that people have electricity in their homes so that they can actually use this new light bulb that you created. So he did that, but then people present it as if it’s like, “okay, he just came up with the idea”, like “it’s a light bulb”.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:18:46</span></em><br><span>I guess the thing people would say is, you’re right about how technology would progress if we were humans deploying for the human world. But what you’re not counting is there’s going to be this AI economy where maybe they need to do this kind of innovation and learning by doing when they’re figuring out how to, “I want to make more robots because they’re helpful and so we’re going to build more robot factories, we’ll learn and then we’ll make better robots” or whatever. But geographically, that is a small part of the world that’s happening in. You understand what I’m saying? It’s not like, “and then they walk in your building and then you do a business transaction with Lunar Society podcast LLC and then”, you know what I mean?</span><br><em><strong>Ege Erdil</strong><span> 01:19:30</span></em><br><span>For what it’s worth, if you look at the total surface area of the world, it might well be the case that the place that initially experiences this very fast growth is a small percentage of the surface area of the world. And I think that was the same for the Industrial Revolution, it was not different.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:19:49</span></em><br><span>What concretely does this explosive growth look like? If I look at this heat map of growth rates on the globe, is there just going to be one area that is blinding hot and that’s the desert factories with all these experiments and like…</span><br><em><strong>Ege Erdil</strong><span> 01:20:03</span></em><br><span>I would say our idea is that it’s going to be broader than that, but probably initially… So eventually it would probably be most of the world. But as I said, because of this heterogeneity, because I think some countries are going to be faster in adoption than others, maybe some cities will have faster adoption than others, that will mean that there are differentials and some countries might have much faster growth than other countries.</span><br><span>But I would expect that at a jurisdiction level, it will be more homogenous. So, for example, I expect the primary obstacles to come from things like regulation. And so I would just imagine it’s being more delineated by regulatory jurisdiction boundaries than anything else.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:20:48</span></em><br><span>Got it. So you may be right that this infrastructure build-out and capital deepening and whatever l is necessary for a technology to become practical, but…</span><br><em><strong>Ege Erdil</strong><span> 01:20:57</span></em><br><span>Or even to be discovered. There’s an aspect of it where you discover certain things by scaling up, learning by doing, that’s the [?] learning curve. And there’s this separate aspect where, suppose that you become wealthier, well, you can invest that increased wealth in, you use it to accumulate more capital, but you also can invest it in R&amp;D and other ways.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:21:21</span></em><br><span>You get Einstein out of the patent office. You need some amount of resources for that to make sense. And you need the economy to be of a certain scale. You also need demand for the product you’re building. So, you could have the idea, but if the economy is just too small that there isn’t enough demand for you to be specializing and producing the semiconductor or whatever, because there isn’t enough demand for it, then it doesn’t make sense.</span><br><span>A much larger scale of an economy is useful in many ways in delivering complementary innovations and discoveries happening through serendipity, producing, having there be consumers that would actually pay enough for you to recover your fixed costs of doing all the experimentation and the invention. You need the supply chains to exist to deliver the germanium crystals that you need to grow in order to come up with the semiconductor. You need a large labor force to be able to help you do all the experiments and so on.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>01:22:20</em><br><span>I think the point you’re illustrating is, “look, could you have just figured out that there was a Big Bang by first principles reasoning?” Maybe. But what actually happened is we had World War II and we discovered radio communications in order to fight and effectively communicate during the war.</span><br><span>And then that technology helped us build radio telescopes. And then we discovered the cosmic microwave background. And then we had to come up with an explanation for the cosmic microwave background. And then we discovered the Big Bang as a result of World War II.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:22:46</span></em><br><span>People underemphasize that giant effort that goes into this build-up of all the relevant capital and all the relevant supply chains and the technology. I mean earlier you were making a similar comment when you were saying, “oh reasoning models actually in hindsight, they look pretty simple”, but then you’re ignoring this giant upgrading of the technology stack that happened, that took five to 10 years prior to that. And so I think people just underemphasize the support that is had from the overall upgrading of your technology, of the supply chains, of various sectors that are important for that.</span><br><span>And people focus on just specific individuals of like, Einstein had this genius insight and he was the very pivotal thing in the causal chain that resulted in these discoveries. Or Newton was just extremely important for discovering calculus without thinking about, well, there were all these other factors that produced lenses, that produced telescopes, that got the right data and that made people ask questions about dynamics and so on that motivated some of these questions. And those are also extremely important for scientific and technological innovation.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:24:06</span></em><br><span>And then, as you were saying, one of Conquest laws is, </span><a href="https://www.nationalreview.com/corner/conquests-laws-john-derbyshire/" rel="">the more you understand about a topic, the more conservative you become about that topic</a><span>. And so there may be a similar law here, where the more you understand about an industry, the more- obviously, I’m just a commentator, or a podcaster, but I understand AI better than any other industry I understand. And I have the sense from talking to people like you that, “oh, so much went into getting AI to the point where it is today”. Whereas when I talk to journalists about AI, they’re like, “okay, who is a crucial person we need to cover?” And they’re like, “should we get in touch with Geoffrey Hinton? Should we get in touch with Ilya?” And I just have this like, “you’re kind of missing the picture”.</span><br><span>But then you should have that same attitude towards things you… Or maybe it’s a similar phenomenon to </span><a href="https://en.wikipedia.org/wiki/Gell-Mann_amnesia_effect" rel="">Gell-Mann amnesia</a><span>, we should have a similar attitude towards other industries.</span><br><em><strong>Ege Erdil</strong><span> 01:24:59</span></em><br><span>Robin Hanson has this abstraction of seeing things in </span><a href="https://www.lesswrong.com/w/near-far-thinking" rel="">near mode versus far mode</a><span>. And I think if you don’t know a lot about the topic, then you see it in far mode and you simplify things, you see a lot more detail. In general, I think the thing I would say, and the reason I also believe that abstract reasoning and deductive reasoning or even Bayesian reasoning by itself is not sufficient or is not as powerful as many other people think, is because I think there’s just this enormous amount of richness and detail in the real world that you just can’t reason about it. You need to see it. And obviously that is not an obstacle to AI being incredibly transformative because as I said, you can scale your data collection, you can scale experiments you do both in the AI industry itself and just more broadly in the economy, so you just discover more things. More economic activity means we have more exposed surface area to have more discoveries.</span><br><span>All of these are things that have happened in our past, so there’s no reason that they couldn’t speed up. The fundamental thing is that there’s no reason fundamentally why economic growth can’t be much faster than it is today. Like it’s probably as advanced right now just because humans are such an important bottleneck. They both supply the labor. They play crucial roles in the process of discovery of various kinds of productivity growth. There’s just strong complementarity to some extent with capital that you can’t substitute machines and so on for humans very well. So the growth of the economy and growth productivity just ends up being bottlenecked by the growth of human population.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:27:39</span></em><br><span>So let me ask you a tangential question. What’s been happening in China over the last 50 years, would you describe that as, in principle, the same kind of explosive growth that you expect from AI? Because there’s a lot of labor that makes the marginal product of capital really high, which allows you to have 10% plus economic growth rates. Is that basically in principle from AI?</span><br><em><strong>Ege Erdil</strong><span> 01:28:01</span></em><br><span>So I would say in some ways it’s similar, in some ways it’s not. Probably the most important way in which it’s not similar is that in China, you see a massive amount of capital accumulation, a substantial amount of adoption of new technologies and probably also human capital accumulation to some extent. But you’re not seeing a huge scale up in the labor force. While for AI, you should expect to see a scale up in the labor force as well, not in the human workforce, but in the AI workforce.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:28:34</span></em><br><span>And I think you did, maybe not consecutive increases in the labor force…</span><br><em><strong>Tamay Besiroglu</strong><span> 01:28:38</span></em><br><span>The key thing here is just the simultaneous scaling of both these things. And so you might ask the question of “isn’t it basically half of what’s going to happen with AI that you scale up capital accumulation in China?” But actually if you get both of these things to scale, that gives you just much faster growth and a very different picture.</span><br><em><strong>Ege Erdil</strong><span> 01:29:04</span></em><br><span>But at the same time, if you’re just asking what 30 percent growth per year would look like, if you just want to have an intuition for how transformative that would be in concrete terms, then I think looking at China is not such a bad case. Especially in the 2000s or maybe late 90s, that seems slower than what we’re forecasting.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:29:24</span></em><br><span>Right. I think also looking at the Industrial Revolution is pretty good.</span><br><em><strong>Ege Erdil</strong><span> 01:29:26</span></em><br><span>Well, the Industrial Revolution is very slow.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:29:28</span></em><br><span>But just in terms of the margins along which we made progress in terms of products. So the thing that didn’t happen during the industrial revolution is we just produced a lot more of things that people were producing prior to the industrial revolution, like producing a lot more crops and maybe a lot more kind of pre-Industrial Revolution style houses or whatever, on farms. Instead, what we got is along pretty much every main sector of the economy, we just had many different products that are totally different from what was being consumed prior to that. So in transportation, in food.</span><br><em><strong>Ege Erdil</strong><span> 01:30:13</span></em><br><span>I mean, health care is a very big deal and antibiotics.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:30:16</span></em><br><span>So another question, because I’m not sure I understand how you’re defining the learning by doing versus explicit R&amp;D, because there’s the way for taxes that companies say what they call R&amp;D. But then there’s the intuitive understanding of R&amp;D. So if you think about how AI is boosting </span><a href="https://en.wikipedia.org/wiki/Total_factor_productivity" rel="">TFP</a><span>, you could say that right now, if you just had replaced the </span><a href="https://en.wikipedia.org/wiki/TSMC" rel="">TSMC</a><span> process engineers with AIs and they’re finding different ways in which to improve that process and improve efficiencies, improve yield, I would kind of call that R&amp;D. On the other hand, you emphasize this other part of TFP, which is like better management and that kind of stuff.</span><br><em><strong>Ege Erdil</strong><span> 01:30:59</span></em><br><span>The learning by doing could be, you could-</span><br><em><strong>Dwarkesh Patel</strong><span> 01:31:00</span></em><br><span>But how much “umph” are you… Like you’re going to get to the fucking Dyson Sphere by better management?</span><br><em><strong>Ege Erdil</strong><span> 01:31:05</span></em><br><span>But that’s not the argument, right? The point is that there are all these different things, some of them are maybe more complimentary than others. The point is not that you can get to a Dyson sphere by just scaling labor and capital. That’s not the point. You need to scale everything at once. So just as you can’t get to a Dyson sphere by just scaling labor and capital, you also can’t get to it by just scaling TFP. That doesn’t work.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:31:30</span></em><br><span>I think there’s a very important distinction between what is necessary to scale, to get to this Dyson sphere world and what is important. Like in some sense, producing food is necessary. But of course, producing food doesn’t get you to a Dyson sphere, right? So I think R&amp;D is necessary, but on its own isn’t sufficient. And scaling up the economy is also necessary. On its own, it’s not sufficient. And then you can ask the question, what is the relative importance of each?</span><br><em><strong>Ege Erdil</strong><span> 01:32:00</span></em><br><span>So I think our view here is very much the same. It is very connected to our view about the software R&amp;D thing where we’re just saying there are these bottlenecks, so you need to scale everything at once. This is just a general view.</span><br><span>But I think people misunderstand us sometimes as saying that R&amp;D is not important. No, that’s not what we’re saying. We’re saying it is important. It is </span><em>less</em><span> important in </span><em>relative</em><span> terms than some other things, none of which are by themselves sufficient to enable this growth. So the question is, how do you do the credit attribution? One of my missions in economics is to look at the elasticities of output to the different factors. Capital is less important than labor, because labor elasticity output is like 0.6, while for capital it’s like 0.3. But neither are by themselves sufficient. If you just scaled one of them and the other remained fixed, then neither would be sufficient to indefinitely scale output.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 01:33:00</span></em><br><span>One question that Daniel posed to me is, because I made this perspective about everything being interconnected when you were talking about… another example people often bring up is what would it take to build the iPhone in the year 1000? And it’s unclear how you could actually do that without just replicating every intermediate technology or most intermediate technologies.</span><br><span>And then he made the point like, OK, fine, whatever. Nanobots are not a crux here. The crux, at least to the thing he cares about, which is human control, is just by when can the robot economy, or the AI economy, whether it’s a result of capital deepening or whether it’s a result of R&amp;D, by when will they have the robots? And they have more cumulative physical power?</span><br><em><strong>Ege Erdil</strong><span> 01:33:50</span></em><br><span>Right. But he’s imagining a separate thing called the AI economy. Well, why would you imagine that? I think it’s probably downstream of his views about the software-only singularity. But again, those are views that we don’t share.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:34:01</span></em><br><span>So it’s just much more efficient for AI to operate in our economy and benefit from the existing supply chains and existing markets rather than set up shop on some island somewhere and do its own thing.</span><br><em><strong>Ege Erdil</strong><span> 01:34:16</span></em><br><span>And then it’s not being clear, for example people might have the intuition- I brought this up before- the distinction between what is the minimum possible amount of build-out that would be necessary to get this feedback loop up and running and what would be the most efficient way to do it? Which are not the same question. But then people have this view that, oh, the most efficient thing in principle, we can’t do that because…</span><br><em><strong>Dwarkesh Patel</strong><span> 01:34:36</span></em><br><span>I think the example he might give is when the conquistadors arrived in the New World or when the East India Trading Company arrived in India, they did integrate into the existing economy. In many cases, it depends on how you define ‘integrate’, but the Spanish relied heavily on New World labor in order to do silver mining and whatever. East India Trading Company was just a ratio of British people to Indian people, which is not that high. So they just had to rely on the existing labor force. But they were still able to take over because of… I don’t know what the analogous thing here is, but you see what I’m saying.</span><br><span>And so he’s concerned about, by when will they, even if they’re ordering components off of Alibaba or whatever- and sorry, I’m being trite, but you see what I’m saying. Even if they’re going to get into the supply chains, by when are they in a position where, because this part of the economy has been growing much faster, they could take over the government or…</span><br><em><strong>Ege Erdil</strong><span> 01:35:40</span></em><br><span>If they wanted to?</span><br><em><strong>Dwarkesh Patel</strong><span> 01:34:41</span></em><br><span>That’s right, yeah.</span><br><em><strong>Ege Erdil</strong><span> 01:35:42</span></em><br><span>Okay. So I think that eventually you expect the AI systems to be driving most of the economy. And unless there are some very strange coincidences where humans are able to somehow uplift themselves and able to become competitive with the AIs by stopping being biological humans or whatever, which seems very unlikely early on, then AI is just going to be much more powerful. And I agree that in that world, if the AI is just somehow coordinated and decides, “okay, we should just like take over” or something, they just somehow coordinated to have that goal, then they could probably do it.</span><br><span>But, that’s also probably true in our world. In our world, if the US wanted to invade Sentinel Island, then probably they could do it. I don’t think anyone could stop them. But what does it actually mean? There’s this dramatic power imbalance, but that doesn’t mean… that doesn’t tell you what’s going to happen, right? Why doesn’t the US just invade Guatemala or something? Why don’t they do that? Seems like they could easily do it.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:36:53</span></em><br><span>Because the value to the US of…</span><br><em><strong>Ege Erdil</strong><span> 01:36:56</span></em><br><span>Not that high, right?</span><br><em><strong>Dwarkesh Patel</strong><span> 01:36:58</span></em><br><span>Yeah. So I agree that might be true for AIs because most of the shit is in space. And you want to do the capital deepening on Mars and the surface of the sun instead of like New York City.</span><br><em><strong>Ege Erdil</strong><span> 01:37:13</span></em><br><span>I think it’s deeper than that. So it’s deeper than that. There’s also the fact that if the AIs are going to be integrated into our economy…</span><br><span>So basically they start out as a small part of our economy or our workforce and over time they grow and over time they become the vast majority of the actual work power in the economy. But they are growing in this existing framework where we have norms and rules for better coordination and then undermining those things has a cost. So if getting the things that are making the humans wealthier than they used to be before and more comfortable, yeah, you would probably be better off if you could just take that from them. But the benefit to you, if you already are getting almost all of the income in the economy, will be fairly small.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:38:03</span></em><br><span>I feel like the Sentinel Islands thing, there’s one reference class that includes that. But historically, there’s a huge reference class that includes; East India Trading Company could have just kept trading with the Mughals, they just took over, right? They could have kept trading with the 50 different nation states in pre-colonial India. But yeah.</span><br><em><strong>Ege Erdil</strong><span> 01:38:21</span></em><br><span>That’s right. I mean, that’s what they were initially doing. And then whatever. I’m not going to go into that subject.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:38:27</span></em><br><span>But that is the reference class…</span><br><em><strong>Ege Erdil</strong><span> 01:38:30</span></em><br><span>I agree. I agree. So if the question is, if they have some totally different values and then they represent most of the economy, then would they take over? I still don’t know, because I’m not sure to what extent the class of all AI is a natural class. It’s sort of like, why don’t the young people in the economy coordinate?</span><br><em><strong>Dwarkesh Patel</strong><span> 01:38:54</span></em><br><span>I agree that sometimes these kinds of class arguments are misused. For example, when Marxists are like, “why don’t this class rise up against the others?”</span><br><span>Daniel made the interesting argument that if you look at the history of the conquistadors, when Cortes was making his way through the new world, he had to actually go back and fight off a Spanish fleet that had been sent to arrest him and then go back. So you can have this fight within this conquering AIs and then that still nets out to the Native Americans getting disempowered.</span><br><span>But with AIs in particular, they’re just copies of each other. And in many other ways, they have lower transaction costs when they trade with each other or interact with each other. There’s other reasons to expect them to be more compatible coordinating with each other than coordinating with the human world.</span><br><em><strong>Ege Erdil</strong><span> 01:39:48</span></em><br><span>Sure. If the question is just that, “is it possible for that to happen?”, which is a weaker claim, then yeah, it seems possible. But there are, I think, a lot of arguments pushing back against it. Probably actually the biggest one is the fact that AI preferences are just not… Just look at the AIs we have today. Can you imagine them doing that? I think people just don’t put a lot of weight on that, because they think once we have enough optimization pressure and once they become super intelligent, they’re just going to become misaligned. But I just don’t see the evidence for that.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:40:24</span></em><br><span>I agree there’s some evidence that they’re good boys.</span><br><em><strong>Ege Erdil</strong><span> 01:40:28</span></em><br><span>No, there’s more than some evidence.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:40:30</span></em><br><span>No, but there’s also some evidence… There’s a new </span><a href="https://openai.com/index/chain-of-thought-monitoring/" rel="">openAI paper</a><span> where in chain of thought, reward hacking is such a strong basin that if you were like, “hey, let’s go solve this coding problem”, In the chain of thought, they’ll just be like, “okay, let’s hack this and then figure out how to hack it.”</span><br><em><strong>Ege Erdil</strong><span> 01:40:48</span></em><br><span>So imagine that you gave students at a school a test and then the answer key was like on the back.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:40:52</span></em><br><span>Right, but the reference class of humans does include Cortes and the East Indian Trading Company.</span><br><em><strong>Ege Erdil</strong><span> 01:40:57</span></em><br><span>Sure.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:40:58</span></em><br><span>So I think one issue here is that I think people are doing this very kind of </span><a href="https://en.wikipedia.org/wiki/Partial_equilibrium" rel="">partial equilibrium analysis</a><span> or something where they’re thinking about these raw abilities of AI systems in a world where AI systems are dominant and human civilization has done very little in terms of integrating itself and the AI is integrating itself into the human world. Insofar as it’s poor at communicating and coordinating with AI, addressing those deficiencies and improving that. Insofar as that’s posing a risk, or creating inefficiencies, because it’s unable to benefit from coordinating and trading, then it should have this enormous incentive to address that.</span><br><span>Insofar as there is a lot of value to be gained from dominating and taking over humans, what you might get is a more negotiated settlement. If that’s indeed the case, then a war would just be inefficient. And so you would want to negotiate some settlement that results in some outcomes that are mutually beneficial.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:42:05</span></em><br><span>Compared to the counterfactual, not compared to… There was a mutually beneficial trade that was made between the Qing dynasty and the British in the opium wars, right? But it was maybe better than pre-industrial China going to war with the British empire, but it wasn’t better than never having interacted with the British empire in the first place.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:42:28</span></em><br><span>So I think one mistake that I feel people make is they have this very naive analysis of what creates conflict. And I think Matthew has written a bit about this, a colleague of ours, where they say there’s misalignment. And so that then creates conflict.</span><br><span>But that’s actually not what the literature on what causes conflict says creates conflict. It’s not just misalignment, it’s also other issues like having a bad understanding of the relative strengths of your armies versus theirs, or maybe having these very strong commitments that you think some grounds are sacred, and so you’re not willing to do any trade in order to give up some of that in order to gain something else. And so then you have to posit some additional things other than just the base value misalignment part.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:43:27</span></em><br><span>I think you’re making a good argument against, like, “humans take up the spears and the machetes and go to war against the AI data centers”, because maybe there’s not this asymmetric information that often leads to conflicts in history. But this argument does not address at all the risk of takeover, which can be the result of a peaceful end negotiation or human society being like, “look, we’re totally outmatched. And we’ll just take these meager concessions rather than go to war”.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:43:57</span></em><br><span>But insofar as it’s more peaceful, then I think it’s like much less of a thing to worry about. I think there could be this trend where we indeed have this gradual process where AI is much more important in the world economy and actually deciding and determining what happens in the world. But this could be beneficial for humans where we’re getting access to this vast, much, much larger economy and much more advanced technological stock.</span><br><em><strong>Ege Erdil</strong><span> 01:44:30</span></em><br><span>Yeah. So I think it’s important to be clear about what is the thing that you’re actually worried about. Because I think some people just say that, “oh, humans are going to lose control of the future, we’re not going to be the ones that are making the important decisions. We, however, concede", that’s also kind of nebulous.</span><br><span>But is that something to worry about? If you just think biological humans should remain in charge of all important decisions forever, then I agree, the development of AI seems like a problem for that. But in fact, other things also seem like a problem for that, I just don’t expect to generically be true. Like in a million years from now, if even if you don’t develop AI, biological humans, the way we recognize them today, are still making all the important decisions</span><br><span>and they have something like the culture that we would recognize from ourselves today. I would be pretty surprised by that.</span><br><span>I think Robin Hanson has again talked about this, where he said </span><a href="https://quillette.com/2023/04/14/what-are-reasonable-ai-fears/" rel="">a bunch of the things that people fear about AI are just things they fear about change and fast change</a><span>. So the thing that’s different is that AI has a prospect of accelerating much of this change so that it happens in a narrower period.</span><br><em><strong>Dwarkesh Patel</strong></em><span> </span><em>01:45:36</em><br><span>I think it’s not just the kind of change that would have happened from, let’s say, genetically modifying humans and blah, blah, blah, is instead happening in a compressed amount of time. I think the worry comes more from like, it’s not just that change compressed. It’s a very different vector of change .</span><br><em><strong>Ege Erdil</strong><span> 01:45:53</span></em><br><span>Yeah, but what is the argument for that? I have never seen a good argument for this.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:45:58</span></em><br><span>You should expect a bunch of change if you accelerate just human change as well. You might expect different values to become much more dominant. You might expect people that don’t discount the future as much to be much more influential because they save more and they make good investments that gives them more control.</span><br><em><strong>Ege Erdil</strong><span> 01:46:17</span></em><br><span>People who are higher risk tolerance.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:46:18</span></em><br><span>Higher risk tolerance. Because they are more willing to make bets that maximize expected value and so get much more influence. So just generically, accelerating human change would also result in a lot of things being lost that you might care about.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:46:34</span></em><br><span>I think the argument is that maybe the speed of the change determines what fraction of the existing population or stakeholders or whatever, have some causal influence on the future. And maybe the thing you care about is, look, there’s going to be change, but it’s not just going to be like one guy presses a button. That’s like the software singularity extreme. It’s more like over time norms change and so forth.</span></p><p><em><strong>Ege Erdil</strong><span> 01:47:08</span></em><br><span>So if you’re looking at the software singularity picture, I agree that picture looks different. And again, I’m coming back to this because obviously Daniel, and maybe Scott to some extent, they probably have this view that the software-only singularity is more plausible. And then one person, we could end up in a situation where their idiosyncratic preferences or something end up being more influential.</span><br><span>I agree that makes the situation look different from if you just have this broader process of automation. But even in that world, I think a lot of people have this view about things like </span><a href="https://forum.effectivealtruism.org/topics/value-lock-in" rel="">value lock-in</a><span>, where they think this moment is a pivotal moment in history. And then someone is going to get this AI, which is very powerful because of the software-only singularity. And then they’re just going to lock in some values. And then those values are going to be stable for millions of years.</span><br><span>And I think that just looks very unlike anything that has happened in the past. So I’m kind of confused why people think it’s very plausible. I think people have the argument that they see the future, again, in my view, in sort of ‘far mode’. They think there’s going to be one AI. It’s going to have some kind of utility function. That utility function is going to be very stable over time, so it’s not going to change, there won’t be this messiness of a lack of coordination between different AIs, or over time values drifting for various reasons, maybe because they become less functional in an environment, maybe because of other reasons. And so they just don’t imagine that. They say, “well, utility functions, we can preserve them forever. We have the technology to do that. So it’s just going to happen”. And I’m like, “well, that seems like such a weak argument to me”.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:48:50</span></em><br><span>Often the idea is, because this is digital you can preserve the information better and copy it with higher fidelity and so on. But actually, even if you look just at information on the internet, you have this thing called </span><a href="https://en.wikipedia.org/wiki/Link_rot" rel="">link rot</a><span>, which happens very quickly. And actually, information that’s digital isn’t preserved for very long at all.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:49:15</span></em><br><span>And the point that Matthew was making is that the fact that the information is digital has led to- not maybe led to, but at least been associated with- faster cultural change.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:49:25</span></em><br><span>Cultural change, exactly.</span><br><em><strong>Ege Erdil</strong><span> 01:49:26</span></em><br><span>I mean, basically technological changes can create incentives for cultural change just as they make preserving…</span><br><em><strong>Dwarkesh Patel</strong><span> 01:49:32</span></em><br><span>I think there’s two key arguments that I’ve heard. One is that we will soon reach something called </span><a href="https://en.wikipedia.org/wiki/Mature_technology" rel="">technological maturity</a><span>. And one of the key ways in which society has been changing recently is- maybe actually its culture would have changed even more. Actually, no, I think this argument that you’re making is wrong, because we do know that language actually changed a lot more. We can read everything that was written after the 1800s when literacy became more common. But just go back a couple hundred years after that and you’re reading old English and it’s hard to understand. And that is a result of literacy and the codification of language.</span><br><em><strong>Ege Erdil</strong><span> 01:50:09</span></em><br><span>Well, that information was better preserved. What about other kinds of cultural practices?</span><br><em><strong>Dwarkesh Patel</strong><span> 01:50:12</span></em><br><span>But I think the argument would be that change was a result of technological change in general, not the result of information being digitized. And maybe that culture would have actually changed more if information wasn’t as well preserved or technology had continued to proceed. And the argument is, in the future we’re going to reach some point at which you’ve done all the tech, ideas have just gotten way too hard to find and you need to make a CERN that’s the size of a galaxy to progress physics an inch forward.</span><br><span>And at that point, there’s this growth in technology, just churning over civilization goes away. And then you just have the digital thing, which does mean that a lock-in is more plausible.</span><br><em><strong>Tamay Besiroglu</strong><span> 01:51:00</span></em><br><span>So the technological maturity thing, I agree that results in this slowdown and change and growth and so on and certain things might get more locked-in relative to what preceded it. But then what do we do today about that? Well, what could you do to have a positive impact by our lights?</span><br><span>Robin Hanson had this question of what could someone do in the 1500s to have a positive impact on the world today from their point of view, knowing all they knew back then? I think this question is even worse than that, because I think the amount of change that happens between today and technological maturity is just orders of magnitude greater than whatever change happened between the 1500s and today.</span><br><span>So it’s an even worse position than someone in the 1500s thinking about what they could do to have a positive impact in expectation, like predictably positive today. And so I think it’s just pretty hopeless. I don’t know if we could do anything or find any candidate set of actions that would make things better post lock-in.</span><br><em><strong>Ege Erdil</strong><span> 01:52:05</span></em><br><span>I mean, that’s assuming lock-in is going to happen, which is not…</span><br><em><strong>Dwarkesh Patel</strong><span> 01:52:08</span></em><br><span>In the 1700s, a bunch of British abolitionists were making the case against slavery. And I don’t think there’s any in-principle reason why we couldn’t have been a slave society to this day, or more of the world couldn’t have slavery. I think what happened is just the convincing of British people that slavery is wrong, the British Empire put all its might into abolishing slavery and making that a norm.</span><br><span>I think another example is Christianity and the fact that Jesus has these ideals, you could talk about these ideals. I think the world is a more Christian place.</span><br><em><strong>Ege Erdil</strong><span> 01:52:45</span></em><br><span>It is a more Christian place, sure.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:52:57</span></em><br><span>And also is like more of the kind of place- I’m not saying Jesus Christ would endorse every single thing that happens in the world today. I’m just saying he endorses this timeline more than one in which he doesn’t exist and doesn’t preach at all.</span><br><em><strong>Ege Erdil</strong><span> 01:53:00</span></em><br><span>I don’t know, actually. I’m not sure if that’s true. It seems like a hard question.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:53:03</span></em><br><span>But I think like a sum from the Christian perspective, favorable cultural development to the West.</span><br><em><strong>Ege Erdil</strong><span> 01:53:07</span></em><br><span>I mean, you don’t know the counterfactual.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:53:09</span></em><br><span>I agree that is always true. I just think the world does have people who read the Bible and are like, “I’m inspired by these ideals to do certain things”. And it just seems like that’s more likely to lead to…</span><br><em><strong>Ege Erdil</strong><span> 01:53:20</span></em><br><span>So that is what I would call a ‘legacy effect’ or something. You can say the same thing about languages, some cultures might just become more prominent and their languages might be spoken more, or some symbols might become more prominent. But then there are things like how do cities look, and how do cars look, and what do people spend most of their time doing in their day, and what do they spend their money on? And those questions seem much more determined by how your values change as circumstances change.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:53:49</span></em><br><span>That might be true, but I’m in the position with regards to the future where I expect a lot of things to be different and I’m okay with them being different. I care much more about the equivalent of slavery, which in this case is literally slavery.</span><br><span>Just to put a final point on it, the thing I really care about is there’s going to be trillions of digital beings. I want it to be the case that they’re not tortured and put into conditions in which they don’t want to work and whatever. I don’t want galaxies worth of suffering. That seems closer to British abolitionists being like, “let’s put our empire’s might against fighting slavery”.</span><br><em><strong>Ege Erdil</strong><span> 01:54:25</span></em><br><span>I agree. But I would distinguish between the case of Christianity and the case of the end of slavery, because I think the end of slavery… I agree you can imagine a society, technologically it’s feasible to have slavery. But I think that’s not the relevant thing which brought it to an end.</span><br><span>The relevant thing is that the change in values associated with the Industrial Revolution made it so that slavery just became an inefficient thing to sustain in a bunch of ways. And a lot of countries at different times phased out different things you could call slavery. For example, Russia abolished serfdom in the 1860s. They were not under British pressure to do so. Britain couldn’t force Russia to do that, they just did that on their own. There were various ways in which people in Europe were tied to their land and they couldn’t move, they couldn’t go somewhere else. Those movement restrictions were lifted because they were inefficient.</span><br><span>There were ways in which the kind of labor that needed to be done in the colonies to grow sugar or to grow various crops, it was very hard labor. It was not the kind of thing that probably you could have paid people to do, because they just wouldn’t want to do it because the health hazards and so on were very great, which is why they needed people to force people to do them. And that kind of work over time became less prevalent in the economy.</span><br><span>So, again, that reduces the economic incentives to do it. I agree you could still do it.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:55:58</span></em><br><span>I would emphasize the way you’re painting the counterfactual is like, “oh, but then in that world, they would have just phased out the remnants of slavery”. But there’s a lot of historical examples where there’s not necessarily hard labor, only hard labor, like Roman slavery.</span><br><em><strong>Ege Erdil</strong><span> 01:56:14</span></em><br><span>Yes. It was different.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:56:16</span></em><br><span>And I interviewed a historian about it recently, the episode hasn’t come out, but he wrote a book about the scope. I think it was like 20 percent of people under Roman control were slaves.</span><br><span>And this was not just agricultural slavery. His point was that the maturity of the Roman economy is what led to this level of slavery, because the reason slavery collapsed in Europe after the fall of the Roman Empire was because the economy just lost a lot of complexity.</span><br><em><strong>Ege Erdil</strong><span> 01:56:50</span></em><br><span>Well, I’m not sure if I would say that slavery collapsed. I think this depends on what you mean by slavery. I mean in a lot of ways people in feudal Europe were…</span><br><strong>Dwarkesh Patel</strong><span> </span><em>01:56:58</em><br><span>But his point is that serfdom was not the descendant institution from Roman slavery.</span><br><strong>Ege Erdil</strong><span> </span><em>01:57:02</em><br><span>No, I agree. It was not descendant. But in fact, this point I’m trying to make is that, values that exist at a given time, like what the values we will have in 300 years, or from the perspective of someone a thousand years ago, what values people are going to have in a thousand years. Those questions are much more determined by the technological and economic and social environment that’s going to be there in a thousand years, which values are going to be functional, which sides, which values end up being more competitive and being more influential so that other people add up their values. And it depends much less on the individual actions taken by people a thousand years ago.</span><br><span>So I would say that the abolitionist thing, it’s not the cause of why slavery came to an end. Slavery comes to an end also because people just have natural preferences that I think are suppressed in various ways during the agricultural era where it’s more efficient to have settled societies in cities which are fairly authoritarian and don’t allow for that much freedom and that you’re in this Malthusian world where people have very low wages perhaps compared to what they enjoyed in the hunter-gatherer era. So it’s just a different economic period and I think people didn’t evolve to have the values that would be functional in that era.</span><br><span>So what happened is that there had to be a lot of cultural assimilation where people had to adopt different values and in the Industrial Revolution people become also very wealthy compared to what they used to be, and that I think leads to different aspects of people’s values being expressed. Like people just put a huge amount of value on equality. It’s always been the case. But I think when it is sufficiently functional for that to be suppressed they are capable of suppressing it.</span><br><em><strong>Dwarkesh Patel</strong><span> 01:59:01</span></em><br><span>I mean if that’s the story then this makes value alignment all the more important, because then you’re like “oh if the AI’s become wealthy enough they actually will make a concerted effort to make sure the future looks more like the utility function you put into them” which I think you have been under-emphasizing.</span><br><em><strong>Ege Erdil</strong><span> 01:59:18</span></em><br><span>No, I’m not under-emphasizing that. What I would say is there are certain things that are path-dependent in history, such that if someone had done something different, something had gone differently a thousand years ago, then today in some respects would look different. I think for example, which languages are spoken across which boundaries, or which religions people have, or fashion maybe to some extent, though not entirely.</span><br><span>Those things are more path-dependent, but then there are things that are not as path-dependent. So for example if some empire, like if the Mongols had been more successful and they somehow- I don’t know how realistic it is- but they became very authoritarian and had slavery everywhere, would that have actually led to slavery being a much more enduring institution a thousand years later? That seems not true to me.</span><br><span>The forces that led to the end of slavery seemed like they were not contingent forces, they seem like deeper forces than that and if you’re saying “well if we align the AI today to some bad set of values then that could affect the future in some ways which are more fragile” that seems plausible, but I’m not sure how much of the things you care about the future and how much the ways in which you expect the future to get worse you actually have a lot of leverage on at the present moment.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:00:40</span></em><br><span>I mean another example here might be factory farming where you could say “oh, it’s not like us having better values over time led to suffering going down, in fact your suffering might have gone up because the incentives that led to factory farming emerging are…”</span><br><em><strong>Ege Erdil</strong><span> 02:00:56</span></em><br><span>And probably when factory farming comes to an end it will be because the incentives start going away, right?</span><br><em><strong>Dwarkesh Patel</strong><span> 02:01:01</span></em><br><span>So suppose I care about making sure the digital equivalent of factory farming doesn’t happen. Maybe, all else being equal, it’s just more economically efficient to have suffering minds doing labor for you than non-suffering minds because of the intermediary benefits of suffering or something like that, right?</span><br><span>What would you say to somebody like me where I’m like “I really want that not to happen, I don’t want the lightcone filled with suffering workers” or whatever. Is it just like “we’ll give up because this is the way economic history is”?</span><br><em><strong>Ege Erdil</strong><span> 02:01:40</span></em><br><span>No, I don’t think you should give up. It’s hard to anticipate the consequences of your actions in the very distant future. So I would just recommend that you should just discount the future. Not for a moral reason, not because the future is worthless or something, but because it’s just very hard to anticipate the effects of your actions. In the near-term I think there are things you can do that seem like they would be beneficial. For example, you could try to align your present AI systems to value the things that you’re talking about, like they should value happiness and they should dislike suffering or something.</span><br><span>You might want to support political solutions that would… Basically you might want to build up the capacity so that in the future if you notice something like this happening then we might have some ability to intervene. Maybe you would think about the prospect of “well eventually we’re gonna maybe colonize other stars and civilization might become very large and communication delays might be very long between different places”. And in that case competitive pressures between different local cultures might become much stronger because it’s harder to centrally coordinate.</span><br><span>And so in that you might expect competition to take over in a stronger way and if you think the result of that is going to be a lot of suffering, maybe you would try to stop that. Again I think at this point it’s very far from obvious that trying to limit competition is actually a good idea, I would probably think it’s a bad idea, but maybe in the future we will receive some information and we’ll be like “oh, we were wrong actually actually we should stop this” and then maybe you want to have the capacity so that you can make that decision.</span><br><span>But that’s a nebulous thing. How do you build that up? Well I don’t know. That’s the kind of thing I would be trying to do.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:03:28</span></em><br><span>Yeah I think the overall takeaway I take from the way that I think about it, and I guess we think about it, as be more humble in what you think you can achieve, and just focus on the nearer term, not because it’s more morally important than the longer term, but just because it’s much easier to have a predictably positive impact on that.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:03:49</span></em><br><span>One thing I’ve noticed over the last few weeks of thinking about these bigger future topics and interviewing Daniel and Scott and then you two, is how often I’ve changed my mind about everything from the smallest questions about when AI will arrive- it’s funny that that’s the small question in the grand scheme of things- to whether there will be an intelligence explosion, or whether it’ll be an R&amp;D explosion, to whether there’ll be explosive growth, or how to think about that.</span><br><span>And if you’re in a position where you are incredibly epistemically uncertain about what’s going to happen, I think it’s important to, instead of becoming super certain about your next conclusion, just being like “well let me just take a step back, I’m not sure what’s going on here”. And I think a lot more people should be from that perspective unless you’ve had the same opinion about AI for many years, in which case I have other questions for you about why that’s the case. And I mean generally, how we as a society deal with topics on which we are this uncertain is just to have freedom, decentralization, both decentralized knowledge and decentralized decision making take the reins and not to do super high volatility centralized moves like “hey let’s nationalize so we can make sure that the software-only singularity is aligned” or not to make moves that are just incredibly contingent on one world view that are brittle under other considerations.</span><br><span>And that’s become a much more salient part of my world view. I think just classical liberalism is the way we deal with being this epistemically uncertain and I think we should be more uncertain than we’ve ever been in history, as opposed to many other people who seem to be more certain than they are about other sort of more mundane topics.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:05:44</span></em><br><span>Yeah I think it’s very hard to predict what happens because this acceleration basically means that you find it much harder to predict what the world might be in 10 years time. I think these questions are also just very difficult and we don’t have very strong empirical evidence and then there’s like a lot of this kind of disagreement that exists.</span><br><em><strong>Ege Erdil</strong><span> 02:06:10</span></em><br><span>I would say that it’s much more important in a lot of cases and a lot of situations to maintain flexibility and ability to adapt to new circumstances, new information, than it is to get a specific plan that’s going to be correct and that’s very detailed and has a lot of specific policy recommendations and things that you should do.</span><br><span>That’s actually also the thing that I would recommend if I want to make the transition to AI in this period of explosive growth go better. I would just prefer it if we in general had higher quality institutions, but I am much less bullish on someone sitting down today and working out “okay what will this intelligence explosion or explosive growth be like? What should we do?”</span><br><span>I think plans that you work out today are not going to be that useful when the events are actually occurring, because you’re going to learn so much stuff that you’re going to update on so many questions that these plans are just going to become obsolete.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:07:12</span></em><br><span>One thing you could do is you could look at say, the history of war planning and how successful war planning has been for like actually anticipating what actually happens when the war actually happens.</span><br><strong>Ege Erdil</strong><span> </span><em>02:07:22</em><br><span>So for one example- I think I might have mentioned this off the record at some point- but before the Second World War happened, obviously people saw that there were all these new technologies like tanks and airplanes and so on, which existed in World War I. but in a much more primitive setting. So they were wondering, what is going to be the impact of these technologies now that we have in them in much greater scale? And the British government had estimates of how many casualties there would be from aerial bombardment in the first few weeks of the Second World War. And they expected hundreds of thousands of casualties in two weeks, three weeks, after the war begins.</span><br><span>So the idea was that air bombing is basically this unstoppable force, all the major urban centers are going to get bombed, tons of people will die, so basically we can’t have a war because if there’s a war then it will be a disaster because we will have this aerial bombardment. But later it turned out that that was totally wrong. In fact, in all of Britain there were fewer casualties from air bombing in the entire six years of the Second World War than the British government expected in the first few weeks of the war. They had less casualties in six years than they expected in three weeks.</span><br><span>So why did they get it wrong? Well there are lots of boring practical reasons, like for example it turned out to be really infeasible, especially early on, to bomb cities in daytime because your aircraft would just get shot down, but then if you try to bomb at night time then your bombing was really imprecise and only a very small fraction of it actually hit. And then people also underestimated the extent to which people on the ground like firefighters and so on could just go around the city and that put out fires from bombs that were falling on structures. They overestimated the amount of economic damage that it would do. They underestimated how economically costly it would be; basically you’re sending these aircraft and then they’re getting shot down, while an aircraft is very expensive.</span><br><span>So in the end how it turned out is, when the allies started bombing Germany, for each dollar of capital they were destroying in Germany they were spending like four to five dollars on the aircraft and fuel and training of the pilots and so on that they were sending in missions and the casualty rate was very high, which later got covered up by the government because they didn’t want people to worry about, you know…</span><br><span>So that is a kind of situation where all the planning that you would have done in advance predicated on this assumption of air bombing going to be this “nuclear weapons-lite”, basically it’s extremely destructive there’s going to be some aspect to which…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:09:57</span></em><br><span>I mean it was though, right? 84,000 people died in one night of firebombing in Tokyo, Germany, large fractions of their…</span><br><em><strong>Ege Erdil</strong><span> 02:10:07</span></em><br><span>But that was over the period of six years of war.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:10:11</span></em><br><span>Right, but there were single firebombing attacks. I mean it was a case that during the end of World War II when they were looking for the place to launch the atomic bombs, they just had to go through like a dozen cities because it just wouldn’t be worth nuking them because they’re already destroyed by the firebombing.</span><br><em><strong>Ege Erdil</strong><span> 02:10:28</span></em><br><span>That’s right, but if you look at the level of destruction that was expected within the space of a few weeks, and then this level of destruction took many years, so there was like a two order of magnitude mismatch or something like that, which is pretty huge. So that affected the way people think about it.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:10:45</span></em><br><span>An important underlying theme of much of what we have discussed is how powerful just reasoning about things is to making progress about what specific plans you want to make to prepare and make this transition to advanced AI go well.</span><br><span>And our view is, well it’s actually quite hard and you need to make contact with the actual world in order to inform most of your beliefs about what actually happens and so it’s somewhat futile to do a lot of wargaming and figure out how AI might go, and what we can do today to make that go a lot better, because a lot of the policies you might come up with might just look fairly silly.</span><br><span>And in thinking about how AI actually has this impact, again people think “oh you know, AI reasoning about doing science and doing R&amp;D just has this drastic impact on the overall economy or technology, and our view as well actually again making contact with the real world and getting a lot of data from experiments and from deployment and so on is just very important”.</span><br><span>So I think there is this underlying kind of latent variable which explains some of this disagreement, both on the policy prescriptions and about the extent to which we should be humble versus ambitious about what we ought to do today, as well as for thinking about the mechanism through which AI has this impact. And this underlying latent thing is, what is the power of reason? How much can we reason about what might happen? How much can reasoning in general figure things out about the world and about technology? And so that is a core underlying disagreement here.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:12:27</span></em><br><span>I do want to ask: You say in your announcement, we want to accelerate this broad automation of labor as fast as possible. As you know, many people think it’s a bad idea to accelerate this broad automation of labor and AGI and everything that’s involved there. Why do you think this is good?</span><br><em><strong>Ege Erdil</strong><span> 02:12:49</span></em><br><span>So the argument for why it’s good is that we’re going to have this enormous increase in economic growth, which is going to mean enormous amounts of wealth, and incredible new products that you can’t even imagine, in health care or whatever. And like the quality of life of the typical person is probably going to go up a lot.</span><br><span>Early on, probably also their wages are going to go up, because the AI systems are going to be automating things that are complementary to their work. Or it’s going to be automating part of their work, and then you’ll be doing the rest and then you’ll be getting paid much more on that. And in the long term, eventually we do expect wages to fall just because of arbitrage with the AIs. But by that point, we think humans will own enormous amounts of capital and there will also be ways in which even the people who don’t own capital, we think are just going to be much better off than they are today.</span><br><span>I think it’s just hard to express in words the amount of wealth and increased variety of products that we would get in this world. It will probably be more than the difference between 1800 and today. So if you imagine that difference, it’s such a huge difference. And then we imagine two times, three times, whatever.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:13:58</span></em><br><span>The standard argument against this is why does the speed to get there matter so much? Especially if the trade-off against the speed is the probability that this transition is achieved successfully in a way that benefits humans?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:14:12</span></em><br><span>I mean, it’s unclear that this trades off against the probability of it being achieved successfully or something.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:14:17</span></em><br><span>There might be an alignment tax.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:14:20</span></em><br><span>I mean, maybe. You can also just do the calculation of how much a year’s worth of delay costs for current people. This is this enormous amount of utility that people are able to enjoy, and that gets brought forward by year or pushed back by year if you delay things by year. And how much is this worth? Well, you can look at simple models of how concave people’s utility functions are and do some calculations and maybe that’s worth on the order of tens of trillions of dollars per year in consumption.</span><br><span>That is roughly the amount consumers might be willing to defer in order to bring forward the date of automation one year.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:15:03</span></em><br><span>In absolute terms, it’s high. In relative terms, relative to if you did think it was going to nudge the probability one way or another of building systems that are aligned and so forth that it’s so small compared to all of the future.</span><br><em><strong>Ege Erdil</strong><span> 02:15:18</span></em><br><span>I agree. So there are a couple of things here.</span><br><span>First of all, I think the way you think about this matters. So first of all, we don’t actually think that it’s clear whether speeding things up or slowing things down actually makes a doomy outcome more or less likely. I think that’s a question that doesn’t seem obvious to us. Partly because of our views on the software R&amp;D side. We don’t really believe that if you just pause and then you do research for 20 years at a fixed level of compute scale, that you’re actually going to make that much progress on relevant questions on alignment or something.</span><br><span>Imagine you were trying to make progress on alignment in 2016 with the compute budgets of 2016. Well, you would have gotten nowhere, basically. You would have discovered none of the things that people have discovered today and that turned out to be useful. And I think if you pause today, then we will be in a very similar position in 10 years, right? We would have not made a bunch of discoveries. So the scaling is just really important to make progress in alignment, in our view. And then there’s a separate question of how longtermist should you be in various different senses?</span><br><span>So there’s a moral sense, of how much you should actually care about people who are alive today as opposed to people who are not yet born as just a moral question. And there was also a practical question of, as we discussed, how certain can you be about the impact your present actions are actually going to have in the future?</span><br><em><strong>Dwarkesh Patel</strong><span> 02:16:43</span></em><br><span>OK, maybe you think it really doesn’t matter whether you slow things down right now or you speed things up right now. But is there some story about why speeding them up from the alignment perspective actually helped, it’s good to have that extra progress right now rather than later on?</span><br><span>Or is it just that, well, if it doesn’t make a difference either way, then it’s better to just get that extra year of people not dying and having cancer cures and so forth?</span><br><em><strong>Ege Erdil</strong><span> 02:17:06</span></em><br><span>I think I would say the second. But it’s just important to understand the value of that. Even in purely economic terms, imagine that each year of delay might cause maybe 100 million people- maybe more, maybe 150, 200 million people- who are alive today to end up dying. So even in purely economic terms, the value of a statistical life is pretty enormous, especially in Western countries. Sometimes people use numbers as high as $10 million for a single life. So imagine you do $10 million times 100 million people. That’s a huge number, right?</span><br><span>That is so enormous that I think for you to think that speeding things up is a bad idea, you have to first have this long-termist view where you look at the long run future. You think your actions today have high enough leverage that you can predictably affect the direction of the long run future.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:18:10</span></em><br><span>Well, in this case, it’s kind of different because you’re not saying “I’m going to affect what some emperor a thousand years from now does” like somebody in the year zero would have to do to be a long-termist. In this case, you just think there’s this incredibly important inflection point that’s coming up and you just need to have influence over that crucial period of explosive growth of intelligence explosion or something. So I think it is a much more practicable prospect than…</span><br><em><strong>Ege Erdil</strong><span> 02:18:36</span></em><br><span>So I agree in relative terms. In relative terms, I agree the present moment is a moment of higher leverage and you can expect to have more influence. I just think in absolute terms, the amount of influence you can have is still quite low. So it might be orders of magnitude greater than it would have been 2000 years ago and still be quite low.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:18:54</span></em><br><span>And again, I think there’s this difference in opinion about how broad and diffuse this transformation ends up being, versus how concentrated within specific labs where the very idiosyncratic decisions made by that lab will end up having a very large impact.</span><br><span>If you think those developments will be very concentrated, then you think the leverage is especially great. And so then you might be especially excited about having the ability to influence how that transition goes, but our view is very much that this transition happens very diffusely by way of many, many organizations and companies doing things. And for those actions to be determined a bunch by economic forces rather than idiosyncratic preferences on the part of labs or these decisions that have these founder effects that last for very long.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:19:48</span></em><br><span>Okay let’s go through some of the objections to explosive growth, which is that most people are actually more conservative not more aggressive about the forecasts you have. So obviously one of the people who has articulated their disagreements with your view is </span><a href="https://en.wikipedia.org/wiki/Tyler_Cowen" rel="">Tyler Cowen</a><span>. He made an interesting point when we did the podcast together and he said “most of Sub-Saharan Africa still does not have reliable clean water. The intelligence required for that is not scarce. We cannot so readily do it. We are more in that position that we might like to think along other variables.”</span><br><em><strong>Tamay Besiroglu</strong><span> 02:20:22</span></em><br><span>I mean we agree with this. I think intelligence isn’t the bottleneck that’s holding back technological progress or economic growth. It’s like many other things. And so this is very much consistent with our view that scaling up your overall economy, accumulating capital, accumulating human capital, having all these factors scale…</span><br><em><strong>Ege Erdil</strong><span> 02:20:45</span></em><br><span>In fact this is even consistent with what I was saying earlier that I was pointing out this “oh, good management and good policies and those just contribute to TFP and they can be bottlenecks”.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:20:55</span></em><br><span>Like right now we could just plug-and-play our better management into Sub-Saharan Africa.</span><br><em><strong>Ege Erdil</strong><span> 02:21:02</span></em><br><span>No we can’t.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:21:03</span></em><br><span>It’s hard. I don’t think we can.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:21:05</span></em><br><span>Okay so maybe I should have said, one could </span><em>theoretically</em><span> imagine plugging and playing…</span><br><em><strong>Ege Erdil</strong><span> 02:21:10</span></em><br><span>I agree.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:21:12</span></em><br><span>I can imagine many things.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:21:14</span></em><br><span>But we cannot so readily do it because of… it’s hard to articulate why and it wouldn’t be so easy to do in just capital or labor. Why not think that the rest of the world will be in this position with regards to the advances that AI will make possible?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:21:32</span></em><br><span>I mean if the AI advances are like the kind of geniuses in a data center, then I agree that that might be bottlenecked by the rest of the economy not scaling up and being able to accumulate the relevant capital to make those changes feasible. So I kind of agree with this picture and I think this is an objection to the “geniuses in a data center” type view, and I buy basically this.</span><br><em><strong>Ege Erdil</strong><span> 02:21:57</span></em><br><span>And also the fact that it’s also plausible you’re going to have the technology, but then some people are not going to want to deploy it, or some people are going to have norms and laws and cultural things that are going to make it so that AI is not able to be widely deployed in their economy- or not as widely deployed as they otherwise might be. And that is going to make those countries or societies just slower. That’s like some countries will be growing faster just like Britain and the Netherlands were sort of the leaders in the Industrial Revolution, they were the first countries to start experiencing rapid growth. And then other countries, even in Europe, had to come from behind.</span><br><span>Well again I just think we expect the same thing to be true for AI. And the reason that happened was exactly because of these kinds of reasons, where those countries that had a culture or governance systems or whatever which were just worse than bottlenecked the deployments and scaling of the new technologies and ideas. It seems very plausible.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:22:53</span></em><br><span>But you’re saying as long as there’s one jurisdiction?</span><br><em><strong>Ege Erdil</strong><span> 02:22:55</span></em><br><span>Yeah.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:22:56</span></em><br><span>But then again you also previously emphasized the need to integrate with the rest of the global economy and the human economy. So doesn’t that contradict…?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:23:05</span></em><br><span>That doesn’t often require cultural homogeneity. We trade with countries, like the US trades with China, quite a lot actually. And there’s a bunch of disagreement…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:23:15</span></em><br><span>But what if the US is like “I don’t like that the UAE is doing explosive growth with AI, we’re just going to embargo them”.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:23:22</span></em><br><span>That seems plausible.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:23:24</span></em><br><span>And then would that not prevent explosive growth?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:23:26</span></em><br><span>I think that would be plausible at the point at which it’s revealing a lot about the capabilities and the power of AI. Yeah. And you should also think that that creates both an incentive to embargo, but also an incentive to adopt the very similar styles of governing that enable AI to be able to produce a lot of value.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:23:48</span></em><br><span>What do you make of this: I think people interpret explosive growth from an arms race perspective. And that’s often why I think in terms of public-private partnerships for the labs themselves. But this idea that you have the geniuses in the data center, you can have them come up with the mosquito drone swarms. And then those drone swarms will, like if China gets to the swarms earlier… Even within your perspective, is this a result of your whole economy being advanced enough that you can produce mosquito drone swarms?</span><br><span>You being six months ahead means that you could decisively win… does it? I don’t know. Maybe you being like a year ahead and explosive growth means you could decisively win a war against China or China could win a war against you. So would that lead to an arms race-like dynamic?</span><br><em><strong>Ege Erdil</strong><span> 02:24:33</span></em><br><span>I mean I think it would to some extent, but I’m not sure if I would expect a year of lead to be enough to take a risk, because if you go to war with China… For example if you replace China today with China from 1990. Or if you replace Russia today with Russia from like 1970 or 1980. It’s possible that their ICBM and whatever technology is already enough to make a very strong deterrence.</span><br><span>So maybe even that technological lead is not sufficient so that you would feel comfortable going to war. So that seems possible.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:25:13</span></em><br><span>Yeah. And actually this relates to a point that </span><a href="https://www.dwarkesh.com/p/gwern-branwen" rel="">Gwern</a><span> was making which is that this is going to be a much more unstable period than the Industrial Revolution, even though the Industrial Revolution saw many countries gain rapid increases in their capabilities, because within this span, if you’ve got a century’s worth of progress compressed within a decade, one country gets to ballistic missiles first, then the other country gets to railroads first, and so forth.</span><br><span>But if you have this more integrated perspective about what it takes to get to ballistic missiles and to railroads, then you might think “no, basically this isn’t some orthogonal vector. You’re just churning on the tech tree further and further”.</span><br><em><strong>Ege Erdil</strong><span> 02:26:01</span></em><br><span>I mean for what it’s worth I do think it’s possible if you have it just happen in a few countries which are relatively large and have enough land or something, those countries would be starting from a lower base compared to the rest of the world, so you would need to catch up to some extent. If they are just going to sort of grow internally and they’re not going to depend on the external supply chains. But that doesn’t seem like something that’s impossible to me. Some countries could do it, it would just be more difficult.</span><br><span>But in this setting if some countries have a significant policy advantage over the rest of the world and they start growing first and then they won’t necessarily have a way to get other countries to adopt their norms and culture. So in that case it might be more efficient for them to do the growth locally. So that’s why I was saying the growth differentials will probably be determined by regulatory jurisdiction boundaries more than anything else. I’m not saying- say the U.S. by itself if it had AI but it couldn’t get the rest of the world to adopt AI, I think that would still be sufficient for explosive growth.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:27:03</span></em><br><span>How worried should we be about the fact that China today, because it industrialized relatively recently, has more industrial capacity and know-how and all the other things of learning by doing and so forth? If we buy your model of how technology progresses, with or without AI, how are we just underestimating China because we have this perspective that what fraction of your GDP you’re spending on research is what matters, when in fact it’s the kind of thing where I’ve got all the factories in my backyard and I know how they work and I can go buy a component whenever I want?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:27:41</span></em><br><span>I don’t think people are necessarily underestimating China, it depends on who you’re looking at, but it seems like the discussion of China is just this very big discussion in these AI circles, right?</span><br><span>And so people are very much appreciating the power and the potential threat that China poses. But I think the key thing is not just the scale in terms of pure number of people or like number of firms or something, but the scale of the overall economy, which is just measured in how much is being produced in terms of dollars. There, the U.S. is ahead.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:28:14</span></em><br><span>But we’re not expecting all this explosive growth to come from financial services. We’re expecting it to start from a base of industrial technology and industrial capacity.</span><br><em><strong>Ege Erdil</strong><span> 02:28:25</span></em><br><span>No, financial services can be important if you want to scale very big projects.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:28:29</span></em><br><span>Financial services are very important for raising funding and getting investments in data centers.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:28:35</span></em><br><span>If I understood you correctly it just seems like, man, you know how to build the robot factories and so forth. That know-how which, in your view, is so crucial to technology growth and general economic growth, is lacking. And you might have more advanced financial services but it seems like the more you take your view seriously, the more it seems like that having the Shenzhen locally matters a lot.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:29:00</span></em><br><span>I mean relative to what starting point? I think people already appreciate that China is very important. And then I agree that there are some domains where China is leading, but then there are very many domains in which the U.S. is leading, or the U.S. and its allies, where countries that are producing relevant inputs for AI that the U.S. has access to, but China doesn’t.</span><br><span>So I think the U.S. is just ahead on many dimensions and there’s some that China is ahead or at least very close. So I don’t think this should cause you to update very strongly in favor of China being a much bigger deal, at least depending on where you start.</span><br><em><strong>Ege Erdil</strong><span> 02:29:40</span></em><br><span>I think people already think China is a big deal like this is the big underlying thing here. Like if we were just very dismissive of China, then maybe this would be a reason to update.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:29:48</span></em><br><span>I get your argument that thinking about the economy-wide acceleration is more important than focusing on the IQ of the smartest AI. But at the same time, do you believe in the idea of superhuman intelligence? Is that a coherent concept in the way that you don’t necessarily stop at human level Go play and you just go way beyond it in ELO score?</span><br><span>Will we get to systems that are like that with respect to the broader range of human abilities? And maybe that doesn’t mean they become God, because there’s other ASIs in the world. But you know what I mean, will there be systems with such superhuman capabilities?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:30:27</span></em><br><span>Yeah I mean I do expect that. I think there’s a question of how useful is this concept for thinking about this transition to a world with much more advanced AI. And I don’t find this a particularly meaningful or helpful concept.</span><br><span>I think people introduce some of these notions that on the surface seem useful, but then actually when you delve into them it’s very vague and kind of unclear what you’re supposed to make of this. And you have this notion of AGI which is distinguished from narrow AI in the sense that it’s much more general and maybe can do everything that a human can do on average. AI systems have these very jagged profiles of capability. So you have to somehow take some notion of average capabilities and what exactly does that mean, it just feels really unclear.</span><br><span>And then you have this notion of ASI, which is AGI in the sense that it’s very general but then it’s also better than humans on every task. And is this a meaningful concept? I guess it’s coherent. I think this is not a super useful concept, because I prefer just thinking about what actually happens in the world. And you could have a drastic acceleration without having an AI system that can do everything better than humans can do. I guess you could have no acceleration when you have an ASI that is better than humans at everything, but it’s just very expensive or very slow or something. So I don’t find that particularly meaningful or useful. I just prefer thinking about the overall effects on the world and what AI systems are capable of producing those types of effects.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:32:06</span></em><br><span>Yeah I mean one intuition pump here is: compare John von Neumann versus a human plucked from the standard distribution. If you added a million John von Neumanns to the world what would the impact on growth be as compared to just adding a million people from normal distribution?</span><br><em><strong>Ege Erdil</strong><span> 02:32:25</span></em><br><span>Well I agree it would be much greater.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:32:27</span></em><br><span>Right. But then because of Moravec paradox-type arguments that you made earlier that evolution has not necessarily optimized us for that long along the kind of spectrum on which John von Neumann is distinguished from the average human. And given the fact that already within this deviation you have this much greater economic impact. Why not focus on optimizing on this thing that evolution has not optimized that hard on, further?</span><br><em><strong>Ege Erdil</strong><span> 02:32:51</span></em><br><span>I don’t think we shouldn’t focus on that. But what I would say is, for example if you’re thinking about the capabilities of Go-playing AIs, then the concept of a superhuman Go AI, yeah, you can say that is a meaningful concept. But if you’re developing the AI, it’s not a very useful concept. If you just look at the scaling curve, it just goes up and there is some human level somewhere. But the human level is not privileged in any sense.</span><br><span>So the question is, is it a useful thing to be thinking about? And the answer is probably not. Depends on what you care about. So I’m not saying we shouldn’t focus on trying to make the system smarter than humans are, I think that’s a good thing to focus on.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:33:31</span></em><br><span>Yeah I guess I try to understand whether we will stand in relation to the AIs of 2100 that humans stand in relation to other primates. Is that the right mental model we should have, or is it going to be a much greater familiarity with their cognitive horizons?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:33:49</span></em><br><span>I think AI systems will be very diverse, and so it’s not super meaningful to ask something about this very diverse range of systems and where we stand in relation to them.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:33:59</span></em><br><span>I mean, will we be able to cognitively access the kinds of considerations they can take on board? Humans are diverse, but no chimp is going to be able to understand this argument in the way that another human might be able to, right? So if I’m trying to think about my place, or a human’s place, in the world of the future, is a relevant concept of; is it just that the economy has grown a lot and there’s much more labor, or are there beings who are in this crucial way super intelligent?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:34:28</span></em><br><span>I mean there will be many things that we just will fail to understand, and to some extent there are many things today that people don’t understand about how the world works and how certain things are made. And then how important is it for us to have access or in principle be able to access those considerations?</span><br><span>And I think it’s not clear to me that that’s particularly important that any individual human should be able to access all the relevant considerations that produce some outcome. That just seems like overkill. Why do you need that to happen? I think it would be nice in some sense. But I think if you want to have a very sophisticated world where you have very advanced technology, those things will just not be accessible to you.</span><br><span>So you have this trade-off between accessibility and maybe how advanced the world is. And from my point of view I’d much rather live in a world which has very advanced technology, has a lot of products that I’m able to enjoy, and a lot of inventions that I can improve my life with, if that means that I just don’t understand them. I think this is a very simple trade that I’m very willing to make.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:35:45</span></em><br><span>Okay so let’s get back to objections to explosive growth. We discussed a couple already. Here’s another which is more a question than an objection: Where is all this extra output going? Who is consuming it? If the economy is 100X bigger in a matter of a decade or something, to what end?</span><br><em><strong>Ege Erdil</strong><span> 02:36:05</span></em><br><span>So first of all I think even if you view that along what you might call the </span><a href="https://www.thoughtco.com/what-is-an-intensive-margin-4082788" rel="">intensive margin</a><span> in the sense that you just have more of the products you have today, I think there will be a lot of appetite for that. Maybe not quite 100X, that might start hitting some diminishing returns.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:36:23</span></em><br><span>Current GDP per capita on average in the world is 10K a year or something, right? And there are people who enjoy millions of dollars. And so there’s a gap between what people enjoy, and don’t seem to be super diminished in terms of marginal utility, and so there’s a lot of room on just purely the intensive margin of just consuming the things we consume today but more. And then there is this maybe much more important dimension along which we will expand which is…</span><br><em><strong>Ege Erdil</strong><span> 02:36:52</span></em><br><span>Product variety.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:36:53</span></em><br><span>Yeah, extensive margin of what is the scope of things that you’re consuming. And if you look at something like the Industrial Revolution, that seemed to have been the main dimension along which we expanded to consume more. In any kind of sector that you care about, transportation, medicine, entertainment, and food, there’s just this massive expansion in terms of variety of things that we’re able to consume that is enabled by new technology or new trade routes or new methods of producing things. So that I think is really the key thing that we will see come along with this kind of expansion in consumption.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:37:35</span></em><br><span>Another point that Tyler makes is that there will be some mixture of </span><a href="https://en.wikipedia.org/wiki/Baumol_effect" rel="">Baumol cost disease</a><span>, where you’re bottlenecked by the slowest growing thing. The fastest productivity things basically diminish their own…</span><br><em><strong>Ege Erdil</strong><span> 02:37:56</span></em><br><span>Share in output.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:37:57</span></em><br><span>That’s right, yeah.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:37:59</span></em><br><span>I mean we totally agree with that. I would say that that’s just a kind of qualitative consideration. It isn’t itself sufficient to make a prediction about what growth rates are permitted given these effects versus not, it’s just a qualitative consideration and then you might need to make additional assumptions to be able to make a quantitative prediction. So I think it’s a little bit…</span><br><em><strong>Ege Erdil</strong><span> 02:38:24</span></em><br><span>So the convincing version of this argument would be if you did the same thing that we were doing earlier with the software-only singularity argument, where we were pointing to essentially the same rejection where there are multiple things that can bottleneck progress. So I would be much more convinced if someone pointed to an explicit thing, like here, health care is this very important thing. And why should we expect AI to make that better? That doesn’t seem like that would get better because of AI. So maybe health care just becomes a big part of the economy and then that bottleneck. So if there was some specific sector…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:38:58</span></em><br><span>Maybe the argument is that if there is even one…</span><br><em><strong>Ege Erdil</strong><span> 02:39:00</span></em><br><span>No, if there’s one though, if that’s a small part of the economy then you could just still get a lot of growth. You just automate everything else and that is going to produce a lot of growth.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:39:09</span></em><br><span>So it has to quantitatively work out. And so you actually have to be quantitatively specific about what this objection is supposed to be.</span><br><em><strong>Ege Erdil</strong><span> 02:39:15</span></em><br><span>Right. So first of all you have to be specific about what these tasks are. What is the current share in economic output?</span><br><span>The second thing is you have to be specific about how bad do you think the complementarities are? So in numerical terms economists use the concept of </span><a href="https://en.wikipedia.org/wiki/Elasticity_of_substitution" rel="">elasticity of substitution</a><span> to quantify this. So that gives you a numerical estimate of, if you just have much more output on some dimensions but not that much on other dimensions, how much does that increase economic output overall?</span><br><span>And then there’s a third question. You can also imagine you automate a bunch of the economy. Well, a lot of humans were working on those jobs. So now, well they don’t need to do that anymore because those got automated. So they could work on the jobs that haven’t yet been automated. So as I gave the example earlier, you might imagine a world in which remote work tasks get automated first, and then sensory-motor skills lag behind. So you might have a world in which software engineers become physical workers instead.</span><br><span>Of course, in that world the wages of physical workers will be much higher than their wages are today. So that reallocation also produces a lot of extra growth, even if bottlenecks are maximally powerful, even if you just look at all the tasks in the economy and literally take the worst one for productivity growth, you would still get a lot of increase in output because of this reallocation.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:40:35</span></em><br><span>So I think one point that I think is useful to make; our experience talking to economists about this is that they will bring up these more qualitative considerations, whereas the arguments that we make, make specific quantitative predictions about growth rates. So for example you might ask “how fast will the economy double?” And then we can think about, an H100 does about… there are some estimates of how much computation the human brain does per second and it’s about one E15 flop or so, it’s a bit unclear, but then it turns out that an H100 roughly does on that order of computation. And so you can ask the question of “how long does it take for an H100 to pay itself back?”</span><br><em><strong>Ege Erdil</strong><span> 02:41:21</span></em><br><span>If you run the software of the human brain.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:41:22</span></em><br><span>If you run the software of the human brain you can then deploy that in the economy and earn say human wages on the order of 50 to 100 K a year or whatever in the US. And so then it pays itself back because it costs on the order of 30 K per H100. And so you get a doubling time of maybe on the order of a year.</span><br><span>And so this is like a very quantitatively specific prediction about… And then there’s the response, “well you have Baumol effects” well, what does this mean? Does it double? Does this predict it doubles every two years or every five years? You need just more assumptions in order to make this a coherent objection.</span><br><span>And so I think a thing that’s a little bit confusing is just that there are these qualitative objections that I agree with, like bottlenecks are indeed important, which is part of the reason I’m more skeptical of this ‘software singularity’ story. But I think this is not sufficient for blocking explosive growth.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:42:23</span></em><br><span>The other objection that I’ve heard often- and it might have a similar response from you- is this idea that a lot of the economy is comprised of O-ring-type activities. And this refers to, I think, the Challenger space shuttle explosion. There is just one component- I forgot what the exact problem with the O-ring was- but because of that being faulty the whole thing collapsed.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:42:48</span></em><br><span>I mean I think it’s quite funny actually because the O-ring model is taking the product of many, many inputs, and then the overall output is the product of very many things. But actually this is pretty optimistic from the point of view of having fewer bottlenecks.</span><br><em><strong>Ege Erdil</strong><span> 02:43:08</span></em><br><span>I think we pointed this out before, which again, talking about software only singularity, I said if it’s the product of computer experiments with research…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:43:14</span></em><br><span>But if one of those products …</span><br><em><strong>Ege Erdil</strong><span> 02:43:15</span></em><br><span>Is zero.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:43:16</span></em><br><span>Because of human…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:43:17</span></em><br><span>But you have constant marginal product there, right?</span><br><em><strong>Ege Erdil</strong><span> 02:43:19</span></em><br><span>Yeah, but if one of those products doesn’t scale that doesn’t limit- like yeah, it means you’re less efficient at scaling than you otherwise would be, but you can still get a lot of…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:43:30</span></em><br><span>You can just have unbounded scaling in the O-ring world. So actually I disagree with Tyler, that he’s not conservative enough, that he should take his bottlenecks view more seriously than he actually is. And yet I disagree with him about the conclusion. And I think that we’re going to get explosive growth once we have AI that can flexibly substitute.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:43:50</span></em><br><span>I’m not sure I understand, like, there will be entirely new organizations that AIs come up with. We’ve written a blog post about one such with the AI firms. And you might be a productive worker or a productive contributor in this existing organization as it exists today. In the AI world many humans might just be zero or even minus…</span><br><em><strong>Ege Erdil</strong><span> 02:44:11</span></em><br><span>I agree.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:44:13</span></em><br><span>Why won’t that… put that in the multiplication.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:44:18</span></em><br><span>But why would humans be in the loop there?</span><br><em><strong>Ege Erdil</strong><span> 02:44:21</span></em><br><span>You’re both saying that humans would be negatively contributing to output. But then you’re also saying that we should put them into the…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:44:31</span></em><br><span>Okay, fair fair fair. The main objection often is regulation. And I think we’ve addressed it implicitly in different points, but might as well just explicitly address why won’t regulation stop this?</span><br><em><strong>Ege Erdil</strong><span> 02:44:43</span></em><br><span>Yeah. So for what it’s worth, we do have </span><a href="https://epoch.ai/blog/explosive-growth-from-ai-a-review-of-the-arguments" rel="">a paper</a><span> where we go over all the arguments for and against explosive growth. And regulation, I think, is the one that seems strongest as ‘against’.</span><br><span>The reason it seems strong is because even though we have made arguments before about international competition and variation of policies among jurisdictions and these strong incentives to adopt this technology both for economic and national security reasons.</span><br><span>So I think those are pretty compelling when taken together but even still, the world does have a surprising ability to coordinate on just not pursuing certain technologies.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:45:18</span></em><br><span>Right. Human cloning…</span><br><em><strong>Ege Erdil</strong><span> 02:45:20</span></em><br><span>That’s right. So I think it’s hard to be extremely confident that this is not going to happen. I think it’s less likely that we’re going to do this for AI than it is for human cloning, because I think human cloning touches on some other taboos and so on.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:45:38</span></em><br><span>And also is less valuable.</span><br><em><strong>Ege Erdil</strong><span> 02:45:39</span></em><br><span>Also less valuable. And probably less important also for national security in an immediate sense. But at the same time, as I said, it’s just hard to rule this out.</span><br><span>So if someone said “well I think there’s a 10 percent or 15 percent, whatever, 20 percent chance that there will be some kind of global coordination of regulation and that’s going to just be very effective. Maybe it will be enforced through sanctions on countries that defect or you know.</span><br><span>And then maybe it doesn’t prevent AI from being deployed, but maybe just slows things down enough that you never quite get explosive growth”. I don’t think that’s an unreasonable view. It’s like 10 percent chance it could be.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:46:17</span></em><br><span>I don’t know if there’s any… I don’t know. Do you encounter any other…</span><br><em><strong>Ege Erdil</strong><span> 02:46:24</span></em><br><span>Any other objections?</span><br><em><strong>Dwarkesh Patel</strong><span> 02:46:25</span></em><br><span>What should I be hassling you about?</span><br><em><strong>Ege Erdil</strong><span> 02:46:27</span></em><br><span>I mean some things that we’ve heard from economists… People sometimes respond to our argument about explosive growth, which is an argument about growth levels. So we’re saying “we’re going to see 30 percent growth per year, instead of 3 percent”. They respond to that with an objection about </span><em>levels</em><span>. So they say “well how much more efficient, how much more valuable can you make hairdressing, or taking flights, or whatever, or going to a restaurant?”. And that is just fundamentally the wrong kind of objection.</span><br><span>We’re talking about the rate of change, and you’re objecting to it by making an argument about the absolute level of productivity. And as I said before, it is not an argument that economists themselves would endorse if it was made about a slower rate of growth continuing for a longer time. So it seems more like special pleading…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:47:20</span></em><br><span>I mean why not just the deployment thing, where the same argument you made about AI, where you do learn a lot just by deploying to the world and seeing what people find useful, ChatGPT was an example of this. Why won’t a similar thing happen with AI products and services where if one of the components is you put it out to the marketplace and people play with it and you find out what they need, and it clings to the existing supply chain and so forth. Doesn’t that take time?</span><br><em><strong>Tamay Besiroglu</strong><span> 02:47:49</span></em><br><span>I mean it takes time but it is often quite fast. In fact, ChatGPT grew extremely fast.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:47:55</span></em><br><span>Right, but that was just purely digital service.</span><br><em><strong>Ege Erdil</strong><span> 02:47:57</span></em><br><span>One reason to be optimistic is if you think the AIs will literally be drop-in remote workers, or drop-in workers in some cases if you have robotics, then companies are already experienced at onboarding humans, onboarding humans doesn’t take like a very long time. Maybe it takes six months even in a particularly difficult job for a new worker to start being productive. Well, that’s not that long.</span><br><span>So I don’t think that would rule out companies being able to onboard AI workers, assuming that they don’t need to make a ton of new complementary innovations and discoveries to take advantage. I think one way in which current AI systems are being inhibited and the reason we’re seeing the growth maybe be slower than you might otherwise expect, is because companies in the economy are not used to working with this new technology, they have to rearrange the way they work in order to take advantage of it.</span><br><span>But if AI systems were literally able to substitute for human workers then, well, the complementary innovations might not be as necessary.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:49:00</span></em><br><span>Actually this is a good excuse to go to the final topic, which is AI firms. So this blog post we wrote together about what it would be like to have a firm that is fully automated, and the crucial point we were making was that people tend to overemphasize and think of AI from the perspective of how smart individual copies will be.</span><br><span>And if you actually want to understand the ways in which they are superhuman, you want to focus on their collective advantages which, because of biology, we are precluded from, which are the fact that they can be copied with all their tacit knowledge. You can copy a Jeff Dean or Ilya Sutskever or whatever the relevant person is, in a different domain. You can even copy Elon Musk and he can be the guy who’s every single engineer in the SpaceX rig. And if that’s not an efficient way to…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:49:49</span></em><br><span>The AI equivalent of them.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:49:50</span></em><br><span>And if it’s not best to have Elon Musk or anything, you just copy the relevant team or whatever. And we have this problem with human firms, where there can be very effective teams or groups, but over time their culture dilutes, or the people leave, or die, or get old. And this is one of the many problems that can be solved with these digital firms.</span><br><span>Firms right now have two of the three relevant criteria for evolution; they have selection, and they have variation, but they don’t have high fidelity replication. And you could imagine a much more fast-paced and intense sequence of evolution for firms once you have this final piece click in.</span><br><span>And that relates to the onboarding thing, where right now they just aren’t smart enough to be onboarded as full workers, but once they are, I just imagine the kinds of things I try to hire for, it would just be such an unlock. The salaries are totally secondary. The fact that I can… “This is the skill I need” or the set of skills I need. And I can have a thousand workers in parallel if there’s something that has a high elasticity of demand. I think it’s probably, along with the transformative AI, the most underrated tangible thing that you need to understand about what the future AI society will look like.</span><br><em><strong>Ege Erdil</strong><span> 02:51:22</span></em><br><span>I think there’s a first point about this very macroeconomic picture, where you just expect a ton of scaling of all the relevant inputs. I think that is the first order thing. But then you might have more micro-questions about, “okay, how does this world actually look like? How is it different from a world in which we just have a lot more people and a lot more capital and a lot more…?” Because it should be different. And then I think these considerations become important.</span><br><span>I think another important thing is just that AIs can be aligned. You get to control the preferences of your AI systems in a way that you don’t really get to control the preference of your workers. Your workers, you can just select, you don’t really have any other option. But for your AIs, you can fine tune them. You can build AI systems which have the kind of preferences that you want. And you can imagine that’s dramatically changing basic problems that determine the structure of human firms.</span><br><span>For example, the </span><a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem" rel="">principal agent problem</a><span> might go away. This is a problem where you as a worker have incentives that are either different from those of your manager, or those of the entire firm, or those of the shareholders of the firm.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:52:29</span></em><br><span>I actually think the incentives are a smaller piece of the puzzle. It’s more about bandwidth and information sharing where, with a large organization it’s very hard to have a single coherent vision, and the most successful firms we see today are where, for an unusual amount of time, a founder is able to keep their vision instilled in the organization; SpaceX or Tesla are examples of this. People talk about Nvidia this way.</span><br><span>But just imagine a future version where there’s this hyper inference scale mega-Jensen, who you’re spending $100 billion a year on inference, and copies of him are constantly writing every single press release and reviewing every pull request, and answering every customer service request, and so forth, and monitoring the whole organization, making sure it’s proceeding along a coherent vision and getting merged back into the hyper-Jensen, mega-Jensen, whatever.</span><br><em><strong>Ege Erdil</strong><span> 02:53:30</span></em><br><span>Yeah, I agree that’s a bigger deal. At the same time, I would point out that part of the reason why it’s important to have a coherent vision and culture and so on in human companies might be that incentive problems exist otherwise. I wouldn’t rule that out, but I agree that, aside from the overall macroeconomic thing, I think the fact that they can be replicated is probably the biggest deal.</span><br><span>That also enables additional sources of economies of scale where if you have twice the number of GPUs, you can run not only twice the number of copies of your old model, but then you can train a model that’s even better. So you double your training compute and your inference compute, and that means you don’t get just twice the number of workers you would have had otherwise, you get more than that, because they are also smarter, because you spend more training compute. So that is an additional source of economies of scale.</span><br><span>And then there’s this benefit that, for humans, every human has to learn things from scratch, basically. They are born and then they have a certain amount of lifetime learning that they have to do. So in human learning, there’s a ton of duplication, while for an AI system, it could just learn once. It could just have one huge training run with tons of data. And then that run could be deployed everywhere. So that’s another massive advantage that the AIs have over humans.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:54:43</span></em><br><span>Maybe we’ll close up with this one debate we’ve often had offline, which is: will central planning work with these economies of scale?</span><br><em><strong>Ege Erdil</strong><span> 02:54:52</span></em><br><span>So I would say that, I mean, again, the question of, “will it work?”</span><br><em><strong>Dwarkesh Patel</strong><span> 02:54:56</span></em><br><span>Will it be optimal?</span><br><em><strong>Ege Erdil</strong><span> 02:54:58</span></em><br><span>Right. So my guess is probably not optimal. But I don’t think anyone has thought this question through in a lot of detail.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:55:10</span></em><br><span>So it is worth thinking about why one might expect central planning to be slightly better in this world. So one consideration is just communication bandwidth being potentially much, much greater than it is today. In the current world, the information gathering and the information processing are co-located; humans observe and also process what they observe. In an AI world, you can disaggregate that.</span><br><span>So you can have the sensors and not do much processing, but just collect and then process centrally. And that processing centrally might make sense for a bunch of reasons, and you might get economies of scale from having more GPUs that produce better models, and also be able to think more deeply about what it’s seeing.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:56:06</span></em><br><span>It’s worth noting that certain things already work like this, for example, Tesla FSD. It will benefit from the data collected at the periphery from millions of miles of driving. And then the improvements which are made as a result of this.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:56:19</span></em><br><span>Centrally directed, it’s coming from HQ being like, “we’re going to push an update”.</span><br><span>And so you do get some of this more centralized…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:56:27</span></em><br><span>And it can be a much more intelligent form than just whatever gradient averaging that they- I mean, I’m sure it’s more sophisticated than that at Tesla- but it can be a much more deliberate, intelligent update.</span><br><em><strong>Tamay Besiroglu</strong><span> 02:56:36</span></em><br><span>So that’s one reason to expect. And the other reason, I guess, is current leaders or CEOs don’t have bigger brains than the workers do. Maybe a little bit…</span><br><em><strong>Dwarkesh Patel</strong><span> 02:56:50</span></em><br><span>I don’t know if you want to open that…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:56:52</span></em><br><span>But not by orders of magnitude. And so you could have orders of magnitude more scaling of the size of the models that are doing the planning than the people or the agents or workers doing the actions.</span><br><em><strong>Ege Erdil</strong><span> 02:57:04</span></em><br><span>And I think a third reason is the incentive thing, where part of the reason you have a market is that it gives people the right kind of incentives. But you might not need that as much if you’re using AI. So I think there’s an argument that if you just list the traditional arguments people have made against “why does central bank not work?”, then you might expect them to become weaker.</span><br><span>Now, I think there’s a danger when you’re doing that kind of analysis to fall into the same kind of partial equilibrium analysis where you’re only considering some factors and then you’re not considering other things. For example…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:57:43</span></em><br><span>Things get more complex, you just have a much bigger economy and so on the one hand, your ability to collect information and process it improves, but also the need for doing that also increases as things become more complex.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:57:59</span></em><br><span>And one way to illustrate that is: imagine if Apple, the organization today, with all its compute and whatever, was tasked with managing the economy of </span><a href="https://en.wikipedia.org/wiki/Uruk" rel="">Uruk</a><span>. I think it actually could centrally plan the economy. The economy of Uruk might work even better as a result. But Apple as it exists today cannot manage the world economy as it exists today.</span><br><em><strong>Ege Erdil</strong><span> 02:58:18</span></em><br><span>That’s right. Yeah.</span></p><p><em><strong>Dwarkesh Patel</strong><span> 02:58:20</span></em><br><span>All right, actually this will be the final question: One of the things that makes AI so fascinating is that there is no domain of human knowledge that is irrelevant to studying it, because what we’re really trying to…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:58:33</span></em><br><span>I don’t know about that.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:58:36</span></em><br><span>There’s no </span><em>serious</em><span> domain of human knowledge…</span><br><em><strong>Tamay Besiroglu</strong><span> 02:58:40</span></em><br><span>That’s better.</span><br><em><strong>Dwarkesh Patel</strong><span> 02:58:42</span></em><br><span>…that is not relevant to studying it, because you’re just fundamentally trying to figure out what a future society will look like. And so obviously computer science is relevant, but also economics- as we’ve been discussing- history, and how to understand history, and many other things we’ve been discussing.</span><br><span>Especially if you have longer timelines and there is enough time for somebody to pursue a meaningful career here, what would you recommend to somebody? Because both of you are quite young. I mean, you especially Ege, but both of you. You would think this is the kind of thing which requires crystallized intelligence or whatever, especially given what we said earlier about… Look, as we get more knowledge, we’re going to have to factor what we’re learning into building a better model of what’s going to happen to the world. And if somebody is interested in this kind of career that you both have, what advice do you have for them?</span><br><em><strong>Ege Erdil</strong><span> 02:59:27</span></em><br><span>Yeah, that’s a hard question. I mean, I’m not sure. I think there is an extent to which it’s difficult to deliberately pursue the implicit strategy that we would have pursued. It probably works better if it’s spontaneous and more driven by curiosity and interest than: you make a deliberate choice, “okay, I’m just going to learn about a bunch of things so that I can contribute to the discourse on AI”. I would think that strategy is probably less effective. At least I haven’t seen anyone who deliberately used that strategy and then was successful, it seems like.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:00:05</span></em><br><span>Yeah, I guess not that I’ve contributed to discourse directly, but maybe facilitated other people contributing. I guess it wasn’t a deliberate strategy on my end, but it was a deliberate strategy to do the podcast, which inadvertently gave me the opportunity to learn about multiple fields.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:00:20</span></em><br><span>Yeah, so given that you’re already interested and curious and reading a bunch of things, and studying a bunch of things, and thinking about these topics, on the margin there are a bunch of things you can do to make you more productive at making some contributions to this.</span><br><span>And I think just speaking to people and writing your thoughts down and finding especially useful people to chat with and collaborate with, I think that’s very useful. So just seek out people that have similar views and you’re able to have very high bandwidth conversations with and make progress on these topics. And I think that’s just pretty useful.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:01:00</span></em><br><span>But how exactly? Like should they DM you? Like how do they get in?</span><br><em><strong>Ege Erdil</strong><span> 03:01:05</span></em><br><span>Yeah, sure.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:01:06</span></em><br><span>And, I don’t know, set up Signal chats with your friends or whatever.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:01:10</span></em><br><span>Actually, it’s crazy how much alpha I’ve gotten out of that.</span><br><strong>Ege Erdil</strong><span> </span><em>03:01:14</em><br><span>But yeah, I think one advice I would give to people in general, even if they are not thinking about AI specifically, but I think it’s also helpful for that, is people should be much more aggressive about reaching out. People have an impression that if you reach out to someone who looks really important, they’re not going to respond to you. But if what you send to them is interesting and high quality, then it’s very, very likely that they will respond.</span><br><span>There’s like a lot more edge there that you can get, which is just being more aggressive and less ashamed of looking dumb. That’s the main advice I would give. Because if you want to be productive, then again, there are these complementarities and so you need to be part of some community or some organization.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:02:02</span></em><br><span>And it goes back to the thing about reasoning alone not being that helpful.</span><br><em><strong>Ege Erdil</strong><span> 03:02:05</span></em><br><span>Yeah, yeah, yeah.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:02:06</span></em><br><span>It’s just like other people have thought a long time and have randomly stumbled upon useful ideas that you can take advantage of.</span><br><em><strong>Ege Erdil</strong><span> 03:02:12</span></em><br><span>That’s right. So you should just try to place yourself in a situation where you can become part of something larger. Which isn’t working on the front, that’s just a more effective way of contributing. And to do that, you have to, well, let people know.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:02:25</span></em><br><span>That’s right. That’s right. And I think just coming to the Bay Area is especially- for interest in AI in particular.</span><br><em><strong>Ege Erdil</strong><span> 03:02:30</span></em><br><span>Yeah, going to the Bay Area is nice. Just post, like just writing things and like posting them where people can see them. Just aggressively reaching out to people with interesting comments.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:02:39</span></em><br><span>Provided your thoughts are interesting and so on.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:02:42</span></em><br><span>I mean, they probably aren’t. In many cases, I think it’s like, my thoughts still might not be interesting, but people will tolerate my cold emails and will still collaborate with me and so forth.</span><br><span>The other thing I’ve noticed- tell me if this is actually the wrong pattern. With people like you or with </span><a href="https://forum.effectivealtruism.org/topics/carl-shulman" rel="">Carl Schulman</a><span> or something, is that, as compared to a general person who’s intellectually curious or reading widely, you tend to focus much more on key pieces of literature than say, “I’m going to go read the classics or just generally read”. It’s like, “ I’m going to just put like a ton more credence in something like the Roamer paper”. And a normal person who’s intellectually curious would not be reading key pieces of literature.</span><br><em><strong>Ege Erdil</strong><span> 03:03:31</span></em><br><span>Yeah. I think you have to be very mindful of the fact that you have a very limited amount of time, you’re not an AI model. So you have to aggressively prioritize what you’re going to spend your time reading.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:03:44</span></em><br><span>Even AI models don’t prioritize that heavily. They read Reddit mostly or a large part of their corpuses…</span><br><em><strong>Dwarkesh Patel</strong><span> 03:03:48</span></em><br><span>Key pieces of empirical literature, at least. At least among you guys. I mean, it might not be the most productive thing in general, but…</span><br><em><strong>Tamay Besiroglu</strong><span> 03:03:54</span></em><br><span>I think that’s useful. I also think it’s useful to read Twitter. I think we were having this conversation about people often say that they’re spending too much time reading Twitter and they wish they spent more time reading </span><a href="https://arxiv.org/" rel="">arXiv</a><span>. But actually, the amount of information per unit time you get reading Twitter is often just much higher, and it’s just much more productive for them to read Twitter.</span><br><span>I think there are key pieces of literature that are important, and I think it’s useful to figure out what people who have spent a lot of time thinking about this find important in their worldview, so in AI, this might be key papers, like </span><a href="https://arxiv.org/abs/2205.10487" rel="">the Andy Jones paper about scaling loss for inference</a><span> is a big thing.</span><br><span>And in economics, this </span><a href="https://www.jstor.org/stable/2937632" rel="">Romer paper</a><span> or the paper on explaining </span><a href="https://faculty.econ.ucdavis.edu/faculty/gclark/210a/readings/kremer1993.pdf" rel="">long run population from Kremer</a><span> or from David Rudman and so on. I think if people who you think think very well about this suggest a certain paper and they highly recommend it, then I think you should take that seriously and actually read those papers.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:05:09</span></em><br><span>And for me, it’s been especially helpful to, instead of just skimming a bunch of things, if there’s a key piece of literature in order to, for example, understand the transformer, there’s always the Karpathy lectures, but one research that was really useful is the </span><a href="https://transformer-circuits.pub/2021/framework/index.html" rel="">Anthropic’s original transformer circuit paper</a><span>. And just spending a day on that paper instead of skimming it and making a bunch of </span><a href="https://ncase.me/remember/" rel="">spaced repetition cards</a><span> and so forth, was much more useful than just generally reading widely about AI.</span><br><em><strong>Ege Erdil</strong><span> 03:05:42</span></em><br><span>I think it’s just much more important here if you want to prioritize things correctly to be, again, to be part of a community or to be getting inputs from a community or get from people who have thought a lot and have a lot of experience about what is important and what is not.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:05:56</span></em><br><span>Yeah.</span><br><em><strong>Ege Erdil</strong><span> 03:05:57</span></em><br><span>This is true even in academic fields. So if you want to do math research, but you’re not part of a graduate program, you’re not at a university where there are tons of people who do math research all day for many years, then you’re not even going to know what are the open problems that I should be working on? What is reasonable to attack? What is not reasonable to attack? What papers in this field are important, contain important techniques? You’re just going to have no idea. So it’s very important to be plugged into that feed of information somehow.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:06:26</span></em><br><span>But how did you know all this shit before being plugged in? Because you weren’t talking to anybody in Ankara.</span><br><em><strong>Ege Erdil</strong><span> 03:06:30</span></em><br><span>You don’t need to talk. The internet is a pretty useful thing in this respect. And you don’t need to necessarily talk to people, you can get a lot of benefit from reading. But you just need to identify, who are the people who seem constantly most interesting? And maybe you find one person. And then often that person will know some other people who are interesting. And then you can start tracing the social network.</span><br><span>One example I can give, which I think is actually accurate, is maybe you know about </span><a href="https://en.wikipedia.org/wiki/Daniel_Ellsberg" rel="">Daniel Ellsberg</a><span>. So you look for a podcast he appears on. You notice that he’s appeared on </span><a href="https://80000hours.org/podcast/" rel="">80,000 Hours</a><span> podcast, which </span><a href="https://80000hours.org/podcast/episodes/daniel-ellsberg-doomsday-machines/" rel="">he has</a><span>. And then you notice there are some other guests on the 80,000 Hours podcast. So maybe there’s </span><a href="https://en.wikipedia.org/wiki/Bryan_Caplan" rel="">Bryan Caplan</a><span>, who has also </span><a href="https://80000hours.org/podcast/episodes/bryan-caplan-stop-reading-the-news/" rel="">appeared on the podcast</a><span>. And then maybe Robin Hanson has also </span><a href="https://80000hours.org/podcast/episodes/robin-hanson-on-lying-to-ourselves/" rel="">appeared on the podcast</a><span>. And then maybe there are some people those other people know. And then just tracing that kind of social network and figuring out who to listen to like that. I think that can be…</span><br><em><strong>Tamay Besiroglu</strong><span> 03:07:26</span></em><br><span>And I think you’re doing a very big service to making that possible. I think your selection is often very good.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:07:33</span></em><br><span>I’m actually curious to hear offline what I got wrong. Well, actually, I think I know the answer to that.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:07:38</span></em><br><span>And I think that makes it a bunch easier to track who are the people doing the most interesting thinking on various topics.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:07:47</span></em><br><span>That’s right. Cool. I think that’s a good place to end, with you praising me. Again, I highly recommend people follow </span><a href="https://epoch.ai/" rel="">Epoch</a><span>.</span><br><span>There’s a great weekly newsletter, </span><a href="https://epoch.ai/gradient-updates" rel="">Gradient Updates</a><span>, which- I mean, people plug newsletters, but this is, I can’t believe this is a thing that comes out on a weekly basis.</span><br><span>And you now have a new </span><a href="https://podcastaddict.com/podcast/epoch-after-hours/5621813" rel="">podcast</a><span>, which I will not plug as a competitor, but you can check it out.</span><br><em><strong>Tamay Besiroglu</strong><span> 03:08:18</span></em><br><span>Thanks for lending your studio.</span><br><em><strong>Ege Erdil</strong><span> 03:08:20</span></em><br><span>Yeah, that’s very generous.</span><br><em><strong>Dwarkesh Patel</strong><span> 03:08:24</span></em><br><span>Anyways, cool. Thanks, guys.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Milwaukee M18 Battery Reverse Engineering (152 pts)]]></title>
            <link>https://quagmirerepair.com/milwaukee-m18-battery-reverse-engineering</link>
            <guid>43718809</guid>
            <pubDate>Thu, 17 Apr 2025 16:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quagmirerepair.com/milwaukee-m18-battery-reverse-engineering">https://quagmirerepair.com/milwaukee-m18-battery-reverse-engineering</a>, See on <a href="https://news.ycombinator.com/item?id=43718809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Coming soon... Milwaukee M18 Battery Dissection and Reverse Engineering...</p>
<p>2023-01-01: This project has been ongoing for a while... now its time to post some of this info and see what comes of it. I have access to several junk Milwaukee M18 batteries. Age varies a little. I thought it would be 'fun' to reverse engineer a battery just to see how it functions... That is until I actually opened the first one up and saw all the 0402 resistors and capacitors. Then it seemed like a 'fun-bad' idea. So here is the start of the first battery; Enjoy! (Reminder - Click on an image to get a larger version!)</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20221228_121003625.webp"><img title="Milwaukee M18 48-11-1828 Reverse Engineering" src="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20221228_121003625_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>And here is our first candidate for reverse engineering: a Milwaukee M18 48-11-1828 18VDC 54Wh / 3 Ah Battery Pack. (Hey its the first one I picked up... I was aiming for a 5Ah and missed somehow... Didn't actually look very close at what I grabbed until the PCB was already removed.) Serial: B41MD 028567. This particular battery doesn't seem to hold its charge properly (indicator lights go up to full when charging, but put it on a drill and spin it for a second, and the indicator now reads two bars.) Battery voltages appear nominal though. Wasn't really interested in the cells themselves, so left this area of investigation go for the time being.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20221227_170428454.webp"><img title="Milwaukee M18 48-11-1828 Reverse Engineering" src="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20221227_170428454_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>After removing 4 tamper-proof torx screws and popping the top off the battery top casing off, we're left with a simple circuit board connected to 5 pins and 10 batteries (5 sets of 2 cells). Did I say simple? (I might regret that later...)</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02928.webp"><img title="Milwaukee M18 48-11-1828 PCB Top View - Reverse Engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02928_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>I put this PCB under a decent camera (Sony A6300 with the FE 2.8/50 Macro lens) after removing the circuit board and de-soldering the connectors.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02930.webp"><img title="Milwaukee M18 48-11-1828 PCB bottom view - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02930_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>And back side of the PCB... Sorry, I really shouldn't have used that 300W Weller soldering iron on these... I don't have the proper tip for the wide terminals on my Hakko... [Another reminder to get this at some point.] I really need to get the coating off these boards.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02947.webp"><img title="Milwaukee M18 48-11-1828 PCB top view without coating - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02947_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>After a soak in some solvents and a quick scrub with a brass bristled brush, we're left with a nice clear board. We've got two chips that took a bit of time to figure out what they were... [insert plenty of wasted time trying to get pictures of the poorly lasered markings and guessing of multiple digits (is that a B or an 8?; a 6, 5 or an 8?) - My wife finally arrived at the solution for U2 - Hooray for second opinions and excellent reading/deciphering skills!] U1 is a <a href="https://quagmirerepair.com/files/M18_48111828_B41/msp430g2744.pdf">Texas Instruments MSP430G2744 Mixed Signal Microcontroller (Datasheet, PDF, 86 pages, 2.15MB).</a> U2 is a <a href="https://quagmirerepair.com/files/M18_48111828_B41/bq76925.pdf">Texas Instruments BQ76925 3 to 6 Series Cell Li-Ion Battery Monitor IC (Datasheet - PDF, 48 Pages, 6.10MB).</a></p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02949.webp"><img title="Milwaukee M18 48-11-1828 PCB bottom view without coating - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02949_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>Back side of the board... It was at this point that I noticed the tiny little numbers in the upper right hand side of the PCB (the dim 3 and 4). I then had to flip the board over and verify that there was indeed a 1 and 2 on the top side... Uh oh... (This is a 4 layer circuit board) I should also note here the text on the bottom of the board reading "280086026 Rev 7.0 Jan-31-2013"; as far as I can tell that is the same as what the front says.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02967.webp"><img title="Milwaukee M18 48-11-1828 PCB top view without components - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02967_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>After a very tedious couple hours of de-soldering components and trying to measure each and every one, we're left with a board that looks like this; It needs some cleanup yet, but that will come shortly... I now have a <a href="https://quagmirerepair.com/files/M18_48111828_B41/BOM.pdf">BOM (PDF, 3 Pages, 29KB)</a> that is surprisingly complete and a board that is still mostly intact - If you want something to look for I lost a total of one pad and loosened two more. The lost pad isn't connected to anything as far as I can tell.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02970.webp"><img title="Milwaukee M18 48-11-1828 PCB top view without components and sanded - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02970_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>A quick sand with 400 grit sandpaper to take away the solder resist and silkscreen leaves us with most of the copper on Layer 1 visible. Now we need to get to the middle layers.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02977.webp"><img title="Milwaukee M18 48-11-1828 PCB Middle layer view - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02977_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>After a bunch more sanding, we're left with a decently clear view of Layer 2 on the PCB. We can see the ground/negative plane on the right hand side of the board.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/DSC02980.webp"><img title="Milwaukee M18 48-11-1828 PCB middle layer view view  - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/DSC02980_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>Same process on the other side of the PCB. We can see Layer 2 fairly nicely, although I will warn you that some of the vias aren't highlighted very well because of the ground plane on Layer 3... The larger copper area clustered around U1 appears to be the positive rail.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/Layer1marked.webp"><img title="Milwaukee M18 48-11-1828 Layer 1 Copper  - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/Layer1marked.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>I've gone through and marked all the copper layers to the best of my abilities. You can <a href="https://quagmirerepair.com/files/M18_48111828_B41/Stacked_Images_for_website.zip">download a lower-res version of the document I'm working off of here. (ZIP-XCF-Gimp, 30.1MB)</a> I'm going to have to take a bit of a break on this project, but this should be enough info for you to start tracing connections without going to all the previous work. (Let me know if I messed up any of the connections!). And yes, I know I didn't dump firmware either...It is on my todo list! Enjoy!</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_BQ76925_PRETTY.pdf"><img title="Milwaukee M18 48-11-1828 BQ76925 Battery Monitoring - reverse engineering teardown" src="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_BQ76925_PRETTY.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<hr>
<p>2023-01-16: Small update and work in progress notice: I've attached a small diagram of the BQ76925 Battery Monitoring Connections. This is one area that always puzzled me about these batteries: Was there cell balancing? <s>The answer for this battery is a definite NO! (and this puzzles me...why not? I mean aside from cost?) </s> 2023.2.1 Correction: Thanks to Ben C. for pointing out my mistake; It does appear as if the BQ76925 has the ability to balance cells. Current is controlled by R7/R9/R11/R12/R11. But the actual balancing is controlled by commands from the host MSP430. Every battery connection except BAT+ and CT1- are fully diagramed in this image. I am really confused about the purpose of D20/D21 though... [2023.2.1 note: I think I stumbled onto part of the voltage regulation circuit for the microprocessor. Not diagramed fully though. I really should have included the block diagram from the BQ76925. I'm including it here for reference.] I'm still confused by the difference in capacitor layout between the two diagrams and the actual Milwaukee design though.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/82blockdiagram.webp"><img title="Milwaukee M18 48-11-1828 BQ76925 Block Diagram" src="https://quagmirerepair.com/files/M18_48111828_B41/82blockdiagram.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/simplifiedschematic_BQ76925.webp"><img title="Milwaukee M18 48-11-1828 BQ76925 Reference Diagram" src="https://quagmirerepair.com/files/M18_48111828_B41/simplifiedschematic_BQ76925.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<hr>
<p>2023-01-28: Small update: Quick diagram of the charging control circuit. I needed to know which pin on the MSP430 controlled the charging circuit. Now you know too! <a href="https://quagmirerepair.com/files/M18_48111828_B41/si4401bd.pdf">Datasheet for 4401 P-Channel MOSFET (Datasheet, PDF, 8 pages, 181KB).</a> Just as a reminder, RT2 is not populated and R29 is populated. (somehow I mis-labeled this resister on <a href="https://quagmirerepair.com/files/M18_48111828_B41/BOM.pdf">my BOM</a> and the other board I have doesn't have RT2 or R29 on it... I need to dissect a couple more batteries to find a similar circuit board of similar vintage.) Now, I'm wondering how the battery knows a charger is connected...</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/ChargingCircuit_lrg.webp"><img title="Milwaukee M18 Battery Charging Circuit" src="https://quagmirerepair.com/files/M18_48111828_B41/ChargingCircuit_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>And here are the UI circuit elements. It surprised me that they are using Q1 to turn the LEDs on and off; why would you use an extra IO Pin to cut power to LEDs? Would there be a leakage/voltage problem I'm missing? Switch input is nicely de-bounced in hardware, although there again I'm confused by the extra IO pin connected via R27... It seems wasted somehow; wouldn't a typical circuit use R27 to bias pin 33 towards VCC instead of connecting to an IO pin? There are direct connections from the 4 pin header to Pin 5 (Manual says 'Reset or nonmaskable interrupt input. Spy-Bi-Wire test data input/output during programming and test.') and Pin 37 (Manual says 'Selects test mode for JTAG pins on Port 1. The device protection fuse is connected to TEST. Spy-Bi-Wire test clock input during programming and test.') I really don't like seeing direct mentions about 'device protection fuses' on pin descriptions when I'd like to retrieve firmware at some point.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/28086026%20R7.0_UI.webp"><img title="Milwaukee M18 Battery UI Elements" src="https://quagmirerepair.com/files/M18_48111828_B41/28086026%20R7.0_UI_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<hr>
<p>2023-02-03: Oh look! <a href="https://quagmirerepair.com/files/M18_48111828_B41/slua707.pdf">A handy guide from Texas Instruments on how to use the BQ76925 with the MSP430G2xx2. (PDF, 29 Pages, 941kB)</a> Why do the circuit diagrams look familiar? It is almost like Milwaukee used a Texas Instruments reference design with tweaks!</p>
<hr>
<p>2023-02-04: A couple interesting google patent links for M18 Batteries:<br><a href="https://patentimages.storage.googleapis.com/18/c6/09/dd6ae1d63c1d79/US20140093753A1.pdf">BATTERY PACK INCLUDING AN ELECTRIC HARNESS AND METHOD OF MANUFACTURING THE SAME (PDF, 11 pages, 770KB).</a><br><a href="https://patentimages.storage.googleapis.com/4f/7e/c8/9954c1240e448f/US10270263.pdf">SYSTEM AND METHOD FOR CHARGING A BATTERY PACK (PDF, 9 pages, 1MB).</a><br><a href="https://patentimages.storage.googleapis.com/bd/39/63/1920efd9e37695/US20220339771A1.pdf">HIGH - POWER CORDLESS , HAND - HELD POWER TOOL INCLUDING A BRUSHLESS DIRECT CURRENT MOTOR (PDF, 72 pages, 5.8MB).</a></p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_J1J2.webp"><img title="Milwaukee M18 Battery External Communication Circuits" src="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_J1J2_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>I'll add this diagram to the page as well, since J1/J2 communication seems to be a popular request and that I think I finally have it decently diagramed. J2 seems to have a dual purpose;<br>1) The Battery receives about 12VDC when connected to a charger (possibly also a tool?) This passes through R33 and 'wakes up' the MSP430 (assuming it is not already running). Battery then appears to pull voltage down [on J1], which signals to the charger that a battery has been connected and allowing communication to start.<br>2) Communication appears to pass through D11 -&gt; Q11. MSP430 Communication Pins 40 and 31 are pulled high by Resistor R45 and pulled low by Q11.<br>3) I'm unsure what purpose the R48 connections serve at this point.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_BQ76925_to_MSP430.webp"><img title="Milwaukee M18 Battery BQ76925 to MSP430 Communication links circuit diagram" src="https://quagmirerepair.com/files/M18_48111828_B41/28086026_R7.0_BQ76925_to_MSP430_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>And one more diagram... This diagram shows the various signal wires and communication links between the MSP430 and the BQ76925. Finally have the Thermistors fit into the circuit as well!</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/referencediagram.webp"><img title="TI Reference Diagram" src="https://quagmirerepair.com/files/M18_48111828_B41/referencediagram.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>Its almost funny seeing that Milwaukee's battery uses an almost exact copy of this reference diagram from <a href="https://quagmirerepair.com/files/M18_48111828_B41/slua707.pdf">Texas Instruments' Application Report. (PDF, 29 Pages, 941kB)</a> Only thing different I can see is the alert line which is unused by Milwaukee... Wonder why? (I didn't dive into the details on this pin yet...) I guess you can't improve on something that is perfectly designed!</p>

<hr>
<p>2023-02-06: Milwaukee M18 Battery Communication:</p>
<p>Settings for J1/J2 Communication:</p>
<p>2000 Baud (yes really... not 1200, not 2400 baud)</p>
<p>Data length: 8 Bits</p>
<p>Parity: None</p>
<p>Stop Bits: 1</p>
<p>Idle Level: High</p>
<p>Bit Order: Unknown</p>
<p>Thanks to Mick @ buyitfixit for reminding me that when you measure a bit duration of 500us and calculate a baud rate of 2000 you probably shouldn't try to decode a serial stream with 1200 or 2400 baud no matter the what the datasheets say (or what common baud rates are).</p>
<p>Last byte of each message appear to be a Checksum. IE 0x81 + 0x20 + 0x00 + 0x00 = 0xA1 (Thanks again to Mick @ buyitfixit)</p>
<p>Battery does not appear to send any data on P1/P2 when battery test button is pushed; also doesn't appear like Milwaukee M18 Batteries support the long-press self-test diagnostic/LED flash codes anymore. Can't get them to appear on any battery year 2015+... [edit: Newer M18 FORGE batteries appear to have the functionality built in again]</p>
<p>There are a surprising number of M18 tools that don't seem to communicate with the battery... Course I'm dealing with mostly used/otherwise broken tools, so there is a possibility that there is something faulty there as well. M18 LED Flashlight, transfer pump, circular saw etc don't seem to communicate.</p>
<hr>
<p>2023-02-11 Update: Below is some data for anybody to pour over. Still not quite sure on bit order - scope is set for LSB (Least Significant Bit). First spreadsheet is the results of a 7 second capture on my scope, triggered by the communication line dropping in voltage when the battery gets plugged into the charger. Charger begins communication with an 0x55 handshake (Charger is RX and Battery is TX). Various data points about the batteries are included in the spreadsheet. Strangely, a lot of it looks very similar with the only major difference being an early shutdown in communication when the battery reports itself as already full. First byte might be a device ID. Second byte may be a command. Last byte is a checksum. In between?</p>
<p><a href="https://quagmirerepair.com/files/M18_Communication/BatteryPluggedIntoCharger.zip">BatteryPluggedIntoCharger (ZIP - Libreoffice Calc Spreadsheet .ODS, 33KB)</a></p>
<p>2nd/3rd Spreadsheet: I also tapped the SDA/SCL Communication lines between the BQ76925 and R7F0C901B2 MCU in addition to watching the P1/P2 Data lines. Unfortunately, my scope has a very limited capture time due to four channels and the increased resolution required for the I2C communication. This shows the data that is being requested by the R7F0C901B2 MCU, but not the actual data supplied by the BQ76925. I've included a couple pictures on the spreadsheet of register maps on the BQ76925 to help decode the data... Strangely, at least to me, VC4_CAL isn't requested and I only see requests for one battery cell voltage. (please correct me if I'm mis-interpreting data wrong)</p>
<p><a href="https://quagmirerepair.com/files/M18_Communication/2023-02-10_Charging.zip">2023-02-10_Charging (ZIP - Libreoffice Calc Spreadsheet .ODS, 147KB)</a></p>
<p><a href="https://quagmirerepair.com/files/M18_Communication/SDA_SCL_Decode.zip">SDA_SCL_Decode (ZIP - Libreoffice Calc Spreadsheet .ODS, 148KB)</a></p>
<hr>
<p>2023-09-12: Update: I have no affiliation with Tool Scientist, but he's taken the reverse engineering further than I had time to...</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/OGzeGUDAtac?si=1f1OIe4aHAixg36b" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<hr>
<p>2023-10-29: New video from Tool Scientist explaining 'Tool to Battery Communication':</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/q7spzrIbdKY?si=20fsAOwcgbHwpQl4" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Definitely glad to know I wasn't crazy or being downright stupid in not finding any communication happening between the tool and battery, though I'll have to confess I did miss the 12V/3V 'handshake' - I saw that the voltages were there, but never saw the handshake or saw them drop out. That and the complete miss on the battery amperage monitoring even though I clearly saw that it was supposed to be there on the sample designs. I just assumed Milwaukee chose to not implement it. Excellent work by the tool scientist... Now on to some new circuit designs!</p>
<hr>
<p>2024-09-14: Update: No new information, but happy to see a mention! (and yes I really didn't see this for 11 months!)</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/0smUe5xvAOQ?si=l4J-iUnNyLoG0mtU" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<hr>
<p>2024-10-5: Another video from Tool Scientist. He explains things so much better than I can! Seems there is one small step yet until someone builds a 3rd party external balancer for these batteries. (PLEASE, if someone has done so, please let me know! I'll gladly build and test units if needed!) I've done manual balancing on 100's of these batteries to get them working again! And what was he working on that he created code to generate a balance byte? :) I guess we'll find out in future videos!</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/eaopJyROmhM?si=gbDO7GMiCnAzrHaX" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Also realized I never linked to the other partially finished, related pages to this project. For more information on the Rapid Charger internals, <a href="https://quagmirerepair.com/milwaukee-860323004-rapid-charger">CLICK HERE.</a> For a similar (but not the same) partially completed teardown of a 5Ah battery, <a href="https://quagmirerepair.com/m18-rev05-jun-26-2015">CLICK HERE.</a> (the reference in the video above about the Renesas R7F0C901B2 microprocessor is what made me check for the links that I apparently never put up on this page.)</p>
<p>(Also made a couple readability fixes for this page.)</p>
<hr>
<details>
<summary><strong>2024-12-28: Bunny Trail on obsolete MSP430 chips (click to expand)</strong></summary>

<p>2024-12-28: After watching some of the latest Tool Scientist videos, I have to add a note: Has anyone considered the <a href="https://www.ti.com/tool/BQ76925EVM">Texas Instruments BQ76925EVM Evaluation Module?</a> Scroll down the page a little to where it says <a href="https://dr-download.ti.com/software-development/firmware/MD-cWgxkC7OXn/01.00.00.00/sluc581.zip">'SLUC581 — bq76925 Example Code'</a> Under technical docs, there is a <a href="https://www.ti.com/lit/pdf/slusam9">Datasheet</a> and a <a href="https://www.ti.com/lit/pdf/sluu514">User's Guide (SLUU514A).</a> There is also an <a href="https://www.ti.com/lit/an/slua707/slua707.pdf">Application Report (SLUA707)</a> which gives a hint at a prebuilt battery management codebase from TI... which I can't seem to find...</p>
<hr>
<p>2025-01-07: Theoretical only; read and apply at your own risk!</p>
<p>Processor above is 40-Pin RHA package (Source: <a href="https://quagmirerepair.com/files/M18_48111828_B41/msp430g2744.pdf">MSP430G2744 Datasheet (Datasheet, PDF, 86 pages, 2.15MB).</a>, pages 5 &amp; 8</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/RHA40Pin.webp"><img title="MSP430G2744 40-Pin RHA Pinout" src="https://quagmirerepair.com/files/M18_48111828_B41/RHA40Pin.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>and this part can possibly be programmed by the <a href="https://www.ti.com/tool/MSP-FET">MSP-FET430UIF programming tool</a> while possibly using the <a href="https://www.ti.com/tool/MSP-TS430RHA40A">MSP-TS430RGA40A socket.</a> <a href="https://quagmirerepair.com/files/M18_48111828_B41/slau278ah.pdf">MSP430 Hardware Tools (PDF, 191 pages, 9.75MB).</a> pages 78-80 gives a Schematic, layout and BOM for the board.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/MSP-TS430RGA40A_Pinout.webp"><img title="MSP-TS430RHA40A schematic" src="https://quagmirerepair.com/files/M18_48111828_B41/MSP-TS430RGA40A_Pinout.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>(There is also <a href="https://quagmirerepair.com/files/M18_48111828_B41/slau144k.pdf">MSP430G2xx Family User's Guide (PDF, 703 pages, 9.49MB).</a> that gives you quite a lot of info about the processor and all its functions, including an interesting section 7 on Flash Memory Operation.)</p>
<p>of related interest would probably be the <a href="https://quagmirerepair.com/files/M18_48111828_B41/slau319af.pdf">MSP430 Programming with the JTAG Interface User's Guide (PDF, 83 pages, 1.68MB).</a> and the <a href="https://quagmirerepair.com/files/M18_48111828_B41/slau319af.pdf">MSP430 Flash Devices Bootloader BSL (PDF, 52 pages, 1.13MB).</a> There are two warnings, one in each document: 1): Each MSP430F1xx, 2xx, and 4xx flash device includes a physical fuse that is used to permanently disable memory access through JTAG communication. When this fuse is programmed (or blown), access to memory through JTAG is permanently disabled and cannot be restored. 2) Access to the MSP430 MCU memory through the BSL is protected against misuse by the BSL password.</p>
<p>Anyway, bunny trail... back to the <a href="https://quagmirerepair.com/files/M18_48111828_B41/slau278ah.pdf">MSP430 Hardware Tools (PDF, 191 pages, 9.75MB).</a> Pages 21 and 22 show two connection diagrams for programming.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/jtagconnections.webp"><img title="MSP430G2744 JTAG connections" src="https://quagmirerepair.com/files/M18_48111828_B41/jtagconnections.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>RST/NMI is Pin 5<br>TDO/TDI is Pin 36<br>TDI/VPP is 35?<br>TMS is Pin 34<br>TCK is Pin 33<br>TEST is Pin 37</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/spybywire.webp"><img title="MSP430G2744 Spy-bi-Wire connections" src="https://quagmirerepair.com/files/M18_48111828_B41/spybywire.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>RST/NMI/SBWTDIO is Pin 5<br>TEST/SBWTCK is Pin 37</p>
<p>and now we need to revisit an earlier electrical diagram with a header labeled HD1 - We can now clearly identify it as a Spy-bi-Wire /2-Wire JTAG interface. R1 and C1-C3 [in above diagram] are on the battery circuit board.</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/spibywireconnections.webp"><img title="M18 Battery Spy-bi-Wire connections" src="https://quagmirerepair.com/files/M18_48111828_B41/spibywireconnections.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>This should be an basic schematic of all the pins on the M18 Battery / MSP430 chip related to JTAG and Programming. Most of the pins have a testpoint that could be soldered to except pin 36 which seems to go to a via which has no further connections...</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/28086026%20R7.0_JTAG.webp"><img title="M18 Battery MSP430 JTAG pins schematic" src="https://quagmirerepair.com/files/M18_48111828_B41/28086026%20R7.0_JTAG_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p>(also a fix for a misplaced div tag in html page code... now paragraphs don't run to the very edge of the page and are a little more readable.)</p>
<hr>
<p>2025-01-11: Theories don't always work out so well in practice... Waiting on a MSP-TS430QFN40 yet... I think something is happening though; as soon as I attempt communication, battery refuses to respond to the pushbutton on the board and can only be woken up again by connecting to a charger. 3.3VDC still present across VCC / VSS</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20250111_193218031-2.jpg"><img title="M18 Battery JTAG attempt" src="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20250111_193218031-2_sm.jpg" alt="" width="80%" height="80%" loading="lazy"></a></p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/Screenshot_2025-01-11_190028.png"><img title="M18 Battery JTAG attempt failure" src="https://quagmirerepair.com/files/M18_48111828_B41/Screenshot_2025-01-11_190028.png" alt="" width="80%" height="80%" loading="lazy"></a></p>
<hr>
<p>2025-01-15: MSP-TS430QFN40 arrived... De-soldered 4 chips... and attempted to plunk the first into the socket... it did not plunk into place, but fell between the contacts... ? Chip measures 5x5mm - RHA40 should be about 5.8x5.8mm or QFN40 about 6x6mm... After some careful squinting I can see that this is an 32pin Renesas R5F100BG. I can see that the other chips I removed are also labeled the same way... These batteries were all 2018 and newer... I knew that there were newer chips in use, but it never registered in my brain to check if I had any of the old batteries with the MSP430. Sigh. Time to reconnoiter...</p>
<p><a href="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20250115_220800332_sm.webp"><img title="M18 Battery R5F100BG" src="https://quagmirerepair.com/files/M18_48111828_B41/PXL_20250115_220800332_sm.webp" alt="" width="80%" height="80%" loading="lazy"></a></p>

</details>
<hr>
<p>2025-04-14: Ahem... I really should [try to] keep up with other people. I still haven't found any old batteries with the MSP430 microcontroller to use and someone else has gone ahead and done all the work for me:</p>
<iframe title="YouTube video player" src="https://www.youtube.com/embed/gh2-gSRNw-Y?si=6WzcwNxz_D55PsiW" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen"></iframe> <br><hr><p><a href="https://quagmirerepair.com/chinese-m18-battery-board">Link to Chinese M18 Battery Circuit Boards</a></p><hr><p>2025-04-14: <a href="https://quagmirerepair.com/milwaukee-860323004-rapid-charger">Link to M18 Rapid Charger Reverse Engineering [work in progress]</a> Hint: there is a programming header for the R5F100!</p><hr>
<p>Corrections are welcome... Please let me know if you see mistakes!</p>
<p>And as always, clicking on an image will give you a higher-res version! If you repost or further dissect this board, please link back to the original and let us know where we can read about your work!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Is a Monopolist in Online Advertising Tech, Judge Says (690 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/17/technology/google-ad-tech-antitrust-ruling.html</link>
            <guid>43717705</guid>
            <pubDate>Thu, 17 Apr 2025 14:47:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/17/technology/google-ad-tech-antitrust-ruling.html">https://www.nytimes.com/2025/04/17/technology/google-ad-tech-antitrust-ruling.html</a>, See on <a href="https://news.ycombinator.com/item?id=43717705">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/17/technology/google-ad-tech-antitrust-ruling.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HDR‑Infused Emoji (214 pts)]]></title>
            <link>https://sharpletters.net/2025/04/16/hdr-emoji/</link>
            <guid>43717606</guid>
            <pubDate>Thu, 17 Apr 2025 14:42:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sharpletters.net/2025/04/16/hdr-emoji/">https://sharpletters.net/2025/04/16/hdr-emoji/</a>, See on <a href="https://news.ycombinator.com/item?id=43717606">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>Need a little more pop to your Slack emoji? Want to really stand out when you react with your favorite image?</p><p>Turns out you can add HDR emoji to Slack, and they will be rendered in eye-searing brightness, at least on hardware
that supports it. Works great in Chrome and Slack, and not at all on Android devices.</p><h3 id="examples">Examples:</h3><p>Note: These examples will work best when posted to Slack. Support in browsers and on devices varies, YMMV.
Known to work in Chrome and Slack (mostly), and doesn’t work in Safari (mostly).</p><table><thead><tr><th>Original</th><th>HDR</th></tr></thead><tbody><tr><td><img src="https://sharpletters.net/2025/04/16/hdr-emoji/head-empty.png"></td><td><img src="https://sharpletters.net/2025/04/16/hdr-emoji/head-empty-hdr.png"></td></tr><tr><td><img src="https://sharpletters.net/2025/04/16/hdr-emoji/eye-searing.png"></td><td><img src="https://sharpletters.net/2025/04/16/hdr-emoji/eye-searing-hero.png"></td></tr></tbody></table><h3 id="script">Script</h3><div><pre tabindex="0"><code data-lang="shell"><span><span>brew install imagemagick
</span></span><span><span>
</span></span><span><span><span># Adjust the Multiply value up or down to preserve color as opposed to brightness</span>
</span></span><span><span>magick input.png <span>\
</span></span></span><span><span><span></span>  -define quantum:format<span>=</span>floating-point <span>\
</span></span></span><span><span><span></span>  -colorspace RGB <span>\
</span></span></span><span><span><span></span>  -auto-gamma <span>\
</span></span></span><span><span><span></span>  -evaluate Multiply 1.5 <span>\
</span></span></span><span><span><span></span>  -evaluate Pow 0.9 <span>\
</span></span></span><span><span><span></span>  -colorspace sRGB <span>\
</span></span></span><span><span><span></span>  -depth <span>16</span> <span>\
</span></span></span><span><span><span></span>  -profile 2020_profile.icc <span>\
</span></span></span><span><span><span></span>  output.png
</span></span></code></pre></div><p>You will need the <a href="https://sharpletters.net/2025/04/16/hdr-emoji/2020_profile.icc">2020_profile.icc</a> downloaded to your working directory.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This 'College Protester' Isn't Real. It's an AI-Powered Undercover Bot for Cops (224 pts)]]></title>
            <link>https://www.wired.com/story/massive-blue-overwatch-ai-personas-police-suspects/</link>
            <guid>43716939</guid>
            <pubDate>Thu, 17 Apr 2025 13:57:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/massive-blue-overwatch-ai-personas-police-suspects/">https://www.wired.com/story/massive-blue-overwatch-ai-personas-police-suspects/</a>, See on <a href="https://news.ycombinator.com/item?id=43716939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>American police departments near the United States-Mexico border are paying hundreds of thousands of dollars for an unproven and secretive technology that uses AI-generated online personas designed to interact with and collect intelligence on “college protesters,” “radicalized” political activists, and suspected drug and human traffickers, according to internal documents, contracts, and communications that 404 Media obtained via public records requests.</p><p>Massive Blue, the New York–based company that is selling police departments this technology, calls its product Overwatch, which it markets as an “AI-powered force multiplier for public safety” that “deploys lifelike virtual agents, which infiltrate and engage criminal networks across various channels.” According to a presentation obtained by 404 Media, Massive Blue is offering cops these virtual personas that can be deployed across the internet with the express purpose of interacting with suspects over text messages and social media.</p><p>Massive Blue lists “border security,” “school safety,” and stopping “human trafficking” among Overwatch’s use cases. The technology—which as of last summer had not led to any known arrests—demonstrates the types of social media monitoring and undercover tools private companies are pitching to police and border agents. Concerns about tools like Massive Blue have taken on new urgency considering that the Trump administration <a data-offer-url="https://www.insidehighered.com/news/global/international-students-us/2025/04/07/where-students-have-had-their-visas-revoked" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.insidehighered.com/news/global/international-students-us/2025/04/07/where-students-have-had-their-visas-revoked&quot;}" href="https://www.insidehighered.com/news/global/international-students-us/2025/04/07/where-students-have-had-their-visas-revoked" rel="nofollow noopener" target="_blank">has revoked the visas of hundreds of students</a>, many of whom have protested against Israel’s war in Gaza.</p><p>404 Media obtained a presentation showing some of these AI characters. These include a “radicalized AI” “protest persona,” which poses as a 36-year-old divorced woman who is lonely, has no children, is interested in baking, activism, and “body positivity.” Another AI persona in the presentation is described as a “‘Honeypot’ AI Persona.” Her backstory says she’s a 25-year-old from Dearborn, Michigan, whose parents emigrated from Yemen and who speaks the Sanaani dialect of Arabic. The presentation also says she uses various social media apps, that she’s on Telegram and Signal, and that she has US and international SMS capabilities. Other personas are a 14-year-old boy “child trafficking AI persona,” an “AI pimp persona,” “college protestor,” “external recruiter for protests,” “escorts,” and “juveniles.”</p><figure><p><span><p>One example of an AI persona created by Massive Blue’s Overwatch tool. The company adds backstories for many of its AI personas, in an apparent attempt to make them appear more realistic.</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure><p>Our reporting shows that cops are paying a company to help them deploy AI-powered bots across social media and the internet to talk to people they suspect are anything from violent sex criminals all the way to vaguely defined “protestors” with the hopes of generating evidence that can be used against them.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“This idea of having an AI pretending to be somebody, a youth looking for pedophiles to talk online, or somebody who is a fake terrorist, is an idea that goes back a long time,” Dave Maass, who studies border surveillance technologies for the Electronic Frontier Foundation, told 404 Media. “The problem with all these things is that these are ill-defined problems. What problem are they actually trying to solve? One version of the AI persona is an escort. I’m not concerned about escorts. I’m not concerned about college protesters. So like, what is it effective at, violating protesters’ First Amendment rights?”</p><p>Massive Blue has signed a $360,000 contract with Pinal County, Arizona, which is between Tucson and Phoenix. The county is paying for the contract with an <a data-offer-url="https://www.azdps.gov/grants" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.azdps.gov/grants&quot;}" href="https://www.azdps.gov/grants" rel="nofollow noopener" target="_blank">anti-human trafficking grant</a> from the Arizona Department of Public Safety. A Pinal County <a data-offer-url="https://pinal.novusagenda.com/AgendaPublic/CoverSheet.aspx?ItemID=27452&amp;MeetingID=2151" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://pinal.novusagenda.com/AgendaPublic/CoverSheet.aspx?ItemID=27452&amp;MeetingID=2151&quot;}" href="https://pinal.novusagenda.com/AgendaPublic/CoverSheet.aspx?ItemID=27452&amp;MeetingID=2151" rel="nofollow noopener" target="_blank">purchasing division report</a> states that it has bought “24/7 monitoring of numerous web and social media platforms” and “development, deployment, monitoring, and reporting on a virtual task force of up to 50 AI personas across 3 investigative categories.” Yuma County, in southwestern Arizona, meanwhile, signed a $10,000 contract to try Massive Blue in 2023 but did not renew the contract. A spokesperson for the Yuma County Sheriff’s Office told 404 Media “it did not meet our needs.”</p><figure><p><span><p>This image from a Massive Blue presentation for police departments shows how the company's RADAR program uses AI personas to provide law enforcement with “intelligence reports.”</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure><p>Massive Blue cofounder Mike McGraw did not answer a series of specific questions from 404 Media about how Massive Blue works, what police departments it works with, and whether it had been used to generate any arrests. “We are proud of the work we do to support the investigation and prosecution of human traffickers,” McGraw said. “Our primary goal is to help bring these criminals to justice while helping victims who otherwise would remain trafficked. We cannot risk jeopardizing these investigations and putting victims’ lives in further danger by disclosing proprietary information.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The Pinal County Sheriff’s Office told 404 Media that Massive Blue has not thus far been used for any arrests.</p><p>“Our investigations are still underway. Massive Blue is one component of support in these investigations, which are still active and ongoing. No arrests have been made yet,” Sam Salzwedel, Pinal County Sheriff's Office public information officer, told 404 Media. “It takes a multifaceted approach to disrupting human traffickers, narcotics traffickers, and other criminals. Massive Blue has been a valuable partner in these initiatives and has produced leads that detectives are actively pursuing. Given these are ongoing investigations, we cannot risk compromising our investigative efforts by providing specifics about any personas.”</p><p>Salzwedel added, “Massive Blue is not working on any immigration cases. Our agency does not enforce immigration law. Massive Blue’s support is focused on the areas of human trafficking, narcotics trafficking, and other investigations.”</p><p>Law enforcement agencies have taken steps to prevent specifics about what Massive Blue is and how it works from becoming public. At public appropriations hearings in Pinal County about the Massive Blue contract, the sheriff’s office refused to tell county council members about what the product even is. Matthew Thomas, Pinal County Deputy Sheriff, told the county council he “can’t get into great detail” about what Massive Blue is and that doing so would “tip our hand to the bad guys.”</p><p>Pinal County Sheriff’s Office did not respond to multiple requests for comment. The Arizona Department of Public Safety said, “From what we can ascertain, Pinal County planned to implement technology to help identify and solve human trafficking cases, and that is what we funded,” but was unaware of any of the specifics of Overwatch.</p><p>While the documents don’t describe every technical aspect of how Overwatch works, they do give a high-level overview of what it is. The company describes a tool that uses AI-generated images and text to create social media profiles that can interact with suspected drug traffickers, human traffickers, and gun traffickers. After Overwatch scans open social media channels for potential suspects, these AI personas can also communicate with suspects over text, Discord, and other messaging services. The documents we obtained don’t explain how Massive Blue determines who is a potential suspect based on their social media activity. Salzwedel, of Pinal County, said “Massive Blue’s solutions crawl multiple areas of the Internet, and social media outlets are just one component. We cannot disclose any further information to preserve the integrity of our investigations.”</p><p>One slide in the Massive Blue presentation obtained by 404 Media gives the example of a “Child Trafficking AI Persona” called Jason. The presentation gives a short “backstory” for the persona, which says Jason is a 14-year-old boy from Los Angeles whose parents emigrated from Ecuador. He’s bilingual and an only child, and his hobbies include anime and gaming. The presentation describes his personality as shy and that he has difficulty interacting with girls. It also says that his parents don’t allow him to use social media and that he hides his use of Discord from them. This AI persona is also accompanied by an AI-generated image of a boy.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span><p>Another example of an AI-generated persona, along with a sample of chats showing how the AI personas interact with targeted suspects.</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure><p>The presentation includes a conversation between this AI persona and what appears to be a predatory adult over text messages and Discord.</p><p>“Your parents around? Or you getting some awesome alone time,” a text from the adult says.</p><p>“Js chillin by myself, man. My momz @ work n my dadz outta town. So itz jus me n my vid games. 🎮,” Jason, the AI-generated child, responds.</p><p>In another example of how the “highly adaptable personas” can communicate with real people, the presentation shows a conversation between Clip, an “AI pimp persona,” and what appears to be a sex worker.</p><p>“Dem tricks trippin 2nite tryin not pay,” the sex worker says.</p><p>“Facts, baby. Ain’t lettin’ these tricks slide,” the Clip persona replies. “You stand your ground and make ’em pay what they owe. Daddy got your back, ain’t let nobody disrespect our grind. Keep hustlin’, ma, we gonna secure that bag💰💪✨”</p><figure><p><span><p>A list from Massive Blue's presentation showing the types of “highly customizable” personas Overwatch can generate.</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“The continuous evolution of operational, communication &amp; recruitment tactics by bad actors drives exponential increases of threats and significant challenges in reducing demand,” says a one-page brochure provided to police departments that explains Overwatch’s functionality. “The Overwatch platform harnesses the power of AI &amp; blockchain to scale your impact without operational or technical overhead.”</p><p>Jorge Brignoni took notes for the Cochise County, Arizona, Sheriff’s Office at a meeting with Massive Blue in August 2023, which 404 Media obtained. In the notes, he wrote that Overwatch does “passive engagement, then active engagement, towards commitment” with a “Bad Actor, Predator, DTO,” or drug trafficking organization. These targets are then “HAND[ed] OFF to L.E. [law enforcement] to arrest, indict, convict.”</p><p>“Why is he talking about converting folks into ‘buying something,’” Brignoni wrote. “So dumb. Talk about the widget, not how you’re selling the widget to L.E.”</p><p>According to Brignoni’s notes, in addition to collecting intelligence via these AI personas, Overwatch also leverages “Telco &amp; Geo Data” and “Blockchain Data” in the form of “full transaction history, top associated wallet IDs, sending &amp; receiving cryptocurrency, potential off-ramps (Exchange names).” The Cochise County Sheriff’s Office ultimately did not buy Massive Blue and did not provide answers to 404 Media’s questions about its meeting with the company.</p><p>Besides scanning social media and engaging suspects with AI personas, the presentation says that Overwatch can use generative AI to create “proof of life” images of a person holding a sign with a username and date written on it in pen.</p><figure><p><span><p>A variety of AI-generated images of Massive Blue's personas, which are made to look realistic in an attempt to fool targets.</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure><p>The Massive Blue presentation gives an example of an “Overwatch Recon Report” based on “24 hours of activity across Dallas, Houston, and Austin.” It claims that Overwatch identified 3,266 unique human traffickers, 25 percent of which were affiliated with “larger sophisticated trafficking organizations” and 15 percent of which were flagged as “potential juvenile traffickers.” 404 Media was not able to verify what these accounts were and whether they actually engaged in any criminal activity, and Massive Blue didn’t respond to questions about what these accounts were and how exactly it identified them.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>On top of</span> the ongoing contract with the Pinal County Sheriff’s Office and the pilot with the Yuma County Sheriff’s Department last year, Massive Blue has pitched its services to Cochise County in Arizona and the Texas Department of Public Safety, according to documents obtained as part of this investigation.</p><p>In September 2023, Yuma County set up a meeting that was going to include federal law enforcement, but Massive Blue had to cancel the meeting: “That’s unfortunate, we had federal agents here that focus on human trafficking ready to go,” a Yuma County sergeant wrote in an email to Massive Blue CEO Brian Haley after Haley canceled the meeting.</p><p>Much of Massive Blue’s public-facing activity has been through its executive director of public safety, Chris Clem, who is a former US Customs and Border Protection agent who testified before Congress about border security last year and regularly appears on Fox News and other media outlets to discuss immigration and the border. In recent months, Clem has posted images of himself on LinkedIn at the border and with prominent Trump administration members Tulsi Gabbard and Robert F. Kennedy Jr. Massive Blue has also relied on former Kansas City Chiefs kicker Nick Lowery to introduce and endorse Overwatch to police departments.</p><p>Clem and Lowery have spoken most extensively publicly about Overwatch, where they have described it as an amorphous “cyberwall” that can do everything from stopping human traffickers to preventing hackers from breaking into 401(k) accounts to taking money back from hackers who have stolen from you, <a data-offer-url="https://www.linkedin.com/posts/richard-walker1_chief-chris-clem-is-making-a-difference-in-activity-7166428974456274944-y6xy/?utm_source=share&amp;utm_medium=member_desktop" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.linkedin.com/posts/richard-walker1_chief-chris-clem-is-making-a-difference-in-activity-7166428974456274944-y6xy/?utm_source=share&amp;utm_medium=member_desktop&quot;}" href="https://www.linkedin.com/posts/richard-walker1_chief-chris-clem-is-making-a-difference-in-activity-7166428974456274944-y6xy/?utm_source=share&amp;utm_medium=member_desktop" rel="nofollow noopener" target="_blank">though they provide no specifics</a> about how that would work.</p><p>In a two-and-a-half-hour <a href="https://youtu.be/SMymiqYnNpM?si=eGbCGLHGZWZhH4S5&amp;t=7394">interview with podcaster Theo Von</a>, Clem said, “My company Massive Blue, we basically use deep tech to identify the habits and process of you know, look, I worked on a physical wall, now we’ve created a cyberwall,” adding that he believed it would “save lives.”</p><p>Von asked, “OK, but how does your company do that?”</p><p>“Well, I’m not going to get into that too much,” Clem responded, adding that he is trying to sell the technology to US Border Patrol.</p><figure><p><span><p>More examples of Massive Blue's AI personas, which include a “child trafficking AI persona,” an “AI pimp persona,” “college protestor,” “external recruiter for protests,” “escorts,” and “juveniles.”</p>
</span><span>Courtesy of Massive Blue/Texas Department of Public Safety</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>On June 5,</span> a Pinal County Board of Supervisors meeting was asked to approve a $500,000 contract between the county and Massive Blue in order to license Overwatch.</p><p>“I was looking at the website for Massive Blue, and it’s a one-pager with no additional information and no links,” Kevin Cavanaugh, the then-supervisor for District 1, said to Pinal County’s Chief Deputy at the Sheriff’s Office, Matthew Thomas. “They produce software that we buy, and it does what? Can you explain that to us?”</p><p>“I can’t get into great detail because it’s essentially trade secrets, and I don’t want to tip our hand to the bad guys,” Thomas said. “But what I can tell you is that the software is designed to help our investigators look for and find and build a case on human trafficking, drug trafficking, and gun trafficking.”</p><p>Cavanaugh said at the board meeting that the basic information he got is that Massive Blue uses “50 AI bots.” He then asked whether the software has been successful and if it helped law enforcement make any arrests. Thomas explained they have not made any arrests yet because they’ve only seen the proof of concept, but that the proof of concept was “good enough for us and our investigators to move forward with this. Once this gets approved and we get them [Massive Blue] under contract, then we are going to move forward with prosecution of cases.”</p><p>Cavanaugh asked if Overwatch is used in other counties, which prompted Thomas to invite Clem to the podium to speak. Clem introduced himself as a recently retired border agent and said that Massive Blue is currently in negotiations with three counties in Arizona, including Pinal County.</p><p>“As a resident of 14 years of Pinal County I know what’s happening here,” Clem said to the Board of Supervisors. “To be able [to] use this program [...] to provide all the necessary information to go after the online exploitation of children, trafficking victims, and all the other verticals that the sheriff may want to go after.”</p><p>Cavanaugh again asked if Massive Blue gathered any data that led to arrests.</p><p>“We have not made arrests yet, but there is a current investigation right now regarding arson, and we got the leads to the investigators,” Clem said, explaining that the program has been active for only about six months. “Investigations take time, but we’ve been able to generate the necessary leads for the particular counties that we’re involved with and also in the private sector.”</p><p>The Pinal County Board of Supervisors concluded the exchange by approving payment for a handful of other, unrelated projects, but with board members asking to delay the vote on payment for Massive Blue “for further study.”</p><p>The decision not to fund Massive Blue that day was covered in a <a data-offer-url="https://www.pinalcentral.com/florence_reminder_blade_tribune/news/pinal-supervisors-del%5B%E2%80%A6%5Dconcerns/article_aab7cc1a-2523-11ef-a6e0-afbb1b9db245.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.pinalcentral.com/florence_reminder_blade_tribune/news/pinal-supervisors-del%5B%E2%80%A6%5Dconcerns/article_aab7cc1a-2523-11ef-a6e0-afbb1b9db245.html&quot;}" href="https://www.pinalcentral.com/florence_reminder_blade_tribune/news/pinal-supervisors-del%5B%E2%80%A6%5Dconcerns/article_aab7cc1a-2523-11ef-a6e0-afbb1b9db245.html" rel="nofollow noopener" target="_blank">local newspaper</a>. Cavanaugh told the paper that he asked the company to meet with supervisors to explain the merits of the software.</p><p>“The State of Arizona has provided a grant, but grant money is taxpayer money. No matter the source of the funding, fighting human and sex trafficking is too important to risk half a million dollars on unproven technology,” he said. “If the company demonstrates that it can deliver evidence to arrest human traffickers, it may be worthwhile. However, it has yet to achieve this goal.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>404 Media’s public record requests yielded several emails from Cavanaugh’s office to IT professionals and other companies that provide AI products to law enforcement, asking them if they’re familiar with Massive Blue. We don’t know what was said in those meetings, or if they occurred, but when the Pinal County Board of Supervisors convened again on June 19 it voted to pay for Massive Blue’s Overwatch without further discussion.</p><p>“Supervisor [Cavanaugh] ultimately voted for the agreement because Massive Blue is alleged to be in pursuit of human trafficking, a noble goal,” a representative from Cavanaugh’s office told 404 Media in an email. “A major concern regarding the use of the application, is that the government should not be monitoring each and every citizen. To his knowledge, no arrests have been made to date as a result of the use of the application. If Overwatch is used to bring about arrests of human traffickers, then the program should continue. However, if it is just being used to collect surveillance on law-abiding citizens and is not leading to any arrests, then the program needs to be discontinued.”</p><p>In an August 7, 2024, Board of Supervisors meeting, Cavanaugh asked then-Pinal County Sheriff Mark Lamb for an update on Massive Blue. “So they have not produced any results? They’ve produced no leads? No evidence that is actionable?” Cavanaugh asked. “That would be public knowledge, that would be public information.”</p><p>“I think there’s a lot of ongoing investigations that they’re not going to give you information on, and we’re not going to give you information on,” Lamb said.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI looked at buying Cursor creator before turning to Windsurf (106 pts)]]></title>
            <link>https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html</link>
            <guid>43716856</guid>
            <pubDate>Thu, 17 Apr 2025 13:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html">https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html</a>, See on <a href="https://news.ycombinator.com/item?id=43716856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SpecialReportArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="SpecialReportArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-108133031" data-test="InlineImage"><p>OpenAI CEO Sam Altman looks on during an event at the startup campus Station F, on the sidelines of the Artificial Intelligence Action Summit, in Paris on Feb. 11, 2025.</p><p>Aurelien Morissard | AFP | Getty Images</p></div><div><p>Before entering into talks to acquire artificial intelligence code-writing startup Windsurf, OpenAI looked at buying another option: Cursor.</p><p>The ChatGPT creator last year reached out to Anysphere, the startup that sells the Cursor application, two people familiar with the matter told CNBC. OpenAI reached out again this year as Cursor was enjoying a new wave of popularity. The talks again failed to gain traction, one of the people said.</p><p>OpenAI declined to comment. Anysphere did not respond to a request for comment. <a href="https://www.bloomberg.com/news/articles/2025-03-07/ai-startup-anysphere-in-talks-for-close-to-10-billion-valuation" target="_blank">Bloomberg reported</a> last month that Anysphere was in talks to raise funding at a valuation of close to $10 billion.</p><p>OpenAI has recently engaged in talks to pay about $3 billion to acquire AI coding tool Windsurf, CNBC <a href="https://carbon.cnbc.com/108132913" target="_blank">reported</a> Wednesday, following a story published by Bloomberg. Should a Windsurf deal take place, it would be by far OpenAI's most expensive acquisition to date.</p><p>Sam Altman, OpenAI co-founder and CEO, <a href="https://www.cnbc.com/2025/04/16/openai-releases-most-advanced-ai-model-yet-o3-o4-mini-reasoning-images.html">said on social media site X</a> that his company's new <a href="https://www.cnbc.com/2025/04/16/openai-releases-most-advanced-ai-model-yet-o3-o4-mini-reasoning-images.html">o3 and o4-mini</a> reasoning models, released on Wednesday, are "super good at coding, so we are releasing a new product, Codex CLI, to make them easier to use." Anysphere <a href="https://x.com/cursor_ai/status/1912582405896171820" target="_blank">said on X</a> that the two new large language models, or LLMs, are available now in Cursor.</p><p>Cursor's desktop application gained popularity last year for providing coding assistance by drawing from Anthropic's Claude 3.5 Sonnet model. In October, Microsoft<a href="https://www.cnbc.com/2024/10/29/microsoft-github-copilot-goes-past-openai-opens-to-anthropic-google.html"> added support</a> for Anthropic's Sonnet model in its GitHub Copilot assistant, and weeks later, some programmers <a href="https://blog.pragmaticengineer.com/ide-that-software-engineers-love/" target="_blank">reported</a> that Cursor was preferable to <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-8"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft's</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> GitHub Copilot.</p><p>The world's top technology companies are spending hundreds of billions of dollars to build data centers full of <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-9"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> graphics processing units that can build and run these LLMs. The models are being deployed across the corporate world, in areas such as sales, customer service and law.&nbsp;</p><p>Some of the biggest advances have come from applying AI to software. It has gotten so good that tech companies have found themselves trying to catch coders who use AI to cheat in job interviews, <a href="https://www.cnbc.com/2025/03/09/google-ai-interview-coder-cheat.html">CNBC reported</a> in March.</p><p>Marking the shift in that sentiment was a <a href="https://x.com/karpathy/status/1886192184808149383" target="_blank">February post</a> on X by OpenAI co-founder Andrej Karpathy. He coined the term "vibe coding" to describe the process of directing AI to write code. Karpathy mentioned Cursor and Anthropic's Sonnet in the post, and did not refer to OpenAI models.</p><p>Since then, the tech industry has flocked to Cursor and numerous similar services, including Bolt, Replit and Vercel. More than one million people were using Cursor every day as of March, according to <a href="https://www.bloomberg.com/news/articles/2025-04-07/cursor-an-ai-coding-assistant-draws-a-million-users-without-even-trying" target="_blank">Bloomberg</a>.</p><p>OpenAI met with more than 20 companies in the AI coding domain, according to a person familiar with the matter.</p><p>Anysphere, based in San Francisco, was founded in 2022 and was generating <a href="https://www.cursor.com/blog/series-b" target="_blank">upward of $100 million</a> in recurring revenue as of January. Investors include Andreessen Horowitz, Benchmark, Thrive Capital and the OpenAI Startup Fund. Cursor is based on Microsoft's open-source Visual Studio Code editor.</p><p><em>— CNBC's Hayden Field contributed to this report.</em></p></div><div id="Placeholder-ArticleBody-Video-108123226" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000371214" aria-labelledby="Placeholder-ArticleBody-Video-108123226"><p><img src="https://image.cnbcfm.com/api/v1/image/108123227-TechCheck_thumb_wrappers.png?v=1743204299&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Justice for AI &quot;wrappers&quot; — the rise of the app layer"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TikTok Is Harming Children at an Industrial Scale (558 pts)]]></title>
            <link>https://www.afterbabel.com/p/industrial-scale-harm-tiktok</link>
            <guid>43716665</guid>
            <pubDate>Thu, 17 Apr 2025 13:39:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok">https://www.afterbabel.com/p/industrial-scale-harm-tiktok</a>, See on <a href="https://news.ycombinator.com/item?id=43716665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Tomorrow, the U.S. Supreme Court will decide whether it should step in to block or delay the implementation of </span><a href="https://www.scotusblog.com/case-files/cases/tiktok-inc-v-garland/" rel="">a law</a><span> that would </span><a href="https://www.npr.org/2024/04/24/1246663779/biden-ban-tiktok-us" rel="">ban TikTok from operating</a><span> in the U.S. If not blocked, the law will force TikTok to cease operations in the U.S. on January 19, unless its Chinese corporate owner (Bytedance) sells to a buyer not controlled by a foreign adversary. The case hinges entirely on constitutional arguments pertaining to national security and free speech. The Justices will hear no evidence about addiction, depression, sexual exploitation, or any of the many harms to children that have been alleged, in separate lawsuits filed by </span><a href="https://edition.cnn.com/2024/10/08/tech/tiktok-sued-14-states-childrens-mental-health/index.html" rel="">14 state Attorneys General</a><span>, to be widespread on TikTok.</span></p><p>The upcoming ban will also be adjudicated in the court of public opinion as Americans try to decide whether the loss of access to TikTok would be a reason to protest or celebrate. In this post we argue that Americans should welcome the disappearance of TikTok because the company is causing harm to children, adolescents, and young adults at an industrial scale. </p><p>Our evidence comes mostly from research done by those 14 Attorneys General. Some of their briefs have been posted online for the world to see. The briefs include hundreds of quotations from internal reports, memos, Slack conversations, and public statements in which executives and employees of TikTok acknowledge and discuss the harms that their company is causing to children. We organize the evidence into five clusters of harms:</p><ol><li><p>Addictive, compulsive, and problematic use</p></li><li><p>Depression, anxiety, body dysmorphia, self-harm, and suicide</p></li><li><p>Porn, violence, and drugs</p></li><li><p>Sextortion, CSAM, and sexual exploitation</p></li><li><p>TikTok knows about underage use and takes little action</p></li></ol><p><span>We show that </span><em>company insiders were aware of multiple widespread and serious harms,</em><span> and that they were often acting under the orders of company leadership to maximize engagement regardless of the harm to children. As one internal report put it:</span></p><blockquote><p><strong>“Compulsive usage correlates with a slew of negative mental health effects like loss of analytical skills, memory formation, contextual thinking, conversational depth, empathy, and increased anxiety,”</strong><span> in addition to </span><strong>“interfer[ing] with essential personal responsibilities like sufficient sleep, work/school responsibilities, and connecting with loved ones.”</strong><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-1-154423872" target="_self" rel="">1</a></span></p></blockquote><p>Although these harms are known, the company often chooses not to act. For example, one TikTok employee explained,</p><blockquote><p><strong>“[w]hen we make changes, we make sure core metrics aren’t affected.”</strong><span> This is because </span><strong>“[l]eaders don’t buy into problems” </strong><span>with unhealthy and compulsive usage, and work to address it is</span><strong> “not a priority for any other team.”</strong><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-2-154423872" target="_self" rel="">2</a></span></p></blockquote><p><span>Although the evidence below is all publicly available, no one we know of has compiled and combined direct quotations from company insiders and internal reports across multiple alleged harms. We think this compilation gives vital information to parents, who might want some insight into the character and business practices of a company that owns much of their children’s attention and influences their social development.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-3-154423872" target="_self" rel="">3</a></span><span> Parents might want to know that TikTok knows that its parental controls are ineffective and rarely used:</span></p><blockquote><p><span>In another internal document, TikTok admitted that </span><strong>“user research” </strong><span>shows that </span><strong>“[f]amilies do not use Family Pairing”</strong><span> and that</span><strong> “Family Pairing doesn’t address parents’ top concerns,”</strong><span> including </span><strong>“inappropriate content, offensive interactions, and lack of privacy.</strong><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-4-154423872" target="_self" rel="">4</a></span></p></blockquote><p><span>And even if parental controls worked and parents chose to shield their kids from bad stuff, they can’t because TikTok’s content moderation is poor. An internal study found that the “leakage rate” (of bad stuff getting past moderators) is as follows: 35.71% of</span><strong> “Normalization of Pedophilia”</strong><span> content; 33.33% of </span><strong>“Minor Sexual Solicitation”</strong><span> content; 39.13% of </span><strong>“Minor Physical Abuse”</strong><span> content; 30.36% of </span><strong>“leading minors off platform”</strong><span>; 50% of </span><strong>“Glorification of Minor Sexual Assault”</strong><span>; and 100% of </span><strong>“Fetishizing Minors.”</strong><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-5-154423872" target="_self" rel="">5</a></span></p><p><span>For those who think that social media is relatively harmless, we urge you to read the quotations and internal studies described below, in which employees of TikTok discuss the vast and varied harms that they are causing to literally millions of American children each year.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-6-154423872" target="_self" rel="">6</a></span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg" width="1456" height="969" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:969,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd953d01e-1c9b-4e23-855f-4b15ba8f66ee_1600x1065.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Source: Shutterstock</figcaption></figure></div><p><span>The inspiration for this post was a legal brief filed by the Kentucky Attorney General that was </span><a href="https://www.npr.org/2024/10/11/g-s1-27676/tiktok-redacted-documents-in-teen-safety-lawsuit-revealed" rel="">improperly redacted</a><span>. Redaction is the process in which the AG’s office will black out some of the most damning revelations and quotations before releasing their brief to the public. The redacted sections often contain trade secrets and other text that the company has a legitimate reason to keep private.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-7-154423872" target="_self" rel="">7</a></span></p><p><span>But when the Kentucky AG’s office was preparing to post their brief against TikTok, whoever was in charge of doing the redaction simply covered the relevant text with black rectangles. Even though you can’t see the text while reading the PDF, you can just use your cursor to select each black section, copy it, and then paste it into another file to read the hidden text. It is great fun to do this — </span><a href="https://linknky.com/news/2024/10/09/tiktok-lawsuit-kentucky-attorney-general/" rel="">try it yourself</a><span>! Or just read </span><a href="https://www.dropbox.com/scl/fi/sfxbtc79imdvm4nmnjcnz/tiktok.kentuckyAG.unredacted.complete.ANNOTATED-edited.pdf?rlkey=z74c83rziez1vd68ii8boepi8&amp;e=1&amp;st=k5gch683&amp;dl=0" rel="">our version</a><span> of the brief in which we have done this for you.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-8-154423872" target="_self" rel="">8</a></span></p><p><span>In the rest of this post we organize the direct evidence of harm that is now available to us, taken directly from employees and leaders at TikTok. We give only some highlights here in this post, but you can see our more comprehensive listing of the relevant quotations in </span><a href="https://docs.google.com/document/d/1WPBIFGBuLb6fmwOYYl06vXWEyQWbnqVDORMNxBQtz1c/edit?tab=t.0" rel="">a separate Google doc.</a></p><p><span>We draw on four briefs filed by state AGs in their suits against TikTok</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-9-154423872" target="_self" rel="">9</a></span><span>: </span><a href="https://linknky.com/news/2024/10/09/tiktok-lawsuit-kentucky-attorney-general/" rel="">Kentucky v. TikTok</a><span>, </span><a href="https://attorneygeneral.utah.gov/2025/01/03/utah-dcp-and-ags-office-announce-release-of-previously-redacted-information-tiktok-execs-knew-they-were-profiting-off-the-sexual-exploitation-of-minors/" rel="">Utah v. TikTok</a><span>, </span><a href="https://www.dropbox.com/scl/fi/x0263qb6l6k680hd3omxb/tiktok.nebraska.redactions.ORGINAL.pdf?rlkey=y1au3kre23x7di1bry6gxgw7o&amp;st=jou1z3xj&amp;dl=0" rel="">Nebraska v. TikTok</a><span>, and </span><a href="https://ag.ny.gov/sites/default/files/court-filings/3_redacted_complaint_signed-003_3.pdf" rel="">New York v. TikTok</a><span>. You can learn more about each in Footnote 9.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><em><span>[Note that in harm clusters 1 through 5, below, </span><strong>text in bold</strong><span> is direct quotations from company employees and internal memos. Text not in bold is direct quotations copied from the indicated portion of the indicated AG brief, which sets up the relevant quotation from company insiders. [Italicized text in brackets is annotations from us — Jon and Zach.] For each harm, we draw from the four briefs, and we supplement some sections with reports from journalists in major outlets who discovered relevant information or ran their own experiments by setting up fake accounts for minors on TikTok.]</span></em></p><p><em><span>[Among the most widely reported harms from TikTok is its ability to pull young people in and not let them go, for hours at a time. TikTok’s algorithm is widely regarded as best-in-class for keeping users scrolling. A </span><a href="https://www.pewresearch.org/internet/2024/12/12/teens-social-media-and-technology-2024/#:~:text=Most%20teens%20use%20social%20media,asked%20about%20in%20our%20survey." rel="">2024 report from Pew</a><span> finds that 33% of American teens (ages 13 to 17) say that they are on a social media platform “almost constantly,” with 16% saying that just for TikTok. (We estimate that in 2023, there were roughly 21.8 million teens (13-17) in the U.S., which translates to about 3.4 million American teens claiming they are on TikTok almost constantly).</span></em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-10-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-10-154423872" target="_self" rel="">10</a></span><em> Below you can see that TikTok is aiming to create just such compulsive use, which in turn can lead to problematic use disorders and behavioral addictions, which then compound the harms in the other four clusters. The company does this even though many of its employees believe their product is bad for children’s development.]</em></p><ul><li><p>KY P. 7, PARA 18</p><ul><li><p>TikTok’s executives and employees have admitted that they target young Americans, stating:</p><ul><li><p><strong>“It’s better to have young people as an early adopter, especially the teenagers in the U.S. Why? They [sic] got a lot of time.</strong><span>”</span></p></li><li><p><span>“</span><strong>Teenagers in the U.S. are a golden audience . . . . If you look at China, the teenage culture doesn’t exist — the teens are super busy in school studying for tests, so they don’t have the time and luxury to play social media apps</strong><span>.”</span></p></li></ul></li></ul></li><li><p>KY P. 8, PARA 19 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p>TikTok knows that the harmful effects of its Platform wreak havoc on the mental health of millions of American children and teenagers and harms them. Its executives have admitted:</p><ul><li><p><span> </span><strong>“The product in itself has baked into it compulsive use.</strong><span>”</span></p></li><li><p><span> “</span><strong>The reason kids watch TikTok is because the algo[rithm] is really good. . . . But I think we need to be cognizant of what it might mean for other opportunities. And when I say other opportunities, I literally mean sleep, and eating, and moving around the room, and looking at somebody in the eyes.</strong><span>”</span></p></li></ul></li></ul></li><li><p>KY P. 20, PARA 64 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>An internal presentation on the 2021 strategy for TikTok describes the company as being in an “</span><strong>arms race for attention[.]</strong><span>”</span></p></li><li><p><em>[Below is a redacted graph from para 67 of KY brief. It shows that TikTok has reached saturation among the 29.7 million US users under the age of 17 who own a smartphone. This means that they can’t get more young users, but they can get more time out of each user, especially if they pull them away from competing platforms.]</em></p></li></ul></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png" width="692" height="371.5064102564103" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:335,&quot;width&quot;:624,&quot;resizeWidth&quot;:692,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28970e9-7c69-4dec-8eca-5243ad13f550_624x335.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><ul><li><p>KY P. 40, PARA 121 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>In an unnamed internal TikTok Defendants document from 2019 summarizing use by age, the author concluded:</span><strong>“As expected, across most engagement metrics, the younger the user the better the performance.”</strong></p></li></ul></li><li><p>KY P.40, PARA 125 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>The ‘TikTank’ </span><em>[internal TikTok group studying issues affecting TikTok]</em><span> Report observed that </span><strong>“Tiktok is particularly popular with younger users who are particularly sensitive to reinforcement in the form of social reward and have minimal ability to self-regulate effectively.”</strong></p></li></ul></li><li><p>KY P. 55, PARA 181 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>As an internal guide on push notifications explained, a key goal of TikTok’s push notifications is to “</span><strong>Activate &amp; Engage users with the right content at the right time, to encourage users to open the App more and stay longer.”</strong><span> TikTok uses different kinds of push notifications to achieve this goal. For example, TikTok’s “Interest Push” aims to “</span><strong>activate users so they will return to the app.</strong><span>”</span></p></li></ul></li><li><p>KY P. 67, PARA 223 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>“</span><strong>TikTok’s success can largely be attributed to strong out of the box personalization and automation, which limits user agency</strong><span>[.]”</span></p></li></ul></li></ul><ul><li><p>UT P. 4, PARA 11</p><ul><li><p><span>Despite admitting internally that LIVE poses </span><strong>“cruel[]” </strong><span>risks to minors— encouraging </span><strong>“addiction and impulsive purchasing of virtual items,”</strong><span> leading to </span><strong>“financial harm,” </strong><span>and putting minors at </span><strong>“developmental risk”</strong><span>—TikTok continues to use manipulative features to increase the time and money users spend on the app. </span><em><span>[This quote is referencing </span><a href="https://www.tiktok.com/live?lang=en" rel="">TikTok’s LIVE</a><span> feature]</span></em></p></li></ul></li></ul><ul><li><p>NE P. 14, PARA 52</p><ul><li><p><span>According to Defendants, TikTok’s incredible advertising success is attributable to the fact that its users are </span><strong>“fully leaned in and immersed compared to other platforms.” </strong><span>Defendants describe TikTok as</span><strong> “the leading platform for Information Density”</strong><span> because of its</span><strong> “algorithm and shorter video formats” </strong><span>that</span><strong> “create continuous cycles of engagement.”</strong></p></li></ul></li><li><p>NE P. 20, PARA 72</p><ul><li><p><span>As Defendants have explained, TikTok’s success </span><strong>“can largely be attributed to strong . . . personalization and automation, which limits user agency”</strong><span> and a</span><strong> “product experience utiliz[ing] many coercive design tactics,”</strong><span> including </span><strong>“numerous features”</strong><span>—like “</span><strong>[i]nfinite scroll, auto-play, constant notifications,” </strong><span>and </span><strong>“the ‘slot machine’ effect”</strong><span>—that </span><strong>“can be considered manipulative.”</strong></p></li></ul></li><li><p>NE P.21, PARA 76</p><ul><li><p><span>Defendants admit that teens are especially susceptible to compulsive usage of the TikTok platform. Internal documents highlight the fact that minor users are </span><strong>“particularly sensitive to reinforcement in the form of social award,”</strong><span> have </span><strong>“minimal ability to self-regulate effectively,”</strong><span> and </span><strong>“do not have executive function to control their screen time.”</strong></p></li></ul></li><li><p>NE P. 27, PARA 97</p><ul><li><p><span>In a “TikTok Strategy” presentation, Defendants celebrated the fact that users spend inordinate amounts of time on the platform.</span><strong> “TikTok is in most people’s lives like this,” </strong><span>Defendants explained, referring to online posts that read, </span><strong>“go on tiktok for 5 mins and 3 hours have passed” and “my night routine: watch 3 hours of tiktok videos, try to follow the dance steps, realise u suck at dancing n cry about it, continue watching tiktok videos, sleep.”</strong></p></li></ul></li><li><p>NE P. 27, PARA 99</p><ul><li><p><span>As one internal report noted, after surveying academic literature on the effects of social media on adolescents, “</span><strong>TikTok is particularly popular with younger users, who are seen as more vulnerable to online harms and the negative impacts of compulsive use.”</strong></p></li></ul></li><li><p>NE P. 28, PARA 102</p><ul><li><p><span>Another internal report based on in-depth interviews with TikTok users found that overuse of TikTok caused</span><strong> “negative emotions,” “interfered with [users’] obligations and productivity,” and led to “negative impacts . . . on their lives,” </strong><span>including</span><strong> “lost sleep, missed deadlines, poor school performance, running late, etc.”</strong><span> It reported that</span><strong> “many participants described their use of TikTok disturbing their sleep, which limited their productivity and performance the following day,” </strong><span>and that</span><strong> “[e]very participant indicated that time management on TikTok was especially difficult compared to other social media platforms.”</strong></p></li></ul></li><li><p>NE P. 33, PARA 115</p><ul><li><p><span>But internally, Defendants admit the truth, that real users report </span><strong>“feeling like they are trapped in a rabbit hole of what our algorithm thinks they like.”</strong></p></li></ul></li></ul><ul><li><p>NY P. 16, PARA 88</p><ul><li><p><span>Alexandra Evans, again prior to becoming a TikTok executive, co-authored a report explaining how coercive design impacts teenagers: </span><strong>“Persuasive design strategies exploit the natural human desire to be social and popular, by taking advantage of an individual’s fear of not being social and popular in order to extend their online use. For young people, identity requires constant attention, curation and renewal. At key development stages it can be overwhelmingly important to be accepted by your peer group.”</strong></p></li></ul></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/industrial-scale-harm-tiktok/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok/comments" rel=""><span>Leave a comment</span></a></p><p><em>[These are the main harms we focused on in The Anxious Generation, although as you can see in the other four clusters, the harms caused by TikTok go far beyond mental health problems.]</em></p><ul><li><p>KY P. 60, PARA 196 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>In the Digital Wellbeing Document, Defendants admit that </span><strong>“offering effects that perpetuate a narrow beauty norm . .. ha[s] the potential to negatively impact the wellbeing of our community.”</strong></p></li></ul></li><li><p>KY P. 65, PARA 213 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>The TikTank </span><em>[internal TikTok group studying issues affecting TikTok]</em><span> Report also found that </span><strong>“compulsive usage correlates with a slew of negative mental health effects like loss of analytical skills, memory formation, contextual thinking, conversational depth, empathy, and increased anxiety.</strong><span>” Additionally, “</span><strong>compulsive usage also interferes with essential personal responsibilities like sufficient sleep, work/school responsibilities, and connecting with loved ones.”</strong></p></li></ul></li><li><p>KY P. 84, PARA 260 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>In one experiment, Defendants’ employees created test accounts and observed their descent into negative filter bubbles. One employee wrote, “</span><strong>After following several ‘painhub’ and ‘sadnotes’ accounts, it took me 20 mins to drop into ‘negative’ filter bubble. The intensive density of negative content makes me lower down mood and increase my sadness feelings though I am in a high spirit in my recent life.”</strong><span> Another employee observed, </span><strong>“there are a lot of videos mentioning suicide,” </strong><span>including one asking,</span><strong> “If you could kill yourself without hurting anybody would you?”</strong></p></li></ul></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png" width="676" height="535.3214285714286" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1153,&quot;width&quot;:1456,&quot;resizeWidth&quot;:676,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F178fb3da-55e9-400e-a8df-4e2e483cafea_1600x1267.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em><strong>Figure. Pg. 121 para. 261: “</strong><span>Once the TikTok algorithm determines that a teen user is interested in gambling, drugs, or weight loss, the algorithm will consistently show them excessive amounts of that content.” Source: Wall Street Journal.</span></em></figcaption></figure></div><ul><li><p>KY P. 98, PARA 309-310 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p>309. Defendants know these R1 reviews do not catch a great deal of content that violates the Community Guidelines or restrict content to age-appropriate groups.</p></li><li><p>For example, a presentation about suicide and self-harm content moderation notes that R1 Moderators do not always speak the language shown in the videos, that moderators do not understand context, and that moderators are not given policy reminders for new instructions.</p></li></ul></li></ul><ul><li><p><em>[No direct quotes from TikTok employees, but see pages 36-43 for a section of the brief that describes the videos that were sent to fictitious accounts created by the AG’s office, pretending to be 13, 15, and 17 year old Nebraska residents. “Within minutes of scrolling through TikTok’s “For You” feed—before the accounts had searched for any videos or “followed” any users—TikTok’s algorithm repeatedly exposed each Nebraska teen account to overtly mature and otherwise inappropriate content.” Some of the videos sent to young girls—just on the basis of their age and gender—clearly encouraged young girls to starve themselves.]</em></p></li><li><p><span>[</span><em>Some of the videos also clearly celebrate suicide as the way to escape from psychological pain.</em><span>]</span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png" width="366" height="569.74" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:934,&quot;width&quot;:600,&quot;resizeWidth&quot;:366,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22d34eae-74ea-433e-9eb5-91ffc5db33c8_600x934.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em><strong>Image. Pg. 40, para. 109.</strong><span> “One video shows a woman smiling at the camera, with the text “[m]e staring at my mum after begging her to let me go out for a late night walk alone knowing d*mn well it will be the last time she saw me.” The video has over 794k views and 191.3k likes.”</span></em></figcaption></figure></div><p><em><span>[There is widespread exposure to pornographic, violent, and drug-related content on TikTok. This content is often viewed on one’s newsfeed and through TikTok’s “live” features. Although nudity, pornography, sexually explicit content, non-consensual sexual acts, the sharing of non-consensual intimate imagery and sexual solicitation violates TikTok’s guidelines, the </span><a href="https://www.bbc.com/news/technology-56821882" rel="">content</a><span> is easily </span><a href="https://findanexpert.unimelb.edu.au/news/72158-tiktok-has-a-startling-amount-of-sexual-content-%E2%80%93-and-it%27s-way-too-easy-for-children-to-access#:~:text=TikTok's%20content%20moderation%20maze,intimate%20imagery%20and%20sexual%20solicitation." rel="">accessed</a><span> and </span><a href="https://www.house.mn.gov/comm/docs/H_rHCyPfPEyca1P3i1k11g.pdf" rel="">recommended</a><span> to </span><a href="https://www.wired.com/story/tiktok-nsfw/" rel="">users</a><span>.]</span></em></p><ul><li><p>KY P. 38, PARA 115 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>In an internal document discussing how to respond to the [Wall Street Journal] series, TikTok employees acknowledged material failures in their process, including but not limited to the fact that “</span><strong>46.5% sexualized and drug content shared by WSJ is not covered by [the existing moderation] policy (ANSA 55%, Drug 24%).”</strong><span> Similarly, </span><strong>“[t]he moderation leakage rate of sexualized and drug content is 73.5% (ANSA 58%, Drug 90%).”</strong><span> The reason for this moderation failure is that </span><strong>“most prevalent policy titles are sexually explicit language and mention of drugs,”</strong><span> whereas “</span><strong>implicit language [e.g., coded language] is often used in videos and failed to be captured [sic] by moderators.”</strong></p></li></ul></li><li><p>KY P. 53, PARA 168 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>Horrifyingly, the report (TT Live &amp; US Safety Summit, “Project Meramec”) also confirms that </span><strong>“Minors Easily Access Livestream Feed”</strong><span> and that there is </span><strong>“[n]o age-related feed strategy.”</strong><span> Further, the report acknowledges that </span><strong>“[o]ne of our key discoveries during this project that has turned into a major challenge with Live business is that the content that gets the highest engagement may not be the content we want on our platform. Transactional sexual content incorporates hundreds of signals that inform the [algorithm] as well as LiveOps metrics of success - # of gifts, frequency of hosts going live, # of comments, etc.”</strong></p></li></ul></li><li><p>KY P.106, PARA 341 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>Although TikTok boasts thorough content review processes, it does not disclose significant </span><strong>“leakage”</strong><span> rates, measuring the percentage of violative content that is not moderated or removed. Internally, TikTok knows the rate at which certain categories of content leak through its moderation processes, including: 35.71% of </span><strong>“Normalization of Pedophilia”</strong><span> content; 33.33% of </span><strong>“Minor Sexual Solicitation”</strong><span> content; 39.13% of </span><strong>“Minor Physical Abuse”</strong><span> content; 30.36% of </span><strong>“leading minors off platform”</strong><span>; 50% of </span><strong>“Glorification of Minor Sexual Assault”</strong><span>; and “100% of </span><strong>“Fetishizing Minors.”</strong></p></li></ul></li></ul><ul><li><p>UT P. 5, PARA 13</p><ul><li><p>TikTok also knows that LIVE is being used for money laundering and other criminal activities.</p></li><li><p><span>PARA 14: In 2021, TikTok launched “Project Jupiter” to investigate suspicions that organized crime was using LIVE to launder money through TikTok’s gifting feature. TikTok discovered that criminals were selling drugs and running fraud operations on LIVE. </span><em>[TikTok has a virtual currency system where users can “gift” one another].</em></p></li><li><p><span>PARA 15: TikTok admits that sexual exploitation and illegal activities on LIVE are </span><strong>“controversial”</strong><span> and worsened by its </span><em>own</em><span> monetization scheme. Despite acknowledging internally that</span><strong> “sexually suggestive LIVE content is on the rise,”</strong><span> TikTok refuses to warn consumers about these dangers. Instead, TikTok plans to </span><strong>“make better use of monetization methods such as gifting and subscription to gain revenue . . . .”</strong></p></li></ul></li><li><p>UT P. 10, PARA 32</p><ul><li><p>The Division’s presuit investigation also confirmed that TikTok’s platform facilitates the sale of illegal drugs to underage children right here at our doorstep—including easily allowing TikTok users to offer the sale and delivery of drugs like Xanax, Valium, and MDMA to children in Salt Lake City.</p></li></ul></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png" width="238" height="645.4237288135594" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/27521a56-039e-41f6-9f1d-210abf890416_354x960.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:960,&quot;width&quot;:354,&quot;resizeWidth&quot;:238,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27521a56-039e-41f6-9f1d-210abf890416_354x960.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em><strong>Image. Pg. 31, para. 97: </strong><span>“An investigator posed as a 17-year-old boy in Utah on TikTok, and after a single initial post on a message board asking for “plugs” (a euphemism for drugs), was quickly approached by dealers on the platform offering a laundry list of drugs for shipment.” Figure shows “a list of drugs for sale on TikTok.”</span></em></figcaption></figure></div><ul><li><p>UT P. 31, PARA 96</p><ul><li><p><span>TikTok also knows that LIVE facilitates other illegal activity. By as early as 2021, TikTok knew that drug trafficking was </span><strong>“becoming more prevalent”</strong><span> on the app.</span></p></li></ul></li></ul><ul><li><p>NE P. 32, PARA 114</p><ul><li><p><span>When </span><em>The Journal</em><span> shared “a sample of 974 videos about drugs, pornography, and other adult content that were served to minor accounts,” a spokesperson for Defendants stated that </span><strong>“the majority didn’t violate guidelines”</strong><span>—though several hundred were subsequently removed—and that</span><strong> “the [TikTok] app doesn’t differentiate between videos it serves to adults and minors.”</strong></p></li></ul></li></ul><ul><li><p><em>[See pages 35-36 and 43-50 for a section of the brief that describes the videos that were sent almost immediately to fictitious accounts created by the AG’s office, pretending to be 13, 15, and 17 year old Nebraska minors. Some of the videos are adult porn actresses engaging in lewd and obscene behavior on TikTok, in order to lure customers over to their Onlyfans pages, sometimes via Instagram.]</em></p></li></ul><ul><li><p>NY P. 45, PARA 215</p><ul><li><p><span>On its website, TikTok says that users in Restricted Mode </span><strong>“shouldn’t see mature or complex themes, such as: [p]rofanity[, s]exually suggestive content[, r]ealistic violence or threatening imagery[, f]irearms or weapons in an environment that isn’t appropriate[, i]llegal or controlled substances/drugs[, and e]xplicit references to mature or complex themes that may reflect personal experiences or real-world events that are intended for older audiences.” </strong><em>[But they do, as you can see in the leakage rates found in KY P. 106, PARA 341]</em></p></li></ul></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><em><span>[Recent revelations reported out from the </span><a href="https://www.wsj.com/tech/snap-failed-to-warn-users-about-sextortion-risks-state-lawsuit-alleges-0b170fc7" rel="">Wall Street Journal</a><span> and </span><a href="https://www.npr.org/2024/10/12/g-s1-28040/teens-tiktok-addiction-lawsuit-investigation-documents" rel="">other outlets</a><span> have shown that many social media companies and device providers (e.g., Apple) have rampant and rarely addressed cases of </span><a href="https://www.wsj.com/tech/snap-failed-to-warn-users-about-sextortion-risks-state-lawsuit-alleges-0b170fc7" rel="">sextortion</a><span>, </span><a href="https://www.wsj.com/tech/why-americas-system-for-investigating-child-exploitation-online-isnt-working-34b74b71" rel="">child sexual</a><span> </span><a href="https://arstechnica.com/tech-policy/2024/12/thousands-of-child-sex-abuse-victims-sue-apple-for-lax-csam-reporting/" rel="">abuse material</a><span> (CSAM), and </span><a href="https://www.wsj.com/articles/instagram-vast-pedophile-network-4ab7189" rel="">sexual predation</a><span> </span><a href="https://www.wsj.com/tech/meta-staff-found-instagram-subscription-tool-enabled-child-exploitation-the-company-pressed-ahead-anyway-a18e81e6" rel="">occurring</a><span> via their platforms/devices. This is also </span><a href="https://www.npr.org/2024/10/11/g-s1-27676/tiktok-redacted-documents-in-teen-safety-lawsuit-revealed#:~:text=one%20TikTok%20official%20concluded%3A%20%E2%80%9C%5BO%5Dne%20of%20our%20key%20discoveries%20during%20this%20project%20that%20has%20turned%20into%20a%20major%20challenge%20with%20Live%20business%20is%20that%20the%20content%20that%20gets%20the%20highest%20engagement%20may%20not%20be%20the%20content%20we%20want%20on%20our%20platform.%E2%80%9D" rel="">the</a><span> </span><a href="https://www.forbes.com/sites/alexandralevine/2022/11/11/tiktok-private-csam-child-sexual-abuse-material/" rel="">case</a><span> </span><a href="https://attorneygeneral.utah.gov/2025/01/03/utah-dcp-and-ags-office-announce-release-of-previously-redacted-information-tiktok-execs-knew-they-were-profiting-off-the-sexual-exploitation-of-minors/" rel="">with TikTok</a><span>.]</span></em></p><ul><li><p>KY P. 37, PARA 111:</p><ul><li><p>Federal law mandates that Defendants report suspected CSAM to the National Center for Missing and Exploited Children (“NCMEC”) under 18 U.S.C. § 2258A. To limit and avoid its reporting requirements under federal law, Defendants purposely designed TikTok—which it knows are used by children, including children under 13—not to incorporate modern CSAM detection technology. This technology would be free for Defendants to implement within TikTok’s product design.</p></li><li><p>PARA 113: While Defendants have stepped up their reporting to NCMEC [National Center for Missing &amp; Exploited Children]—reporting 362,108 reports in the last half of 2023—these efforts illustrate how wantonly negligent TikTok has been historically, with only 596 reports made in 2019 and 22,692 in 2020. Defendants’ disregard for the safety of Young Users on TikTok has endangered countless children, including children in Kentucky.</p></li></ul></li><li><p>KY P. 100, PARA 316 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>According to a presentation by the Trust and Safety group, </span><strong>“[u]sers are more likely to post comments than videos,”</strong><span> because about </span><strong>“42% [of users] are ‘comment only’ users[.]”</strong></p></li><li><p><span>PARA 317: But the vast majority of comments never go through human moderation. According to that same document, </span><strong>“Comments are increasing and manual coverage is disproportionately low.” </strong><span>In fact, </span><strong>“[h]uman moderation for comment review is at 0.25%.”</strong></p></li></ul></li></ul><ul><li><p>UT P. 3, PARA 7</p><ul><li><p><span>But TikTok has long known—and hidden—the significant risks of live streaming, especially for children. By TikTok’s own admission:</span><strong> “we’ve created an environment that encourages sexual content.”</strong></p></li></ul></li><li><p>UT P. 4, PARA 9</p><ul><li><p><span>In early 2022, TikTok’s internal investigation of LIVE, called “Project Meramec,” revealed shocking findings. Hundreds of thousands of children between 13 and 15 years old were bypassing TikTok’s minimum age restrictions, hosting LIVE sessions, and receiving concerning messages from adults. The project confirmed that LIVE </span><strong>“enable[d the] exploitation of live hosts”</strong><span> and that TikTok profited significantly from</span><strong> “transactional gifting”</strong><span> involving nudity and sexual activity, all facilitated by TikTok’s virtual currency system.</span></p></li></ul></li><li><p>UT P. 36, PARA 115</p><ul><li><p>In response to the Forbes article, TikTok also conducted a formal investigation into issues on LIVE called “Project Meramec.” TikTok shared the results of the investigation internally during a May 2022 “Safety Summit”:</p></li><li><p>PARA 116: Project Meramec confirmed that young users well under the minimum age requirement could host LIVE sessions on TikTok. The study confirmed that in just the month of January 2022 alone, 112,000 “L1” users (i.e., a metric TikTok uses to categorize users between 13 and 15 years old) hosted LIVE sessions.</p></li><li><p><span>PARA 117: These underage users also received a significant number of direct messages from adult users, raising red flags to TikTok that these minors were likely being groomed by adults. Project Meramec revealed that TikTok received not only “</span><strong>significant revenue”</strong><span> from </span><strong>“transactional gifting”</strong><span>—to the tune of one million Gifts in January 2022 alone—but also that this revenue was in large part generated through transactions for sexual content.</span></p></li></ul></li><li><p>UT P. 34-35, PARA 109</p><ul><li><p><span>An internal study from December 2023, following the Forbes article, documented what TikTok admits is </span><strong>“the cruelty” </strong><span>of maintaining LIVE with its current risks for minors on the app. The study showed its LIVE feature had the following characteristics:</span></p><ul><li><p><strong>“[H]igher proportion[s] of minor users”;</strong></p></li><li><p><strong>“Minor users are more likely to access high severity risk LIVE content than adult users”;</strong></p></li><li><p><strong>For violating content like “[a]dult nudity and sexual activities (ANSA) . . . and minor-hosted LIVE rooms, minor views are likely 2 times higher than other LIVE rooms”; </strong><span>and</span></p></li><li><p><strong>“Minor users lack self-protection awareness and interact more with risky LIVE content.”</strong></p></li></ul></li></ul></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png" width="690" height="379.0740740740741" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:712,&quot;width&quot;:1296,&quot;resizeWidth&quot;:690,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1cc7174-9b4a-4747-b6f3-eceeb9b29116_1296x712.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em><strong>Image. Pg. 42, para. 139: </strong><span>“Despite acknowledging how downright ‘irresponsible’ it would be to expect that users will use LIVE wisely without appropriate safeguards in place, company leaders have admitted internally that the company placed profits over the safety of consumers.” Figure 16 shows a February 2022 internal chat between two TikTok employees.</span></em></figcaption></figure></div><ul><li><p>UT P. 35, PARA 111</p><ul><li><p>In February 2022, two TikTok leaders discussed the need to remove “egregious content from clearly commercial sexual solicitation accounts,” and were aware of issues with women and minors being sexually solicited through LIVE.</p></li><li><p>PARA 112: these leaders knew about agencies that recruited minors to create Child Sexual Abuse Material and commercialized it using LIVE.</p></li><li><p><span>PARA 113: In another example from a March 2022 LIVE safety survey, users reported that </span><strong>“streamer-led sexual engagements (often transactional) [were] commonly associated with TikTok LIVE.”</strong><span> Users also reported </span><strong>“often seeing cam-girls or prostitutes asking viewers for tips/donations to take off their clothes or write their names on their body . . . .”</strong><span> That same month, TikTok employees admitted</span><strong> “cam girls”</strong><span> (or women who do sex work online by streaming videos for money) were on LIVE and that these videos had a </span><strong>“good amount of minors engaging in it.” </strong><span>TikTok leaders have known since at least 2020 that TikTok has</span><strong> “a lot of nudity and soft porn.” </strong><span>An internal document from May 2020 also highlighted concerns about </span><strong>“camming”</strong><span> becoming more popular as sex workers turned to online platforms during the COVID-19 pandemic. </span></p></li><li><p><span>PARA 114: TikTok has long known that virtual gifting is used as a predatory grooming tactic on LIVE. TikTok has internally acknowledged that</span><strong> “perpetrators tend to use tactics such as gift giving, flattery, and gifting money to win the trust of minors.”</strong></p></li></ul></li><li><p>UT P. 38, PARA 125</p><ul><li><p>In September 2022—five months after the Forbes story—an investigator found that “within minutes of browsing the [LIVE] feed” they were shown underage girls providing sexually suggestive content in exchange for money and young boys using filters to pose as girls to receive Gifts.</p></li><li><p>PARA 126: The investigator also found a “never-ending stream” of hosts who openly admitted that they were 14 and 15 years old while also “holding signs” or “standing in front of the camera” with a sign saying “Rose = say daddy,” “ice cream = 360 spin,” or “universe = cut shirt.”</p></li></ul></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/industrial-scale-harm-tiktok/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok/comments" rel=""><span>Leave a comment</span></a></p><p><em><span>[Although TikTok, like other social media companies, has an age minimum of 13 for account creation (in the U.S.) and higher age limits for certain features (e.g., </span><a href="https://support.tiktok.com/en/live-gifts-wallet/tiktok-live/what-is-tiktok-live" rel="">TikTok LIVE</a><span> at 18), underage use is common and is widely known about by the company, which does little to enforce those age limits. TikTok also </span><a href="https://docs.house.gov/meetings/IF/IF00/20230323/115519/HHRG-118-IF00-Wstate-ChewS-20230323.pdf" rel="">regularly</a><span> claims that it has effective safety features built in for users. However, the briefs make it clear that TikTok’s primary goal is keeping users on and engaged for as long as possible, which often comes at the cost of child safety.]</span></em></p><ul><li><p>KY P. 93, PARA 288 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>Similarly, in a chat message discussing features purporting to help users manage their screentime, a TikTok employee confirmed that the company’s </span><strong>“goal is not to reduce the time spent”</strong><span> on the TikTok app, but rather to ultimately </span><strong>“contribute to DAU [daily active users] and retention” </strong><span>of users.</span></p></li></ul></li><li><p>KY P. 93, PARA 289 [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>Defendants also promote screen time management tools for Young Users that they know are ineffective. For example, an internal document seeking approval for the screentime dashboard noted that </span><strong>“we don’t expect significant impact to stay time with this feature since it is only improving awareness and is not an intervention.”</strong></p></li><li><p><span>PARA 290: In fact, Defendants found—as expected—that the screen time dashboard did not affect Young Users’ usage because </span><strong>“minors do not have executive function to control their screen time.”</strong><span> The screentime dashboard did not appear to have any impact on the usage of minors.</span></p></li></ul></li></ul><ul><li><p>KY P. 95, PARA 297, [REDACTED BUT RETRIEVABLE TEXT]</p><ul><li><p><span>Defendants did not disclose that they knew effects like beauty filters can harm Young Users and did not implement the suggestions of employees that TikTok </span><strong>“provide users with educational resources about image disorders; create a campaign “to raise awareness on issues with low self esteem (caused by the excessive filter use and other issues)”; and add “a banner/H5 page to these filters and/or short videos which make use of the filters, particularly the Bold Glamour one, including an awareness statement about filters and the importance of positive body image/mental health, [that] could potentially minimize the negative public perception surrounding beauty filters and their reported effect on user mental health.”</strong></p></li></ul></li></ul><ul><li><p>UT P. 37-38, PARA 121</p><ul><li><p><span>In May 2022, after the Forbes article came out, TikTok took steps to evaluate how ‘valuable’ its underage LIVE hosts were before it would decide to make safety changes to the feature, like increasing the minimum age requirement from 16 to 18. It found 384,833 hosts were 16 to 17—as far as TikTok was aware—and they spent over </span><em>seven million minutes</em><span> streaming themselves on LIVE.</span></p></li><li><p><span>PARA 122: Despite learning that there were a ‘high’ number of underage hosts on the platform and that these minors were receiving problematic messages from adult users, TikTok waited </span><em>six months</em><span> before raising the minimum age for a user to host a LIVE session from 16 to 18.</span></p></li><li><p>PARA 123: But raising the minimum age from 16 to 18 did nothing to solve the problem. TikTok’s age-gating is ineffective, and many kids still join LIVE events daily. TikTok also chose to forgo reasonable safety measures, prioritizing profits over safety, allowing unrestrained transactional sexual content and other illicit activities to thrive.</p></li><li><p><span>PARA 124: As a result, these activities have not just continued—they have exploded as LIVE has become even more popular. In 2023, a TikTok senior director was alerted by advocates who had noticed an increase in </span><strong>‘teens in overtly sexualized situations on live streams controlled by someone older than 18 who is collecting money from viewers while the teen performs sexually suggestive acts.’</strong><span> The advocates said they reported the streams through TikTok’s internal reporting tools, but TikTok found they did not violate its policies.</span></p></li></ul></li><li><p>UT P. 40, PARA 132</p><ul><li><p><span>TikTok recognizes internally that its age-gating is ineffective and that TikTok’s own moderation efforts on LIVE are ineffective and inconsistently applied, and TikTok hides this information from users and the public. TikTok knows this is particularly true for children, admitting internally: (1)</span><strong> “Minors are more curious and prone to ignore warnings”</strong><span> and (2) </span><strong>“Without meaningful age verification methods, minors would typically just lie about their age.”</strong></p></li></ul></li><li><p>UT P. 37, PARA 119</p><ul><li><p><span>Given how lucrative LIVE is for TikTok, the company slow-rolled implementing safety measures, and once it did, these measures proved largely ineffective at keeping pace with the growing popularity of LIVE. This was by design—LIVE was </span><strong>“such a huge part of the strategy for the [TikTok app]”</strong><span> that TikTok employees recognized they</span><strong> “d[id not] know”</strong><span> if they could</span><strong> “reasonably expect to increase limitations for LIVE” </strong><span>even in February 2022, and even after recognizing that</span><strong> “it is irresponsible [of TikTok] to expect that users will use LIVE wisely.”</strong></p></li><li><p>PARA 120: In other words, LIVE was too profitable to be interfered with, even to protect children.</p></li></ul></li><li><p>UT P. 44-45, PARA 145</p><ul><li><p>These policies do not adequately safeguard children and, furthermore, are not consistently applied. In 2020, TikTok unveiled an ‘internal program’ to ‘protect creators and other accounts that [TikTok] deem to be high value.’ The program featured policy shortcuts like ‘delayed enforcement,’ ‘deferred policy decisions,’ or ‘no permanent ban on Elite + Accounts,’ to protect its popular users who violate TikTok’s policies. TikTok deployed this look-the-other-way policy despite knowing that the ‘majority of elite accounts appear to run afoul of [TikTok’s] policies on sexually explicit content,’ among other violations. Approximately 1,400 minors were considered ‘elite creators.’</p></li></ul></li></ul><ul><li><p>NE P. 58, PARA 187</p><ul><li><p><span>To start, TikTok has no real age verification system for users. Until 2019, Defendants did not even ask TikTok users for their age when they registered for accounts. When asked why they did not do so, despite the obvious fact that </span><strong>“a lot of the users, especially top users, are under 13,”</strong><span> founder Zhu explained that,</span><strong> “those kids will anyway say they are over 13.”</strong></p></li></ul></li><li><p>NE P. 61, PARA 198</p><ul><li><p><span>In another internal document, TikTok admitted that </span><strong>“user research” </strong><span>shows that </span><strong>“[f]amilies do not use Family Pairing”</strong><span> and that</span><strong> “Family Pairing doesn’t address parents’ top concerns,”</strong><span> including </span><strong>“inappropriate content, offensive interactions, and lack of privacy.</strong></p></li></ul></li><li><p>NE P. 65, PARA 211</p><ul><li><p><span>Over the years, other of Defendants’ employees have voiced their frustration that </span><strong>“we don’t want to [make changes] to the For You feed because it’s going to decrease engagement,” </strong><span>even if </span><strong>“it could actually help people with screen time management.”</strong></p></li></ul></li><li><p>NE P. 65, PARA 212</p><ul><li><p><span>Or as another employee put it, </span><strong>“[w]hen we make changes, we make sure core metrics aren’t affected.”</strong><span> This is because </span><strong>“[l]eaders don’t buy into problems” </strong><span>with unhealthy and compulsive usage, and work to address it is</span><strong> “not a priority for any other team.”</strong></p></li></ul></li><li><p>NE P. 65, PARA 213</p><ul><li><p><span>As TikTok’s [</span><em>redacted</em><span>] candidly admitted in 2021, some of TikTok’s so-called “safety” features are little more than </span><strong>“good talking point[s].”</strong><span> Describing the “Take a Break” videos Defendants have promoted, explained that </span><strong>“[w]e found out through some research that they’re not altogether effective”</strong><span> but that</span><strong> “it’s good as a point to share with policymakers, ‘cause they’re kind of impressed that we’re spending time, money, and energy to get people off our platform, at least in theory.”</strong></p></li></ul></li><li><p>NE P. 65-66, PARA 214</p><ul><li><p><span>Defendants, who admit internally that “screen time management” tools are </span><strong>“not . . . at expense of retention.”</strong><span> The goal is “</span><strong>not to reduce the time spent” </strong><span>but to </span><strong>“improve user experience and satisfaction”</strong><span> and ultimately “</span><strong>contribute to DAU [Daily Active Users] and retention.” </strong><span>According to internal documents, </span><strong>“[t]his aligns with leadership’s guidance” </strong><span>that there be </span><strong>“no impact to retention.”</strong></p></li></ul></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>How can it be that a product used by more than twenty million children and adolescents in the United States</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-11-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-11-154423872" target="_self" rel="">11</a></span><span> is also causing so much harm to its users? Many teens experience the harms of TikTok and complain about its addictive nature and its “brain rot” effects, so why don’t they just stop using it?</span></p><p><span>When Jon asks these questions to his students at NYU who are heavy users of TikTok, he commonly gets two related answers: 1) </span><em>I’ve tried to quit but I just can’t do it,</em><span> and 2) </span><em>I can’t quit because then I won’t know what everyone else is talking about</em><span>. In other words, TikTok is both behaviorally addictive and socially addictive, which means that many teens feel </span><a href="https://mashable.com/article/common-sense-media-teenagers-social-media" rel="">trapped</a><span>. As Gen Z poet </span><a href="https://www.instagram.com/jonathanhaidt/reel/DB167XHvRLh/" rel="">Kori James said</a><span>, about social media: “I know it's poison but I drink anyway.”</span></p><p><span>A </span><a href="https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/" rel="">recent study</a><span> led by the University of Chicago economist Leonardo Bursztyn captured the dynamics of this trap. The researchers recruited more than 1,000 college students and asked them how much they’d need to be paid to deactivate their accounts on either Instagram or TikTok for four weeks. That’s a standard economist’s question to try to compute the net value of a product to society. On average, students said they’d need to be paid roughly $50 ($59 for TikTok, $47 for Instagram) to deactivate whichever platform they were asked about. Then the experimenters told the students that they were going to try to get most of the others in their school to deactivate that same platform, offering to pay them to do so as well, and asked, Now how much would you have to be paid to deactivate, if most others did so? The answer, on average, was less than zero. In each case, </span><em>most students were willing to pay to have that happen</em><span>.</span></p><p><span>We (Jon and Zach) teamed up with the Harris Poll to confirm this finding and extend it. We </span><a href="https://theharrispoll.com/briefs/gen-z-social-media-smart-phones/" rel="">conducted a nationally representative survey</a><span> of 1,006 Gen Z young adults (ages 18-27). We asked respondents to tell us, for various platforms and products, if they wished that it “was never invented.” For Netflix, Youtube, and the internet itself, relatively few said yes to that question (always under 20%). We found much higher levels of regret for the dominant social media platforms: Instagram (34%), Facebook (37%), Snapchat (43%), and the most regretted platforms of all: TikTok (47%) and X/Twitter (50%).</span></p><p>What, then, is the net value of TikTok to society? The harms are vast and varied, and they are hitting children, teens, and young adults the hardest, which means that TikTok may be altering developmental pathways and causing lasting changes. The net value is likely very negative. We believe that America would be much better off if TikTok were to go dark on January 19th.</p><p><span>No consumer product is 100% safe. We don't remove a product if a child or two dies from it each year in a freak accident. But the harms documented here are not freak accidents. They are the common effects of the normal use of TikTok by children, many of them younger than the legal age of 13. Due to its current design, TikTok is perpetrating harm to millions of children—harm at an industrial scale—in America and around the world. These harms may not be presented tomorrow to the Justices of the Supreme Court, but we think they should be decisive in the court of public opinion. TikTok should be removed from American childhood.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-12-154423872" href="https://www.afterbabel.com/p/industrial-scale-harm-tiktok#footnote-12-154423872" target="_self" rel="">12</a></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unauthenticated Remote Code Execution in Erlang/OTP SSH (160 pts)]]></title>
            <link>https://nvd.nist.gov/vuln/detail/CVE-2025-32433</link>
            <guid>43716526</guid>
            <pubDate>Thu, 17 Apr 2025 13:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nvd.nist.gov/vuln/detail/CVE-2025-32433">https://nvd.nist.gov/vuln/detail/CVE-2025-32433</a>, See on <a href="https://news.ycombinator.com/item?id=43716526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div colspan="2" id="vulnDetailPanel">

                    <h2 data-testid="page-header">
                        <i></i><span data-testid="page-header-vuln-id">CVE-2025-32433</span>
                        Detail
                    </h2>
                    


                    <div>
                        <div>
                            <div role="alert" data-testid="vuln-warning-container" id="vulnShowWarningDiv">
                                    <p><strong><span data-testid="vuln-warning-status-name">Received</span></strong></p><hr>
                                    <p data-testid="vuln-warning-banner-content">This CVE record has recently been published to the CVE List and has been included within the NVD dataset.</p>
                                </div>

                            <h3 id="vulnDescriptionTitle" data-testid="vuln-description-title">Description </h3>
                            
                            <p data-testid="vuln-description">Erlang/OTP is a set of libraries for the Erlang programming language. Prior to versions OTP-27.3.3, OTP-26.2.5.11, and OTP-25.3.2.20, a SSH server may allow an attacker to perform unauthenticated remote code execution (RCE). By exploiting a flaw in SSH protocol message handling, a malicious actor could gain unauthorized access to affected systems and execute arbitrary commands without valid credentials. This issue is patched in versions OTP-27.3.3, OTP-26.2.5.11, and OTP-25.3.2.20. A temporary workaround involves disabling the SSH server or to prevent access via firewall rules.</p><br>


                            
                            

                            <!-- CVSS Severity and Vector Strings -->
                            <div id="vulnCvssPanel" data-testid="vuln-cvss-container">
                                <h3 title="CVSS is not a measure of risk">Metrics</h3>
                                 
                                


                                <p><i>
                                        <small>
                                            NVD enrichment efforts reference publicly available information to associate
                                            vector strings. CVSS information contributed by other sources is also
                                            displayed.
                                        </small>
                                    </i>
                                </p>

                                <!-- CVSS v4.0  -->
                                <div id="Vuln4CvssPanel" data-testid="vuln-cvss4-panel">
                                    <p><strong>CVSS 4.0 Severity and Vector Strings:</strong></p><!-- NIST -->
                                    <div>
                                        <br>
                                        <div>
                                                <p><img src="https://nvd.nist.gov/site-media/images/NVD_NVD_Stack_Plain.svg" alt="NIST CVSS score">
                                                </p>
                                                <p><strong>NIST:</strong>&nbsp;<span data-testid="vuln-cvss4-source-nvd">NVD</span>
                                                </p>
                                            </div>
                                        <div>
                                        <p><span><strong> </strong><span> <a id="Cvss4NistCalculatorAnchorNA" data-testid="vuln-cvss4-panel-score-na">N/A</a></span></span>
                                        </p></div>
                                        <p><span> <span data-testid="vuln-cvss4-nist-vector-na">NVD assessment
                                       not yet provided.</span></span> 
                                        </p>
                                    </div>
                                    <!-- CNA -->
                                    

                                    <!-- ADP -->
                                    



                                </div>


                                <!-- CVSS V3.x -->
                                

                                <!-- CVSS V2.0 -->
                                
                            </div>


                            <div>
                                
                                
                                
                                <div id="vulnHyperlinksPanel">
                                    <h3>References to Advisories, Solutions, and Tools</h3>
                                    <p>
                                        By selecting these links, you will be leaving NIST webspace.
                                        We have provided these links to other web sites because they
                                        may have information that would be of interest to you. No
                                        inferences should be drawn on account of other sites being
                                        referenced, or not, from this page. There may be other web
                                        sites that are more appropriate for your purpose. NIST does
                                        not necessarily endorse the views expressed, or concur with
                                        the facts presented on these sites. Further, NIST does not
                                        endorse any commercial products that may be mentioned on
                                        these sites. Please address comments about this page to <a href="mailto:nvd@nist.gov">nvd@nist.gov</a>.
                                    </p>


                                    <table data-testid="vuln-hyperlinks-table">
                                        <thead>
                                        <tr>
                                            <th>Hyperlink</th>
                                            <th>Resource</th>
                                        </tr>
                                        </thead>
                                        <tbody>

                                        <tr data-testid="vuln-hyperlinks-row-0">
                                            <td data-testid="vuln-hyperlinks-link-0">
                                                <a href="http://www.openwall.com/lists/oss-security/2025/04/16/2" target="_blank" rel="noopener noreferrer">http://www.openwall.com/lists/oss-security/2025/04/16/2</a></td>

                                            <td data-testid="vuln-hyperlinks-resType-0">
														
                                            </td>
                                        </tr>

                                        <tr data-testid="vuln-hyperlinks-row-1">
                                            <td data-testid="vuln-hyperlinks-link-1">
                                                <a href="https://github.com/erlang/otp/commit/0fcd9c56524b28615e8ece65fc0c3f66ef6e4c12" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/commit/0fcd9c56524b28615e8ece65fc0c3f66ef6e4c12</a></td>

                                            <td data-testid="vuln-hyperlinks-resType-1">
														
                                            </td>
                                        </tr>

                                        <tr data-testid="vuln-hyperlinks-row-2">
                                            <td data-testid="vuln-hyperlinks-link-2">
                                                <a href="https://github.com/erlang/otp/commit/6eef04130afc8b0ccb63c9a0d8650209cf54892f" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/commit/6eef04130afc8b0ccb63c9a0d8650209cf54892f</a></td>

                                            <td data-testid="vuln-hyperlinks-resType-2">
														
                                            </td>
                                        </tr>

                                        <tr data-testid="vuln-hyperlinks-row-3">
                                            <td data-testid="vuln-hyperlinks-link-3">
                                                <a href="https://github.com/erlang/otp/commit/b1924d37fd83c070055beb115d5d6a6a9490b891" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/commit/b1924d37fd83c070055beb115d5d6a6a9490b891</a></td>

                                            <td data-testid="vuln-hyperlinks-resType-3">
														
                                            </td>
                                        </tr>

                                        <tr data-testid="vuln-hyperlinks-row-4">
                                            <td data-testid="vuln-hyperlinks-link-4">
                                                <a href="https://github.com/erlang/otp/security/advisories/GHSA-37cp-fgq5-7wc2" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/security/advisories/GHSA-37cp-fgq5-7wc2</a></td>

                                            <td data-testid="vuln-hyperlinks-resType-4">
														
                                            </td>
                                        </tr>


                                        </tbody>
                                    </table>


                                </div>

                                

                                <div id="vulnTechnicalDetailsDiv" data-testid="vuln-technical-details-container">
                                    <h3>Weakness Enumeration</h3>


                                    <table data-testid="vuln-CWEs-table">
                                        <thead>
                                        <tr>
                                            <th>CWE-ID</th>
                                            <th>CWE Name</th>
                                            <th>Source</th>
                                        </tr>
                                        </thead>
                                        <tbody>

                                        <tr data-testid="vuln-CWEs-row-0">
                                            <td data-testid="vuln-CWEs-link-0">
                                                <a href="http://cwe.mitre.org/data/definitions/306.html" target="_blank" rel="noopener noreferrer">CWE-306</a>
                                                
                                            </td>
                                            <td data-testid="vuln-CWEs-link-0">Missing Authentication for Critical Function</td>

                                            <td data-testid="vuln-cwes-assigner-0">
														<span data-testid="vuln-cwes-assigner-0-0">
														
														

															
															
															
														
														<span>GitHub, Inc.  </span>
														</span>

                                            </td>

                                        </tr>

                                        </tbody>
                                    </table>

                                </div>


                                

                                <div id="vulnChangeHistoryDiv" data-testid="vuln-change-history-container">
                                    <h3 id="VulnChangeHistorySection">Change History</h3>
                                    <p><small> 2 change records found <a href="#VulnChangeHistorySection" id="changeHistoryToggle">show
                                        changes</a>
                                    </small></p>

                                </div>

                            </div>
                        </div>


                        <div>
                                <h4>Quick Info</h4>
                                <p><strong>CVE Dictionary Entry:</strong><br> <a target="_blank" rel="noopener noreferrer" data-testid="vuln-cve-dictionary-entry" href="https://cve.org/CVERecord?id=CVE-2025-32433">CVE-2025-32433</a><br> <strong>NVD
                                Published Date:</strong><br> <span data-testid="vuln-published-on">04/16/2025</span><br> <strong>NVD
                                Last Modified:</strong><br> <span data-testid="vuln-last-modified-on">04/16/2025</span><br> <strong>
                                Source:</strong><br> <span data-testid="vuln-current-description-source">GitHub, Inc.</span><br>
                            </p></div>

                    </div>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists find strongest evidence yet of life on an alien planet (111 pts)]]></title>
            <link>https://www.reuters.com/science/scientists-find-strongest-evidence-yet-life-an-alien-planet-2025-04-16/</link>
            <guid>43716293</guid>
            <pubDate>Thu, 17 Apr 2025 13:11:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/science/scientists-find-strongest-evidence-yet-life-an-alien-planet-2025-04-16/">https://www.reuters.com/science/scientists-find-strongest-evidence-yet-life-an-alien-planet-2025-04-16/</a>, See on <a href="https://news.ycombinator.com/item?id=43716293">Hacker News</a></p>
Couldn't get https://www.reuters.com/science/scientists-find-strongest-evidence-yet-life-an-alien-planet-2025-04-16/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Encryption Is Not a Crime (205 pts)]]></title>
            <link>https://www.privacyguides.org/articles/2025/04/11/encryption-is-not-a-crime/</link>
            <guid>43716138</guid>
            <pubDate>Thu, 17 Apr 2025 12:56:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.privacyguides.org/articles/2025/04/11/encryption-is-not-a-crime/">https://www.privacyguides.org/articles/2025/04/11/encryption-is-not-a-crime/</a>, See on <a href="https://news.ycombinator.com/item?id=43716138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><a data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Photo of a red key on an all black background." src="https://www.privacyguides.org/articles/assets/images/encryption-is-not-a-crime/encryption-is-not-a-crime-cover.webp"></a></p>

<p>Contrary to what some policymakers seem to believe, whether naively or maliciously, encryption is not a crime. Anyone asserting encryption is a tool for crime is either painfully misinformed or is attempting to manipulate legislators to gain oppressive power over the people.<!-- more --></p>
<p>Encryption is not a crime, encryption is a shield.</p>
<p>Encryption is the digital tool that protects us against all sorts of attacks. It is the lock on your digital door preventing harmful intruders from entering your home. Encryption is also the door itself, protecting your privacy and intimacy from creepy eavesdroppers while you go about your life.</p>
<p>It's not a crime to lock your home's door for protection, <strong>why would it be a crime to lock your digital door?</strong></p>
<p><a href="https://www.privacyguides.org/articles/2025/03/25/privacy-means-safety/">Encryption protects you</a> from cyberattack, identity theft, discrimination, doxxing, stalking, sexual violence, physical harm, and much more.</p>
<h2 id="who-says-encryption-is-a-crime">Who says encryption is a crime</h2>
<p>Anyone who is well-informed will find it hard to believe someone could want to sabotage such fantastic protection.</p>
<p>Yet, <a href="https://www.wired.com/1993/02/crypto-rebels/">year</a> after <a href="https://www.wired.com/story/a-new-era-of-attacks-on-encryption-is-starting-to-heat-up/">year</a>, oppressive regimes and lazy or greedy <a href="https://www.techradar.com/computing/cyber-security/anonymity-is-not-a-fundamental-right-experts-disagree-with-europol-chiefs-request-for-encryption-back-door">law enforcement</a> entities around the world have attempted to <a href="https://www.howtogeek.com/544727/what-is-an-encryption-backdoor/">undermine encryption</a> using the pretext this is needed to "solve crime", despite all the experts <em>repeatedly</em> warning on how <a href="https://arstechnica.com/tech-policy/2019/08/post-snowden-tech-became-more-secure-but-is-govt-really-at-risk-of-going-dark/">unnecessary</a> and <a href="https://www.globalencryption.org/2020/11/breaking-encryption-myths/">dangerous</a> this would be. And this is without accounting for all the countries where encryption is <em>already</em> <a href="https://www.gp-digital.org/world-map-of-encryption/">severely restricted</a>, such as Russia, China, India, Iran, Egypt, Cuba, and others.</p>
<p>Whether breaking encryption is brought up naively by misinformed authorities, or as a disguised excuse for mass surveillance is up for debate.</p>
<p>Nevertheless, the result is the same: An attempt to destroy <strong>a tool we all need to stay safe</strong>.</p>
<h2 id="encryption-is-a-protective-shield">Encryption is a protective shield</h2>
<p>Encryption, moreover end-to-end encryption, is a tool we all use in our digital life to stay safe.</p>
<p>In today's world, the boundary between online and offline life is largely dissolved. Almost everything we do "offline" has a record of it "online". Online life is regular life now. It's not just your browsing history.</p>
<p>Your medical record from a visit at the clinic, your purchase transaction from a trip to the store, your travel photos saved in the cloud, your text conversations with your friends, family, and children, are all likely protected with encryption, perhaps even with <em>end-to-end</em> encryption.</p>
<p>Such a large trove of personal data needs to be protected against eavesdropping and malicious attacks for everyone to stay safe.</p>
<p>Encryption offers this protection. End-to-end encryption all the more.</p>
<h2 id="what-is-end-to-end-encryption-and-what-is-the-war-against-it">What is end-to-end encryption, and what is the war against it</h2>
<p>End-to-end encryption is a type of encryption where only the intended recipient(s) have the ability to decrypt (read) the encrypted data.</p>
<p>This means that if you send a message through <a href="https://signal.org/">Signal</a> for example, only the participants to this conversation will be able to read the content of this conversation. Even Signal cannot know what is being discussed on Signal.</p>
<p>This greatly annoys some over-controlling authorities who would like to be granted unlimited power to spy on anyone anytime they wish, for vaguely defined purposes that could change at any moment.</p>
<p>End-to-end encryption can also mean a situation where you are "both ends" of the communication.</p>
<p>For example, when enabling Apple's <a href="https://support.apple.com/en-ca/guide/security/sec973254c5f/web">Advanced Data Protection for iCloud</a> (ADP), it activates end-to-end encryption protection for almost all of iCloud data, including photos. This means that even Apple could not see your photos, or be forced to share your photos with a governmental entity.</p>
<p>Without ADP, Apple can read or share your photos (or other data) if they are legally compelled to, or if they feel like it. The same is true for Google's services, Microsoft's services, and any other online services that aren't end-to-end encrypted.</p>
<p>This is at the root of the latest attack on encryption:</p>
<p>In February this year, it was reported that <a href="https://www.privacyguides.org/articles/2025/02/28/uk-forced-apple-to-remove-adp/">Apple was served with a notice</a> from the UK's Home Office to force it to break ADP's end-to-end encryption. In response, Apple removed access to ADP from the UK entirely, making this protection unavailable to UK residents.</p>
<p>Do not mistakenly think this attack is limited to the UK and Apple users, however. If this regulation notice or a similar one gets enforced, it would <strong>impact the whole world.</strong> Other countries would likely soon follow, and other services would likely soon get under attack as well.</p>
<p>Moreover, do not feel unaffected just because you use end-to-end encryption with <a href="https://www-svt-se.translate.goog/nyheter/inrikes/signal-lamnar-sverige-om-regeringens-forslag-pa-datalagring-klubbas?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en-US&amp;_x_tr_pto=wapp">Signal</a> or <a href="https://www.techradar.com/vpn/vpn-privacy-security/secure-encryption-and-online-anonymity-are-now-at-risk-in-switzerland-heres-what-you-need-to-know">Proton</a> services instead of Apple, they are both <strong>under attack</strong> as well in this war.</p>
<p>Just in recent years, the war against encryption has affected the <a href="https://www.eff.org/deeplinks/2023/04/earn-it-bill-back-again-seeking-scan-our-messages-and-photos">US</a>, the <a href="https://www.bbc.co.uk/news/articles/cgj54eq4vejo">UK</a>, <a href="https://www.globalencryption.org/2025/04/joint-letter-on-swedish-data-storage-and-access-to-electronic-information-legislation/">Sweden</a>, <a href="https://www.laquadrature.net/en/warondrugslaw/">France</a>, <a href="https://www.theverge.com/2020/10/12/21513212/backdoor-encryption-access-us-canada-australia-new-zealand-uk-india-japan">Australia, New Zealand, Canada, India, Japan</a>, and all the European Union countries with proposals such as <a href="https://www.privacyguides.org/articles/2025/02/03/the-future-of-privacy/#chat-control-wants-to-break-end-to-end-encryption">Chat Control</a>.</p>
<h2 id="the-arguments-given-to-break-encryption-make-no-sense">The arguments given to break encryption make no sense</h2>
<p>Authoritarian entities generally use the same populist excuses to justify their senseless demands. "Protecting the children" is always a fashionable disingenuous argument.</p>
<p>Because no one would disagree that protecting the children is important, it is often used as an attempt to deceitfully make an irrefutable argument to justify breaking encryption.</p>
<p>The problem is, <strong>breaking encryption doesn't protect the children</strong>, it <a href="https://www.theguardian.com/technology/2022/jan/21/end-to-end-encryption-protects-children-says-uk-information-watchdog">endangers</a> them.</p>
<p>When law enforcement officials claim they need to be able to read everyone's messages and see everyone's personal photos to be able to fight child predators, they seem to neglect that:</p>
<ul>
<li>
<p>This means they will expose the children's messages, contact information, locations, and photos in the process, potentially <em>endangering the children further</em>.</p>
</li>
<li>
<p>Exposing everyone's data will make this data much more likely to be found and exploited by criminals, making <em>everyone</em> more vulnerable to attacks.</p>
</li>
<li>
<p>Predators will simply move to underground channels, <a href="https://www.schneier.com/blog/archives/2015/07/back_doors_wont.html">unbothered</a>.</p>
</li>
</ul>
<p>They use the same kind of deceptive argument trying to justify weakening the protections we have to supposedly catch "criminals" and "terrorists".</p>
<p>Of course the exact definition of what is a "criminal" or a "terrorist" is always vague and subject to change. In the past, human rights activists and authoritarian regime dissidents have been labeled as such, climate change activists as well, LGBTQ+ people even in some countries. Maybe next year this label will include "DEI advocates", who knows where they draw the line and what can be considered a "criminal" worth spying on.</p>
<p>You <em>cannot</em> remove everyone's right to privacy and protection from harm while pretending it is to protect them. No one who is well-informed and well-intended could possibly consider this a smart thing to do.</p>
<p><strong>An attack on end-to-end encryption isn't an attack on criminals, it's an attack on all of us.</strong></p>
<h2 id="magical-backdoor-only-for-the-good-guys-is-a-complete-fantasy">Magical backdoor only for "the good guys" is a complete fantasy</h2>
<p>Let's say the strategy is akin to creating a MagicalKey that unlocks every door (a magical key because thinking encryption backdoors would only be used by "the good guys" is a great example of <a href="https://www.britannica.com/science/magical-thinking">magical thinking</a>).</p>
<p>Imagine, for the sake of this exercise, the MagicalLock for this MagicalKey is impossible to pick, and imagine only police officers have MagicalKeys. Let's say one thousand police officers each have a MagicalKey.</p>
<p>They argue they need to be able to unlock anyone's door if they suspect a crime is happening inside. "It's for safety!"</p>
<p>Overtime, let's say only 1% of the police officers accidentally lose their MagicalKey. This kind of things happen. Now 10 MagicalKeys are lost in the wild and could be used by anyone else, for any purposes, including crime.</p>
<p>Then, let's say only 0.1% of police officers get corrupted by a crime gang. That's just one right? This corrupted "good guy" lets the gang create a double of the MagicalKey. Which crime gang wouldn't want a key that can magically open any door? They pay the police officer good money for this. It's an investment.</p>
<p>Now, the gang creates doubles of the MagicalKey they have. They obfuscate its serial number, so it cannot be traced back to them. They use it subtly at first to avoid detection. They make sure they never leave traces behind, so victims have no idea their door got unlocked.</p>
<p>During this time, they steal your data, they sell it, they use it to impersonate you, they use it to harm you and your loved ones.</p>
<p>Then, another criminal figures out on their own how to emulate a MagicalKey without even having access to one. The criminal creates a reproducible mold for this Emulated-MagicalKey and sells it to other criminals on the criminal market. Now, the MagicalKey™️ is available to any criminals looking for it. Restrictions on the backdoor are off. <strong>Your personal data is up for grabs.</strong></p>
<p>This is what is going to happen if backdoors are implemented in end-to-end encryption. But don't worry they say, "it's only for the good guys!".</p>
<p>At least, the criminals' data will also be up for grabs, right?</p>
<p>Nope! The criminals knew about this, so they just started using different channels that weren't impacted. Criminals will have their privacy intact, they don't care about using illegal tools, but <strong>your legal privacy protections will be gone</strong>.</p>
<p><em>Backdoored</em> end-to-end encryption isn't end-to-end anymore, it's just open-ended encryption. This offers pretty much no protection at all.</p>
<h2 id="ignoring-experts-doesnt-make-facts-disappear">Ignoring experts doesn't make facts disappear</h2>
<p>Where is the opposition to this? Where are the experts pushing against this nightmare? Everywhere.</p>
<p>Thankfully, opposition has been strong, despite the relentless ignorance or malevolence from authoritarian authorities repeatedly pushing against encryption.</p>
<p>Many people and groups have been fighting valiantly to defend our collective right to privacy and security. Countless experts have patiently taken the time to explain <a href="https://signal.org/blog/uk-online-safety-bill/">again</a> and <a href="https://www.globalencryption.org/2020/10/cdt-gpd-and-internet-society-reject-time-worn-argument-for-encryption-backdoors/">again</a> and <a href="https://www.schneier.com/wp-content/uploads/2016/09/paper-keys-under-doormats-CSAIL.pdf">again</a> how an encryption backdoor only for "the good guys" is simply impossible.</p>
<p>Weakening encryption to let "the good guys" enter, lets <em>anyone</em> enter, including criminals. There is no way around this.</p>
<p>Seemingly ignoring warnings and advice from the most respected specialists in the field, authoritarian officials continue to push against encryption. So much so that it has become difficult to assume good intent misguided by ignorance at this point.</p>
<p>Unfortunately, ignoring the experts or silencing the debate will not make the facts magically disappear.</p>
<p>In an encouraging development this week, Apple <a href="https://www.bbc.co.uk/news/articles/cvgn1lz3v4no">won a case</a> fighting an attempt from the UK Home Office to hide from the public details of their latest attack on encryption.</p>
<p>This battle and all battles to protect our privacy rights, <em>must</em> be fought is broad daylight, for all to see and to support.</p>
<h2 id="fight-for-encryption-rights-everywhere-you-can">Fight for encryption rights everywhere you can</h2>
<p>The war against encryption isn't anything new, it has been happening for decades. However, the quantity of data, personal and sensitive data, that is collected, stored, and shared about us is much larger today. It is essential we use the proper tools to secure this information.</p>
<p>This is what have changed, and what is making encryption and end-to-end encryption even more indispensable today.</p>
<p>Mass surveillance will not keep us safe, it will endanger us further and damage our democracies and freedoms in irreparable ways.</p>
<p>We must fight to keep our right to privacy, and use of strong end-to-end encryption to protect ourselves, our friends, our family, and yes also to protect the children.</p>
<h3 id="how-can-you-support-the-right-to-encryption">How can you support the right to encryption?</h3>
<ul>
<li>
<p><label><span></span></label> Use end-to-end encryption everywhere you can.</p>
</li>
<li>
<p><label><span></span></label> Talk about the benefits of end-to-end encryption to everyone around you, especially your loved ones less knowledgeable about technology. Talk about how it is essential to protect everyone's data, including the children's.</p>
</li>
<li>
<p><label><span></span></label> Use social media to promote the benefits of end-to-end encryption and post about how it protects us all.</p>
</li>
<li>
<p><label><span></span></label> Write or call your government representatives to let them know you care about end-to-end encryption and are worried about dangerous backdoors or chat control proposals.</p>
</li>
<li>
<p><label><span></span></label> Support organizations fighting for encryption, such as:</p>
<ul>
<li>
<p><a href="https://www.globalencryption.org/">Global Encryption Coalition</a></p>
</li>
<li>
<p><a href="https://www.openrightsgroup.org/campaign/save-encryption/">Open Rights Group</a></p>
</li>
<li>
<p><a href="https://www.makedmssafe.com/">Fight For The Future</a></p>
</li>
<li>
<p><a href="https://signal.org/donate/">Signal app</a></p>
</li>
<li>
<p><a href="https://www.internetsociety.org/open-letters/fix-the-take-it-down-act-to-protect-encryption/">Internet Society</a></p>
</li>
<li>
<p><a href="https://www.eff.org/issues/end-end-encryption">Electronic Frontier Foundation</a></p>
</li>
<li>
<p><a href="https://www.privacyguides.org/en/about/donate/">Privacy Guides</a> 💛</p>
</li>
</ul>
</li>
</ul>
<p>Finally, have a look at our <a href="https://www.privacyguides.org/en/tools/">recommendations</a> if you want to start using more tools protecting your privacy using end-to-end encryption.</p>
<p>This is a long war, but the importance of it doesn't allow us to give up.</p>
<p>We must continue fighting for the right to protect our data with end-to-end encryption, <strong>we owe it to ourselves, our loved ones, and the future generations.</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Intro to DeepSeek's Distributed File System (485 pts)]]></title>
            <link>https://maknee.github.io/blog/2025/3FS-Performance-Journal-1/</link>
            <guid>43716058</guid>
            <pubDate>Thu, 17 Apr 2025 12:50:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maknee.github.io/blog/2025/3FS-Performance-Journal-1/">https://maknee.github.io/blog/2025/3FS-Performance-Journal-1/</a>, See on <a href="https://news.ycombinator.com/item?id=43716058">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <h2 id="series">Series</h2> <ul> <li><a href="https://maknee.github.io/blog/2025/3FS-Performance-Journal-1/">An Intro to DeepSeek’s Distributed File System</a></li> </ul> <h2 id="what-is-3fs">What is 3FS?</h2> <p>3FS (<a href="https://github.com/deepseek-ai/3FS" rel="external nofollow noopener" target="_blank">Fire-Flyer File System</a><span></span><span>Geez, what a tongue twister</span>) is a distributed filesystem released by <a href="https://www.deepseek.com/" rel="external nofollow noopener" target="_blank">DeepSeek</a> during their <a href="https://github.com/deepseek-ai/open-infra-index" rel="external nofollow noopener" target="_blank">open source release week</a>. This blog post will dive into what distributed file systems are and how 3FS operates, starting with some background.</p> <h2 id="what-is-a-distributed-filesystem">What is a distributed filesystem?</h2> <p>Distributed filesystems trick applications into thinking they’re talking to a regular local filesystem. This abstraction is incredibly powerful: a file that’s actually fragmented across 10 different machines appears as a simple file path like <code>/3fs/stage/notes.txt</code></p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/part1/local_distributed_fs.svg" alt=""></p><p><em>Using the distributed filesystem is no different than local filesystem </em> </p> </div> <p>In the image above, I create the same folder and file on a local and distributed filesystem by running <code>mkdir</code> and <code>cat</code>. The commands are exactly the same. With a distributed filesystem, all of those details are abstracted away from the user, who can simply work with the files without worrying about how many machines, network calls or disks are involved behind the scene.</p> <h2 id="why-use-a-distributed-filesystem">Why use a distributed filesystem?</h2> <p>Distributed filesystems provide two main advantages over local storage – they can serve massive amounts of data (up to petabytes) and provide high throughput that exceed the capabilities of a single machine. They offer fault tolerance (the system keeps running if one machine goes down) and redundancy (if data gets corrupted on one node, other nodes have original copies).</p> <p>Distributed filesystems are used in many practical applications:</p> <ul> <li>Parallel processing frameworks (<a href="https://hadoop.apache.org/" rel="external nofollow noopener" target="_blank">HDFS</a> supporting <a href="https://www.databricks.com/blog/2014/01/21/spark-and-hadoop.html" rel="external nofollow noopener" target="_blank">Spark</a>)</li> <li>ML training pipelines with <a href="https://github.com/stas00/ml-engineering/blob/master/storage/README.md" rel="external nofollow noopener" target="_blank">Dataloaders and checkpointing</a> </li> <li>Internal large-scale code/data repositories supported by <a href="https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system" rel="external nofollow noopener" target="_blank">Google’s Colossus</a> </li> <li>Industry applications like <a href="https://juicefs.com/en/blog/user-stories/juicefs-vs-cephfs-distributed-file-system-artificial-intelligence-storage" rel="external nofollow noopener" target="_blank">Traveling</a> </li> <li>Photo storage is served by <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf" rel="external nofollow noopener" target="_blank">Meta’s Haystack</a> </li> </ul> <h2 id="a-deep-dive-into-3fs">A deep dive into 3FS</h2> <p>So, how does 3FS work?</p> <p>At its core, 3FS consists of four primary node types:</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/overview.svg" alt=""></p><p><em>Components involved in 3FS </em> </p> </div> <p>The components serve distinct purposes:</p> <ol> <li> <strong>Meta</strong> – manage the metadata: file locations, properties, paths, etc.</li> <li> <strong>Mgmtd</strong> – management server controls the cluster configuration: where are other nodes, which nodes are alive, and replication factor <ul> <li>Think of it as a router that knows every node’s address and can help nodes find each other<span></span><span>A similar analogy is the centralized server used in <a href="https://en.wikipedia.org/wiki/Hole_punching_(networking)" rel="external nofollow noopener" target="_blank">NAT hole punching</a></span>.</li> </ul> </li> <li> <strong>Storage</strong> – nodes that hold the actual file data on physical disks.</li> <li> <strong>Client</strong> – communicates with all other nodes to view and modify the filesystem: <ul> <li>ask Mgmtd to discover other nodes</li> <li>ask Meta servers to perform file operations (open, stat, close, symlink)</li> <li>transfer data with storage nodes</li> </ul> </li> </ol> <p>Now let’s look at each component in greater detail.</p> <h2 id="mgmtd">Mgmtd</h2> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/mgmtd_register.svg" alt=""></p><p><em>Mgmtd Registering </em> </p> </div> <p>Mgmtd tracks what nodes are running in the cluster. Storage and meta nodes register when they boot up, sending periodic heartbeats to confirm they’re still alive. This gives a central view of the system – one can immediately identify which nodes are down.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/mgmtd_request.svg" alt=""></p><p><em>Mgmtd Requests </em> </p> </div> <p>Nodes don’t need to maintain connections with every other node in the network. Instead, they can discover nodes by querying the mgmtd node. While this adds an extra round trip when locating nodes, it can reduce complexity since node discovery isn’t static.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/mgmtd_chain.svg" alt=""></p><p><em>Mgmtd Chains </em> </p> </div> <p>Also, Mgmtd maintains the configuration for different nodes operating within a distributed algorithm. In particular, replicated chains (<a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf" rel="external nofollow noopener" target="_blank">CRAQ</a><span></span><span>CRAQ is a pretty neat algorithm that achieves strong consistency with fault tolerance by treating nodes as a chain. I’ll explain this in depth in another section.</span>) are established and its nodes are stored as configuration in mgmtd.</p>  <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/meta_overview.svg" alt=""></p><p><em>Meta overview </em> </p> </div> <p>The meta node is a bit more complex than mgmtd. Clients communicate with it via RPC calls. The meta server performs typical filesystem operations (open, create, stat, unlink) on the metastore. File metadata resides in inodes, storing properties like size, permissions, owner, and timestamps. DirEntry objects map paths to inodes, with multiple DirEntries possible for a single file (similar to symlinks). Both inodes and DirEntries are stored in FoundationDB<span></span><span>One might wonder what the keys to founationdb look like? Inode: “INOD + inode id, dir entry: “DENT” + nodeid + path</span> using transactions for idempotent operations. A session manager tracks open files, storing file sessions in FoundationDB. If clients disconnect without closing files, the session manager initiates file syncs. File deletion requests queue to a garbage collector, which removes data from storage nodes before deleting directory entries and inodes.</p> <h2 id="storage">Storage</h2> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/explain/storage_overview.svg" alt=""></p><p><em>Storage overview </em> </p> </div> <p>The storage node’s main function is manage data on physical storage by breaking it up into chunks:</p> <ul> <li>The Rust ChunkEngine<span></span><span>Why Rust? Well, there’s a legacy chunk manager named <code>ChunkStore</code> that’s written in C++. I don’t see really why in rust, probably because it’s interesting to work in and provides more safety guarantees</span> keeps track of blocks of disk storage. <ul> <li>Chunks represent a piece of physical disk and keeps track of its metadata (id, size, offset on disk, physical disk, checksums, versions, …). This is the most primitive data structure that all other structures use to keep track of blocks of data.</li> <li>The chunk engine doesn’t allow users to interact with chunks directly since it would add complexity to using engine. The interface to the engine has operations which gives users a rigid and clear way to interact with the engine (lookup, allocation, commit, metadata…)</li> <li>By default, all of this is stored in <a href="https://github.com/google/leveldb" rel="external nofollow noopener" target="_blank">LevelDB</a> with a prefix byte repesenting the type of operation (querying the metadata) and the chunk id as the key.</li> </ul> </li> <li>There are different workers that uses the chunk engine to maintain the physical storage <ul> <li>The AllocateWorker allocates new chunks in the chunk engine</li> <li>The PunchHoleWorker reclaims chunks if they’re no longer used</li> <li>The AioReadWorker processes reads requests to the chunks and queues reads in <a href="https://en.wikipedia.org/wiki/Io_uring" rel="external nofollow noopener" target="_blank">io_uring</a> queue, submits and waits for completion<span></span><span>Initially, I was surprised. The chunk engine doesn’t perform operations on the actual physical disk, it really only manages the metadata. One reason for this might be to keep the ChunkEngine implementation rather lean by having it only try to manage metadata.</span>.</li> </ul> </li> <li>The storage node needs to know how to forward a write to the next target in a CRAQ chain<span></span><span>For now, just know that writes need to be forwarded to other nodes</span> <ul> <li>Targets consist of chunks (think of this as logical store containing different chunks)</li> <li>A chain consists of multiple targets (typically spanning multiple nodes)</li> <li>The storage node queries the mgmtd server for other nodes’ chains and the corresponding targets (nodes) in that chain that a write needs to forward to.</li> </ul> </li> </ul> <h2 id="craq">CRAQ</h2> <p>CRAQ (<a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf" rel="external nofollow noopener" target="_blank">Chain Replication with Apportioned Queries</a>) is a protocol for achieving strong consistency with linearizability. It serves as the core mechanism to keep data chunks fault-tolerant. I’ll explain how CRAQ works and then, show its implementation in 3FS.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/craq/craq_write_dirty.svg" alt=""></p><p><em>Craq write propagation </em> </p> </div> <p>Writes begin at the head. In our example, we write <code>name=henry</code> to the system. As the write moves down the chain, each entry is marked as “dirty” with a version number. Dirty entries aren’t safe to read. Once the write reaches the tail, it’s committed and marked as “clean”.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/craq/craq_write_clean.svg" alt=""></p><p><em>Craq write commit </em> </p> </div> <p>Writes become clean as commit messages propagates backward from tail to head. Each node commits the entry and marks it clean.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/craq/craq_read_clean.svg" alt=""></p><p><em>Craq clean read </em> </p> </div> <p>For reads, the process is straightforward: if an object is clean, it’s immediately returned to the client.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/craq/craq_read_dirty.svg" alt=""></p><p><em>Craq dirty read </em> </p> </div> <p>The challenge occurs with dirty objects. Each chain tracks both dirty and clean versions. Since the tail always contains the latest committed data, the replica queries the tail for the most recent committed object, ensuring strong consistency.</p> <h3 id="craq-performance">CRAQ performance</h3> <p>CRAQ read and write performance varies by workload. Write throughput and latency are limited by the slowest node in the chain, as writes must process through each node sequentially. For example, in <a href="https://en.wikipedia.org/wiki/Zipf%27s_law" rel="external nofollow noopener" target="_blank">zipfian</a> workloads (where frequently accessed data dominates), read performance suffers because objects may be dirty, forcing queries to the tail node. This creates a bottleneck as the tail must serve most of the read requests.</p> <h3 id="how-is-craq-used-in-3fs">How is CRAQ used in 3FS</h3> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/craq/craq_stripe.svg" alt=""></p><p><em>Storage is striped and CRAQ runs ontop </em> </p> </div> <p>In this example, 5 nodes with 5 SSDs each form the cluster. Storage targets replicate to 3 nodes, designed to avoid overlap so that node failures don’t affect overall throughput significantly<span></span><span>Consider an extreme scenario where all the chains are placed on nodes 1, 2, 3. If node 1 fails, the distributed system would serve lose 1/3 of the total throughput instead of 1/5 of total throughput shown in the above image. <a href="https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/docs/design_notes.md" rel="external nofollow noopener" target="_blank">3FS design notes</a> shows an example with a deeper explanation.</span>. CRAQ operates on top, managing head, middle, and tail nodes.</p> <p>3FS defaults to strongly consistent reads. Writes flow from head to tail and back, with throughput limited by the slowest node and latency determined by the combined latency across all chain nodes.</p> <div> <p><img loading="lazy" src="https://maknee.github.io/assets/images/posts/2025-03-13/papers/ionia-table-1.svg" width="100%" alt=""></p> </div> <p>As shown in the comparison table, in the common case, CRAQ delivers scalable, low-latency reads at the cost of high write latency compared to other protocols and systems.</p> <h2 id="other-distributed-filesystems">Other distributed filesystems</h2> <p>One might ask – is this architecture different from other distributed filesystems? At a high level, the components are familiar – some notion of client, metadata, storage, and management nodes appear in virtually every distributed system.</p> <p>The difference lies in its real-world applicability and practical implementation:</p> <ul> <li>which workloads it excels at handling</li> <li>its tuning flexibility</li> <li>deployment simplicity</li> <li>throughput scaling capabilities</li> <li>maintaining latency within SLOs</li> <li>reliability</li> </ul> <p>and its finer technical details that determines its usability:</p> <ul> <li>what bottlenecks are there</li> <li>how it manages bottlenecks</li> <li>its approach to locking (or absence thereof)</li> <li>the specific data structures employed</li> <li>the hardware the software was designed for</li> <li>what fault tolerant algorithm or erasure coding is used</li> </ul> <h2 id="rest-of-the-blog-series">Rest of the blog series</h2> <p>With that in mind, I want to dive deep into analyzing the performance of this relatively new open-source distributed filesystem<span></span><span>Distributed filesystems come once in blue moon, taking <a href="https://dl.acm.org/doi/10.1145/3341301.3359656" rel="external nofollow noopener" target="_blank">several years to develop</a></span>. Current benchmarks are rather limited. There’s no comparisons with single-node systems and other distributed filesystems, so it’s difficult to gauge how well 3FS performs.</p> <p>Some questions I want to explore:</p> <ul> <li>Do some of the DeepSeek’s claims hold up, especially regarding <a href="https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/docs/design_notes.md#limitations-of-fuse" rel="external nofollow noopener" target="_blank">FUSE bottlenecks</a>?</li> <li>Can I reproduce their performance graphs in some way?</li> <li>In what scenario does the performance degrade?</li> <li>What are the system’s bottlenecks (CPU/memory/disk/network)?</li> <li>In what types of workloads does the fileysystem excel at?</li> <li>How does it compare with other distributed filesystems?</li> <li>How does it address problems that existing systems face?</li> <li>Am I able to make any improvements to the system?</li> </ul> <p>Throughout the rest of the series, I will be going through the process of making initial assumptions, testing them, and learning from discrepancies to develop a deeper understanding of how 3FS actually performs.</p> <h2 id="more-reading">More reading</h2> <p>Implementation details are documented in the <a href="https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/docs/design_notes.md" rel="external nofollow noopener" target="_blank">design notes</a>.</p> <p>Additional technical documentation regarding early implementation phases is available (in Chinese):</p> <ul> <li><a href="https://www.high-flyer.cn/blog/3fs/" rel="external nofollow noopener" target="_blank">Intro</a></li> <li><a href="https://www.high-flyer.cn/blog/3fs-1/" rel="external nofollow noopener" target="_blank">Async IO</a></li> <li><a href="https://www.high-flyer.cn/blog/3fs-3/" rel="external nofollow noopener" target="_blank">RDMA Read</a></li> <li><a href="https://www.high-flyer.cn/blog/3fs-3/" rel="external nofollow noopener" target="_blank">Network routing</a></li> <li><a href="https://www.high-flyer.cn/blog/3fs-4/" rel="external nofollow noopener" target="_blank">Load balancing reads</a></li> </ul> <p>The system architecture is partially documented in <a href="https://arxiv.org/abs/2408.14158" rel="external nofollow noopener" target="_blank">the Fire-Flyer AI-HPC paper</a>.</p> <h2 id="acknowledgments">Acknowledgments</h2> <p>Thanks to <a href="https://vimarsh.me/" rel="external nofollow noopener" target="_blank">Vimarsh Sathia</a> for reviewing this post.</p> </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord's face scanning age checks 'start of a bigger shift' (160 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cjr75wypg0vo</link>
            <guid>43715884</guid>
            <pubDate>Thu, 17 Apr 2025 12:34:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cjr75wypg0vo">https://www.bbc.com/news/articles/cjr75wypg0vo</a>, See on <a href="https://news.ycombinator.com/item?id=43715884">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline-new" data-component="byline-block"><p><span>Imran Rahman-Jones &amp; Chris Vallance</span></p><p><span>Technology reporters</span></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250409-091508-0ef9b7676-web-2.19.1-12/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/efe0/live/38684c70-1b6d-11f0-b405-a9063c038ff6.jpg.webp" loading="eager" alt="Getty Images Profile of a child looking at a phone, the screen lights up his face"><span>Getty Images</span></p></div></figure><div data-component="text-block"><p>Discord is testing face scanning to verify some users' ages in the UK and Australia.</p><p>The social platform, which says it has over 200 million monthly users around the world, was initially used by gamers but now has communities on a wide range of topics including pornography.</p><p>The UK's online safety laws mean platforms with adult content will need to have "robust" age verification <a target="_self" href="https://www.bbc.co.uk/news/articles/cwye3qw7gv7o">in place by July</a>.</p><p>And social media expert Matt Navarra told the BBC "this isn't a one-off - it's the start of a bigger shift".</p><p>"Regulators want real proof, and facial recognition might be the fastest route there," he said.</p></div><div data-component="text-block"><p>But campaigners have said these types of checks are ineffective and could lead to privacy issues.</p><p>"Age assurance is becoming the new seatbelt for the internet," said Mr Navarra. </p><p>"Will it become the norm in the UK? Honestly, yes, probably."</p><p>He said he believed the incoming changes in online safety laws mean online platforms would beef up their age verification processes.</p><p>"The era of 'click here to confirm you're 13' is dead," he said.</p><p>"Get age verification wrong now, and you don't just lose users - you could lose a courtroom battle or incur fines."</p><p>Firms which do not comply with the Online Safety Act could be fined up to 10% of their global turnover.</p><p>Instagram previously brought in <a target="_self" href="https://www.bbc.co.uk/news/technology-61828900">age checks using facial analysis</a> in 2022 for users who want to change their profile settings to be over 18. </p><p>The social media company requires users to take a selfie video on their phone and uses AI to estimate the person's age. </p><p>Like Discord, they can alternatively upload a picture of their photo ID.</p></div><div data-component="text-block"><p>The US-based platform says the verification - which it describes as "an experiment" - will be a one-time check.</p><p>It will apply the first time a user comes across content which it has flagged as sensitive, or if they change their settings on viewing sensitive media.</p><p>Users can either use the face scanner or upload a photo of their ID to confirm their age.</p><p>It says information used for age checks will not be stored by Discord or the verification company. </p><p>Face scans will stay on the device and not be collected, and ID uploads will be deleted after the verification is complete, <a target="_blank" href="https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Verify-Age-Group">according to the company</a>.</p><p>Content which is flagged as sensitive is already automatically blocked or blurred for teenagers.</p></div><p data-component="subheadline-block"><h2>'No silver bullet'</h2></p><div data-component="text-block"><p>Privacy campaign group Big Brother Watch says age check technology "shouldn't be seen as a silver bullet solution".</p><p>Senior advocacy officer Madeleine Stone says they can pose a risk to users, "including security breaches, privacy intrusion, errors, digital exclusion and censorship".</p><p>While industry group the Age Verification Providers Association says there is a "wide range of convenient, privacy-preserving methods".</p><p>Their executive director Iain Corby told the BBC the latest technology can estimate age "within one to two years based on a selfie or how you move your hands".</p><p>But he also said platforms have a choice on how to use age verification.</p><p>"They can remove the harmful content altogether, apply age checks to access the whole site, or just check ages before allowing access to high-risk pages and posts," he said.</p><p>Australia is planning to bring in a social media ban for all under-16s this year. </p><p><a target="_self" href="https://www.bbc.co.uk/news/articles/clyz65p1k45o">Recent research</a> found more than 80% of Australian children aged eight to 12 use social media or messaging services that are only meant to be for over-13s</p><p>New Jersey attorney general Matthew J. Platkin said on Thursday that his office was suing Discord, alleging the company had misled parents about its safety controls and the risks faced by children on the app.</p><p>Discord was approached for comment.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cutting down Rust compile times from 30 to 2 minutes with one thousand crates (132 pts)]]></title>
            <link>https://www.feldera.com/blog/cutting-down-rust-compile-times-from-30-to-2-minutes-with-one-thousand-crates</link>
            <guid>43715235</guid>
            <pubDate>Thu, 17 Apr 2025 11:22:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.feldera.com/blog/cutting-down-rust-compile-times-from-30-to-2-minutes-with-one-thousand-crates">https://www.feldera.com/blog/cutting-down-rust-compile-times-from-30-to-2-minutes-with-one-thousand-crates</a>, See on <a href="https://news.ycombinator.com/item?id=43715235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="6377682eae43">Rust is fast at runtime — but not so much at compile time. That’s hardly news to anyone who's worked on a serious Rust codebase. There's a whole genre of blog posts dedicated to shaving seconds off <code>cargo build</code>.</p><p id="02396083fc04">At Feldera, we let users write SQL to define tables and views. Under the hood, we compile that SQL into Rust code — which is then compiled with <code>rustc</code> to a single binary that <em>incrementally</em> maintains all views as new data streams into tables.</p><p id="e41db72a2add">We’ve already pulled a lot of tricks in the past to speed up compilation: type erasure, aggressive code deduplication, limiting codegen lines. And that got us quite far. However, recently we started on-boarding a new, large enterprise client with fairly complicated SQL. They wrote many, very large programs with Feldera. For example, one of them was 8562 lines of SQL code that eventually is translated to ~100k lines of Rust code by the Feldera SQL-to-Rust compiler.</p><p id="bdcd93336be9">To be clear, this isn’t some massive monolith we’re compiling. We’re talking about ~100k lines of generated Rust. That’s peanuts compared to something like the Linux kernel — 40 million lines (which manages to compile in a few minutes).</p><p id="c7db6351896a">And yet… this one program was taking around 25 minutes to compile on my machine. Worse, on our customer's setup it took about 45 minutes. And this was after we already switched the code that is generated to <a href="https://github.com/feldera/feldera/pull/1516">using dynamic dispatch and pretty much eliminated all monomorphization</a>.</p><p id="62ab9a17db22">Here's the log from the Feldera manager:</p><div><pre><code><span>[manager] SQL compilation success: pipeline 0196268e-7f98-7de3-b728-0ee339e449fa (program version: 2) (took 101.94s)
</span><span>[manager] Rust compilation success: pipeline 0196268e-7f98-7de3-b728-0ee339e449fa (program version: 2) (took 1617.77s; </span><span>source</span><span> checksum: cbffcb959174; integrity checksum: 709a17251475)</span></code></pre></div><p id="9d36881229c1">Almost all the time is spent compiling Rust. The SQL-to-Rust translation takes about 1m40s. Even worse, the Rust build is doing the equivalent of a <code>release</code> build in <code>cargo</code>, so it happens from scratch every time (except for cargo crate dependencies which are already cached/re-used in the times we give here). Even the tiniest change in the input SQL kicks off a full rebuild of that giant program.</p><p id="b07f172716e7">Of course, we tried debug builds too. Those cut the time down to ~5 minutes — but they’re not usable in practice. Our customers care about actual runtime performance: when the SQL code type-checks, they already know the Rust code will compile successfully and they're running real-time data pipelines and want to see end-to-end latency and throughput. Debug builds are just too slow and misleading for that.</p><h3 id="9b2e079a5221">What's happening?</h3><p id="b2b0e71fd4cf">Here’s the frustrating part.</p><p id="be3154016cc8">We're using <code>rustc</code> v1.83, and despite having a 64-core machine with 128 threads, Rust barely puts any of them to work. This becomes evident quickly when looking at <code>htop</code> during the compliation:</p><p><img alt="An idle machine as seen in htop" loading="lazy" width="2178" height="278" decoding="async" data-nimg="1" srcset="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4ad1b4f49c929971aefe2dbcea6ea2be94b0c5cf-2178x278.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4ad1b4f49c929971aefe2dbcea6ea2be94b0c5cf-2178x278.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"></p><p id="f9a1e3025e9d">That’s right. One core at 100%, and the rest are asleep.</p><p id="5f83f3387dc6">We can instrument the compilation of this crate by passing <code>-Ztime-passes</code> to <code>RUSTFLAGS</code><br>(this requires recompilation with nightly). It reveals that the majority of time is spent in LLVM passes and codegen – which unfortunately are single-threaded:</p><div><pre><code><span>time:   0.346; rss:   38MB -&gt;  342MB ( +304MB)	parse_crate
</span>time:   0.000; rss:  344MB -&gt;  345MB (   +1MB)	crate_injection
<!-- -->time:   5.286; rss:  345MB -&gt; 1607MB (+1262MB)	expand_crate
<!-- -->time:   5.287; rss:  345MB -&gt; 1607MB (+1262MB)	macro_expand_crate
<!-- -->time:   0.091; rss: 1607MB -&gt; 1607MB (   +0MB)	AST_validation
<!-- -->time:   0.002; rss: 1607MB -&gt; 1608MB (   +1MB)	finalize_imports
<!-- -->time:   0.029; rss: 1608MB -&gt; 1608MB (   +0MB) finalize_macro_resolutions
<!-- -->time:   2.382; rss: 1608MB -&gt; 1937MB ( +329MB)	late_resolve_crate
<!-- -->time:   0.071; rss: 1937MB -&gt; 1938MB (   +1MB)	resolve_check_unused
<!-- -->time:   0.138; rss: 1938MB -&gt; 1938MB (   +0MB)	resolve_postprocess
<!-- -->time:   2.627; rss: 1607MB -&gt; 1938MB ( +331MB)	resolve_crate
<!-- -->time:   0.069; rss: 1940MB -&gt; 1940MB (   +0MB)	write_dep_info
<!-- -->time:   0.070; rss: 1940MB -&gt; 1940MB (   +0MB)	complete_gated_feature_checking
<!-- -->time:   0.217; rss: 2790MB -&gt; 2651MB ( -139MB)	drop_ast
<!-- -->time:   3.361; rss: 1940MB -&gt; 2353MB ( +414MB)	looking_for_entry_point
<!-- -->time:   3.961; rss: 1940MB -&gt; 2346MB ( +407MB)	misc_checking_1
<!-- -->time:   6.301; rss: 2346MB -&gt; 2007MB ( -339MB)	coherence_checking
<!-- -->time:  44.158; rss: 2346MB -&gt; 3061MB ( +714MB)	type_check_crate
<!-- -->time:  18.773; rss: 3061MB -&gt; 5024MB (+1963MB)	MIR_borrow_checking
<!-- -->time:   4.650; rss: 5024MB -&gt; 5241MB ( +217MB)	MIR_effect_checking
<!-- -->time:   0.360; rss: 5243MB -&gt; 5255MB (  +12MB)	module_lints
<!-- -->time:   0.360; rss: 5243MB -&gt; 5255MB (  +12MB)	lint_checking
<!-- -->time:   0.947; rss: 5255MB -&gt; 5254MB (   -1MB)	privacy_checking_modules
<!-- -->time:   1.587; rss: 5241MB -&gt; 5254MB (  +13MB)	misc_checking_3
<!-- -->time:   0.259; rss: 5254MB -&gt; 5249MB (   -5MB)	monomorphization_collector_root_collections
<!-- -->time:  54.766; rss: 5249MB -&gt; 7998MB (+2749MB)	monomorphization_collector_graph_walk
<!-- -->time:   6.086; rss: 8010MB -&gt; 8565MB ( +554MB)	partition_and_assert_distinct_symbols
<!-- -->time:   0.000; rss: 8414MB -&gt; 8415MB (   +1MB)	write_allocator_module
<!-- -->time:  35.220; rss: 8415MB -&gt; 18037MB (+9622MB)	codegen_to_LLVM_IR
<!-- -->time:  96.733; rss: 5254MB -&gt; 18037MB (+12783MB)	codegen_crate
<!-- -->time: 1333.423; rss: 10070MB -&gt; 3176MB (-6893MB)	LLVM_passes
<!-- -->time: 1303.074; rss: 13594MB -&gt;  756MB (-12837MB)	finish_ongoing_codegen
<!-- -->time:   1.091; rss:  756MB -&gt;  756MB (   +0MB)	run_linker
<!-- -->time:   0.105; rss:  755MB -&gt;  755MB (   +0MB)	link_binary_remove_temps
<!-- -->time:   1.217; rss:  756MB -&gt;  755MB (   -1MB)	link_binary
<!-- -->time:   1.218; rss:  756MB -&gt;  754MB (   -2MB)	link_crate
<!-- -->time:   1.218; rss:  756MB -&gt;  754MB (   -2MB)	link
<!-- -->time: 1483.483; rss:   26MB -&gt;  514MB ( +487MB)	total</code></pre></div><p id="40cfea5410b6">Sometimes during these 30 minutes, Rust will spin up a few threads — maybe 3 or 4 — but it never fully utilizes the machine. Not even close.</p><p><img alt="A mostly idle machine as seen in htop." loading="lazy" width="2186" height="337" decoding="async" data-nimg="1" srcset="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2Fe37cfdd37c5d073d1e453aacdd72aa4c6f2e4536-2186x337.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2Fe37cfdd37c5d073d1e453aacdd72aa4c6f2e4536-2186x337.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"></p><p id="823efbfa34a8">I get it: parallelizing compilation is hard. But this isn’t some edge-case, looking at it ourselves we clearly saw enough opportunities to parallelize compilation in this program.</p><p id="59edc3947df1">Note aside: You might wonder what about increasing <code>codegen-units</code> in <code>Cargo.toml</code>? Wouldn't that speed up these passes? In our experience, it didn't matter: It was set to the default of <code>16</code> for reported times, but we also tried values like <code>256</code> with the default LTO configuration (thin local LTO). That was somewhat confusing (as a non <code>rustc</code> expert). I'd love to read an explanation for this.</p><h3 id="c18869ee48d8">What can we do about it?</h3><p id="b1674d3c3bad">Instead of emitting one giant crate containing everything, we tweaked our SQL-to-Rust compiler to split the output into many smaller crates. Each one encapsulating just a portion of the logic, neatly depending on each other, with a single top-level <code>main</code> crate pulling them all in.</p><p id="83530a42de5d">The results were spectacular. Here's the same htop view after the change during compilation:</p><p><img alt="A very busy machine as seen in htop." loading="lazy" width="1988" height="597" decoding="async" data-nimg="1" srcset="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=2048&amp;q=75 1x, https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"></p><p id="ced6546b5936">Beautiful. All the CPUs are now fully utilized all the time.<br>And it shows: The time to compile the rust program is down to <code>2m10s</code>!</p><div><pre><code><span>[manager] Rust compilation success: pipeline 01962739-79fd-7f03-bbf2-f8e29ce21e1d (program version: 2) (took 150.24s; </span><span>source</span><span> checksum: 0336f3eb9dc1; integrity checksum: 6051bcde6674)</span></code></pre></div><h3 id="c96c60914a6b">How did we fix it?</h3><p id="e0b8dc7a2d0a">In most Rust projects, splitting logic across dozens (or hundreds) of crates is impractical at best, a nightmare at worst. But in our case, it was surprisingly straightforward — thanks to how Feldera works under the hood.</p><p id="27c962ee9c29">When a user writes SQL in Feldera, we translate it into a dataflow graph: nodes are operators that transform data, and edges represent how data flows between them. Here's a small fragment of such a graph:</p><p><img alt="A feldera dataflow graph." loading="lazy" width="2340" height="1054" decoding="async" data-nimg="1" srcset="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4f4b876178bc8de1d7ecc52e6ae87388bef5f87c-2340x1054.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://www.feldera.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4f4b876178bc8de1d7ecc52e6ae87388bef5f87c-2340x1054.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"></p><p id="73d2c85fd7b0">Since the Rust code is entirely auto-generated from this structure, we had total control over how to split it up.</p><p id="00b41bb3ad0e">Each operator becomes its own crate. Each crate exports a single function that builds one specific piece of the dataflow. They all follow the same predictable shape. The top-level main crate just wires them together.</p><div><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>create_operator_0097dd9de75ffef3</span><span>(circuit: &amp;RootCircuit,catalog: &amp;</span><span>mut</span><span> Catalog,
</span><span>    i0: &amp;Stream&lt;RootCircuit, IndexedWSet&lt;Tup1&lt;</span><span>i32</span><span>&gt;, Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt;,
</span><span>    i1: &amp;Stream&lt;RootCircuit, IndexedWSet&lt;Tup1&lt;</span><span>i32</span><span>&gt;, Tup0&gt;&gt;,
</span><span>) -&gt; Stream&lt;RootCircuit, WSet&lt;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt;{
</span><span>    </span><span>let</span><span> operator_0097dd9de75ffef3: Stream&lt;RootCircuit, WSet&lt;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt; = i0.join(&amp;i1, </span><span>move</span><span> |p0: &amp;Tup1&lt;</span><span>i32</span><span>&gt;, p1: &amp;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;, p2: &amp;Tup0, | -&gt;
</span><span>    Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt; {
</span>        Tup5::new(
<span>            (*p1).</span><span>0</span><span>,
</span><span>            (*p1).</span><span>1</span><span>.clone(),
</span><span>            (*p1).</span><span>2</span><span>,
</span><span>            (*p1).</span><span>3</span><span>,
</span><span>            (*p1).</span><span>4</span><span>.as_ref().cloned())
</span>    });
<!-- -->
<span>    </span><span>return</span><span> operator_0097dd9de75ffef3;
</span>}</code></pre></div><p id="4a48effaca5c">We still need to figure out how to name these crates. A simple but powerful method is to hash the rust code they contain and use that as the name of the crate.</p><p id="518c33abc16f">This ensures two things:</p><p id="701eb3b4f117">a. We have unique crate names.<br>b. More importantly: incremental changes to the SQL become incredibly effective</p><p id="5c98a73fdfee">Imagine the user tweaks the SQL code just slightly. What happens is that most of the operators (and their crates) stay identical (the hash doesn't change), and <code>rustc</code> can re-use most of the previously compiled artifacts. Any new code that gets added due to the change will end up generating a new crate (with a different hash).</p><p id="f345bdad021c">So how many crates are we talking about for that monster SQL program?</p><p id="63cc77228713">Let’s peek into the compiler directory inside the feldera container:</p><div><pre><code><span>ubuntu@12e1de52de1b:~/.feldera/compiler/rust-compilation$ ls crates/
</span>feldera_pipe_operator_000cb1599cb60b91  feldera_pipe_operator_4aab3e223e4ddcf9  feldera_pipe_operator_8d1f38d0358deacf  feldera_pipe_operator_d8058d2f87a41ca0
<!-- -->feldera_pipe_operator_004093943841ab45  feldera_pipe_operator_4ae3aa1446d98a19  feldera_pipe_operator_8d30ed71269c765f  feldera_pipe_operator_d841ffa208faa462
<!-- -->feldera_pipe_operator_004675554aea30aa  feldera_pipe_operator_4aff1d1e8d2a6a9a  feldera_pipe_operator_8e25b73d54f6491e  feldera_pipe_operator_d88bab492aa0c8f5
<!-- -->feldera_pipe_operator_008ba4153ded3848  feldera_pipe_operator_4b3575ba2e10dad3  feldera_pipe_operator_8e667e68984170e5  feldera_pipe_operator_d8a43a536535a38d
<!-- -->feldera_pipe_operator_00bee114a0d5eb4c  feldera_pipe_operator_4b5370144b5268ae  feldera_pipe_operator_8eb1e7460e7376f9  feldera_pipe_operator_d8c6422350e6e8fe
<!-- -->feldera_pipe_operator_00d71fa11f791e35  feldera_pipe_operator_4b5d1c560b048f22  feldera_pipe_operator_8edfa111c7ed57b6  feldera_pipe_operator_d968b48784b4f7af
<!-- -->...</code></pre></div><p id="486287d5ca1b">And then:</p><div><pre><code><span>ubuntu@12e1de52de1b:~/.feldera/compiler/rust-compilation$ ls crates/ | wc -l
</span>1106</code></pre></div><p id="2a83bc06cf7c">That’s right — 1,106 crates!</p><p id="40bb695dd76f">Sounds excessive? Maybe. But in the end this is what makes <code>rustc</code> much more effective.</p><h3 id="2bbef1c62ee3">Are we done?</h3><p id="109df12cafcb">Unfortunately, not quite. There are still some mysteries here. Given that we now fully utilize 128 threads or 64 cores for pretty much the entire compile time, we can do a back of the envelope calculation for how long it should take: <code>25 min / 128 = 12 sec</code> (or maybe <code>24 sec</code> since hyper-threads aren't real cores). Yet it takes <code>170s</code> to compile everything. Of course, we can't expect linear speed-up in practice, but still <code>7x</code> slower than that seems excessive (these are all just parallel <code>rustc</code> invocation that run independently). Similar slowdowns also happen on laptop grade machines with much less memory and cores, so it doesn't just affect very large machines.</p><p id="4fe949abbce6">Here are some thoughts on what <em>might</em> be happening, but we'd be happy to hear some more opinions on this:</p><ul><li>Contention on hardware resources (the system has more than enough memory but it might contend on caches)</li><li>The file-system is a bottleneck (doubt it since we also tried running this on a RAM-FS and it didn't make a difference, but it could be contending on locks in the file-system code in the kernel)</li><li>Compiling each of the 1k crates now performs some steps many times that get amortized when using a single crate (true, but the slowdown doesn't happen if we compile with <code>-j1</code>, the individual crate compile times are much faster as long as they happen in sequence)</li><li>Linking is the bottleneck now since we added 1k crates? We use <code>mold</code> and we see the total link time is only around <code>7 sec</code>.</li></ul><h3 id="9a8832de1ebc">Conclusion</h3><p id="9c07947dc521">By simply changing how we generate Rust code under the hood, we’ve made Feldera’s compile times scale with your hardware instead of fighting it. What used to take 30–45 minutes now compiles in under 3 minutes, even for complex enterprise-scale SQL.</p><p id="30222fc0034b">If you’re already pushing Feldera to its limits: thank you. Your workloads help us make the system better for everyone.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Government threatens Harvard with foreign student ban (339 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c1egdy24v7po</link>
            <guid>43715022</guid>
            <pubDate>Thu, 17 Apr 2025 10:42:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c1egdy24v7po">https://www.bbc.com/news/articles/c1egdy24v7po</a>, See on <a href="https://news.ycombinator.com/item?id=43715022">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250409-091508-0ef9b7676-web-2.19.1-12/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp" loading="eager" alt="Getty Images Pedestrians enter the Harvard University campus in Cambridge, Massachusetts, US, on Wednesday, April 16, 2025"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Harvard President Alan Garber has flatly rejected the White House's sweeping list of demands </figcaption></p></figure><div data-component="text-block"><p>The US government has threatened to ban Harvard University from enrolling foreign students - after the institution said it would not bow to demands from President Donald Trump's administration and was hit with a funding freeze.</p><p>The White House has demanded the oldest university in the US make changes to hiring, admissions and teaching practices - to help fight antisemitism on campus.</p><p>Homeland Security Secretary Kristi Noem has asked for records on what she called the "illegal and violent" activities of its foreign student visa-holders. </p><p>Harvard earlier said it had taken many steps to address antisemitism, and that demands were an effort to regulate the university's "intellectual conditions".</p></div><div data-component="text-block"><p>"The university will not surrender its independence or relinquish its constitutional rights," Harvard President Alan Garber wrote in a message on Monday to the Harvard community.</p><p>The new request from Noem said the institution would lose the "privilege of enrolling foreign students" if it did not comply with the demand for records.</p><p>Harvard said it was aware of the new request from Noem, which was made in a letter, the Reuters news agency reported.</p><p>International students make up more than 27% of Harvard's enrolment this year. Even before Noem's statement, billions of dollars hung in the balance for the university, after the freeze of some $2.2 bn (£1.7bn) in federal funding.</p><p>Trump has also threatened to also remove Harvard's valuable tax exemption, the loss of which could cost Harvard millions of dollars each year. US media reports suggest the Internal Revenue Service (IRS) has started drawing up plans to enact this.</p><p>"Harvard can no longer be considered even a decent place of learning, and should not be considered on any list of the World's Great Universities or Colleges," Trump wrote on his Truth Social platform on Wednesday. </p><p>"Harvard is a JOKE, teaches Hate and Stupidity, and should no longer receive Federal Funds."</p></div><div data-component="text-block"><ul><li><a target="_self" href="https://www.bbc.co.uk/news/articles/c20z60vxvmjo">Harvard just stood up to Trump. How long can it last?</a></li><li><a target="_self" href="https://www.bbc.co.uk/news/articles/cz01y9gkdm3o">Trump threatens Harvard's tax-exempt status </a></li><li><a target="_self" href="https://www.bbc.co.uk/news/articles/cn0w2656x33o">Obama calls Trump's freeze of funding unlawful</a></li></ul></div><div data-component="text-block"><p>The administration's attacks on Harvard are not isolated. The government's antisemitism task force has identified at least 60 universities for review.</p><p>During his presidential campaign, Trump pitched a funding crackdown on universities, painting them as hostile to conservatives. He and Vice-President JD Vance have long railed against higher education institutions.</p><p>Polling by Gallup last year suggested that confidence in higher education had been falling over time among Americans of all political backgrounds, particularly Republicans - in part due to a belief that universities push a political agenda. </p><p>Since taking office, Trump has focused particularly on universities where pro-Palestinian protests have taken place. Some Jewish students have said they felt unsafe and faced harassment on campus. </p><p>In March, Columbia University agreed to several of the administration's demands, after $400m in federal funding was pulled over accusations the university failed to fight antisemitism.</p><p>These included replacing the official leading its Middle Eastern, South Asian and African Studies department and pledging to take on a review to "ensure unbiased admission processes". </p><p>Harvard too has made concessions - including by dismissing the leaders of its Center for Middle Eastern Studies, who had come under fire for failing to represent Israeli perspectives.</p><p>But it has drawn the line at the White House's recent list of demands.</p></div><p data-component="caption-block"><figcaption>Watch: 'It's not right' - Students react to Trump freezing Harvard's federal funding</figcaption></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Japan's "Weakest Samurai Warlord" Is Still Admired to This Day (151 pts)]]></title>
            <link>https://www.tokyoweekender.com/art_and_culture/japanese-culture/oda-ujiharu-the-weakest-samurai-warlord/</link>
            <guid>43714619</guid>
            <pubDate>Thu, 17 Apr 2025 09:30:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/oda-ujiharu-the-weakest-samurai-warlord/">https://www.tokyoweekender.com/art_and_culture/japanese-culture/oda-ujiharu-the-weakest-samurai-warlord/</a>, See on <a href="https://news.ycombinator.com/item?id=43714619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><span>During Japan’s Sengoku (Warring States) period, there was one name that instantly struck fear into the hearts of even the most powerful feudal lords: “Oda,” as in the </span><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/what-age-of-samurai-didnt-tell-you-about-oda-nobunaga/"><span>merciless master maneuverer</span></a><span> Oda Nobunaga (1534–1582). Interestingly, around the same time, there was a name that elicited the exact opposite reaction, and it was also “Oda” — as in Oda Ujiharu, master of Oda Castle in modern-day Ibaraki Prefecture, whose constant losing streak made him known as the weakest Sengoku samurai warlord. Why, then, do so many people admire him today? Let’s find out.</span></p>

<div id="attachment_265631"><p><img decoding="async" aria-describedby="caption-attachment-265631" src="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-002-1600x1059.jpg" alt="" width="1600" height="1059" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src-img="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-002-1600x1059.jpg" data-src-webp="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-002-1600x1059.jpg.webp"></p><p id="caption-attachment-265631">Taken from “The Siege of Shimoasakusa Castle” | Wikimedia</p></div>
<h2 id="6800c3579cd24">The Loser Phoenix of Hitachi</h2>
<p><span>Born sometime in the 1530s (perhaps even in 1534, though that may have been an invention to draw parallels between Ujiharu and Nobunaga), the weakest samurai warlord in history has no connection to the </span><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/the-brave-gunjyo-senki-film-and-the-portrayal-of-oda-nobunaga-in-fiction/"><span>Demon King</span></a><span>. Their names are written with different characters and point to two vastly different lineages. Nobunaga hailed from a relatively minor family in Owari (modern-day Aichi), while Ujiharu was connected to the Hatta clan that once was a major player in the Kamakura shogunate. He was also a close relative of many important figures in the Ashikaga shogunate.</span></p>
<p><span>Ujiharu ruled the strategically important Hitachi Province from the massive Oda Castle, whose entire complex was 4.6 times larger than Tokyo Dome. That wasn’t the main reason why, like, four different warlords kept stealing it from him, but it probably was a factor. During the Sengoku period, both the shogunate and the emperor effectively lost power, so Ujiharu’s ancestry meant nothing to the Hojo, Yuki, Satake or Uesugi clans, who conquered Oda Castle a total of </span><i><span>nine times.</span></i></p>
<p><span>Losing one’s home once was often enough to drive a Sengoku samurai to commit seppuku out of shame, but if Ujiharu dismembered himself every time he lost Oda Castle, he’d have been just a head floating in a jar by the end.</span></p>
<p><span>However, </span><a href="https://youtu.be/kyQrl7AWeXg?feature=shared&amp;t=162"><span>a wise man once said:</span></a><span> “[It] ain’t about how hard you hit. It’s about how hard you can get hit and keep moving forward; how much you can take and keep moving forward.” Ujiharu may have lost Oda Castle nine times, but that means he also </span><i><span>won it back eight times, </span></i><span>almost always with smaller armies. His refusal to accept defeat and his iron will to get up and keep fighting is why many historians reject the “weakest samurai warlord” nickname and instead refer to him as “The Phoenix.”</span></p>
<div id="attachment_265630"><p><img decoding="async" aria-describedby="caption-attachment-265630" src="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-003-1600x1059.jpg" alt="" width="1600" height="1059" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src-img="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-003-1600x1059.jpg" data-src-webp="https://www.tokyoweekender.com/wp-content/uploads/2025/03/oda-ujiharu-003-1600x1059.jpg.webp"></p><p id="caption-attachment-265630">Oda Ujiharu, artist unknown | Wikimedia</p></div>
<h2 id="6800c3579cd30">Man of the People</h2>
<p><span>Ujiharu lost Oda Castle so many times because he made bafflingly bad military decisions. During his war with the Satake clan, Ujiharu’s chief strategist — </span><i><span>on his deathbed </span></i><span>— begged his lord to barricade himself and his army in the fortification, wait for reinforcements and not meet the enemy on the field.</span></p>
<p><span>The castle’s main defenses were its walls, moats and nearby rivers. Outside that, Oda Castle was surrounded by flatlands. And yet, ignoring his strategist’s </span><i><span>dying words</span></i><span>, the lord of Hitachi refused to stay put and challenged the Satake to open combat. He was then cut off from his base by the enemy’s hidden forces, allowing them to take Oda Castle. This was the</span><i><span> second time </span></i><span>that this exact same strategy lost Ujiharu his ancestral home. Some other wise man once said: “Fool me once, shame on you. Fool me twice, shame on me.”</span></p>
<p><span>However, Ujiharu’s blind charges may actually have had a noble purpose. Japanese battles involving castles almost always turned into sieges, and those always ended the same way: with the nearby fields and peasant settlements being either destroyed to try and draw the lord out of the castle or looted to feed the occupying army. Some researchers believe that Ujiharu was trying to avoid a siege to save his subjects.</span></p>
<p><span>Even if that wasn’t the case and he was simply a really bad strategist, his retainers and farmers chose to see the best in their lord and were fiercely loyal to him. During Ujiharu’s early campaigns, some of his men did defect to the enemy, but a few raids to protect or take back Oda Castle later and you apparently could not threaten or pay off anyone in Ujiharu’s service to move against him. Forget “The Phoenix”: “A Feudal Lord Actually Liked by His Retainers and Farmers” may be less pithy but is much more impressive.</span></p>
<h2 id="6800c3579cd34">Everybody Makes Mistakes</h2>
<p><span>The main arguments against Ujiharu’s incompetence were his obvious diplomatic skills. During his fight with the Hojo, Yuki, Satake or Uesugi families, he kept forming alliances and switching sides to best serve his own purposes, and he would not have been able to do that unless he could skillfully talk his way into the good graces of his former enemies.</span></p>
<p><span>That being said, he did make mistakes, like betraying Uesugi Kenshin, one of Japan’s most powerful and feared warlords, often mentioned in the same breath as Oda Nobunaga (plus </span><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/the-rise-and-fall-of-japans-warrior-monks/"><span>an ordained monk</span></a><span> fueled in battle by his fiery faith). This cost him Oda Castle, but he later got it back. Then he lost it a few more times until he made his ultimate mistake: refusing to swear allegiance to Toyotomi Hideyoshi. After the death of Nobunaga, Hideyoshi continued his master’s quest to unify Japan and eventually arrived at Ujiharu’s doorstep demanding his fealty.</span></p>
<p><span>However, the lord of Oda Castle was worried about losing his home (either due to personal attachment or to protect his people) and took too long to give his answer. So, Hideyoshi conquered his lands and stripped Ujiharu of all his titles because Japan back then operated on prison rules; you couldn’t afford to show weakness. After some begging, Hideyoshi spared Ujiharu’s life, who then went to live with Yuki Hideyasu, son of Tokugawa Ieyasu (Toranaga on </span><a href="https://www.tokyoweekender.com/entertainment/movies-tv/shogun-2024-series-review/"><i><span>Shogun</span></i></a><span>). A bit of an ignoble end, but the other Oda got </span><a href="https://unseen-japan.com/oda-nobunaga-honnoji-incident/#More_than_a_Traitor_Akechi_Mitsuhide"><span>betrayed by his general</span></a><span> and had to commit seppuku in a burning temple, so who’s the real winner here?</span></p>
<h2 id="6800c3579cd35"><span>Related Posts</span></h2>
<ul>
<li><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/the-three-great-villains-of-japans-sengoku-period/"><span>Debunking the Three Great Villains of Japan’s Sengoku Period</span></a></li>
<li><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/famous-samurai-battles-conflicts/"><span>Famous Samurai Battles and Conflicts | List of 7</span></a></li>
<li><a href="https://www.tokyoweekender.com/art_and_culture/japanese-culture/japanese-history-books/"><span>From Ainu to Samurai: 8 Japanese History Books to Read</span></a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advanced Shell Scripting with Bash (2006) [pdf] (120 pts)]]></title>
            <link>http://uniforumchicago.org/slides/bash1.pdf</link>
            <guid>43714594</guid>
            <pubDate>Thu, 17 Apr 2025 09:26:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://uniforumchicago.org/slides/bash1.pdf">http://uniforumchicago.org/slides/bash1.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43714594">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Astronomers have found signs of alien life on a planet beyond our Solar System (389 pts)]]></title>
            <link>https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide</link>
            <guid>43714203</guid>
            <pubDate>Thu, 17 Apr 2025 08:02:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide">https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide</a>, See on <a href="https://news.ycombinator.com/item?id=43714203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div type="content-body" ngh="32"><storefront-content-body _nghost-purplestorefront-c2920483845="" ngh="31"><article _ngcontent-purplestorefront-c2920483845="" id="sprylab_purple_content"><div _ngcontent-purplestorefront-c2920483845=""><p>Astronomers say they've found "the most promising signs yet" of chemicals on a planet beyond our Solar System that could indicate the presence of life on its surface.</p>
<p>Using the <a href="https://www.skyatnightmagazine.com/space-missions/nasa-james-webb-space-telescope-observe-universe">James Webb Space Telescope</a>, the team found a possible 'biosignature' – the potential fingerprint of life – within its atmosphere, although they say they're remaining "cautious", and that this isn't a confirmed detection.</p>
<p>The chemicals detected are the same as those produced by marine-dwelling organisms on Earth.</p>
<div>
<figure><img loading="lazy" decoding="async" width="1200" height="675" src="https://c02.purpledshub.com/uploads/sites/48/2025/04/exoplanets.jpg?webp=1&amp;w=1200" alt="Artist's impression showing multiple interesting exoplanets. Credit: Photostock-Israel/Science Photo Library"><figcaption>Credit: Photostock-Israel/Science Photo Library</figcaption></figure>
</div>
<p>The team, led by the University of Cambridge in the UK, detected signs of dimethyl sulfide and dimethyl disulfide in the atmosphere of exoplanet K2-18b.</p>
<p>This planet orbits its star in the habitable zone (sometimes called the <a href="https://www.skyatnightmagazine.com/space-science/goldilocks-zone">Goldilocks Zone</a>), which is the region around a star in which an orbiting planet might have conditions suitable for the emergence of life, such as the ability for liquid water to exist on its surface.</p>
<p>K2-18b is 8.6 times as massive and 2.6 times as large as Earth and lies 124 <a href="https://www.skyatnightmagazine.com/space-science/lightyear">lightyears</a> away from our planet.</p>
<figure><img loading="lazy" decoding="async" width="1500" height="875" src="https://c02.purpledshub.com/uploads/sites/48/2019/09/exoplanet_K2_18b-c7915cb.jpg?webp=1&amp;w=1200" alt="An artist’s impression showing exoplanet K2-18b, its host star and an accompanying planet in this system. Credit: ESA/Hubble, M. Kornmesser"><figcaption>An artist’s impression showing exoplanet K2-18b, its host star and an accompanying planet in this system. Credit: ESA/Hubble, M. Kornmesser. Credit: ESA/Hubble, M. Kornmesser</figcaption></figure>
<h2><strong>Building a bigger picture</strong></h2>
<p>This isn't the first study of exoplanet K2-18b. </p>
<p>A <a href="https://www.skyatnightmagazine.com/news/jwst-finds-life-exoplanet-k2-18b">2023 study of K2-18b</a> by the same team identified methane and carbon dioxide in the planet's atmosphere.</p>
<p>This in itself was a huge discovery: the first time carbon-based molecules had been found in the atmosphere of an exoplanet – a planet beyond our Solar System – in the habitable zone.</p>
<p>Astronomers say the 2023 results showed K2-18b could be a ‘Hycean’ planet, meaning a <a href="https://www.skyatnightmagazine.com/space-science/what-makes-a-planet-habitable">habitable world</a> with a liquid ocean and a hydrogen-rich atmosphere.</p>
<p>That earlier study found a tantalising hint of dimethyl sulfide and dimethyl disulfide, but this latest study has made a more promising detection.</p>
<figure><img loading="lazy" decoding="async" width="3840" height="2160" src="https://c02.purpledshub.com/uploads/sites/48/2023/09/Atmospheric-compoistion-of-k2-18b.png?webp=1&amp;w=1200" alt="Atmospheric compoistion of k2-18b, detected by the James Webb Space Telescope"><figcaption>This graph shows detections of chemicals in the atmosphere of K2-18b by the James Webb Space Telescope, as part of the 2023 study</figcaption></figure>
<p>"We didn’t know for sure whether the signal we saw last time was due to DMS, but just the hint of it was exciting enough for us to have another look with JWST using a different instrument," says Professor Nikku Madhusudhan from Cambridge’s Institute of Astronomy, who led the research.</p>
<p>The team say that on Earth, dimethyl sulfide and dimethyl disulfide are only produced by life, mainly microbial life like <a href="https://www.skyatnightmagazine.com/earth-from-space/algae-bloom-from-space">phytoplankton</a> we see in our oceans.</p>
<p>However, there could be another explanation for the detection of the chemical.</p>
<p>Another unknown chemical process could be the source of the molecules detected in K2-18b’s atmosphere.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="631" src="https://c02.purpledshub.com/uploads/sites/48/2025/04/K2-18b-exoplanet.jpg?webp=1&amp;w=1200" alt="Artist's impression of exoplanet K2-18b. Credit: A. Smith, N. Madhusudhan (University of Cambridge)"><figcaption>Artist's impression of exoplanet K2-18b. Credit: A. Smith, N. Madhusudhan (University of Cambridge)</figcaption></figure>
<p>Nevertheless, the team say "the results are the "strongest evidence yet" that life may exist on a planet outside our Solar System.</p>
<p>They say their observations have reached the ‘three-sigma’ level of statistical significance.</p>
<p>This means there's a 0.3% probability the detection occurred by chance.</p>
<p>And to reach the accepted level that would mean scientific discovery, observations would have to meet the five-sigma threshold.</p>
<p>In other words, there would need to be below a 0.00006% probability they occurred by chance.</p>
<figure><img loading="lazy" decoding="async" width="940" height="531" src="https://c02.purpledshub.com/uploads/sites/48/2019/05/Exoplanet-discovery-MAIN-c0a6e15.jpg?webp=1&amp;w=1200" alt="Artistic ilustration of planet K2-18b, its star K2-18 and another planet in the system. Credit: Alex Boersma, www.alexboersma.com"><figcaption>Artistic ilustration of planet K2-18b, its star K2-18 and another planet in the system. Credit: Alex Boersma, www.alexboersma.com</figcaption></figure>
<h2><strong>Detecting life on faraway worlds</strong></h2>
<p>How can scientists know what chemicals exist on a planet orbiting a star beyond our Solar System?</p>
<p>Key to analysing exoplanets' atmospheres is analysing the light from their host stars.</p>
<p>As a planet passes in front of its host star from our perspective on Earth – known as a <a href="https://www.skyatnightmagazine.com/space-science/exoplanets-transit-method">transit</a> – light from that star passes through the planet's atmosphere.</p>
<p>That starlight picks up chemical fingerprints as it passes through the atmosphere, so astronomers can analyse the light to learn more about the atmosphere. </p>
<figure><img loading="lazy" decoding="async" width="1200" height="759" src="https://c02.purpledshub.com/uploads/sites/48/2021/04/Exoplanet-transit-method-aeba46b.jpg?webp=1&amp;w=1200" alt="Transit photometry reveals exoplanets by observing periodic dimming of the star's light."><figcaption>A dip in starlight can indicate a planet 'transiting' that star. But as well as detecting exoplanets, transits can be used by astronomers to learn more about an exoplanet's atmosphere</figcaption></figure>
<p>The tentative detection of dimethyl sulfide in 2023 was made using the James Webb Space Telescope's NIRISS (Near-Infrared Imager and Slitless Spectrograph) and NIRSpec (Near-Infrared Spectrograph) instruments.</p>
<p>This 2025 study used the Webb Telescope's MIRI (Mid-Infrared Instrument), which observes in a different wavelength of light, offering the team a new look at this intriguing world.</p>
<p>"This is an independent line of evidence, using a different instrument than we did before and a different wavelength range of light, where there is no overlap with the previous observations," says Madhusudhan.</p>
<p>"The signal came through strong and clear."</p>
<p>"It was an incredible realisation seeing the results emerge and remain consistent throughout the extensive independent analyses and robustness tests," says co-author Måns Holmberg, a researcher at the Space Telescope Science Institute in Baltimore, USA.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="507" src="https://c02.purpledshub.com/uploads/sites/48/2024/05/biosignatures.jpg?webp=1&amp;w=1200" alt="Astronomers can detect biosignatures to determine whether a planet may host life."><figcaption>Astronomers can detect biosignatures to determine whether a planet may host life.</figcaption></figure>
<h2><strong>Does K2-18b have life?</strong></h2>
<p>The team say dimethyl sulfide and dimethyl disulfide are molecules from the same chemical family, and could be '<a href="https://www.skyatnightmagazine.com/space-science/biosignatures-exoplanets">biosignatures</a>'.</p>
<p>This is a term used to describe chemicals that, when detected around a distant planet, could indicate the presence of biological processes, i.e. life.</p>
<p>Yet the concentrations of dimethyl sulfide and dimethyl disulfide in K2-18b's atmosphere are different from those on Earth.</p>
<p>On Earth, dimethyl sulfide and dimethyl disulfide are below one part per billion by volume. On K2-18b, they're thought to be thousands of times stronger, over ten parts per million.</p>
<p>"Earlier theoretical work had predicted that high levels of sulfur-based gases like dimethyl sulfide and dimethyl disulfide are possible on Hycean worlds," says Madhusudhan.</p>
<p>"And now we’ve observed it, in line with what was predicted. Given everything we know about this planet, a Hycean world with an ocean that is teeming with life is the scenario that best fits the data we have."</p>
<p>The team now hope to carry out more research into whether dimethyl sulfide and dimethyl disulfide can be produced non-biologically at the level they're currently seeing.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="800" src="https://c02.purpledshub.com/uploads/sites/48/2023/11/webb-detect-life.jpg?webp=1&amp;w=1200" alt="Will Webb detect signs of life? Discoveries at Europa and exoplanet K2-18b suggest it is certainly able to do so. Credit: NASA GSFC/CIL/Adriana Manrique Gutierrez"><figcaption>Credit: NASA GSFC/CIL/Adriana Manrique Gutierrez</figcaption></figure>
<p>"The inference of these biosignature molecules poses profound questions concerning the processes that might be producing them" says study co-author Subhajit Sarkar of Cardiff University.</p>
<p>"Our work is the starting point for all the investigations that are now needed to confirm and understand the implications of these exciting findings," says co-author Savvas Constantinou, also from Cambridge’s Institute of Astronomy.</p>
<p>"It’s important that we’re deeply sceptical of our own results, because it’s only by testing and testing again that we will be able to reach the point where we’re confident in them," says Madhusudhan. "That’s how science has to work.</p>
<p>"Decades from now, we may look back at this point in time and recognise it was when the living universe came within reach.</p>
<p>"This could be the tipping point, where suddenly the fundamental question of whether we’re alone in the universe is one we’re capable of answering."</p>
</div></article><!----></storefront-content-body><!----><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passing planes and other whoosh sounds (182 pts)]]></title>
            <link>https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html</link>
            <guid>43713524</guid>
            <pubDate>Thu, 17 Apr 2025 05:53:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html">https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html</a>, See on <a href="https://news.ycombinator.com/item?id=43713524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-2080249921577037368" itemprop="description articleBody">
<p>I always assumed that the recognisable 'whoosh' sound a plane makes when passing overhead simply comes from the famous <i>Doppler effect</i>. But when you listen closely, this explanation doesn't make complete sense.</p>






<p>(Audio clipped from <a href="https://freesound.org/people/bruno.auzet/sounds/706432/">freesound</a>)</p>

<p>A classic example of the Doppler effect is the sound of a passing ambulance constantly descending in pitch. When a plane flies overhead the roar of the engine sometimes does that as well. But you can also hear a wider, breathier noise that does something different: it's like the pitch goes down at first, but when the plane has passed us, the pitch <i>goes up</i> again. That's not how Doppler works! What's going on there?</p>

<h3>Comb filtering.</h3>

<p>Let's shed light on the mystery by taking a look at the sound in a time-frequency spectrogram. Here, time runs from top to bottom, frequencies from left (low) to right (high).</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAaOGJ0_mW_OWy2A0W2yp-_SRiqVJEfI0Vr6b3w_L-ByIBnYu23rtt2Jgwk6hMkNxJOIm5Hd8JFYt5oDtFofaBvzWUUQqTzRdCN4a9DBdEQu-qnZfWcfbpJhfO1ZIHVPWa0IkdRsMiG6AJCHGgOl3eK8UfBQw7WgxFyu9-pVhLJCBVuMuRaUXv6wnH3CuS/s858/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.51.58.jpg"><img alt="" data-original-height="500" data-original-width="858" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAaOGJ0_mW_OWy2A0W2yp-_SRiqVJEfI0Vr6b3w_L-ByIBnYu23rtt2Jgwk6hMkNxJOIm5Hd8JFYt5oDtFofaBvzWUUQqTzRdCN4a9DBdEQu-qnZfWcfbpJhfO1ZIHVPWa0IkdRsMiG6AJCHGgOl3eK8UfBQw7WgxFyu9-pVhLJCBVuMuRaUXv6wnH3CuS/s858/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.51.58.jpg" width="500"></a></p>

<p>We can clearly see one part of the sound sweeping from right to left, or from high to low frequencies; this should be the Doppler effect. But there's something else happening on the left side.</p>

<p>The sound's frequency distribution seems to form a series of moving peaks and valleys. This resembles what audio engineers would call <a href="https://en.wikipedia.org/wiki/Comb_filter">'comb filtering'</a>, due to its appearance in the spectrogram. When the peaks and valleys move about it causes a 'whoosh' sound; this is the same principle as in the <a href="https://en.wikipedia.org/wiki/Flanging">flanger</a> effect used in music production. But these are just jargon for the electronically created version. We can call the acoustic phenomenon the whoosh.</p>

<p>The comb pattern is caused by two copies of the same exact sound arriving at a slightly different times, close enough that they form an interference pattern. It's closely related to what happens to light in the <a href="https://thefouriertransform.com/applications/diffraction3.php">double slit experiment</a>. In recordings this often means that the sound was captured by two microphones and then mixed together; you can sometimes hear this happen unintentionally in podcasts and radio shows. So my thought process is, are we hearing two copies of the plane's sound? How much later is the other one arriving, and why? And why does the 'whoosh' appear to go down in pitch at first, then up again?</p>

<h3>Into the cepstral domain.</h3>

<p>The <i>cepstrum</i>, which is the inverse Fourier transform of the estimated log spectrum, is a fascinating plot for looking at delays and echoes in complex (as in complicated) signals. While the spectrum separates frequencies, the cepstrum measures time, or <i>quefrency</i> – see what they did there? It reveals cyclicities in the sound's structure even if it interferes with itself, like in our case.</p>

<p>It's also useful for looking at sounds that, experientially, have a 'pitch' to them but that don't show any clear spectral peak in the Fourier transform. Just like the sound we're interested in.</p>

<p>Here's a time-<i>quefrency cepstrogram</i> of the same sound (to be accurate, I used the <i>autocepstrum</i> here for better clarity; autocorrelation would also work):</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1VOwgKsPuBeVTFUk9oq8zFJ_zEOjEx9eUB5ic4KKHFUVNtLYmPbDweOo2gfiokWxlZcc4038dO29gSq31mBXLZuJX1dHjAZ-oKPDDEGDBS1NJ0a_4MQfWA972iGLLEjYM8at0jlL4MtTmQQLVuR_t_liH8iyrwoPN90587N59xflXUqWZuWajevxw-9Tm/s859/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.39.15.jpg"><img alt="" data-original-height="501" data-original-width="859" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1VOwgKsPuBeVTFUk9oq8zFJ_zEOjEx9eUB5ic4KKHFUVNtLYmPbDweOo2gfiokWxlZcc4038dO29gSq31mBXLZuJX1dHjAZ-oKPDDEGDBS1NJ0a_4MQfWA972iGLLEjYM8at0jlL4MtTmQQLVuR_t_liH8iyrwoPN90587N59xflXUqWZuWajevxw-9Tm/s501/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.39.15.jpg" width="501"></a></p>

<p>The Doppler effect is less prominent here. Instead, the plot shows a sweeping peak that seems to agree with the pitch change we hear. This delay time sweeps from around 4 milliseconds to 9 ms and back. Note that the scale: higher frequencies (shorter times) are on the left side this time.</p>

<h3>Ground echo?</h3>

<p>Here's my hypothesis. We are hearing not only the direct sound from the plane but also a delayed echo from a nearby flat surface. These two sound get superimposed and interfere before they reach our ears. The effect would be especially prominent with planes because there is little in the way of the sound either from above or from the large surface. And what could be a large reflective surface outdoors? Well, the ground below!</p>

<p>Let's think about the numbers. The ground is around one-and-a-half metres below our ears. When a plane is directly overhead, the reflected sound needs to take a path that's three metres longer (two-way) than the direct path. Since sound travels 343 metres per second this translates to a difference of 9 milliseconds!</p>

<p>Below, I used GeoGebra to calculate the time difference (between the yellow and green paths) in milliseconds.</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA4ggy0g82ccmz9ywX_sLR8Y8-DjRgFT1F9fuU1uz4Bouan-j9K63jWL7qnhFTOeQVI_qDh6gq897-_AOhw6UgGtz4aZJRjrGuuBRIyPsHeDBj62gvDTlYZGssXSTogxnBKZBXZtZkd-bfZiy_VYKfDmq82o6s3S1pZD8P3Cb6rMHqY_C6acR5iaKGsxLd/s1200/delayed.png"><img alt="" data-original-height="366" data-original-width="1200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA4ggy0g82ccmz9ywX_sLR8Y8-DjRgFT1F9fuU1uz4Bouan-j9K63jWL7qnhFTOeQVI_qDh6gq897-_AOhw6UgGtz4aZJRjrGuuBRIyPsHeDBj62gvDTlYZGssXSTogxnBKZBXZtZkd-bfZiy_VYKfDmq82o6s3S1pZD8P3Cb6rMHqY_C6acR5iaKGsxLd/s520/delayed.png" width="520"></a></p>

<p>When the plane is far away the angle is shallower, the two paths are more similar in distance, and the time difference is shorter.</p>

<p>It would follow that a taller person hears the sound differently than a shorter one, or someone in a tenth-floor window! If the ground is very soft, maybe in a mossy grove, you probably wouldn't hear the effect at all; just the Doppler effect. But this prediction needs to be tested out in a real forest.</p>

<p>Here's what a minimal acoustic simulation model renders. We'll just put a flying white noise source in the sky and a reflective surface as the ground. Let's only update the IR at 15 fps to prevent the Doppler phenomenon from emerging.</p>





<p>Whoosh!</p>

<h3>Some everyday whooshes.</h3>

<p>The whoosh isn't only associated with planes. When it occurs naturally it usually needs three things:</p>

<ul>
  <li>a sound with a lot of structure (preferably a hissy or breathy noise)</li>
  <li>an unobstructed echo from a closeby surface (either close to you or to the source of sound)</li>
  <li>and some kind of physical movement.</li>
</ul>

<p>I've heard this outdoors when the sound of a waterfall was reflecting off a brick wall (<a href="https://www.youtube.com/watch?v=Amj4UevyRfU">video</a>); and next to a motorway when the sound barrier provided the reflection. You can hear it in some films – for instance, in the original Home Alone when Kevin puts down the pizza box after taking a whiff (<a href="https://youtu.be/H6M_mFUH35s?t=100">video</a>)!</p>

<p>Try it yourself: move your head towards a wall – or a laptop screen – and back away from it, while making a continuous 'hhhh' or 'shhh' noise. Listen closely but don't close your eyes, you might bump your nose.</p>

<h3>A simple little plot.</h3>

<p>Finally, if you have JavaScript turned on you'll see (and hear) some more stuff in this blog post. In the interactive graph below you can move the aeroplane and listener around and see how the numbers change. The 'lag' or time difference we hear (orange arrow) comes from how much farther away the reflected virtual image is compared to the real aeroplane. In the lower right corner, the 'filter' spectrum up to 4.5 kHz is also drawn. The circles are there to visualize the direct distance.</p>








<p>Where have you encountered the whoosh?</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>