<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 09 Nov 2024 19:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[SQLite does not do checksums (109 pts)]]></title>
            <link>https://avi.im/blag/2024/sqlite-bit-flip/</link>
            <guid>42094663</guid>
            <pubDate>Sat, 09 Nov 2024 14:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avi.im/blag/2024/sqlite-bit-flip/">https://avi.im/blag/2024/sqlite-bit-flip/</a>, See on <a href="https://news.ycombinator.com/item?id=42094663">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>SQLite does not do checksums by default. I learned this from <a href="https://fosstodon.org/@AlexMillerDB/109553692861357766">Alex Miller</a>. What does this mean? If there is disk corruption, the database or application won’t be able to know that the database is ‘corrupt’.</p><p>Even a single bit flip can cause havoc. This can happen due to a faulty disk, a bug in the disk driver, or when another application (malicious or otherwise) modifies the database files.</p><p>This is not a bug - it’s properly documented:</p><blockquote><p>SQLite assumes that the detection and/or correction of bit errors caused by cosmic rays, thermal noise, quantum fluctuations, device driver bugs, or other mechanisms, is the responsibility of the underlying hardware and operating system. SQLite does not add any redundancy to the database file for the purpose of detecting corruption or I/O errors. SQLite assumes that the data it reads is exactly the same data that it previously wrote.</p></blockquote><p>I created a <a href="https://gist.github.com/avinassh/0e7e4b0578136a338f1b9a03fba36ead">simple script</a> to demonstrate this:</p><ol><li><p>Create a sample database using <a href="https://gist.github.com/avinassh/0e7e4b0578136a338f1b9a03fba36ead">this script</a>. It creates a bank database and adds a row for Alice with $83K.</p></li><li><p>Flip a single bit:</p><pre><code> printf '\x00\x00\x00\x00\x00\x80' | dd of=bank.db bs=1 seek=$((0x1ffd)) count=1 conv=notrunc
</code></pre></li><li><p>Alice’s balance is now zero. Sorry, Alice.</p></li></ol><p>It passes <code>PRAGMA integrity_check</code> too. Here’s an ASCII animation if you prefer that:</p><h2 id="wal-and-checksums">WAL and Checksums</h2><p>SQLite has checksums for WAL frames. However, when it detects a corrupt frame, it silently ignores the faulty frame and all subsequent frames. It doesn’t even raise an error!</p><p>Ignoring frames might be acceptable, but not raising an error is where it gets me.</p><h2 id="checksum-vfs-shim">Checksum VFS Shim</h2><p>You can use the <a href="https://www.sqlite.org/cksumvfs.html">Checksum VFS Shim</a>, but there’s one important caveat:</p><blockquote><p>Checksumming only works on databases that have a reserve bytes value of exactly 8</p></blockquote><p>The <a href="https://www.sqlite.org/fileformat2.html#resbyte">documentation of reserve bytes</a> explains:</p><blockquote><p>SQLite has the ability to set aside a small number of extra bytes at the end of every page for use by extensions. These extra bytes are used, for example, by the SQLite Encryption Extension to store a nonce and/or cryptographic checksum associated with each page. The “reserved space” size in the 1-byte integer at offset 20 is the number of bytes of space at the end of each page to reserve for extensions. This value is usually 0. The value can be odd.</p></blockquote><p>This means if you’re using any extension that uses reserve bytes, you can’t use the Checksum shim.</p><p>Again, this is not a bug. <a href="https://avi.im/blag/2024/databases-checksum">Most databases (except a few)</a> assume that the OS, filesystem, and disk are sound. Whether this matters depends on your application and the guarantees you need.</p><p>edit: I wrote a <a href="https://avi.im/blag/2024/databases-checksum">follow up post</a>.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientist treated her own cancer with viruses she grew in the lab (230 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-03647-0</link>
            <guid>42094573</guid>
            <pubDate>Sat, 09 Nov 2024 14:23:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-03647-0">https://www.nature.com/articles/d41586-024-03647-0</a>, See on <a href="https://news.ycombinator.com/item?id=42094573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                        <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Coloured transmission electron micrograph of cultured measles virus particles." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg"><figcaption><p><span>Viruses such as measles (pictured here) can be used to attack cancerous cells. </span><span>Credit: Eye Of Science/Science Photo Library</span></p></figcaption></picture></figure><p>A scientist who successfully treated her own <a href="https://www.nature.com/subjects/breast-cancer" data-track="click" data-label="https://www.nature.com/subjects/breast-cancer" data-track-category="body text link">breast cancer</a> by injecting the tumour with lab-grown viruses has sparked discussion about the ethics of self-experimentation. </p><p>Beata Halassy discovered in 2020, aged 49, that she had breast cancer at the site of a previous mastectomy. It was the second recurrence there since her left breast had been removed, and she couldn’t face another bout of chemotherapy. </p><p>Halassy, a virologist at the University of Zagreb, studied the literature and decided to take matters into her own hands with an unproven treatment. </p><p>A case report published in <i>Vaccines</i> in August<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> outlines how Halassy self-administered a treatment called <a href="https://www.nature.com/articles/s41571-022-00719-w" data-track="click" data-label="https://www.nature.com/articles/s41571-022-00719-w" data-track-category="body text link">oncolytic virotherapy</a> (OVT) to help treat her own stage 3 cancer. She has now been cancer-free for four years. </p><p>In choosing to <a href="https://www.nature.com/articles/nm0508-471b" data-track="click" data-label="https://www.nature.com/articles/nm0508-471b" data-track-category="body text link">self-experiment</a>, Halassy joins a long line of scientists who have participated in this under-the-radar, stigmatized and ethically fraught practice. “It took a brave editor to publish the report,” says Halassy.</p><h2>Up-and-coming therapy</h2><p>OVT is an emerging field of <a href="https://www.nature.com/subjects/cancer-therapy" data-track="click" data-label="https://www.nature.com/subjects/cancer-therapy" data-track-category="body text link">cancer treatment</a> that uses viruses to both attack cancerous cells and provoke the immune system into fighting them. Most OVT clinical trials so far have been in late-stage, metastatic cancer, but in the past few years they have been directed towards earlier-stage disease. One OVT, called T-VEC, has been in approved in the United States to treat metastatic melanoma, but there are as yet no OVT agents approved to treat breast cancer of any stage, anywhere in the world. </p><p>Halassy stresses that she isn’t a specialist in OVT, but her expertise in cultivating and purifying viruses in the laboratory gave her the confidence to try the treatment. She chose to target her tumour with two different viruses consecutively — a <a href="https://www.nature.com/subjects/measles-virus" data-track="click" data-label="https://www.nature.com/subjects/measles-virus" data-track-category="body text link">measles virus</a> followed by a vesicular stomatitis virus (VSV). Both pathogens are known to infect the type of cell from which her tumour originated, and have already been used in OVT clinical trials. A measles virus has been trialled against metastatic breast cancer.</p><p>Halassy had previous experience working with both viruses, and both have a good safety record. The strain of measles she chose is used extensively in childhood vaccines, and the strain of VSV induces, at worst, mild influenza-like symptoms. </p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Portrait of Beata Halassy." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg"><figcaption><p><span>Halassy’s experience with self-treatment has changed the focus of her research. </span><span>Credit: Ivanka Popić </span></p></figcaption></picture></figure><p>Over a two-month period, a colleague administered a regime of treatments with research-grade material freshly prepared by Halassy, injected directly into her tumour. Her oncologists agreed to monitor her during the self-treatment, so that she would be able to switch to conventional chemotherapy if things went wrong.</p><p>The approach seemed to be effective: over the course of the treatment, and with no serious side effects, the tumour shrank substantially and became softer. It also detached from the pectoral muscle and skin that it had been invading, making it easy to remove surgically.</p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-024-02613-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27470032.jpg"><p>How a trove of cancer genomes could improve kids’ leukaemia treatment</p></a></article><p>Analysis of the tumour after removal showed that it was thoroughly infiltrated with immune cells called lymphocytes, suggesting that the OVT had worked as expected and provoked Halassy’s immune system to attack both the viruses and the tumour cells. “An immune response was, for sure, elicited,” says Halassy. After the surgery, she received a year’s treatment with the anticancer drug trastuzumab. </p><p>Stephen Russell, an OVT specialist who runs virotherapy biotech company Vyriad in Rochester, Minnesota, agrees that Halassy’s case suggests the viral injections worked to shrink her tumour and cause its invasive edges to recede. </p><p>But he doesn’t think her experience really breaks any new ground, because researchers are already trying to use OVT to help treat earlier-stage cancer. He isn’t aware of anyone trying two viruses sequentially, but says it isn’t possible to deduce whether this mattered in an ‘<i>n</i> of 1’ study. “Really, the novelty here is, she did it to herself with a virus that she grew in her own lab,” he says.</p><h2>Ethical dilemma</h2><p>Halassy felt a responsibility to publish her findings. But she received more than a dozen rejections from journals — mainly, she says, because the paper, co-authored with colleagues, involved self-experimentation. “The major concern was always ethical issues,” says Halassy. She was particularly determined to persevere after she came across a review highlighting the value of self-experimentation<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. </p><p>That journals had concerns doesn’t surprise Jacob Sherkow, a law and medicine researcher at the University of Illinois Urbana-Champaign who has examined the ethics of researcher self-experimentation in relation to COVID-19 vaccines. </p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-023-02075-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_26019860.jpg"><p>Huge leap in breast cancer survival rate</p></a></article><p>The problem is not that Halassy used self-experimentation as such, but that publishing her results could encourage others to reject conventional treatment and try something similar, says Sherkow. People with cancer can be particularly susceptible to trying unproven treatments. Yet, he notes, it’s also important to ensure that the knowledge that comes from self-experimentation isn’t lost. The paper emphasizes that self-medicating with cancer-fighting viruses “should not be the first approach” in the case of a cancer diagnosis. </p><p>“I think it ultimately does fall within the line of being ethical, but it isn’t a slam-dunk case,” says Sherkow, adding that he would have liked to see a commentary fleshing out the ethics perspective, published alongside the case report.</p><p>Halassy has no regrets about self-treating, or her dogged pursuit of publication. She thinks it is unlikely that someone would try to copy her, because the treatment requires so much scientific knowledge and skill. And the experience has given her own research a new direction: in September she got funding to investigate OVT to treat cancer in domestic animals. “The focus of my laboratory has completely turned because of the positive experience with my self-treatment,” she says.</p>
                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memories are not only in the brain, human cell study finds (139 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html</link>
            <guid>42094427</guid>
            <pubDate>Sat, 09 Nov 2024 13:53:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html">https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html</a>, See on <a href="https://news.ycombinator.com/item?id=42094427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/memories-are-not-only.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2024/memories-are-not-only.jpg" data-sub-html="An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/memories-are-not-only.jpg" alt="Memories are not only in the brain, new research finds" title="An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin" width="800" height="530">
             <figcaption>
                An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin
            </figcaption>        </figure>
    </div><p>It's common knowledge that our brains—and, specifically, our brain cells—store memories. But a team of scientists has discovered that cells from other parts of the body also perform a memory function, opening new pathways for understanding how memory works and creating the potential to enhance learning and to treat memory-related afflictions.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>"Learning and <a href="https://medicalxpress.com/tags/memory/" rel="tag">memory</a> are generally associated with brains and brain cells alone, but our study shows that other cells in the body can learn and form memories, too," explains New York University's Nikolay V. Kukushkin, the lead author of the <a href="https://www.nature.com/articles/s41467-024-53922-x" target="_blank">study</a>, which appears in the journal <i>Nature Communications</i>.</p>
<p>The research sought to better understand if non-brain cells help with memory by borrowing from a long-established neurological property—the massed-spaced effect—which shows that we tend to retain information better when studied in spaced intervals rather than in a single, intensive session—better known as cramming for a test.</p>
<p>In the research, the scientists replicated learning over time by studying two types of non-brain human cells in a laboratory (one from nerve tissue and one from kidney tissue) and exposing them to different patterns of chemical signals—just like brain cells are exposed to patterns of neurotransmitters when we learn new information.</p>
<p>In response, the non-brain cells turned on a "memory gene"—the same gene that brain cells turn on when they detect a pattern in the information and restructure their connections in order to form memories.</p>
<p>To monitor the memory and learning process, the scientists engineered these non-brain cells to make a glowing protein, which indicated when the memory gene was on and when it was off.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>The results showed that these cells could determine when the chemical pulses, which imitated bursts of neurotransmitter in the brain, were repeated rather than simply prolonged—just as neurons in our brain can register when we learn with breaks rather than cramming all the material in one sitting.</p>
<p>Specifically, when the pulses were delivered in spaced-out intervals, they turned on the "memory gene" more strongly, and for a longer time, than when the same treatment was delivered all at once.</p>
<p>"This reflects the massed-space effect in action," says Kukushkin, a clinical associate professor of life science at NYU Liberal Studies and a research fellow at NYU's Center for Neural Science. "It shows that the ability to learn from spaced repetition isn't unique to <a href="https://medicalxpress.com/tags/brain+cells/" rel="tag">brain cells</a>, but, in fact, might be a fundamental property of all cells."</p>
<p>The researchers add that the findings not only offer new ways to study memory, but also point to potential health-related gains.</p>
<p>"This discovery opens new doors for understanding how memory works and could lead to better ways to enhance learning and treat memory problems," observes Kukushkin.</p>
<p>"At the same time, it suggests that in the future, we will need to treat our body more like the brain—for example, consider what our pancreas remembers about the pattern of our past meals to maintain healthy levels of blood glucose or consider what a cancer cell remembers about the pattern of chemotherapy."</p>
<p>The work was jointly supervised by Kukushkin and Thomas Carew, a professor in NYU's Center for Neural Science. The study's authors also included Tasnim Tabassum, an NYU researcher, and Robert Carney, an NYU undergraduate researcher at the time of the study.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    N. V. Kukushkin et al, The massed-spaced learning effect in non-neural human cells, <i>Nature Communications</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1038/s41467-024-53922-x" target="_blank">DOI: 10.1038/s41467-024-53922-x</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Memories are not only in the brain, human cell study finds (2024, November 8)
                                                 retrieved 9 November 2024
                                                 from https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I Analyzed 650k TikTok Influencers and This Is What I Found (291 pts)]]></title>
            <link>https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</link>
            <guid>42093911</guid>
            <pubDate>Sat, 09 Nov 2024 11:49:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/">https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</a>, See on <a href="https://news.ycombinator.com/item?id=42093911">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Money was never the end goal – mrdoob – threejs creator (110 pts)]]></title>
            <link>https://twitter.com/mrdoob/status/1854662365163536613</link>
            <guid>42093795</guid>
            <pubDate>Sat, 09 Nov 2024 11:21:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/mrdoob/status/1854662365163536613">https://twitter.com/mrdoob/status/1854662365163536613</a>, See on <a href="https://news.ycombinator.com/item?id=42093795">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Mergiraf: a syntax-aware merge driver for Git (261 pts)]]></title>
            <link>https://mergiraf.org/</link>
            <guid>42093756</guid>
            <pubDate>Sat, 09 Nov 2024 11:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mergiraf.org/">https://mergiraf.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42093756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <p><em>Are you held back by conflicts? Then meet</em></p>

<p>Mergiraf can solve <a href="https://mergiraf.org/conflicts.html">a wide range of Git merge conflicts</a>. That's because it's aware of the trees in your files!
Thanks to <a href="https://mergiraf.org/languages.html">its understanding of your language</a>, it can often reconcile the needs of both sides.</p>
<p>You can <a href="https://mergiraf.org/adding-a-language.html">teach Mergiraf a new language</a> in a completely declarative way. It's a nonviolent animal, so it prefers that over imperatives.</p>
<h2 id="demo">Demo</h2>
<p>Configure Git to use Mergiraf instead of its default merge heuristics. This will enhance <code>git merge</code>, <code>revert</code>, <code>rebase</code>, <code>cherry-pick</code> and more.</p>


<p>You can also keep Git's original behaviour and manually invoke Mergiraf after encountering conflicts.</p>


<div>
<p><img src="https://mergiraf.org/img/scene_1.png" alt="A giraffe observes a fighting pair"></p><p><strong>Figure 1:</strong> Two git users making inadequate use of <code>blame</code>, <code>push</code> and <code>pull</code> to resolve a conflict</p>
</div>
<h2 id="ready-to-give-it-a-try"><a href="#ready-to-give-it-a-try">Ready to give it a try?</a></h2>
<p>Head to the <a href="https://mergiraf.org/installation.html">installation</a> page and start merging nonviolently today!</p>
<h2 id="aspirations"><a href="#aspirations">Aspirations</a></h2>
<p>Mergiraf is designed with your needs in mind. Its goals are:</p>
<h3 id="dont-sweep-conflicts-under-the-rug"><a href="#dont-sweep-conflicts-under-the-rug">Don't sweep conflicts under the rug</a></h3>
<p>Syntax-aware merging heuristics can sometimes be a bit too optimistic in considering a conflict resolved. Mergiraf does its best to err on the side of caution and retain conflict markers in the file when encountering suspicious cases.</p>
<p>If it manages to resolve all conflicts on its own, it encourages you to review its mediation work via the <code>mergiraf review</code> command.
If a merge looks faulty, <a href="https://mergiraf.org/usage.html#reporting-a-bad-merge">you can report it easily</a>.</p>
<h3 id="be-fast-enough-for-interactive-use"><a href="#be-fast-enough-for-interactive-use">Be fast enough for interactive use</a></h3>
<div>
<p><img src="https://mergiraf.org/img/scene_2.png" alt="The giraffe surrounds the pair with its neck and they are surprised by its intervention"></p><p><strong>Figure 2:</strong> Mergiraf offers to mediate</p>
</div>
<p>Did you know that giraffes can run as fast as 60 kilometers per hour? Anyways. The operation of merging diverging versions of files happens routinely when working on a code base, often without you noticing as long as there aren't any conflicts. So Mergiraf tries to be quick so as not to interrupt you in your tasks.</p>
<h3 id="be-open-to-other-methods"><a href="#be-open-to-other-methods">Be open to other methods</a></h3>
<p>In many cases, line-based merging works just great and there is no need for tree-munging business. If a line-based merge is conflict-free, then Mergiraf just returns that merge (which is very quick).
One exception to this rule is <a href="https://mergiraf.org/conflicts.html#line-based-merges">when line-based merging creates duplicate keys</a>. In such a case, Mergiraf does a bit more work to resolve the issue or highlight it to you with conflict markers.</p>


                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HTML-to-Markdown – convert entire websites to Markdown with Golang/CLI (193 pts)]]></title>
            <link>https://github.com/JohannesKaufmann/html-to-markdown</link>
            <guid>42093511</guid>
            <pubDate>Sat, 09 Nov 2024 09:48:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/JohannesKaufmann/html-to-markdown">https://github.com/JohannesKaufmann/html-to-markdown</a>, See on <a href="https://news.ycombinator.com/item?id=42093511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">html-to-markdown</h2><a id="user-content-html-to-markdown" aria-label="Permalink: html-to-markdown" href="#html-to-markdown"></a></p>
<p dir="auto">A robust html-to-markdown converter that transforms HTML (even entire websites) into clean, readable Markdown. It supports complex formatting, customizable options, and plugins for full control over the conversion process.</p>
<p dir="auto">Use the fully extendable <a href="#golang-library">Golang library</a> or a quick <a href="#cli---using-it-on-the-command-line">CLI command</a>. Alternatively, try the <a href="https://html-to-markdown.com/demo" rel="nofollow">Online Demo</a> or <a href="https://html-to-markdown.com/api" rel="nofollow">REST API</a> to see it in action!</p>
<p dir="auto">Here are some <em>cool features</em>:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Bold &amp; Italic:</strong> Supports bold and italic—even within single words.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_bold_italic.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_bold_italic.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>List:</strong> Handles ordered and unordered lists with full nesting support.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_list.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_list.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Blockquote:</strong> Blockquotes can include other elements, with seamless support for nested quotes.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_blockquote.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_blockquote.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Inline Code &amp; Code Block:</strong> Correctly handles backticks and multi-line code blocks, preserving code structure.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_code.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_code.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Link &amp; Image:</strong> Properly formats multi-line links, adding escapes for blank lines where needed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_link_image.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_link_image.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Smart Escaping:</strong> Escapes special characters only when necessary, to avoid accidental Markdown rendering.
🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_escaping.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_escaping.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Remove/Keep HTML:</strong> Choose to strip or retain specific HTML tags for ultimate control over output.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_wrapper.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_wrapper.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Plugins:</strong> Easily extend with plugins. Or create custom ones to enhance functionality.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_strikethrough.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_strikethrough.png" alt=""></a></p>
</li>
</ul>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Golang Library</h2><a id="user-content-golang-library" aria-label="Permalink: Golang Library" href="#golang-library"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go get -u github.com/JohannesKaufmann/html-to-markdown/v2"><pre>go get -u github.com/JohannesKaufmann/html-to-markdown/v2</pre></div>
<p dir="auto"><em>Or if you want a specific commit add the suffix <code>/v2@commithash</code></em></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">This is the documentation for the v2 library. For the old version switch to the <a href="https://github.com/JohannesKaufmann/html-to-markdown/tree/v1">"v1" branch</a>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/JohannesKaufmann/html-to-markdown/v2" rel="nofollow"><img src="https://camo.githubusercontent.com/4de9ed495aaf54b8396c04b85bc3edb47d7736aab876b29756705763dc8d1ec1/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f4a6f68616e6e65734b6175666d616e6e2f68746d6c2d746f2d6d61726b646f776e2f76322e737667" alt="Go V2 Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/JohannesKaufmann/html-to-markdown/v2.svg"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	htmltomarkdown &quot;github.com/JohannesKaufmann/html-to-markdown/v2&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	markdown, err := htmltomarkdown.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: **Bold Text**
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	htmltomarkdown <span>"github.com/JohannesKaufmann/html-to-markdown/v2"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>htmltomarkdown</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: **Bold Text**</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/basics/main.go">Example code, basics</a></li>
</ul>
<p dir="auto">The function <code>htmltomarkdown.ConvertString()</code> is a <em>small wrapper</em> around <code>converter.NewConverter()</code> and the <em>base</em> and <em>commonmark</em> plugins. If you want more control, use the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/converter&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	conv := converter.NewConverter(
		converter.WithPlugins(
			base.NewBasePlugin(),
			commonmark.NewCommonmarkPlugin(
				commonmark.WithStrongDelimiter(&quot;__&quot;),
				// ...additional configurations for the plugin
			),
		),
	)

	markdown, err := conv.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: __Bold Text__
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/converter"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>conv</span> <span>:=</span> <span>converter</span>.<span>NewConverter</span>(
		<span>converter</span>.<span>WithPlugins</span>(
			<span>base</span>.<span>NewBasePlugin</span>(),
			<span>commonmark</span>.<span>NewCommonmarkPlugin</span>(
				<span>commonmark</span>.<span>WithStrongDelimiter</span>(<span>"__"</span>),
				<span>// ...additional configurations for the plugin</span>
			),
		),
	)

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>conv</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: __Bold Text__</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/options/main.go">Example code, options</a></li>
</ul>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If you use <code>NewConverter</code> directly make sure to also <strong>register the commonmark and base plugin</strong>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plugins</h3><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Published Plugins</h4><a id="user-content-published-plugins" aria-label="Permalink: Published Plugins" href="#published-plugins"></a></p>
<p dir="auto">These are the plugins located in the <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/plugin">plugin folder</a>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Base</td>
<td>Implements basic shared functionality (e.g. removing nodes)</td>
</tr>
<tr>
<td>Commonmark</td>
<td>Implements Markdown according to the <a href="https://spec.commonmark.org/" rel="nofollow">Commonmark Spec</a></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>GitHubFlavored</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>TaskListItems</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>Strikethrough</td>
<td>Converts <code>&lt;strike&gt;</code>, <code>&lt;s&gt;</code>, and <code>&lt;del&gt;</code> to the <code>~~</code> syntax.</td>
</tr>
<tr>
<td>Table</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>VimeoEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>YoutubeEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>ConfluenceCodeBlock</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>ConfluenceAttachments</td>
<td><em>planned</em></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Not all the plugins from v1 are already ported to v2. These will soon be implemented...</p>
</div>
<p dir="auto">These are the plugins in other repositories:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>[Plugin Name](Your Link)</td>
<td>A short description</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Writing Plugins</h4><a id="user-content-writing-plugins" aria-label="Permalink: Writing Plugins" href="#writing-plugins"></a></p>
<p dir="auto">You want to write custom logic?</p>
<ol dir="auto">
<li>
<p dir="auto">Write your logic and <strong>register</strong> it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/autocomplete_register.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/autocomplete_register.png" alt=""></a></p>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></li>
</ul>
</li>
<li>
<p dir="auto"><em>Optional:</em> Package your logic into a <strong>plugin</strong> and publish it.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ol>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI - Using it on the command line</h2><a id="user-content-cli---using-it-on-the-command-line" aria-label="Permalink: CLI - Using it on the command line" href="#cli---using-it-on-the-command-line"></a></p>
<p dir="auto">Using the Golang library provides the most customization, while the CLI is the simplest way to get started.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew Tap</h4><a id="user-content-homebrew-tap" aria-label="Permalink: Homebrew Tap" href="#homebrew-tap"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install JohannesKaufmann/tap/html2markdown"><pre>brew install JohannesKaufmann/tap/html2markdown</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manually</h4><a id="user-content-manually" aria-label="Permalink: Manually" href="#manually"></a></p>
<p dir="auto">Download the pre-compiled binaries from the <a href="https://github.com/JohannesKaufmann/html-to-markdown/releases">releases page</a> and copy them to the desired location.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Version</h3><a id="user-content-version" aria-label="Permalink: Version" href="#version"></a></p>

<div dir="auto"><p dir="auto">Note</p><p dir="auto">Make sure that <code>--version</code> prints <code>2.X.X</code> as there is a different CLI for V2 of the converter.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-1" aria-label="Permalink: Usage" href="#usage-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo &quot;<strong>important</strong>&quot; | html2markdown

**important**"><pre>$ <span>echo</span> <span><span>"</span>&lt;strong&gt;important&lt;/strong&gt;<span>"</span></span> <span>|</span> html2markdown

<span>**</span>important<span>**</span></pre></div>
<div data-snippet-clipboard-copy-content="$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)"><pre lang="text"><code>$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)
</code></pre></div>
<p dir="auto"><em>(The cli does not support every option yet. Over time more customization will be added)</em></p>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Extending with Plugins</h3><a id="user-content-extending-with-plugins" aria-label="Permalink: Extending with Plugins" href="#extending-with-plugins"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Need your own logic? Write your own code and then <strong>register</strong> it.</p>
<ul dir="auto">
<li>
<p dir="auto">Don't like the <strong>defaults</strong> that the library uses? You can use <code>PriorityEarly</code> to run you logic <em>earlier</em> than others.</p>
</li>
<li>
<p dir="auto">🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></p>
</li>
</ul>
</li>
<li>
<p dir="auto">If you believe that you logic could also benefit others, you can package it up into a <strong>plugin</strong>.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bugs</h3><a id="user-content-bugs" aria-label="Permalink: Bugs" href="#bugs"></a></p>
<p dir="auto">You found a bug?</p>
<p dir="auto"><a href="https://github.com/JohannesKaufmann/html-to-markdown/issues/new/choose">Open an issue</a> with the HTML snippet that does not produce the expected results. Please, please, plase <em>submit the HTML snippet</em> that caused the problem. Otherwise it is very difficult to reproduce and fix...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">This library produces markdown that is readable and can be changed by humans.</p>
<p dir="auto">Once you convert this markdown back to HTML (e.g. using <a href="https://github.com/yuin/goldmark">goldmark</a> or <a href="https://github.com/russross/blackfriday">blackfriday</a>) you need to be careful of malicious content.</p>
<p dir="auto">This library does NOT sanitize untrusted content. Use an HTML sanitizer such as <a href="https://github.com/microcosm-cc/bluemonday">bluemonday</a> before displaying the HTML in the browser.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/SECURITY.md">SECURITY.md</a> if you find a security vulnerability</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goroutines</h3><a id="user-content-goroutines" aria-label="Permalink: Goroutines" href="#goroutines"></a></p>
<p dir="auto">You can use the <code>Converter</code> from (multiple) goroutines. Internally a mutex is used &amp; there is a test to verify that behaviour.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Escaping &amp; Backslash</h3><a id="user-content-escaping--backslash" aria-label="Permalink: Escaping &amp; Backslash" href="#escaping--backslash"></a></p>
<p dir="auto">Some characters have a special meaning in markdown (e.g. "*" for emphasis). The backslash <code>\</code> character is used to "escape" those characters. That is perfectly safe and won't be displayed in the final render.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You want to contribute? Thats great to hear! There are many ways to help:</p>
<p dir="auto">Helping to answer questions, triaging issues, writing documentation, writing code, ...</p>
<p dir="auto">If you want to make a code change: Please first discuss the change you wish to make, by opening an issue. I'm also happy to guide you to where a change is most likely needed. There are also extensive tests (see below) so you can freely experiment 🧑‍🔬</p>
<p dir="auto"><em>Note: The outside API should not change because of backwards compatibility...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto">You don't have to be afraid of breaking the converter, since there are many "Golden File" tests:</p>
<p dir="auto">Add your problematic HTML snippet to one of the <code>.in.html</code> files in the <code>testdata</code> folders. Then run <code>go test -update</code> and have a look at which <code>.out.md</code> files changed in GIT.</p>
<p dir="auto">You can now change the internal logic and inspect what impact your change has by running <code>go test -update</code> again.</p>
<p dir="auto"><em>Note: Before submitting your change as a PR, make sure that you run those tests and check the files into GIT...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Unless otherwise specified, the project is licensed under the terms of the MIT license.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/LICENSE">LICENSE</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SVDQuant: 4-Bit Quantization Powers 12B Flux on a 16GB 4090 GPU with 3x Speedup (129 pts)]]></title>
            <link>https://hanlab.mit.edu/blog/svdquant</link>
            <guid>42093112</guid>
            <pubDate>Sat, 09 Nov 2024 07:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hanlab.mit.edu/blog/svdquant">https://hanlab.mit.edu/blog/svdquant</a>, See on <a href="https://news.ycombinator.com/item?id=42093112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Muyang Li*, Yujun Lin*, Zhekai Zhang*, Tianle Cai, Xiuyu Li, Junxian Guo, Enze Xie, Chenlin Meng, Jun-Yan Zhu, Song Han</p><p>November 7, 2024</p></div><p>A new post-training training quantization paradigm for diffusion models, which quantize both the weights and activations of FLUX.1 to 4 bits, achieving 3.5× memory and 8.7× latency reduction on a 16GB laptop 4090 GPU.</p><div><p>
  <img src="https://github.com/mit-han-lab/nunchaku/blob/main/assets/demo.gif?raw=true" width="70%">
</p><p>Check our interactive demo at <a href="https://svdquant.mit.edu/">https://svdquant.mit.edu</a>! Our quantization library is at <a href="https://github.com/mit-han-lab/deepcompressor">github.com/mit-han-lab/deepcompressor</a> and inference engine is at <a href="https://github.com/mit-han-lab/nunchaku">github.com/mit-han-lab/nunchaku</a>. Our paper is at <a href="http://arxiv.org/abs/2411.05007">this link</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcef3c3ec127e8078fd_672d1b2115081c1e8ac82ea9_teaser.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant is a post-training quantization technique for 4-bit weights and activations that well maintains visual fidelity. On 12B FLUX.1-dev, it achieves 3.6× memory reduction compared to the BF16 model. By eliminating CPU offloading, it offers 8.7× speedup over the 16-bit model when on a 16GB laptop 4090 GPU, 3× faster than the NF4 W4A16 baseline. On PixArt-∑, it demonstrates significantly superior visual quality over other W4A4 or even W4A8 baselines.</p><h2>Background</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a9dcbacb7d59271c5662e_672a9a6c364fccc4e4443187_trend.jpeg" loading="lazy" alt=""></p><figcaption>Computation <em>v.s.</em> parameters for LLMs and diffusion models.</figcaption></figure><p>Diffusion models are revolutionizing AI with their ability to generate high-quality images from text prompts. To improve image quality and improve the alignment between text and image, researchers are scaling up these models. As shown in the right figure, while Stable Diffusion 1.4 has 800 million parameters, newer models like AuraFlow and FLUX.1 reach billions, delivering more refined and detailed outputs. However, scaling brings challenges: these models become computationally heavy, demanding high memory and longer processing times, making them prohibitive for real-time applications.</p><p>As Moore's law slows down, hardware vendors are turning to low-precision inference, such as NVIDIA's new 4-bit floating point (FP4) precision in Blackwell. In large language models (LLMs), quantization has helped reduce model sizes and speed up inference, primarily by addressing latency from loading model weights. Diffusion models, however, are computationally bound, even for single batches, so quantizing weights alone yields limited gains. To achieve measured speedups, both weights and activations must be quantized to the same bit width; otherwise, the lower precision is upcast during computation, negating any performance benefits.</p><p>In this blog, we introduce SVDQuant to quantize both the weights and activations of diffusion models to 4 bits. At such an aggressive level, conventional post-training methods fall short. Unlike smoothing, which redistributes outliers, SVDQuant absorbs them through a high-precision low-rank branch, significantly preserving image quality. Visual examples demonstrate its effectiveness. See the above figure for some visual examples.</p><h2>SVDQuant: Absorbing Outliers via Low-Rank Branch</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a66701e9812afb49e0cfa_672a651614cb88ed4fd9dc29_intuition-animate.gif" loading="lazy" alt=""></p></figure><div>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LaTeX Rendering Example</title>
    


    <p>
The key idea behind SVDQuant is to introduce an additional low-rank branch that can absorb quantization difficulties in both weights and activations. As shown in the above animation, originally, both the activation \( \boldsymbol{X} \) and weights \( \boldsymbol{W} \) contain massive outliers, making 4-bit quantization challenging. We can first aggregate the outliers by migrating them from activations to weights via smoothing, resulting in the updated activation \( \hat{\boldsymbol{X}} \) and weights \( \hat{\boldsymbol{W}} \). While \( \hat{\boldsymbol{X}} \) becomes easier to quantize, \( \hat{\boldsymbol{W}} \) now becomes more difficult. At the last stage, SVDQuant further decomposes \( \hat{\boldsymbol{W}} \) into a low-rank component \( \boldsymbol{L}_1 \boldsymbol{L}_2 \) and a residual \( \hat{\boldsymbol{W}} - \boldsymbol{L}_1 \boldsymbol{L}_2 \) with Singular Value Decomposition (SVD). As the singular value distribution of \( \hat{\boldsymbol{W}} \) is highly imbalanced, with only the first several values being significantly larger, removing these dominant values can dramatically reduce \( \hat{\boldsymbol{W}} \)’s magnitude and outliers, as suggested by <a href="https://en.wikipedia.org/wiki/Low-rank_approximation">Eckart-Young-Mirsky theorem</a>. Thus, the quantization difficulty is alleviated by the low-rank branch, which runs at 16-bit precision. The below figure illustrates an example value distribution of the input activations and weights in PixArt-∑.
    </p>

</div><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672abca95c5f67bff08b7664_672abca0fde8974bb6d63e6d_distribution.jpeg" loading="lazy" alt=""></p><figcaption>Example value distribution of inputs and weights in PixArt-∑.</figcaption></figure><h2>Nunchaku: Fusing Low-Rank and Low-Bit Branch Kernels</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1fccad9d41d739c84c2c_672a6ac09cf7fc46071c3fb8_672a6a991adf3346a0ee4dbb_engine.jpeg" loading="lazy" alt=""></p></figure><p>Although the low-rank branch adds only minor computational costs on paper, running it separately can lead to significant latency overhead—about 50% of the 4-bit branch's latency, as shown in figure (a). This is because, despite reduced computation costs with a small rank, the data size of input and output activations remains the same, shifting the bottleneck to memory access instead of computation.</p><p>To address this, we co-designed our inference engine, Nunchaku, with the SVDQuant algorithm. Specifically, we noted that the down projection in the low-rank branch uses the same input as the quantization kernel in the low-bit branch, and the up projection shares the same output as the 4-bit computation kernel, as shown in figure (b). By fusing the down projection with the quantization kernel and the up projection with the 4-bit computation kernel, the low-rank branch can now share activations with the low-bit branch. This eliminates extra memory access and cuts the number of kernel calls in half. As a result, the low-rank branch now adds only 5–10% additional latency, making its cost almost negligible.</p><h2>Performance</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcdf3c3ec127e8078f3_672d1b5772f1247fa24e231d_efficiency.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant reduces the model size of the 12B FLUX.1 by 3.6×. Additionally, Nunchaku further cuts memory usage of the 16-bit model by 3.5× and delivers 3.0× speedups over the NF4 W4A16 baseline on both the desktop and laptop NVIDIA RTX 4090 GPUs. Remarkably, on laptop 4090, it achieves in total 10.1× speedup by eliminating CPU offloading. </p><h2>Quality</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672ac9098069a7c6f2baedbd_672ac78c0b59dc8da3c15987_visual.jpeg" loading="lazy" alt=""></p></figure><p>On FLUX.1 models, our 4-bit models outperform the NF4 W4A16 baselines, demonstrating superior text alignment and closer similarity to the 16-bit models. For instance, NF4 misinterprets "dinosaur style," generating a real dinosaur. On PixArt-∑ and SDXL-Turbo, our 4-bit results demonstrate noticeably better visual quality than ViDiT-Q's and MixDQ's W4A8 results.</p><p>‍</p><h2>Integrate with LoRA</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a6c74c47e63fff4b5b216_672a6c25ef1acf8704ef65af_lora.jpeg" loading="lazy" alt=""></p></figure><p>Traditional quantization methods require fusing LoRA branches and then requantizing the model when integrating LoRAs. Our SVDQuant, however, avoids redundant memory access, making it possible to add a separate LoRA branch directly. The figure above shows visual examples of our INT4 FLUX.1-dev model with LoRAs applied in five distinct styles—<a href="https://huggingface.co/XLabs-AI/flux-RealismLora">Realism</a>, <a href="https://huggingface.co/aleksa-codes/flux-ghibsky-illustration">Ghibsky Illustration</a>, <a href="https://huggingface.co/alvdansen/sonny-anime-fixed">Anime</a>, <a href="https://huggingface.co/Shakker-Labs/FLUX.1-dev-LoRA-Children-Simple-Sketch">Children Sketch</a>, and <a href="https://huggingface.co/linoyts/yarn_art_Flux_LoRA">Yarn Art</a>. Our INT4 model adapts seamlessly to each style, maintaining the image quality of the original 16-bit version.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texture-Less Text Rendering (146 pts)]]></title>
            <link>https://poniesandlight.co.uk/reflect/debug_print_text/</link>
            <guid>42093037</guid>
            <pubDate>Sat, 09 Nov 2024 07:27:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://poniesandlight.co.uk/reflect/debug_print_text/">https://poniesandlight.co.uk/reflect/debug_print_text/</a>, See on <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  	
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/look_ma.png" loading="lazy">
</figure>
<div>
<p>Sometimes, all you want is to quickly print some text into a Renderpass. But <a href="https://stackoverflow.com/questions/22080881/how-to-render-text-in-modern-opengl-with-glsl">traditionally, drawing text</a> requires you first to render all possible glyphs of a font into an atlas, to bind this atlas as a texture, and then to render glyphs one by one by drawing triangles on screen, with every triangle picking the correct glyph from the font atlas texture.</p>
<p>This is how <a href="https://github.com/ocornut/imgui">imgui</a> does it, how anyone using <a href="https://github.com/nothings/stb/blob/master/stb_truetype.h">stb_truetype</a> does it, and it’s delightfully close to how <a href="https://en.wikipedia.org/wiki/Typesetting">type setting</a> used to be done ages bygone on physical letterpresses.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/upper_case_and_lower_case.jpg" alt="Composing cases of an early letterpress" title="Composing cases of an early letterpress">
<figcaption>
    Case in point: Some ancient Letterpress Type Cases (public domain) – <a href="https://babel.hathitrust.org/846c4e7f-3fa3-4275-b53c-3183150e9481">source</a><p>In case you wonder – <a href="https://www.mcgill.ca/oss/article/did-you-know-history/why-it-called-upper-and-lower-case">yes</a></p><p>That’s enough (ed).
</p></figcaption>
</figure>
<p>Quaint, correct, but also quite cumbersome.</p>
<p>What if – for quick and dirty debug messaging – there was a simpler way to do this?</p>
<p>Here, I’ll describe a technique for <em>texture-less</em> rendering of debug text. On top of it all, it draws all the text in a single draw call.</p>
<h2 id="the-font-pixels-sans-texture">The Font: Pixels Sans Texture&nbsp;<a href="#the-font-pixels-sans-texture"></a></h2>
<p>How can we get rid of the font atlas texture? We’d need to store a font atlas or something similar <em>directly inside</em> the fragment shader. Obviously, we can’t store <em>bitmaps</em> inside our shaders, but we can store integer constants, which, if you squint hard enough, are nothing but maps of bits. Can we pretend that an integer is a bitmap?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/0x42_as_bitmap.svg" alt="The integer 0x42 as a bitmap" title="The integer 0x42 as a bitmap">
<figcaption>
    An 8 bit integer as a bitmap. The value 66, or <code>0x42</code> in hex notation, translates to <code>0b01000010</code> in binary notation. If we assume that every bit is a pixel  on/off value, we get something like this.
</figcaption>
</figure>
<p>We can draw this to the screen using a GLSL fragment shader by mapping a fragment’s <code>xy</code> position to the bit that is covered by it in the “bitmap”. If the bit is set, we draw in the foreground colour. If the bit is not set, we draw in the background colour.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>bitmap</span> <span>=</span> <span>0x42</span><span>;</span>
</span></span><span><span><span>vec4</span> <span>col_fg</span> <span>=</span> <span>vec4</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span><span>vec4</span> <span>col_bg</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>
</span></span><span><span><span>// vec2 uv is the normalized texture coordinate for the fragment</span>
</span></span><span><span><span>// with the origin top-left</span>
</span></span><span><span><span>uint</span> <span>which_bit</span> <span>=</span> <span>7</span> <span>-</span> <span>min</span><span>(</span><span>7</span><span>,</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>x</span> <span>*</span> <span>8</span><span>));</span> 
</span></span><span><span>
</span></span><span><span><span>out_color</span> <span>=</span> <span>mix</span><span>(</span><span>col_bg</span><span>,</span> <span>col_fg</span><span>,</span> <span>(</span><span>bitmap</span> <span>&gt;&gt;</span> <span>which_bit</span><span>)</span> <span>&amp;</span> <span>1</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Now, one byte will only draw one line of pixels for us. If we want to draw nicer glyphs, we will need more bytes. If we allowed <span>16 bytes</span><span> (that’s 16 lines)</span> per glyph, this would give us an 8x16 pixel canvas to work with. A single <code>uvec4</code>, which is a built-in type in GLSL, covers exactly the correct amount of bytes that we need.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/character_A.svg" alt="The Glyph A encoded as an uvec4" title="The Glyph A encoded as an uvec4">
<figcaption>
    The character <code>A</code> encoded in 16 bytes, stored as an <code>uvec4</code>, that’s 4 uints with each 4 bytes.
</figcaption>
</figure>
<p>16 bytes per glyph seems small enough; It should allow us to encode the complete <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> subset of 96 printable glyphs in all of 1536 bytes of shader <span>memory</span><span>. (We could probably compress this further, but we would lose simplicity and/or readability)</span>.</p>
<h2 id="where-do-we-get-the-bitmaps-from">Where do we get the bitmaps from?&nbsp;<a href="#where-do-we-get-the-bitmaps-from"></a></h2>
<p>Conveniently, the encoding of a font into bitmaps such as described above is very much the definition of the venerable <a href="https://en.wikipedia.org/wiki/PC_Screen_Font">PSF1 format</a>, give or take a few header bytes. We can therefore harvest the glyph pixels from any PSF1 terminal font by opening it in a hex editor such as <a href="https://imhex.werwolv.net/">ImHex</a>, travelling past the header (4 bytes) and the first section of non-printable glyphs (512 bytes), and then exporting the raw data for the next 96 glyphs (1536 bytes) by using “Copy as → C Array”.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/imhex_screenshot.png" alt="A Screenshot of ImHex" title="A Screenshot of ImHex">
<figcaption>
    The ImHex hex editor has a really useful feature: you can copy binary data as a c-array.
</figcaption>
</figure>
<p>This will give us a nicely formatted array of chars, which we can easily edit into an array of <code>uint</code>s, which we then group into <code>uvec4</code>s. We need to remember that just concatenating the raw chars into <code>uint</code>s flips the endianness of our <code>uint</code>s, but we can always flip this back when we sample the font data…</p>
<p>Once we’re done, this is how our font bitmap data table looks like in the fragment shader:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uvec4</span> <span>font_data</span><span>[</span><span>96</span><span>]</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x1e: SPACE</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080800</span><span>,</span> <span>0x08080000</span> <span>},</span> <span>// 0x21: '!'</span>
</span></span><span><span>  <span>{</span> <span>0x00002222</span><span>,</span> <span>0x22220000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x22: '\'</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x1212127E</span><span>,</span> <span>0x24247E48</span><span>,</span> <span>0x48480000</span> <span>},</span> <span>// 0x23: '#'</span>
</span></span><span><span>  <span>// ... etc ... </span>
</span></span><span><span>
</span></span><span><span>  <span>{</span> <span>0x00000808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span> <span>},</span> <span>// 0x7C: '|'</span>
</span></span><span><span>  <span>{</span> <span>0x00000030</span><span>,</span> <span>0x08081010</span><span>,</span> <span>0x08040810</span><span>,</span> <span>0x10080830</span> <span>},</span> <span>// 0x7D: '}'</span>
</span></span><span><span>  <span>{</span> <span>0x00000031</span><span>,</span> <span>0x49460000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x7E: '~'</span>
</span></span><span><span>  <span>{</span> <span>0xFC1B26EF</span><span>,</span> <span>0xC8E04320</span><span>,</span> <span>0x8958625E</span><span>,</span> <span>0x79BAEE7E</span> <span>},</span> <span>// 0x7F: BACKSPACE</span>
</span></span><span><span><span>};</span>                                              </span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>I say table, because the <code>font_data</code> array now stores the bitmaps for 96 character glyphs, indexed by their ASCII value (minus 0x20). This table therefore covers the full printable ASCII range from <code>0x20</code> <kbd>SPACE</kbd> to <code>0x7F</code> <kbd>BACKSPACE</kbd> (inclusive), but in the snippet above I’m showing only 8 of them, to save space.</p>
<p>So far, all this is just so that we don’t have to bind a texture when drawing our text. But how to draw the text itself?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small.png" alt="Text output" title="Text output">
<figcaption>
    This is what we want to print at the end of this process
</figcaption>
</figure>
<h2 id="one-draw-call-thats-all">One Draw Call, That’s All.&nbsp;<a href="#one-draw-call-thats-all"></a></h2>
<p>We’re going to use a single <strong>instanced</strong> draw call.</p>

</div>
<div>
    
<p>With instanced drawing, we don’t have to repeatedly issue draw <em>instructions</em>, since we encode the logic into per-instance data. One draw call contains everything we need, provided it uses two attribute streams. The fist stream, per-draw, has just the necessary information to draw a generic quad. And the second stream, per-instance, packs the two pieces of information that change with every instance of such a quad: First, a position offset, so that we know <em>where in screen space</em> to draw the quad. And second, of course, the text that we want to print.</p>
<p>For the position offset we can use one float each for x and y, which leaves two floats for this particular attribute binding <span>unused</span><span> (attribute bindings in GLSL/Vulkan are at minimum the equivalent of 4 floats wide)</span>. We have more than enough space to use one extra float to pack in a font scale parameter, if we like.</p>

</div>
<div>
  
<p>For the text that we want to print, we have a similarly wasteful situation – the smallest basic vertex attribute data type <a href="https://docs.vulkan.org/spec/latest/chapters/fxvertex.html#fxvertex-attrib-location">is usually 32bit wide</a>, and so it makes sense to make best use of this and pack at least 4 characters at a time. If we do this, we must make sure that the message that we want to print has a length divisible by 4. If it was shorter, we need to fill up the difference with zero byte (<code>\0</code>) characters. Conveniently, the zero byte is also used to signal the end of a c-string.</p>
<p>Our per-instance data looks like this:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>struct</span> <span>word_data</span> <span>{</span>
</span></span><span><span>  <span>float</span>          <span>pos_and_scale</span><span>[</span> <span>3</span> <span>];</span> <span>// xy position + scale 
</span></span></span><span><span><span></span>  <span>uint32_t</span>       <span>word</span><span>;</span>               <span>// four characters that we want to print
</span></span></span><span><span><span></span><span>};</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>It’s the application’s responsibility to split up the message into chunks of 4 characters, to convert these four characters into an <code>unit32_t</code>, and to store it into a <code>word_data</code> struct together with the position offset for where on screen to render these four characters. Once a <code>word_data</code> is filled, we append it into an array where we accumulate all the data for our text draw calls. Once we are ready to draw, we can then bind this array as a per-instance binding to our debug text drawing pipeline, and draw all text with a single <span>instanced draw call</span><span>, with the number of instances being the number of quads that we want to draw</span>.</p>
<p>More interesting things happen in the vertex and fragment shader of the debug text drawing pipeline.</p>
<h2 id="vertex-shader">Vertex Shader&nbsp;<a href="#vertex-shader"></a></h2>
<p>Our vertex shader produces three outputs.</p>
<p>First, it writes to <code>gl_Position</code> to place the vertices for our triangles on the screen. This operates in <span> NDC </span><span> = Normalised Device </span> “screen space” Coordinates. We calculate an offset for each vertex using the per-instance <code>pos_and_scale</code> attribute data.</p>
<p>The second output of the vertex shader is the word that we want to render: We just pass though the attribute <code>uint</code> as an output to the fragment shader – but we make sure to use the <code>flat</code> qualifier so that it does not get interpolated.</p>
<p>And then, the vertex shader synthesizes texture coordinates (via <code>gl_VertexIndex</code>). It does so pretty cleverly:</p>
<ul>
<li><code>12 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>0, 0, 1, 1</code>,</li>
<li><code> 9 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>1, 0, 0, 1</code>,</li>
</ul>
<p>This creates a sequence of uv coordinates <code>(0,1), (0,0), (1,0), (1,1)</code> in a branchless way.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>#version 450 core</span>
</span></span><span><span>
</span></span><span><span><span>#extension GL_ARB_separate_shader_objects : enable</span>
</span></span><span><span><span>#extension GL_ARB_shading_language_420pack : enable</span>
</span></span><span><span>
</span></span><span><span><span>// Inputs </span>
</span></span><span><span><span>// Uniforms - Push Constants</span>
</span></span><span><span><span>layout</span> <span>(</span><span>push_constant</span><span>)</span> <span>uniform</span> <span>Params</span>
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>vec2</span> <span>u_resolution</span><span>;</span> <span>// screen canvas resolution in physical pixels</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>// Input Attributes</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>in</span> <span>vec3</span> <span>pos</span><span>;</span>      <span>// "vanilla" vertex position attribute - given in pixels</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>in</span> <span>uint</span> <span>word</span><span>;</span>     <span>// per-instance: four chars</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>2</span><span>)</span> <span>in</span> <span>vec3</span> <span>word_pos</span><span>;</span> <span>// per-instance: where to place the word in screen space</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>3</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_fg</span><span>;</span>   <span>// per-instance: foreground colour</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>4</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_bg</span><span>;</span>   <span>// per-instance: background colour</span>
</span></span><span><span>
</span></span><span><span><span>// Vertex Outputs </span>
</span></span><span><span><span>struct</span> <span>per_word_data</span> <span>{</span>
</span></span><span><span>	<span>uint</span> <span>msg</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>fg_colour</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>bg_colour</span><span>;</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>out</span> <span>gl_PerVertex</span> <span>{</span> <span>vec4</span> <span>gl_Position</span><span>;</span> <span>};</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>out</span> <span>vec2</span> <span>outTexCoord</span><span>;</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>flat</span> <span>out</span> <span>per_word_data</span> <span>outMsg</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>void</span> <span>main</span><span>()</span> 
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>msg</span> <span>=</span> <span>word</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>fg_colour</span> <span>=</span> <span>col_fg</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>bg_colour</span> <span>=</span> <span>col_bg</span><span>;</span>
</span></span><span><span>
</span></span><span><span>	<span>vec2</span> <span>scale_factor</span> <span>=</span> <span>vec2</span><span>(</span><span>1.</span><span>,</span><span>2.</span><span>)</span><span>/</span><span>(</span><span>u_resolution</span><span>);</span>
</span></span><span><span>	<span>outTexCoord</span> <span>=</span> <span>vec2</span><span>((</span><span>12</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span><span>)</span> <span>&amp;</span><span>1</span><span>,</span> <span>(</span><span>9</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span> <span>)</span> <span>&amp;</span><span>1</span><span>);</span>
</span></span><span><span>	<span>vec4</span> <span>position</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>	<span>position</span><span>.</span><span>xy</span> <span>=</span> <span>vec2</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>-</span><span>1</span><span>)</span> <span>+</span> <span>(</span><span>pos</span><span>.</span><span>xy</span> <span>*</span> <span>word_pos</span><span>.</span><span>z</span> <span>+</span> <span>word_pos</span><span>.</span><span>xy</span><span>)</span> <span>*</span> <span>scale_factor</span><span>;</span>
</span></span><span><span>	<span>gl_Position</span> <span>=</span> <span>position</span><span>;</span>
</span></span><span><span><span>}</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>If we at this point visualise just the output of the vertex shader, we will get something like this:</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv_continuous.png" alt="Quad visualisation with uv coords" title="Quad visualisation with uv coords">
<figcaption>
    Visualisation of per-quad <code>outTexCoord</code> uv coords. Note that these are continuous (smooth).
</figcaption>
</figure>
<h2 id="fragment-shader">Fragment Shader&nbsp;<a href="#fragment-shader"></a></h2>

</div>
<div>
  
<p>Our fragment shader needs three pieces of information to render text, two of which it receives from the vertex shader stage:</p>
<ol>
<li>The fragment’s interpolated uv coordinate, <code>uv</code></li>
<li>The character that we want to draw, <code>in_word</code></li>
<li>The font data array, <code>font_data</code></li>
</ol>
<p>To render a glyph, each fragment must map its uv-coordinate to the correct bit of the glyph bitmap. If the bit at the lookup position is set, then render the fragment in the foreground colour, otherwise render it in background colour.</p>
<p>This mapping works like this:</p>
<p>First, we must map the uv coordinates to <span>word </span><span>– <strong>word</strong> not, <em>world</em>! –</span> pixel coordinates. The nice thing about these two coordinate systems is that they both have their origin at the <span>top left</span><span>, so we only need to bother with scaling, and not origin transformation</span>.</p>
<p>We know that our uv coordinates are normalised floats going from <code>vec2(0.f,0.f)</code> to <code>vec2(1.f,1.f)</code>, while our font pixel coordinates are integers, going from <code>uvec2(0,0)</code> to <code>uvec2(7,15)</code>.</p>
<p>We also must find out which one of the four characters in the word to draw.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uint</span> <span>WORD_LEN</span> <span>=</span> <span>4</span><span>;</span> <span>// 4 characters in a word</span>
</span></span><span><span>
</span></span><span><span><span>// quantize uv coordinate to discrete steps</span>
</span></span><span><span><span>uvec2</span> <span>word_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>xy</span> <span>*</span> <span>vec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span><span>,</span> <span>16</span><span>)));</span> 
</span></span><span><span><span>// limit pixel coord range to uvec2(0..31, 0..15)</span>
</span></span><span><span><span>word_pixel_coord</span> <span>=</span> <span>min</span><span>(</span><span>uvec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span> <span>-</span><span>1</span><span>,</span> <span>16</span> <span>-</span><span>1</span><span>),</span> <span>word_pixel_coord</span><span>);</span>
</span></span><span><span><span>// Find which of the four characters in the word this fragment falls onto</span>
</span></span><span><span><span>uint</span> <span>printable_character</span> <span>=</span> <span>in_word</span> <span>&gt;&gt;</span> <span>(</span><span>WORD_LEN</span> <span>-</span> <span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>/</span> <span>8</span><span>));</span>
</span></span><span><span><span>// Map fragment coordinate to pixel coordinate inside character bitmap</span>
</span></span><span><span><span>uvec2</span> <span>glyph_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>%</span> <span>8</span><span>,</span> <span>word_pixel_coord</span><span>.</span><span>y</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv.png" alt="Quad visualisation of word_pixel_coord" title="Quad visualisation of word_pixel_coord">
<figcaption>
    A visualisation of <code>word_pixel_coord</code> (normalised)
</figcaption>
</figure>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv.png" alt="Quad visualisation of glyph_pixel_coord" title="Quad visualisation of glyph_pixel_coord">
<figcaption>
    A visualisation of <code>glyph_pixel_coord</code> (normalised)
</figcaption>
</figure>
<p>Remember, to draw a character, we must look up the character in the font bitmap table, where we must find the correct bit to check based on the uv coordinate of the fragment. You will notice that in the first GLSL example above, we were only worried about the <code>.x</code> coordinate. Now, let’s focus on <code>.y</code>, so that we can draw more lines of pixels by looking up the correct line to sample from.</p>
<p>Let’s do this step by step. First, we fetch the character bitmap from our <code>font_data</code> as an <code>uvec4</code>. Then we use the <code>glyph_pixel_coord.y</code> to pick the correct one of 4 <code>uints</code> that make up the glyph. This will give us four lines of pixels.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>// First, map character ASCII code to an index offset into font_data table. </span>
</span></span><span><span><span>// The first character in the font_data table is 0x20, SPACE.</span>
</span></span><span><span><span>offset</span> <span>=</span> <span>printable_character</span> <span>-</span> <span>0x20</span><span>;</span> 
</span></span><span><span><span>// Then get the bitmap for this glyph</span>
</span></span><span><span><span>uvec4</span> <span>character_bitmap</span> <span>=</span> <span>font_data</span><span>[</span><span>offset</span><span>];</span> 
</span></span><span><span><span>// Find the uint that contains one of the four lines that </span>
</span></span><span><span><span>// are touched by our pixel coordinate</span>
</span></span><span><span><span>uint</span> <span>four_lines</span> <span>=</span> <span>character_bitmap</span><span>[</span><span>glyph_pixel_coord</span><span>.</span><span>y</span> <span>/</span> <span>4</span><span>];</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Once we have the <code>uint</code> covering four lines, we must pick the correct line from it.</p>
<p>Note that lines are stored in reverse order because after we used ImHex to lift the bitmap bytes out of the font file, we just concatenated the <code>chars</code> into <code>uint</code>. This means that our bitmap <code>uint</code>s have the wrong endianness; We want to keep it like this though, because it is much less work to just concatenate chars copied form ImHex than to manually convert endianness in a text editor.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_line</span>  <span>=</span> <span>(</span><span>four_lines</span> <span>&gt;&gt;</span> <span>(</span><span>8</span><span>*</span><span>(</span><span>3</span><span>-</span><span>(</span><span>glyph_pixel_coord</span><span>.</span><span>y</span><span>)</span><span>%</span><span>4</span><span>)))</span> <span>&amp;</span> <span>0xff</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>And, lastly, we must pick the correct bit in the bitmap. Note the <code>7-</code> – this is because bytes are stored with the most significant bit at the highest index. To map this to a left-to-right coordinate system, we must index backwards, again.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_pixel</span> <span>=</span> <span>(</span><span>current_line</span> <span>&gt;&gt;</span> <span>(</span><span>7</span><span>-</span><span>glyph_pixel_coord</span><span>.</span><span>x</span><span>))</span> <span>&amp;</span> <span>0x01</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>We now can use the current pixel to shade our fragment, so that if the pixel is set in the bitmap, we shade our fragment in the foreground colour, and if it is not set, shade our fragment in the background colour:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>vec3</span> <span>color</span> <span>=</span> <span>mix</span><span>(</span><span>background_colour</span><span>,</span> <span>foreground_colour</span><span>,</span> <span>current_pixel</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv_overlay.png" alt="Quad visualisation" title="Quad visualisation">
<figcaption>
    Text printed with uv coordinates overlaid
</figcaption>
</figure>
<p>What about the fill chars that get inserted if our printable text is too short to be completely divisible by 4? We detect these in the fragment shader: In case were are about to render such a fill character, we should do absolutely nothing, not even draw the background. We can do this by testing <code>printable_character</code>, and issuing a <code>discard</code> in case the printable character is <code>\0</code>.</p>
<h2 id="a-visual-summary">A Visual Summary&nbsp;<a href="#a-visual-summary"></a></h2>
<p>It is said that an image is worth a thousand words. Why not have both? Here is a diagram which summarises the mapping from quad-uv space to glyph bitmap space:</p>
</div>
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/summary.svg" loading="lazy">
<figcaption>
	    <div><p>Note: Our Fragment position is marked by the blue speck.</p><p>① pick the correct character from our per-quad word. ② calculate the offset into <code>font_data</code> using the character ASCII code. ③ fetch the <code>uvec4</code> that holds the bitmap for our glyph from <code>font_data</code> ④ pick the <code>uint</code> representing the four lines of the glyph that our fragment falls in (via its y-coord) ⑤ pick the correct line using the fragment’s .y coord ⑥ pick the correct bit using the per-glyph <code>x</code> coordinate.
	    </p></div>
</figcaption>
</figure>
<div>
<h2 id="full-implementation--more-source-code">Full Implementation &amp; More Source Code&nbsp;<a href="#full-implementation--more-source-code"></a></h2>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/island_preview.png" alt="Island preview image" title="Island preview image">
<figcaption>
    You can find an implementation of the technique described above in the source code for <a href="https://github.com/tgfrerer/island/tree/wip/modules/le_debug_print_text">le_print_debug_print_text</a>, which is a new <a href="https://poniesandlight.co.uk/tags/island/">Island</a> module that allows you to easily print debug messages to screen. It has some extra nice bits around text processing and caching which, however, would be too wordy to describe here.
</figcaption>
</figure>
<p>Using this technique, it is now possible, from nearly anywhere in an Island project, to call:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>char</span> <span>const</span> <span>msg_2</span><span>[]</span> <span>=</span> <span>{</span> <span>70</span><span>,</span> <span>111</span><span>,</span> <span>108</span><span>,</span> <span>107</span><span>,</span> <span>115</span><span>,</span> <span>'!'</span><span>,</span> <span>0</span> <span>};</span>
</span></span><span><span><span>le</span><span>::</span><span>DebugPrint</span><span>(</span> <span>"That's all, %s"</span><span>,</span> <span>msg_2</span> <span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>And see the following result on screen:

</p><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/that_s_all_folks.png" alt="Image That&amp;rsquo;s all Folks">
</figure>
<h2 id="acknowledgements">Acknowledgements&nbsp;<a href="#acknowledgements"></a></h2>
<ul>
<li>Diagrams drawn with <a href="https://excalidraw.com/">Excalidraw</a></li>
<li>Original source data for the pixel font came from <a href="http://www.fial.com/~scott/tamsyn-font/">Tamsyn</a>, a free pixel font by Scott Fial</li>
</ul>
<h2 id="backlinks">Backlinks&nbsp;<a href="#backlinks"></a></h2>
<p>This article was featured on <a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-363/">Graphics Programming Weekly</a>, and discussed on <a href="https://lobste.rs/s/5iiqji/texture_less_text_rendering">Lobste.rs</a>, and <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a>.</p>
<p>If you like more of this, subscribe to the rss feed, and if you want the very latest, and hear about occasional sortees into generative art and design, follow me on <a href="https://bsky.app/profile/tgfrerer.bsky.social">bluesky</a> or <a href="https://mastodon.social/@tgfrerer">mastodon</a>, or maybe even <a href="https://www.instagram.com/tgfrerer/">Instagram</a>. Shameless plug: my services are also available for contract work.</p>


	</div>
	
	
	
		<div>
			<h3>RSS:</h3>
			<p>Find out first about new posts by subscribing to the <a href="https://poniesandlight.co.uk//reflect/feed.xml">RSS Feed</a> <a href="https://poniesandlight.co.uk//reflect/feed.xml" type="application/rss+xml"><svg style="width: 1em; position:relative; bottom:-0.25em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm64 120c0 17.7-14.3 32-32 32s-32-14.3-32-32s14.3-32 32-32s32 14.3 32 32z"></path></svg></a></p>
		</div>
	
		<p>
			<h3>Further Posts:</h3>
		</p>
		
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's legal for police to use deception in interrogations. Some want that to end (261 pts)]]></title>
            <link>https://text.npr.org/nx-s1-4974964</link>
            <guid>42091423</guid>
            <pubDate>Fri, 08 Nov 2024 23:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/nx-s1-4974964">https://text.npr.org/nx-s1-4974964</a>, See on <a href="https://news.ycombinator.com/item?id=42091423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ted Bradford says the worst day of his life was when detectives took him into a tiny room to question him about a rape.</p><p>“The whole day it was like accusation after accusation,” he says. “I kept telling them over and over, ‘I didn't do this.’”</p><p>Bradford says the officers in Yakima, Wash., <a href="https://wainnocenceproject.org/stories/ted-bradford/"><u>claimed they had biological evidence</u></a> that would prove he did it, and they weren't going to let him leave until he admitted it.</p><p>“I knew I didn’t do it,” he said. “So I'm thinking, ‘In order to get out of this situation, I could just give them a statement. They’ll test that evidence. It’ll show that I didn’t do it, and then this will all be done with.’”</p><p>After<em> </em>hours of questioning, Bradford confessed to the crime. But the evidence police had – a mask left at the scene – could not be DNA-tested. This was the late nineties and the technology wasn’t there yet.</p><p>Bradford recanted his confession, but was convicted anyway. He was 22 with two small children when he went to prison.</p><p>“Every day I woke up and knew that I shouldn't be there,” he says.</p><p>Advancements in DNA testing helped lead to his exoneration in 2010.</p><p>What happened to Bradford might seem extreme, but nearly 30 years later, the tactic used on him is not. In every state, police officers are allowed to lie to adults during an interrogation. The hope, in many cases, is that they’ll get a person to confess to committing a crime.</p><p>When it comes to children and teenagers, a growing number of states are stopping that practice: Ten have passed laws in recent years effectively banning police from lying to juveniles during interrogations, starting with Illinois in 2021. But some legal advocates are pushing for a deception ban that would apply to everyone, not just kids.</p><h2>‘A quick and relatively straightforward way to close a case’</h2><p>Deception is a powerful law enforcement tool in eliciting confessions, says wrongful convictions attorney Laura Nirider.</p><p>“Police are trained around the country in all 50 states to use deception during interrogation, to lie both about the evidence against a suspect and to lie about the consequences of confessing in order to make it seem not so bad if you just say that you did these things,” she says.</p><p>Police can go into an interrogation room with a suspect, Nirider says, and emerge with “one of the most believable pieces of evidence imaginable, a confession.”</p><p>“It's a quick and relatively straightforward way to close a case,” she says.</p><p>But Nirider says using deception can also draw false confessions.</p><p>According to the Innocence Project, a national organization that works to overturn wrongful convictions, nearly a third of DNA exonerations from 1989 to 2020 <a href="https://innocenceproject.org/dna-exonerations-in-the-united-states/"><u>involved a false confession</u></a>.</p><p>Legal experts say the deception bans passed in recent years fail to protect other vulnerable groups: young adults, people with intellectual disabilities, even just people who are naturally compliant.</p><p>“Children are one category that makes you more vulnerable, but it's certainly not the only category,” says Lara Zarowsky, executive and policy director at the Washington Innocence Project. “It's something that all of us are vulnerable to.”</p><h2>‘Law enforcement is the biggest impediment’</h2><p>In Washington state, where Bradford was convicted, Democratic lawmakers want to set a higher bar: A bill that would make incriminating statements made in police custody – by adults or children – largely inadmissible in court if obtained using deception.</p><p>State Rep. Strom Peterson has introduced the bill twice, but it hasn’t gone anywhere.</p><p>“Law enforcement is the biggest impediment to the bill. They believe that the system in which they work is effective,” he says.</p><p>The Washington Association of Sheriffs and Police Chiefs declined NPR’s request for an interview, but said in a statement that it opposes such a measure, because banning deception would take away a tactic that yields “many more true confessions” than false ones.</p><p>“We fear that it will negatively impact our ability to solve crimes and would result in less accountability for those who victimize others,” the association’s policy director, James McMahan, <a href="https://tvw.org/video/house-appropriations-2024021057/?eventID=2024021057"><u>said at a hearing</u></a> for the bill in February.</p><p>“Criminals often conduct elaborate stories to conceal their crimes,” McMahan said at the hearing. “Sometimes the use of deception is required to locate the truth both to convict and to exonerate people. Such deceptions include telling a person that abuse was discovered during a routine medical exam rather than reported by a family member.”</p><p>In its statement, the association added that judges assess whether confessions are given voluntarily before they can be introduced as evidence, and convictions based solely on confessions are rare.</p><p>Even with other evidence, however, confessions carry a lot of weight. Research indicates that people who confess <a href="https://core.ac.uk/reader/81748492?utm_source=linkout"><u>are treated differently</u></a> afterwards: They’re more likely to be charged, face more charges, and receive a harsher punishment when convicted.</p><p>“A confession will trump everything,” says Jim Trainum, a retired homicide detective in Washington, D.C.</p><p>In his experience, there is pressure to move on after a suspect confesses because a detective’s measure of success is often tied to closure rates.</p><p>“Let's say that I get a confession and I get all the stuff that I want to go out and corroborate. I want to make sure that this is an accurate confession,” Trainum says. “I'm sitting there at my desk working very, very hard on it. And my sergeant comes up and says, ‘What are you doing? That's a confession. That's closed. Move on. You got other ones to take care of.’”</p><h2>‘Trying to give the police new tools’</h2><p>Those against deception bans see them as an attack on police, says Mark Fallon, a consultant on interrogation practices and former federal agent. In fact, he says, it’s the opposite.</p><p>“It is actually trying to give the police new tools, better tools,” he says.</p><p>There’s another way for police to question people, Fallon says, that relies on building rapport and asking open-ended questions, and where the primary goal is information, rather than a confession.</p><p>That technique is used in other countries, including much of Europe. In England, France, Germany, Australia, Japan and elsewhere, for instance, the police are generally <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3669413"><u>not allowed to deceive suspects</u></a>.</p><p>Trainum says interrogation methods that don’t rely on deception ultimately make the police more trustworthy to communities.</p><p>“Today’s suspect is tomorrow's witness,” he says.</p><p>When a suspect or witness has been lied to, he says, “that radiates out. And no wonder people don't trust us. Why should they trust us?”</p><p>That is why Peterson, the lawmaker, plans to introduce the bill in Washington again. He says the public is<em> </em>better off when police use the best tools available to convict the right people.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delta: A syntax-highlighting pager for Git, diff, grep, and blame output (528 pts)]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>42091365</guid>
            <pubDate>Fri, 08 Nov 2024 23:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dandavison/delta">https://github.com/dandavison/delta</a>, See on <a href="https://news.ycombinator.com/item?id=42091365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png" alt="image"></a>
</p>
<p dir="auto">
  <a href="https://github.com/dandavison/delta/actions">
    <img src="https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg" alt="CI">
  </a>
  <a href="https://coveralls.io/github/dandavison/delta?branch=main" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e8785ac8ede00f6ec8ad672e5031d27eb6eb5a599d56b232a469b9824f76753c/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64616e64617669736f6e2f64656c74612f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main">
  </a>
  <a href="https://gitter.im/dandavison-delta/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6c92914f6e39c859372cd85d6c7676c73d524f994663f1ae0e2b0b566a0e1361/68747470733a2f2f6261646765732e6769747465722e696d2f64616e64617669736f6e2d64656c74612f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/dandavison-delta/community.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><a href="https://dandavison.github.io/delta/installation.html" rel="nofollow">Install it</a> (the package is called "git-delta" in most package managers, but the executable is just <code>delta</code>) and add this to your <code>~/.gitconfig</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true    # use n and N to move between diff sections

    # delta detects terminal colors automatically; set one of these to disable auto-detection
    # dark = true
    # light = true

[merge]
    conflictstyle = zdiff3"><pre>[<span>core</span>]
    <span>pager</span> <span>=</span> <span>delta</span>

[<span>interactive</span>]
    <span>diffFilter</span> <span>=</span> <span>delta</span> <span>--color-only</span>

[<span>delta</span>]
    <span>navigate</span> <span>=</span> <span>true</span>    <span><span>#</span> use n and N to move between diff sections</span>

    <span><span>#</span> delta detects terminal colors automatically; set one of these to disable auto-detection</span>
    <span><span>#</span> dark = true</span>
    <span><span>#</span> light = true</span>

[<span>merge</span>]
    <span>conflictstyle</span> <span>=</span> <span>zdiff3</span></pre></div>
<p dir="auto">Delta has many features and is very customizable; please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Language syntax highlighting with the same syntax-highlighting themes as <a href="https://github.com/sharkdp/bat#readme">bat</a></li>
<li>Word-level diff highlighting using a Levenshtein edit inference algorithm</li>
<li>Side-by-side view with line-wrapping</li>
<li>Line numbering</li>
<li><code>n</code> and <code>N</code> keybindings to move between files in large diffs, and between diffs in <code>log -p</code> views (<code>--navigate</code>)</li>
<li>Improved merge conflict display</li>
<li>Improved <code>git blame</code> display (syntax highlighting; <code>--hyperlinks</code> formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)</li>
<li>Syntax-highlights grep output from <code>rg</code>, <code>git grep</code>, <code>grep</code>, etc</li>
<li>Support for Git's <code>--color-moved</code> feature.</li>
<li>Code can be copied directly from the diff (<code>-/+</code> markers are removed by default).</li>
<li><code>diff-highlight</code> and <code>diff-so-fancy</code> emulation modes</li>
<li>Commit hashes can be formatted as terminal <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">hyperlinks</a> to the hosting provider page (<code>--hyperlinks</code>).
File paths can also be formatted as hyperlinks for opening in your OS.</li>
<li>Stylable box/line decorations to draw attention to commit, file and hunk header sections.</li>
<li>Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git</li>
<li>Handles traditional unified diff output in addition to git output</li>
<li>Automatic detection of light/dark terminal background</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">A syntax-highlighting pager for git, diff, and grep output</h2><a id="user-content-a-syntax-highlighting-pager-for-git-diff-and-grep-output" aria-label="Permalink: A syntax-highlighting pager for git, diff, and grep output" href="#a-syntax-highlighting-pager-for-git-diff-and-grep-output"></a></p>
<p dir="auto">Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.</p>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a>
      <br>
      <sub>delta with <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a>
      <br>
      <sub>delta with <code>side-by-side</code> and <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<p dir="auto">Here's what <code>git show</code> can look like with git configured to use delta:</p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax-highlighting themes</h3><a id="user-content-syntax-highlighting-themes" aria-label="Permalink: Syntax-highlighting themes" href="#syntax-highlighting-themes"></a></p>
<p dir="auto"><strong>All the syntax-highlighting color themes that are available with <a href="https://github.com/sharkdp/bat/">bat</a> are available with delta:</strong></p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Side-by-side view</h3><a id="user-content-side-by-side-view" aria-label="Permalink: Side-by-side view" href="#side-by-side-view"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/side-by-side-view.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    side-by-side = true"><pre>[<span>delta</span>]
    <span>side-by-side</span> <span>=</span> <span>true</span></pre></div>
<p dir="auto">By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [<a href="#side-by-side-view-1">config</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto">Side-by-side view wraps long lines automatically:</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Line numbers</h3><a id="user-content-line-numbers" aria-label="Permalink: Line numbers" href="#line-numbers"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/line-numbers.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    line-numbers = true"><pre>[<span>delta</span>]
    <span>line-numbers</span> <span>=</span> <span>true</span></pre></div>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Merge conflicts</h3><a id="user-content-merge-conflicts" aria-label="Permalink: Merge conflicts" href="#merge-conflicts"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/merge-conflicts.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png"><img width="500px" src="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Git blame</h3><a id="user-content-git-blame" aria-label="Permalink: Git blame" href="#git-blame"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/git-blame.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ripgrep, git grep</h3><a id="user-content-ripgrep-git-grep" aria-label="Permalink: Ripgrep, git grep" href="#ripgrep-git-grep"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/grep.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"><img width="600px" alt="image" src="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"></a>
</p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation and usage</h3><a id="user-content-installation-and-usage" aria-label="Permalink: Installation and usage" href="#installation-and-usage"></a></p>
<p dir="auto">Please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a> and <code>delta --help</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maintainers</h3><a id="user-content-maintainers" aria-label="Permalink: Maintainers" href="#maintainers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dandavison">@dandavison</a></li>
<li><a href="https://github.com/th1000s">@th1000s</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude AI to process secret government data through new Palantir deal (223 pts)]]></title>
            <link>https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</link>
            <guid>42091043</guid>
            <pubDate>Fri, 08 Nov 2024 22:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/">https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</a>, See on <a href="https://news.ycombinator.com/item?id=42091043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>An ethical minefield</h2>
<p>Since its founders started Anthropic in 2021, the company has <a href="https://www.youtube.com/watch?v=UMF1nf3Iy3Q">marketed itself</a> as one that takes an ethics- and safety-focused approach to AI development. The company differentiates itself from competitors like OpenAI by adopting what it calls responsible development practices and self-imposed ethical constraints on its models, such as its "<a href="https://arstechnica.com/information-technology/2023/05/ai-with-a-moral-compass-anthropic-outlines-constitutional-ai-in-its-claude-chatbot/">Constitutional AI</a>" system.</p>
<p>As Futurism <a href="https://futurism.com/the-byte/ethical-ai-anthropic-palantir">points out</a>, this new defense partnership appears to conflict with Anthropic's public "good guy" persona, and pro-AI pundits on social media are noticing. <span>Frequent AI commentator Nabeel S. Qureshi <a href="https://x.com/nabeelqu/status/1854574146283618521">wrote</a> on X, </span><span>"Imagine telling the safety-concerned, effective altruist founders of Anthropic in 2021 that a mere three years after founding the company, they'd be signing partnerships to deploy their ~AGI model straight to the military frontlines.</span>"</p>
<figure>
    <div>
              <p><a data-pswp-width="1200" data-pswp-height="675" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w" data-cropped="true" href="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" target="_blank">
                <img decoding="async" width="1200" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" alt="Anthropic's &quot;Constitutional AI&quot; logo." srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w" sizes="(max-width: 1200px) 100vw, 1200px">
              </a></p><div id="caption-2061278"><p>
                Anthropic's "Constitutional AI" logo.
                                  </p><p>
                    Credit:
                                          Anthropic / Benj Edwards
                                      </p>
                              </div>
            </div>
                  <figcaption>
          <div>
    
    <p>
      Anthropic's "Constitutional AI" logo.

              <span>
          Credit:

          
          Anthropic / Benj Edwards

                  </span>
          </p>
  </div>
        </figcaption>
            </figure>

<p>Aside from the implications of working with defense and intelligence agencies, the deal connects Anthropic with Palantir, a <a href="https://amp.theguardian.com/commentisfree/2020/sep/04/palantir-ipo-ice-immigration-trump-administration">controversial company</a> which <a href="https://defensescoop.com/2024/05/29/palantir-480-million-army-contract-maven-smart-system-artificial-intelligence/">recently won</a> a $480 million contract to develop an AI-powered target identification system called Maven Smart System for the US Army. Project Maven has <a href="https://www.reuters.com/article/business/media-telecom/google-to-scrub-us-military-deal-protested-by-employees-source-idUSL2N1T320P/">sparked criticism</a> within the tech sector over military applications of AI technology.</p>
<p>It's worth noting that Anthropic's terms of service <a href="https://www.anthropic.com/news/expanding-access-to-claude-for-government">do outline</a> specific rules and limitations for government use. These terms permit activities like foreign intelligence analysis and identifying covert influence campaigns, while prohibiting uses such as disinformation, weapons development, censorship, and domestic surveillance. Government agencies that maintain regular communication with Anthropic about their use of Claude may receive broader permissions to use the AI models.</p>
<p>Even if Claude is never used to target a human or as part of a weapons system, other issues remain. While its Claude models are highly regarded in the AI community, they (like all LLMs) have the tendency to <a href="https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/">confabulate</a>, potentially generating incorrect information in a way that is difficult to detect.</p>
<p>That's a huge potential problem that could impact Claude's effectiveness with secret government data, and that fact, along with the other associations, has Futurism's Victor Tangermann worried. As he puts it, "It's a disconcerting partnership that sets up the AI industry's growing ties with the US military-industrial complex, a worrying trend that should raise all kinds of alarm bells given the tech's many inherent flaws—and even more so when lives could be at stake."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Staff Engineer? (132 pts)]]></title>
            <link>https://nishtahir.com/what-is-a-staff-engineer/</link>
            <guid>42090771</guid>
            <pubDate>Fri, 08 Nov 2024 21:55:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nishtahir.com/what-is-a-staff-engineer/">https://nishtahir.com/what-is-a-staff-engineer/</a>, See on <a href="https://news.ycombinator.com/item?id=42090771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <!--kg-card-begin: markdown--><blockquote>
<p><em>"I've worked with a couple of Staff Engineers on different teams in the past and I've seen them do different things, but I've not been able to pin down exactly what they do."</em></p>
</blockquote>
<p>I get this question quite frequently. Sometimes from engineers looking to elevate their roles. At other times, team members reach out looking to learn how they could get the most value from Staff Engineers on the teams. It is a complicated question because a lot of ambiguity exists in the role. Different engineers have distinct interpretations, so you may get a significantly different answer depending on who you ask. With that in mind, I wanted to capture my thoughts on the subject. It's deep, complex, and nuanced. As a result, I'm likely to be as successful as someone attempting to unravel the mysteries of Engineering Management <sup><a href="#fn1" id="fnref1">[1]</a></sup> in a single blog post.</p>
<p>To lay some foundation, I'll be describing a class of engineers as <em>Staff Plus</em> (Staff+). These engineers operate above the Senior level. However, they do not assume the role of an Engineering Manager. These engineers often aim to stay within the technical track of an organization's career ladder. While there is currently no universally accepted title for this role <sup><a href="#fn2" id="fnref2">[2]</a></sup>, successful individuals I've seen in this role tend to share notable common traits</p>
<ul>
<li>They are proven experts in their area of expertise</li>
<li>They have a lot of experience leading teams toward shipping products</li>
</ul>
<h2 id="characterizing-a-staff-engineer">Characterizing a Staff+ Engineer</h2>
<p>One of my favorite ways to characterize the Staff+ role is by using the "4 key skills <sup><a href="#fn3" id="fnref3">[3]</a></sup> every job needs". It provides a solid framework that we can use to determine the distribution of skills one would need to be successful in the role.</p>
<p><img src="https://nishtahir.com/content/images/2023/01/four_skills_every_job_needs.png" alt="four_skills_every_job_needs" loading="lazy"></p>
<h2 id="core-technical-skill">Core Technical Skill</h2>
<p>This is the foundational skill needed to execute the role effectively and one that the Staff+ Engineer should be highly proficient in. In my experience, this level requires deep technical knowledge in some specialty<sup><a href="#fn4" id="fnref4">[4]</a></sup>, and it is often accompanied by a wide breadth of knowledge and experience working with multiple different systems within multiple different environments<sup><a href="#fn5" id="fnref5">[5]</a></sup>. This is the wealth of experience that the Staff+ Engineer reaches into to solve complex technical problems that contribute toward furthering their team's objectives. While I cannot overstate the importance of this skill as a foundational element of the role, it's not enough to be successful on its own. It must be fluidly combined with other skills to empower the Staff+ Engineer to fluidly adapt to different roles on the team, some of which I will cover below.</p>
<h2 id="product-management">Product Management</h2>
<p>A Staff+ Engineer relies on this skill to determine what should be built as well as why. At this level, the Staff+ Engineer should be capable of looking at a team, project, and/or organization's objectives, gaining some understanding of its history, and developing a technical vision<sup><a href="#fn6" id="fnref6">[6]</a></sup> to meet those objectives<sup><a href="#fn7" id="fnref7">[7]</a></sup>. A skilled Staff+ Engineer should be able to communicate this vision to their stakeholders, as well as other parties that may have a stake in the outcome, and get buy-in from all parties, especially the engineering team that will be responsible for building the solution. This role may sometimes manifest as a Technical Architect<sup><a href="#fn8" id="fnref8">[8]</a></sup>.</p>
<h2 id="project-management">Project Management</h2>
<p>This skill helps the Staff+ engineer break down large work items into smaller more manageable tasks for more junior members of the team, create a plan/timeline for completion that can be tracked, as well as manage uncertainties/risks that may deter completion of the work. Proficiency in this skill requires a mastery of basic project management fundamentals <sup><a href="#fn9" id="fnref9">[9]</a></sup>. This does not mean that Staff+ Engineers should be expected to replace project managers; rather these roles should be seen as complementary.</p>
<h2 id="people-management">People Management</h2>
<p>This includes the ability to rally and lead a team toward completing a set of objectives. I've heard this fondly described as "herding cats"<sup><a href="#fn10" id="fnref10">[10]</a></sup>. While I don't think a Staff+ engineer in this role is required to assume full people management responsibilities (that's what Managers are for), there is notably a lot of overlap. For example, I would expect an engineer operating at this level to be an effective mentor, able to provide technical and a reasonable extent of career guidance. This skill also requires having a solid awareness of the team's composition. This includes the skills makeup, strengths as well as growth areas. At this level, the Staff+ engineer should be able to use this awareness to elevate the effectiveness of the team through coaching and mentoring.</p>
<h2 id="youre-rubber-im-glue">You're rubber, I'm glue</h2>
<blockquote>
<p><em>"I feel like they do a little bit of everything. They seem to be the go-to on the team when there's an issue. They are like a rock with all the answers!"</em></p>
</blockquote>
<p>I've found that a key aspect of my day-to-day is autonomously combining these skills to fill roles that may find difficult to fill. It's often the less glamorous but high-value work that is required to build or maintain team momentum. This is sometimes described as "glue" work.</p>
<blockquote>
<p><em>"Every senior person in an organisation should be aware of the less glamorous - and often less-promotable - work that needs to happen to make a team successful. Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting."</em><sup><a href="#fn11" id="fnref11">[11]</a></sup></p>
</blockquote>
<p>Doing glue work often requires a cross-functional grasp of how the team operates as well as deep insight into areas of the team that may require optimization. Here are a couple of scenarios that exemplify glue work,</p>
<ol>
<li>You notice that a couple of email threads between your engineers and a 3rd party vendor have been running long. They seem to be talking past each other without making any headway. You decide to help improve the situation by scheduling a couple of meetings to help foster alignment and develop a culture of partnership between the teams.</li>
<li>You notice an up tick in the number of bug tickets being written about a feature in the product. After a brief investigation, you find that area of the code lacks automated tests because of a dependency on a third-party framework and will require some rework to make it testable. The development team needs some coaching on how to handle these sorts of problems in the future and a plan needs to be drafted and communicated to the leadership team. There's some upfront cost but will pay for itself in fewer bug tickets down the road.</li>
<li>A team member has been struggling with a new aspect of their assignment. They are unsure of what specific skills they need to learn to be most effective. So you help by offering some light coaching by offering some resources that help them get up to speed quickly as well as setting up 1:1s where they can ask questions and get feedback.</li>
<li>Your team was asked to build a tool that aggregates data for marketing and Business Intelligence (BI). The requirements were vague but enough for the engineering team to work on. Noticing the potential for improvement, you schedule meetings with representatives from the marketing and BI team to better understand how the aggregated data will be used to provide a better product.</li>
</ol>
<p>While one could argue that this work has a high-value impact on the team, it may be tough to justify having the Staff+ Engineer function doing any one of those things in the long term. As a result, a crucial part of the role is leveling up the team such that they may take over such responsibilities such that the Staff+ Engineer may shift their focus towards tackling other priorities. It may be by coaching an existing team member to own one of those tasks or working with the leadership team to staff a new permanent owner.</p>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p><em>"I forget what was said exactly, but [Staff+ Engineer] spoke up and said something with clarity and confidence that changed the conversation to be much more productive. They were thoughtful with their comments and have a keen ability to drive toward clarity in a room of swirling indecision."</em></p>
</blockquote>
<p>I've only scratched the surface here, but hope I've captured some specific nuances in the role. Ultimately I think a Staff+ Engineer should be able to use their autonomy and influence within an organization and turn that into meaningful impact and value in service of a team or organization's objectives.</p>
<p>Here are a couple of great resources that I recommend if you are interested in learning more.</p>
<ol>
<li><a href="https://learning.oreilly.com/library/view/the-staff-engineers/9781098118723/?ref=nishtahir.com">The Staff Engineers Path</a> by Tanya Rielly</li>
<li><a href="https://staffeng.com/book?ref=nishtahir.com">Staff Engineer: Leadership beyond the management track</a> by Will Larson</li>
</ol>
<p>To wrap things up, I'm adding an assorted collection of questions I've gotten recently. This is either because I couldn't figure out a way to answer it directly within the context of this blog post or because I thought it may add additional perspective to address the question directly.</p>
<h2 id="faq">FAQ</h2>
<ol>
<li>
<blockquote>
<p>Does Staff+ Engineering require mentoring responsibilities?</p>
</blockquote>
</li>
</ol>
<p>Yes. I think this is a non-negotiable part of the role. The ability to elevate a team's capability is predicated on being a good mentor. In essence, the ability to identify strengths and growth areas on the team. Additionally, creating opportunities for team members to learn and grow.</p>
<ol start="2">
<li>
<blockquote>
<p>What kinds of teams need a Staff+ Engineer?</p>
</blockquote>
</li>
</ol>
<p>A Staff+ Engineer can exist on any team in theory. However, their role will depend on the specific team composition. The Staff+ Engineer may be the main Individual Contributor (IC) on a small team working on a proof of concept for some experimental technology, while a Staff+ Engineer may act as a technical lead on a larger team trying to build long-term momentum. The opportunity cost is the Staff+ Engineer's time and must be considered when making staffing decisions. Could a Senior Engineer be sourced to fill the IC role? This would free up the Staff+ Engineer to work on more complex or higher value problems for the project.</p>
<ol start="3">
<li>
<blockquote>
<p>What differentiates senior levels of Staff Engineers?</p>
</blockquote>
</li>
</ol>
<p>The main differentiator is their scope of impact. More senior Staff+ Engineers should be able to have and manage an impact on an organization or company, in some cases an industry at large. Being able to build and leverage their influence to guide a technical direction is a skill in and of itself</p>
<ol start="4">
<li>
<blockquote>
<p>Hmm... It looks like you went over a lot of general points but didn't address a lot of specific expectations of the role</p>
</blockquote>
</li>
</ol>
<p>This is because the nature of the role changes with each individual and circumstance. This means that being able to adapt to each circumstance is important. That being said, I think the most important thing is that the Staff+ Engineer can turn autonomy into meaningful impact at a scale proportional to their role/level.</p>
<ol start="5">
<li>
<blockquote>
<p>I stayed on the technical track with I got promoted because I wanted to continue to write code. How do I balance leadership responsibilities but still retain coding in my day-to-day?</p>
</blockquote>
</li>
</ol>
<p>I would argue that at this level, your leadership skills are likely your most valuable asset. Trying to keep hands-on-keyboard writing code a major part of your role may not be using your talents to their full potential. However, your day-to-day should be determined by the team/project needs while considering that time dedicated towards work that an IC would typically do comes at the cost of glue work and other higher-level work that may require your attention. This is not to say that you should be completely removed from the code avenues such as working on future work such as PoCs or lower priority features as you have availability might be great ways to keep you engaged in writing code.</p>
<hr>
<section>
<ol>
<li id="fn1"><p><a href="https://dzone.com/articles/the-art-of-engineering-management?ref=nishtahir.com">Chegini, A. (2022) The art of engineering management, dzone.com. DZone. Available at: https://dzone.com/articles/the-art-of-engineering-management (Accessed: January 24, 2023)</a> <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Some alternate titles I've encountered include Lead Engineer/Developer, Principal/Distinguished Engineer, Technical Fellow, etc... <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p><a href="https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff?ref=nishtahir.com">Zunger, Y. (no date) Role and Influence: The IC trajectory beyond Staff, Leaddev.com. Available at: https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff (Accessed: January 24, 2023).</a> <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p><a href="https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/?ref=nishtahir.com">Woodhams, B. (2018) Balance between breadth and depth of learning software development, candidates. Available at: https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/ (Accessed: January 24, 2023).</a> <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>This may be different in your organization and your specific personality <a href="#fnref5">↩︎</a></p>
</li>
<li id="fn6"><p><a href="https://lethain.com/what-do-staff-engineers-actually-do/?ref=nishtahir.com">What do Staff engineers actually do? (2020) Lethain.com. Available at: https://lethain.com/what-do-staff-engineers-actually-do/ (Accessed: January 24, 2023).</a> <a href="#fnref6">↩︎</a></p>
</li>
<li id="fn7"><p><a href="https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/?ref=nishtahir.com">Micol, D. (2021) Writing our 3-year technical vision, Engineering Blog. Available at: https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/ (Accessed: January 24, 2023).</a> <a href="#fnref7">↩︎</a></p>
</li>
<li id="fn8"><p><a href="https://www.lucidchart.com/blog/defining-technical-architects?ref=nishtahir.com">Rethinking the role of the technical architect (2021) Lucidchart. Available at: https://www.lucidchart.com/blog/defining-technical-architects (Accessed: January 24, 2023).</a> <a href="#fnref8">↩︎</a></p>
</li>
<li id="fn9"><p><a href="https://www.northeastern.edu/graduate/blog/essential-project-management-skills/?ref=nishtahir.com">Joubert, S. (2019) Project management skills, Northeastern University Graduate Programs. Available at: https://www.northeastern.edu/graduate/blog/essential-project-management-skills/ (Accessed: January 24, 2023).</a> <a href="#fnref9">↩︎</a></p>
</li>
<li id="fn10"><p><a href="https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/?ref=nishtahir.com">Tech lead engineer - herding cats &amp; drinks - Front End Happy Hour (no date) Frontendhappyhour.com. Available at: https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/ (Accessed: January 25, 2023).</a> <a href="#fnref10">↩︎</a></p>
</li>
<li id="fn11"><p><a href="https://noidea.dog/glue?ref=nishtahir.com">Being Glue — (no date) No Idea Blog. Available at: https://noidea.dog/glue (Accessed: January 25, 2023).</a> <a href="#fnref11">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Notes on Apple Math Notes (146 pts)]]></title>
            <link>https://mlajtos.mu/posts/new-kind-of-paper-5</link>
            <guid>42090633</guid>
            <pubDate>Fri, 08 Nov 2024 21:31:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mlajtos.mu/posts/new-kind-of-paper-5">https://mlajtos.mu/posts/new-kind-of-paper-5</a>, See on <a href="https://news.ycombinator.com/item?id=42090633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div><div><p>September 24, 2024</p><!-- --><p> · </p><!-- --><p>Milan Lajtoš</p></div><p><span>new kind of paper</span><span>, </span><span>thinking</span><span>, </span><span>computation</span><span>, </span><span>paper &amp; pencil</span><span>, </span><span>human-computer interaction</span><span>, </span><span>Apple</span></p></div>
<p>In the previous parts (<a href="https://mlajtos.mu/posts/new-kind-of-paper">1</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">2</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-3">3</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-4">4</a>) written in 2021, I described <strong>New Kind of Paper</strong> – an app that enhances <strong>paper &amp; pencil</strong>, the best medium for thinking, with the capabilities of a crazy <strong>advanced calculator</strong>.</p>
<p>In 2024, Apple introduced their spin on this topic under the name <strong>Math Notes</strong>. In this article, I will provide my <strong>deep praise (and even deeper hate)</strong> for their attempt to bring a bit of <strong>innovation into the UX of math</strong>.</p>
<hr>
<p>Let's start with a <strong>simple example</strong> of how Math Notes works...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/0-8601d68a71218ed6ce2ff0869d1845c8.mov" poster="https://mlajtos.mu/_next/static/media/0.7b1a32c5.png" preload="none"></video><figcaption>Writing a math expression in Apple Math Notes</figcaption></figure>
<p>It <span>*fucking*</span> works! 🥹</p>
<p>At first glance, it may not seem like much, but in this brief example, a lot has happened. First, the handwriting recognition worked flawlessly, despite my awful handwriting. It perfectly recognized what I meant by those scratch marks. Second, after I wrote the trigger symbol, <code>=</code> (the equal sign), the expression was evaluated, and the result was inserted inline, mimicking my handwriting style. The inline insertion could be improved to better match the handwriting style, but overall, this is basically magic. With my writing magic wand, I have conjured up a little computational spell. 🪄</p>
<p>The fact that millions of people have this technology at their fingertips and pencil tips (works both on iPads &amp; iPhones too), is a major miracle. The democratization of this technology is the hardest part, and it is in the hands of the people who know how to get shit done. Maybe not on the first try, but the third iteration... <span><em>*chef's kiss*</em></span></p>
<h2>Too Magical &amp; Not Alive Enough</h2>
<p><strong>How do you know that the result is correct?</strong> The calculation is definitely correct, but how can you trust your calculator to recognize your badly handwritten "1" as "1" and not as "7"? You simply don't. This is essentially Apple claiming that their handwriting recognition is infallible. It's a rather bold claim, don't you think? I appreciate the confidence, but I don't believe we have reached that level of accuracy yet. Even basic calculators indicate which button you (mis-)pressed.</p>
<p><strong>Why does it appear lifeless most of the time?</strong> If you only saw the first 90% of that demonstration, you wouldn't even know if this thing works. Honestly, it seemed dead most of the time. And when the result finally appeared, it was accompanied by flashy animation. 🫣 I love the animation, and I understand why it adds a nice touch to the initial version, but it's really just a distraction. This calculator should feel MORE alive!</p>
<p>Of course, talk is cheap, so let me demonstrate what I mean:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-a218e67f18e4f4486a486defaa970615.mp4" poster="https://mlajtos.mu/_next/static/media/1.7046d6ac.png" preload="none"></video><figcaption>Writing a math expression with live feedback (<a href="https://mlajtos.mu/posts/new-kind-of-paper-2">source</a>, 2021)</figcaption></figure>
<p><strong>Not as polished, but it is alive!</strong> And snappy. And colorful. The feedback is immediate, and you can see the result as you write. This kind of feedback instills trust in the system and gives you a sense of control. Of course, Apple will fix these issues differently...</p>
<p>The first problem – whether the system recognized your handwriting correctly – can be solved with another iPadOS feature called Smart Script. It lets you beautify your handwriting – simply write an ugly "1" and it will progressively transform the scribble into neatly handwritten "1" or "7". The point is to inform the user, give them feedback on how the system recognized the symbol. This helps tremendously with the trust issue.</p>
<p>The second problem, the missing liveness, is even easier to solve – just ditch the "=" and evaluate the expression when the user pauses. Not too eager, not too lazy. This "interactive" mode can be simulated in Math Notes with this technique:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/7-b425cecd44d2f48d757ebb2aea627c14.mov" poster="https://mlajtos.mu/_next/static/media/7.b98d48de.png" preload="none"></video><figcaption>"Interactive" mode in Math Notes<br><span>&amp; number of WTF moments</span></figcaption></figure>
<h2>Scratch to Delete</h2>
<p>*no comment*</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-1dfb304ebcd57e666ca89e09b4b70b33.mov" poster="https://mlajtos.mu/_next/static/media/1.7fd6e9b0.png" preload="none"></video><figcaption>Unnecessary switching between writing and erasing<br><span>&amp; 2-second long inconsistent state</span></figcaption></figure>
<h2>The Math You Know™</h2>
<h3>2D notation</h3>
<p>Math Notes supports 2D notation – you can write exponents as superscript, use fractions, etc. You know, the usual scary math stuff:</p>
<figure><div><p><img alt="log_2(2^10 / 2) = 9" loading="lazy" width="358.5" height="200.5" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=384&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75"></p></div><figcaption>Example of 2D notation: Relation between exponentiation, divison, and logarithm.<br><span>Every operation has different 2D representation.</span></figcaption></figure>
<p>I know how crazy difficult this must have been to pull off. <span>*Bravo!*</span></p>
<h3>PEMDAS</h3>
<p>PEMDAS – the order of operations: <strong>P</strong>arentheses, <strong>E</strong>xponents, <strong>M</strong>ultiplication/<strong>D</strong>ivision, <strong>A</strong>ddition/<strong>S</strong>ubtraction. It's everywhere. It's in our textbooks, our calculators, programming languages and now even in Apple's Math Notes. <span>*sigh*</span></p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/2-d47b8c3b0a560012784715d75efa08ee.mov" poster="https://mlajtos.mu/_next/static/media/2.6ce2b48c.png" preload="none"></video><figcaption>Illustration of operator precedence</figcaption></figure>
<h3>The Future of Math Notation</h3>
<p>Supporting the traditional handwritten math notation is no easy task. It is extremely messy, inconsistent and sometimes ambiguous. However, a calculator that wants to be useful must support ideas that have been forged for centuries. It is hard to change math.</p>
<p>When math started to become executable in form of software &amp; hardware, we developed consistent notation that was shaped by keyboards, not by pencils. We migrated from 2D into 1D, misused some glyphs, and introduced constructs that made sense for computing. Math definitely adapted to this new medium.</p>
<p>Math Notes embodies even newer medium on which math can grow and change. While supporting existing traditional notation is a must, adding ability to define custom notation is an aspiration. We can't evolve math if the medium does not allow it. Today, the notation in Math Notes is fixed and it doesn't even cover a lot of useful math (e.g. calculus). This is fine in the short term, but if we are serious, we should start to think about user-definable 2D notation. Heck, even user-definable operators (e.g. <code>≈</code> or <code>⊙</code>) would be a good first step.</p>
<p>While Math Notes isn't doing anything on this front yet, Apple leaned heavily into different direction...</p>
<h2>Dynamic Scribbles</h2>
<p>Since we are not stuck with static scribbles on the paper, Math Notes supports some dynamic behaviors, e.g. changing a numeric value just by dragging a slider.</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/4-67b47bb57bbaee5b32156324a02cd185.mov" poster="https://mlajtos.mu/_next/static/media/4.3af29c54.png" preload="none"></video><figcaption>Simple means of "solving".<br><span>Circular knob with different speeds might be better in the long-term,<br> but the slider is a great choice for first iteration.</span></figcaption></figure>
<p>Or graphing a function...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/5-35e4fbbd8d953708a710ff81dc9844f7.mov" poster="https://mlajtos.mu/_next/static/media/5.50a8d043.png" preload="none"></video><figcaption>Term "graphing calculator" has a new meaning now.</figcaption></figure>
<p>These are fantastic features that millions of people will love. With just a scribble and touch of a finger, I can solve non-trivial computational problems. Can you imagine the effort, if you wanted to achieve the same thing in e.g. Python? <span><em>*Bleh..*</em></span></p>
<p>However, graphs are dead – they do not respond to changing coefficients...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/8-cc08b6635b462f3697d8c2027d7e0e76.mov" poster="https://mlajtos.mu/_next/static/media/8.43e7c2c7.png" preload="none"></video><figcaption>Graphs in Math Notes are useful, but dead.</figcaption></figure>
<h3>λλλ</h3>
<p>One obvious omission in this part of Math Notes, is proper function definition. Define a function, see its graph, and be able to evaluate it with a specific input value. You know, something like this...</p>
<figure><div><p><img alt="fn(x)=10*x; a=1; b=fn(a); b=10" loading="lazy" width="592" height="313" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=640&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75"></p></div><figcaption>Mockup of a better function definition.<br><span>Showing a point at [1, 10] would be neat...</span></figcaption></figure>
<p>This notation for function definition (or lambdas/λ in comp-sci jargon) is pretty understandable and supports multiple arguments. Also, it opens up a route to primitive custom (infix) operators.</p>
<hr>
<h2>Solving Way Harder Stuff</h2>
<p>All these features are hinting at a calculator that is a good companion for a mind that wants to solve problems that can be turned into a computation. So far, the capabilities of Math Notes are pretty limited – e.g. <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">how would you sum up numbers from 1 to 100?</a> That is a pretty easy computational problem, but you can't solve it easily with this type of calculator – yet.</p>
<p>However, "solving" is much broader topic than a straight-to-an-answer computation. What about problems that involves optimizing a function with thousand of parameters in an iterated manner? This problem-solving technique is currently limited to small set of smart people. Math Notes could unlock it for much broader, and younger audience. Like Excel did open up sophisticated computation for mere mortals. But this time in a much more humane way.</p>
<h2>∞ Amount of Constructive Criticism...</h2>
<p>I have been thinking about this type of calculator for many many years, and I am extremely happy to see this <strong>new kind of calculator</strong> in the wild. I want to see it used by everybody – from curious 5 year olds to PhD-level proffesionals in the science &amp; engineering. Solving our personal problems and civilization-level ones too.</p>
<blockquote>
<p>We can only see a short distance ahead, but we can see plenty there that needs to be done.</p>
<p>– Alan Turing</p>
</blockquote>
<hr>
<p>Do you have ideas about this kind of stuff? Please share them online!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Macintosh before System 7 (101 pts)]]></title>
            <link>https://earlymacintosh.org/</link>
            <guid>42090544</guid>
            <pubDate>Fri, 08 Nov 2024 21:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earlymacintosh.org/">https://earlymacintosh.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42090544">Hacker News</a></p>
<div id="readability-page-1" class="page">
		
		<p><a id="TA31885" name="TA31885"></a>All information presented here is based on primary sources, mainly original, unmodified Apple disks and other Apple documentation.</p>
		<p>Anyone interested in this history must be especially careful when reviewing the information presented in Apple Knowledge Base article TA31885, <a href="https://support.apple.com/kb/TA31885">Macintosh: System Software Version History</a>, a secondary source that contains major errors:</p>
		<ul>
			<li>In the first table, "System 2.0 Finder 1.1g" should be System 1.1 Finder 1.1g.</li>
  			<li>The first numbered "Macintosh System Software" release was version 5.0 in October 1987. The article assigns <i>ex post facto</i> version numbers to earlier releases and presents a timeline. But the numbers are problematic, and the early timeline is simply not accurate. These mistakes then carry over to Apple's tech specs and <a href="https://support.apple.com/kb/TA41109">other</a> documentation for early Macintosh <a href="#hardware">hardware</a> online. See my discussion of how this mess was made: <a href="https://earlymacintosh.org/cd.html">Apple's developer CDs and their spawn</a>. </li>
  		</ul>
		<p>Understandably, this Apple article has been widely used as a source of (mis)information on the Internet, including Wikipedia. <strong>Beware!</strong></p>
		<p>Sites with information about various aspects of early Macs include <a href="http://lowendmac.com/early-macs.html">Low End Mac</a>, <a href="http://chrislawson.net/writing/"> Mac Daniel</a>, <a href="http://myoldmac.net/FAQ/index.htm">68k Mac FAQ</a>, <a href="http://www.mac128.com/">Mac 128 Update</a>, <a href="http://www.ccadams.org/se/">Mac SE Support</a>, <a href="https://macgui.com/">Mac GUI</a>, <a href="http://www.macmothership.com/">The Mothership</a>, <a href="http://vintagemacmuseum.com/">The Vintage Mac Museum</a>, <a href="http://www.aresluna.org/guidebook">GUIdebook</a>. Download sites include <a href="https://www.macintoshrepository.org/">Macintosh Repository</a>, <a href="http://macintoshgarden.org/">Macintosh Garden</a>, <a href="http://www.macfixer.com/vintage-software/">MacFixer</a>. Discussions include <a href="http://lowendmac.com/lists/vintagemacs.shtml">Vintage Macs</a>, <a href="http://lowendmac.com/lists/system6.html">System 6</a>, and <a href="https://68kmla.org/forums/">68k Macintosh Liberation Army</a>. Expert Classic Mac Tech Info is available in a PDF document <a href="http://home.earthlink.net/~gamba2/images/plus_analog.PDF">here</a>. Decode your 68k Mac serial number at <a href="http://myoldmac.net/FAQ/Mac-Serialnumber-decoder-e.php">myoldmac.net</a>. First-hand history is available at <a href="http://www.folklore.org/">Folklore</a> and <a href="http://library.stanford.edu/mac/">Making the Macintosh</a>.</p>
		<p><a href="http://www.gryphel.com/c/minivmac/index.html">Mini vMac</a> is an excellent Macintosh Plus, SE, and 128K emulator that runs on Mac OS X and earlier, as well as Linux and Windows. Requires the appropriate ROM. <a href="https://www.emaculation.com/">E-Maculation</a> is a good place to check on the progress of other early Macintosh emulation projects.</p>
		<p>Finally, <a href="https://www.bigmessowires.com/floppy-emu/">Big Mess o' Wires</a> offers the essential piece of equipment for anyone who owns a functional early Macintosh and wants to use it: a floppy/hard disk emulator that allows you to save your work to a current SD memory card.</p>
		<h2><a id="hardware" name="hardware"></a><span color="#00008b">Macintosh hardware releases</span></h2>
		<h4>Table of hardware releases before System 7 (May 1991)</h4>
		<table>
	  		<tbody><tr>
				<td><b>Date</b></td>
				<td><b>Name</b></td>
				<td><b>Model #</b></td>
				<td><b>Tech Specs </b></td>
				<td><b>Original </b><b>System file</b></td>
			</tr>
			<tr>
				<td>01/84</td>
				<td>Macintosh (128K)</td>
				<td>M0001<br>
			    M0001P*</td>
			  <td><a href="https://support.apple.com/kb/SP186">SP186</a></td>
				<td>System 1.0†</td>
			</tr>
			<tr>
				<td>09/84</td>
				<td>Macintosh 512K</td>
				<td>M0001W<br>
			    M0001WP</td>
			  <td><a href="https://support.apple.com/kb/SP187">SP187</a></td>
				<td>System 1.1‡</td>
			</tr>
			<tr>
				<td>01/86</td>
				<td>Macintosh Plus</td>
				<td>M0001A<br>
			    M0001AP</td>
			  <td><a href="https://support.apple.com/kb/SP190">SP190</a></td>
				<td>System 3.0</td>
			</tr>
			<tr>
				<td>03/86</td>
				<td>Macintosh <a href="#800">512K/800</a></td>
			  <td>M0001D</td>
			  <td>n/a</td>
				<td>System 3.0</td>
			</tr>
			<tr>
				<td>04/86</td>
				<td>Macintosh 512K<i>e</i></td>
				<td>M0001E</td>
				<td><a href="https://support.apple.com/kb/SP188">SP188</a></td>
				<td>System 3.0</td>
			</tr>
			<tr>
				<td>03/87</td>
				<td>Macintosh SE</td>
				<td>M5010<br>
					M5011**</td>
				<td><a href="https://support.apple.com/kb/SP191">SP191</a><br>
			  <a href="https://support.apple.com/kb/SP192">SP192</a></td>
				<td>System 4.0</td>
			</tr>
			<tr>
				<td>03/87</td>
				<td>Macintosh II</td>
				<td>M5000</td>
				<td><a href="https://support.apple.com/kb/SP193">SP193</a></td>
				<td>System 4.1§</td>
			</tr>
			<tr>
				<td>09/88</td>
				<td>Macintosh IIx</td>
				<td>M5840</td>
				<td><a href="https://support.apple.com/kb/SP194">SP194</a></td>
				<td>System 6.0.1</td>
			</tr>
			<tr>
				<td>01/89</td>
				<td>Macintosh SE/30</td>
				<td>M5119</td>
				<td><a href="https://support.apple.com/kb/SP195">SP195</a></td>
				<td>System 6.0.3</td>
			</tr>
			<tr>
				<td>03/89</td>
				<td>Macintosh IIcx</td>
				<td>M5650</td>
				<td><a href="https://support.apple.com/kb/SP196">SP196</a></td>
				<td>System 6.0.3</td>
			</tr>
			<tr>
				<td>09/89</td>
				<td>Macintosh IIci</td>
				<td>M5780</td>
				<td><a href="https://support.apple.com/kb/SP197">SP197</a></td>
				<td>System 6.0.4</td>
			</tr>
			<tr>
				<td>09/89</td>
				<td>Macintosh Portable</td>
				<td>M5120</td>
				<td><a href="https://support.apple.com/kb/SP140">SP140</a></td>
				<td>System 6.0.4</td>
			</tr>
			<tr>
				<td>03/90</td>
				<td>Macintosh IIfx</td>
				<td>M5525</td>
				<td><a href="https://support.apple.com/kb/SP203">SP203</a></td>
				<td>System 6.0.5</td>
			</tr>
			<tr>
				<td>10/90</td>
				<td>Macintosh Classic</td>
				<td>M0420</td>
				<td><a href="https://support.apple.com/kb/SP198">SP198</a></td>
				<td>System 6.0.7</td>
			</tr>
			<tr>
				<td>10/90</td>
				<td>Macintosh IIsi</td>
				<td>M0360</td>
				<td><a href="https://support.apple.com/kb/SP199">SP199</a></td>
				<td>System 6.0.7</td>
			</tr>
			<tr>
				<td>10/90</td>
				<td>Macintosh LC</td>
				<td>M0350</td>
				<td><a href="https://support.apple.com/kb/SP205">SP205</a></td>
				<td>System 6.0.7</td>
			</tr>
		</tbody></table>
		<p>* "P" after the model number indicates a 220-240V power supply (Europe, Asia, Australia), as opposed to a 110-120V power supply (North America, Japan).<br>
		** M5011 was used for Macintosh SE machines configured with internal hard drives. This would later include the SE FDHD (SuperDrive), which replaced the SE in August 1989.<br>
  		� Apple's recommended System file is version 2.0, with 3.2 as the maximum.<br>
 		� Apple's recommended System file is version 3.2 (or <a href="#3.3">3.3</a> as an AppleShare client), with 4.1 as the maximum.<br>
  		§ While both Macintosh SE and Macintosh II were introduced in March 1987, the II did not actually ship until April 1987, with System file version 4.1. See <a href="http://www.mactech.com/articles/mactech/Vol.03/03.05/MacII,SE/index.html">MacTech</a>.</p>
		<p><b>Printers:</b> <a href="https://support.apple.com/kb/SP442">ImageWriter</a>, <a href="https://support.apple.com/kb/SP472">LaserWriter</a>, <a href="https://support.apple.com/kb/SP444">ImageWriter II</a>, <a href="https://support.apple.com/kb/SP473">LaserWriter Plus</a>, <a href="https://support.apple.com/kb/SP447">ImageWriter LQ</a>, <a href="https://support.apple.com/kb/SP474">LaserWriter IISC</a>, <a href="https://support.apple.com/kb/SP475">LaserWriter IINT</a>, <a href="https://support.apple.com/kb/SP476">LaserWriter IINTX</a>, <a href="https://support.apple.com/kb/SP441">Personal LaserWriter SC</a>, <a href="https://support.apple.com/kb/SP439">Personal LaserWriter NT</a>, <a href="https://support.apple.com/kb/SP440">Personal LaserWriter LS</a>.</p>
		<p><b>Monitors:</b> <a href="https://support.apple.com/kb/SP417">High-Resolution Monochrome Monitor</a>, <a href="https://support.apple.com/kb/SP418">High-Resolution RGB Monitor</a>, <a href="https://support.apple.com/kb/SP431">Two-Page Monochrome Display</a>, <a href="https://support.apple.com/kb/SP426">Macintosh Portrait Display</a>, <a href="https://support.apple.com/kb/SP420">Macintosh 12-inch Monochrome Display</a>, <a href="https://support.apple.com/kb/SP421">Macintosh 12-inch RGB Display</a>.</p>
		<h2><a id="software" name="software"></a><span color="#00008b">Macintosh software releases</span></h2>
		<p><em>All of the information in the table below comes from original copies of the disks in question.</em></p>
		<h4>Table of software releases before System 7 (May 1991)</h4>
		<table>
		  <tbody><tr>
				<td><b>Date</b></td>
				<td><b>Title</b></td>
				<td><b>System </b></td>
				<td><b>Finder </b></td>
				<td><b>MultiFinder </b></td>
			</tr>
			<tr>
				<td>01/84</td>
				<td><a href="https://earlymacintosh.org/disk_images.html#1.0">Mac Software</a></td>
				<td>1.0</td>
				<td>1.0</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>05/84</td>
				<td><a href="https://earlymacintosh.org/disk_images.html#System_1">Mac Software</a></td>
				<td>1.1</td>
				<td>1.1g*</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>04/85</td>
				<td><a href="https://earlymacintosh.org/disk_images.html#System_2">Mac Software</a></td>
				<td>2.0</td>
				<td>4.1</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>09/85</td>
				<td>Mac Software</td>
				<td>2.1</td>
				<td>5.0</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>01/86</td>
				<td>Mac Software</td>
				<td>3.0</td>
				<td>5.1</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>02/86</td>
				<td>Mac Software</td>
				<td>3.1</td>
				<td>5.2</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>06/86</td>
				<td><a href="https://earlymacintosh.org/disk_images.html#System_3">Mac Software</a></td>
				<td>3.2</td>
				<td>5.3</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>01/87</td>
				<td>Macintosh System Software</td>
				<td>4.0</td>
				<td>5.4†</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>04/87</td>
				<td><a href="https://earlymacintosh.org/disk_images.html#System_4">Macintosh System Software</a></td>
				<td>4.1</td>
				<td>5.5†</td>
				<td>N/A</td>
			</tr>
			<tr>
				<td>10/87</td>
				<td>Macintosh System Software 5.0</td>
				<td>4.2</td>
				<td>6.0</td>
				<td>1.0</td>
			</tr>
			<tr>
				<td>11/87</td>
				<td>Macintosh System Software 5.1</td>
				<td>4.3</td>
				<td>6.0</td>
				<td>1.0</td>
			</tr>
			<tr>
				<td>04/88</td>
				<td>Macintosh System Software 6.0</td>
				<td>6.0</td>
				<td>6.1‡</td>
				<td>6.0</td>
			</tr>
			<tr>
				<td>08/88</td>
				<td>Macintosh System Software 6.0.1</td>
				<td>6.0.1</td>
				<td>6.1</td>
				<td>6.0.1</td>
			</tr>
			<tr>
				<td>09/88</td>
				<td>Macintosh System Software 6.0.2</td>
				<td>6.0.2</td>
				<td>6.1</td>
				<td>6.0.1</td>
			</tr>
			<tr>
				<td>12/88</td>
				<td>Macintosh System Software <a href="https://earlymacintosh.org/disk_images.html#System_6">6.0.3</a></td>
				<td>6.0.3</td>
				<td>6.1</td>
				<td>6.0.3</td>
			</tr>
			<tr>
				<td>09/89</td>
				<td>Macintosh System Software 6.0.4</td>
				<td>6.0.4</td>
				<td>6.1.4</td>
				<td>6.0.4</td>
			</tr>
			<tr>
				<td>03/90</td>
				<td>Macintosh System Software <a href="https://earlymacintosh.org/disk_images.html#System_6">6.0.5</a></td>
				<td>6.0.5</td>
				<td>6.1.5</td>
				<td>6.0.5</td>
			</tr>
			<tr>
				<td>10/90</td>
				<td>Macintosh System Software 6.0.7</td>
				<td>6.0.7</td>
				<td>6.1.7</td>
				<td>6.0.7</td>
			</tr>
			<tr>
				<td>04/91</td>
				<td>Macintosh System Software <a href="https://earlymacintosh.org/disk_images.html#System_6">6.0.8</a></td>
				<td>6.0.8</td>
				<td>6.1.8</td>
				<td>6.0.8</td>
			</tr>
		</tbody></table>
		<p>* System 1.1 supported at least two beta releases of the Finder (Finder 2.6 and Finder 3.4), widely distributed amongst developers, as discussed in <a href="http://preserve.mactech.com/articles/index.html">MacTech</a>: see the Letters sections of Volume 1, Issues 5 and 6.<br>
		<a id="3.3" name="3.3"></a>† System 3.3 (for the Macintosh 512K) was distributed on the Work Station Installer disk for versions 1.0 (with Finder 5.4) and 1.1 (with Finder 5.5) of the AppleShare file server.<br>
		‡ System 3.4 (for the Macintosh 512K<em>e</em>) was distributed with AppleShare version 2.0 (with Finder 6.1).</p>
		<h3>Notes:</h3>
		<ul>
			<li>The two training disks that came with the original January 1984 software bundle (see <a href="#128_bundles">below</a>) used an early version of the Finder. The Macintosh icon is especially interesting, as it appears to show a prototype with a <a href="http://www.folklore.org/StoryView.py?project=Macintosh&amp;story=Hide_Under_This_Desk.txt">5.25" disk drive</a> like the first <a href="http://lowendmac.com/lisa/lisa.shtml">Lisa</a>:</li>
		</ul>
		<blockquote>
			<blockquote>
				<p><img src="https://earlymacintosh.org/graphics/GuidedTour.jpg" alt="" width="357" height="126"></p>
			</blockquote>
		</blockquote>
		<ul>
			<li>The System file used on the January 1984 System Disk and Write/Paint disks is, technically, "Version .97 14-Jan-84." This resource was hidden from the public, for internal reference only. From the point of view of the public, this System file was numbered version 1.0. See the <a href="https://earlymacintosh.org/disk_images.html#1.0">Disk Images</a> page for more information.</li>
			<li>Finder 1.1h appears on the "Guided Tour of Macintosh" training disk, used in all software bundles from May 1984 up to January 1986 (see <a href="#1.1">below</a>).</li>
			<li>System 2.0 Finder 4.1 was released in April 1985. [<a href="https://earlymacintosh.org/disk_images.html#System_2">disk images</a>] MacWrite 4.5 and MacPaint 1.5 were released, along with an update disk that featured the application System Update (a.k.a. Finder Update, its icon appears at the bottom of this page) that could be used to update any startup disk. The Update disk also included the Font/DA Mover application, a Fonts suitcase with one font in it [Taliesin, a pictorial font], and a "What's New" document. A complete System Disk was not released until June 1985 (see <a href="#E">below</a>).</li>
			<li>System 2.1 Finder 5.0 was released on the first HD 20 Startup disk (with Hard Disk 20 1.0 and HD 20 Test 1.0) that shipped with the <a href="https://web.archive.org/web/20170908154008/http://www.vintagemacworld.com/hd20.html">Hard Disk 20</a>. Introduced support for the Hierarchical File System (HFS).</li>
			<li>System 3.0 Finder 5.1 was released on the first Macintosh Plus System Tools disk. This same disk also came with the first <a href="#OEM_upgrades">Macintosh Plus Disk Drive Kit</a>.</li>
			<li><a id="3.1" name="3.1"></a>System 3.1 Finder 5.2 was only released on the Printer Installation (v1.0) [690-5075-A] disk that shipped with the <a href="https://books.google.com/books?id=4R5VAAAAMAAJ&amp;pg=RA3-PA6">LaserWriter Plus</a> and featured LaserWriter 3.0 and LaserWriter Namer 2.0, along with an updated Font/DA Mover. Apple intended to ship System 3.1 (or, more likely, System 3.1.1) Finder 5.2 with the first <a href="#Plus_bundles">Macintosh 512K<em>e</em></a> machines, but for unknown reasons they used the earlier Macintosh Plus System Tools disk instead. System 3.1 Finder 5.2 was never released as a System disk, and System 3.1.1 Finder 5.2 is only found on the Macintosh 512K <em>enhanced:</em> A Guided Tour disk.</li>
			<li>System 3.2 Finder 5.3 was released in June 1986. [<a href="https://earlymacintosh.org/disk_images.html#System_3">disk images</a>] In addition to separate 800K System Tools disks for the Macintosh Plus and 512K<i>e,</i> along with a 400K HD 20 Startup disk (with Hard Disk 20 1.1 and HD 20 Test 1.1), Apple distributed two 400K update disks:</li>
				<ul>
					<li>The System Installation (v1.0) disk came with two Installer scripts: "Mac Plus Update" and "External Drive."</li>
				  	<li>The Printer Installation (v1.1) [690-5075-B] disk featured LaserWriter 3.1 and LaserWriter Namer 2.1.</li>
				</ul>
			<li>The earliest references to "Macintosh System Software" are in the Read Me documents on the System 4.0 Finder 5.4 and System 4.1 Finder 5.5 disks.</li>
			<li>System 4.0 Finder 5.4 was released in January 1987. It came on two 800K disks:</li>
				<ul>
					<li>Macintosh System Tools (v1.0)</li>
					<li>Macintosh Utilities (v1.0)</li>
				</ul>
			<li>System 4.1 Finder 5.5 was released in April 1987. [<a href="https://earlymacintosh.org/disk_images.html#System_4">disk images</a>] It came on two 800K disks:</li>
				<ul>
					<li>Macintosh System Tools (v2.0). Revised June 1987 (v2.0.1).</li>
					<li>Macintosh Utilities (v2.0). Revised June 1987 (v2.0.1). Revised August 1987 (v2.1, two disks).</li>
				</ul>
			<li>Macintosh System Software 5.0 and 5.1 came on four 800K disks: System Tools 1, System Tools 2 (Printers), Utilities 1, Utilities 2.</li>
			<li>Macintosh System Software 6.0–6.0.5 came on four 800K disks: System Tools, Printing Tools, Utilities 1, Utilities 2. [<a href="https://earlymacintosh.org/disk_images.html#System_6">disk images</a>]</li>
			<li>Macintosh System Software 6.0.7–6.0.8 came on two 1.4 Mb (high-density) disks: System Startup and System Additions.
		Four 800K disks were also available. [<a href="https://earlymacintosh.org/disk_images.html#System_6">disk images</a>]</li>
		</ul>
		<p><a id="A-1" name="A-1"></a>Throughout 1987, Apple considered System file 3.2 (or 3.3 as an AppleShare client) to be the maximum for machines with 512K memory. By early 1988, however, this recommendation had been changed to System file 4.1:</p>
		<blockquote>
			<blockquote>
				<p><img src="https://earlymacintosh.org/graphics/Figure.gif" alt="" width="360" height="450"></p>
			</blockquote>
			<p>From "A History of Macintosh System Software," Appendix A in <i>Macintosh System Software User's Guide Version 6.0</i> (1988).</p>
		</blockquote>
		<h2><a id="128_hardware" name="128_hardware"></a><span color="#00008b">Macintosh 128K and 512K hardware</span></h2>
		<p>The following information reflects the current state of my knowledge of Macintosh 128K [M0001 and M0001P] "Mac" and 512K [M0001W and M0001WP] "Fat Mac" hardware. It may not be complete, but it is accurate, based on personal experience and detailed reports from others, along with conclusions gleaned from the <a href="http://www.mac128.com/m0001">M0001 Registry</a>.</p>
		<p>There were three cases:</p>
		<ol>
		  <li>Early M0001 cases that read "Macintosh" on the back.</li>
			<li>Later M0001 cases that read "Macintosh 128K" on the back. This change was made in week 47 of 1984 (November).</li>
			<li>M0001W cases that read "Macintosh 512K" on the back.</li>
		</ol>
		<p>There were (at least) three generations of logic boards:</p>
		<ol>
		  <li>[820-0086-C] © 1983, 128K (630-0101) only.</li>
			<li>[820-0086-F] © 1983-84, could be configured as either 128K (630-0101) or 512K (630-0118) boards.</li>
			<li>[820-0141-A] © 1983-84, could be configured as either 128K (630-0101) or 512K (630-0118) boards.</li>
		</ol>
		<p>There were (at least) two generations of 128K/512K analog boards (630-0102):</p>
		<ol>
		  <li>[820-0082-B] © 1983, had a metal shield that ran along the top at BB1. Apple later removed the shield to increase convective cooling.</li>
		  <li>[820-0082-C] © 1983-84, had neither the shield nor BB1.</li>
		</ol>
    	<p>There were two generations of disk drives:</p>
		<ol>
		  <li>Early Sony model OA-D34V.</li>
			<li>Later Sony models OA-D34V-02 or OA-D34V-22. These models had a new insert/eject mechanism.</li>
    	</ol>
		<p>There were two series of external disk drives (model M0130):</p>
		<ol>
			<li>Serial number started with D, made in USA.* The earliest of these contained Sony OA-D34V drives. Later they contained OA-D34V-02/22 drives.</li>
			<li>Serial number started with Y, made in Japan.* These contained Sony OA-D34V-02/22 drives.</li>
		</ol>
		<blockquote>
			<p>* There is a difference between the two in the coloration of the plastic case. The plastic used for the D drives is the same as that used for early Macintosh machines. The plastic used for the Y drives is slightly different and does not yellow, at least not nearly as much.</p>
		</blockquote>
		<h2><a id="128_manuals" name="128_manuals"></a><span color="#00008b">Macintosh 128K and 512K manuals</span></h2>
		<p>Macintosh owner's guide:</p>
		<ul>
			<li>030-0687 [Macintosh] owner's guide, 160 pp. © 1983. Covered System 1.0 Finder 1.0. </li>           
			<li>030-0687-A [Macintosh] owner's guide, 160 pp. © 1984. Content is the same as the first edition.</li>
			  	<ul>
			    	<li>032-0001 [Macintosh System Update] insert. Dated January 25, 1984. [<a href="https://earlymacintosh.org/PDFs/032-0001.pdf">PDF</a>] Included with both of the above editions.</li>
					<li>032-0003 [Software Enhancements] insert, 3 pp. Added May 1984. [<a href="https://earlymacintosh.org/PDFs/032-0003.pdf">PDF</a>] Introduced new features in System 1.1 Finder 1.1g.</li>
		       	</ul>
  			<li>030-0687-B [Macintosh] owner's guide, 165 pp. © 1984. Covered System 1.1 Finder 1.1g.</li>
	  			<ul>
		  			<li>032-0017 [Macintosh Update: Finder and MacWrite] insert, 12 pp. Added June 1985. Introduced new features in System 2.0 Finder 4.1.</li>
	 			</ul>
		</ul>
		<p>MacWrite manual:</p>
		<ul>
			<li>030-0688 [MacWrite] manual, 143 pp. © 1983. Covered MacWrite 1.0.</li>
				<ul>
					<li>032-0002 [MacWrite/MacPaint Update] insert. Dated January 25, 1984. [<a href="https://earlymacintosh.org/PDFs/032-0002.pdf">PDF</a>]</li>
				</ul>
			<li>030-0688-B [MacWrite] manual, 143 pp. © 1984. Covered MacWrite 2.2.</li>
				<ul>
					<li>032-0012 [Macintosh Update: Disk-Based MacWrite] insert, 4 pp. Added April 1985. Introduced new features in MacWrite 4.5.</li>
				</ul>
		</ul>
		<p>MacPaint manual:</p>
		<ul>
			<li>030-0848 [MacPaint] manual, 32 pp. © 1983. Used for MacPaint versions 1.0 to 1.5.</li>
        </ul>
	    <p>Other items:</p>
        <ul>
          	<li>[Macintosh] five-fold leaflet. "The Adventure Begins Here." A guide to setting up the machine and getting started, along with a packing list.</li>  
          	<li>[Limited Warranty on Hardware] card. Ninety (90) days!</li>
          	<li>[Free MacWorld Offer] card. Two issues!</li>
		  	<li>Apple logo stickers. [<a href="https://earlymacintosh.org/graphics/Stickers-01-84.jpg">January 1984</a>]</li>
          	<li>One blank disk with two blank labels.</li>
        </ul>
    	<h2><a id="128_bundles" name="128_bundles"></a><span color="#00008b">Macintosh 128K and 512K software bundles</span></h2>
		<p><img src="https://earlymacintosh.org/graphics/WelcomeMac.jpg" alt="" width="448" height="126"></p>
		<p>The first Macintosh 128K machines came with a plastic box that included:</p>
		<ul>
		  <li>690-5003A "System Disk" disk: System 1.0 Finder 1.0 [<a href="https://earlymacintosh.org/disk_images.html#1.0">more info</a>]</li>
			<li>690-5002A "A Guided Tour of Macintosh" training disk</li>
				<ul>
					<li>942-0387A [A Guided Tour of Macintosh] audio tape (Side 1: 027-0013A, Side 2: 027-0014A)</li>
				</ul>
		</ul>
		<p>MacWrite and MacPaint came in a cardboard box that included:</p>
		<ul>
			<li>690-5009A "MacWrite MacPaint" disk [2]: MacWrite 1.0, MacPaint 1.0 [<a href="https://earlymacintosh.org/disk_images.html#1.0">more info</a>]</li>
			<li>690-5006A "MacWrite MacPaint: A Guided Tour" training disk</li>
				<li>942-0417A [A Guided Tour of MacWrite MacPaint] audio tape (Side 1: 027-0015B, Side 2: 027-0016B)</li>
		</ul>
		<p>Font Mover was included on the MacWrite MacPaint (Write/Paint) disk.</p>
		<p><a id="1.1" name="1.1"></a>In May 1984, the software bundle was updated and reorganized for System 1.1 Finder 1.1g. Font Mover and the additional fonts were moved to the System Disk in order to create more space on the MacWrite MacPaint disk and a new MacPaint disk was added. The two audio tapes remained the same [with the recordings updated?], and MacWrite MacPaint still came in a separate box:</p>
		<ul>
			<li>690-5003B "System Disk" disk: System 1.1 Finder 1.1g* [<a href="https://earlymacintosh.org/disk_images.html#System_1">disk image</a>]</li>
			<li>690-5002B "A Guided Tour of Macintosh" training disk (Finder 1.1h)</li>
				<ul>
					<li>[A Guided Tour of Macintosh] audio tape</li>
				</ul>
		</ul>
		<ul>
			<li>690-5009B "MacWrite MacPaint" disk [2]: MacWrite 2.2, MacPaint 1.3</li>
			<li>690-5011B "MacPaint" disk</li>
			<li>690-5006B "MacWrite MacPaint: A Guided Tour" training disk</li>
				<ul>
					<li>[A Guided Tour of MacWrite MacPaint] audio tape</li>
				</ul>
		</ul>
		<p>In September 1984, with the introduction of the Macintosh 512K, the bundle was changed so that all the components would fit inside the plastic Macintosh box:</p>
		<ul>
			<li>690-5003-C or 690-5003-D "System Disk" disk: System 1.1 Finder 1.1g*</li>
			<li>690-5023-A "System and MacWrite MacPaint: Back-Up" disk: MacWrite 2.2, MacPaint 1.4 [<a href="https://earlymacintosh.org/disk_images.html#System_1">disk image</a>]</li>
			<li>690-5024-A "MacWrite" disk [<a href="https://earlymacintosh.org/disk_images.html#System_1">disk image</a>]</li>
			<li>690-5011-C "MacPaint" disk [<a href="https://earlymacintosh.org/disk_images.html#System_1">disk image</a>]</li>
			<li>690-5002-C "A Guided Tour of Macintosh" training disk (Finder 1.1h)</li>
			<li>690-5006-C "MacWrite MacPaint: A Guided Tour" training disk</li>
			<li>685-0011-A [A Guided Tour of Macintosh and MacWrite MacPaint] audio tape (Side 1: 027-0021-A, Side 2: 027-0022-A)</li>
		</ul>
		<p>* There is no difference in content between the 690-5003B, 690-5003-C, and 690-5003-D disks. The different part numbers reflect changes in the packaging.</p>
		<p><a id="E" name="E"></a>In June 1985, the software bundle was updated for System 2.0 Finder 4.1. The training disks and audio tape remained the same:</p>
		<ul>
			<li>690-5003-E "System Disk" disk: System 2.0 Finder 4.1 [<a href="https://earlymacintosh.org/disk_images.html#System_2">disk image</a>]</li>
			<li>690-5023-B "System and MacWrite MacPaint: Back-Up" disk: MacWrite 4.5, MacPaint 1.5</li>
			<li>690-5024-B "MacWrite: Disk Based" disk [<a href="https://earlymacintosh.org/disk_images.html#System_2">disk image</a>]</li>
			<li>690-5011-D "MacPaint" disk [<a href="https://earlymacintosh.org/disk_images.html#System_2">disk image</a>]</li>
			<li>690-5002-C "A Guided Tour of Macintosh" training disk (Finder 1.1h)</li>
			<li>690-5006-C "MacWrite MacPaint: A Guided Tour" training disk</li>
			<li>685-0011-A [A Guided Tour of Macintosh and MacWrite MacPaint] audio tape (Side 1: 027-0021-A, Side 2: 027-0022-A)</li>
		</ul>
		<h2><a id="Plus_hardware" name="Plus_hardware"></a><span color="#00008b">Macintosh Plus and 512K<i>e</i> hardware</span></h2>
		<h3>Macintosh Plus</h3>
		<p>All original Macintosh Plus [M0001A and M0001AP] machines had the words "Macintosh Plus" on the front and came with the M0110A extended keyboard. There were three generations:</p>
		<ol>
			<li>"Beige" Macintosh Plus machines read "Macintosh Plus 1 Mb" on the back, with no copyright date. Beige was also the color of the Macintosh 128K and 512K, as well as the 512K<i>e.</i></li>
			<li>In 1987, Apple changed the label on the back to read "Macintosh Plus 1 Mb" with a 1987 copyright date. The case color was changed to "platinum" to match the color of the new Macintosh II and SE machines. The owner's guide was redesigned and revised (see below).</li>
			<li>In 1988, Apple changed the label on the back to read "Macintosh Plus" with a 1988 copyright date. The owner's guide was redesigned and revised again (see below).</li>
		</ol>
		<p>The Macintosh Plus ROMs were revised twice. The second revision coincided with the release of the platinum machines in 1987.</p>
		<h3><a id="e" name="e"></a>Macintosh 512K<i>e</i></h3>
		<p>There were two generations of Macintosh 512K<i>e</i> [M0001E] machines:</p>
		<ol>
			<li>Beige machines produced in 1986 have a label on the back with no copyright date. They came with the M0110 standard keyboard and contained first-revision Macintosh Plus ROMs. The location and design of the Apple logo on the front was the same as the original Macintosh and the 512K.</li>
			<li>Platinum machines have a 1987 copyright date on the label. They came with the M0110A extended keyboard and contained second-revision Macintosh Plus ROMs. The location and design of the Apple logo on the front was the same as the Plus.</li>
		</ol>
		<p><strong>Note:</strong> I have never seen a M0001E with a 220-240V power supply.</p>
    	<h3><a id="800" name="800"></a>Macintosh 512K/800</h3>
		<p>The Macintosh 512K/800 [M0001D or M0001E, depending on the power supply required locally] was a 512K<i>e</i> with a M0110A extended keyboard. To my knowledge, the 512K/800 was never sold retail in the United States. Like the first-generation 512K<i>e</i>, the location and design of the Apple logo on the front was the same as the original Macintosh and the 512K.</p>
		<p>The M0001D probably existed as a second-generation, platinum 1987 machine, but I have never seen one without "Macintosh ED" (see below) printed on the front.</p>
		<p><strong>Note:</strong> I have never seen a M0001D with a 110-120V power supply.</p>
		<h3><a id="ED" name="ED"></a>Macintosh ED</h3>
		<p>The Macintosh ED was a 512K/800 sold to educational institutions, mostly, if not entirely [?], outside of the United States. There were four editions of these machines:</p>
		<ol>
		  <li>Beige with M0001ED model number. [Serial numbers begin with F, for Fremont, California]</li>
          <li>Platinum with M0001ED model number.</li>
	      <li>Beige with "Macintosh ED" printed on the front and M0001D model number on the back. [Serial numbers begin with C, for Cork, Ireland.]</li>
          <li>Platinum with "Macintosh ED" printed on the front and M0001D model number on the back.*</li>
		</ol>
		<p>* A 1987 Dutch edition of the "Macintosh ED Addendum" booklet, covering System 4.0 Finder 5.4, has come to light. You can download a PDF at <a href="http://macintoshgarden.org/apps/macintosh-ed-addendum-manual-only-dutch">Macintosh Garden</a>.
		</p><h3>Macintosh Plus ED</h3>
		<p>The Macintosh Plus ED was a platinum Macintosh Plus with "Macintosh Plus ED" printed on the front.</p>
		<p><strong>Note:</strong> I have never seen a Macintosh Plus ED with a 110-120V power supply.</p>
    	<h2><a id="Plus_manuals" name="Plus_manuals"></a><span color="#00008b">Macintosh Plus and 512K<i>e</i> manuals</span></h2>
		<h3>Macintosh Plus</h3>
		<p>Changes in the design of the Macintosh Plus owner's guide (along with the software bundle) parallel the changes in the hardware.</p>
		<h4>First edition:</h4>
		<blockquote>
			<p><img src="https://earlymacintosh.org/graphics/PlusOG1.jpg" alt="" width="230" height="278"></p>
		</blockquote>
		<ul>
			<li>030-1246-A [Macintosh Plus] owner's guide, 183 pp. © 1986. Covered System 3.0 Finder 5.1.</li>
				<ul>
					<li>032-0027 [Important Macintosh Plus Information] insert, 4 pp. January 1986.</li>
				</ul>
			<li>030-1246-B [Macintosh Plus] owner's guide, 183 pp. © 1986. Revised to include content from the January 1986 insert.</li>
		</ul>
		<h4>Second edition:</h4>
		<blockquote>
			<p><img src="https://earlymacintosh.org/graphics/PlusOG2.jpg" alt="" width="233" height="279"></p>
		</blockquote>
		<ul>
			<li>030-1242-A [Macintosh Plus Owner's Guide] 234 pp. © 1987. Covered System 4.0 Finder 5.4. Bundled with:</li>
			<li>030-3173-A [Macintosh Utilities User's Guide] 54 pp. © 1987.</li>
				<ul>
					<li>Replaced by the manuals for Macintosh System Software 5.0 in October 1987:</li>
						<ul>
							<li>031-1302-A [Macintosh New Features Update] insert, 21 pp. © 1987.</li>
							<li>030-5623-A [MultiFinder User's Guide] 35 pp. © 1987.</li>
							<li>030-2133-A [Macintosh Utilities User's Guide] 109 pp. © 1987.</li>
						</ul>
				</ul>
		</ul>
		<h4>Third edition:</h4>
		<blockquote>
			<p><img src="https://earlymacintosh.org/graphics/PlusOG3.jpg" alt="" width="233" height="279"></p>
		</blockquote>
		<ul>
			<li>030-3294-A [Macintosh Plus Owner's Guide] 101 pp. © 1988.</li>
				<ul>
					<li>Bundled with the manuals for Macintosh System Software 6.0:</li>
						<ul>
							<li>030-3281-A [Macintosh System Software User's Guide Version 6.0] 274 pp. © 1988.</li>
							<li>030-3283-A [Macintosh Utilities User's Guide] 171 pp. © 1988.</li>
						</ul>
				</ul>
			<li>030-3294-B [Macintosh Plus Owner's Guide] 101 pp. © 1988. Updated the Unpacking guide, along with the Technical Information and Guide to Technical Documentation chapters.</li>
				<ul>
					<li>Bundled with the manuals for Macintosh System Software 6.0.4:</li>
						<ul>
							<li>030-3399-A [Macintosh System Software User's Guide Version 6.0.4] 275 pp. © 1989.</li>
							<li>030-3418-A [Macintosh Utilities User's Guide] 166 pp. © 1988.</li>
						</ul>
				</ul>
		</ul>
		<h3><a id="ke" name="ke"></a>Macintosh 512K<i>e</i></h3>
		<blockquote>
			<p><img src="https://earlymacintosh.org/graphics/512KeOG1.jpg" alt="" width="230" height="279"></p>
		</blockquote>
		<ul>
			<li>030-1326-A [Macintosh 512K <i>enhanced]</i> owner's guide, 181 pp. © 1986. Covered System 3.0 Finder 5.1.</li>
		</ul>
		<p>Sales of the Macintosh 512K<i>e</i> continued until September 1987. Apple did not update the 512K<em>e</em> owner's guide along with that of the Macintosh Plus. At the time, Apple considered System 3.2 Finder 5.3 to be the maximum for machines with 512K of memory. [It was only <a href="#software">later</a> that System 4.1 Finder 5.4 was declared the maximum.] This fact may explain why no effort was made to update the 512K<em>e</em> owner's guide and software bundle for the second-generation 512K<em>e</em> in 1987 (see <a href="#e">above</a>), while the Plus received a complete overhaul.</p>
		<h2><a id="Plus_bundles" name="Plus_bundles"></a><span color="#00008b">Macintosh Plus and 512K<i>e</i> software bundles</span></h2>
		<p>Before April 1988, all Macintosh Plus and 512K<i>e</i> software bundles included a demo disk for MacDraw, MacWrite, MacProject, MacPaint.</p>
		<h3>Macintosh Plus</h3>
		<p>In January 1986, the Macintosh Plus software bundle featured System 3.0 Finder 5.1:</p>
		<ul>
			<li>690-5064-A "Macintosh Plus: System Tools" disk (v1.0) [2]</li>
			<li>690-5065-A "Macintosh Plus: A Guided Tour" training disk (v1.0)</li>
				<ul>
					<li>[Macintosh Plus: A Guided Tour] audio tape</li>
				</ul>
		</ul>
		<p>In June 1986, the System Tools disk was updated for System 3.2 Finder 5.3:</p>
		<ul>
			<li>690-5064-B "Macintosh Plus: System Tools" disk (v1.1) [2] [<a href="https://earlymacintosh.org/disk_images.html#System_3">disk image</a>]</li>
		</ul>
		<p>In January 1987, the software bundle was updated for System 4.0 Finder 5.4:</p>
		<ul>
			<li>"Macintosh: System Tools" disk (v1.0)</li>
			<li>"Macintosh: Utilities" disk (v1.0)</li>
			<li>"Your Apple Tour of the Macintosh Plus" training disk (v1.1)</li>
		</ul>
		<p>In April 1987, the software bundle was updated for System 4.1 Finder 5.5:</p>
		<ul>
			<li>"Macintosh: System Tools" disk (v2.0)</li>
			<li>"Macintosh: Utilities" disk (v2.0)</li>
			<li>"Your Apple Tour of the Macintosh Plus" training disk (v1.1)</li>
		</ul>
		<p>In June 1987, the System Tools and Utilities disks were revised:</p>
		<ul>
			<li>690-6023-B "Macintosh: System Tools" disk (v2.0.1) [<a href="https://earlymacintosh.org/disk_images.html#System_4">disk image</a>]</li>
			<li>690-6024-B "Macintosh: Utilities" disk (v2.0.1)</li>
			<li>690-5157-B "Your Apple Tour of the Macintosh Plus" training disk (v1.1)</li>
		</ul>
		<p>In August 1987, the Utilities disk was revised a second time, on two disks:</p>
		<ul>
			<li>"Macintosh: Utilities 1" disk (v2.1) [<a href="https://earlymacintosh.org/disk_images.html#System_4">disk image</a>]</li>
			<li>"Macintosh: Utilities 2" disk (v2.1) [<a href="https://earlymacintosh.org/disk_images.html#System_4">disk image</a>]</li>
		</ul>
		<p>In October 1987, the software bundle was updated for Macintosh System Software 5.0, on four disks: System Tools 1, System Tools 2 (Printers), Utilities 1, Utilities 2.</p>
		<p>In April 1988, the software bundle was updated for Macintosh System Software 6.0, on four disks: System Tools, Printing Tools, Utilities 1, Utilities 2. HyperCard was also added to the box:</p>
		<ul>
			<li>690-5209-A "Your Apple Tour of the Macintosh Plus" training disk (v2.0)</li>
			<li>"HyperCard and Stacks"</li>
			<li>"HyperCard Help"</li>
			<li>"HyperCard Ideas"</li>
		</ul>
		<h3>Macintosh 512K<i>e</i></h3>
		<p>The Macintosh 512K<i>e</i> shipped in April 1986. It came with the earlier Macintosh Plus System Tools disk:</p>
		<ul>
		  <li>690-5064-A "Macintosh Plus: System Tools" disk (v1.0, System 3.0 Finder 5.1) [2]</li>
			<li>690-5090-A "Macintosh 512K <i>enhanced:</i> A Guided Tour" training disk (System 3.1.1 Finder 5.2)</li>
				<ul>
					<li>[Macintosh 512K <i>enhanced:</i> A Guided Tour] audio tape</li>
				</ul>
		</ul>
		<p>In June 1986, the System Tools disk was updated for System 3.2 Finder 5.3 and the Macintosh 512K<i>e:</i></p>
		<ul>
			<li>690-5091-A "Macintosh 512K <i>enhanced:</i> System Tools" disk (v1.0) [2] [<a href="https://earlymacintosh.org/disk_images.html#System_3">disk image</a>]</li>
		</ul>
		<p>Sales of the Macintosh 512K<i>e</i> continued until September 1987, but the software bundle did not change after June 1986. For more on this, see <a href="#ke">above</a>.</p>
		<h2><a id="OEM_upgrades" name="OEM_upgrades"></a><span color="#00008b">Apple OEM upgrades</span></h2>
		<p>Apple's OEM (Original Equipment Manufacturer) upgrades:</p>
		<ul>
			<li>[Macintosh 512K Memory Expansion Kit]</li>
				<ul>
					<li>Result was equivalent to a Macintosh 512K.</li>
					<li>Replaced 128K logic board with 512K logic board.</li>
				</ul>
			<li>[Macintosh Plus Disk Drive Kit]</li>
				<ul>
					<li>Result was equivalent to a Macintosh 512K<i>e</i>. Could also be performed on a Macintosh 128K, resulting in a Macintosh 128K<i>e</i>.</li>
					<li>Replaced 400K internal disk drive with 800K internal disk drive.</li>
					<li>Replaced 64K ROM chips with 128K ROM chips on the logic board.</li>
					<li>Included current Macintosh Plus System Tools disk.</li>
					<li>Included 030-1245-A or 030-1245-B [Macintosh Plus Internal Disk Drive] upgrade guide, 43 pp. © 1986. A thorough introduction to Finder 5.x and the Hierarchical File System (HFS).*</li>
				</ul>
			<li>[Macintosh Plus 1 Mb Logic Board Kit]</li>
				<ul>
					<li>Result was equivalent to a Macintosh Plus.</li>
					<li>Macintosh 128K/512K required Macintosh Plus Disk Drive Kit (above).</li>
					<li>Replaced 128K/512K/512K<i>e</i> logic board with Plus logic board.</li>
					<li>Replaced 128K/512K/512K<i>e</i> back panel with Plus back panel. Machines upgraded with this kit thus read "Macintosh Plus 1 Mb" on the back, but don't say "Macintosh Plus" on the front.</li>
					<li>Included current Macintosh Plus owner's guide.</li>
				</ul>
			<li>Macintosh Plus memory upgrades. Result was a Macintosh Plus with up to 4 Mb of memory.</li>
				<ul>
					<li>Replaced 256K plug-in memory modules with 1 Mb modules. You could replace either two or four modules, resulting in 2560K (2.5 Mb) or 4096K (4 Mb) of memory.</li>
				</ul>
		</ul>
		<p><a id="_400K_HFS" name="_400K_HFS"></a>* As far as I know, this is the only printed Apple manual that tells you how to initialize single-sided 400K disks in the HFS format. Requires Finder 5.x or 6.x: "Holding down the Option key while you click One-Sided (or if the disk is in a 400K disk drive, holding the Option key down while you press the Return key after you've named it) installs the hierarchical file system on just one side of the disk. Use disks initialized this way with updated startup disks only." In other words, they can't be used as startup disks. Or else!</p>
		
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I quit Google to work for myself (2018) (316 pts)]]></title>
            <link>https://mtlynch.io/why-i-quit-google/</link>
            <guid>42090430</guid>
            <pubDate>Fri, 08 Nov 2024 20:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/why-i-quit-google/">https://mtlynch.io/why-i-quit-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42090430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the past four years, I’ve worked as a software developer at Google. On February 1st, I quit. It was because they refused to buy me a Christmas present.</p><p>Well, I guess it’s a little more complicated than that.</p><h2 id="the-first-two-years">The first two years<a href="#the-first-two-years" arialabel="Anchor"> 🔗︎</a></h2><p>Two years in, I loved Google.</p><p>When the annual employee survey asked me whether I expected to be at Google in five years, it was a no-brainer.</p><p>Of <em>course</em> I’d still be at Google in five years. I was surrounded by the best engineers in the world, using the most advanced development tools in the world, and eating the free-est food in the world.</p><p><a href="https://mtlynch.io/why-i-quit-google/spoiled-coder.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/spoiled-coder.png 1024w" src="https://mtlynch.io/why-i-quit-google/spoiled-coder.png" alt="My typical day at Google" loading="lazy"></a></p><p>My most recent performance rating was “Strongly Exceeds Expectations.” If I just kept going, I’d soon be promoted to the next level, Senior Software Engineer. What a great title! Forever after in my career, I’d be able to say, “Yes, I was a <em>Senior</em> Software Engineer. At <em>Google</em>.” People would be so impressed.</p><p>My manager assured me that my promotion was close. He felt that I was already capable of senior-level work. I just needed the right project to prove it to the promotion committee.</p><p>No, managers at Google can’t promote their direct reports. They don’t even get a vote.</p><p>Instead, promotion decisions come from small committees of upper-level software engineers and managers who have never heard of you until the day they decide on your promotion.</p><p>You apply for promotion by assembling a “promo packet”: a collection of written recommendations from your teammates, design documents you’ve created, and mini-essays you write to explain why your work merits a promotion.</p><p>A promotion committee then reviews your packet with a handful of others, and they spend the day deciding who gets promoted and who doesn’t.</p><p>During my two-year honeymoon phase, this system sounded great to me. Of <em>course</em> my fate should be in the hands of a mysterious committee who’s never met me. They wouldn’t be tainted by any sort of favoritism or politics. They’d see past all that and recognize me for my high-quality code and shrewd engineering decisions.</p><h2 id="thats-not-really-how-it-works">That’s not really how it works<a href="#thats-not-really-how-it-works" arialabel="Anchor"> 🔗︎</a></h2><p>Before I put together my first promo packet, I never thought about the logistics of how it all worked.</p><p>In my head, the promotion committee was this omniscient and fair entity. If I spent each day choosing the right problems to solve, making the codebase better, and helping my team execute efficiently, the promotion committee would magically know this and reward me for it.</p><p>Unsurprisingly, it doesn’t work like that. It took me two years to figure that out.</p><h2 id="working-naïvely">Working naïvely<a href="#working-naïvely" arialabel="Anchor"> 🔗︎</a></h2><p>My main responsibility until that point was a legacy data pipeline. It had been in maintenance mode for years, but load had increased, and the pipeline was buckling under the pressure. It frequently died silently or produced incorrect output. Its failures took days to diagnose because nobody had written documentation for it since its original design spec.</p><p>I proudly and lovingly nursed the pipeline back to health. I fixed dozens of bugs and wrote automated tests to make sure they wouldn’t reappear. I deleted thousands of lines of code that were either dead or could be replaced by modern libraries. I documented the pipeline as I learned it so that the institutional knowledge was available to my teammates instead of siloed in my head.</p><p>The problem, as I discovered at promotion time, was that none of this was quantifiable. I couldn’t prove that anything I did had a positive impact on Google.</p><h2 id="metrics-or-it-didnt-happen">Metrics or it didn’t happen<a href="#metrics-or-it-didnt-happen" arialabel="Anchor"> 🔗︎</a></h2><p>The pipeline didn’t record many metrics. The ones it did have made it look like things had gotten worse. My bug discoveries caused the overall bug count to increase. The pipeline’s failures increased because I made it fail fast on anomalies instead of silently passing along bad data. I drastically reduced the time developers spent repairing those failures, but there were no metrics that tracked developer time.</p><p>My other work didn’t look so good on paper either. On several occasions, I put my projects on hold for weeks or even months at a time to help a teammate whose launch was at risk. It was the right decision for the team, but it looked unimpressive in a promo packet. To the promotion committee, my teammate’s project was the big, important work that demanded coordination from multiple developers. If they hornswoggled me into helping them, it’s evidence of their strong leadership qualities. I was just the mindless peon whose work was so irrelevant that it could be pre-empted at a moment’s notice.</p><p>I submitted my first promo packet, and the results were what I feared: the promotion committee said that I hadn’t proven I could handle technical complexity, and they couldn’t see the impact I had on Google.</p><p><a href="https://mtlynch.io/why-i-quit-google/promo-committee.png"><img sizes="(min-width: 768px) 800px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/promo-committee.png 1024w" src="https://mtlynch.io/why-i-quit-google/promo-committee.png" alt="Arguing my case to the promotion committee" loading="lazy"></a></p><h2 id="learning-from-rejection">Learning from rejection<a href="#learning-from-rejection" arialabel="Anchor"> 🔗︎</a></h2><p>The rejection was a difficult blow, but I wasn’t discouraged. I felt I was performing above my level, but the promotion committee couldn’t see it. That was solvable.</p><p>I decided that I had been too naïve in my first couple years. I didn’t do enough planning up front to make sure the work I was doing left a paper trail. Now that I understood how the process worked, I could keep doing the same good work, just with better record-keeping.</p><p>For example, my team was receiving tons of distracting email alerts due to false alarms. Old me would have just fixed these alerts. But now I knew that for this work to appear in my promo packet, I should first set up metrics so that we’d have historical records of alert frequency. At promotion time, I’d have an impressive-looking graph of the alerts trending downward.</p><p>Shortly after, I was assigned a project that seemed destined for promotion. It depended heavily on machine-learning, which was and still is the hot thing at Google. It would automate a task that hundreds of human operators were doing manually, so it had a clear, objective impact on Google. It also required me to lead a junior developer throughout the project, which generally won points with promotion committees.</p><h2 id="the-holiday-gift-wake-up-call">The holiday gift wake up call<a href="#the-holiday-gift-wake-up-call" arialabel="Anchor"> 🔗︎</a></h2><p>A few months later, Google <a href="http://fortune.com/2016/12/09/alphabet-donated-its-employees-holiday-gifts-to-charity/">made headlines</a> when they ended their long-standing tradition of giving lavish holiday gifts to all of their employees. Instead, they used the gift budget to buy <del>advertising disguised as charity</del> Chromebooks for underprivileged schoolchildren.</p><p>Shortly after this, I witnessed the following conversation between two employees:</p><blockquote><p><strong>Employee A</strong>: You effectively <strong>are</strong> still getting the gift. Cuts like these increase the value of Google’s stock. You can sell your stock grants and buy any present you choose.</p><p><strong>Employee B</strong>: What if I told my wife that I wasn’t buying her a Christmas gift, but she could use the money in our bank account to buy any present she wants?</p><p><strong>Employee A</strong>: You’re in a <strong>business</strong> relationship with Google. If you’re disappointed that Google isn’t “romancing” you with gifts like you do for your wife, you have a misguided notion of the relationship.</p></blockquote><p>Wait a second. <em>I</em> was in a business relationship with Google.</p><p>It may sound strange that it took me two and a half years to realize it, but Google does a good job of building a sense of community within the organization. To make us feel that we’re not just employees, but that we <em>are</em> Google.</p><p>That conversation made me realize that I’m <em>not</em> Google. I provide a service to Google in exchange for money.</p><p>So if Google and I have a business relationship that exists to serve each side’s interests, why was I spending time on all these tasks that served Google’s interests instead of my own? If the promotion committee doesn’t reward bugfixing or team support work, why was I doing that?</p><p>My first denied promotion taught me the wrong lesson. I thought I could keep doing the same work but package it to look good for the promotion committee. I should have done the opposite: figure out what the promotion committee wants, and do that work exclusively.</p><p>I adopted a new strategy. Before starting any task, I asked myself whether it would help my case for promotion. If the answer was no, I didn’t do it.</p><p>My quality bar for code dropped from, “Will we be able to maintain this for the next 5 years?” to, “Can this last until I’m promoted?” I didn’t file or fix any bugs unless they risked my project’s launch. I wriggled out of all responsibilities for maintenance work. I stopped volunteering for campus recruiting events. I went from conducting one or two interviews per week to zero.</p><h2 id="then-my-project-was-canceled">Then my project was canceled<a href="#then-my-project-was-canceled" arialabel="Anchor"> 🔗︎</a></h2><p>Priorities shifted. Management traded my project away to our sister team in India. In exchange, that team gave us one of their projects. It was an undocumented system, built on deprecated infrastructure, but it was nevertheless a critical component in production. I was assigned to untangle it from our sister team’s code and migrate it to a new framework, all while keeping it running in production and hitting its performance metrics.</p><p>As far as my promotion was concerned, this was a setback of several months. Because I hadn’t released anything for my canceled project, the two months I spent on it were worthless. It would take me weeks just to get up to speed on the system I was inheriting, and I was liable to lose several more in the gruntwork of keeping it operational.</p><h2 id="what-am-i-even-doing">What am I even doing?<a href="#what-am-i-even-doing" arialabel="Anchor"> 🔗︎</a></h2><p>It was the third time in six months that my manager had reassigned me midway through a project. Each time, he assured me that it had nothing to do with the quality of my work, but rather some shift in upper management strategy or team headcount.</p><p>At this point, I took a step back to assess what was happening from a high level. Forget my manager, forget his managers, forget the promotion committee. What if I boiled it down to just me and just Google? What was happening in our “business relationship?”</p><p>Well, Google kept telling me that it couldn’t judge my work until it saw me complete a project. Meanwhile, I couldn’t complete any projects because Google kept interrupting them midway through and assigning me new ones.</p><p>The dynamic felt absurd.</p><p><a href="https://mtlynch.io/why-i-quit-google/book-publisher.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/book-publisher.png 1024w" src="https://mtlynch.io/why-i-quit-google/book-publisher.png" alt="The Google promotion committee approach to book publishing" loading="lazy"></a></p><p>My career was being dictated by a shifting, anonymous committee who thought about me for an hour of their lives. Management decisions that I had no input into were erasing months of my career progress.</p><p>Worst of all, I wasn’t proud of my work. Instead of asking myself, “How can I solve this challenging problem?” I was asking, “How can I make this problem <em>look</em> challenging for promotion?” I hated that.</p><p>Even if I got the promotion, what then? Popular wisdom said that each promotion was exponentially harder than the last. To continue advancing my career, I’d need projects that were even larger in scope and involved collaboration with more partner teams. But that just meant the project could fail due to even more factors outside my control, wasting months or years of my life.</p><h2 id="whats-the-alternative">What’s the alternative?<a href="#whats-the-alternative" arialabel="Anchor"> 🔗︎</a></h2><p>Around this time, I discovered Indie Hackers.</p><p><a href="https://mtlynch.io/why-i-quit-google/indie-hackers.png"><img sizes="(min-width: 768px) 550px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_1200x0_resize_lanczos_3.png 1200w,
https://mtlynch.io/why-i-quit-google/indie-hackers.png 1545w" src="https://mtlynch.io/why-i-quit-google/indie-hackers.png" alt="Screenshot of Indie Hackers website" loading="lazy"></a></p><p>It’s an online community for founders of small software businesses. Emphasis on small. These weren’t Zuckerberg hopefuls, but rather people who wanted to build modest, profitable businesses that pay their bills.</p><p>I had always been interested in starting my own software company, but I only knew of the Silicon Valley startup path. I thought being a software founder meant spending most of my time fundraising and the rest of it worrying about how to attract my next million users.</p><p>Indie Hackers presented an attractive alternative. Most members built their businesses with their own savings or as side projects to their full-time jobs. They didn’t answer to investors, and they certainly didn’t have to prove themselves to anonymous committees.</p><p>There were downsides, of course. Their income was less steady, and they faced more numerous catastrophic risks. If I ever made a mistake at Google that cost the company $10 million, I would suffer no consequences. I’d be asked to write a post-mortem, and everyone would celebrate the learning opportunity. For most of these founders, a $10 million mistake would mean the end of their business and several lifetimes of debt.</p><p>Founders on Indie Hackers captivated me because they were in control. Whether their business became a runaway success or stagnated for years, they were calling the shots. At Google, I didn’t feel in control of my own projects, much less my career growth or my team’s direction.</p><p>I thought about it for months and finally decided. I wanted to be an Indie Hacker.</p><h2 id="one-last-thing-before-i-leave">One last thing before I leave<a href="#one-last-thing-before-i-leave" arialabel="Anchor"> 🔗︎</a></h2><p>I still had unfinished business at Google. After investing three years into my promotion, I hated the idea of leaving with nothing to show for it. There were only a few months left until I could reapply for promotion, so I decided to give it one last shot.</p><p>Six weeks before the performance period ended, my project was canceled. Again.</p><p>Actually, my whole team was canceled. This was a common enough occurrence at Google that there was a euphemism for it: a defrag. Management transferred my team’s projects to our sister team in India. My teammates and I all had to start over in different areas of the company.</p><p>I applied for the promotion anyway. Weeks later, my manager read me the results. My performance rating was “Superb,” the highest possible score, given to around 5% of employees each cycle. The promotion committee noted that in the past six months, I clearly demonstrated senior-level work. These were, uncoincidentally, the months when I was optimizing for promotion.</p><p><em>But</em> they felt that six months wasn’t a long enough track record, so… better luck next time.</p><p>My manager told me I had a strong chance at promotion if I did the same quality work for another six months. I can’t say I wasn’t tempted, but by that point, I’d been hearing, “great shot at promotion in six months,” for the past two years.</p><p>It was time to go.</p><h2 id="whats-next">What’s next?<a href="#whats-next" arialabel="Anchor"> 🔗︎</a></h2><p>When I tell people I left Google, they assume I must have some brilliant startup idea. Only an <em>idiot</em> would leave a job as cushy as Google Software Engineer.</p><p>But I am indeed an idiot with no idea.</p><p>My plan is to try different projects for a few months each to see if any of them catch on, for example:</p><ul><li>Continue working on <a href="https://mtlynch.io/tags/ketohub">KetoHub</a> to see if I can make it profitable</li><li>Build a business on top of Sia, a distributed storage technology I’ve <a href="https://mtlynch.io/tags/sia">written about frequently</a></li><li>Spend more time writing, and look for ways to earn money from it</li></ul><p>Google was a great place to work, and I learned valuable skills during my time there. Leaving was difficult because I had more to learn, but there will always be employers like Google. I won’t always have the freedom to start my own company, so I look forward to seeing where this takes me.</p><h2 id="updates">Updates<a href="#updates" arialabel="Anchor"> 🔗︎</a></h2><ul><li><strong>Update (Feb. 1, 2019)</strong>: <a href="https://mtlynch.io/solo-developer-year-1/">My First Year as a Solo Developer</a></li><li><strong>Update (Jan. 31, 2020)</strong>: <a href="https://mtlynch.io/solo-developer-year-2/">My Second Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2021)</strong>: <a href="https://mtlynch.io/solo-developer-year-3/">My Third Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2022)</strong>: <a href="https://mtlynch.io/solo-developer-year-4/">My Fourth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2023)</strong>: <a href="https://mtlynch.io/solo-developer-year-5/">My Fifth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2024)</strong>: <a href="https://mtlynch.io/solo-developer-year-6/">My Sixth Year as a Bootstrapped Founder</a></li></ul><hr><p><em>Illustrations by <a href="https://www.loraineyow.com/">Loraine Yow</a>.</em></p></div></div>]]></description>
        </item>
    </channel>
</rss>