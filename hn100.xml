<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 11 Jul 2023 06:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[After 30 Years, Linux Finally Hits 3% Market Share (112 pts)]]></title>
            <link>https://linuxiac.com/linux-hits-3-percent-market-share/</link>
            <guid>36676103</guid>
            <pubDate>Tue, 11 Jul 2023 03:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxiac.com/linux-hits-3-percent-market-share/">https://linuxiac.com/linux-hits-3-percent-market-share/</a>, See on <a href="https://news.ycombinator.com/item?id=36676103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p><strong><strong>Linux enthusiasts rejoice! After a long journey, according to StatCounter’s data, by June 2023, Linux has achieved a 3% desktop market share.</strong></strong></p>



<p>Linux has a long history that dates back <a href="https://linuxiac.com/linux-birthday/">more than 30 years</a>. However, it has never been as popular among regular computer users as other operating systems such as Microsft’s Windows or Apple’s macOS.</p>



<p>Of course, for many years, Linux has emerged as a dominant force in the realm of server operating systems. Due to its exceptional performance, stability, reliability, and security, it has been widely adopted in server/cloud/IoT environments.</p>



<p>However, these days, Linux is no longer limited to these environments alone; it is rapidly gaining momentum as an operating system of choice for many desktop users, especially developers.</p>



<p>And the most recent figures confirm this, giving all advocates of Linux and open source in general reason to rejoice.</p>





<p><a href="https://gs.statcounter.com/os-market-share/desktop/worldwide" target="_blank" rel="noreferrer noopener">According to StatCounter</a>, a web analytics company, by June 2023, Linux has reached a 3% market share in the desktop segment. This is a remarkable achievement considering its fierce competition from other operating systems.</p>



<figure><a href="https://linuxiac.b-cdn.net/wp-content/uploads/2023/07/lunux-marketshare-statcounter.jpg"><img decoding="async" width="1024" height="838" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMTIwIDkxNyIgd2lkdGg9IjExMjAiIGhlaWdodD0iOTE3IiBkYXRhLXU9Imh0dHBzJTNBJTJGJTJGbGludXhpYWMuY29tJTJGd3AtY29udGVudCUyRnVwbG9hZHMlMkYyMDIzJTJGMDclMkZsdW51eC1tYXJrZXRzaGFyZS1zdGF0Y291bnRlci5qcGciIGRhdGEtdz0iMTEyMCIgZGF0YS1oPSI5MTciIGRhdGEtYmlwPSIiPjwvc3ZnPg==" data-spai="1" alt="Desktop Operating System Market Share Worldwide" srcset=" " sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Desktop Operating System Market Share Worldwide</figcaption></figure>



<p>While someone may seem the figure modest, it signifies a growing acceptance and recognition of the power and versatility of Linux.</p>



<p>In any case, the achievement of a 3% market share by Linux is undoubtedly a cause for celebration among its dedicated community. It reflects the growing recognition of Linux’s strengths and the efforts to overcome its historical barriers.</p>



<p>Moreover, with the continued development and innovation within the Linux ecosystem, its market share will continue growing in the coming years.</p>



<p>The growing importance of cloud computing and the rise of server infrastructure have also contributed to Linux’s success. Still, the main reason for reaching this figure is the operating system’s growing popularity among desktop users.</p>



<p>With exceptionally easy-to-use and entirely user-centric <a href="https://linuxiac.com/best-7-linux-distro-releases-for-desktop-in-2022/">Linux desktop distributions</a>, the operating system is no longer what it was 20 years ago – a complex equation available only to highly technically enlightened hackers.</p>


<h2 id="h-linux-growing-popularity-among-desktop-users">Linux Growing Popularity among Desktop Users</h2>


<figure><a href="https://linuxiac.b-cdn.net/wp-content/uploads/2023/07/linux-desktop.jpg"><img decoding="async" width="1024" height="640" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxNjgwIDEwNTAiIHdpZHRoPSIxNjgwIiBoZWlnaHQ9IjEwNTAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZsaW51eGlhYy5jb20lMkZ3cC1jb250ZW50JTJGdXBsb2FkcyUyRjIwMjMlMkYwNyUyRmxpbnV4LWRlc2t0b3AuanBnIiBkYXRhLXc9IjE2ODAiIGRhdGEtaD0iMTA1MCIgZGF0YS1iaXA9IiI+PC9zdmc+" data-spai="1" alt="Linux with GNOME Desktop." srcset=" " sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Linux with GNOME Desktop.</figcaption></figure>



<p>Yes, I know. Over the last 10+ years, each one has often been heralded as “Linux on the Desktop,” although it turns out that’s not quite the case. But still, we’re close to that point now. And for good reasons.</p>


<h3 id="free-lightweight-amp-customizable">Free, Lightweight &amp; Customizable</h3>


<p>The main appealing aspect of Linux for desktop users is its lightweight nature, free from corporate bloatware, and especially the limitless customization options.</p>



<p>It allows users to tailor their desktop environment to suit their preferences and workflow. With a vast selection of desktop environments like GNOME, KDE, Xfce, and many others, users can choose the one that best aligns with their needs.</p>


<h3 id="valuing-user-privacy">Valuing User Privacy</h3>


<p>Another important factor driving Linux’s growing popularity among desktop users is privacy. Compared to other mainstream operating systems, Linux generally collects no user data.</p>



<p>While <a href="https://linuxiac.com/fedora-40-plans-to-use-telemetry/">some distributions may try to collect basic telemetry data</a> for improvement purposes, the level of data collection is typically minimal and can be disabled or opted out of entirely. This aspect appeals to privacy-conscious individuals who prefer more control over their personal information.</p>


<h3 id="linux-is-a-developers-dream-come-true">Linux is a Developer’s Dream Come True</h3>


<p>Linux has long been the operating system of choice for developers worldwide, and its allure continues to grow.</p>



<p>First and foremost, Linux’s open-source nature empowers developers with unparalleled freedom. They can access and modify the source code, customize their environments, and contribute to the community, fostering collaboration and innovation.</p>



<p>Furthermore, performance is also a crucial factor. Linux’s efficiency, scalability, and ability to run on diverse hardware architectures make it ideal for resource-intensive tasks.</p>



<p>Lastly, its command-line interface and powerful scripting capabilities offer flexibility and automation, streamlining development workflows.</p>


<h2 id="bottom-line">Bottom Line</h2>


<p>So, as Linux enthusiasts rejoice, it is essential to remember that the journey does not end here. Linux has proven its worth, and its rise to a 3% desktop market share is a testament to its resilience and adaptability in the desktop field.</p>



<p>With ongoing advancements and increased support from the Open Source community and businesses, Linux is poised to become an even more formidable player in the world of operating systems.</p>




		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 details leaked? (170 pts)]]></title>
            <link>https://threadreaderapp.com/thread/1678545170508267522.html</link>
            <guid>36675934</guid>
            <pubDate>Tue, 11 Jul 2023 03:00:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://threadreaderapp.com/thread/1678545170508267522.html">https://threadreaderapp.com/thread/1678545170508267522.html</a>, See on <a href="https://news.ycombinator.com/item?id=36675934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-controller="mentions">

<div>
<p><a href="https://threadreaderapp.com/user/Yampeleg"><img src="https://pbs.twimg.com/profile_images/1505912788031623170/GC7LMHNp_bigger.jpg" alt="Yam Peleg Profile picture" data-controller="twitter-profile" data-twtrid="634339745" data-action="error->twitter-profile#error"></a>
</p>

</div> 
<div id="tweet_1" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545170508267522" dir="auto"><p>
GPT-4's details are leaked. </p><p>

It is over.</p><p>

Everything is here: <a data-preview="true" href="https://twitter.com/i/web/status/1678545170508267522">twitter.com/i/web/status/1…</a>
<sup><i></i></sup></p></div>
<div id="tweet_2" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545175210074112" dir="auto"><p>
Parameters count:</p><p>

GPT-4 is more than 10x the size of GPT-3. We believe it has a total of ~1.8 trillion parameters across 120 layers.
<sup><i></i></sup></p></div>
<div id="tweet_3" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545177282052098" dir="auto"><p>
Mixture Of Experts - Confirmed.</p><p>

OpenAI was able to keep costs reasonable by utilizing a mixture of experts (MoE) model.<br>
They utilizes 16 experts within their model, each is about ~111B parameters for MLP. 2 of these experts are routed to per forward pass.
<sup><i></i></sup></p></div>
<div id="tweet_4" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545179840589836" dir="auto"><p>
MoE Routing:</p><p>

While the literature talks a lot about advanced routing algorithms for choosing which experts to route each token to, OpenAI’s is allegedly quite simple, for the current GPT-4 model.</p><p>

There roughly ~55B shared parameters for attention.
<sup><i></i></sup></p></div>
<div id="tweet_5" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545182990512129" dir="auto"><p>
Inference:</p><p>

Each forward pass inference (generation of 1 token) only utilizes ~280B parameters and ~560 TFLOPs. This contrasts with the ~1.8 trillion parameters and ~3,700 TFLOP that would be required per forward pass of a purely dense model.
<sup><i></i></sup></p></div>
<div id="tweet_6" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545185108631552" dir="auto"><p>
Dataset:</p><p>

GPT-4 is trained on ~13T tokens.</p><p>

These are not unique tokens, they count the epochs as more tokens as well.</p><p>

Epoch number: 2 epochs for text-based data and 4 for code-based data.</p><p>

There is millions of rows of instruction fine-tuning data from ScaleAI &amp; internally.
<sup><i></i></sup></p></div>
<div id="tweet_7" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545188363329539" dir="auto"><p>
GPT-4 32K</p><p>

There was an 8k context length (seqlen) for the pre-training phase. The 32k seqlen version of GPT-4 is based on fine-tuning of the 8k after the pre-training.
<sup><i></i></sup></p></div>
<div id="tweet_8" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545190892470272" dir="auto"><p>
Batch Size:</p><p>

The batch size was gradually ramped up over a number of days on the cluster, but by the end, OpenAI was using a batch size of 60 million! This, of course, is “only” a batch size of 7.5 million tokens per expert due to not every expert seeing all tokens.
<sup><i></i></sup></p></div>
<p>
For the real batch size:<br>
Divide this number by the seq len to get the real batch size. just stop with this misleading numbers already.
<sup><i></i></sup>
</p>
<div id="tweet_10" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545195506233344" dir="auto"><p>
Parallelism Strategies</p><p>

To parallelize across all their A100s GPUs They utilized 8-way tensor parallelism as that is the limit for NVLink.</p><p>

Beyond that, they are using 15-way pipeline parallelism.</p><p>

(likely used ZeRo Stage 1. It is possible they used block-level FSDP)
<sup><i></i></sup></p></div>
<div id="tweet_11" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545197792206851" dir="auto"><p>
Training Cost</p><p>

OpenAI’s training FLOPS for GPT-4 is ~2.15e25, on ~25,000 A100s for 90 to 100 days at about 32% to 36% MFU.</p><p>

Part of this extremely low utilization is due to an absurd number of failures requiring checkpoints that needed to be restarted from.
<sup><i></i></sup></p></div>
<div id="tweet_12" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545200325558272" dir="auto"><p>
If their cost in the cloud was about $1 per A100 hour, the training costs for this run alone would be about $63 million.</p><p>

(Today, the pre-training could be done with ~8,192 H100 in ~55 days for $21.5 million at $2 per H100 hour.)
<sup><i></i></sup></p></div>
<div id="tweet_13" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545202477146113" dir="auto"><p>
Mixture of Expert Tradeoffs</p><p>

There are multiple MoE tradeoffs taken: For example, MoE is incredibly difficult to deal with on inference because not every part of the model is utilized on every token generation.
<sup><i></i></sup></p></div>
<div id="tweet_14" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545205442621440" dir="auto"><p>
This means parts may sit dormant when other parts are being used. When serving users, this really hurts utilization rates.</p><p>

Researchers have shown that using 64 to 128 experts achieves better loss than 16 experts, but that’s purely research.
<sup><i></i></sup></p></div>
<p>
There are multiple reasons to go with fewer experts. One reason for OpenAI choosing 16 experts is because more experts are difficult to generalize at many tasks. More experts can also be more difficult to achieve convergence with.
<sup><i></i></sup>
</p>
<p>
With such a large training run, OpenAI instead chose to be more conservative on the number of experts.
<sup><i></i></sup>
</p>
<div id="tweet_17" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545212581265409" dir="auto"><p>
GPT-4 Inference Cost</p><p>

GPT-4 costs 3x that of the 175B parameter Davinchi.<br>
This is largely due to the larger clusters required for GPT-4 and much lower utilization achieved.
<sup><i></i></sup></p></div>
<p>
AN estimate of it's costs is $0.0049 cents per 1k tokens for 128 A100s to inference GPT-4 8k seqlen and $0.0021 cents per 1k tokens for 128 H100’s to inference GPT-4 8k seqlen. It should be noted, we assume decent high utilization, and keeping batch sizes high.
<sup><i></i></sup>
</p>
<div id="tweet_19" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545217631272960" dir="auto"><p>
Multi-Query Attention</p><p>

OpenAI are using MQA just like everybody else.<br>
Because of that only 1 head is needed and memory capacity can be significantly reduced for the KV cache. Even then, the 32k seqlen GPT-4 definitely cannot run on 40GB A100s, and the 8k is capped on max bsz.
<sup><i></i></sup></p></div>
<div id="tweet_20" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545219774562304" dir="auto"><p>
Continuous batching</p><p>

OpenAI implements both variable batch sizes and continuous batching. This is so as to allow some level of maximum latency as well optimizing the inference costs.
<sup><i></i></sup></p></div>
<div id="tweet_21" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545222815424512" dir="auto"><p>
Vision Multi-Modal</p><p>

It is a separate vision encoder from the text encoder, with cross-attention. The architecture is similar to Flamingo. This adds more parameters on top of the 1.8T of GPT-4. It is fine-tuned with another ~2 trillion tokens, after the text only pre-training.
<sup><i></i></sup></p></div>
<p>
On the vision model, OpenAI wanted to train it from scratch, but it wasn’t mature enough, so they wanted to derisk it by starting with text.
<sup><i></i></sup>
</p>
<p>
One of the primary purposes of this vision capability is for autonomous agents able to read web pages and transcribe what’s in images and video.
<sup><i></i></sup>
</p>
<div id="tweet_24" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678545231300403200" dir="auto"><p>
Some of the data they train on is joint data (rendered LaTeX/text), screen shots of web page, youtube videos: sampling frames, and run Whisper around it to get transcript.</p><p>

[Dont want to say "I told you so" but..]
<sup><i></i></sup></p></div>
<div id="tweet_25" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678546324105330689" dir="auto"><p>
Speculative Decoding</p><p>

OpenAI might be using speculative decoding on GPT-4's inference. (not sure 100%)</p><p>

The idea is to use a smaller faster model to decode several tokens in advance, and then feeds them into a large oracle model as a single batch.
<sup><i></i></sup></p></div>
<p>
If the small model was right about its predictions – the larger model agrees and we can decode several tokens in a single batch.
<sup><i></i></sup>
</p>
<p>
But if the larger model rejects the tokens predicted by the draft model then the rest of the batch is discarded. And we continue with the larger model.
<sup><i></i></sup>
</p>
<p>
The conspiracy theory that the new GPT-4 quality had been deteriorated might be simply because they are letting the oracle model accept lower probability sequences from the speculative decoding model.
<sup><i></i></sup>
</p>
<div id="tweet_29" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678547812177330180" dir="auto"><p>
Inference Architecture</p><p>

The inference runs on a cluster of 128 GPUs.</p><p>

There are multiple of these clusters in multiple datacenters in different locations.</p><p>

It is done in 8-way tensor parallelism and 16-way pipeline parallelism.</p><p>

Each node of 8 GPUs has only ~130B parameters, or… <a data-preview="true" href="https://twitter.com/i/web/status/1678547812177330180">twitter.com/i/web/status/1…</a>
<sup><i></i></sup></p></div>
<p>
The model has 120, so it fits in 15 different nodes.<br>
[Possibly the there are less layers on the first node since it needs to also compute the embeddings]
<sup><i></i></sup>
</p>
<div id="tweet_31" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678549234612674560" dir="auto"><p>
According to these numbers: OpenAI should have trained on 2x the tokens if they were trying to go by chinchilla's optimal.</p><p>

[let alone surpass it like we do]</p><p>

This goes to show that they are struggling to get high quality data.
<sup><i></i></sup></p></div>
<div id="tweet_32" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678550338075336706" dir="auto"><p>
Why no FSDP?</p><p>

A possible reason for this could be that some of the hardware infra they secured is of an older generation. </p><p>

This is pretty common at local compute clusters as the organisation usually upgrade the infra in several "waves" to avoid a complete pause of operation.… <a data-preview="true" href="https://twitter.com/i/web/status/1678550338075336706">twitter.com/i/web/status/1…</a>
<sup><i></i></sup></p></div>
<div id="tweet_33" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678553044219224064" dir="auto"><p>
Dataset Mixture</p><p>

They trained on 13T tokens.<br>
CommonCrawl &amp; RefinedWeb are both 5T.</p><p>

Remove the duplication of tokens from multiple epochs and we get to a much reasonable number of "unaccounted for" tokens: The "secret" data.
<sup><i></i></sup></p></div>
<div id="tweet_34" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678553048501633024" dir="auto"><p>
Which by this point we already get rumors that parts of it came from twitter, reddit &amp; youtube.</p><p>

[Rumors that start to become lawsuits] </p><p>

Some speculations are:<br>
- LibGen (4M+ books)<br>
- Sci-Hub (80M+ papers)<br>
- All of GitHub
<sup><i></i></sup></p></div>
<div id="tweet_35" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678553050296856577" dir="auto"><p>
My own opinion:</p><p>

The missing dataset it a custom dataset of college textbooks collected by hand for as much courses as possible.</p><p>

This is very easy to convert to txt file and than with self-instruct into instruction form.
<sup><i></i></sup></p></div>
<div id="tweet_36" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678553055673872387" dir="auto"><p>
This creates the "illusion" that GPT-4 "is smart" no matter who use it.</p><p>

Computer scientist? sure! it can help you with your questions about P!=NP<br>
Philosophy major? It can totally talk to you about epistemology.</p><p>

Don't you see?<br>
It was trained on the textbooks. It is so obvious.
<sup><i></i></sup></p></div>
<div id="tweet_37" data-controller="thread" data-action="click->thread#showTweet" data-screenname="Yampeleg" data-tweet="1678553507236835328" dir="auto"><p>
There are also papers that try to extract by force memorized parts of books from GPT-4 to understand what it trained on. </p><p>

There are some books it knows so well that it had seen them for sure.</p><p>

Moreover, If i remember correctly: It even know the unique ids of project Euler exes.
<sup><i></i></sup></p></div>
<p>• • •</p>
<p><span>
Missing some Tweet in this thread? You can try to
<a id="force-click" href="#" data-category="refresh" data-action="1678545170508267522">force a refresh</a>
</span>
</p>
　
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Easy HTTPS for your private networks (102 pts)]]></title>
            <link>https://www.getlocalcert.net/</link>
            <guid>36674224</guid>
            <pubDate>Mon, 10 Jul 2023 23:05:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.getlocalcert.net/">https://www.getlocalcert.net/</a>, See on <a href="https://news.ycombinator.com/item?id=36674224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <h2>ACME Client Configuration</h2>

<div>
  <div>
    <h3>Using Caddy</h3>

    <p>
    Modern, all-in-one web server
    </p>

    <div><p>
    Edit Caddyfile:
    </p><!-- https://github.com/caddy-dns/acmedns -->
    <pre><code>
<yoursubdomain>.localhostcert.net {
  tls {
    dns acmedns credentials.json
  }
  respond "Hello"
}
</yoursubdomain></code></pre>

    <p><a href="https://docs.getlocalcert.net/acme-clients/caddy/">See full example</a>

    </p></div>
  </div>

  <div>
    <h3>Using traefik</h3>
    <p>
    Cloud-native application proxy
    </p>
    <div><p>
    Edit configuration:
    </p><pre><code>
certificatesResolvers:
  myresolver:
    acme:
      dnsChallenge:
        provider: acme-dns</code></pre>

    <p><a href="https://docs.getlocalcert.net/acme-clients/traefik/">See full example</a>
    </p></div>
  </div>

</div>
<div>

  <div>
    <h3>Using cert-manager</h3>

    <p>
    Certificate automation for Kubernetes
    </p>

    <div><p>
    Edit configuration:
    </p><pre><code>
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: example-issuer
spec:
  acme:
    solvers:
    - dns01:
        acmeDNS:
          host: https://api.getlocalcert.net/api/v1/acme-dns-compat
          accountSecretRef:
            name: acme-dns
            key: credentials.json</code></pre>

    <p><a href="https://docs.getlocalcert.net/acme-clients/cert-manager/">See full example</a>

    </p></div>
  </div>

  <div>
    <h3>Using acme.sh</h3>

    <p>
    Get started quickly
    </p>

    <div>
    <pre><code>
$ export ACMEDNS_BASE_URL=https://api.getlocalcert.net/api/v1/acme-dns-compat
$ export ACMEDNS_USERNAME=yourApiKeyId
$ export ACMEDNS_PASSWORD=yourApiKeySecret
$ export ACMEDNS_SUBDOMAIN=yoursubdomain
$ ./acme.sh --issue \
            --dns dns_acmedns \
            -d yoursubdomain.localhostcert.net</code></pre>
    <p><a href="https://docs.getlocalcert.net/acme-clients/acme-sh/">See full example</a>
    </p></div>
  </div>



</div>

<div>

  <div>
    <h3>Using LEGO</h3>

    <p>
    A client build by Let's Encrypt
    </p>

    <div>
    <pre><code>
$ export ACME_DNS_API_BASE=https://api.getlocalcert.net/api/v1/acme-dns-compat
$ export ACME_DNS_STORAGE_PATH=credentials.json
$ lego --email you@example.com \
       --dns acme-dns \
       --domains yoursubdomain.localhostcert.net \
       run</code></pre>
    <p><a href="https://docs.getlocalcert.net/acme-clients/lego/">See full example</a>
    </p></div>
    
  </div>

  <div>
    <h3>Certify The Web</h3>

    <p>
    Manage certificates on Windows and IIS
    </p>

    <div>
      <pre><code>
1. Select acme-dns as the DNS update method.
2. Enter https://api.getlocalcert.net/api/v1/acme-dns-compat as the server
3. Click Request Certificate
4. Skip the CNAME step, you won't need it
      </code></pre>
      <p><a href="https://docs.getlocalcert.net/acme-clients/certify-the-web/">See full example</a>
    </p></div>
  </div>

</div>

    <section>
      <h2>
        Ready to set up your free domain name?
      </h2>
      
      <p>
      <a href="https://console.getlocalcert.net/">Get Started</a>
      </p>
    </section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shortening the Let's Encrypt chain of trust (268 pts)]]></title>
            <link>https://letsencrypt.org/2023/07/10/cross-sign-expiration.html</link>
            <guid>36673793</guid>
            <pubDate>Mon, 10 Jul 2023 22:19:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2023/07/10/cross-sign-expiration.html">https://letsencrypt.org/2023/07/10/cross-sign-expiration.html</a>, See on <a href="https://news.ycombinator.com/item?id=36673793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<article>
		<p>When Let’s Encrypt first launched, we needed to ensure that our certificates were widely trusted. To that end, we arranged to have our intermediate certificates <a href="https://letsencrypt.org/2015/10/19/lets-encrypt-is-trusted.html">cross-signed by IdenTrust’s DST Root CA X3</a>. This meant that all certificates issued by those intermediates would be trusted, even while our own ISRG Root X1 wasn’t yet. During subsequent years, our Root X1 became <a href="https://letsencrypt.org/docs/certificate-compatibility/">widely trusted</a> on its own.&nbsp;</p>
<p>Come late 2021, our cross-signed intermediates and DST Root CA X3 itself were expiring. And while all up-to-date browsers at that time trusted our root, <a href="https://letsencrypt.org/2020/11/06/own-two-feet.html">over a third of Android devices</a> were still running old versions of the OS which would suddenly stop trusting websites using our certificates. That breakage would have been too widespread, so we arranged for a new cross-sign – this time <a href="https://letsencrypt.org/2020/12/21/extending-android-compatibility.html">directly onto our root</a> rather than our intermediates – which would outlive DST Root CA X3 itself. This stopgap allowed those old Android devices to continue trusting our certificates for three more years.</p>
<p>On September 30th, 2024, that cross-sign too will expire.</p>
<p>In the last three years, the percentage of Android devices which trust our ISRG Root X1 has risen from 66% to 93.9%. That percentage will increase further over the next year, especially as Android releases version 14, which has the ability to <a href="https://www.xda-developers.com/android-14-root-certificates-updatable">update its trust store without a full OS update</a>. In addition, dropping the cross-sign will reduce the number of certificate bytes sent in a TLS handshake by over 40%. Finally, it will significantly reduce our operating costs, allowing us to focus our funding on continuing to improve your privacy and security.</p>
<p>For these reasons, we will not be getting a new cross-sign to extend compatibility any further.</p>
<p>The transition will roll out as follows:</p>
<ul>
<li>
<p>On <strong>Thursday, Feb 8th, 2024</strong>, we will stop providing the cross-sign by default in requests made to our /acme/certificate API endpoint. For most Subscribers, this means that your ACME client will configure a chain which terminates at ISRG Root X1, and your webserver will begin providing this shorter chain in all TLS handshakes. The longer chain, terminating at the soon-to-expire cross-sign, will still be available as an alternate chain which you can configure your client to request.</p>
</li>
<li>
<p>On <strong>Thursday, June 6th, 2024</strong>, we will stop providing the longer cross-signed chain entirely. This is just over <a href="https://letsencrypt.org/2015/11/09/why-90-days.html">90 days</a> (the lifetime of one certificate) before the cross-sign expires, and we need to make sure subscribers have had at least one full issuance cycle to migrate off of the cross-signed chain.</p>
</li>
<li>
<p>On <strong>Monday, September 30th, 2024</strong>, the cross-signed certificate will expire. This should be a non-event for most people, as any client breakages should have occurred over the preceding six months.</p>
</li>
</ul>
<p><img alt="Infographic of the distribution of installed Android versions, showing that 93.9% of the population is running Android 7.1 or above." src="https://letsencrypt.org/images/2023.07.10-android-version-distribution.png">
</p>
<p><strong>If you use Android 7.0 or earlier</strong>, you may need to take action to ensure you can still access websites secured by Let’s Encrypt certificates. We recommend installing and using <a href="https://www.mozilla.org/en-US/firefox/browsers/mobile/android/">Firefox Mobile</a>, which uses its own trust store instead of the Android OS trust store, and therefore trusts ISRG Root X1.</p>
<p><strong>If you are a site operator</strong>, you should keep an eye on your website usage statistics and active user-agent strings during Q2 and Q3 of 2024. If you see a sudden drop in visits from Android, it is likely because you have a significant population of users on Android 7.0 or earlier. We encourage you to provide the same advice to them as we provided above.</p>
<p><strong>If you are an ACME client author</strong>, please make sure that your client correctly downloads and installs the certificate chain provided by our API during every certificate issuance, including renewals. Failure modes we have seen in the past include a) never downloading the chain at all and only serving the end-entity certificate; b) never downloading the chain and instead serving a hard-coded chain; and c) only downloading the chain at first issuance and not re-downloading during renewals. Please ensure that your client does not fall into any of these buckets.</p>
<p>We appreciate your understanding and support, both now and in the years to come as we provide safe and secure communication to everyone who uses the web. If you have any questions about this transition or any of the other work we do, please ask on our <a href="https://community.letsencrypt.org/">community forum</a>.</p>
<p>We’d like to thank IdenTrust for their years of partnership. They played an important role in helping Let’s Encrypt get to where we are today and their willingness to arrange a stopgap cross sign in 2021 demonstrated a true commitment to creating a secure Web.&nbsp;</p>
<p>We depend on contributions from our supporters in order to provide our services. If your company or organization can help our work by becoming a <a href="https://www.abetterinternet.org/sponsor/">sponsor</a> of Let’s Encrypt please email us at <a href="mailto:sponsor@letsencrypt.org">sponsor@letsencrypt.org</a>. We ask that you make an <a href="https://letsencrypt.org/donate/">individual contribution</a> if it is within your means.</p>

	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-hosted photo and video backups directly from your mobile phone (432 pts)]]></title>
            <link>https://github.com/immich-app/immich</link>
            <guid>36673224</guid>
            <pubDate>Mon, 10 Jul 2023 21:28:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/immich-app/immich">https://github.com/immich-app/immich</a>, See on <a href="https://news.ycombinator.com/item?id=36673224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto"> 
    
  <p><a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/7d08b7e3dec312341d94a4aff5add03658295489c509aa6a7af1d911a7b93e33/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e7376673f636f6c6f723d334635314235267374796c653d666f722d7468652d6261646765266c6162656c3d4c6963656e7365266c6f676f436f6c6f723d303030303030266c6162656c436f6c6f723d656365636563" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/license-MIT-green.svg?color=3F51B5&amp;style=for-the-badge&amp;label=License&amp;logoColor=000000&amp;labelColor=ececec"></a>
  <a href="https://discord.gg/D8JsnBEuKb" rel="nofollow">
    <img src="https://camo.githubusercontent.com/9951ac4f9dbf9adbd35d470c4668d875f6ffa8769bdb3f97d5b353ec154f5dac/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3937393131363632333837393336383735352e7376673f6c6162656c3d446973636f7264266c6f676f3d446973636f7264267374796c653d666f722d7468652d6261646765266c6f676f436f6c6f723d303030303030266c6162656c436f6c6f723d656365636563" data-canonical-src="https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;logo=Discord&amp;style=for-the-badge&amp;logoColor=000000&amp;labelColor=ececec">
  </a></p></div>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/immich-app/immich/blob/main/design/immich-logo.svg"><img src="https://github.com/immich-app/immich/raw/main/design/immich-logo.svg" width="150" title="Login With Custom URL"></a>
</p>
<h3 tabindex="-1" dir="auto">Immich - High performance self-hosted photo and video backup solution</h3>
<br>
<a href="https://immich.app/" rel="nofollow">
<img src="https://github.com/immich-app/immich/raw/main/design/immich-screenshots.png" title="Main Screenshot">
</a>

<p dir="auto">
  <a href="https://github.com/immich-app/immich/blob/main/README_zh_CN.md">中文</a>
  <a href="https://github.com/immich-app/immich/blob/main/README_tr_TR.md">Türkçe</a>
  <a href="https://github.com/immich-app/immich/blob/main/README_ca_ES.md">Català</a>
</p>
<h2 tabindex="-1" dir="auto">Disclaimer</h2>
<ul dir="auto">
<li><g-emoji alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> The project is under <strong>very active</strong> development.</li>
<li><g-emoji alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> Expect bugs and breaking changes.</li>
<li><g-emoji alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> <strong>Do not use the app as the only way to store your photos and videos!</strong></li>
</ul>
<h2 tabindex="-1" dir="auto">Content</h2>
<ul dir="auto">
<li><a href="https://immich.app/docs" rel="nofollow">Official Documentation</a></li>
<li><a href="https://github.com/orgs/immich-app/projects/1">Roadmap</a></li>
<li><a href="#demo">Demo</a></li>
<li><a href="#features">Features</a></li>
<li><a href="https://immich.app/docs/overview/introduction" rel="nofollow">Introduction</a></li>
<li><a href="https://immich.app/docs/install/requirements" rel="nofollow">Installation</a></li>
<li><a href="https://immich.app/docs/overview/support-the-project" rel="nofollow">Contribution Guidelines</a></li>
<li><a href="#support-the-project">Support The Project</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">You can find the main documentation, including installation guides, at <a href="https://immich.app/" rel="nofollow">https://immich.app/</a>.</p>
<h2 tabindex="-1" dir="auto">Demo</h2>
<p dir="auto">You can access the web demo at <a href="https://demo.immich.app/" rel="nofollow">https://demo.immich.app</a></p>
<p dir="auto">For the mobile app, you can use <code>https://demo.immich.app/api</code> for the <code>Server Endpoint URL</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="The credential
email: demo@immich.app
password: demo"><pre>The credential
email: demo@immich.app
password: demo</pre></div>
<div data-snippet-clipboard-copy-content="Spec: Free-tier Oracle VM - Amsterdam - 2.4Ghz quad-core ARM64 CPU, 24GB RAM"><pre><code>Spec: Free-tier Oracle VM - Amsterdam - 2.4Ghz quad-core ARM64 CPU, 24GB RAM
</code></pre></div>
<h2 tabindex="-1" dir="auto">Features</h2>
<table>
<thead>
<tr>
<th>Features</th>
<th>Mobile</th>
<th>Web</th>
</tr>
</thead>
<tbody>
<tr>
<td>Upload and view videos and photos</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Auto backup when the app is opened</td>
<td>Yes</td>
<td>N/A</td>
</tr>
<tr>
<td>Selective album(s) for backup</td>
<td>Yes</td>
<td>N/A</td>
</tr>
<tr>
<td>Download photos and videos to local device</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Multi-user support</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Album and Shared albums</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Scrubbable/draggable scrollbar</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Support raw formats</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Metadata view (EXIF, map)</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Search by metadata, objects, faces, and CLIP</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Administrative functions (user management)</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Background backup</td>
<td>Yes</td>
<td>N/A</td>
</tr>
<tr>
<td>Virtual scroll</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>OAuth support</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>API Keys</td>
<td>N/A</td>
<td>Yes</td>
</tr>
<tr>
<td>LivePhoto backup and playback</td>
<td>iOS</td>
<td>Yes</td>
</tr>
<tr>
<td>User-defined storage structure</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Public Sharing</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Archive and Favorites</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Global Map</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Partner Sharing</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Facial recognition and clustering</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Memories (x years ago)</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Offline support</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Read-only gallery</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Support the project</h2>
<p dir="auto">I've committed to this project, and I will not stop. I will keep updating the docs, adding new features, and fixing bugs. But I can't do it alone. So I need your help to give me additional motivation to keep going.</p>
<p dir="auto">As our hosts in the <a href="https://selfhosted.show/79?t=1418" rel="nofollow">selfhosted.show - In the episode 'The-organization-must-not-be-name is a Hostile Actor'</a> said, this is a massive undertaking of what the team and I are doing. And I would love to someday be able to do this full-time, and I am asking for your help to make that happen.</p>
<p dir="auto">If you feel like this is the right cause and the app is something you are seeing yourself using for a long time, please consider supporting the project with the option below.</p>
<h2 tabindex="-1" dir="auto">Donation</h2>
<ul dir="auto">
<li><a href="https://github.com/sponsors/alextran1502">Monthly donation</a> via GitHub Sponsors</li>
<li><a href="https://github.com/sponsors/alextran1502?frequency=one-time&amp;sponsor=alextran1502">One-time donation</a> via GitHub Sponsors</li>
<li><a href="https://liberapay.com/alex.tran1502/" rel="nofollow">Librepay</a></li>
<li><a href="https://www.buymeacoffee.com/altran1502" rel="nofollow">buymeacoffee</a></li>
<li>Bitcoin: 1FvEp6P6NM8EZEkpGUFAN2LqJ1gxusNxZX</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gandi.net updates pricing, increases rates by up to 1000% (113 pts)]]></title>
            <link>https://chatting.neocities.org/posts/2023-gandi-pricing</link>
            <guid>36673108</guid>
            <pubDate>Mon, 10 Jul 2023 21:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chatting.neocities.org/posts/2023-gandi-pricing">https://chatting.neocities.org/posts/2023-gandi-pricing</a>, See on <a href="https://news.ycombinator.com/item?id=36673108">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h5 id="july-10-2023">July 10, 2023</h5>
<hr>
<p>According to <a href="https://chatting.neocities.org/documents/gandi-pricing-email.html">an email</a> sent to its customers in mid-June, Gandi.net, a major European domain name registration and web hosting company, is <a href="https://gandi.link/eur-prices2023">increasing</a> prices across its entire suite of products.</p>
<p>For domain names, the new prices will usually amount to a 25 to 50% increase, depending on the extension. For example, .com domain prices will jump by 34%, .net by 45%, .org by 32%, etc.</p>
<p>A much steeper price hike is awaiting web hosting customers, who will see their costs almost double in some cases. In particular, the Advanced web hosting plan will be raised from €8.25/month to €15.00/month, an 82% surge.</p>
<p>But by far the most egregious is the email service.</p>
<p>Gandi had already started to inform customers on their intention to <a href="https://news.ycombinator.com/item?id=35080777">discontinue</a> their offer of 2 free mailboxes included with every domain name registration, including for users who had pre-paid for multiple years.</p>
<p>Now, Gandi will raise the prices of the Standard mailbox plan from €0.35/month to €3.99/month per mailbox, <b>a 1040% increase</b>. The Premium plan will go from €1.75/month to €5.99/month, a 242% increase.</p>
<p>In its announcement, Gandi appears to justify these price increases by describing the product as “new and improved”, citing increased storage (<i>editor’s note: this does not apply to Premium plan customers</i>) and other nebulous commitments, such as “better anti-spam protection”, and “stronger security”.</p>
<p>The price hikes will come into effect on July 13.</p>
<p><b>It is unclear how with the action of dropping extreme price increases on customers, backed by dubious justifications, and with barely a month’s notice can be reconciled with Gandi’s famous and long-standing <a href="https://www.gandi.net/en/no-bullshit">“No Bullshit” policy</a>.</b></p>
<p>At the time of writing, Gandi has still not updated its website (apart from the <a href="https://www.gandi.net/en/domain/email">email hosting page</a>, which does feature the new prices) to inform potential new customers of the upcoming changes.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Stripe is holding 50% for 9 month (105 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36673091</link>
            <guid>36673091</guid>
            <pubDate>Mon, 10 Jul 2023 21:18:53 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36673091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36674721"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36674721" href="https://news.ycombinator.com/vote?id=36674721&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Some staff members from Stripe already replied that they are looking into this. But if you take a look at reviews on Trustpilot this (withholding funds) seems to be a very common complain, which is terrifying.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36674461"><td></td></tr>
                      <tr id="36674703"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36674703" href="https://news.ycombinator.com/vote?id=36674703&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Every time one of these Stripe posts shows up, I always wonder what'll happen when Edwin retires or moves on.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36674963"><td></td></tr>
                  <tr id="36675493"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36675493" href="https://news.ycombinator.com/vote?id=36675493&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>What is the alternative to stripe? I was going to set it up for a new service in making but with all these posts I'm not so sure.<p>A quick google brings up paddle, is that going to have the same issues?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36675243"><td></td></tr>
            <tr id="36675031"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36675031" href="https://news.ycombinator.com/vote?id=36675031&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>9 month is long. I thought credit card companies only hold for 3 months at the most so not sure why Stripe needs it 3x longer</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675695"><td></td></tr>
                  <tr id="36675561"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36675561" href="https://news.ycombinator.com/vote?id=36675561&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Stop using Stripe, this is what you sign up for when you use them. PayPal is not much better. Use Adyen, or a processor that doesn't have to squeeze every dollar out of the transaction like Google Payments.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675789"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36675789" href="https://news.ycombinator.com/vote?id=36675789&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>This is a regulatory problem not a business problem. Payment processors need to understand a client's risk profile and what business they do in order to prevent money laundering, and in practice, regulators only care about clients that have a certain volume.<p>Paypal, Stripe, and any other major payment processor have developed a strategy of letting users use the service with no restrictions until they hit that volume then they begin doing things like this.</p><p>Ultimately, this is caused by regulation and needs to be fixed by regulation, but it won't because practices like this are extremely lucrative.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36674629"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36674629" href="https://news.ycombinator.com/vote?id=36674629&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Thank you for submitting your support request through the Stripe back channel support network.  Your ticket will be reviewed by nobody, unless you happen to be extremely lucky and win the Hacker News lottery.  Best of luck!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675273"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36675273" href="https://news.ycombinator.com/vote?id=36675273&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>I'm sorry your request has been denied by some schmuck you slighted in 3rd year of uni who works at stripe.<p>Too bad there is no incentive for companies to put in place adequate volume to deal with necessary customer support.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36675487"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36675487" href="https://news.ycombinator.com/vote?id=36675487&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>The shareholders have proclaimed that such a strategy is illegal due to fiduciary duty /s</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36676060"><td></td></tr>
            <tr id="36675998"><td></td></tr>
            <tr id="36673940"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36673940" href="https://news.ycombinator.com/vote?id=36673940&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>There are a bunch of factors—we look at your refund and chargeback rates, then your revenue and how much you have in your Stripe balance. For macro factors, the card networks may also sense an uptick in refund requests depending on the product/service you're selling.<p>That said, I see your email into our support team and we're taking another look at this now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36674267"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36674267" href="https://news.ycombinator.com/vote?id=36674267&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>It's a bit horrifying it takes a disgruntled HN post and <i>the pure chance</i> you happened across it. It's also discomforting how comfortable Stripe employees like yourself think holding 50% of someone's earning for any amount of time is acceptable. I really don't care if Stripe is HN's baby, this is awful customer service and gives me great pause in recommending or using Stripe.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36674329"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36674329" href="https://news.ycombinator.com/vote?id=36674329&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>I feel like these posts should be disallowed. Seems like Stripe is using HN as a free help forum, and it's customers have accepted that this is the place to go when you need to talk to a human. I don't think HN should encourage it, and I don't know why we all play along. I've seen a solid handful or two of these posts, and most of the time users aren't looking for discussion, only enough attention to get the Stripe team to act. My opinion only, obviously I sympathize with OP whose just trying to get their money and this seems to be the tried and true way to get a response, but I definitely don't think it adds anything positive to the site other than a recurring warning to other would-be Stripe customers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675014"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36675014" href="https://news.ycombinator.com/vote?id=36675014&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>&gt; other than a recurring warning to other would-be Stripe customers<p>that seems like an exceptionally high-value positive in a site with a large number of users who need payment services.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36674498"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36674498" href="https://news.ycombinator.com/vote?id=36674498&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>HN should encourage it, because startup founders read HN. They should think twice risking their business existence, after seeing this benevolent approach.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36674557"><td></td></tr>
                <tr id="36675455"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36675455" href="https://news.ycombinator.com/vote?id=36675455&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>Sunlight only works reasonably well for waterborne pathogens, and only when you've got time.<p>As with disinfecting anything, and especially for societal issues, we need more than sunlight alone.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36674851"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36674851" href="https://news.ycombinator.com/vote?id=36674851&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>Tell that to Edward Snowden, Julian Assange, or one of the billions of working families all over the world that <i>everyone</i> knows is getting f*cked over on a constant basis.<p>Sunlight is not a disinfectant. Better to try gasoline.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36675244"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36675244" href="https://news.ycombinator.com/vote?id=36675244&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>These types of companies are often frauds (anything involving large amounts charged for travel, or housing of some sort). A bunch of <i>big</i> charges comes in, and then months later there are massive chargebacks and the company in question no longer exists. Stripe is left holding the bag. Their only option with these large charges for services to be delivered in the future is to not release funds until they are quite certain there won't be a charge back.<p>For every instance of what appears to be bad behavior by a payments company, consider the angle of the fraudster. They are really screwing things up for everybody.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36675298"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36675298" href="https://news.ycombinator.com/vote?id=36675298&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>In a working payment system, the scenario where someone initiates a valid dispute nine months after the fact would be extremely rare: it would be limited to a few types of physical card theft where the card owner is unable to report the card missing for some relatively unusual reason. We just don’t have a working payment system, so unfortunately this stuff is incredibly common and everyone has to suffer because of it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675346"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36675346" href="https://news.ycombinator.com/vote?id=36675346&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>There are genuine cases (travel and lodging are the obvious ones) where people tend to pay for things months in advance. I don't see it going away. If you can come up with a cheap, effective, convenient payment method to cover these things, you are on a winner. I don't think it's possible because the time horizon creates risk, there is no avoiding it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36674505"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36674505" href="https://news.ycombinator.com/vote?id=36674505&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>The alternative is likely not being able to work with the business at all due to their risk profile and chargeback rates.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36675032"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36675032" href="https://news.ycombinator.com/vote?id=36675032&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>That seems... better? At least you know what you're in for (ie. you can only take crypto or go with a risk-taking payment processor that has an explicit net 120 payout schedule), so you can plan your business around it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36674159"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36674159" href="https://news.ycombinator.com/vote?id=36674159&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>As always, why bother having real support when you can instead wait for paying customer to bitch publicly on HN?<p>Sickening.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36674289"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36674289" href="https://news.ycombinator.com/vote?id=36674289&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Sickening is hardly the word for a comms lead of Stripe being the first reply to a post about a customers issue, complete with some informative context and saying they will double check the issue.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36674376"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36674376" href="https://news.ycombinator.com/vote?id=36674376&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>Not the place for many reasons. As an example this discussion should not be publicly indexable whenever a customer Googles this same problem in the future.<p>Basic Marketing and Customer Care Management.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36674378"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36674378" href="https://news.ycombinator.com/vote?id=36674378&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Are you new here? This website seems to be the only way to get human help from stripe. THAT is sickening.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36674531"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36674531" href="https://news.ycombinator.com/vote?id=36674531&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>What would you say the percentage of the total support requests that Stripe receives per day is compared to issues raised on HN?</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="36675291"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36675291" href="https://news.ycombinator.com/vote?id=36675291&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>When you hold on to someone's money for an extremely long time, do you earn any interest on that money?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36676021"><td></td></tr>
                  <tr id="36674192"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36674192" href="https://news.ycombinator.com/vote?id=36674192&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>Just wanted to say I appreciate seeing the responsiveness here. First comment on the thread even. Always better if it doesn’t reach this point, but it’s nice to know you can get a human’s attention one way or another.<p>Hoping to @edwinwee will share the outcome for other businesses who might need to evaluate Stripe.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36674562"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36674562" href="https://news.ycombinator.com/vote?id=36674562&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>You know what would be better? Maybe a support email? Or this crazy thing called a 1-800-number? The fact that Stripe de facto uses HN as their support forum and that people are lauding them for it is pretty laughable.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36674386"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36674386" href="https://news.ycombinator.com/vote?id=36674386&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><br><div>
                  <p><span>Search this website. Outcome is always the same: something resolved just this once. No procedural changes made. Stripe remains unreachable unless you get enough upvotes on HN</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36674849"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36674849" href="https://news.ycombinator.com/vote?id=36674849&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>The outcome isn't always the same.<p>It's 50/50:</p><p>- The poster was doing something shady and upon further investigation it turns out the situation is warranted</p><p>- The poster was indeed let down by a broken support system and Stripe staff chimes in to save the day
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36675253"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36675253" href="https://news.ycombinator.com/vote?id=36675253&amp;how=up&amp;goto=item%3Fid%3D36673091"></a></center>    </td><td><p><span>The outcome is not always, or perhaps even often, the same.<p>The last time I paid attention to one of these complaints, someone was using stripe to sell cellphone accessories (and yes, at least on my Stripe application, they asked what I was selling.)</p><p>After selling accessories for a while, he then used it to sell a minivan, and had a tantrum when Stripe -- quite reasonably -- said this flags all the flags, and Stripe was going to hold onto the money until they were sure things were kosher.</p><p>Getting dollars before multiple months post transaction basically leaves someone holding a bag of risk, and if you act shady AF, you can't be surprised if Stripe declines to hold that bag of risk for you.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A hash array-mapped trie implementation in C (103 pts)]]></title>
            <link>https://github.com/mkirchner/hamt</link>
            <guid>36672957</guid>
            <pubDate>Mon, 10 Jul 2023 21:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mkirchner/hamt">https://github.com/mkirchner/hamt</a>, See on <a href="https://news.ycombinator.com/item?id=36672957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">libhamt</h2>
<p dir="auto">A hash array-mapped trie (HAMT) implementation in C99. A HAMT is a data
structure that can be used to efficiently implement
<a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="nofollow"><em>persistent</em></a> associative arrays (aka maps,
dicts) and sets, see the <a href="#introduction">Introduction</a>. The implementation here
loosely follows Bagwell's 2000 paper<a href="https://lampwww.epfl.ch/papers/idealhashtrees.pdf" rel="nofollow">[1]</a>, with a focus on
code clarity.</p>
<p dir="auto">What prompted the somewhat detailed writeup was the realization that there is
not a lot of in-depth documentation for HAMTs beyond the original Bagwell
paper[<a href="https://lampwww.epfl.ch/papers/idealhashtrees.pdf" rel="nofollow">1</a>]. Some of the more helpful posts are <a href="http://blog.higher-order.net/2009/09/08/understanding-clojures-persistenthashmap-deftwice.html" rel="nofollow">Karl Krukow's
intro to Clojure's <code>PersistentHashMap</code></a>, <a href="https://github.com/chaelim/HAMT">C. S. Lim's
C++ template implementation</a>, <a href="https://blog.acolyer.org/2015/11/27/hamt/" rel="nofollow">Adrian Coyler's morning paper
post</a> and the original <a href="https://michael.steindorfer.name/publications/oopsla15.pdf" rel="nofollow">Steindoerfer/Vinju compressed HAMT
article it summarizes</a>. The rest mostly seems to be
all bits and pieces and this document is an attempt to (partially) improve that
situation.</p>
<p dir="auto"><em>FIXME: Complete docs (removal, persistence, path copying)</em></p>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">To build the library and run the tests:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:mkirchner/hamt.git
$ cd hamt
$ make
$ make test"><pre>$ git clone git@github.com:mkirchner/hamt.git
$ <span>cd</span> hamt
$ make
$ make <span>test</span></pre></div>
<p dir="auto">In order to use <code>libhamt</code> in your own projects, copy <code>include/hamt.h</code> and
<code>src/hamt.c</code> in your own source tree and build from there.</p>
<h3 tabindex="-1" dir="auto">Benchmarks</h3>
<p dir="auto">For basic performance comparison with AVL and red-black trees (from <code>libavl</code>)
and the HashTree from GLib, see <a href="https://github.com/mkirchner/hamt-bench">the benchmarking repo</a>.</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">A <em>hash array mapped trie (HAMT)</em> is a data structure that can be used to
implement <a href="https://en.wikipedia.org/wiki/Associative_array" rel="nofollow">associative arrays</a> (aka maps) and
<a href="https://en.wikipedia.org/wiki/Set_(abstract_data_type)" rel="nofollow">sets</a>.</p>
<p dir="auto">Structurally, HAMTs are <a href="https://en.wikipedia.org/wiki/Hash_tree_(persistent_data_structure)" rel="nofollow">hash trees</a> that combine favorable
characteristics of <a href="https://en.wikipedia.org/wiki/Hash_table" rel="nofollow">hash tables</a> and array mapped
<a href="https://en.wikipedia.org/wiki/Trie" rel="nofollow">tries</a>, namely almost hash table-like time complexity
guarantees<a href="https://lampwww.epfl.ch/papers/idealhashtrees.pdf" rel="nofollow">[1]</a> (O(log<sub>32</sub>n)) and economic use of memory.</p>
<p dir="auto">An additional benefit, and a key motivation for the work presented here, is that
augmentation of HAMTs with path copying and garbage collection allows for a
straightforward and efficient implementation of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="nofollow">persistent</a>
versions of maps and sets.</p>
<p dir="auto">The remaining documentation starts with a description of the <code>libhamt</code> API and
two examples that demonstrate the use of a HAMT as an ephemeral and persistent
data structure, respectively. It then details the implementation: starting from
the foundational data structures and the helper code required for hash
exhaustion and table management, we cover search, insertion, removal, and
iterators. The final implementation section introduces path copying and explains
the changes required to support persistent insert and remove operations. It
closes with an outlook and an appendix.</p>
<h2 tabindex="-1" dir="auto">API</h2>
<h2 tabindex="-1" dir="auto">HAMT lifecycle</h2>
<p dir="auto">The core data type exported in the <code>libhamt</code> interface is <code>struct hamt</code>. In order to
create a <code>struct hamt</code> instance, one must call <code>hamt_create()</code>, which requires a
hash function of type <code>hamt_key_hash_fn</code> to hash keys, a comparison function of
type <code>hamt_cmp_fn</code> to compare keys, and a pointer to a <code>hamt_allocator</code> instance.
<code>hamt_delete()</code> deletes <code>struct hamt</code> instances that were created with <code>hamt_create()</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* The libhamt core data structure is a handle to a hash array-mapped trie */

/* Function signature definitions for key comparison and hashing */
typedef int (*hamt_cmp_fn)(const void *lhs, const void *rhs);
typedef uint32_t (*hamt_key_hash_fn)(const void *key, const size_t gen);

/* API functions for lifecycle management */
struct hamt *hamt_create(hamt_key_hash_fn key_hash, hamt_cmp_fn key_cmp, struct hamt_allocator *ator);
void hamt_delete(struct hamt *);"><pre><span>/* The libhamt core data structure is a handle to a hash array-mapped trie */</span>

<span>/* Function signature definitions for key comparison and hashing */</span>
<span>typedef</span> <span>int</span> (<span>*</span><span>hamt_cmp_fn</span>)(<span>const</span> <span>void</span> <span>*</span><span>lhs</span>, <span>const</span> <span>void</span> <span>*</span><span>rhs</span>);
<span>typedef</span> <span>uint32_t</span> (<span>*</span><span>hamt_key_hash_fn</span>)(<span>const</span> <span>void</span> <span>*</span><span>key</span>, <span>const</span> <span>size_t</span> <span>gen</span>);

<span>/* API functions for lifecycle management */</span>
<span>struct</span> <span>hamt</span> <span>*</span><span>hamt_create</span>(<span>hamt_key_hash_fn</span> <span>key_hash</span>, <span>hamt_cmp_fn</span> <span>key_cmp</span>, <span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>);
<span>void</span> <span>hamt_delete</span>(<span>struct</span> <span>hamt</span> <span>*</span>);</pre></div>
<p dir="auto">The <code>hamt_key_hash_fn</code> takes a <code>key</code> and a generation <code>gen</code>. The expectation is
that the supplied hash function returns different hashes for the same key but
different generations. Depending on the choice of hash function this can be
implemented using <code>gen</code> as a seed or modifying a copy of <code>key</code> on the fly.
See the <a href="#examples">examples</a> section for a <code>murmur3</code>-based implementation and
the <a href="#hashing">hashing</a> section for more information on suitable hash functions.</p>
<h3 tabindex="-1" dir="auto">Memory management</h3>
<p dir="auto"><code>libhamt</code> exports its internal memory management API through the <code>hamt_allocator</code>
struct. The struct specifies the functions that the HAMT implementation uses to
allocate, re-allocate and deallocate system memory. The API provides a default
<code>hamt_allocator_default</code> which refers to the standard <code>malloc()</code>, <code>realloc()</code>
and <code>free()</code> functions.</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct hamt_allocator {
    void *(*malloc)(const size_t size);
    void *(*realloc)(void *chunk, const size_t size);
    void (*free)(void *chunk);
};

extern struct hamt_allocator hamt_allocator_default;"><pre><span>struct</span> <span>hamt_allocator</span> {
    <span>void</span> <span>*</span>(<span>*</span><span>malloc</span>)(<span>const</span> <span>size_t</span> <span>size</span>);
    <span>void</span> <span>*</span>(<span>*</span><span>realloc</span>)(<span>void</span> <span>*</span><span>chunk</span>, <span>const</span> <span>size_t</span> <span>size</span>);
    <span>void</span> (<span>*</span><span>free</span>)(<span>void</span> <span>*</span><span>chunk</span>);
};

<span>extern</span> <span>struct</span> <span>hamt_allocator</span> <span>hamt_allocator_default</span>;</pre></div>
<p dir="auto">Exporting the <code>libhamt</code> memory management API enables library clients to make
use of alternate memory management solutions, most notably of garbage collection
solutions (e.g. the <a href="https://www.hboehm.info/gc/" rel="nofollow">Boehm-Demers-Weiser GC</a>) which are required when
using the HAMT as a persistent data structure (see the <a href="#example-2-garbage-collected-persistent-hamts">structural sharing
example</a>).</p>
<h2 tabindex="-1" dir="auto">Query</h2>
<div dir="auto" data-snippet-clipboard-copy-content="size_t hamt_size(const struct hamt *trie);
const void *hamt_get(const struct hamt *trie, void *key);"><pre><span>size_t</span> <span>hamt_size</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>);
<span>const</span> <span>void</span> <span>*</span><span>hamt_get</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>);</pre></div>
<p dir="auto">The <code>hamt_size()</code> function returns the size of the HAMT in O(1). Querying the
HAMT (i.e. searching a key) is done with <code>hamt_get()</code> which takes a pointer to a
key and returns a result in O(log<sub>32</sub> n) - or <code>NULL</code> if the key does
not exist in the HAMT.</p>
<h3 tabindex="-1" dir="auto">Iterators</h3>
<p dir="auto">The API also provides key/value pair access through the <code>hamt_iterator</code> struct.</p>
<div dir="auto" data-snippet-clipboard-copy-content="size_t hamt_size(const struct hamt *trie);
const void *hamt_get(const struct hamt *trie, void *key);"><pre><span>size_t</span> <span>hamt_size</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>);
<span>const</span> <span>void</span> <span>*</span><span>hamt_get</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>);</pre></div>
<p dir="auto">Iterators are tied to a specific HAMT and are created using the
<code>hamt_it_create()</code> function, passing the HAMT instance the iterator should refer
to. Iterators can be advanced with the <code>hamt_it_next()</code> function and as long as
<code>hamt_it_valid()</code> returns <code>true</code>, the <code>hamt_it_get_key()</code> and
<code>hamt_it_get_value()</code> functions will return the pointers to the current
key/value pair. In order to delete an existing and/or exhausted iterator, call
<code>hamt_it_delete()</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef struct hamt_iterator_impl *hamt_iterator;

hamt_iterator hamt_it_create(const struct hamt *trie);
void hamt_it_delete(hamt_iterator it);
bool hamt_it_valid(hamt_iterator it);
hamt_iterator hamt_it_next(hamt_iterator it);
const void *hamt_it_get_key(hamt_iterator it);
const void *hamt_it_get_value(hamt_iterator it);"><pre><span>typedef</span> <span>struct</span> <span>hamt_iterator_impl</span> <span>*</span><span>hamt_iterator</span>;

<span>hamt_iterator</span> <span>hamt_it_create</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>);
<span>void</span> <span>hamt_it_delete</span>(<span>hamt_iterator</span> <span>it</span>);
<span>bool</span> <span>hamt_it_valid</span>(<span>hamt_iterator</span> <span>it</span>);
<span>hamt_iterator</span> <span>hamt_it_next</span>(<span>hamt_iterator</span> <span>it</span>);
<span>const</span> <span>void</span> <span>*</span><span>hamt_it_get_key</span>(<span>hamt_iterator</span> <span>it</span>);
<span>const</span> <span>void</span> <span>*</span><span>hamt_it_get_value</span>(<span>hamt_iterator</span> <span>it</span>);</pre></div>
<p dir="auto">Iterators maintain state about their traversal path and changes to the HAMT
that an iterator refers to implicitly invalidate the iteration (i.e. undefined
behavior).</p>
<p dir="auto">The order in which iterators return the key value pairs is fully defined by
the structure of the trie, which, in turn, is completely defined by the choice
of hash function and (where applicable) seed.</p>
<h2 tabindex="-1" dir="auto">Insert &amp; Remove</h2>
<p dir="auto"><code>libhamt</code> supports ephemeral and
<a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="nofollow">persistent</a> (aka not ephemeral) HAMTs through two different interfaces:
<code>hamt_set()</code> and <code>hamt_remove()</code> for ephemeral use, and their <code>p</code>-versions
<code>hamt_pset()</code> and <code>hamt_premove()</code> for persistent use.</p>
<h3 tabindex="-1" dir="auto">Ephemeral modification</h3>
<div dir="auto" data-snippet-clipboard-copy-content="const void *hamt_set(struct hamt *trie, void *key, void *value);
void *hamt_remove(struct hamt *trie, void *key);"><pre><span>const</span> <span>void</span> <span>*</span><span>hamt_set</span>(<span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>);
<span>void</span> <span>*</span><span>hamt_remove</span>(<span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>);</pre></div>
<p dir="auto"><code>hamt_set()</code> takes a pair of <code>key</code> and <code>value</code> pointers and adds the pair to the HAMT,
returning a pointer to the <code>value</code>. If the <code>key</code> already exists, <code>hamt_set()</code>
updates the pointer to the <code>value</code>.</p>
<p dir="auto"><code>hamt_remove()</code> takes a <code>key</code> and removes the key/value pair with the
respective <code>key</code> from the HAMT, returning a pointer to the <code>value</code> that was
just removed. If the <code>key</code> does not exist, <code>hamt_remove()</code> returns <code>NULL</code>.</p>
<h3 tabindex="-1" dir="auto">Persistent HAMTs</h3>
<p dir="auto">The semantics of persistent HAMTs are different from their ephemeral
counterparts: since every modification creates a new version of a HAMT, the
modificiation functions return a new HAMT. Modification of a persistent HAMT
therefore requires a reassignment idiom if the goal is modification only:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const struct hamt *h = hamt_create(...)
...
/* Set a value and drop the reference to the old HAMT; the GC
 * will take care of cleaning up remaining unreachable allocations.
 */
h = hamt_pset(h, some_key, some_value);
..."><pre><span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>h</span> <span>=</span> <span>hamt_create</span>(...)
...
<span>/* Set a value and drop the reference to the old HAMT; the GC</span>
<span> * will take care of cleaning up remaining unreachable allocations.</span>
<span> */</span>
<span>h</span> <span>=</span> <span>hamt_pset</span>(<span>h</span>, <span>some_key</span>, <span>some_value</span>);
...</pre></div>
<p dir="auto">This seems wasteful at first glance but the respective functions implement structural
sharing such that the overhead is limited to <em>~log<sub>32</sub>(N)</em> nodes (where <em>N</em> is the
number of nodes in the graph).</p>
<div dir="auto" data-snippet-clipboard-copy-content="const struct hamt *hamt_pset(const struct hamt *trie, void *key, void *value);
const struct hamt *hamt_premove(const struct hamt *trie, void *key);"><pre><span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>hamt_pset</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>);
<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>hamt_premove</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>);</pre></div>
<p dir="auto"><code>hamt_pset()</code> inserts or updates the <code>key</code> with <code>value</code> and returns an opaque
handle to the new HAMT. The new HAMT is guaranteed to contain the new
key/value pair.</p>
<p dir="auto"><code>hamt_premove()</code> attempts to remove the value with the key <code>key</code>. It is <em>not</em>
an error if the key does not exist; the new HAMT is guaranteed to not contain
the key <code>key</code>.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<h3 tabindex="-1" dir="auto">Example 1: ephemeral HAMT w/ standard allocation</h3>
<div dir="auto" data-snippet-clipboard-copy-content="#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include &quot;hamt.h&quot;
#include &quot;murmur3.h&quot;


static uint32_t hash_string(const void *key, const size_t gen)
{
    return murmur3_32((uint8_t *)key, strlen((const char *)key), gen);
}

int main(int argn, char *argv[])
{
    enum { N = 5; };
    struct {
        char *country;
        char *capital;
    } cities[N] = {
        {&quot;Germany&quot;, &quot;Berlin&quot;},
        {&quot;Spain&quot;, &quot;Madrid&quot;},
        {&quot;Italy&quot;, &quot;Rome&quot;},
        {&quot;France&quot;, &quot;Paris&quot;},
        {&quot;Romania&quot;, &quot;Bucharest&quot;}
        /* ... */
    };

    struct hamt *t;

    /* create table */
    t = hamt_create(hash_string, strcmp, &amp;hamt_allocator_default);
    /* load table */
    for (size_t i = 0; i < N; i++) {
        hamt_set(t, cities[i].country, cities[i].capital);
    }

    /* query table */
    for (size_t i = 0; i < N; i++) {
        printf(&quot;%s has capital %s\n&quot;, cities[i].country,
                                      hamt_get(t, cities[i].country));
    }
    /* cleanup */
    hamt_delete(t);
    return 0;
}"><pre><span>#include</span> <span>&lt;stdint.h&gt;</span>
<span>#include</span> <span>&lt;stdio.h&gt;</span>
<span>#include</span> <span>&lt;stdlib.h&gt;</span>
<span>#include</span> <span>&lt;string.h&gt;</span>

<span>#include</span> <span>"hamt.h"</span>
<span>#include</span> <span>"murmur3.h"</span>


<span>static</span> <span>uint32_t</span> <span>hash_string</span>(<span>const</span> <span>void</span> <span>*</span><span>key</span>, <span>const</span> <span>size_t</span> <span>gen</span>)
{
    <span>return</span> <span>murmur3_32</span>((<span>uint8_t</span> <span>*</span>)<span>key</span>, <span>strlen</span>((<span>const</span> <span>char</span> <span>*</span>)<span>key</span>), <span>gen</span>);
}

<span>int</span> <span>main</span>(<span>int</span> <span>argn</span>, <span>char</span> <span>*</span><span>argv</span>[])
{
    <span>enum</span> { <span>N</span> <span>=</span> <span>5</span>; };
    <span>struct</span> {
        <span>char</span> <span>*</span><span>country</span>;
        <span>char</span> <span>*</span><span>capital</span>;
    } <span>cities</span>[<span>N</span>] <span>=</span> {
        {<span>"Germany"</span>, <span>"Berlin"</span>},
        {<span>"Spain"</span>, <span>"Madrid"</span>},
        {<span>"Italy"</span>, <span>"Rome"</span>},
        {<span>"France"</span>, <span>"Paris"</span>},
        {<span>"Romania"</span>, <span>"Bucharest"</span>}
        <span>/* ... */</span>
    };

    <span>struct</span> <span>hamt</span> <span>*</span><span>t</span>;

    <span>/* create table */</span>
    <span>t</span> <span>=</span> <span>hamt_create</span>(<span>hash_string</span>, <span>strcmp</span>, <span>&amp;</span><span>hamt_allocator_default</span>);
    <span>/* load table */</span>
    <span>for</span> (<span>size_t</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>N</span>; <span>i</span><span>++</span>) {
        <span>hamt_set</span>(<span>t</span>, <span>cities</span>[<span>i</span>].<span>country</span>, <span>cities</span>[<span>i</span>].<span>capital</span>);
    }

    <span>/* query table */</span>
    <span>for</span> (<span>size_t</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>N</span>; <span>i</span><span>++</span>) {
        <span>printf</span>(<span>"%s has capital %s\n"</span>, <span>cities</span>[<span>i</span>].<span>country</span>,
                                      <span>hamt_get</span>(<span>t</span>, <span>cities</span>[<span>i</span>].<span>country</span>));
    }
    <span>/* cleanup */</span>
    <span>hamt_delete</span>(<span>t</span>);
    <span>return</span> <span>0</span>;
}</pre></div>
<h3 tabindex="-1" dir="auto">Example 2: Garbage-collected persistent HAMTs</h3>
<p dir="auto">The key to making use of structural sharing is to provide <code>libhamt</code> with a
<code>struct hamt_allocator</code> instance that implements garbage collection.</p>
<p dir="auto">The example below uses the the <a href="https://www.hboehm.info/gc/" rel="nofollow">Boehm-Demers-Weiser</a> GC. For
GC installation, compilation and linking instructions, please refer to the GC
documentation.</p>
<p dir="auto">In brief, the Boehm GC provides a <code>gc.h</code> include file and drop-in replacements
for the standard memory management functions, including <code>malloc</code>, <code>realloc</code>
and <code>free</code>.</p>
<p dir="auto">The following snippet illustrates the required changes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="...
#include &quot;gc.h&quot;  /* Boehm-Demers-Weiser GC */

...

inline void nop(void *_) { return; }

int main(int argc, char *argv[]) {
    ...
    /*
    Set up garbage collection. We set the function pointer for `free` to
    NULL to avoid explicit freeing of memory.
    */
    struct hamt_allocator gc_alloc = {GC_malloc, GC_realloc, nop};
    const struct hamt *t = hamt_create(hash_string, strcmp, &amp;gc_alloc);
    ...
}"><pre>...
<span>#include</span> <span>"gc.h"</span>  <span>/* Boehm-Demers-Weiser GC */</span>

...

<span>inline</span> <span>void</span> <span>nop</span>(<span>void</span> <span>*</span><span>_</span>) { <span>return</span>; }

<span>int</span> <span>main</span>(<span>int</span> <span>argc</span>, <span>char</span> <span>*</span><span>argv</span>[]) {
    ...
    <span>/*</span>
<span>    Set up garbage collection. We set the function pointer for `free` to</span>
<span>    NULL to avoid explicit freeing of memory.</span>
<span>    */</span>
    <span>struct</span> <span>hamt_allocator</span> <span>gc_alloc</span> <span>=</span> {<span>GC_malloc</span>, <span>GC_realloc</span>, <span>nop</span>};
    <span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>t</span> <span>=</span> <span>hamt_create</span>(<span>hash_string</span>, <span>strcmp</span>, <span>&amp;</span><span>gc_alloc</span>);
    ...
}</pre></div>
<p dir="auto">We set the <code>gc_alloc.free</code> function pointer to point to <code>nop()</code>, a
no-operation function. This is necessary to ensure that we rely on the garbage
collector. If we were to provide a pointer to <code>GC_free()</code> (i.e. GC's drop-in
replacement for the <code>free()</code> function), we would still implement explicit
deallocation, just with a different free function.</p>
<h3 tabindex="-1" dir="auto">Example 3: Iterators</h3>
<p dir="auto">The following snipped illustrates how to create, test, exhaust and dispose of
an iterator. We first create the iterator using <code>hamt_it_create()</code>, jump into
a <code>while</code> loop and advance the iterator using <code>hamt_it_next()</code> while the
iterator is valid. In every interation we print the current key/value pair to
<code>stdout</code>. Once we exit the loop, we clean up using <code>hamt_it_delete()</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="    ...
    struct hamt *t = hamt_create(hash_string, strcmp, &amp;hamt_allocator_default);

    /* load table */
    ...

    /* create iterator */
    hamt_iterator it = hamt_it_create(t);
    while (hamt_it_valid(it)) {
        printf(&quot;(%s, %s)\n&quot;, (char *)hamt_it_get_key(it),
                             (char *)hamt_it_get_value(it));
        hamt_it_next(it);
    }
    /* clean up */
    hamt_it_delete(it);

    ...
    hamt_delete(t);
    ..."><pre>    ...
    <span>struct</span> <span>hamt</span> <span>*</span><span>t</span> <span>=</span> <span>hamt_create</span>(<span>hash_string</span>, <span>strcmp</span>, <span>&amp;</span><span>hamt_allocator_default</span>);

    <span>/* load table */</span>
    ...

    <span>/* create iterator */</span>
    <span>hamt_iterator</span> <span>it</span> <span>=</span> <span>hamt_it_create</span>(<span>t</span>);
    <span>while</span> (<span>hamt_it_valid</span>(<span>it</span>)) {
        <span>printf</span>(<span>"(%s, %s)\n"</span>, (<span>char</span> <span>*</span>)<span>hamt_it_get_key</span>(<span>it</span>),
                             (<span>char</span> <span>*</span>)<span>hamt_it_get_value</span>(<span>it</span>));
        <span>hamt_it_next</span>(<span>it</span>);
    }
    <span>/* clean up */</span>
    <span>hamt_it_delete</span>(<span>it</span>);

    ...
    <span>hamt_delete</span>(<span>t</span>);
    ...</pre></div>
<p dir="auto">This concludes the description of the <code>libhamt</code> interface and we now move on
to detailed implementation notes.</p>
<h2 tabindex="-1" dir="auto">Implementation</h2>
<h2 tabindex="-1" dir="auto">Prelude: Setup</h2>
<h3 tabindex="-1" dir="auto">Project structure</h3>
<p dir="auto">The <code>hamt</code> source tree has the following structure:</p>
<div data-snippet-clipboard-copy-content="hamt/
  build/         Out-of-source build destination
  include/       Header files that are part of the interface
  src/           Source and header files
  test/          Test and utility headers &amp; sources
  Makefile"><pre><code>hamt/
  build/         Out-of-source build destination
  include/       Header files that are part of the interface
  src/           Source and header files
  test/          Test and utility headers &amp; sources
  Makefile
</code></pre></div>
<p dir="auto">Sources are organized in three folders: the <code>include</code> folder, for all header
files that are part of the public interface; the <code>src</code> folder, for the
actual implementation and private header files; and the <code>test</code> folder, for all
test code, including headers and sources for testing utilities (e.g. data
loading and benchmarking functions).</p>
<p dir="auto">The build process is governed by a single <code>Makefile</code> in the project root
directory.</p>
<h3 tabindex="-1" dir="auto">Programming Style</h3>
<h3 tabindex="-1" dir="auto">Building the project</h3>
<p dir="auto">To build the library and run the tests:</p>

<h2 tabindex="-1" dir="auto">Design</h2>
<h3 tabindex="-1" dir="auto">Introduction</h3>
<p dir="auto"><strong>Hash tables.</strong> A common and practical answer to efficient value retrieval
from a collection given a key is to "use a <em>hash table</em>".  This is good
advice. <em>Hash tables</em> provide insert, modification, and retrieval in amortized
constant average time, using space linear in the number of elements they
store.  They have been the subject of intensive research and
optimization and are part of <a href="https://www.amazon.com/Algorithms-4th-Robert-Sedgewick/dp/032157351X" rel="nofollow">every</a>
<a href="https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/ref=zg_bs_491298_1/147-2375898-2942653?pd_rd_i=0262033844&amp;psc=1" rel="nofollow">introductory</a> CS textbook.  Chances are that the
standard library of the languange at hand contains a readily available, tried
and tested implementation.</p>
<p dir="auto">For instance, <code>std::unordered_set</code> and <code>std::unordered_map</code> (and their
<code>*_multiset</code> cousins) are hash table implementations for C++ <sup id="user-content-ac_hash_table_cpp"><a href="#fn_hash_table_cpp">1</a></sup>; for C, multiple
<a href="https://en.wikipedia.org/wiki/C_standard_library" rel="nofollow">libc</a> implementations (e.g. <a href="https://en.wikipedia.org/wiki/Glibc" rel="nofollow">glibc</a>, <a href="https://www.musl-libc.org/" rel="nofollow">musl</a>,
<a href="https://en.wikipedia.org/wiki/C_standard_library#BSD_libc" rel="nofollow">BSD libc</a>) provide POSIX-compliant <code>hsearch</code> facilities,
GNOME's <a href="https://en.wikipedia.org/wiki/GLib" rel="nofollow">GLib</a>
and others provide <a href="https://gitlab.gnome.org/GNOME/glib/-/blob/main/glib/ghash.c" rel="nofollow">hash table</a> implementations<sup id="user-content-ac_hash_table_c"><a href="#fn_hash_table_c">2</a></sup>. Python has the <code>dict</code> type
for associative arrays which <a href="https://stackoverflow.com/a/9022835" rel="nofollow">is implemented as a hash
table</a><sup id="user-content-ac_hash_table_python"><a href="#fn_hash_table_python">3</a></sup>.  Java has
<code>Hashtable</code>, <code>HashMap</code>, and <code>HashSet</code> <sup id="user-content-ac_hash_table_java"><a href="#fn_hash_table_java">4</a></sup> and JavaScript has
<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map" rel="nofollow"><code>Map</code></a>.</p>
<p dir="auto">One property of the classical hash table implementations is that they do not
provide support for <em>persistence</em> (in the sense of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="nofollow">persistent data
structures</a>, not persistent storage). They are a
<a href="https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/ValueOfValues.md">place-oriented</a> solution to associative storage and
make destructive modifications to the data structure when the data changes
(note that this is independent of any particular conflict resolution and
capacity maintenance strategies).</p>
<p dir="auto">Persistent associative containers require a different approach.</p>
<p dir="auto"><strong>Persistent data structures.</strong> <em>(Full) persistence</em> is the property of a data
structure to always preserve (all) previous versions if itself under
modification. The property is related to
<a href="https://en.wikipedia.org/wiki/Immutable_object" rel="nofollow">immutability</a>: from the perspective of the client,
every update yields a new copy, making instances practically immutable. This
is a huge conceptual change: if data structures are immutable, functions using
these data structures are pure (i.e. side effect-free). That in turn enables
<a href="https://en.wikipedia.org/wiki/Value_semantics" rel="nofollow">value semantics</a>, <a href="https://en.wikipedia.org/wiki/Referential_transparency" rel="nofollow">referential
transparency</a>, and, consequently, substantial
reduction in programming complexity when dealing with paralellism and
synchronization (see e.g. Rich Hickey's presentations on <a href="https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/ValueOfValues.md"><em>The Value of
Values</em></a> and <a href="https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/AreWeThereYet.md"><em>Are We There
Yet?</em></a>).</p>
<p dir="auto">The catch is that classical hash tables set a high bar in terms of time and
space performance characteristics, and persistent data structures need to
approximate that bar.</p>
<p dir="auto"><strong>Efficient persistence.</strong> Persistent associative data structures need to
minimize the memory overhead introduced by value
semantics (i.e. returning copies as opposed to modified originals) and, at
the same time, provide practically average constant time insert, retrieve and
delete capabilities to minimize the performance gap to classical hash tables.</p>
<p dir="auto">It turns out that the data structure of choice to tackle these challenges is a
<em>tree</em>. Trees support efficient <a href="https://en.wikipedia.org/wiki/Persistent_data_structure#Trees" rel="nofollow"><em>structural
sharing</em></a> strategies for efficient memory management
and, if they are <em>balanced</em> and have <em>large branching factors</em>, provide
O(log<sub>k</sub> N) average performance guarantees.</p>
<p dir="auto"><em>Persistent hash array-mapped tries</em> are, in essence, a sophisticated,
practical implementation of such a data structure.</p>
<h3 tabindex="-1" dir="auto">Persistent Hash Array-Mapped Tries</h3>
<p dir="auto">One way to understand hash array-mapped tries is to look at them as an
evolution of <em>k</em>-ary trees (Fig. 1) that follows from a series of real-world
tradeoffs.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mkirchner/hamt/blob/main/doc/img/hamt-trees.png"><img src="https://github.com/mkirchner/hamt/raw/main/doc/img/hamt-trees.png" width="600"></a>
</p>
<p dir="auto"><b>Figure 1:</b> *k*-ary tree, hash tree, and
hash array-mapped trie.</p>
<p dir="auto">In classic <em>k</em>-ary trees Ⓐ,  Internal and leaf nodes have
different types: internal nodes point to <em>n</em> internal or leaf nodes and leaf
nodes hold or point to data (i.e. the keys/value pairs). In their basic form,
<em>n</em>-ary trees (just like binary trees) are not balanced and their performance
characteristics can easily degrade from <em>O(log<sub>k</sub> n)</em> to <em>O(n)</em>
for degenerate input sequences.</p>
<p dir="auto">One approach to balanced trees are explicit implementations of
tree rebalancing (as in e.g. <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree" rel="nofollow">Red-black
trees</a>, <a href="https://en.wikipedia.org/wiki/AVL_tree" rel="nofollow">AVL trees</a>, or
<a href="https://en.wikipedia.org/wiki/B-tree" rel="nofollow">B-trees</a>).</p>
<p dir="auto">Another option is to use a <a href="https://en.wikipedia.org/wiki/Hash_tree_(persistent_data_structure)" rel="nofollow"><em>hash tree</em></a> Ⓑ: like the name
implies, it uses the <em>hash</em> of the key, interpreted as a sequence of <em>b</em>-bit
groups, to detetermine the location of the leaf node that stores the key/value
pair. The group size <em>b</em> determines the branching factor 2<sup><i>b</i></sup>,
i.e. for <em>b</em>=5, every node can have 2<sup>5</sup>=32 child nodes.
Instead of implementing explicit tree rebalancing, hash trees rely on the
distributional properties of a (good) hash function to place nodes uniformly.
While this saves some effort for rebalancing, note that hash trees <em>do</em>
require a strategy to deal with <em>hash exhaustion</em>, a topic covered below.</p>
<p dir="auto">The challenge with vanilla hash trees is that they reserve space for <em>k</em>
children in every internal node. If the tree is sparsely populated this will
cause significant memory overhead and impact performance due to cache misses.</p>
<p dir="auto">For that reason, HAMTs implement <em>array mapping</em> Ⓒ: instead of reserving space
for <em>n</em> pointers to children in each internal node, the parent node stores a
bitmap that indicates which children are present and the actual node only
allocates the memory required to refer to its children. This is an important
optimization that makes trees with a high branching factor more memory
efficient and cache-friendly.</p>
<p dir="auto">In order to implement a <em>persistent</em> map or set, every modification operation
must return a modified copy and maintain the source data structure. And
returning actual copies is prohibitively expensive in time and memory.</p>
<p dir="auto">This, finally, is where HAMTs really shine and the true reason why we build
them in the first place.</p>
<p dir="auto">HAMTs are trees and trees are compatible with
<a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="nofollow">structural sharing</a> strategies. Common
techniques are copy-on-write, fat nodes, <a href="https://en.wikipedia.org/wiki/Persistent_data_structure#Techniques_for_preserving_previous_versions" rel="nofollow">path
copying</a>, and there are <a href="https://www.cs.cmu.edu/~sleator/papers/another-persistence.pdf" rel="nofollow">complex
combinations of the previous three</a>. Path copying is
simple, efficient and general and therefore the technique of choice for
<code>libhamt</code>: Instead of returning an actual copy of the tree during an insert,
update or delete operations, we follow the search path to the item in
question, maintaining a path copy with all the nodes along the way, make our
modification along this path and return it to the caller.</p>
<p dir="auto">Note that enabling persistence <em>requires</em> the use of a garbage collection
strategy. Under stanard <code>malloc()</code> memory management, there is no way for
the HAMT nodes to know how many descendants of a HAMT refer to them.</p>
<h3 tabindex="-1" dir="auto">Documentation structure and implementation strategy</h3>
<p dir="auto">In the following we will address these concepts in turn: we first define the
foundational data structure used to build a tree and introduce the concept of
an <em>anchor</em>. We then dive into hash functions and the <em>hash state management</em>
required to make hashing work for trees of arbitrary depths and in the
presence of hash collisions. We then turn to <em>table management</em>,
introducing a set of functions used to create, modify, query and dispose of
mapped arrays.  With these pieces in place, we are ready to implement the
insert/update, query, and delete functions for non-persistent HAMTs. And
lastly, we introduce the concept of path copying and close with the
implementation of persistent insert/update and delete functions for HAMTs.</p>
<h3 tabindex="-1" dir="auto">Foundational data structures</h3>

<p dir="auto"><code>libhamt</code> uses different types to implement internal and leaf nodes.</p>
<p dir="auto">Leaf nodes contain two fields, called <code>value</code> and <code>key</code> (the rationale for the
reverse ordering of the two fields will become evident shortly).</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct {
    void *value;
    void *key;
} kv;"><pre><span>struct</span> {
    <span>void</span> <span>*</span><span>value</span>;
    <span>void</span> <span>*</span><span>key</span>;
} <span>kv</span>;</pre></div>
<p dir="auto">Both fields are
defined as <code>void*</code> pointers to support referring to arbitrary data types via
type casting
<sup id="user-content-ac_cpp_virtual_method_table"><a href="#fn_cpp_virtual_method_table">5</a></sup>.</p>
<p dir="auto"><code>libhamt</code>'s internal nodes are where the magic happens, based on Bagwell's <em><a href="https://lampwww.epfl.ch/papers/idealhashtrees.pdf" rel="nofollow">Ideal Hash
Trees</a></em> paper and according to the design principles
outlined above.</p>
<p dir="auto">With a branching factor <em>k</em>, internal nodes have at most <em>k</em> successors but
can be sparsely populated. To allow for a memory-efficient representation,
internal nodes have a pointer <code>ptr</code> that points to a fixed-size, right-sized
<em>array</em> of child nodes (also known as a <em>table</em>) and a <em>k</em>-bit <code>index</code> bitmap field that
keeps track of the size and occupancy of that array.</p>
<p dir="auto"><code>libhamt</code> uses <em>k</em>=32 and because <code>index</code> is a 32-bit bitmap field, the number
of one-bits in <code>index</code> yields the size of the array that <code>ptr</code> points to (also
known as the <em>population count</em> or <code>popcount()</code> of <code>index</code>).</p>
<p dir="auto">This suggests an initial (incomplete) definition along the following lines:</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct {
    struct T *ptr;  /* incomplete */
    uint32_t index;
} table;"><pre><span>struct</span> {
    <span>struct</span> <span>T</span> <span>*</span><span>ptr</span>;  <span>/* incomplete */</span>
    <span>uint32_t</span> <span>index</span>;
} <span>table</span>;</pre></div>
<p dir="auto">The specification of <code>T</code> must provide the ability for that datatype to point to
internal and external nodes alike, using only a single pointer type.
A solution is to wrap the two types into a <code>union</code> (and then to wrap
the <code>union</code> into a <code>typedef</code> for convenience):</p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef struct hamt_node {
    union {
        struct {
            void *value;
            void *key;
        } kv;
        struct {
            struct hamt_node *ptr;
            uint32_t index;
        } table;
    } as;
} hamt_node;"><pre><span>typedef</span> <span>struct</span> <span>hamt_node</span> {
    <span>union</span> {
        <span>struct</span> {
            <span>void</span> <span>*</span><span>value</span>;
            <span>void</span> <span>*</span><span>key</span>;
        } <span>kv</span>;
        <span>struct</span> {
            <span>struct</span> <span>hamt_node</span> <span>*</span><span>ptr</span>;
            <span>uint32_t</span> <span>index</span>;
        } <span>table</span>;
    } <span>as</span>;
} <span>hamt_node</span>;</pre></div>
<p dir="auto">With this structure, given a pointer <code>hamt_node *p</code> to a <code>hamt_node</code>
instance, <code>p-&gt;as.kv</code> addresses the leaf node, and <code>p-&gt;as.table</code> addresses the
internal node and <code>p-&gt;as.kv.value</code>, <code>p-&gt;as.kv.key</code>, <code>p-&gt;as.table.ptr</code>, and
<code>p-&gt;as.table.index</code> provide access to the respective fields.</p>
<p dir="auto">To maintain sanity, we define the following convenience macros:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define TABLE(node) node->as.table.ptr
#define INDEX(node) node->as.table.index
#define VALUE(node) node->as.kv.value
#define KEY(node)   node->as.kv.key"><pre><span>#define</span> <span>TABLE</span>(<span>node</span>) node-&gt;as.table.ptr
<span>#define</span> <span>INDEX</span>(<span>node</span>) node-&gt;as.table.index
<span>#define</span> <span>VALUE</span>(<span>node</span>) node-&gt;as.kv.value
<span>#define</span> <span>KEY</span>(<span>node</span>)   node-&gt;as.kv.key</pre></div>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mkirchner/hamt/blob/main/doc/img/hamtnode-table.png"><img src="https://github.com/mkirchner/hamt/raw/main/doc/img/hamtnode-table.png" width="450"></a>
</p>
<p dir="auto"><b>Figure 2:</b>
Memory structure of an internal node. If <code>node</code> is a pointer
to an internal node, <code>TABLE(node)</code> (or, equivalently, <code>
node-&gt;as.table.ptr</code>) points to the first field of the successor table.
</p>
<h3 tabindex="-1" dir="auto">The Anchor</h3>
<p dir="auto">The <code>libhamt</code> codebase makes liberal use of the concept of an <em>anchor</em>.  An
<em>anchor</em> is a <code>hamt_node*</code> pointer to an internal node (i.e.
<code>is_value(VALUE(anchor))</code> evaluates to false). An <code>anchor</code> provides access to
all information relevant to manage the table of child nodes: <code>INDEX(anchor)</code>
returns the bitmap that encodes the array mapping, applying a popcount to the
bitmap gives the size of the table and indexing is implemented using partial
popcounts. Table elements can be accessed through
<code>TABLE(anchor)[i]</code>, where <code>i</code> must be in the valid range.</p>
<h3 tabindex="-1" dir="auto">Pointer tagging</h3>
<p dir="auto">The definition of <code>hamt_node</code> enables the construction of trees with a mix of
internal and leaf nodes. What the definition does not provide, is a way to
determine if a concrete <code>hamt_node*</code> pointer points to an internal or a leaf
node. One solution would be to specify an <code>enum</code> that indicates the type
(i.e. <code>NODE_LEAF</code>, etc.) and to add a <code>type</code> field to <code>struct hamt_node</code>.  While
valid, this would also increase the size of the struct by 50% just to maintain
a single bit of information. Luckily, there is a more memory-efficient
solution: pointer tagging.</p>
<p dir="auto">Since pointers need to be word-aligned, that leaves the lower 3 bits of all
pointers on 64-bit architectures always set to zero. It is possible to make
use of these bits under two conditions: (1) we know we are looking at a
pointer (the bottom three bits for the integer 1 are zero, too); and (2) we
carefully mask the bits in question whenever we actually use the pointer
(since it would point to the wrong location otherwise). The first is not a
problem since we own the code; the second requires diligence and some helper
functions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define HAMT_TAG_MASK 0x3
#define HAMT_TAG_VALUE 0x1
#define tagged(__p) (hamt_node *)((uintptr_t)__p | HAMT_TAG_VALUE)
#define untagged(__p) (hamt_node *)((uintptr_t)__p &amp; ~HAMT_TAG_MASK)
#define is_value(__p) (((uintptr_t)__p &amp; HAMT_TAG_MASK) == HAMT_TAG_VALUE)"><pre><span>#define</span> <span>HAMT_TAG_MASK</span> 0x3
<span>#define</span> <span>HAMT_TAG_VALUE</span> 0x1
<span>#define</span> <span>tagged</span>(<span>__p</span>) (hamt_node *)((uintptr_t)__p | HAMT_TAG_VALUE)
<span>#define</span> <span>untagged</span>(<span>__p</span>) (hamt_node *)((uintptr_t)__p &amp; ~HAMT_TAG_MASK)
<span>#define</span> <span>is_value</span>(<span>__p</span>) (((uintptr_t)__p &amp; HAMT_TAG_MASK) == HAMT_TAG_VALUE)</pre></div>
<p dir="auto">In order to mark a leaf node as such, we set <code>key</code> as usual and tag the value
pointer before assigning it to <code>value</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    p->as.kv.key = key_ptr;
    p->as.kv.value = tagged(value_ptr);"><pre>    <span>p</span><span>-&gt;</span><span>as</span>.<span>kv</span>.<span>key</span> <span>=</span> <span>key_ptr</span>;
    <span>p</span><span>-&gt;</span><span>as</span>.<span>kv</span>.<span>value</span> <span>=</span> <span>tagged</span>(<span>value_ptr</span>);</pre></div>
<p dir="auto">Given a pointer to a leaf (e.g. a search result), we untag <code>value</code> before
returning it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    ...
    if (status == SEARCH_SUCCESS) {
        return untagged(p->as.kv.value);
    }
    ..."><pre>    ...
    <span>if</span> (<span>status</span> <span>==</span> <span>SEARCH_SUCCESS</span>) {
        <span>return</span> <span>untagged</span>(<span>p</span><span>-&gt;</span><span>as</span>.<span>kv</span>.<span>value</span>);
    }
    ...</pre></div>
<p dir="auto">And, in order to determine what we are looking at, we use <code>is_value</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    if (is_value(p->as.kv.value)) {
        /* this is a leaf */
        ...
    } else {
        /* this is an internal node */
        ...
    }"><pre>    <span>if</span> (<span>is_value</span>(<span>p</span><span>-&gt;</span><span>as</span>.<span>kv</span>.<span>value</span>)) {
        <span>/* this is a leaf */</span>
        ...
    } <span>else</span> {
        <span>/* this is an internal node */</span>
        ...
    }</pre></div>
<p dir="auto">Pointer tagging is the reason why the <code>value</code> and <code>key</code>
fields in the <code>struct kv</code> struct are ordered the way they are.
The <code>union</code> in <code>hamt_node</code> causes the
memory locations of the <code>struct kv</code> and <code>struct table</code> structs to overlap. Since
the <code>table.index</code> field is <em>not</em> a pointer (and the bottom-three-bits-are-zero
guarantee does not apply), its storage location cannot be used for pointer
tagging, leaving the <code>table.ptr</code> to the task. Putting <code>kv.value</code> first,
aligns the value field with <code>table.ptr</code>. The reverse order would work, but the
<code>kv.key</code> pointer is dereferenced much more often in the code and so it is more
convenient to use <code>kv.value</code>.</p>
<h2 tabindex="-1" dir="auto">Array mapping</h2>
<p dir="auto">The principal idea behing array mapping is to project a sparse bitmap index
onto the index of a dense array, where the size of the array corresponds to
the number of non-zero bits in the bitmap index.</p>
<p dir="auto">Given <code>hamt_node *p</code> is a valid pointer to a node, <code>INDEX(p)</code> corresponds to a
sparse bitmap index. The dense array is located at <code>TABLE(p)</code> and its size is
determined by the <a href="https://en.wikipedia.org/wiki/Hamming_weight" rel="nofollow"><em>population count</em></a> of <code>INDEX(p)</code>.</p>
<p dir="auto">The mapping itself is conceptually trivial: to determine the dense index for
every non-zero bit in the bitmap index, count the number of non-zero bits to
the right of it. In other words, the first set bit goes to index 0, the second
to index 1, and so forth.</p>
<p dir="auto">Efficiently implementing population counting (also known as the hamming
weight) of a bitset is <a href="https://en.wikipedia.org/wiki/Hamming_weight" rel="nofollow">not trivial</a>. <code>libhamt</code> falls back on a
GCC/Clang intrinsic:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline int get_popcount(uint32_t n) { return __builtin_popcount(n); }"><pre><span>static</span> <span>inline</span> <span>int</span> <span>get_popcount</span>(<span>uint32_t</span> <span>n</span>) { <span>return</span> <span>__builtin_popcount</span>(<span>n</span>); }</pre></div>
<p dir="auto">With <code>get_popcount()</code> available, determining the position (i.e. dense index)
for a sparse index in a bitmap reduces to calculating the population count of
the bitmap masked off above the sparse index:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline int get_pos(uint32_t sparse_index, uint32_t bitmap)
{
    return get_popcount(bitmap &amp; ((1 << sparse_index) - 1));
}"><pre><span>static</span> <span>inline</span> <span>int</span> <span>get_pos</span>(<span>uint32_t</span> <span>sparse_index</span>, <span>uint32_t</span> <span>bitmap</span>)
{
    <span>return</span> <span>get_popcount</span>(<span>bitmap</span> <span>&amp;</span> ((<span>1</span> &lt;&lt; <span>sparse_index</span>) <span>-</span> <span>1</span>));
}</pre></div>
<p dir="auto">Lastly, to determine if a node has a child at a particular index <code>index</code>, we
check if the bit at that index is set in the bitmap:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline bool has_index(const hamt_node *anchor, size_t index)
{
    return INDEX(anchor) &amp; (1 << index);
}"><pre><span>static</span> <span>inline</span> <span>bool</span> <span>has_index</span>(<span>const</span> <span>hamt_node</span> <span>*</span><span>anchor</span>, <span>size_t</span> <span>index</span>)
{
    <span>return</span> <span>INDEX</span>(<span>anchor</span>) <span>&amp;</span> (<span>1</span> &lt;&lt; <span>index</span>);
}</pre></div>
<h2 tabindex="-1" dir="auto">Hashing</h2>
<p dir="auto">A <a href="https://en.wikipedia.org/wiki/Hash_function" rel="nofollow"><em>hash function</em></a> is a function that takes data of
arbitrary size and maps it to a fixed-size value (often machine word sizes).
<em>Good</em> hash functions are fast to compute and produce <em>uniform</em> output, they
map their inputs as evenly as possible over the output range.  If it is
practically infeasible to invert the mapping (i.e. determine which hash
corresponds to which input value), the hash function is called a <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function" rel="nofollow">cryptographic
hash function</a>.</p>
<p dir="auto">For the purpose of implementing a HAMT, cryptographical security is not a
design goal. However, the uniformity of the hash function has direct impact on
the balance of the tree: it is the hash that pre-determines all key positions
in the fully populated tree and it is its distribution properties that
determines the number of collisions (and hence depth extensions) we introduce.</p>
<p dir="auto"><code>libhamt</code> does not force clients to use a particular hash function. The
libary exposes a hash function signature of the form</p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef uint32_t (*hamt_key_hash_fn)(const void *key, const size_t gen);"><pre><span>typedef</span> <span>uint32_t</span> (<span>*</span><span>hamt_key_hash_fn</span>)(<span>const</span> <span>void</span> <span>*</span><span>key</span>, <span>const</span> <span>size_t</span> <span>gen</span>);</pre></div>
<p dir="auto">and expects users to provide a suitable function pointer as part of the call to
<code>hamt_create()</code> which, among other parameters, takes a hash function:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* ... see below for a practical definition of my_keyhash_string */

    struct hamt *t = hamt_create(my_keyhash_string, my_keycmp_string,
                                 &amp;hamt_allocator_default);"><pre><span>/* ... see below for a practical definition of my_keyhash_string */</span>

    <span>struct</span> <span>hamt</span> <span>*</span><span>t</span> <span>=</span> <span>hamt_create</span>(<span>my_keyhash_string</span>, <span>my_keycmp_string</span>,
                                 <span>&amp;</span><span>hamt_allocator_default</span>);</pre></div>
<p dir="auto">There are multiple <a href="https://theoryofcomputing.org/articles/v009a030/v009a030.pdf" rel="nofollow">good, practical choices</a>
for the HAMT.  Per default <code>libhamt</code> includes its <a href="https://github.com/mkirchner/hamt/blob/main/src/murmur3.c">own</a>,
<a href="https://github.com/mkirchner/hamt/blob/62a24e5501d72d5fb505d3c642113015f46904d3/test/test_hamt.c#L92">tested</a> implementation of 32-bit
<a href="https://en.wikipedia.org/wiki/MurmurHash" rel="nofollow">MurmurHash3</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* from include/murmur3.h */

uint32_t murmur3_32(const uint8_t *key, size_t len, uint32_t seed);"><pre><span>/* from include/murmur3.h */</span>

<span>uint32_t</span> <span>murmur3_32</span>(<span>const</span> <span>uint8_t</span> <span>*</span><span>key</span>, <span>size_t</span> <span>len</span>, <span>uint32_t</span> <span>seed</span>);</pre></div>
<p dir="auto">This declares the <em>murmur</em> hash function. In its standard form <code>murmur3_32</code>
takes a pointer <code>key</code> to byte-sized objects, a count of <code>len</code> that speficies
the number of bytes to hash and a random seed <code>seed</code>.</p>
<p dir="auto">In order to use murmur3 as a <code>hamt</code> hash function, we need to wrap it into a
helper function:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static uint32_t my_keyhash_string(const void *key, const size_t gen)
{
    uint32_t hash = murmur3_32((uint8_t *)key, strlen((const char *)key), gen);
    return hash;
}"><pre><span>static</span> <span>uint32_t</span> <span>my_keyhash_string</span>(<span>const</span> <span>void</span> <span>*</span><span>key</span>, <span>const</span> <span>size_t</span> <span>gen</span>)
{
    <span>uint32_t</span> <span>hash</span> <span>=</span> <span>murmur3_32</span>((<span>uint8_t</span> <span>*</span>)<span>key</span>, <span>strlen</span>((<span>const</span> <span>char</span> <span>*</span>)<span>key</span>), <span>gen</span>);
    <span>return</span> <span>hash</span>;
}</pre></div>
<p dir="auto">Here, the wrapper makes use of <code>strlen(3)</code>, assuming valid C strings as keys.
Note the use of <code>gen</code> as a seed for the hash (see below for the hash exhaustion
discussion).</p>
<p dir="auto">Here is a full example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &quot;murmur3.h&quot;

/* ... */

static uint32_t my_keyhash_string(const void *key, const size_t gen)
{
    uint32_t hash = murmur3_32((uint8_t *)key, strlen((const char *)key), gen);
    return hash;
}

/* ... */

    struct hamt *t = hamt_create(my_keyhash_string, my_keycmp_string,
                                 &amp;hamt_allocator_default);
"><pre><span>#include</span> <span>"murmur3.h"</span>

<span>/* ... */</span>

<span>static</span> <span>uint32_t</span> <span>my_keyhash_string</span>(<span>const</span> <span>void</span> <span>*</span><span>key</span>, <span>const</span> <span>size_t</span> <span>gen</span>)
{
    <span>uint32_t</span> <span>hash</span> <span>=</span> <span>murmur3_32</span>((<span>uint8_t</span> <span>*</span>)<span>key</span>, <span>strlen</span>((<span>const</span> <span>char</span> <span>*</span>)<span>key</span>), <span>gen</span>);
    <span>return</span> <span>hash</span>;
}

<span>/* ... */</span>

    <span>struct</span> <span>hamt</span> <span>*</span><span>t</span> <span>=</span> <span>hamt_create</span>(<span>my_keyhash_string</span>, <span>my_keycmp_string</span>,
                                 <span>&amp;</span><span>hamt_allocator_default</span>);</pre></div>
<h3 tabindex="-1" dir="auto">Hash exhaustion: hash generations and state management</h3>
<p dir="auto">For a hash trie, the number of elements in the trie is limited by the total number
of hashes that fits into a 32-bit <code>uint32_t</code>, i.e. 2^32-1. Since the HAMT only
uses 30 bits (in 6 chunks of 5 bits), the number of unique keys in the trie is
limited to 2<sup>30</sup>-1 = 1,073,741,823 keys.
At the same time, since every layer of the
tree uses 5 bits of the hash, the trie depth is limited to 32/5 = 6 layers.
Neither the hard limit to the number of elements in the trie,
nor the inability to build a trie beyond depth of 6 are desirable properties.</p>
<p dir="auto">To address both issues, <code>libhamt</code> recalculates the hash with a different seed every
6 layers. This requires a bit of state management and motivates the
existence of the <code>hash_state</code> data type and functions that operate on it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef struct hash_state {
    const void *key;
    hamt_key_hash_fn hash_fn;
    uint32_t hash;
    size_t depth;
    size_t shift;
} hash_state;"><pre><span>typedef</span> <span>struct</span> <span>hash_state</span> {
    <span>const</span> <span>void</span> <span>*</span><span>key</span>;
    <span>hamt_key_hash_fn</span> <span>hash_fn</span>;
    <span>uint32_t</span> <span>hash</span>;
    <span>size_t</span> <span>depth</span>;
    <span>size_t</span> <span>shift</span>;
} <span>hash_state</span>;</pre></div>
<p dir="auto">The struct maintains the pointers <code>key</code> to the key that is being hashed and
<code>hash_fn</code> to the hash function used to calculate the current hash <code>hash</code>. At
the same time, it tracks the current depth <code>depth</code> in the tree (this is the
<em>hash generation</em>) and the bitshift <code>shift</code> of the current 5-bit hash chunk.</p>
<p dir="auto">The interface provides two functions: the means to step from the current 5-bit
hash to the next in <code>hash_next()</code>; and the ability query the current index of a
key at the current trie depth in <code>hash_get_index()</code>.</p>
<p dir="auto"><code>hash_next()</code> takes a pointer to a <code>hash_state</code> instance and steps that instance
from the current to the next chunk. Taking a step involves increasing the
<code>depth</code> and <code>shift</code>, and initiating a rehash if the <code>shift</code> indicates
that the hash has been exhausted:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline hash_state *hash_next(hash_state *h)
{
    h->depth += 1;
    h->shift += 5;
    if (h->shift > 25) {
        h->hash = h->hash_fn(h->key, h->depth / 5);
        h->shift = 0;
    }
    return h;
}"><pre><span>static</span> <span>inline</span> <span>hash_state</span> <span>*</span><span>hash_next</span>(<span>hash_state</span> <span>*</span><span>h</span>)
{
    <span>h</span><span>-&gt;</span><span>depth</span> <span>+=</span> <span>1</span>;
    <span>h</span><span>-&gt;</span><span>shift</span> <span>+=</span> <span>5</span>;
    <span>if</span> (<span>h</span><span>-&gt;</span><span>shift</span> <span>&gt;</span> <span>25</span>) {
        <span>h</span><span>-&gt;</span><span>hash</span> <span>=</span> <span>h</span><span>-&gt;</span><span>hash_fn</span>(<span>h</span><span>-&gt;</span><span>key</span>, <span>h</span><span>-&gt;</span><span>depth</span> / <span>5</span>);
        <span>h</span><span>-&gt;</span><span>shift</span> <span>=</span> <span>0</span>;
    }
    <span>return</span> <span>h</span>;
}</pre></div>
<p dir="auto">The index of a hash at its current depth corresponds to the decimal
representation of the current chunk. To determine the current chunk,
we right-shift the hash by <code>h-&gt;shift</code> to right-align the desired
LSB and then mask with <code>0x11111</code> which equals <code>0x1f</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline uint32_t hash_get_index(const hash_state *h)
{
    return (h->hash >> h->shift) &amp; 0x1f;
}"><pre><span>static</span> <span>inline</span> <span>uint32_t</span> <span>hash_get_index</span>(<span>const</span> <span>hash_state</span> <span>*</span><span>h</span>)
{
    <span>return</span> (<span>h</span><span>-&gt;</span><span>hash</span> &gt;&gt; <span>h</span><span>-&gt;</span><span>shift</span>) <span>&amp;</span> <span>0x1f</span>;
}</pre></div>
<h2 tabindex="-1" dir="auto">Table management</h2>
<p dir="auto">In order to facilitate memory management for tables (aka the internal nodes),
<code>libhamt</code> defines a set of helper functions. Each of these functions takes a
<code>hamt_allocator</code> and calls the user-supplied allocation, re-allocation and
deallocation functions as appropriate.</p>
<p dir="auto">We start by defining a simple memory abstraction (it would also be correct to use real functions
instead of preprocessor macros for this):</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define mem_alloc(ator, size) (ator)->malloc(size)
#define mem_realloc(ator, ptr, size) (ator)->realloc(ptr, size)
#define mem_free(ator, ptr) (ator)->free(ptr)"><pre><span>#define</span> <span>mem_alloc</span>(<span>ator</span>, <span>size</span>) (ator)-&gt;malloc(size)
<span>#define</span> <span>mem_realloc</span>(<span>ator</span>, <span>ptr</span>, <span>size</span>) (ator)-&gt;realloc(ptr, size)
<span>#define</span> <span>mem_free</span>(<span>ator</span>, <span>ptr</span>) (ator)-&gt;free(ptr)</pre></div>
<p dir="auto">This will make it easier to add optimizations (e.g. table caching) in the
future. On top of these macros, table lifecycle management is accomplished
with a few dedicated allocation and de-allocation functions.</p>
<h3 tabindex="-1" dir="auto">Simple allocation and deallocation</h3>
<p dir="auto"><code>table_allocate()</code> allocates tables with size <code>size</code> and returns a pointer to
the newly allocated table.</p>
<div dir="auto" data-snippet-clipboard-copy-content="hamt_node *table_allocate(struct hamt_allocator *ator, size_t size)
{
    return (hamt_node *)mem_alloc(ator, (size * sizeof(hamt_node)));
}"><pre><span>hamt_node</span> <span>*</span><span>table_allocate</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>size_t</span> <span>size</span>)
{
    <span>return</span> (<span>hamt_node</span> <span>*</span>)<span>mem_alloc</span>(<span>ator</span>, (<span>size</span> <span>*</span> <span>sizeof</span>(<span>hamt_node</span>)));
}</pre></div>
<p dir="auto"><code>table_free()</code> deallocates the allocation referenced by <code>ptr</code>. It also
supports taking a <code>size</code> parameter for future extension (e.g. provide a hint
for allocation pool management) that is currently ignored by the underlying
<code>mem_free()</code> implementation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="void table_free(struct hamt_allocator *ator, hamt_node *ptr, size_t size)
{
    mem_free(ator, ptr);
}
"><pre><span>void</span> <span>table_free</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>hamt_node</span> <span>*</span><span>ptr</span>, <span>size_t</span> <span>size</span>)
{
    <span>mem_free</span>(<span>ator</span>, <span>ptr</span>);
}</pre></div>
<h3 tabindex="-1" dir="auto">Specialized table resize operations</h3>
<p dir="auto">While it is possible to implement table re- and right-sizing with the
two functions introduced above, it makes a lot of sense to provide specialized
functionality for the key allocation/de-allocation use cases: extending,
shrinking and gathering a table.</p>
<p dir="auto"><strong>Table extension.</strong> Since the tables in a HAMT are right-sized to minimize
memory overhead, item insertion must necessarily add an additional row to an
existing table. As illustrated in figure 3, the table extension function takes an anchor for an existing
table, allocates a new table with increased size, copies over the exsiting
entries (leaving a gap at the appropriate position for the new row), assigns
the new key and value to the fields in the new row, updates the anchor with
the new memory location of the table and the new index, and eventually frees the
memory of the old table.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mkirchner/hamt/blob/main/doc/img/table-extend.png"><img src="https://github.com/mkirchner/hamt/raw/main/doc/img/table-extend.png" width="450"></a>
</p>
<p dir="auto"><b>Figure 3:</b>
Extending a table creates a new copy of the existing table with an additional
row for the new node.
</p>
<p dir="auto">Looking at the code, this is implemented in verbatim in the <code>table_extend()</code>
function. <code>table_extend()</code> takes an <code>anchor</code> pointer to a table of
size <code>n_rows</code>, then uses the allocator <code>ator</code> to create a new table of size <code>n_rows + 1</code>
with an empty row at position <code>pos</code> and the bitmap index bit <code>index</code> set. It
uses <code>memcpy()</code> to copy memory ranges into the the appropriate positions in
the new allocation, frees the old table and assignes the new table <code>ptr</code> and
<code>index</code> in the anchor:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hamt_node *table_extend(struct hamt_allocator *ator, hamt_node *anchor,
                       size_t n_rows, uint32_t index, uint32_t pos)
{
    hamt_node *new_table = table_allocate(ator, n_rows + 1);
    if (!new_table)
        return NULL;
    if (n_rows > 0) {
        /* copy over table */
        memcpy(&amp;new_table[0], &amp;TABLE(anchor)[0], pos * sizeof(hamt_node));
        /* note: this works since (n_rows - pos) == 0 for cases
         * where we're adding the new k/v pair at the end and memcpy(a, b, 0)
         * is a nop */
        memcpy(&amp;new_table[pos + 1], &amp;TABLE(anchor)[pos],
               (n_rows - pos) * sizeof(hamt_node));
    }
    table_free(ator, TABLE(anchor), n_rows);
    TABLE(anchor) = new_table;
    INDEX(anchor) |= (1 << index);
    return anchor;
}"><pre><span>hamt_node</span> <span>*</span><span>table_extend</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>,
                       <span>size_t</span> <span>n_rows</span>, <span>uint32_t</span> <span>index</span>, <span>uint32_t</span> <span>pos</span>)
{
    <span>hamt_node</span> <span>*</span><span>new_table</span> <span>=</span> <span>table_allocate</span>(<span>ator</span>, <span>n_rows</span> <span>+</span> <span>1</span>);
    <span>if</span> (!<span>new_table</span>)
        <span>return</span> <span>NULL</span>;
    <span>if</span> (<span>n_rows</span> <span>&gt;</span> <span>0</span>) {
        <span>/* copy over table */</span>
        <span>memcpy</span>(<span>&amp;</span><span>new_table</span>[<span>0</span>], <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>0</span>], <span>pos</span> <span>*</span> <span>sizeof</span>(<span>hamt_node</span>));
        <span>/* note: this works since (n_rows - pos) == 0 for cases</span>
<span>         * where we're adding the new k/v pair at the end and memcpy(a, b, 0)</span>
<span>         * is a nop */</span>
        <span>memcpy</span>(<span>&amp;</span><span>new_table</span>[<span>pos</span> <span>+</span> <span>1</span>], <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span>],
               (<span>n_rows</span> <span>-</span> <span>pos</span>) <span>*</span> <span>sizeof</span>(<span>hamt_node</span>));
    }
    <span>table_free</span>(<span>ator</span>, <span>TABLE</span>(<span>anchor</span>), <span>n_rows</span>);
    <span>TABLE</span>(<span>anchor</span>) <span>=</span> <span>new_table</span>;
    <span>INDEX</span>(<span>anchor</span>) |= (<span>1</span> &lt;&lt; <span>index</span>);
    <span>return</span> <span>anchor</span>;
}</pre></div>
<p dir="auto"><strong>Shrinking a table.</strong> Shrinking a table is the inverse operation of table
extension: since we maintain right-sized tables as an invariant, we need to
adjust table sizes the moment the client deletes a key/value pair from the
HAMT.</p>
<p dir="auto">Figure 4 illustrates the concept: given an anchor, the shrinking function
returns a new table with the specified row removed.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mkirchner/hamt/blob/main/doc/img/table-shrink.png"><img src="https://github.com/mkirchner/hamt/raw/main/doc/img/table-shrink.png" width="450"></a>
</p>
<p dir="auto"><b>Figure 4:</b>
Shrinking a table creates a new copy of the table with the specified row
removed.
</p>
<p dir="auto">In the code, this is what <code>table_shrink()</code> does. In the same way as
<code>table_extend()</code> the function takes a pointer <code>ator</code> to the global allocator,
a pointer <code>anchor</code> to the current anchor, the size of the current tables as
<code>n_rows</code>, and the pair of one-hot bitmap index <code>index</code> and storage array
position <code>pos</code>. And, in analogy to table extension, the function allocation a
right-sized table, copies the data to keep using range copies with <code>memcpy()</code>,
frees up the old table and updates the anchor to reflect the changes.</p>
<div dir="auto" data-snippet-clipboard-copy-content="hamt_node *table_shrink(struct hamt_allocator *ator, hamt_node *anchor,
                       size_t n_rows, uint32_t index, uint32_t pos)
{
    hamt_node *new_table = NULL;
    uint32_t new_index = 0;
    if (n_rows > 0) {
        new_table = table_allocate(ator, n_rows - 1);
        if (!new_table)
            return NULL;
        new_index = INDEX(anchor) &amp; ~(1 << index);
        memcpy(&amp;new_table[0], &amp;TABLE(anchor)[0], pos * sizeof(hamt_node));
        memcpy(&amp;new_table[pos], &amp;TABLE(anchor)[pos + 1],
               (n_rows - pos - 1) * sizeof(hamt_node));
    }
    table_free(ator, TABLE(anchor), n_rows);
    INDEX(anchor) = new_index;
    TABLE(anchor) = new_table;
    return anchor;
}"><pre><span>hamt_node</span> <span>*</span><span>table_shrink</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>,
                       <span>size_t</span> <span>n_rows</span>, <span>uint32_t</span> <span>index</span>, <span>uint32_t</span> <span>pos</span>)
{
    <span>hamt_node</span> <span>*</span><span>new_table</span> <span>=</span> <span>NULL</span>;
    <span>uint32_t</span> <span>new_index</span> <span>=</span> <span>0</span>;
    <span>if</span> (<span>n_rows</span> <span>&gt;</span> <span>0</span>) {
        <span>new_table</span> <span>=</span> <span>table_allocate</span>(<span>ator</span>, <span>n_rows</span> <span>-</span> <span>1</span>);
        <span>if</span> (!<span>new_table</span>)
            <span>return</span> <span>NULL</span>;
        <span>new_index</span> <span>=</span> <span>INDEX</span>(<span>anchor</span>) <span>&amp;</span> ~(<span>1</span> &lt;&lt; <span>index</span>);
        <span>memcpy</span>(<span>&amp;</span><span>new_table</span>[<span>0</span>], <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>0</span>], <span>pos</span> <span>*</span> <span>sizeof</span>(<span>hamt_node</span>));
        <span>memcpy</span>(<span>&amp;</span><span>new_table</span>[<span>pos</span>], <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span> <span>+</span> <span>1</span>],
               (<span>n_rows</span> <span>-</span> <span>pos</span> <span>-</span> <span>1</span>) <span>*</span> <span>sizeof</span>(<span>hamt_node</span>));
    }
    <span>table_free</span>(<span>ator</span>, <span>TABLE</span>(<span>anchor</span>), <span>n_rows</span>);
    <span>INDEX</span>(<span>anchor</span>) <span>=</span> <span>new_index</span>;
    <span>TABLE</span>(<span>anchor</span>) <span>=</span> <span>new_table</span>;
    <span>return</span> <span>anchor</span>;
}</pre></div>
<p dir="auto"><strong>Table gathering.</strong> As we are deleting entries from the HAMT, we may end up
with the table structure shown in Figure 5: a table in which one of the
entries is a single-row table. What we want to do in these cases is to replace
the table entry in <code>TABLE(anchor)[1]</code> with the key/value pair from
<code>TABLE(TABLE(anchor)[1])</code> and <em>gather</em> the one-row table into its parent.
While this comes at additional computational cost upon delete, it maintains
the logarithmic depth properties as the HAMT changes its size.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mkirchner/hamt/blob/main/doc/img/table-gather.png"><img src="https://github.com/mkirchner/hamt/raw/main/doc/img/table-gather.png" width="450"></a>
</p>
<p dir="auto"><b>Figure 5:</b>
Gathering pulls a one-row-sized table into its parent table (essentially
converting an internal node into a leaf node).
</p>
<p dir="auto">The code is straightforward: we take the allocator <code>alloc</code>, the <code>anchor</code>
pointer, and the position <code>pos</code> of the single-row table inside the parent
table, copy over the key and value from the child table to the parent
(maintaining a temporary handle on the child) and then free the child table:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hamt_node *table_gather(struct hamt_allocator *ator, hamt_node *anchor,
                       uint32_t pos)
{
    int n_rows = get_popcount(INDEX(anchor));
    hamt_node *table = TABLE(anchor);
    KEY(anchor) = table[pos].as.kv.key;
    VALUE(anchor) = table[pos].as.kv.value; /* already tagged */
    table_free(ator, table, n_rows);
    return anchor;
}
"><pre><span>hamt_node</span> <span>*</span><span>table_gather</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>,
                       <span>uint32_t</span> <span>pos</span>)
{
    <span>int</span> <span>n_rows</span> <span>=</span> <span>get_popcount</span>(<span>INDEX</span>(<span>anchor</span>));
    <span>hamt_node</span> <span>*</span><span>table</span> <span>=</span> <span>TABLE</span>(<span>anchor</span>);
    <span>KEY</span>(<span>anchor</span>) <span>=</span> <span>table</span>[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>key</span>;
    <span>VALUE</span>(<span>anchor</span>) <span>=</span> <span>table</span>[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>value</span>; <span>/* already tagged */</span>
    <span>table_free</span>(<span>ator</span>, <span>table</span>, <span>n_rows</span>);
    <span>return</span> <span>anchor</span>;
}</pre></div>
<p dir="auto"><strong>Table duplication.</strong> Lastly, table duplication. This will be required for path
copying when we implement persistency and it is so straightforward that there
is no diagram: given an anchor, <code>table_dup()</code> determines the size of the table
that the anchor points to, allocates the required memory and performs a range
copy using <code>memcpy()</code> to duplicate the table contents:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hamt_node *table_dup(struct hamt_allocator *ator, hamt_node *anchor)
{
    int n_rows = get_popcount(INDEX(anchor));
    hamt_node *new_table = table_allocate(ator, n_rows);
    if (new_table) {
        memcpy(&amp;new_table[0], &amp;TABLE(anchor)[0], n_rows * sizeof(hamt_node));
    }
    return new_table;
}"><pre><span>hamt_node</span> <span>*</span><span>table_dup</span>(<span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>)
{
    <span>int</span> <span>n_rows</span> <span>=</span> <span>get_popcount</span>(<span>INDEX</span>(<span>anchor</span>));
    <span>hamt_node</span> <span>*</span><span>new_table</span> <span>=</span> <span>table_allocate</span>(<span>ator</span>, <span>n_rows</span>);
    <span>if</span> (<span>new_table</span>) {
        <span>memcpy</span>(<span>&amp;</span><span>new_table</span>[<span>0</span>], <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>0</span>], <span>n_rows</span> <span>*</span> <span>sizeof</span>(<span>hamt_node</span>));
    }
    <span>return</span> <span>new_table</span>;
}</pre></div>
<h2 tabindex="-1" dir="auto">Putting it all together</h2>
<p dir="auto">The following subsections detail the implementations of search, insertion and
removal of key/value pairs in our HAMT implementation. Note that, while the
implementations shown here have been thoroughly tested and are deemed correct,
they may have been replaced by faster or more capable implementations in the
actual <code>libhamt</code> source. An attempt is being made to keep this section up to
date with the actual implementation but the choice here is in favor of
conceptual clarity and will not necessarily cover every implementation detail.
PRs welcome.</p>
<h3 tabindex="-1" dir="auto">Example data</h3>
<table>
<thead>
<tr>
<th>key</th>
<th>key hash</th>
<th>binary key hash</th>
<th>5-bit ints</th>
</tr>
</thead>
<tbody>
<tr>
<td>"0"</td>
<td>d271c07f</td>
<td><code>11 01001 00111 00011 10000 00011 11111</code></td>
<td>[ 31  3 16  3  7 9 ]</td>
</tr>
<tr>
<td>"2"</td>
<td>0129e217</td>
<td><code>00 00000 10010 10011 11000 10000 10111</code></td>
<td>[ 23 16 24 19 18 0 ]</td>
</tr>
<tr>
<td>"4"</td>
<td>e131cc88</td>
<td><code>11 10000 10011 00011 10011 00100 01000</code></td>
<td>[  8  4 19 3 19 16 ]</td>
</tr>
<tr>
<td>"7"</td>
<td>23ea8628</td>
<td><code>00 10001 11110 10101 00001 10001 01000</code></td>
<td>[  8 17 1 21 30 17 ]</td>
</tr>
<tr>
<td>"8"</td>
<td>bd920017</td>
<td><code>10 11110 11001 00100 00000 00000 10111</code></td>
<td>[ 23 0  0  4 25 30 ]</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Search: internal API</h3>
<p dir="auto">Search plays a double role: finding a HAMT entry is a fundamental part of the
HAMT interface (exposed by <code>hamt_get()</code>); and the first step in the insert and remove
functions is finding the anchors to operate on.</p>
<p dir="auto">It is therefore desirable to approach the search implementation from a
more generic perspective such that we do not need to re-invent the
wheel for each of these use cases. We therefore define an internal search
function</p>
<div dir="auto" data-snippet-clipboard-copy-content="static ... search_recursive(...);"><pre><span>static</span> ... <span>search_recursive</span>(...);</pre></div>
<p dir="auto">that is called from internal and the API functions alike. As the
name implies, we implement search in a recursive manner (this is for clarity;
conversion to an iterative solution is straightforward).</p>
<p dir="auto">When we search for a key in the HAMT, there are two fundamental outcomes: the
key is either there, or it is not (note that these are exactly the semantics
of the user-facing <code>hamt_get()</code> function: it either returns a pointer to the
value stored under the key or it returns <code>NULL</code>). However, looking more
closely, searches can fail for two reasons: the search can be unsuccessful
because a key does not exist in the HAMT <em>or</em> it can be unsuccessful because
there is a key value pair that happens to have the same partial hash but a
different key (i.e. there is a hash collission or the hash has not been
sufficiently exhausted to differentiate between the two keys).  And each of
these three cases is meaningful (the latter two corresponding directly to the
two different insertion strategies described below).</p>
<p dir="auto">A good approach here is to define a ternary return value (as opposed to
the usual, binary use-<code>NULL</code>-as-a-failure-indicator approach that is often
prevalent in C code) to allow us to signal each of these cases clearly.</p>
<p dir="auto">We create a suitable three-value <code>enum</code> called <code>search_status</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef enum {
    SEARCH_SUCCESS,
    SEARCH_FAIL_NOTFOUND,
    SEARCH_FAIL_KEYMISMATCH
} search_status;"><pre><span>typedef</span> <span>enum</span> {
    <span>SEARCH_SUCCESS</span>,
    <span>SEARCH_FAIL_NOTFOUND</span>,
    <span>SEARCH_FAIL_KEYMISMATCH</span>
} <span>search_status</span>;</pre></div>
<p dir="auto">where <code>SEARCH_SUCCESS</code> indicates that the key in question was
found, <code>SEARCH_FAIL_NOTFOUND</code> indicates a search failure due to a missing key,
and <code>SEARCH_FAIL_KEYMISMATCH</code> signals a hash conflict.</p>
<p dir="auto">In order to return the result of a search (and not only its status), we
introduce a search result data type that is a bit more heavy-weight:</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct search_result {
    search_status status;
    hamt_node *anchor;
    hamt_node *value;
    hash_state *hash;
};"><pre><span>struct</span> <span>search_result</span> {
    <span>search_status</span> <span>status</span>;
    <span>hamt_node</span> <span>*</span><span>anchor</span>;
    <span>hamt_node</span> <span>*</span><span>value</span>;
    <span>hash_state</span> <span>*</span><span>hash</span>;
};</pre></div>
<p dir="auto">Here, <code>anchor</code> always points to the anchor at which the search was terminated;
if the search was successful, <code>value</code> points to the table row that holds the
key/value pair with matching key; if it was unsuccessful with a key mismatch,
<code>value</code> points to the mismatching key/value pair; and if it was unsuccessful
because the key did not exist, <code>value</code> equals <code>NULL</code>. Depending on the depth
that the search reached, we may have hit hash exhaustion and the hash may have
been recalculated, so we are returning this here, too.</p>
<p dir="auto">Given <code>struct search_result</code>, the return value of <code>search_recursive()</code>
becomes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static struct search_result search_recursive(...)
{
    // ...
}"><pre><span>static</span> <span>struct</span> <span>search_result</span> <span>search_recursive</span>(...)
{
    <span>// ...</span>
}</pre></div>
<p dir="auto">With these prerequisites out of the way, we can tackle the actual search
algorithm:</p>
<div data-snippet-clipboard-copy-content="    search_recursive(anchor, hash, eq, key, ...):
        if the current 5-bit sub-hash is a valid index in the current table: 
            if the index refers to a key/value pair:
                if the key matches the search key:
                    return SEARCH_SUCCESS
                else:
                    return SEARCH_FAIL_KEYMISMATCH
            else (i.e. it refers to a sub-table):
                search_recursive(sub-table, hash_next(hash), eq, key)
        else:
            return SEARCH_FAIL_NOTFOUND"><pre><code>    search_recursive(anchor, hash, eq, key, ...):
        if the current 5-bit sub-hash is a valid index in the current table: 
            if the index refers to a key/value pair:
                if the key matches the search key:
                    return SEARCH_SUCCESS
                else:
                    return SEARCH_FAIL_KEYMISMATCH
            else (i.e. it refers to a sub-table):
                search_recursive(sub-table, hash_next(hash), eq, key)
        else:
            return SEARCH_FAIL_NOTFOUND
</code></pre></div>
<p dir="auto">The basic idea is to start from the root of the HAMT and then, at every level,
test if the curret sub-hash of the key is present in the current sub-trie. If
not, bail and report failure immediately. If yes, check if the entry refers to
a key/value pair or to another table. If this is true as well, check if the
keys match and return success or failure accordingly. If the entry refers to
a sub-table, repeat the search at the level of the sub-table.</p>
<p dir="auto">With the conceptual approach lined out, let's get into the implementation
details.
We start with deriving the table index for the current search level from the
hash. This is accomplished using
<code>hash_get_index()</code>, which encapsulates the bit-fiddling required to extract
the correct 5-bit hash for the current search level and returns the index as
an unsigned integer.</p>
<div dir="auto" data-snippet-clipboard-copy-content="static search_result search_recursive(hamt_node *anchor,
                                      hash_state *hash,
                                      hamt_cmp_fn cmp_eq,
                                      const void *key, ...)
{
    uint32_t expected_index = hash_get_index(hash);
    ...
}"><pre><span>static</span> <span>search_result</span> <span>search_recursive</span>(<span>hamt_node</span> <span>*</span><span>anchor</span>,
                                      <span>hash_state</span> <span>*</span><span>hash</span>,
                                      <span>hamt_cmp_fn</span> <span>cmp_eq</span>,
                                      <span>const</span> <span>void</span> <span>*</span><span>key</span>, ...)
{
    <span>uint32_t</span> <span>expected_index</span> <span>=</span> <span>hash_get_index</span>(<span>hash</span>);
    ...
}</pre></div>
<p dir="auto">The code then checks if the <code>expected_index</code> exists in the current table:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    ...
    if (has_index(anchor, expected_index)) {
    ...
    }"><pre>    ...
    <span>if</span> (<span>has_index</span>(<span>anchor</span>, <span>expected_index</span>)) {
    ...
    }</pre></div>
<p dir="auto">Here, <code>has_index()</code> is a simple helper function that checks if
the <code>INDEX(anchor)</code> bitfield has the bit set at <code>expected_index</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline bool has_expected_index(const hamt_node *anchor, size_t expected_index)
{
    return INDEX(anchor) &amp; (1 << expected_index);
}"><pre><span>static</span> <span>inline</span> <span>bool</span> <span>has_expected_index</span>(<span>const</span> <span>hamt_node</span> <span>*</span><span>anchor</span>, <span>size_t</span> <span>expected_index</span>)
{
    <span>return</span> <span>INDEX</span>(<span>anchor</span>) <span>&amp;</span> (<span>1</span> &lt;&lt; <span>expected_index</span>);
}</pre></div>
<p dir="auto">If <code>has_index()</code> evaluates to false, the key does not exist in the HAMT and we
can immediately fail the search and return the result:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    uint32_t expected_index = hash_get_index(hash);
    if (has_index(anchor, expected_index)) {
        ...
        ... 
        ...
    }
    search_result result = {.status = SEARCH_FAIL_NOTFOUND,
                            .anchor = anchor,
                            .value = NULL,
                            .hash = hash};
    return result;
}"><pre>{
    <span>uint32_t</span> <span>expected_index</span> <span>=</span> <span>hash_get_index</span>(<span>hash</span>);
    <span>if</span> (<span>has_index</span>(<span>anchor</span>, <span>expected_index</span>)) {
        ...
        ... 
        ...
    }
    <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_FAIL_NOTFOUND</span>,
                            .<span>anchor</span> <span>=</span> <span>anchor</span>,
                            .<span>value</span> <span>=</span> <span>NULL</span>,
                            .<span>hash</span> <span>=</span> <span>hash</span>};
    <span>return</span> <span>result</span>;
}</pre></div>
<p dir="auto">If <code>has_index()</code> evaluates to true, we find the array index using
<code>get_pos()</code> (see above), store it into <code>pos</code> and then acquire a pointer to the
<code>next</code> node by addressing <code>pos</code> indices into the <code>anchor</code>'s table.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    ...
    if (has_index(anchor, expected_index)) {
        /* If yes, get the compact index to address the array */
        int pos = get_pos(expected_index, INDEX(anchor));
        /* Index into the table */
        hamt_node *next = &amp;TABLE(anchor)[pos];
        ...
    }
    ...
}"><pre>{
    ...
    <span>if</span> (<span>has_index</span>(<span>anchor</span>, <span>expected_index</span>)) {
        <span>/* If yes, get the compact index to address the array */</span>
        <span>int</span> <span>pos</span> <span>=</span> <span>get_pos</span>(<span>expected_index</span>, <span>INDEX</span>(<span>anchor</span>));
        <span>/* Index into the table */</span>
        <span>hamt_node</span> <span>*</span><span>next</span> <span>=</span> <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span>];
        ...
    }
    ...
}</pre></div>
<p dir="auto">If the <code>next</code> node is not a value, we advance the hash state and recurse the
search. If it is, we compare the keys and return success or failure
accordingly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
        ...
        /* Index into the table */
        hamt_node *next = &amp;TABLE(anchor)[pos];
        /* Are we looking at a value or another level of tables? */
        if (is_value(VALUE(next))) {
            if ((*cmp_eq)(key, KEY(next)) == 0) {
                /* Found: keys match */
                search_result result = {.status = SEARCH_SUCCESS,
                                        .anchor = anchor,
                                        .value = next,
                                        .hash = hash};
                return result;
            }
            /* Not found: same hash but different key */
            search_result result = {.status = SEARCH_FAIL_KEYMISMATCH,
                                    .anchor = anchor,
                                    .value = next,
                                    .hash = hash};
            return result;
        } else {
            /* For table entries, recurse to the next level */
            return search_recursive(next, hash_next(hash), cmp_eq, key);
        }"><pre>{
        ...
        <span>/* Index into the table */</span>
        <span>hamt_node</span> <span>*</span><span>next</span> <span>=</span> <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span>];
        <span>/* Are we looking at a value or another level of tables? */</span>
        <span>if</span> (<span>is_value</span>(<span>VALUE</span>(<span>next</span>))) {
            <span>if</span> ((<span>*</span><span>cmp_eq</span>)(<span>key</span>, <span>KEY</span>(<span>next</span>)) <span>==</span> <span>0</span>) {
                <span>/* Found: keys match */</span>
                <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_SUCCESS</span>,
                                        .<span>anchor</span> <span>=</span> <span>anchor</span>,
                                        .<span>value</span> <span>=</span> <span>next</span>,
                                        .<span>hash</span> <span>=</span> <span>hash</span>};
                <span>return</span> <span>result</span>;
            }
            <span>/* Not found: same hash but different key */</span>
            <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_FAIL_KEYMISMATCH</span>,
                                    .<span>anchor</span> <span>=</span> <span>anchor</span>,
                                    .<span>value</span> <span>=</span> <span>next</span>,
                                    .<span>hash</span> <span>=</span> <span>hash</span>};
            <span>return</span> <span>result</span>;
        } <span>else</span> {
            <span>/* For table entries, recurse to the next level */</span>
            <span>return</span> <span>search_recursive</span>(<span>next</span>, <span>hash_next</span>(<span>hash</span>), <span>cmp_eq</span>, <span>key</span>);
        }</pre></div>
<p dir="auto">That concludes the implementation of the recursive search function and the
complete implementation looks like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static search_result search_recursive(hamt_node *anchor, hash_state *hash,
                                      hamt_cmp_fn cmp_eq, const void *key)
{
    /* Determine the expected index in table */
    uint32_t expected_index = hash_get_index(hash);
    /* Check if the expected index is set */
    if (has_index(anchor, expected_index)) {
        /* If yes, get the compact index to address the array */
        int pos = get_pos(expected_index, INDEX(anchor));
        /* Index into the table */
        hamt_node *next = &amp;TABLE(anchor)[pos];
        /* Are we looking at a value or another level of tables? */
        if (is_value(VALUE(next))) {
            if ((*cmp_eq)(key, KEY(next)) == 0) {
                /* Found: keys match */
                search_result result = {.status = SEARCH_SUCCESS,
                                        .anchor = anchor,
                                        .value = next,
                                        .hash = hash};
                return result;
            }
            /* Not found: same hash but different key */
            search_result result = {.status = SEARCH_FAIL_KEYMISMATCH,
                                    .anchor = anchor,
                                    .value = next,
                                    .hash = hash};
            return result;
        } else {
            /* For table entries, recurse to the next level */
            return search_recursive(next, hash_next(hash), cmp_eq, key);
        }
    }
    /* Not found: expected index is not set, key does not exist */
    search_result result = {.status = SEARCH_FAIL_NOTFOUND,
                            .anchor = anchor,
                            .value = NULL,
                            .hash = hash};
    return result;
}"><pre><span>static</span> <span>search_result</span> <span>search_recursive</span>(<span>hamt_node</span> <span>*</span><span>anchor</span>, <span>hash_state</span> <span>*</span><span>hash</span>,
                                      <span>hamt_cmp_fn</span> <span>cmp_eq</span>, <span>const</span> <span>void</span> <span>*</span><span>key</span>)
{
    <span>/* Determine the expected index in table */</span>
    <span>uint32_t</span> <span>expected_index</span> <span>=</span> <span>hash_get_index</span>(<span>hash</span>);
    <span>/* Check if the expected index is set */</span>
    <span>if</span> (<span>has_index</span>(<span>anchor</span>, <span>expected_index</span>)) {
        <span>/* If yes, get the compact index to address the array */</span>
        <span>int</span> <span>pos</span> <span>=</span> <span>get_pos</span>(<span>expected_index</span>, <span>INDEX</span>(<span>anchor</span>));
        <span>/* Index into the table */</span>
        <span>hamt_node</span> <span>*</span><span>next</span> <span>=</span> <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span>];
        <span>/* Are we looking at a value or another level of tables? */</span>
        <span>if</span> (<span>is_value</span>(<span>VALUE</span>(<span>next</span>))) {
            <span>if</span> ((<span>*</span><span>cmp_eq</span>)(<span>key</span>, <span>KEY</span>(<span>next</span>)) <span>==</span> <span>0</span>) {
                <span>/* Found: keys match */</span>
                <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_SUCCESS</span>,
                                        .<span>anchor</span> <span>=</span> <span>anchor</span>,
                                        .<span>value</span> <span>=</span> <span>next</span>,
                                        .<span>hash</span> <span>=</span> <span>hash</span>};
                <span>return</span> <span>result</span>;
            }
            <span>/* Not found: same hash but different key */</span>
            <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_FAIL_KEYMISMATCH</span>,
                                    .<span>anchor</span> <span>=</span> <span>anchor</span>,
                                    .<span>value</span> <span>=</span> <span>next</span>,
                                    .<span>hash</span> <span>=</span> <span>hash</span>};
            <span>return</span> <span>result</span>;
        } <span>else</span> {
            <span>/* For table entries, recurse to the next level */</span>
            <span>return</span> <span>search_recursive</span>(<span>next</span>, <span>hash_next</span>(<span>hash</span>), <span>cmp_eq</span>, <span>key</span>);
        }
    }
    <span>/* Not found: expected index is not set, key does not exist */</span>
    <span>search_result</span> <span>result</span> <span>=</span> {.<span>status</span> <span>=</span> <span>SEARCH_FAIL_NOTFOUND</span>,
                            .<span>anchor</span> <span>=</span> <span>anchor</span>,
                            .<span>value</span> <span>=</span> <span>NULL</span>,
                            .<span>hash</span> <span>=</span> <span>hash</span>};
    <span>return</span> <span>result</span>;
}</pre></div>
<h3 tabindex="-1" dir="auto">Search: external API</h3>
<p dir="auto">The external API for search is <code>hamt_get(trie, key)</code> which takes a <code>trie</code>
and attempts to find (and return) a key/value pair specified by <code>key</code>. Its
implementation uses <code>search_recursive()</code> from above:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const void *hamt_get(const struct hamt *trie, void *key)
{
    hash_state *hash = &amp;(hash_state){.key = key,
                                     .hash_fn = trie->key_hash,
                                     .hash = trie->key_hash(key, 0),
                                     .depth = 0,
                                     .shift = 0};
    search_result sr = search_recursive(trie->root, hash, trie->key_cmp, key,
                                        NULL, trie->ator);
    if (sr.status == SEARCH_SUCCESS) {
        return untagged(sr.VALUE(value));
    }
    return NULL;
}"><pre><span>const</span> <span>void</span> <span>*</span><span>hamt_get</span>(<span>const</span> <span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>)
{
    <span>hash_state</span> <span>*</span><span>hash</span> <span>=</span> <span>&amp;</span>(<span>hash_state</span>){.<span>key</span> <span>=</span> <span>key</span>,
                                     .<span>hash_fn</span> <span>=</span> <span>trie</span><span>-&gt;</span><span>key_hash</span>,
                                     .<span>hash</span> <span>=</span> <span>trie</span><span>-&gt;</span><span>key_hash</span>(<span>key</span>, <span>0</span>),
                                     .<span>depth</span> <span>=</span> <span>0</span>,
                                     .<span>shift</span> <span>=</span> <span>0</span>};
    <span>search_result</span> <span>sr</span> <span>=</span> <span>search_recursive</span>(<span>trie</span><span>-&gt;</span><span>root</span>, <span>hash</span>, <span>trie</span><span>-&gt;</span><span>key_cmp</span>, <span>key</span>,
                                        <span>NULL</span>, <span>trie</span><span>-&gt;</span><span>ator</span>);
    <span>if</span> (<span>sr</span>.<span>status</span> <span>==</span> <span>SEARCH_SUCCESS</span>) {
        <span>return</span> <span>untagged</span>(<span>sr</span>.<span>VALUE</span>(<span>value</span>));
    }
    <span>return</span> <span>NULL</span>;
}</pre></div>
<p dir="auto">In order to use <code>search_recursive()</code>, it is necessary to set up the hash state
management, initializing it with the <code>key</code>, the hashed <code>key</code>, and starting
search from level <code>0</code> (corresponding to a shift of <code>0</code>). If the search is
not successful, the function returns <code>NULL</code>, if it is successful, it passes
a <code>void</code> pointer to the value that corresponds to <code>key</code>. Note the <em>untagging</em>
of the <code>value</code> field since we're using it as a <em>tagged pointer</em> to indicate
field types.</p>
<h3 tabindex="-1" dir="auto">Insert: internal functions</h3>
<p dir="auto"><code>libhamt</code> does not support an explicit insertion function; all insertions into
the HAMT are <em>upserts</em>, i.e. after calling <code>hamt_set()</code> the API guarantees
that the requested key/value pair exists, irrespective of potential previous
entries that may have had the same key but a different value.</p>
<p dir="auto">The internal function that implements this behavior is <code>set()</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static const hamt_node *set(struct hamt *h, hamt_node *anchor, hamt_key_hash_fn hash_fn,
                            hamt_cmp_fn cmp_fn, void *key, void *value)"><pre><span>static</span> <span>const</span> <span>hamt_node</span> <span>*</span><span>set</span>(<span>struct</span> <span>hamt</span> <span>*</span><span>h</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>, <span>hamt_key_hash_fn</span> <span>hash_fn</span>,
                            <span>hamt_cmp_fn</span> <span>cmp_fn</span>, <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>)</pre></div>
<p dir="auto"><code>set()</code> takes a HAMT, an anchor in that HAMT, hashing and comparison
functions as well as a key/value pair. After initializing the hash state, the
function makes use of <code>search_recursive</code> to find the specified <code>key</code>. It deals
with three different search outcomes: (1) if the search is successful, the
value of <code>key</code> gets replaced with the new <code>value</code>; (2) if the search is
unsuccessful because the key does not exist, it attempts to insert a new
key/value pair at the appropriate position; and (3) if the search fails due to
a key mismatch (i.e. there is an entry at the expected hash position but its
key does not equal <code>key</code>), it extends the hash trie until the new key/value
pair can be placed correctly. Cases (2) and (3) are covered by the
<code>insert_kv()</code> and <code>insert_table()</code> helper functions, respectively.</p>
<div dir="auto" data-snippet-clipboard-copy-content="static const hamt_node *set(struct hamt *h, hamt_node *anchor, hamt_key_hash_fn hash_fn,
                            hamt_cmp_fn cmp_fn, void *key, void *value)
{
    hash_state *hash = &amp;(hash_state){.key = key,
                                     .hash_fn = hash_fn,
                                     .hash = hash_fn(key, 0),
                                     .depth = 0,
                                     .shift = 0};
    search_result sr =
        search_recursive(anchor, hash, cmp_fn, key, NULL, h->ator);
    const hamt_node *inserted;
    switch (sr.status) {
    case SEARCH_SUCCESS:
        sr.VALUE(value) = tagged(value);
        inserted = sr.value;
        break;
    case SEARCH_FAIL_NOTFOUND:
        if ((inserted = insert_kv(sr.anchor, sr.hash, key, value, h->ator)) !=
            NULL) {
            h->size += 1;
        }
        break;
    case SEARCH_FAIL_KEYMISMATCH:
        if ((inserted = insert_table(sr.value, sr.hash, key, value, h->ator)) !=
            NULL) {
            h->size += 1;
        }
        break;
    }
    return inserted;
}"><pre><span>static</span> <span>const</span> <span>hamt_node</span> <span>*</span><span>set</span>(<span>struct</span> <span>hamt</span> <span>*</span><span>h</span>, <span>hamt_node</span> <span>*</span><span>anchor</span>, <span>hamt_key_hash_fn</span> <span>hash_fn</span>,
                            <span>hamt_cmp_fn</span> <span>cmp_fn</span>, <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>)
{
    <span>hash_state</span> <span>*</span><span>hash</span> <span>=</span> <span>&amp;</span>(<span>hash_state</span>){.<span>key</span> <span>=</span> <span>key</span>,
                                     .<span>hash_fn</span> <span>=</span> <span>hash_fn</span>,
                                     .<span>hash</span> <span>=</span> <span>hash_fn</span>(<span>key</span>, <span>0</span>),
                                     .<span>depth</span> <span>=</span> <span>0</span>,
                                     .<span>shift</span> <span>=</span> <span>0</span>};
    <span>search_result</span> <span>sr</span> <span>=</span>
        <span>search_recursive</span>(<span>anchor</span>, <span>hash</span>, <span>cmp_fn</span>, <span>key</span>, <span>NULL</span>, <span>h</span><span>-&gt;</span><span>ator</span>);
    <span>const</span> <span>hamt_node</span> <span>*</span><span>inserted</span>;
    <span>switch</span> (<span>sr</span>.<span>status</span>) {
    <span>case</span> <span>SEARCH_SUCCESS</span>:
        <span>sr</span>.<span>VALUE</span>(<span>value</span>) <span>=</span> <span>tagged</span>(<span>value</span>);
        <span>inserted</span> <span>=</span> <span>sr</span>.<span>value</span>;
        <span>break</span>;
    <span>case</span> <span>SEARCH_FAIL_NOTFOUND</span>:
        <span>if</span> ((<span>inserted</span> <span>=</span> <span>insert_kv</span>(<span>sr</span>.<span>anchor</span>, <span>sr</span>.<span>hash</span>, <span>key</span>, <span>value</span>, <span>h</span><span>-&gt;</span><span>ator</span>)) <span>!=</span>
            <span>NULL</span>) {
            <span>h</span><span>-&gt;</span><span>size</span> <span>+=</span> <span>1</span>;
        }
        <span>break</span>;
    <span>case</span> <span>SEARCH_FAIL_KEYMISMATCH</span>:
        <span>if</span> ((<span>inserted</span> <span>=</span> <span>insert_table</span>(<span>sr</span>.<span>value</span>, <span>sr</span>.<span>hash</span>, <span>key</span>, <span>value</span>, <span>h</span><span>-&gt;</span><span>ator</span>)) <span>!=</span>
            <span>NULL</span>) {
            <span>h</span><span>-&gt;</span><span>size</span> <span>+=</span> <span>1</span>;
        }
        <span>break</span>;
    }
    <span>return</span> <span>inserted</span>;
}</pre></div>
<p dir="auto">If the call to <code>search_recursive()</code> fails with <code>SEARCH_FAIL_NOTFOUND</code>, we know
that there is a free row in the table of <code>sr.anchor</code>. To insert the new
<code>key</code>/<code>value</code> pair, we calculate the position of the <code>key</code> in the current
table: it extracts the 0-31 index position for the current key and stores it
into <code>ix</code>, extends the existing <code>INDEX(anchor)</code> index bitmap to include the
new key by setting the <code>ix</code>-th bit, and then calculates the dense index
position of the new entry via <code>get_pos()</code>. It then uses <code>table_extend()</code> to
extend the table to the correct size and populates the <code>key</code> and <code>value</code>
entries to reflect the new key/value pair. Note the pointer tagging on the
value field to mark it as a key/value row in the table (as opposed to a row
that points to a sub-table).</p>
<div dir="auto" data-snippet-clipboard-copy-content="static const hamt_node *insert_kv(hamt_node *anchor, hash_state *hash,
                                  void *key, void *value,
                                  struct hamt_allocator *ator)
{
    /* calculate position in new table */
    uint32_t ix = hash_get_index(hash);
    uint32_t new_index = INDEX(anchor) | (1 << ix);
    int pos = get_pos(ix, new_index);
    /* extend table */
    size_t n_rows = get_popcount(INDEX(anchor));
    anchor = table_extend(ator, anchor, n_rows, ix, pos);
    if (!anchor)
        return NULL;
    hamt_node *new_table = TABLE(anchor);
    /* set new k/v pair */
    new_table[pos].as.kv.key = key;
    new_table[pos].as.kv.value = tagged(value);
    /* return a pointer to the inserted k/v pair */
    return &amp;new_table[pos];
}"><pre><span>static</span> <span>const</span> <span>hamt_node</span> <span>*</span><span>insert_kv</span>(<span>hamt_node</span> <span>*</span><span>anchor</span>, <span>hash_state</span> <span>*</span><span>hash</span>,
                                  <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>,
                                  <span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>)
{
    <span>/* calculate position in new table */</span>
    <span>uint32_t</span> <span>ix</span> <span>=</span> <span>hash_get_index</span>(<span>hash</span>);
    <span>uint32_t</span> <span>new_index</span> <span>=</span> <span>INDEX</span>(<span>anchor</span>) | (<span>1</span> &lt;&lt; <span>ix</span>);
    <span>int</span> <span>pos</span> <span>=</span> <span>get_pos</span>(<span>ix</span>, <span>new_index</span>);
    <span>/* extend table */</span>
    <span>size_t</span> <span>n_rows</span> <span>=</span> <span>get_popcount</span>(<span>INDEX</span>(<span>anchor</span>));
    <span>anchor</span> <span>=</span> <span>table_extend</span>(<span>ator</span>, <span>anchor</span>, <span>n_rows</span>, <span>ix</span>, <span>pos</span>);
    <span>if</span> (!<span>anchor</span>)
        <span>return</span> <span>NULL</span>;
    <span>hamt_node</span> <span>*</span><span>new_table</span> <span>=</span> <span>TABLE</span>(<span>anchor</span>);
    <span>/* set new k/v pair */</span>
    <span>new_table</span>[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>key</span> <span>=</span> <span>key</span>;
    <span>new_table</span>[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>value</span> <span>=</span> <span>tagged</span>(<span>value</span>);
    <span>/* return a pointer to the inserted k/v pair */</span>
    <span>return</span> <span>&amp;</span><span>new_table</span>[<span>pos</span>];
}</pre></div>
<p dir="auto">When the call to <code>search_recursive()</code> in <code>set()</code> fails with
<code>SEARCH_FAIL_KEYMISMATCH</code>, the situation is different: there is another entry
(either a key/value pair or a reference to a sub-table) in the HAMT that
currently occupies a transitionary trie location for <code>key</code>. This is expected
to happen regularly: keys are always inserted with the shortest possible trie
path that resolves hashing conflicts between <em>existing</em> keys. As more and more
entries are added to the HAMT, these paths necessarily must increase in
length. This situation is handled by <code>insert_table()</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="static const hamt_node *insert_table(hamt_node *anchor, hash_state *hash,
                                     void *key, void *value,
                                     struct hamt_allocator *ator)
{
    /* Collect everything we know about the existing value */
    hash_state *x_hash =
        &amp;(hash_state){.key = KEY(anchor),
                      .hash_fn = hash->hash_fn,
                      .hash = hash->hash_fn(KEY(anchor), hash->depth / 5),
                      .depth = hash->depth,
                      .shift = hash->shift};
    void *x_value = VALUE(anchor); /* tagged (!) value ptr */
    /* increase depth until the hashes diverge, building a list
     * of tables along the way */
    hash_state *next_hash = hash_next(hash);
    hash_state *x_next_hash = hash_next(x_hash);
    uint32_t next_index = hash_get_index(next_hash);
    uint32_t x_next_index = hash_get_index(x_next_hash);
    while (x_next_index == next_index) {
        TABLE(anchor) = table_allocate(ator, 1);
        INDEX(anchor) = (1 << next_index);
        next_hash = hash_next(next_hash);
        x_next_hash = hash_next(x_next_hash);
        next_index = hash_get_index(next_hash);
        x_next_index = hash_get_index(x_next_hash);
        anchor = TABLE(anchor);
    }
    /* the hashes are different, let's allocate a table with two
     * entries to store the existing and new values */
    TABLE(anchor) = table_allocate(ator, 2);
    INDEX(anchor) = (1 << next_index) | (1 << x_next_index);
    /* determine the proper position in the allocated table */
    int x_pos = get_pos(x_next_index, INDEX(anchor));
    int pos = get_pos(next_index, INDEX(anchor));
    /* fill in the existing value; no need to tag the value pointer
     * since it is already tagged. */
    TABLE(anchor)[x_pos].as.kv.key = (void *)x_hash->key;
    TABLE(anchor)[x_pos].as.kv.value = x_value;
    /* fill in the new key/value pair, tagging the pointer to the
     * new value to mark it as a value ptr */
    TABLE(anchor)[pos].as.kv.key = key;
    TABLE(anchor)[pos].as.kv.value = tagged(value);

    return &amp;TABLE(anchor)[pos];
}"><pre><span>static</span> <span>const</span> <span>hamt_node</span> <span>*</span><span>insert_table</span>(<span>hamt_node</span> <span>*</span><span>anchor</span>, <span>hash_state</span> <span>*</span><span>hash</span>,
                                     <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>,
                                     <span>struct</span> <span>hamt_allocator</span> <span>*</span><span>ator</span>)
{
    <span>/* Collect everything we know about the existing value */</span>
    <span>hash_state</span> <span>*</span><span>x_hash</span> <span>=</span>
        <span>&amp;</span>(<span>hash_state</span>){.<span>key</span> <span>=</span> <span>KEY</span>(<span>anchor</span>),
                      .<span>hash_fn</span> <span>=</span> <span>hash</span><span>-&gt;</span><span>hash_fn</span>,
                      .<span>hash</span> <span>=</span> <span>hash</span><span>-&gt;</span><span>hash_fn</span>(<span>KEY</span>(<span>anchor</span>), <span>hash</span><span>-&gt;</span><span>depth</span> / <span>5</span>),
                      .<span>depth</span> <span>=</span> <span>hash</span><span>-&gt;</span><span>depth</span>,
                      .<span>shift</span> <span>=</span> <span>hash</span><span>-&gt;</span><span>shift</span>};
    <span>void</span> <span>*</span><span>x_value</span> <span>=</span> <span>VALUE</span>(<span>anchor</span>); <span>/* tagged (!) value ptr */</span>
    <span>/* increase depth until the hashes diverge, building a list</span>
<span>     * of tables along the way */</span>
    <span>hash_state</span> <span>*</span><span>next_hash</span> <span>=</span> <span>hash_next</span>(<span>hash</span>);
    <span>hash_state</span> <span>*</span><span>x_next_hash</span> <span>=</span> <span>hash_next</span>(<span>x_hash</span>);
    <span>uint32_t</span> <span>next_index</span> <span>=</span> <span>hash_get_index</span>(<span>next_hash</span>);
    <span>uint32_t</span> <span>x_next_index</span> <span>=</span> <span>hash_get_index</span>(<span>x_next_hash</span>);
    <span>while</span> (<span>x_next_index</span> <span>==</span> <span>next_index</span>) {
        <span>TABLE</span>(<span>anchor</span>) <span>=</span> <span>table_allocate</span>(<span>ator</span>, <span>1</span>);
        <span>INDEX</span>(<span>anchor</span>) <span>=</span> (<span>1</span> &lt;&lt; <span>next_index</span>);
        <span>next_hash</span> <span>=</span> <span>hash_next</span>(<span>next_hash</span>);
        <span>x_next_hash</span> <span>=</span> <span>hash_next</span>(<span>x_next_hash</span>);
        <span>next_index</span> <span>=</span> <span>hash_get_index</span>(<span>next_hash</span>);
        <span>x_next_index</span> <span>=</span> <span>hash_get_index</span>(<span>x_next_hash</span>);
        <span>anchor</span> <span>=</span> <span>TABLE</span>(<span>anchor</span>);
    }
    <span>/* the hashes are different, let's allocate a table with two</span>
<span>     * entries to store the existing and new values */</span>
    <span>TABLE</span>(<span>anchor</span>) <span>=</span> <span>table_allocate</span>(<span>ator</span>, <span>2</span>);
    <span>INDEX</span>(<span>anchor</span>) <span>=</span> (<span>1</span> &lt;&lt; <span>next_index</span>) | (<span>1</span> &lt;&lt; <span>x_next_index</span>);
    <span>/* determine the proper position in the allocated table */</span>
    <span>int</span> <span>x_pos</span> <span>=</span> <span>get_pos</span>(<span>x_next_index</span>, <span>INDEX</span>(<span>anchor</span>));
    <span>int</span> <span>pos</span> <span>=</span> <span>get_pos</span>(<span>next_index</span>, <span>INDEX</span>(<span>anchor</span>));
    <span>/* fill in the existing value; no need to tag the value pointer</span>
<span>     * since it is already tagged. */</span>
    <span>TABLE</span>(<span>anchor</span>)[<span>x_pos</span>].<span>as</span>.<span>kv</span>.<span>key</span> <span>=</span> (<span>void</span> <span>*</span>)<span>x_hash</span><span>-&gt;</span><span>key</span>;
    <span>TABLE</span>(<span>anchor</span>)[<span>x_pos</span>].<span>as</span>.<span>kv</span>.<span>value</span> <span>=</span> <span>x_value</span>;
    <span>/* fill in the new key/value pair, tagging the pointer to the</span>
<span>     * new value to mark it as a value ptr */</span>
    <span>TABLE</span>(<span>anchor</span>)[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>key</span> <span>=</span> <span>key</span>;
    <span>TABLE</span>(<span>anchor</span>)[<span>pos</span>].<span>as</span>.<span>kv</span>.<span>value</span> <span>=</span> <span>tagged</span>(<span>value</span>);

    <span>return</span> <span>&amp;</span><span>TABLE</span>(<span>anchor</span>)[<span>pos</span>];
}</pre></div>
<p dir="auto"><code>insert_table()</code> works in three stages: (1) it initiatlizes the <code>hash_state</code>
for the current anchor; (2) creates a series of single-entry tables until the
hashes of the current and new keys diverge; and (3) finally creates a new
table of size 2 that holds the old entry as well as the new key/value pair.</p>
<h3 tabindex="-1" dir="auto">Insert: external API</h3>
<p dir="auto">The implementation of the external API for inserting and updating values in
the HAMT is straighforward:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const void *hamt_set(struct hamt *trie, void *key, void *value)
{
    const hamt_node *n =
        set(trie, trie->root, trie->key_hash, trie->key_cmp, key, value);
    return VALUE(n);
}"><pre><span>const</span> <span>void</span> <span>*</span><span>hamt_set</span>(<span>struct</span> <span>hamt</span> <span>*</span><span>trie</span>, <span>void</span> <span>*</span><span>key</span>, <span>void</span> <span>*</span><span>value</span>)
{
    <span>const</span> <span>hamt_node</span> <span>*</span><span>n</span> <span>=</span>
        <span>set</span>(<span>trie</span>, <span>trie</span><span>-&gt;</span><span>root</span>, <span>trie</span><span>-&gt;</span><span>key_hash</span>, <span>trie</span><span>-&gt;</span><span>key_cmp</span>, <span>key</span>, <span>value</span>);
    <span>return</span> <span>VALUE</span>(<span>n</span>);
}</pre></div>
<p dir="auto"><code>hamt_set()</code> uses a vanilla call to the internal <code>set()</code> function and returns
a pointer to the value of the new key.</p>
<h3 tabindex="-1" dir="auto">Remove</h3>
<h3 tabindex="-1" dir="auto">Iterators</h3>
<h2 tabindex="-1" dir="auto">Persistent data structures and structural sharing</h2>
<h3 tabindex="-1" dir="auto">Path copying</h3>
<h3 tabindex="-1" dir="auto">Insert</h3>
<h3 tabindex="-1" dir="auto">Remove</h3>
<h2 tabindex="-1" dir="auto">Appendix</h2>
<h2 tabindex="-1" dir="auto">Unit testing</h2>
<p dir="auto">For testing, <code>hamt</code> uses a variant of <a href="http://www.jera.com/techinfo/jtns/jtn002.html" rel="nofollow">John Brewer's <code>minunit</code> testing
framework</a>. Minunit is extremely minimalistic and its
header-only implementation easily fits on a single page:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// test/minunit.h
#ifndef MINUNIT_H
#define MINUNIT_H

#define MU_ASSERT(test, message)                                               \
    do {                                                                       \
        if (!(test))                                                           \
            return message;                                                    \
    } while (0)
#define MU_RUN_TEST(test)                                                      \
    do {                                                                       \
        char *message = test();                                                \
        mu_tests_run++;                                                        \
        if (message)                                                           \
            return message;                                                    \
    } while (0)

#define MU_TEST_CASE(name) static char *name()
#define MU_TEST_SUITE(name) static char *name()

extern int mu_tests_run;

#endif /* !MINUNIT_H */"><pre><span>// test/minunit.h</span>
<span>#ifndef</span> <span>MINUNIT_H</span>
<span>#define</span> <span>MINUNIT_H</span>

<span>#define</span> <span>MU_ASSERT</span>(<span>test</span>, <span>message</span>)                                               \
    do {                                                                       \
        if (!(test))                                                           \
            return message;                                                    \
    } while (0)
<span>#define</span> <span>MU_RUN_TEST</span>(<span>test</span>)                                                      \
    do {                                                                       \
        char *message = test();                                                \
        mu_tests_run++;                                                        \
        if (message)                                                           \
            return message;                                                    \
    } while (0)

<span>#define</span> <span>MU_TEST_CASE</span>(<span>name</span>) static char *name()
<span>#define</span> <span>MU_TEST_SUITE</span>(<span>name</span>) static char *name()

<span>extern</span> <span>int</span> <span>mu_tests_run</span>;

<span>#endif</span> <span>/* !MINUNIT_H */</span></pre></div>
<p dir="auto">With <code>minunit</code>, every unit test is a <code>MU_TEST_CASE</code> We use <code>MU_ASSERT</code> to test
the test invariants.  Test cases are grouped into <code>MU_TEST_SUITE</code>s as
sequential calls to <code>MU_RUN_TEST</code>.  When an assertion fails, the <code>return</code>
statement in <code>MU_ASSERT</code> short-circuts test execution and returns a non-null
pointer to the respective <code>message</code> (generally a static string). This, in turn,
causes <code>MU_RUN_TEST</code> to issue a <code>return</code> call with the string pointer,
short-circuting the remaining test suite. The header also declares a global
variable <code>mu_tests_run</code> that keeps track of the total number of executed
tests.</p>
<p dir="auto">The following listing illustrates the basic structure of unit test
implementations with <code>minunit</code>, check the <a href="https://github.com/mkirchner/hamt/blob/main/test/test_hamt.c">actual tests</a> for
a full listing.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// test/test_hamt.c
#include &quot;minunit.h&quot;
#include &quot;../src/hamt.c&quot;

int mu_tests_run = 0;

MU_TEST_CASE(test_dummy)
{
    /* do something here */
    MU_ASSERT(0 == 0, &quot;Oops X-{&quot;);
    return 0;
}

MU_TEST_SUITE(test_suite)
{
    /* Add tests here */
    MU_RUN_TEST(test_dummy);
    /*
     * ... many more ...
     */
    return 0;
}

int main()
{
    printf(&quot;---=[ Hash array mapped trie tests\n&quot;);
    char *result = test_suite();
    if (result != 0) {
        printf(&quot;%s\n&quot;, result);
    } else {
        printf(&quot;All tests passed.\n&quot;);
    }
    printf(&quot;Tests run: %d\n&quot;, tests_run);
    return result != 0;
}"><pre><span>// test/test_hamt.c</span>
<span>#include</span> <span>"minunit.h"</span>
<span>#include</span> <span>"../src/hamt.c"</span>

<span>int</span> <span>mu_tests_run</span> <span>=</span> <span>0</span>;

<span>MU_TEST_CASE</span>(<span>test_dummy</span>)
{
    <span>/* do something here */</span>
    <span>MU_ASSERT</span>(<span>0</span> <span>==</span> <span>0</span>, <span>"Oops X-{"</span>);
    <span>return</span> <span>0</span>;
}

<span>MU_TEST_SUITE</span>(<span>test_suite</span>)
{
    <span>/* Add tests here */</span>
    <span>MU_RUN_TEST</span>(<span>test_dummy</span>);
    <span>/*</span>
<span>     * ... many more ...</span>
<span>     */</span>
    <span>return</span> <span>0</span>;
}

<span>int</span> <span>main</span>()
{
    <span>printf</span>(<span>"---=[ Hash array mapped trie tests\n"</span>);
    <span>char</span> <span>*</span><span>result</span> <span>=</span> <span>test_suite</span>();
    <span>if</span> (<span>result</span> <span>!=</span> <span>0</span>) {
        <span>printf</span>(<span>"%s\n"</span>, <span>result</span>);
    } <span>else</span> {
        <span>printf</span>(<span>"All tests passed.\n"</span>);
    }
    <span>printf</span>(<span>"Tests run: %d\n"</span>, <span>tests_run</span>);
    <span>return</span> <span>result</span> <span>!=</span> <span>0</span>;
}</pre></div>
<p dir="auto">Note that the test setup <code>include</code>s the <code>hamt.c</code> implementation file. This is a
common trick used in unit testing to gain easy access to testing <code>static</code>
functions that would otherwise be inaccessible since they are local to the
<code>hamt.c</code> compilation unit. This requires some care in
the Makefile setup in order to avoid symbol duplication.</p>
<h2 tabindex="-1" dir="auto">Footnotes</h2>
<p dir="auto"><b id="user-content-fn_hash_table_cpp">[1]</b>
The <code>std::unordered_*</code> methods implement open hashing (aka separate chaining),
with the hash table being an array of buckets, each pointing to the head of a
linked list. This is a deliberate and reasonable compromise for general use;
gaining an order of magnitude of speed improvements for specialized use cases
(e.g. append-only, guaranteed high-quality hash functions) is possible. See
<a href="https://stackoverflow.com/a/31113618" rel="nofollow">this stackoverflow post</a> for a summary of the <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2003/n1456.html" rel="nofollow">standard
proposal</a>.
<a href="#ac_hash_table_cpp"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
<p dir="auto"><b id="user-content-fn_hash_table_c">[2]</b>
<code>musl</code> provides a <code>hsearch</code> implementation that uses closed hashing with
quadratic probing for conflict resolution. The
<a href="https://git.musl-libc.org/cgit/musl/tree/src/search/hsearch.c" rel="nofollow">documentation</a> states that they use powers of two for
table sizing which seems wrong due to the impact on the modulo (table sizes
should ideally be prime). The GLib <code>GHashTable</code> has surprisingly little
documentation in its implementation details but <a href="https://gitlab.gnome.org/GNOME/glib/-/blob/main/glib/ghash.c" rel="nofollow">appears to be
using</a> a separate chaining approach similar to the C++
solution.
<a href="#ac_hash_table_c"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
<p dir="auto"><b id="user-content-fn_hash_table_python">[3]</b> Python's <code>dict</code> implementation uses
closed hashing (aka open addressing) with pseudo-random probing to mitigate
the poor hashing properties of standard python <code>hash()</code> function for some data
types (from <a href="https://stackoverflow.com/a/9022835" rel="nofollow">here</a>). Python keeps the load factor below
0.66; this avoids gradual performance degradation associated w/ high load
factors in closed hashing but comes at increased memory footprint. The
<a href="https://github.com/python/cpython/blob/main/Objects/dictobject.c">codebase</a> was refactored to split the actual data from the
hash table in 3.6, resulting in better memory efficiency and GC friendliness
(see <a href="https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html" rel="nofollow">here</a> and <a href="https://mail.python.org/pipermail/python-dev/2012-December/123028.html" rel="nofollow">here</a>).
<a href="#ac_hash_table_python"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
<p dir="auto"><b id="user-content-fn_hash_table_java">[4]</b> Java provides <code>Hashtable&lt;K,V&gt;</code> and
<code>HashMap&lt;K,V&gt;</code>, both of which implement <code>Map</code> and <code>Collection</code> interfaces; in
addition, <code>Hashtable</code> is synchronized. The <code>HashSet</code> type internally uses a
<code>HashMap</code>. <code>Hashtable</code> and <code>HashMap</code> implement open hashing
(separate chaining) with a default load factor of 0.75; The OpenJDK
implementation of <code>HashMap</code> converts
between linked list and tree representations in the hash buckets, depending on
bucket size, see <a href="https://github.com/openjdk/jdk17/blob/74007890bb9a3fa3a65683a3f480e399f2b1a0b6/src/java.base/share/classes/java/util/HashMap.java">the source</a>.
<a href="#ac_hash_table_java"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
<p dir="auto"><b id="user-content-fn_cpp_virtual_method_table">[5]</b>
There are alternative approaches to enable (somewhat) typesafe templating in
C, mainly by implementing what basically amounts to virtual method tables
using the C preprocessor. See e.g. <a href="https://stackoverflow.com/questions/10950828/simulation-of-templates-in-c-for-a-queue-data-type/11035347" rel="nofollow">here</a> for a useful stackoverflow
summary or <a href="http://blog.pkh.me/p/20-templating-in-c.html" rel="nofollow">here</a> for a more in-depth treatise.
<a href="#ac_cpp_virtual_method_table"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2048 Bit RSA and the Year 2030 (184 pts)]]></title>
            <link>https://articles.59.ca/doku.php?id=em:20482030</link>
            <guid>36672115</guid>
            <pubDate>Mon, 10 Jul 2023 19:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://articles.59.ca/doku.php?id=em:20482030">https://articles.59.ca/doku.php?id=em:20482030</a>, See on <a href="https://news.ycombinator.com/item?id=36672115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
                                                            <!-- wikipage start -->
                    <!-- TOC START -->
<div id="dw__toc">
<h3>Table of Contents</h3>

</div>
<!-- TOC END -->


<p>
In the course of some recent work I developed the impression that 2048 RSA was quite secure. Canada<sup><a href="#fn__1" id="fnt__1">1)</a></sup> (my country of residence) and others
<sup><a href="#fn__2" id="fnt__2">2)</a></sup> are currently strongly suggesting that 2048 bit RSA should be considered potentially insecure after the year 2030 and that the minimum length considered secure should be then be 3072 bits. That is only 7 years from now (2023).
</p>

<h2 id="where_did_the_2030_cutoff_come_from">Where did the 2030 cutoff come from?</h2>
<div>

<p>
I am reasonably certain that the ideas here came from an influential paper released in 2004 by Arjen K. Lenstra<sup><a href="#fn__3" id="fnt__3">3)</a></sup> that showed this year in a table. Here is a simplified version of the table:
</p>
<div><table>
	<thead>
	<tr>
		<th> Modulus Bit Length </th><th> Conservative Year </th><th> Optimistic Year </th>
	</tr>
	</thead>
	<tbody><tr>
		<td> 1024 </td><td> 2006 </td><td> 2006 </td>
	</tr>
	<tr>
		<td> 1280 </td><td> 2014 </td><td> 2017 </td>
	</tr>
	<tr>
		<td> 1536 </td><td> 2020 </td><td> 2025 </td>
	</tr>
	<tr>
		<td> 2048 </td><td> 2030 </td><td> 2040 </td>
	</tr>
	<tr>
		<td> 3072 </td><td> 2046 </td><td> 2065 </td>
	</tr>
	<tr>
		<td> 4096 </td><td> 2060 </td><td> 2085 </td>
	</tr>
	<tr>
		<td> 8192 </td><td> 2100 </td><td> 2142 </td>
	</tr>
</tbody></table></div>

<p>
<em><sub>Common RSA modulus bit-length life spans. Table 4 from: <a href="https://infoscience.epfl.ch/record/164539/files/NPDF-32.pdf" target="_tab" title="https://infoscience.epfl.ch/record/164539/files/NPDF-32.pdf" rel="ugc nofollow noopener">Key Lengths</a></sub></em>
</p>

<p>
So we look at the 2048 bit row, decide we do not feel all that optimistic, and then choose 2030 as the cutoff date. Simple. Straightforward. Definite. Great for long term planning…
</p>

<p>
Lenstra's prediction was largely based on two observations:
</p>
<ul>
<li><p> That the performance of computing technology was doubling every 18 months.</p>
</li>
<li><p> That the increase of factoring efficiency due to software improvement was doubling every 18 months.</p>
</li>
</ul>

<p>
Combining the two observations means that as of 2004, the capability to attack RSA 2048 was doubling every 9 months. Then 2004 to 2030 is 26 years or 312 months or 35 doublings. That is a capability increase of 2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2×2 or 2<sup>35</sup> in exponential notation which works out to a predicted capability increase of 34,359,738,368 times as of 2030. So around 34 billion (34×10<sup>9</sup>) times. This figure can be interpreted as how far 2048 bit RSA encryption was out of reach as of 2004. This is what that increase looks like on a plot:
</p>

<p>
<a href="https://articles.59.ca/lib/exe/detail.php?id=em%3A20482030&amp;media=em:9m0430.svg" target="_tab" title="em:9m0430.svg" rel="noopener"><img src="https://articles.59.ca/lib/exe/fetch.php?media=em:9m0430.svg" loading="lazy" alt=""></a><br>

<em><sub>Doubling every 9 months from 2004 to 2030</sub></em>
</p>

<p>
This sort of curve and this sort of increase is called “exponential” after exponential notation. It is well known that any physical quantity can not increase in this way past a certain point. There is a common and ancient story that illustrates this principle in a way quite appropriate to this discussion:
</p>

<p>
Someone is to be rewarded. As a reward, they ask that the following process be completed and that they should then be rewarded with the resultant number of wheat/rice grains.
</p>

<p>
Place a single grain on the first square of a chessboard. Place double that number of grains (2) on the next empty square. Then double <em>that</em> number of wheat grains (4) on the next empty square. If you fill all 64 squares of the chessboard, doubling each time, you end up with an amount of wheat some thousands of times more than the entire yearly production of wheat on the entire planet. Obviously this process can never be completed. The exponential nature of the increase precludes that<sup><a href="#fn__4" id="fnt__4">4)</a></sup>. An appropriate quote:
</p>
<blockquote><p>
Exponentials can't go on forever, because they will gobble up everything.<br>
</p></blockquote>

<p>
<sub>Carl Sagan, <em>Billions and Billions: Thoughts On Life And Death At the Brink Of The Millennium</em></sub>
</p>

<p>
Having seen that we have a predicted exponential increase of RSA factoring<sup><a href="#fn__5" id="fnt__5">5)</a></sup> capability here, an important task will be to determine if a limit has yet occurred that would prevent that predicted increase.
</p>

</div>

<h2 id="how_did_things_actually_go">How did things actually go?</h2>
<div>

<p>
The best we can do here is to look at the length of the numbers, of the sort relevant to RSA, that have been actually factored. So far, the largest number is 829 bits long<sup><a href="#fn__6" id="fnt__6">6)</a></sup> which was factored in 2020. Late in 2003, a 576 bit number was factored. Here is a plot of those factoring achievements, including the ones between them:
</p>

<p>
<a href="https://articles.59.ca/lib/exe/detail.php?id=em%3A20482030&amp;media=em:factoring.svg" target="_tab" title="em:factoring.svg" rel="noopener"><img src="https://articles.59.ca/lib/exe/fetch.php?media=em:factoring.svg" loading="lazy" alt=""></a>
</p>

<p>
I ignored the impression that the increase in factoring capability seems to have levelled off after 2009 and added a linear extrapolation based on the record factorizations over the entire predicted interval. The result (1024 bits by 2030) was still quite underwhelming. One would expect a more definite trend if the capability was increasing exponentially. The increasing trend is not enough to make us think that 2048 bit RSA would be under threat by 2030.
</p>

<p>
If the actual factoring demonstrations <em>had</em> shown a more definite upward trend then we could assume that the researchers were simply funded at a lower level than, say, some over funded state run signals intelligence agency and that there was the possibility of a genuine threat. But as it is, this is just inconclusive for our purposes. There are any number of reasons that less time and fewer resources might be allocated to these factoring demonstrations. We have to find another way to approach this question.
</p>

</div>

<h2 id="how_are_the_basic_assumptions_holding_up_so_far">How are the basic assumptions holding up so far?</h2>
<p>
Let's consider the two basic assumptions that the prediction was based on:
</p>

<h3 id="factoring_algorithm_performance">Factoring Algorithm Performance</h3>
<div>

<p>
The assumption is that the increase of factoring efficiency due to software improvement will double every 18 months. 
</p>

<p>
It isn't normally possible to predict the rate of software efficiency increase. It is safe to assume that there will be <em>some</em> increase of performance possible for a particular software system, but not how much or when. Software performance improvement, very generally, seems to have three phases:
</p>
<div><table>
	<thead>
	<tr>
		<th>Phase              </th><th> Performance Increase </th><th> Relative Complexity </th>
	</tr>
	</thead>
	<tbody><tr>
		<td>Low hanging fruit  </td><td>Large                 </td><td>Low                  </td>
	</tr>
	<tr>
		<td>High hanging fruit </td><td>Low                   </td><td>High                 </td>
	</tr>
	<tr>
		<td>New algorithm      </td><td>Small to very large   </td><td>—                  </td>
	</tr>
</tbody></table></div>

<p>
So improvement is first easy in the “low hanging fruit” phase and progressively harder in the “high hanging fruit” phase. The cost of this improvement is increased complexity. At some point someone might invent a new algorithm and the cycle can continue. The improvement that comes with a new algorithm can be very large; perhaps even enough to count as exponential if it happens more than once.
</p>

<p>
That is exactly what happened in the case of factoring algorithms in the '80s and '90s<sup><a href="#fn__7" id="fnt__7">7)</a></sup>. The <em>continued fraction factoring algorithm</em> was followed by the <em>quadratic sieve factoring algorithm</em> which was in turn followed by the <em>number field sieve</em> (NFS) algorithm. At the time of Lenstra's paper it seemed that his <em>elliptic curve method</em> might exceed the capability of the NFS algorithm.
</p>

<p>
For the 19 years from 2004 and 2023 and an assumption of 18 month doubling we end up with a predicted increase of algorithm performance of 6,502 times. It is hard to find definite figures on actual algorithm performance increase in this interval as it is mixed in with hardware performance. The CADO-NFS<sup><a href="#fn__8" id="fnt__8">8)</a></sup> system claims a performance increase of 3.2 from version 1.1 to version 2.3.0 at the 512 bit (RSA-155) level. The researchers responsible for the most recent factoring record<sup><a href="#fn__9" id="fnt__9">9)</a></sup> (829 bits) claimed a performance increase of 3-4 times. Even combining these improvements (I am not sure that is appropriate) we end up with a performance increase of 12 times which is well short of the predicted 6,502 times.
</p>

<p>
The elliptic curve method never ended up exceeding the NFS algorithm for factoring at the scale of RSA 2048. The NFS algorithm was never exceeded by any other invented algorithm. As a result the NFS algorithm is still the best available 27 years after its invention. That seems to be the reason for the severe slowdown in algorithm performance increase.
</p>

<p>
The history of computing shows that there is normally a quick burst of progress related to algorithmic performance when some particular task becomes feasible followed by a long period of very gradual improvement. The popular example of sorting is a good example. The mergesort, quicksort and heapsort algorithms were invented in 1945, 1959 and 1964 respectively. They are still in routine use today for sorting large lists of values. In retrospect it very much seems that the same sort of thing happened with respect to factoring algorithms. The complexity here seems to be high (CADO-NFS has hundreds of thousands of lines of code) so we are probably in the “high hanging fruit” phase. At this point there seems to be no reason to expect the predicted exponential increase in factoring algorithm performance (165,140 times) required to threaten 2048 bit RSA by the year 2030.
</p>

</div>

<h3 id="computing_performance">Computing Performance</h3>
<div>

<p>
The prediction is based in the assumption that the available computing performance will double every 18 months.
</p>

<p>
This assumption is popularly known as “Moore's Law”<sup><a href="#fn__10" id="fnt__10">10)</a></sup>. It has become fashionable to speculate that Moore's law is now dead. That is both true and false.
</p>

<p>
It turns out that there are two versions of Moore's law. The 18 month doubling refers to the increase in available computing performance and is appropriate to our discussion here. The original Moore's law refers to the number of <a href="https://en.wikipedia.org/wiki/Transistor" target="_tab" title="https://en.wikipedia.org/wiki/Transistor" rel="noopener">transistors</a> available on a substrate of a particular size and is now generally accepted to mean a doubling every 24 months. The 24 month law related to the number of transistors is still alive (but the rate of examples is decreasing rapidly). The 18 month performance law is the one that is dead. That's the one that the 2030 prediction is based on…
</p>

<p>
If you double the number of transistors on a substrate of a particular size then if the power consumption of those new transistors is half the power consumption of the old transistors then the result will be a substrate that produces the same amount of heat. <a href="https://en.wikipedia.org/wiki/Dennard_scaling" target="_tab" title="https://en.wikipedia.org/wiki/Dennard_scaling" rel="noopener">Dennard scaling</a> explains why this used to be the case. Otherwise, each doubling of transistors would produce more heat in the same area. That heat would quickly become unmanageable. The 18 month performance version of Moore's law depends on Dennard scaling to be practical. But Dennard scaling no longer works and as a result Moore's law 18 is dead.
</p>

<p>
This graph shows an example based on Intel processors:
</p>

<p>
<a href="https://articles.59.ca/lib/exe/detail.php?id=em%3A20482030&amp;media=em:dennard.png" target="_tab" title="em:dennard.png" rel="noopener"><img src="https://articles.59.ca/lib/exe/fetch.php?w=640&amp;tok=b6207e&amp;media=em:dennard.png" loading="lazy" alt="" width="640"></a><br>

<em><sub>From: <a href="https://www.extremetech.com/computing/116561-the-death-of-cpu-scaling-from-one-core-to-many-and-why-were-still-stuck" target="_tab" title="https://www.extremetech.com/computing/116561-the-death-of-cpu-scaling-from-one-core-to-many-and-why-were-still-stuck" rel="ugc nofollow noopener">The death of CPU scaling: From one core to many -- and why we're still stuck</a><br>

… which was from: <a href="http://www.gotw.ca/publications/concurrency-ddj.htm" target="_tab" title="http://www.gotw.ca/publications/concurrency-ddj.htm" rel="ugc nofollow noopener">The Free Lunch Is Over - A Fundamental Turn Toward Concurrency in Software</a></sub></em>
</p>

<p>
Note the logarithmic scale. The rising, roughly straight line for the number of transistors indicates that some sort of exponential increase is occurring. The qualities we are interested in, clock speed and performance per clock, have levelled off. The power consumption has levelled off because of physical limitations associated with removing heat from a substrate. Because of the end of Dennard scaling, performance is limited by the power efficiency of the transistors and the amount of heat that can be removed from the substrate. We can't make the transistors smaller in a way that would make them faster because making transistors smaller greatly decreases their power efficiency. That is mostly because of <a href="https://en.wikipedia.org/wiki/Quantum_tunnelling" target="_tab" title="https://en.wikipedia.org/wiki/Quantum_tunnelling" rel="noopener">quantum tunnelling</a> which turned out to be a fundamental physical limit on the performance of the highest performance computing technology we have.
</p>

<p>
There it is. A physical limit that prevents an exponential increase. In retrospect, it can be seen that this limit was already preventing an exponential increase in 2004 when the prediction was made. Unfortunate timing for the one making the prediction but it makes our task here easier. There was no exponential growth of computing performance from 2004 to 2023. It is very unlikely that such growth will reappear in the 7 years before 2030.
</p>

</div>

<h2 id="where_are_we_now">Where Are We Now?</h2>
<div>

<p>
How do things look for breaking 2048 bit RSA right now in 2023?
</p>

<p>
The best available algorithm known, usable with the most powerful computers we know how to build, is NFS. So we would use the NFS algorithm.
</p>

<p>
How much computing power could be brought to bear? As a exorbitant example we could use the Bitcoin mining network. The Bitcoin mining network is a distributed network devoted to breaking a cryptographic function with a brute force search. So it would seem to be a fairly good example to use with respect to breaking RSA which is the same sort of thing.
</p>

<p>
Bitcoin mining is a process that makes money for the entity running the mining system. This financial incentive has created a situation where the mining network has expanded to what might seem a ridiculous extent. The incentive is very sensitive to the cost of electricity. As a result the mining systems are designed to be as power efficient as humanly possible. The end of Dennard scaling is very relevant here. The troublesome heat starts as expensive electricity. Even with this desperate quest for energy efficiency, it is estimated that the Bitcoin mining network consumed 1/200th (0.5%) of all the electricity generated on the entire planet<sup><a href="#fn__11" id="fnt__11">11)</a></sup>in 2021. This makes the network a good upper limit on what might be done in secret. If some over funded national signals intelligence agency built that much processing power we would be able to tell just by checking their power bill. Electricity consumption at the level of an entire country would be impossible to hide.
</p>

<p>
Let's imagine that we could magically repurpose the processing power of the entire Bitcoin mining network for breaking a single 2048 bit RSA key. This will require us to relate what the network is currently doing to the NFS algorithm. I will use the “apples to apples” relation developed in RFC3766<sup><a href="#fn__12" id="fnt__12">12)</a></sup>. It's based on the situation in 2004 but there does not seem to be a better one available. The operations that the Bitcoin network performs would seem to take roughly the same amount of processing as the operations used as a reference in RFC3766<sup><a href="#fn__13" id="fnt__13">13)</a></sup>. By RFC3766, breaking 2048 bit RSA would require 9.01×10<sup>30</sup> cryptographic operations. The Bitcoin mining network recently achieved a rate of 1.24×10<sup>28</sup> operations/year<sup><a href="#fn__14" id="fnt__14">14)</a></sup>.
</p>

<p>
So using the power of the largest amount of computing ever dedicated to breaking cryptographic operations in history, it would take  9.01×10<sup>30</sup>/1.24×10<sup>28</sup> years to break one RSA key. That works out to 727 years. If we could magically create enough physical hardware to break a RSA key in a year then we would need to come up with 727/200 or 3.6 times the amount of electricity currently generated on the planet to run that hardware.
</p>

<p>
This only compares the amount of computing power required to break 2048 bit RSA vs the amount of computing power embodied by the Bitcoin mining network. The operations that the Bitcoin network do require very little memory/RAM. The NFS algorithm on the other hand requires a tremendous amount of memory. In 2004, R. D. Silverman pushed back against the idea that 1024 bit RSA was at imminent risk of compromise. As part of that argument he pointed out that the NFS algorithm has a phase (matrix reduction) that requires a large amount of computing power tightly coupled to a large amount of memory. On the basis of that observation he predicted that 1024 bit RSA would not be publicly broken before the 2030s. So far that prediction seems on track. In passing he mentioned that 2048 bit RSA would require 10<sup>18</sup> bytes of memory for the irreducible matrix reduction step<sup><a href="#fn__15" id="fnt__15">15)</a></sup>. That's a million terabytes, an unimaginable amount of memory to be found in one place, much less tightly coupled to enough processing power to provide any practical benefit. Speaking of memory, the speed of DRAM has lagged to be something like a hundred times slower than processing and sieving is likely very cache unfriendly. So the idea that the processing power of the Bitcoin network could break a single 2048 bit RSA key in a mere 727 years is hopelessly optimistic.
</p>

<p>
It is clear that 2048 bit RSA is vastly out of the scope of current computing technology running the best available algorithm (NFS)…
</p>

</div>

<h2 id="the_future">The future</h2>
<div>

<p>
It appears that a fundamental algorithmic breakthrough would be a prerequisite to threaten the security of RSA 2048. How likely is such a breakthrough?
</p>

<p>
Factoring, prime numbers and the relationship between the two subjects have fascinated humanity for a very long time. The fundamental idea of sieving as a fast method of finding a lot of primes has been around for thousands of years<sup><a href="#fn__16" id="fnt__16">16)</a></sup> (Number Field <em>Sieve</em>, Quadratic <em>Sieve</em>).
</p>

<p>
When creating advanced factoring algorithms there is a vast amount of historical knowledge available. This is very well trodden ground. I think this reduces the chances of surprising insights and reduces the advantage to those working in secret.
</p>

</div>

<h3 id="quantum_computing">Quantum computing</h3>
<div>

<p>
Quantum computing of the sort intended to break RSA involves a breakthrough in both computing and algorithms. Normally some sort of new computing technology is invented and then algorithms are designed to enable that technology to do something useful. The quantum computing threat to RSA is different. We now have the algorithm (Shor's) but the computer to run it on only exists in our imagination.
</p>

<p>
If someone were to invent such a computer then RSA 2048 would be immediately and trivially breakable. RSA 3072 would also be trivially breakable. The same applies to RSA 4096 and 8192. The threat here is admittedly hypothetical, but this still serves as an example of a situation where routine key length extension is of no real value. By repeatedly increasing the size of keys we are betting that a breakthrough will be exactly strong enough to break the superseded key length and not break the current key length. That seems unlikely.
</p>

<p>
New threats tend to take a different form than old threats…
</p>

</div>

<h2 id="conclusion">Conclusion</h2>
<div>

<p>
The assumptions that the 2030 date for increasing RSA key length were based on turned out to be invalid. A check of current capability confirms this. There seems to be no rational reason to increase RSA key sizes past 2048 starting in the year 2030. We don't have any reason to increase RSA key sizes at <em>any</em> time based on our current understanding.
</p>
<blockquote><p>
Although this type of estimates is the best that can be done at this point, it should be understood that actual factoring capabilities may follow an entirely different pattern. Any prediction more than a few decades away about security levels is wishful thinking. The figures in the tables should be properly interpreted, namely as today’s best estimates that may have to be revised tomorrow. Anyone using factoring based asymmetric cryptosystems should constantly monitor and stay ahead of the developments in the research community.</p></blockquote>

<p>
The proceeding quoted text is found with the previously shown “Common RSA modulus bit-length life spans” table in the original paper. If you don't believe me you should still believe Dr. A. K. Lenstra, the one that came up with the double exponential prediction in the first place. We should enact a continuous process of watchful waiting. Any policy changes should be done as a response to changes in the algorithmic and computing performance landscape.
</p>

<p>
This is important because an aspect like a key length is often deeply embedded in the systems protected by the associated cryptography. Rooting out and changing such aspects is normally very expensive in the sorts of systems where cryptographic protection is provided. Where this is not possible at the software level then wholesale equipment replacement is required. The time and resources expended on pointless key length increases can be more profitably used elsewhere. Longer RSA keys require more processing power to process so that pointless keylength increases waste computing resources and power as well.
</p>

</div>

<h2 id="other_systems">Other systems</h2>
<p>
Up to this point this article was made exclusively about RSA to improve readability. Let's use the ideas developed here to briefly examine some other popular cryptographic systems. I will use the NIST recommendations as the practical example<sup><a href="#fn__17" id="fnt__17">17)</a></sup><sup><a href="#fn__18" id="fnt__18">18)</a></sup>. The period for all of these NIST recommendations is from 2019 to 2030 (11 years). The current keysize recommendation became effective as of 2019 and the next one becomes effective as of 2030.
</p>

<h3 id="discrete_logarithm">Discrete logarithm</h3>
<div>

<p>
Current group size: 2048 bits. Next group size: 3072 bits.
</p>

<p>
This is most often seen as the basis of the <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_tab" title="https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange" rel="noopener">Diffie–Hellman key exchange</a> system.
</p>

<p>
The best known algorithm to attack discrete logarithm systems is also a version of NFS. The difficulty vs RSA is slightly harder where the RSA key size is the same as the discrete logarithm group size. So the proceeding discussion about the pointlessness of increasing RSA key sizes directly applies to discrete logarithm systems.
</p>

</div>

<h3 id="elliptic_curve_based">Elliptic curve based</h3>
<div>

<p>
Current key size: 224 bits. Next key size: 256 bits.
</p>

<p>
The rule of thumb for elliptic curves is that 2 extra key bits doubles the difficulty. That's (256-224)/2=16 difficulty doublings over the 11 year period. So an implicit assumption that the capability available for breaking elliptic curves will double every 11*12/16=8.25 months. That's a bit faster than the 9 month double exponential assumption that in turn comes from the assumption that available processing power and algorithmic capability are each doubling every 18 months. We know that that is not true for processing power. I have not been able to find any indication of a current or upcoming breakthrough in software methods for breaking elliptic curves, but I am not really qualified to judge that. So I will have to leave this here. In the absence of any evidence of a algorithmic breakthrough then the increase from 224 bits to 256 bits would be unnecessary.
</p>

<p>
Elliptic curve based systems can use much shorter key lengths than other systems. Pointlessly increasing elliptic curve key length would be tragic. If the current assumptions are maintained that would mean we would see a recommendation for more than 256 bit elliptic curve keys for the 2040 decade.
</p>

</div>

<h3 id="symmetric_encryption">Symmetric encryption</h3>
<div>

<p>
Current key size: 112 bits. Next key size: 128 bits.
</p>

<p>
Some examples of symmetric encryption schemes are: <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_tab" title="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" rel="noopener">AES</a>, <a href="https://en.wikipedia.org/wiki/Salsa20#ChaCha_variant" target="_tab" title="https://en.wikipedia.org/wiki/Salsa20#ChaCha_variant" rel="noopener">ChaCha20</a> and <a href="https://en.wikipedia.org/wiki/Camellia_(cipher)" target="_tab" title="https://en.wikipedia.org/wiki/Camellia_(cipher)" rel="noopener">Camellia</a>.
</p>

<p>
One extra key bit doubles the difficulty here. That's 128-112=16 difficulty doublings over the 11 year period. So an implicit assumption that the capability available for breaking elliptic curves will double every 11*12/16=8.25 months. That's a bit faster than the 9 month double exponential assumption that in turn comes from the assumption that available processing power and algorithmic capability are each doubling every 18 months. We know that that is not true for processing power.
</p>

<p>
The idea that the algorithmic capability against symmetric encryption might be doubling every 18 months is fairly surprising. A regular increase here is not something that is normally assumed. Perhaps there was some sort of “debt” with respect to key length that we are making up for in this time period. It might be good to apply the Bitcoin thought experiment as previously seen in this article as a sort of sanity check.
</p>

<p>
The number of cryptographic operations required to use brute force to break a 112 bit key in a symmetric system is 2<sup>112</sup>=5.19×10<sup>33</sup> operations. We will make the reasonable assumption that one Bitcoin operation would take roughly the same time as one symmetric encryption operation. Then it would take 5.19×10<sup>33</sup>/1.24×10<sup>28</sup>=418,548 years. Reducing this to a year would require 418,548/200=2092 times the current total planetary electricity production<sup><a href="#fn__19" id="fnt__19">19)</a></sup>.
</p>

<p>
It does not seem reasonable to increase minimum symmetric encryption key size past 112 bits after 2030.
</p>

<p>
<a href="https://articles.59.ca/doku.php?id=em:index" title="em:index" data-wiki-id="em:index">Encrypted Messaging index</a><br>

<a href="https://articles.59.ca/doku.php?id=start" title="start" data-wiki-id="start">Home</a>
</p>

</div>


                    <!-- wikipage stop -->
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tuition costs have risen 710% since 1983 (1200% since 1980). Inflation: 194% (658 pts)]]></title>
            <link>https://statecraft.beehiiv.com/p/student-loan-debt-forgiveness</link>
            <guid>36669253</guid>
            <pubDate>Mon, 10 Jul 2023 17:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://statecraft.beehiiv.com/p/student-loan-debt-forgiveness">https://statecraft.beehiiv.com/p/student-loan-debt-forgiveness</a>, See on <a href="https://news.ycombinator.com/item?id=36669253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-blocks"><p><i><b>Quick updates before we begin: </b></i></p><p><i><b>New Perks for Subscribers! </b></i><i>Starting today, we’ve added the following perks: </i></p><div><ul><li><p><i>Enabled comment section (leave feedback or suggest a topic!)</i></p><ul><li><p><i>We’ve already received suggestions for AI and climate topics, and those are in the works!</i></p></li></ul></li><li><p><i>Sub-only posts</i></p></li><li><p><i>Access to our full archive</i></p></li><li><p><i>Early access to interactive web and video projects</i></p></li></ul></div><p><i>Lastly, Statecraft is now available on </i><a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL25ld3MuZ29vZ2xlLmNvbS9wdWJsaWNhdGlvbnMvQ0FBcUJ3Z0tNTGFjMFFzdzliZm9Bdz9jZWlkPUNBOmVuJm9jPTMiLCJwb3N0X2lkIjoiODU0YzFlMDgtOTQyMi00ZjZiLWE0ODItNTI3M2Y0YjM5ZDM5IiwicHVibGljYXRpb25faWQiOiJkMWI4MGM5My1lODI4LTRhOTQtOTlkNC1lYzgyYTE0MzAyOGEiLCJ2aXNpdF90b2tlbiI6IjQ3Njc2MDU4LTEwMzctNDY4MC05YjcwLTBjYjIxNjQyN2RiZSIsImlhdCI6MTY4OTAxMjAwMy4zODEsImlzcyI6Im9yY2hpZCJ9.YMZWkJXYt0PLse4X9xGH-asL9J3XH3LbYflfs0C5J1g" target="_blank" rel="noopener noreferrer nofollow"><i>Google News</i></a><i>! </i>🎉<i>&nbsp;</i></p><p> The outstanding student loan debt in the United States is <b>1.78 trillion dollars</b>. For reference, the GDPs of developed countries like South Korea, Australia, and oil-rich Saudi Arabia are less than $1.7T respectively. The explosion in tuition costs and associated debt accumulation is undeniably a looming economic crisis. It’s a crisis that requires a basket of policy solutions to transform higher education from the bottom up - including, yes, cancellation of some federal student loans. But while the fight to cancel student loan debt <a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3d3dy53aGl0ZWhvdXNlLmdvdi9icmllZmluZy1yb29tL3N0YXRlbWVudHMtcmVsZWFzZXMvMjAyMi8wOC8yNC9mYWN0LXNoZWV0LXByZXNpZGVudC1iaWRlbi1hbm5vdW5jZXMtc3R1ZGVudC1sb2FuLXJlbGllZi1mb3ItYm9ycm93ZXJzLXdoby1uZWVkLWl0LW1vc3QvP3V0bV9zb3VyY2U9c3RhdGVjcmFmdC5iZWVoaWl2LmNvbSZ1dG1fbWVkaXVtPXJlZmVycmFsJnV0bV9jYW1wYWlnbj13ZS13ZXJlbi10LXJlYWR5LWZvci1hLTcxMC1yaXNlLWluLXR1aXRpb24tY29zdHMiLCJwb3N0X2lkIjoiODU0YzFlMDgtOTQyMi00ZjZiLWE0ODItNTI3M2Y0YjM5ZDM5IiwicHVibGljYXRpb25faWQiOiJkMWI4MGM5My1lODI4LTRhOTQtOTlkNC1lYzgyYTE0MzAyOGEiLCJ2aXNpdF90b2tlbiI6IjQ3Njc2MDU4LTEwMzctNDY4MC05YjcwLTBjYjIxNjQyN2RiZSIsImlhdCI6MTY4OTAxMjAwMy4zODIsImlzcyI6Im9yY2hpZCJ9.TbC4ohDc8GWT4aCRNVhqLlvS81GLNaPsRD2whAgXK1E" target="_blank" rel="noopener noreferrer nofollow">continues</a>, we think it would be especially worthwhile to explore some data and highlight potential solutions for this debt burden. </p><p><h3>📈 How We Got Here</h3></p><p> Tuition cost and fee inflation have outpaced CPI Inflation 4-to-1 over the last 40 years: </p><div><p><img alt="" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/33ae477a-f0ea-4d56-a664-710b346bf8cf/inflation_capture.png"></p><p><small><p>Animated versions of these charts on Threads (or Twitter): @theArmanMadani</p></small></p></div><p> The resulting $1.78T of debt includes $1.65T that is federally owned (93%). 45M Americans have federal student loan debt. Roughly half of all the debt belongs to individuals with graduate degrees while the other half belongs to individuals with undergraduate degrees; though it’s worth noting that there are fewer graduate students overall so the debt held per student is higher for graduates: </p><div><p><img alt="" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/98cda4db-b39d-47e8-98f9-5dc3f95d832e/TotalDebtCapture.jpg"></p><p><small><p>Animated versions of these charts on Threads (or Twitter): @theArmanMadani</p></small></p></div><p><b>Student enrollment in higher ed institutions has </b><a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3d3dy5zdGF0aXN0YS5jb20vc3RhdGlzdGljcy8xODM5OTUvdXMtY29sbGVnZS1lbnJvbGxtZW50LWFuZC1wcm9qZWN0aW9ucy1pbi1wdWJsaWMtYW5kLXByaXZhdGUtaW5zdGl0dXRpb25zLz91dG1fc291cmNlPXN0YXRlY3JhZnQuYmVlaGlpdi5jb20mdXRtX21lZGl1bT1yZWZlcnJhbCZ1dG1fY2FtcGFpZ249d2Utd2VyZW4tdC1yZWFkeS1mb3ItYS03MTAtcmlzZS1pbi10dWl0aW9uLWNvc3RzIiwicG9zdF9pZCI6Ijg1NGMxZTA4LTk0MjItNGY2Yi1hNDgyLTUyNzNmNGIzOWQzOSIsInB1YmxpY2F0aW9uX2lkIjoiZDFiODBjOTMtZTgyOC00YTk0LTk5ZDQtZWM4MmExNDMwMjhhIiwidmlzaXRfdG9rZW4iOiI0NzY3NjA1OC0xMDM3LTQ2ODAtOWI3MC0wY2IyMTY0MjdkYmUiLCJpYXQiOjE2ODkwMTIwMDMuMzgyLCJpc3MiOiJvcmNoaWQifQ.syv1ZnkHSR_7B0ialU7w22IbaGYPuInRtz-3KPUDXic" target="_blank" rel="noopener noreferrer nofollow"><b>risen consistently since 2000</b></a>. With higher demand for college degrees - including out-of-state demand for state universities - tuition has risen precipitously. Rising enrollment is also associated with a changing <a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3d3dy5zdGF0aXN0YS5jb20vdG9waWNzLzc3MS9lbXBsb3ltZW50Lz91dG1fc291cmNlPXN0YXRlY3JhZnQuYmVlaGlpdi5jb20mdXRtX21lZGl1bT1yZWZlcnJhbCZ1dG1fY2FtcGFpZ249d2Utd2VyZW4tdC1yZWFkeS1mb3ItYS03MTAtcmlzZS1pbi10dWl0aW9uLWNvc3RzI3RvcGljT3ZlcnZpZXciLCJwb3N0X2lkIjoiODU0YzFlMDgtOTQyMi00ZjZiLWE0ODItNTI3M2Y0YjM5ZDM5IiwicHVibGljYXRpb25faWQiOiJkMWI4MGM5My1lODI4LTRhOTQtOTlkNC1lYzgyYTE0MzAyOGEiLCJ2aXNpdF90b2tlbiI6IjQ3Njc2MDU4LTEwMzctNDY4MC05YjcwLTBjYjIxNjQyN2RiZSIsImlhdCI6MTY4OTAxMjAwMy4zODIsImlzcyI6Im9yY2hpZCJ9.0u-HWi65MIPQbv9rF94ngToxvo3-H3xf_iibpMZwDIU" target="_blank" rel="noopener noreferrer nofollow">US labor profile</a>; for example, manufacturing jobs were eclipsed by “business and professional services” jobs as well as healthcare, education, and retail jobs. One troubling manifestation of the demand for higher degrees can be seen during the 2008-09 Recession as newly unemployed individuals scrambled for retraining. From 2008 through 2009, enrollment in private for-profit colleges rose disproportionately compared to private non-profit and public colleges. Private for-profit colleges have <a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2VkdWNhdGlvbmRhdGEub3JnL3N0dWRlbnQtbG9hbi1kZWZhdWx0LXJhdGU_dXRtX3NvdXJjZT1zdGF0ZWNyYWZ0LmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXdlLXdlcmVuLXQtcmVhZHktZm9yLWEtNzEwLXJpc2UtaW4tdHVpdGlvbi1jb3N0cyIsInBvc3RfaWQiOiI4NTRjMWUwOC05NDIyLTRmNmItYTQ4Mi01MjczZjRiMzlkMzkiLCJwdWJsaWNhdGlvbl9pZCI6ImQxYjgwYzkzLWU4MjgtNGE5NC05OWQ0LWVjODJhMTQzMDI4YSIsInZpc2l0X3Rva2VuIjoiNDc2NzYwNTgtMTAzNy00NjgwLTliNzAtMGNiMjE2NDI3ZGJlIiwiaWF0IjoxNjg5MDEyMDAzLjM4MiwiaXNzIjoib3JjaGlkIn0.-8EXNxtP3mX6u68fZeH1Y6Dbz7SOxEOYlb5VcgJofFE" target="_blank" rel="noopener noreferrer nofollow">extraordinarily high rates of default</a>, near 16% of borrowers default within 3 years. </p><p><img alt="" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/ccaaffe9-1806-4cae-8fad-4bbb1da00da6/image.png"></p><p> During this period of heightened demand, a more obvious inflationary effect took place: <b><a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3d3dy5uZWEub3JnL2Fkdm9jYXRpbmctZm9yLWNoYW5nZS9uZXctZnJvbS1uZWEvc3RhdGUtZnVuZGluZy1oaWdoZXItZWR1Y2F0aW9uLXN0aWxsLWxhZ2dpbmc_dXRtX3NvdXJjZT1zdGF0ZWNyYWZ0LmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXdlLXdlcmVuLXQtcmVhZHktZm9yLWEtNzEwLXJpc2UtaW4tdHVpdGlvbi1jb3N0cyM6fjp0ZXh0PVdoZW4lMjBzdGF0ZSUyMGxhd21ha2VycyUyMHR1cm4lMjB0aGVpcixkb3duJTJDJTIwc3R1ZGVudCUyMHR1aXRpb24lMjBnb2VzJTIwdXAuIiwicG9zdF9pZCI6Ijg1NGMxZTA4LTk0MjItNGY2Yi1hNDgyLTUyNzNmNGIzOWQzOSIsInB1YmxpY2F0aW9uX2lkIjoiZDFiODBjOTMtZTgyOC00YTk0LTk5ZDQtZWM4MmExNDMwMjhhIiwidmlzaXRfdG9rZW4iOiI0NzY3NjA1OC0xMDM3LTQ2ODAtOWI3MC0wY2IyMTY0MjdkYmUiLCJpYXQiOjE2ODkwMTIwMDMuMzgyLCJpc3MiOiJvcmNoaWQifQ.VIfYccx1zSUkzhZU--9xiKvePMPUk1LdVSt0esoPxrI" target="_blank" rel="noopener noreferrer nofollow">state funds were cut</a></b><b> for public colleges on a per-student basis </b>in the run-up and fallout of the Recession. </p><p><h3>💸 What Now</h3></p><p> [WARNING: I include my opinion in this section, I look forward to a lively discussion in the comment section] </p><p> There are short and long-term solutions needed to address the debt problem. </p><p> Short-term, students need recourse. Defaulting on loans creates a cascade of consequences that necessarily harm borrowers earning potential for years (e.g. colleges can withholding proof of attendance, decline in credit score, wage garnishments, etc.) There are loans that are highly likely to default regardless after the COVID moratorium on payments ends. These loans should be forgiven/cancelled. The fallout of default en masse - especially amongst low and middle-income degree holders - would present a much greater cost to the economy than the cost of cancellation. Additionally, controlling what information can be reported to credit bureaus (like medical debt) and regulating what information colleges can withhold would also reduce negative income effects caused by default (e.g. a private for-profit institution cannot withhold proof of attendance in the event of default). </p><p> Long-term, controlling the underlying cost of higher ed itself is an imperative. Federal support for and expansion of programs like <a href="https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3d3dy5jY2Njby5lZHUvQWJvdXQtVXMvQ2hhbmNlbGxvcnMtT2ZmaWNlL0RpdmlzaW9ucy9FZHVjYXRpb25hbC1TZXJ2aWNlcy1hbmQtU3VwcG9ydC9TdHVkZW50LVNlcnZpY2UvV2hhdC13ZS1kby9DYWxpZm9ybmlhLVByb21pc2U_dXRtX3NvdXJjZT1zdGF0ZWNyYWZ0LmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXdlLXdlcmVuLXQtcmVhZHktZm9yLWEtNzEwLXJpc2UtaW4tdHVpdGlvbi1jb3N0cyIsInBvc3RfaWQiOiI4NTRjMWUwOC05NDIyLTRmNmItYTQ4Mi01MjczZjRiMzlkMzkiLCJwdWJsaWNhdGlvbl9pZCI6ImQxYjgwYzkzLWU4MjgtNGE5NC05OWQ0LWVjODJhMTQzMDI4YSIsInZpc2l0X3Rva2VuIjoiNDc2NzYwNTgtMTAzNy00NjgwLTliNzAtMGNiMjE2NDI3ZGJlIiwiaWF0IjoxNjg5MDEyMDAzLjM4MiwiaXNzIjoib3JjaGlkIn0.46i8nRok0CXsqfgPv_peIiPNn1SIoVbsi1ofW1vypas" target="_blank" rel="noopener noreferrer nofollow">The California Promise</a> - which provides free tuition for California residents who attend CA community colleges - would eliminate the burden for some new graduates. Apportioning more existing or raising new tax revenue to invest in underfunded private colleges (e.g. HBCUs) and public colleges can reduce tuition costs by supplanting/exceeding the aforementioned state funding cuts as well. </p><p> This is a complex issue which requires comprehensive policy solutions. But one of the reasons student debt has received the attention it has is because of the opportunity it presents. An opportunity to extend a stimulus to low/middle income earners in the short-term and transform the higher education system in the long-term. </p><p><i>Thank you for reading this article! If you enjoyed it, consider sharing Statecraft with a friend. You can also connect with us on Threads, Twitter or Instagram. We’re working on our first long-form video content as well, so if you want to see what we produce, head over to YouTube or TikTok. Links below:</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Invisible Details of Interaction Design (116 pts)]]></title>
            <link>https://rauno.me/craft/interaction-design</link>
            <guid>36669249</guid>
            <pubDate>Mon, 10 Jul 2023 17:02:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rauno.me/craft/interaction-design">https://rauno.me/craft/interaction-design</a>, See on <a href="https://news.ycombinator.com/item?id=36669249">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-stage=""><p>Design can feel like there's no science to it — only feel and intuition. Even researchers have trouble grounding interaction design practices in science, inherently treating them as a mysterious black box. <sup>1</sup> While from my own experience that's partly true, I have been trying to deconstruct and dig out the <i>why</i> behind great displays of interaction design.</p><p>Searching the Internet for depth on interaction design yields a plethora of recycled content obsessing over user personas, storyboards, and Venn diagrams labeled with "UI" and "UX". Besides a few exceptional talks, actual substance and insight reveal themselves to those willing to fanatically dig for them. Either through studying obscure, long-winded research papers or by maniacally replaying hundreds of slow motion screen recordings.</p><p>Sitting down and just thinking hard does not magically produce valuable discoveries either. The essence of the word "interaction" implies a relationship between a human and an environment. In my experience, great revelations surface from making something — filling your headspace with a problem — and then going for a synthesising daydreaming walk to stir the pot.</p><p>This writing is not a tutorial nor a collection of guidelines. But rather an observation on the invisible details of a few interactions that I use often but rarely think about. Besides recreating interfaces, I found this exercise in reflection to be another great way to build a stronger design intuition and vocabulary.</p><h3 data-heading="true" id="metaphors">Metaphors</h3><p>What even is interaction design? Here's how I think about it through the lens of technology. Interaction design is an artform to make experiences that fluidly respond to human intent. When does a swipe trigger an action? Do gestures retain momentum? What happens if a finger is covering content? How can we predict intent based on context? Executing well on details like these make products feel like a natural extension of ourselves.<!-- --> <sup>2</sup></p><p>But it's not an artform in the same way as painting or composing music. There's a unique human component to interaction design. Why? Because ultimately people are trying to get stuff done using a product. Beauty in form and composition is not enough. There's an inherent satisfaction apparent in striking a holistic balance between form <i>and </i>function.</p><p>Great interaction design rewards learning by reusing metaphors. You can use most touch interfaces with just two gestures: tapping and swiping. For example, on iOS the only gesture you're explicitly taught how to do is swiping up to open:</p><p>Now you've learned swiping which unlocks control over many other parts of the interface. The sliding motion also tells you that the interface is composed of stacked layers, like a deck of cards. Knowing so, you might be enthused to try swiping down on the screen to discover more controls. Conceptually, the interface is further implicitly teaching you that swiping <i>down</i> reveals layers of system functionality. This knowledge compounds as you delve deeper into the Apple ecosystem.</p><p>We can stretch interaction design metaphors even further. Why does swiping horizontally navigate between pages? Because that's how we've intuitively interfaced with books for thousands of years.<!-- --> </p><p>Great interactions are modeled after properties from the real world, like interruptability. This sounds kinda silly because, duh, obviously flipping a page in a book is interruptible. But imagine if it were an animation that you had to wait for!</p><p>Pinching is another gesture that we've come to intuitively associate with zooming. Simply put, zooming is an act of precision — adjusting the amount of detail visible.</p><p>We can think of pinching akin to movements that require intricate motor skills, like picking up tiny objects or working with spices. Naturally, we pinch our fingers for higher precision:</p><p>Notice how pinching on a touch screen works in reverse. You start with your fingers together, and then move them apart for precision. But to grab something, you bring fingers together from afar. This is because the interface needs to first establish an anchor point from where the zooming originates.</p><p><img alt="Two app icons are in focus, both of them have the bottom 10 points duplicated and stretched for an elongated effect." loading="lazy" width="1920" height="1400" decoding="async" data-nimg="1" srcset="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpinch-anchor.09bc6fa5.png&amp;w=1920&amp;q=75 1x, https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpinch-anchor.09bc6fa5.png&amp;w=3840&amp;q=75 2x" src="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpinch-anchor.09bc6fa5.png&amp;w=3840&amp;q=75"></p><p>Scientifically or intuitively, there are hundreds of design decisions made by someone obsessesing over the tiniest margins so that when they work, no one has to think about. And many of them tap into our instinctive behaviors.</p><h3 data-heading="true" id="kinetic-physics">Kinetic Physics</h3><p>The lock screen sliding up establishes that, in essence, it's just an overlay that can be dismissed by swiping up, and within that framing so is an app. That means you also now know how to dismiss an application.</p><p>Let's take a look at how dismissing an app morphs into the Dynamic Island. Notice how the gesture retains the momentum and angle at which it was thrown. It's never perfectly centered or consistent in timing.</p><p>This movement builds on our natural sense of physics from the real world, like how swiping a playing card would feel. Although the movement of the playing card exhibits less bounce since it's conceptually lighter and does not magnetically morph into something.<!-- --> </p><h3 data-heading="true" id="swipe-gestures">Swipe Gestures</h3><p>When does a swipe trigger an action? It seems trivial: you press down, move a little, and then finally trigger an action <i>after</i> releasing the finger. After building a few touch interactions myself using SwiftUI, I realised that might not always be the case. Sometimes we expect the action to be triggered <i>whilst</i> <!-- -->swiping.</p><p>Lightweight actions, such as displaying overlays, feel more natural to trigger during the swipe after an arbitrary amount of distance. For example, with a single gesture, I can immediately grok the overlaying surface, understand that it gives me a search input, and then dismiss if it's not what I want. Waiting for the gesture to end would feel like a drag here.</p><p>Here's an example from the MercuryOS SwiftUI prototype I was working on. It feels expected to trigger an action when elements moving during the gesture reach their logical, final position. Notice how the screen is unlocked after both the titles snap to their position, and then locked with a single gesture without releasing the finger. Again, waiting for the gesture to end before unlocking would make the interface feel broken and provide less affordance.</p><p>Now, let's look at examples where triggering an action requires explicit intent. The iOS App Switcher will never dismiss an app before the gesture ends. No matter the distance or the fact that the app is partially off-screen:</p><p>This makes sense to me because dismissing an app is destructive, and it wouldn't feel nice if the app were to dismiss in the middle of the swipe. What if I were change my mind half-way through and accidentally reached the threshold for dismissing? I could potentially lose some important progress in an app! To make sure the interface responds to intent, triggering on gesture end, regardless of distance, feels right here.</p><p>Here's another example where despite swiping an adequate amount of distance for the view to be fully visible and snap, it doesn't until the gesture ends. This makes it lightweight to briefly peek at another screen when scanning for an app, without committing to it, and quickly interrupt the gesture by changing direction.</p><h3 data-heading="true" id="responsive-gestures">Responsive Gestures</h3><p>Truly fluid gestures are immediately responsive. As mentioned above, gestures can have an explicit trigger threshold, but this does not mean simply performing an animation 0 → 1 would feel great.</p><p>For example, a naive implementation for pinching a card would exponentially zoom in after a certain threshold:</p><p>Pinching an adequate amount to animate would not feel exactly broken here. But the interface gives zero affordance or confidence that the card is even pinchable with a lower velocity. Neither does this feel satisfying to perform.</p><p>It feels a lot better by feeling the scale delta applying immediately, and then performing an animation past a given threshold:</p><p>For some reason navigating iOS Settings does not feel as responsive as the App Switcher. A layer slides over from the right which tells me that it can be dismissed by swiping left. But if you happen to mistap, then swiping back immediately does not interrupt the animation. You have to wait for it to end.</p><h3 data-heading="true" id="spatial-consistency">Spatial Consistency</h3><p>The Dynamic Island has this nice interaction where on tap the application slides out under from the Island to cover the screen:</p><p>But if the Island is <i>expanded</i> which conceptually tells the interface my intent is to receive <i>more</i> <!-- -->detail, the application does not slide out from the Island. Instead, it launches from the icon, if its visible. Alternatively, the application slides in from the right:</p><p>I can only assume that by launching Spotify from the icon, it is a lot more clear where the audio is playing from. Say you had three music apps on the same row. Through motion this helps establish a relationship between the audio player and its source.</p><p>Similarly, if the app slides in from the right, it communicates where it is spatially — in the App Switcher. By moving in from the right, not left, it also signifies that the app is now first on the stack of apps in the switcher.</p><p>However, the native Clock app will never open from its icon. It always jumps out from the Island, even when expanded:</p><p>This seems to support the theory above. Because the Island timer module is only specific to one app, and there can't be another with the same Island, there's no need to make it clear where it's from.</p><h3 data-heading="true" id="fluid-morphing">Fluid Morphing</h3><p>We're all familiar with the beautifully fluid, interruptible gestures of iOS to quickly navigate apps. Swiping up morphs the full screen app into its icon:</p><p>A curious detail here is that the icon is intentionally stretched from the bottom to fill the frame as it fludily morphs its shape from a vertical rectangle to a uniform square. It's a tiny bit more obvious what happens when looking at the non-standard GitHub icon:</p><p><img alt="Two app icons are in focus, both of them have the bottom 10 points duplicated and stretched for an elongated effect." loading="lazy" width="1920" height="1080" decoding="async" data-nimg="1" srcset="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-crop.0334862c.png&amp;w=1920&amp;q=75 1x, https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-crop.0334862c.png&amp;w=3840&amp;q=75 2x" src="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-crop.0334862c.png&amp;w=3840&amp;q=75"></p><p>This technique does assume that app icons adhere to the guidelines outlined by Apple. The Bluesky icon ignores the recommended safe zone and as a result the bottom ~10pt of the icon is cropped, duplicated, and stretched, resulting in this weird repeating image effect:</p><p><img alt="The Bluesky app icon is in focus. It is an image of a blue sky with clouds. The bottom 10 points are duplicated and stretched, but because its an image, the result is an odd stretching image effect." loading="lazy" width="1920" height="1080" decoding="async" data-nimg="1" srcset="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-bsky.720d6ba8.png&amp;w=1920&amp;q=75 1x, https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-bsky.720d6ba8.png&amp;w=3840&amp;q=75 2x" src="https://rauno.me/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fiphone-close-bsky.720d6ba8.png&amp;w=3840&amp;q=75"></p><p>In practice this does not feel completely off, but definitely not as great:</p><h3 data-heading="true" id="frequency-novelty">Frequency &amp; Novelty</h3><p>As a designer, I love to animate everything. Object permanence, creating a focal point, and delight are all good reasons for doing so. But it's not so obvious when <i>not</i> to animate something.</p><p>Sometimes we can get away with not animating mouse or keyboard interactions, without it feeling jarring. There is an inherent disconnect between input from peripheral devices and what happens on the screen. Pressing a key feels less visceral, and more mechanical than touching the screen.</p><p>A good example for this would be command menus. It's tempting to throw an opacity and scale fade on the overlay.<!-- --> <!-- -->But if we for a moment consider the interaction frequency being hundreds of times a day, it does start to feel more like cognitive burden after seeing the same animation for the hundredth time. <sup>3</sup></p><p>When so commonly executed, the interaction novelty is also diminished. It doesn't feel like you're doing anything peculiar, deserving of a special flourish.</p><p>A case in point: I was working on a bookmarking tool (<a href="https://bmrks.com/" target="_blank" rel="noopener noreferrer">bmrks.com</a>) and intuitively felt great about animating the active indicator and elements being added and removed from the list:</p><p>After a couple of days they began to feel sluggish. Despite making the motion even snappier, my perceived performance was making me feel like I have to wait too much when interfacing with the keyboard. I removed motion from core interactions and suddenly felt like I was moving much faster:</p><p>Context (right-click) menus on macOS also appear without motion. Used thousands of times a day, with very low novelty and high frequency. Despite being a mouse interaction, it feels right to not animate the menu appearing:</p><p>Interestingly enough, the menu subtly fades out. On closer inspection, the selected item briefly blinks the accent color (pink) to provide assurance that the element was successfully selected. I can only assume that the menu fading out makes this feel more graceful and intentional than abruptly disappearing after the blink:</p><p>Another good example is the App Switcher on macOS which gets a lot of mileage for heavy keyboard users. The overlay never animates which makes moving between apps feel snappy:<!-- --> </p><p>Furthermore, if the time delta between pressing Command and Tab is low enough, the previously active window receives focus immediately without showing the menu:<!-- --> </p><h3 data-heading="true" id="fidgetability">Fidgetability</h3><p>Wonderful interactions don't have to be entirely practical. We've all been in math class, either biting our lips or repetitively clicking a pencil while crunching numbers. Behaviors like this are considered fidgeting. In other words, repetitive movements that apparently help release situational stress, or even enhance concentration. Although there is no scientific research that supports this claim <sup>4</sup>, fidgeting does regardless feel like a part of intentional interaction design.</p><p>Fidgetability could also be an after-thought, or a happy side-effect. However, the AirPods case is uncannily satisfying to play with. Assuming it to be a coincidence would be very generous.</p><p>Apple Pencil is a more obvious candidate to intentionally design to be fidgetable. The tip of the pencil is unscrewable which means it can be replaced eventually. Oddly enough, twisting the tip and rotating the pencil body provides satisfying friction to casually play with while thinking.</p><p>Now here's a crazy one that I would not bet my money on being intentional. Although it is dope.</p><h3 data-heading="true" id="scroll-landmarks">Scroll Landmarks</h3><p>On macOS you can always find the pointer by shaking the mouse. This interaction feels wonderful because it taps into the frustration and natural reaction that people feel when losing track of the pointer.</p><p>Something similar quite often happens to me on mobile when browsing long-form content. I've scrolled down half-way, and while reading I want to quickly recall something from above. But then I feel awkward scrolling back up because I will lose my precious scroll position and reading progress.</p><p>I made a tiny prototype where double tapping the scrollbar will place a landmark for the current scroll position. Now I could freely navigate around the page and double tap the landmark to get back to where I was before.</p><p>This feels familiar to use because the scrollbar is already interactive on touch. If you didn't know, long-pressing the scrollbar would make it draggable which is much faster to scroll quickly.</p><p>This reminds me of an old minimap prototype I made. Inspired by games where you always have a bird's eye view of the surrounding environment. Why not have a similar heads up display for navigating a page?</p><h3 data-heading="true" id="touch-content-visiblity">Touch Content Visiblity</h3><p>On touch interfaces, sometimes a finger might obfuscate what's happening on the screen which makes it hard to perform gestures at pixel-level precision. Commonly, the interface would then render a temporary representation of what's underneath the finger.</p><p>For example, on iOS when pressing down and dragging to move the text caret, a magnifying loupe will appear above the touch point. However, whenever the finger moves downwards and no longer covers the caret, the loupe disappears.</p><p>A similar detail is used for the keyboard. Pressing a key will show an enlarged key which gives you confidence that the interface understood what you meant.</p><p>It doesn't always make sense to mirror the obfuscated region. For example, sliders can be tiny and disappear under the touch of the thumb. It helps to ensure that the dragging gesture does not cancel when moving away from the slider and still pressing down:</p><p>Although seeking video is mostly a visual interaction, there's an unintelligible level of discomfort apparent when interacting with an element that you can't see.</p><p>Here's a more obvious example where it's critical to understand contents of the menu: </p><h3 data-heading="true" id="implicit-input">Implicit Input</h3><p>Forever long we've been peeling back the layers between humans and computing. Touch input elevated the relationship by introducing gestures and haptics. Soon applications will no longer be bound by the constraints of a fixed screen.</p><p>The keyboard, mouse, touch, voice are all explicit inputs. They feel like a natural extension of ourselves<!-- --> <sup>2</sup> when dialed into perfection. But isn't the mother of all inputs no input at all? When an interface makes use of context as input and can infer what you're trying to do without asking, it truly feels magical.</p><p>For example, by looking at the screen, Apple Maps will show the active route navigation without unlocking. Apple Wallet will increase the brightness when presenting a pass for scanning. Spotify will adjust the interface to be more accessible while driving.</p><p>Some custom iOS apps will blur the contents of the app when opening the App Switcher. At first, I figured it was just a performance optimization. But it turns out that it's a deliberate attempt to conceal possibly sensitive data, like medical records or a bank statement.</p><h3 data-heading="true" id="fittss-law">Fitts's Law</h3><p>Fitts's Law states that the time to click on something depends on distance and size. <sup>5</sup> The bigger the target, and the closer it is to where your pointer is, the better.</p><p>Operating systems make use of "magic corners" on the edges of the screen because the target area is infinitely large. <sup>6</sup> For example, on macOS, you can configure what happens when the pointer moves to a corner. You could show the Launchpad from the top-left corner:</p><p>The target size is infinite because the pointer can't overshoot past the corner, so the precision required for this interaction is very low. Reaching for any corner becomes a quick flick of the mouse. This is also why operating systems place commonly used menus, like the Apple menu, in corners.</p><p>Radial menus are an exemplary case of Fitts's Law. They spawn around the pointer making the size and distance towards any target the same for all actions. Over time, muscle memory will kick in and even make it possible to select an action based purely on distance and direction.</p><p>Here's a radial menu you can try:</p><div><p>Hold and rotate from anywhere</p></div><h3 data-heading="true" id="scrolling">Scrolling</h3><p>On most operating systems, you can scroll any scrollable region, even if the window itself is not active. This is great, except when another window scrolls unintentionally.</p><p>With the Magic Mouse I can scroll on a window, then move the pointer over a second window to click or find something, and the scroll events will not register on the second window. This feels great to me.</p><p>However, with any traditional mouse, like the Logitech MX Master 3, the scrolling on the first window is cancelled and hijacked by the second window. And it's really frustrating when this happens daily:</p><p>With the Magic Mouse, scrolling is cancelled explicitly by focusing another window:</p><p>Pointing devices like the Magic Trackpad and Magic Mouse also unlock direct manipulation for desktop computing. Besides the obvious ones like swiping between apps, it's also possible to directly manipulate sliders by scrolling, all with a single interaction:</p><h3 data-heading="true" id="closing-thoughts">Closing Thoughts</h3><p>For me, understanding and articulating why something feels right does not come as intuitively as<!-- --> <i>designing</i> something to feel right. But they are two sides of the same coin. There must be a reason. It can be as simple as a particular spring curve or something more innate, like metaphors. Analyzing and making sense of design details beyond just "it feels nice" helps nurture taste, amplify level of execution, and grow appreciation for how hard the pursuit of excellence is.</p><h3 data-heading="true" id="acknowledgments">Acknowledgments</h3><p>Thanks to <a href="https://twitter.com/pacocoursey" target="_blank" rel="noopener noreferrer">Paco</a>,<!-- --> <a href="https://twitter.com/almonk" target="_blank" rel="noopener noreferrer">Alasdair</a>,<!-- --> <a href="https://twitter.com/emilkowalski_" target="_blank" rel="noopener noreferrer">Emil</a>,<!-- --> <a href="https://twitter.com/thomaspaulmann" target="_blank" rel="noopener noreferrer">Thomas</a> for reading early drafts and their insights and feedback.</p><p>No artificial intelligence was used to generate content for this article.</p><h3 data-heading="true" id="resources">Resources</h3><ol><li><a href="https://summit.sfu.ca/_flysystem/fedora/sfu_migrate/15215/2011_CHI_Understanding_Goodman_vy-edited.pdf" target="_blank" rel="noopener noreferrer">E. Goodman, E. Stolterman, R. Wakkary. Understanding Interaction Design Practices (2011)</a></li><li><a href="https://developer.apple.com/videos/play/wwdc2018/803/" target="_blank" rel="noopener noreferrer">C. Karunamuni, N. Vries, M. Alonso. Designing Fluid Interfaces (2018)</a></li><li><a href="https://brandur.org/interfaces" target="_blank" rel="noopener noreferrer">Brandur. Learning From Terminals to Design the Future of User Interfaces (2017)</a></li><li><a href="https://digscholarship.unco.edu/cgi/viewcontent.cgi?article=1669&amp;context=dissertations" target="_blank" rel="noopener noreferrer">S. L. Kriescher. The Effects of Fidgets on Attention and Learning of College Students (2020)</a></li><li><a href="https://en.wikipedia.org/wiki/Fitts%27s_law" target="_blank" rel="noopener noreferrer">Paul Morris Fitts. The information capacity of the human motor system in controlling the amplitude of movement (1954)</a></li><li><a href="http://www.particletree.com/features/visualizing-fittss-law/" target="_blank" rel="noopener noreferrer">Kevin Hale. Visualizing Fitts's Law (2010)</a></li><li><a href="https://andymatuschak.org/files/papers/Apple%20Human%20Interface%20Guidelines%201987.pdf" target="_blank" rel="noopener noreferrer">Apple Human Interface Guidelines (1987)</a></li><li><a href="https://www.youtube.com/watch?v=76b3c_ssyPQ&amp;ab_channel=Figma" target="_blank" rel="noopener noreferrer">Rasmus Andersson. The curious case of user interfaces (2023)</a></li><li><a href="https://museapp.com/podcast/17-rethink-the-os/" target="_blank" rel="noopener noreferrer">Metamuse. Rethink the OS with Jason Yuan (2020)</a></li><li><a href="https://www.mercuryos.com/" target="_blank" rel="noopener noreferrer">Jason Yuan. MercuryOS (2019)</a></li><li><a href="http://paulgraham.com/greatwork.html#f2n" target="_blank" rel="noopener noreferrer">Paul Graham. How to Do Great Work (2023)</a></li><li><a href="https://brianlovin.com/app-dissection" target="_blank" rel="noopener noreferrer">App Dissection. Brian Lovin</a></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lima: A nice way to run Linux VMs on Mac (406 pts)]]></title>
            <link>https://jvns.ca/blog/2023/07/10/lima--a-nice-way-to-run-linux-vms-on-mac/</link>
            <guid>36668964</guid>
            <pubDate>Mon, 10 Jul 2023 16:44:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/07/10/lima--a-nice-way-to-run-linux-vms-on-mac/">https://jvns.ca/blog/2023/07/10/lima--a-nice-way-to-run-linux-vms-on-mac/</a>, See on <a href="https://news.ycombinator.com/item?id=36668964">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! Here’s a new entry in the “cool software julia likes” section.</p>

<p>A little while ago I started using a Mac, and one of my biggest
frustrations with it is that often I need to run Linux-specific software. For
example, the <a href="https://jvns.ca/blog/2021/09/24/new-tool--an-nginx-playground/">nginx playground</a> I
posted about the other day only works on Linux because it uses Linux namespaces (via <code>bubblewrap</code>)
to sandbox nginx. And I’m working on another playground right now that uses bubblewrap too.</p>

<p>This post is very short, it’s just to say that Lima seems nice and much simpler
to get started with than Vagrant.</p>

<h3 id="enter-lima">enter Lima!</h3>

<p>I was complaining about this to a friend, and they mentioned
<a href="https://lima-vm.io/">Lima</a>, which stands for <strong>Li</strong>nux on <strong>Ma</strong>c. I’d heard
of <a href="https://github.com/abiosoft/colima">colima</a> (another way to run Linux
containers on Mac), but I hadn’t realized that Lima also just lets you run VMs.</p>

<p>It was surprisingly simple to set up. I just had to:</p>

<ol>
<li>Install Lima (I did <code>nix-env -iA nixpkgs.lima</code> but you can also install it with <code>brew install lima</code>)</li>
<li>Run <code>limactl start default</code> to start the VM</li>
<li>Run <code>lima</code> to get a shell</li>
</ol>

<p>That’s it! By default it mounts your home directory as read-only inside the VM</p>

<p>There’s a config file in <code>~/.lima/default/lima.yaml</code>, but I haven’t needed to change it yet.</p>

<h3 id="some-nice-things-about-lima">some nice things about Lima</h3>

<p>Some things I appreciate about Lima (as opposed to Vagrant which I’ve used in the past and found kind of frustrating) are:</p>

<ol>
<li>it provides a default config</li>
<li>it automatically downloads a Ubuntu 22.04 image to use in the VM (which is what I would have probably picked anyway)</li>
<li>it mounts my entire home directory inside the VM, which I really like as a default choice (it feels very seamless)</li>
</ol>

<p>I think the paradigm of “I have a single chaotic global Linux VM which I use
for all my projects” might work better for me than super carefully configured
per-project VMs. Though I’m sure that you can have carefully configured
per-project VMs with Lima too if you want, I’m just only using the <code>default</code> VM.</p>

<h3 id="problem-i-don-t-know-how-to-mount-directories-read-write">problem: I don’t know how to mount directories read-write</h3>

<p>I wanted to have my entire home directory mounted read-only, but have some
subdirectories (like <code>~/work/nginx-playground</code>) mounted read-write. I did some
research and here’s what I found:</p>

<ul>
<li>a comment on <a href="https://github.com/lima-vm/lima/issues/873">this github issue</a> says that you can use <a href="https://github.com/lima-vm/lima/blob/master/docs/vmtype.md#vz">mountType: “virtiofs” and vmType: “vz”</a> to mount subdirectories of your home directory read-write</li>
<li>the Lima version packaged in nix 23.05 doesn’t seem to support <code>vmType: vz</code> (though I could be wrong about this)</li>
</ul>

<p>Maybe I’ll figure out how to mount directories read-write later, I’m not too
bothered by working around it for now.</p>

<h3 id="why-not-use-containers">why not use containers?</h3>

<p>I wanted a VM and not a Linux container because:</p>

<ol>
<li>the playground runs on a VM in production, not in a container, and generally
it’s easier to develop in a similar environment to production</li>
<li>all of my playgrounds use Linux namespaces, and I don’t know how to create a
namespace inside a container. Probably you can but I don’t feel like
figuring it out and it seems like an unnecessary distraction.</li>
<li>on Mac you need to run containers inside a Linux VM anyway, so I’d rather
use a VM directly and not introduce another unnecessary layer</li>
</ol>

<h3 id="that-s-all">that’s all!</h3>

<p>Some other notes:</p>

<ul>
<li>It looks like Lima works on Linux too</li>
<li>a bunch of people on Mastodon also said <a href="https://github.com/abiosoft/colima">colima</a> (built on top of Lima) is a nice Docker alternative on Mac for running Linux containers</li>
<li>there’s also an new alternative Linux container runtime for Mac called <a href="https://docs.orbstack.dev/">Orb Stack</a>, which I know nothing about</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple VisionOS Simulator streaming wirelessly to Meta Quest headset (361 pts)]]></title>
            <link>https://github.com/zhuowei/VisionOSStereoScreenshots/tree/alvr</link>
            <guid>36668732</guid>
            <pubDate>Mon, 10 Jul 2023 16:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zhuowei/VisionOSStereoScreenshots/tree/alvr">https://github.com/zhuowei/VisionOSStereoScreenshots/tree/alvr</a>, See on <a href="https://news.ycombinator.com/item?id=36668732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">visionOS Simulator to ALVR / Meta Quest wireless streaming</h2>
<p dir="auto">Streams the visionOS Simulator to a Meta Quest wirelessly with <a href="https://github.com/alvr-org/ALVR">ALVR</a> installed.</p>
<p dir="auto">Tested with Xcode 15 beta 2 / macOS 14 beta 2 on Apple Silicon, Meta Quest (original).</p>
<h3 tabindex="-1" dir="auto">Usage</h3>
<ol dir="auto">
<li>
<p dir="auto">First, sideload <a href="https://github.com/alvr-org/ALVR-nightly/releases/tag/v21.0.0-dev00%2Bnightly.2023.07.06">ALVR Nightly 2023.07.06</a> onto your Meta Quest.</p>
<p dir="auto">(This does not currently work with stable ALVR)</p>
</li>
<li>
<p dir="auto">Start the visionOS Simulator from Xcode.</p>
</li>
<li>
<p dir="auto">Download and extract <a href="https://github.com/zhuowei/VisionOSStereoScreenshots/releases">alvr_visionos_streaming.zip</a>.</p>
</li>
<li>
<p dir="auto">Inject the streaming library into the Simulator:</p>
<div data-snippet-clipboard-copy-content="./inject.sh
# this resprings the simulator"><pre><code>./inject.sh
# this resprings the simulator
</code></pre></div>
</li>
<li>
<p dir="auto">Open ALVR on your Meta Quest: if all goes well, the visionOS interface should stream into your headset.</p>
</li>
<li>
<p dir="auto">To configure streaming settings, you can use the ALVR dashboard (./alvr_dashboard). See <a href="https://github.com/alvr-org/ALVR">ALVR's documentation</a> for more info.</p>
</li>
<li>
<p dir="auto">You can't control the Simulator using the Quest's controllers yet (I'm looking into it).</p>
<p dir="auto">For now, use the computer's mouse/keyboard to control the Simulator.</p>
<p dir="auto">You probably want to enable a visible mouse cursor inside the Simulator (Settings -&gt; Accessibility -&gt; Pointer Control)</p>
</li>
</ol>
<h3 tabindex="-1" dir="auto">How it works</h3>
<p dir="auto">This hooks CompositorService APIs inside backboardd so that it renders to our own textures instead of to the simulator screen. We then pass these textures to ALVR's server, which encodes them and streams them to the headset.</p>
<h3 tabindex="-1" dir="auto">What's next</h3>
<ul dir="auto">
<li>Enable passthrough</li>
<li>Hook up Quest controllers / eye gaze?</li>
</ul>
<h3 tabindex="-1" dir="auto">Credits</h3>
<p dir="auto">Thank you so much to <a href="https://mastodon.social/@ShinyQuagsire" rel="nofollow">@ShinyQuagsire</a>: he <a href="https://mastodon.social/@ShinyQuagsire/110670442474420349" rel="nofollow">released</a> the <a href="https://github.com/shinyquagsire23/XRGyroControls_OpenXR">first ever tool</a> for streaming the visionOS Simulator to a Quest headset (via wired Quest Link), and helped me figure out how to port this to work wirelessly using ALVR.</p>
<p dir="auto">Thanks to <a href="https://infosec.exchange/@jjtech" rel="nofollow">@JJTech</a> and <a href="https://mastodon.social/@keithahern" rel="nofollow">@keithahern</a> for figuring out how the visionOS Simulator handles input.</p>
<p dir="auto">Thanks to <a href="https://github.com/alvr-org/ALVR">the ALVR developers</a> for making an amazing cross-platform VR streaming system.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study: 87% of classic video games are not legally available (469 pts)]]></title>
            <link>https://gamehistory.org/87percent/</link>
            <guid>36668472</guid>
            <pubDate>Mon, 10 Jul 2023 16:15:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gamehistory.org/87percent/">https://gamehistory.org/87percent/</a>, See on <a href="https://news.ycombinator.com/item?id=36668472">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-24002">
	
	<!-- .cover-header -->

	<div id="post-inner">

		
<p>The Video Game History Foundation, in partnership with the Software Preservation Network, has conducted <a href="https://doi.org/10.5281/zenodo.7996492">the first ever study</a> on the commercial availability of classic video games, and the results are bleak. <strong>87% of classic video games released in the United States are critically endangered</strong>.</p>



<p>Imagine if the only way to watch <em>Titanic</em> was to find a used VHS tape, and maintain your own vintage equipment so that you could still watch it. And what if no library, not even the Library of Congress, could do any better — they could keep and digitize that VHS of <em>Titanic</em>, but you’d have to go all the way there to watch it. It sounds crazy, but that’s the reality we live in with video games, a $180 billion industry, while the games and their history disappear. </p>



<div><figure><img decoding="async" width="1024" height="1024" src="https://gamehistory.org/wp-content/uploads/2023/07/8-1-1024x1024.png" alt="" srcset="https://gamehistory.org/wp-content/uploads/2023/07/8-1-1024x1024.png 1024w, https://gamehistory.org/wp-content/uploads/2023/07/8-1-300x300.png 300w, https://gamehistory.org/wp-content/uploads/2023/07/8-1-740x740.png 740w, https://gamehistory.org/wp-content/uploads/2023/07/8-1-768x768.png 768w, https://gamehistory.org/wp-content/uploads/2023/07/8-1.png 1080w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><div>
<p>Just 13% of video game history is being represented in the current marketplace. In fact, no period of video game history defined in this study even cracked <em>20% representation</em>.</p>



<p>Figure 1: Availability rate of historical games, by period, between 1960 and 2009. (n = 1500, ±2.5%, 95% CI) Curious about our methodology? Check out our <a href="https://gamehistory.org/study-explainer">study explainer blog pos</a><a href="https://gamehistory.org/?p=24007">t</a>!</p>
</div></div>



<p>For accessing <em>nearly 9 in 10</em> classic games, there are few options: seek out and maintain vintage collectible games and hardware, travel across the country to visit a library, or… piracy. None of those options are desirable, which means that most video games are inaccessible to all but the most diehard and dedicated fans. That’s pretty grim!</p>



<p>This is where libraries and archives&nbsp;<em>should</em>&nbsp;come in. Anyone&nbsp;<em>should</em>&nbsp;be able to easily explore, research and play classic video games, in the same way that they can read classic novels, listen to classic albums, and watch classic movies. But outdated copyright laws are preventing institutions like ours from doing our jobs.</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple.png" alt="" width="454" height="454" srcset="https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple.png 1080w, https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple-300x300.png 300w, https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple-1024x1024.png 1024w, https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple-740x740.png 740w, https://gamehistory.org/wp-content/uploads/2023/07/Historical-Games-Simple-768x768.png 768w" sizes="(max-width: 454px) 100vw, 454px"><figcaption><em>Availability rate of historical games. (</em>n<em> = 1500, ±2.5%, 95% CI)</em><br><em>Random list of games pulled from MobyGames</em>.</figcaption></figure></div>


<p><strong>Goal of this study:</strong> Get expanded exemptions for libraries and organizations preserving video games, which are currently far more limited than their ability to preserve books, movies, audio, etc.</p>



<p><strong>How this study helps:</strong> The <a href="https://arstechnica.com/gaming/2023/03/why-game-archivists-are-dreading-this-months-3ds-wii-u-eshop-shutdown/">video game industry’s main lobbying group</a> has successfully argued to the US Copyright Office that the industry already does enough to preserve its own history commercially, and that additional protections for preservation institutions would hurt their bottom line. We proved them wrong: the industry has actually only managed to make 13% of its history available, and <a href="https://www.youtube.com/watch?v=HLWY7fCXUwE">it’s unlikely to get better</a>.</p>



<p><em>The argument that these games are commercially available is what’s keeping video games behind in the preservation world.</em></p>











<p>The next <a href="https://www.copyright.gov/1201/">rulemaking proceeding</a> under the Digital Millennium Copyright Act (“DMCA”), Title 17, section 1201, of the&nbsp;<em>United States Code</em> is scheduled for 2024. We’re hopeful that this study will incite change, and that video game preservation will become stronger — before we lose more.</p>



<p><em>Survey of the Video Game Reissue Market in the United States was conducted for the Video Game History Foundation and the Software Preservation Network by VGHF Library Director Phil Salvador, published July 2023.</em></p>



<p><mark>Want to learn more?</mark> Check out our <a href="http://gamehistory.org/study-explainer">explainer blog post</a> for a more in-depth look at this study. A bonus episode of our podcast about this study and its findings will be available soon. You can <a href="https://doi.org/10.5281/zenodo.7996492">read the full study here</a>.</p>



<hr>



<h4>Special thanks to our volunteers:</h4>





		</div><!-- .post-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First U.S. ban on sale of cellphone location data might be coming (495 pts)]]></title>
            <link>https://www.wsj.com/articles/first-u-s-ban-on-sale-of-cellphone-location-data-might-be-coming-fbe47e53</link>
            <guid>36667848</guid>
            <pubDate>Mon, 10 Jul 2023 15:28:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/first-u-s-ban-on-sale-of-cellphone-location-data-might-be-coming-fbe47e53">https://www.wsj.com/articles/first-u-s-ban-on-sale-of-cellphone-location-data-might-be-coming-fbe47e53</a>, See on <a href="https://news.ycombinator.com/item?id=36667848">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
This copy is for your personal, non-commercial use only. Distribution and use of this material are governed by
our Subscriber Agreement and by copyright law. For non-personal use or to order multiple copies, please contact
Dow Jones Reprints at 1-800-843-0008 or visit www.djreprints.com.
</p><p>https://www.wsj.com/articles/first-u-s-ban-on-sale-of-cellphone-location-data-might-be-coming-fbe47e53</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keep Linux Open and Free–We Can’t Afford Not To (188 pts)]]></title>
            <link>https://www.oracle.com/news/announcement/blog/keep-linux-open-and-free-2023-07-10/</link>
            <guid>36667582</guid>
            <pubDate>Mon, 10 Jul 2023 15:11:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oracle.com/news/announcement/blog/keep-linux-open-and-free-2023-07-10/">https://www.oracle.com/news/announcement/blog/keep-linux-open-and-free-2023-07-10/</a>, See on <a href="https://news.ycombinator.com/item?id=36667582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-trackas="rc25"><p><span>Press Release</span></p><p><strong> <!-- -->By Edward Screven, Chief Corporate Architect and Wim Coekaerts, Head of Oracle Linux Development<!-- -->—<!-- -->July 10, 2023<!-- --> </strong></p></div>
<div>
<p>Oracle has been part of the Linux community for 25 years. Our goal has remained the same over all those years: help make Linux the best server operating system for everyone, freely available to all, with high-quality, low-cost support provided to those who need it.</p>

<p>Our Linux engineering team makes significant contributions to the kernel, file systems, and tools. We push all that work back to mainline so that every Linux distribution can include it. We are proud those contributions are part of the reason Linux is now so very capable, benefiting not just Oracle customers, but all users.</p>

<p>In 2006, we launched what is now called Oracle Linux, a RHEL compatible distribution and support offering that is used widely, and powers Oracle’s engineered systems and our cloud infrastructure. We chose to be RHEL compatible because we did not want to fragment the Linux community. Our effort to remain compatible has been enormously successful. In all the years since launch, we have had almost no compatibility bugs filed. Customers and ISVs can switch to Oracle Linux from RHEL without modifying their applications, and we certify Oracle software products on RHEL even though they are built and tested on Oracle Linux only, never on RHEL.</p>

<p>While Oracle and IBM have compatible Linux distributions, we have very different ideas about our responsibilities as open source stewards and about operating under the GPLv2. Oracle has always made Oracle Linux binaries and source freely available to all. We do not have subscription agreements that interfere with a subscriber’s rights to redistribute Oracle Linux. On the other hand, IBM subscription agreements specify that you’re in breach if you use those subscription services to exercise your GPLv2 rights. And now, as of June 21, IBM no longer publicly releases RHEL source code.</p>

<p>Why did IBM make this change? Well, if you read IBM’s <a href="https://www.redhat.com/en/blog/red-hats-commitment-open-source-response-gitcentosorg-changes">blog</a> attempting to explain its rationale, it boils down to this:</p>

<blockquote><q>At Red Hat, thousands of people spend their time writing code to enable new features, fixing bugs, integrating different packages and then supporting that work for a long time … We have to pay the people to do that work.</q></blockquote>

<p>Interesting. IBM doesn’t want to continue publicly releasing RHEL source code because it has to pay its engineers? That seems odd, given that Red Hat as a successful independent open source company chose to publicly release RHEL source and pay its engineers for many years before IBM acquired Red Hat in 2019 for $34 billion.</p>

<p>The blog goes on to mention CentOS. It is no surprise CentOS was top of mind for the author attempting to justify withholding RHEL source. CentOS had been a very popular free RHEL compatible distribution. In December 2020, IBM effectively killed it as a free alternative to RHEL. Two new alternatives to RHEL have sprung up in CentOS’s place: AlmaLinux and Rocky Linux. Now, by withholding RHEL source code, IBM has directly attacked them.</p>

<p>And perhaps that is the real answer to the question of why: eliminate competitors. Fewer competitors means more revenue opportunity for IBM.</p>

<p>As for Oracle, we will continue pursuing our goal for Linux as transparently and openly as we always have while minimizing fragmentation. We will continue to develop and test our software products on Oracle Linux. Oracle Linux will continue to be RHEL compatible to the extent we can make it so. In the past, Oracle’s access to published RHEL source has been important for maintaining that compatibility. From a practical standpoint, we believe Oracle Linux will remain as compatible as it has always been through release 9.2, but after that, there may be a greater chance for a compatibility issue to arise. If an incompatibility does affect a customer or ISV, Oracle will work to remediate the problem.</p>

<p>We want to emphasize to Linux developers, Linux customers, and Linux distributors that Oracle is committed to Linux freedom. Oracle makes the following promise: as long as Oracle distributes Linux, Oracle will make the binaries and source code for that distribution publicly and freely available. Furthermore, Oracle welcomes downstream distributions of every kind, community and commercial. We are happy to work with distributors to ease that process, work together on the content of Oracle Linux, and ensure Oracle software products are certified on your distribution.</p>

<p>By the way, if you are a Linux developer who disagrees with IBM’s actions and you believe in Linux freedom the way we do, we are hiring.</p>

<p>One observation for ISVs: IBM’s actions are not in your best interest. By killing CentOS as a RHEL alternative and attacking AlmaLinux and Rocky Linux, IBM is eliminating one way your customers save money and make a larger share of their wallet available to you. If you don’t yet support your product on Oracle Linux, we would be happy to show you how easy that is. Give your customers more choice.</p>

<p>Finally, to IBM, here’s a big idea for you. You say that you don’t want to pay all those RHEL developers? Here’s how you can save money: just pull from us. Become a downstream distributor of Oracle Linux. We will happily take on the burden.</p>
</div>
<!-- --> <!-- -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feature Flags: Theory vs. Reality (110 pts)]]></title>
            <link>https://bpapillon.com/post/feature-flags-theory-vs-reality/</link>
            <guid>36667469</guid>
            <pubDate>Mon, 10 Jul 2023 15:02:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bpapillon.com/post/feature-flags-theory-vs-reality/">https://bpapillon.com/post/feature-flags-theory-vs-reality/</a>, See on <a href="https://news.ycombinator.com/item?id=36667469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        

<figure>
  <img src="https://bpapillon.com/communismtheoryhomer.gif" alt="A discussion about DevOps in 2023">
  <figcaption>A discussion about DevOps in 2023</figcaption>
</figure>

<h2 id="the-rise-of-feature-flags-in-devops"><strong>The Rise of Feature Flags in DevOps</strong></h2>

<p>During the second half of the 2010s, the DevOps movement gained massive momentum throughout the SaaS industry. Riding this wave and buoyed by the marketing efforts of LaunchDarkly, feature toggles rapidly became an essential tool for engineering operations used by practically every SaaS company.</p>

<p>In the DevOps context, feature flags are especially great for continuous deployment. By decoupling release from deployment, they allow marketing and engineering to operate independently. This flexibility enables engineers to continuously deploy features in progress.</p>

<p>However, a few downsides were clear even from the beginning. To name a few:</p>

<ul>
<li><strong>They add complexity to the code</strong>, including additional testing overhead.</li>
<li><strong>It’s difficult to verify</strong> whether all of your changes are actually “behind” a feature flag as intended.</li>
<li><strong>Feature toggle checks aren’t free</strong>; it’s more logic, which means more possible bugs, and the check may take time if a database or external service is involved.</li>
</ul>

<p>Due to these shortcomings, the <a href="https://martinfowler.com/articles/feature-toggles.html">conventional wisdom</a> has always been that feature flags should be short-lived and kept to a minimum:</p>

<blockquote>
<p>Savvy teams view the Feature Toggles in their codebase as inventory which comes with a carrying cost and seek to keep that inventory as low as possible.</p>
</blockquote>

<h2 id="reality-check"><strong>Reality Check!</strong></h2>

<figure>
  <img src="https://bpapillon.com/sideshow-bob-rakes.gif" alt="A software developer interacts with their feature management system">
  <figcaption>A software developer interacts with their feature management system</figcaption>
</figure>

<p>As adoption of the feature toggle pattern has spread throughout the industry, a few common problems can be observed.</p>

<h3 id="1-release-follow-through-and-ever-expanding-complexity"><strong>1. Release follow-through and ever-expanding complexity</strong></h3>

<p>If feature flags are meant to be short-lived, then there must be a process for reviewing them and cleaning them up at the appropriate time. This often takes the form of a manual process, such as filing a ticket for a future sprint.</p>

<p>As a general rule of thumb, any process that relies on humans to remember things is not going to be a reliable one, and for most companies, these processes end up being spotty and inconsistent.</p>

<p>A few common issues I’ve seen:</p>

<ul>
<li><strong>Zombie flags</strong>

<ul>
<li>In our haste to move on to the next big feature, we often forget to rip out the release flag. This leads to higher “carrying cost”, taking many forms: the readability of the code, the number of automated tests that continually execute each branch of the feature flag logic, and so forth. Over time, this makes our code base harder to work on and leads to annoyance, wasted time, and bugs.</li>
</ul></li>
<li><strong>Unfinished business</strong>

<ul>
<li>Perhaps we forget to finish rolling out our flag, or maybe some customer segments never even get the new feature. This leads to unexpected support tickets months later, at a time when everyone in the organization thought that the rollout was long finished.</li>
</ul></li>
<li><strong>Ghost flags</strong>

<ul>
<li>Sometimes, even when we remember to rip out the feature flag, there may be a communication breakdown with other users, who end up futilely toggling a control that has no effect.</li>
</ul></li>
</ul>

<h3 id="2-unintended-or-inappropriate-usage"><strong>2. Unintended or inappropriate usage</strong></h3>

<p>Even with perfect follow-through, a flag meant for release purposes might end up being implemented for long-term feature access. This may seem like a time-saving win, but it results in third-party services becoming load-bearing for cases beyond their intended purpose.</p>

<p>Imagine even a very short outage by the service provider. If we only rely on that service provider for release flags, we probably live with our hardcoded fallback values; but, if we’re using it for something like a permission or entitlement check, there is now essentially an outage of our own.</p>

<p>Many teams understand this danger, and respond by implementing separate systems for short-lived and long-lived flags; the former may use a managed service, while the latter may be a home-grown system that stores its data in the main application database.</p>

<p>Even though we now have a more correct tool for each job, we still end up with a lot of problems in practice:</p>

<ul>
<li><strong>Lack of portability &amp; promotion</strong>

<ul>
<li>We’ve mentioned that release flags can sometimes take on a second life as other types of toggles. With this model, if a release flag starts to make sense as a long-lived flag later, there’s no way to promote it to the more appropriate system without making code changes.</li>
</ul></li>
<li><strong>User confusion &amp; frustration</strong>

<ul>
<li>Across these two systems (short and long-lived), there may be a broad base of user types: engineering, product, customer success, marketing, ops. It’s unlikely that these groups share a consistent mental model for the systems, and people tend to just refer to all of it as “flags”. Many users may be unclear as to why there are two separate systems at all, and feel frustrated that they just have to remember which flag lives in which system.</li>
</ul></li>
<li><strong>Lack of context &amp; readability</strong>

<ul>
<li>Exacerbating the user confusion issue, most flags are exposed as a list of keys (e.g. “new_onboarding_flow”, “widgets_v2”) that provide very little context about what these flags do or how they’re meant to be used.</li>
<li>Without talking to someone, reading code, or separately maintaining documentation, it’s very difficult to know much about the flags, which frustrates non-technical and technical stakholders alike.</li>
</ul></li>
<li><strong>Testing headaches</strong>

<ul>
<li>Developers have to accommodate multiple systems in testing; for example, if you’re using mocks or stubs in your tests to simulate the behavior of these systems, you now need twice as many of these.</li>
</ul></li>
<li><strong>Feature gaps</strong>

<ul>
<li>A long-lived flag service that is homegrown may be able to provide better guarantees with regards to latency and availability; however, the short-lived flag service will almost always be more feature-rich because it’s often provided by a managed service. This reality may incentivize its use over the more reliable system in certain cases.</li>
</ul></li>
</ul>

<h2 id="accepting-reality">Accepting Reality</h2>

<p>After observing the feature flag experiment in the wild for some time, I’ve come to the conclusion that the conventional wisdom to limit the number and age of feature flags in your code base is wise, but unrealistic. The fast-paced and cross-functional nature of modern software development create dynamics that are too hard to overcome with best intentions and best practices.</p>

<p>Furthermore, there’s a disconnect between “feature management” as a term of industry and the actual “feature management” that goes on. This term, and the tools that are sold within this market, generally refer only to DevOps use cases like rollout and experimentation. However, we clearly do a lot more managing of features than this.</p>

<ul>
<li>Every time a new customer signs up, are their features not being managed?</li>
<li>When they upgrade to a more expensive plan?</li>
<li>When a sales negotiation results in a bespoke enterprise plan?</li>
<li>When a customer success rep enables an add-on?</li>
</ul>

<p>These are all feature management, but none of them fall into the definition of “feature management” that our tooling and DevOps culture wants to support.</p>

<p>As engineers, it’s time to change our framing of feature management to better align with the businesses we operate in, but to do this, we need new tools.</p>

<h2 id="taming-complexity">Taming complexity</h2>

<figure>
  <img src="https://bpapillon.com/homer-grill-fail.gif" alt="A software developer evaluates their adherence to feature management best practices">
  <figcaption>A software developer evaluates their adherence to feature management best practices</figcaption>
</figure>

<p>A software developer evaluates their adherence to feature management best practices</p>

<p>If we accept that we as engineers are powerless to contain the spread of feature management, and perhaps that we are holding back our businesses to the extent we try to do so, then we need to stop relying on manual processes for hygiene and maintenance.</p>

<p>Let’s imagine what capabilities we might need a new feature management tool to have in order to accomplish this. A few possibilities:</p>

<ul>
<li>Long-lived and short-lived use cases coexist within the same tool, but are clearly delineated in its interfaces.

<ul>
<li>Short-lived flags might come with additional metadata, such as an expiration date by which we expect the flag should no longer be in use.</li>
</ul></li>
<li>Flags should have an owner, either an individual user or perhaps a user role or group.</li>
<li>Users should be able to add meaning to flags after the fact via metadata and grouping.</li>
<li>If a flag changes purpose, say from a release flag to an entitlement check, we can simply update this in the tool. Such a change would be tracked in an audit log.</li>
<li>Policies can be set; for example, short-lived flags must be removed or graduated within a specified amount of time, or perhaps certain metadata (like expiration date) can be made required for certain types of flags.</li>
<li>Flags can easily be used in relation to one another; for example, one flag might be required in order for another flag to be enabled, or two flags might be incompatible with one another for code reasons. The tool should make it easy to configure such invariants.</li>
</ul>

<p>With capabilities like this in place, the tool could start to automate some of the maintenance processes that are currently manual.</p>

<p>For example:</p>

<ul>
<li>Auditing a codebase for out-of-date flags could be done via a static analysis tool in CI.</li>
<li>We could fail builds or notify engineering or product managers if certain assumptions are not met.</li>
<li>Flag owners could receive notifications when flags they are responsible for are out of compliance, or a ticket could automatically be filed in the ticketing system.</li>
</ul>

<p>If we can automate these processes, then we finally might have a system that holds up to the chaos of the modern software development process and fights back against ever-growing complexity.</p>

<h2 id="onward">Onward!</h2>

<figure>
  <img src="https://bpapillon.com/twirling-towards-freedom.gif" alt="Leaving the old expectations behind as we move to a new framing of feature management">
  <figcaption>Leaving the old expectations behind as we move to a new framing of feature management</figcaption>
</figure>

<p>It’s high time that we take another look at what “feature management” means in our industry.  If we accept a more expansive view that aligns with how our businesses want to be managing features and build the tools needed to support this, we can free ourselves from the need to adhere to best practices that have proved unrealistic.</p>

<p>If we were to have a tool like this that better suited the natural complexity of feature management, then this would be a great start. However, there are more considerations, such as the architecture of such a tool, that I will explore in upcoming posts.</p>

        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Danswer – Open-source question answering across all your docs (164 pts)]]></title>
            <link>https://github.com/danswer-ai/danswer</link>
            <guid>36667374</guid>
            <pubDate>Mon, 10 Jul 2023 14:55:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/danswer-ai/danswer">https://github.com/danswer-ai/danswer</a>, See on <a href="https://news.ycombinator.com/item?id=36667374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">
<a href="https://www.danswer.ai/" rel="nofollow"> <img width="50%" src="https://github.com/danswer-owners/danswer/raw/1fabd9372d66cd54238847197c33f091a724803b/DanswerWithName.png?raw=true)"></a>
</h2>
<p dir="auto">OpenSource Enterprise Question-Answering</p>
<p dir="auto">
<a href="https://docs.danswer.dev/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/769b1399e79e3be7736d96d113701fd40006e4c9f8e2086ed401496f89785201/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d766965772d626c7565" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-view-blue">
</a>
<a href="https://join.slack.com/t/danswer/shared_invite/zt-1u5ycen3o-6SJbWfivLWP5LPyp_jftuw" rel="nofollow">
    <img src="https://camo.githubusercontent.com/d3c199e9bb1afecb780ec71151ae464e07aff40b28c2aef5301d7935d6d1aa09/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a6f696e2d626c75652e7376673f6c6f676f3d736c61636b" alt="Slack" data-canonical-src="https://img.shields.io/badge/slack-join-blue.svg?logo=slack">
</a>
<a href="https://discord.gg/TDJ59cGV2X" rel="nofollow">
    <img src="https://camo.githubusercontent.com/936ab21c6224f88d885798b4029607590ef711f69f608fd97256d4913a24d681/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d6a6f696e2d626c75652e7376673f6c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Discord" data-canonical-src="https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;logoColor=white">
</a>
<a href="https://github.com/danswer-ai/danswer/blob/main/README.md">
    <img src="https://camo.githubusercontent.com/1befec5200d934517068ce2e354d48fff5a9f3e762f8e48029e44903d356646c/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d6c6963656e7365266d6573736167653d4d495426636f6c6f723d626c7565" alt="License" data-canonical-src="https://img.shields.io/static/v1?label=license&amp;message=MIT&amp;color=blue">
</a>
</p>
<p dir="auto"><strong><a href="https://www.danswer.ai/" rel="nofollow">Danswer</a></strong> allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others.</p>
<p dir="auto">Check out our <strong><a href="https://www.youtube.com/watch?v=geNzY1nbCnU" rel="nofollow">Video Demo</a></strong>!</p>
<h2 tabindex="-1" dir="auto">Features <g-emoji alias="woman_dancing" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f483.png">💃</g-emoji></h2>
<ul dir="auto">
<li>Direct QA powered by Generative AI models with answers backed by quotes and source links.</li>
<li>Intelligent Document Retrieval (Semantic Search/Reranking) using the latest LLMs.</li>
<li>An AI Helper backed by a custom Deep Learning model to interpret user intent.</li>
<li>User authentication and document level access management.</li>
<li>Connectors to Slack, GitHub, GoogleDrive, Confluence, local files, and web scraping, with more to come.</li>
<li>Management Dashboard to manage connectors and set up features such as live update fetching.</li>
<li>One line Docker Compose (or Kubernetes) deployment to host Danswer anywhere.</li>
</ul>
<h2 tabindex="-1" dir="auto">Upcoming</h2>
<ul dir="auto">
<li>Chat/Conversation support.</li>
<li>Support custom endpoints for Generative AI models or even self-host options.</li>
<li>Templates to easily build custom connectors.</li>
<li>Personalized search</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A physicist who bets that gravity can’t be quantized (233 pts)]]></title>
            <link>https://www.quantamagazine.org/the-physicist-who-bets-that-gravity-cant-be-quantized-20230710/</link>
            <guid>36667278</guid>
            <pubDate>Mon, 10 Jul 2023 14:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/the-physicist-who-bets-that-gravity-cant-be-quantized-20230710/">https://www.quantamagazine.org/the-physicist-who-bets-that-gravity-cant-be-quantized-20230710/</a>, See on <a href="https://news.ycombinator.com/item?id=36667278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody"><div><h2>The Physicist Who’s Challenging the Quantum Orthodoxy</h2><div><p>For decades, physicists have struggled to develop a quantum theory of gravity. But what if gravity — and space-time — are fundamentally classical?</p></div></div><figure><div><p><img alt="A portrait of Jonathan Oppenheim. He’s in an office and is gazing into the distance, looking thoughtful." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/07/JonathanOppenheim-byPhilippAmmon-Lede-scaled.webp"></p></div><figcaption><div><p>Jonathan Oppenheim, a physicist at University College London, is developing hybrid theories that could unify classical gravity and quantum mechanics.</p><p>Philipp Ammon for <em>Quanta Magazine</em></p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Most physicists expect that when we zoom in on the fabric of reality, the unintuitive weirdness of quantum mechanics persists down to the very smallest scales. But in those settings, quantum mechanics collides with classical gravity in a resolutely incompatible way.</p>
<p>So for almost a century, theorists have tried to create a unified theory by quantizing gravity, or sculpting it according to the rules of quantum mechanics. They still haven’t succeeded.</p>
<p><a href="https://www.ucl.ac.uk/oppenheim/">Jonathan Oppenheim</a>, who runs a program exploring post-quantum alternatives at University College London, suspects that’s because gravity simply can’t be squeezed into a quantum box. Maybe, he argues, our presumption that it must be quantized is wrong. “That view is ingrained,” he said. “But no one knows what the truth is.”</p>
<p>Quantum theories are based on probabilities rather than certainties. For example, when you measure a quantum particle, you can’t predict exactly where you will find it, but you can predict the likelihood that it will be found in a particular place. What’s more, the more certain you are about a particle’s location, the less certain you are about its momentum. Over the 20th century, physicists gradually made sense of electromagnetism and other forces using this framework.<strong>&nbsp;</strong></p>
<p>But when they tried to quantize gravity, they ran into unnatural infinities that had to be sidestepped with clumsy mathematical tricks.</p>
<p><strong>&nbsp;</strong>The problems arise because gravity is a result of space-time itself, rather than something that acts on top of it. So if gravity is quantized, that means space-time is also quantized. But that doesn’t work, because quantum theory only makes sense against a classical space-time background — you can’t add and then evolve quantum states on top of an uncertain foundation.<strong>&nbsp;</strong></p>
</div></div><div><h2>Introduction</h2><div><p>To deal with this deep conceptual conflict, most theorists turned to string theory, which imagines that matter and space-time emerge from tiny, vibrating strings. A smaller faction looked to loop quantum gravity, which replaces the smooth space-time of Einstein’s general relativity with a network of interlocked loops. In both theories, our familiar, classical world somehow emerges from these fundamentally quantum building blocks.<strong>&nbsp;</strong></p>
<p>Oppenheim was originally a string theorist, and string theorists believe in the primacy of quantum mechanics. But he soon became uncomfortable with the elaborate mathematical acrobatics his peers performed to tackle one of the most notorious problems in modern physics: the <a href="https://www.quantamagazine.org/tag/information-paradox">black hole information paradox</a>.<strong>&nbsp;</strong></p>
<p>In 2017, Oppenheim started searching for alternatives that avoided the information paradox by taking both the quantum and the classical worlds as bedrocks. He stumbled across some overlooked <a href="https://www.sciencedirect.com/science/article/abs/pii/037596019390818K">research</a> on quantum-classical <a href="https://arxiv.org/abs/quant-ph/9503023">hybrid theories</a> from the 1990s, which he’s been <a href="https://arxiv.org/abs/1811.03116">extending</a> and <a href="https://arxiv.org/abs/2302.07283">exploring</a> ever since. By studying how the classical and quantum worlds interrelate, Oppenheim hopes to find a deeper theory that is neither quantum nor classical, but some kind of hybrid. “Often we put all our eggs in a few baskets, when there are lots of possibilities,” he said.<strong>&nbsp;</strong></p>
<p>To make his point, Oppenheim recently <a href="https://www.ucl.ac.uk/oppenheim/pub/quantum_vs_classical_bet.pdf">made a bet</a> with <a href="https://physics.berkeley.edu/people/faculty/geoff-penington">Geoff Penington</a> and <a href="https://perimeterinstitute.ca/people/carlo-rovelli">Carlo Rovelli</a> — leaders in their respective fields of string theory and loop quantum gravity. The odds? 5,000-to-1. If Oppenheim’s hunch is correct and space-time isn’t quantized, he stands to win bucketloads of potato chips, colorful plastic <a href="https://twitter.com/postquantum/status/1352292958259785729">bazinga balls</a>, or shots of olive oil, according to his fancy — as long as each item costs at most 20 pence (about 25 cents).</p>
<p>We met in a north London café lined with books, where he calmly unpacked his concerns about the quantum gravity status quo and extolled the surprising beauty of these hybrid alternatives. “They raise all kinds of remarkably subtle questions,” he said. “I’ve really lost my feet trying to understand these systems.” But he perseveres.<strong>&nbsp;</strong></p>
<p>“I want my 5,000 bazinga balls.”</p>
<p>The interview has been condensed and edited for clarity.</p>
<h3><strong>Why are most theorists so sure that space-time is quantized?</strong></h3>
<p>It’s become dogma. All the other fields in nature are quantized. There’s a sense that there’s nothing special about gravity — it’s just a field like any other — and therefore we should quantize it.</p>
</div></div><figure><div><p><img alt="Four images of Oppenheim with his students. In the first, he is studying a chalkboard filled with equations. In the second, a student in a turquoise dress is showing her computer screen to several others while Oppenheim, in the background, writes on a white board. The final two images are of Oppenheim and his students on a lunch outing. It’s a sunny day. We see them ordering from a food stand and then enjoying lunch on a grassy lawn." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/07/JonathanOppenheim-Quatriptych-byPhilippAmmon-scaled.webp"></p></div><figcaption><div><p>Oppenheim and his students, seen here in and around the UCL campus,&nbsp;are developing a new class of hybrid quantum-classical theories in which gravity stays classical. Maybe, Oppenheim argues, gravity is special and the quantum consensus is wrong.</p><p>Philipp Ammon for <em>Quanta Magazine</em></p></div></figcaption></figure><div><h2>Introduction</h2><div><h3><strong>Is gravity special in your view?</strong></h3>
<p>Yes. Physicists define all the other forces in terms of fields evolving in space-time. Gravity alone tells us about the geometry and curvature of space-time itself. None of the other forces describe the universal background geometry that we live in like gravity does.</p>
<p>At the moment, our best theory of quantum mechanics uses this background structure of space-time — which gravity defines. And if you really believe that gravity is quantized, then we lose that background structure.</p>
<h3><strong>What sorts of problems do you run into if gravity is classical and not quantized? </strong></h3>
<p>For a long time, the community believed it was logically impossible for gravity to be classical because coupling a quantum system with a classical system would lead to inconsistencies. In the 1950s, Richard Feynman imagined a situation that illuminated the problem: He began with a massive particle that is in a superposition of two different locations. These locations could be two holes in a metal sheet, as in the famous double-slit experiment. Here, the particle also behaves like a wave. It creates an interference pattern of light and dark stripes on the other side of the slits, which makes it impossible to know which slit it went through. In popular accounts, the particle is sometimes described as going through both slits at once.</p>

<p>But since the particle has mass, it creates a gravitational field that we can measure. And that gravitational field tells us its location. If the gravitational field is classical, we can measure it to infinite precision, infer the particle’s location, and determine which slit it went through. So we then have a paradoxical situation — the interference pattern tells us that we can’t determine which slit the particle went through, but the classical gravitational field lets us do just that.</p>
<p>But if the gravitational field is quantum, there is no paradox — uncertainty creeps in when measuring the gravitational field, and so we still have uncertainty in determining the particle’s location.</p>
<h3><strong>So if gravity behaves classically, you end up knowing too much. And that means that cherished ideas from quantum mechanics, like superposition, break down?</strong></h3>
<p>Yes, the gravitational field knows too much. But there’s a loophole in Feynman’s argument that could allow classical gravity to work.</p>
<h3><strong>What is that loophole?</strong></h3>
<p>As it stands, we only know which path the particle took because it produces a definite gravitational field that bends space-time and allows us to determine the particle’s location.<strong>&nbsp;</strong></p>
<p>But if that interaction between the particle and space-time is random — or unpredictable — then the particle itself doesn’t completely dictate the gravitational field. Which means that measuring the gravitational field will not always determine which slit the particle went through because the gravitational field could be in one of many states. Randomness creeps in, and you no longer have a paradox.</p>
<h3><strong>So why don’t more physicists think gravity is classical?</strong></h3>
<p>Well, it is logically possible to have a theory in which we don’t quantize all the fields. But for a classical theory of gravity to be consistent with everything else being quantized, then gravity has to be fundamentally random. To a lot of physicists that’s unacceptable.</p>
</div></div><figure><div><p><img alt="Oppenheim writing on a blackboard that is stuffed with equations. His back is to the camera." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/07/JonathanOppenheim-Blackboard-byPhilippAmmon-scaled.webp"></p></div><figcaption><div><p>Oppenheim started out as a string theorist, but he eventually grew frustrated with the clumsy mathematical tricks his colleagues employed to get around one of the most notorious conundrums in physics: the black hole information paradox.</p><p>Philipp Ammon for <em>Quanta Magazine</em></p></div></figcaption></figure><div><h2>Introduction</h2><div><h3><strong>Why?</strong></h3>
<p>Physicists spend a lot of time trying to figure out how nature works. So the idea that there is, on a very deep level, something inherently unpredictable is troubling to many.</p>
<p>The outcome of measurements within quantum theory appears to be probabilistic. But many physicists prefer to think that what appears as randomness is just the quantum system and the measuring apparatus interacting with the environment. They don’t see it as some fundamental feature of reality.</p>
<h3><strong>What are you proposing instead?</strong></h3>
<p>My best guess is that the next theory of gravity will be something that is neither completely classical nor completely quantum, but something else entirely.</p>
<p>Physicists are only ever coming up with models that approximate nature. But as an attempt at a closer approximation, my students and I constructed a fully consistent theory in which quantum systems and classical space-time interact. We just had to modify quantum theory slightly and modify classical general relativity slightly to allow for the breakdown of predictability that is required.</p>
<h3><strong>Why did you start working on these hybrid theories?</strong></h3>
<p>I was motivated by the black hole information paradox. When you throw a quantum particle into a black hole and then let that black hole evaporate, you encounter a paradox if you believe that black holes preserve information. Standard quantum theory demands that whatever object you throw into the black hole is radiated back out in some scrambled but recognizable way. But that violates general relativity, which tells us that you can never know about objects that cross the black hole’s event horizon.</p>
<p>But if the black hole evaporation process is indeterministic then there’s no paradox. We never learn what was thrown into the black hole because predictability breaks down. General relativity is safe.</p>
</div></div><figure><div><p><img alt="A portrait of Oppenheim in profile. He is mid-sentence and gesturing with his hands." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/07/JonathanOppenheim-Talking-byPhilippAmmon.webp"></p></div><figcaption><div><p>Recently, Oppenheim made a 5,000-to-1 bet with&nbsp;two colleagues that gravity can’t be quantized. If he wins, he gets to stuff his pockets with 5,000 bags of potato chips or bazinga balls or anything else that suits his fancy — as long as each item costs at most 20 pence (about 25 cents). “I feel I’ve made a pretty safe bet, even if I lose,” Oppenheim said.</p><p>Philipp Ammon for <em>Quanta Magazine</em></p></div></figcaption></figure><div><h2>Introduction</h2><div><h3><strong>So the noisiness in these quantum-classical hybrid theories allows information to be lost?</strong></h3>
<p>Exactly.<strong>&nbsp;</strong></p>
<h3><strong>But information conservation is a key principle in quantum mechanics. Losing this can’t sit easily with many theorists.</strong></h3>
<p>That’s true. There were huge debates about this in recent decades, and almost everybody came to believe that black hole evaporation is deterministic. I’m always puzzled by that.</p>
<h3><strong>Will experiments ever resolve if gravity is quantized or not?</strong></h3>
<p>At some point. We still know almost nothing about gravity on the smallest scales. It hasn’t even been tested to the millimeter scale, let alone to the scale of a proton. But there are some exciting experiments coming online which will do that.</p>
<p>One is <a href="https://arxiv.org/abs/2203.01982">a modern-day version</a> of the “Cavendish experiment,” which calculates the strength of the gravitational attraction between two lead spheres. If there is randomness in the gravitational field, as in these quantum-classical hybrids, then when we try and measure its strength we won’t always get the same answer. The gravitational field will jiggle around. Any theory in which gravity is fundamentally classical has a certain level of gravitational noise.</p>

<h3><strong>How do you know this randomness is intrinsic to the gravitational field and not some noise from the environment?</strong></h3>
<p>You don’t. Gravity is such a weak force that even the best experiments already have a lot of jiggle in them. So you have to eliminate all these other sources of noise as much as possible. What’s exciting is that my students and I showed that if these hybrid theories are true, there must be some minimal amount of gravitational noise. This can be measured by studying gold atoms in a double-slit experiment. These experiments already place bounds on whether gravity is fundamentally classical. We are gradually closing in on the amount of indeterminacy allowed.</p>
<h3><strong>On the flip side of the bet, are there any experiments that would prove that gravity is quantized?</strong></h3>
<p>There are <a href="https://arxiv.org/abs/1707.06050">proposed experiments</a> that look for entanglement mediated by the gravitational field. As entanglement is a quantum phenomenon, that would be a direct test of the quantum nature of gravity. These experiments are very exciting, but probably decades away.</p>
</div></div></div><div><h2>Next article</h2><p>The Lawlessness of Large Numbers</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stéphane Graber has left Canonical (105 pts)]]></title>
            <link>https://stgraber.org/2023/07/10/time-to-move-on/</link>
            <guid>36666920</guid>
            <pubDate>Mon, 10 Jul 2023 14:24:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stgraber.org/2023/07/10/time-to-move-on/">https://stgraber.org/2023/07/10/time-to-move-on/</a>, See on <a href="https://news.ycombinator.com/item?id=36666920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			    
<h2>Resignation</h2>



<p>After a bit over 12 years working for Canonical, Friday 7th of July was my last day.</p>



<p>It’s a bit of a bittersweet moment leaving a company after you’ve invested so much of your time into it, but I believe that now was the right time for me. As I’ve told colleagues and upper management, Canonical isn’t the company I excitedly joined back in 2011 and it’s not a company that I would want to join today, therefore it shouldn’t be a company that I keep working for either.</p>



<p>I’ll most miss working with the LXD team. Canonical is truly lucky to have such a great team of engineers going above and beyond to support a project like LXD. It’s quite unique to have a small team with such a wide variety of skills ranging from kernel development, to distributed systems, to web frontends and documentation, all working together to make a project like LXD possible.</p>


<div>
<figure><img decoding="async" src="https://discuss.linuxcontainers.org/uploads/default/optimized/2X/9/9a2706de31098d5ac2a35e673b20c14b595cee32_2_375x500.jpeg" alt=""></figure></div>


<h2>LXD</h2>



<p>Following the announcement of my resignation, Canonical decided to pull LXD out of the Linux Containers projects and relocate it to a full in-house project.<br>That’s the news which <a rel="noreferrer noopener" href="https://linuxcontainers.org/lxd/" target="_blank">we announced last week</a>.</p>



<p>I obviously wish that this particular change hadn’t happened, I strongly see value in having a project like LXD be run in a more open, community environment where everyone’s opinion is valued and everyone’s contribution, no matter the size, is welcome. Having the “LXD community experiment” be labeled a failure within Canonical seems unfair to me and to everyone who contributed over the years.</p>



<p>As for my particular involvement in Canonical’s LXD moving forward, I will definitely remain an active user of LXD and will likely still be filing issues and the occasional fix. However, I don’t intend to ever sign <a href="https://ubuntu.com/legal/contributors" data-type="URL" data-id="https://ubuntu.com/legal/contributors">Canonical’s CLA</a>, so should that become a barrier to contribution for the project, I will have to stop contributing to it.</p>



<h2>Ubuntu</h2>



<p>On the Ubuntu front, I’m currently a mostly inactive member of the Ubuntu Release team, Ubuntu Archive team and Ubuntu SRU team. I will be stepping down from all of those as I struggled to find any time to help them out while working for Canonical full time and don’t expect things to improve now.</p>



<p>I will remain an Ubuntu Core Developer and may contribute the occasional bugfix, package updates or new packages here and there. I don’t have any plans to move away from Ubuntu for my own systems.</p>



<h2>Future</h2>



<p>As for what I’ll be doing next. One thing I can share immediately is that I’m not joining another company nor do I have any intention to join another company at this stage.</p>



<p>I’m going to start by working on a number of pet projects that I’ve either neglected or been unable to even start so far. Some of those could lead to a source of revenue, some others will just be for the community’s benefit.</p>



<p>I’m also getting setup for freelance work, so will be able to accept the occasional consultancy or training contract where those make sense for me.</p>



<h2>Conclusion</h2>



<p>It’s a bit of an end of an era for me, a lot has changed over those 12 years both personally and in the industry, so I’m looking forward to have some time to reset and figure out what’s next!</p>
			    			</div><div><p>
		    This entry was posted in <a href="https://stgraber.org/category/planet-ubuntu/" rel="category tag">Planet Ubuntu</a> and tagged <a href="https://stgraber.org/tag/canonical/" rel="tag">canonical</a>. Bookmark the <a href="https://stgraber.org/2023/07/10/time-to-move-on/" title="Permalink to Time to move on" rel="bookmark">permalink</a>.		    		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We replaced Firecracker with QEMU (364 pts)]]></title>
            <link>https://hocus.dev/blog/qemu-vs-firecracker/</link>
            <guid>36666782</guid>
            <pubDate>Mon, 10 Jul 2023 14:15:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hocus.dev/blog/qemu-vs-firecracker/">https://hocus.dev/blog/qemu-vs-firecracker/</a>, See on <a href="https://news.ycombinator.com/item?id=36666782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content" itemprop="articleBody"><p><img loading="lazy" alt="Firecracker vs QEMU" src="https://hocus.dev/blog/assets/images/qemu-vs-firecracker-bg-6924bd95888c267d0fcbdbb34b61cea3.png" width="1830" height="583"></p><p>Firecracker, the microVM hypervisor, is renowned for being lightweight, fast, and secure. It's excellent for running short-lived workloads, which is why it's the backbone of AWS Lambda. Our initial prototype for Hocus, a self-hosted alternative to Gitpod and GitHub Codespaces, utilized Firecracker. However, after weeks of testing, we decided to entirely replace it with QEMU. A little-known fact about Firecracker is its lack of support for many modern hypervisor features, such as dynamic RAM management, which is vital for long-lived workloads. In this post, I will explain why Firecracker might not be the best hypervisor choice and when you should avoid it.</p><h2 id="firecracker-optimizes-for-short-lived-workloads">Firecracker Optimizes for Short-Lived Workloads<a href="#firecracker-optimizes-for-short-lived-workloads" aria-label="Direct link to Firecracker Optimizes for Short-Lived Workloads" title="Direct link to Firecracker Optimizes for Short-Lived Workloads">​</a></h2><p>The creators of Firecracker <a href="https://github.com/firecracker-microvm/firecracker/blob/dbd9a84b11a63b5e5bf201e244fe83f0bc76792a/README.md?plain=1#L24" target="_blank" rel="noopener noreferrer">state that</a>:</p><blockquote><p>"Firecracker has a minimalist design. It excludes unnecessary devices and guest-facing functionality to reduce the memory footprint and attack surface area of each microVM."</p></blockquote><p>The term "unnecessary" is intriguing - if this functionality is unnecessary, why was it incorporated into other hypervisors? The definition of "unnecessary" must be understood in the context of what Firecracker was built for. These excluded features are unnecessary for AWS Lambda, which spins up VMs to run short function calls and then shuts them down. If you're running a different kind of workload, like a VM that contains your development environment or a self-hosted GitHub Actions agent, these features cease to be unnecessary. Your VM will run for hours, days, or even months without stopping, unlike the typical Firecracker VM, which runs for seconds or minutes.</p><h2 id="firecracker-not-so-lightweight-after-all">Firecracker, Not So Lightweight After All<a href="#firecracker-not-so-lightweight-after-all" aria-label="Direct link to Firecracker, Not So Lightweight After All" title="Direct link to Firecracker, Not So Lightweight After All">​</a></h2><p>Here are the two most significant features Firecracker lacks:</p><ul><li>Dynamic memory management - Firecracker's RAM footprint starts low, but once a workload inside allocates RAM, Firecracker will never return it to the host system. After running several workloads inside, you end up with an idling VM that consumes 32 GB of RAM on the host, even though it doesn't need any of it.<sup id="fnref-1-1f96f1"><a href="#fn-1-1f96f1">1</a></sup></li><li>Discard operations on storage - if you create a 10 GB file inside a VM and then delete it, the backing space won't be reclaimed on the host. The VM will occupy that disk space until you delete the entire VM drive.<sup id="fnref-2-1f96f1"><a href="#fn-2-1f96f1">2</a></sup></li></ul><p>These deficiencies make Firecracker a memory and disk space hog. The plot below shows the memory usage of the same memory-intensive workload running in QEMU and Firecracker virtual machines.</p><p><img loading="lazy" alt="QEMU vs Firecracker VM Memory Usage" src="https://hocus.dev/blog/assets/images/vm-mem-usage-ae3ffeb0cc6a2df2f662597c653d9bf4.png" title="QEMU vs Firecracker VM Memory Usage" width="1696" height="967"></p><p><em>The workload in Firecracker finishes running around the 200-second mark, and in QEMU around the 250-second mark. It's not a performance difference; it's just when I manually stopped them.</em></p><h2 id="other-features-firecracker-is-missing">Other Features Firecracker Is Missing<a href="#other-features-firecracker-is-missing" aria-label="Direct link to Other Features Firecracker Is Missing" title="Direct link to Other Features Firecracker Is Missing">​</a></h2><ul><li>GPU support - if you need a GPU inside the VM, <a href="https://github.com/firecracker-microvm/firecracker/issues/849" target="_blank" rel="noopener noreferrer">you have to pick a different hypervisor</a>.</li><li>High-performance disk IO - when you connect multiple drives to the VM and run intensive IO operations, you will likely run into a bottleneck. Firecracker uses a virtio-blk implementation that isn’t as memory-hungry as alternatives, but has a <a href="https://lwn.net/Articles/812055/" target="_blank" rel="noopener noreferrer">smaller throughput</a>.<sup id="fnref-3-1f96f1"><a href="#fn-3-1f96f1">3</a></sup></li></ul><h2 id="qemu-is-not-perfect-though">QEMU is Not Perfect Though<a href="#qemu-is-not-perfect-though" aria-label="Direct link to QEMU is Not Perfect Though" title="Direct link to QEMU is Not Perfect Though">​</a></h2><p>The main issue we've had with QEMU is that it has too many options you need to configure. For instance, enabling your VM to return unused RAM to the host requires at least three challenging tasks:</p><ul><li>Knowing that the feature even exists (it's called <a href="https://docs.kernel.org/mm/free_page_reporting.html" target="_blank" rel="noopener noreferrer">free page reporting</a> and you have to specifically enable it in QEMU)</li><li>Understanding that an obscure feature of Linux called <a href="https://www.kernel.org/doc/html/v5.17/vm/damon/index.html" target="_blank" rel="noopener noreferrer">DAMON</a> exists, knowing what it's for<sup id="fnref-4-1f96f1"><a href="#fn-4-1f96f1">4</a></sup>, knowing how to configure it, and compiling a guest Linux kernel that supports it</li><li>Knowing that you need to disable transparent huge pages on the guest, otherwise the VM will never return large amounts of memory</li></ul><p>It took us two months of experimentation, reading through the source code of Firecracker, QEMU, and other hypervisors to develop a reliable QEMU proof of concept. To comprehend DAMON configuration, my co-founder spent days <a href="https://lore.kernel.org/damon/20230504171749.89225-1-sj@kernel.org/T/" target="_blank" rel="noopener noreferrer">running benchmarks and conversing with one of its authors</a>. It's great that we could talk and we are grateful that the author spent the time to help us, but it shows that the technology is not easily accessible yet.</p><h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2><p>QEMU has the features you need to run general-purpose workloads, but configuring it requires a lot of time and patience. If you want to run short-lived, untrusted workloads, Firecracker is a great choice. However, if you just want to run your development environment in a VM, you can use <a href="https://github.com/hocus-dev/hocus" target="_blank" rel="noopener noreferrer">Hocus</a>. We've done all the hard work for you already. It's still in alpha, but you can already check it out on <a href="https://github.com/hocus-dev/hocus" target="_blank" rel="noopener noreferrer">GitHub</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shelf – open-source asset management software (293 pts)]]></title>
            <link>https://github.com/Shelf-nu/shelf.nu</link>
            <guid>36666702</guid>
            <pubDate>Mon, 10 Jul 2023 14:10:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Shelf-nu/shelf.nu">https://github.com/Shelf-nu/shelf.nu</a>, See on <a href="https://news.ycombinator.com/item?id=36666702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Shelf.nu - Open Source Asset Management Infrastructure for everyone.</h2>
<p dir="auto"><a href="https://twitter.com/ShelfQR" rel="nofollow"><img src="https://camo.githubusercontent.com/529b5acd0d1cbf3a3cfaba6ed41f98eebdba9a4f0b8136b1bcd9ffad15b2ed68/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f636c6f7564706f7373652e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f772532302534305368656c665152" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&amp;label=Follow%20%40ShelfQR"></a>
<a href="https://github.com/Shelf-nu/shelf.nu/actions/workflows/deploy.yml"><img src="https://github.com/Shelf-nu/shelf.nu/actions/workflows/deploy.yml/badge.svg?branch=dev" alt="🚀 Deploy"></a></p>
<p dir="auto">Shelf <g-emoji alias="label" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png">🏷️</g-emoji> Asset Management infrastructure for absolutely everyone (open source).</p>
<p dir="auto">Shelf is a simple and visual asset management and location tracking system that allows people to track their physical assets with ease.</p>
<h2 tabindex="-1" dir="auto">Core Features and Benefits</h2>
<p dir="auto">With Shelf, you can take a picture of any item you own and store it in your own database. From there, you can generate a printable code (QR) that you can tag onto the item, making it easy to identify and locate in the future. Shelf has a handy code printing area where you can add as many QR codes as you can on an A4 sticker paper sheet. You can also add detailed information about the item, including its purchase date, purchase price, warranty information, and more.</p>
<h3 tabindex="-1" dir="auto">Once your assets are online, you will be able to:</h3>
<ul dir="auto">
<li>Generate printable PDFs sheets from assets you select, so you can stick them onto anything</li>
<li>Check the last known location of your assets</li>
<li>Instant Search through your assets database</li>
<li>Use 'lost mode' for emergencies (offer a bounty for a return of an item)</li>
<li>Get notified of assets you are not using</li>
<li>Share your asset vault with other users</li>
</ul>
<h3 tabindex="-1" dir="auto">Use Shelf alone, or as a team. And, these questions will be a thing of the past.</h3>
<ul dir="auto">
<li>Who was the last person that took X,Y or Z?</li>
<li>What gear does X have currently?</li>
<li>Which assets did we appoint to our team member abroad?</li>
<li>What do we have in our storage facility now?</li>
</ul>
<h2 tabindex="-1" dir="auto">Shelf's vision and ambition</h2>
<p dir="auto">To enable and facilitate the tagging of 1 Billion assets by 2023. Shelf therefore allows users to create unlimited assets on their environments. We will fund the growth and further development of the tool by releasing premium features. However, Shelf core will be forever free for individuals.</p>
<hr>
<h3 tabindex="-1" dir="auto">Shelf's current stack</h3>
<p dir="auto">We have decided to give RemixJS a try.</p>
<p dir="auto">For the purpose of shipping asap, we have opted into using a template: <a href="https://github.com/rphlmr/supa-fly-stack">https://github.com/rphlmr/supa-fly-stack</a></p>
<h3 tabindex="-1" dir="auto">Getting started with Shelf</h3>
<h2 tabindex="-1" dir="auto">Remix Supa Fly Stack</h2>
<blockquote>
<p dir="auto">This Readme will be re-written soon</p>
</blockquote>
<div data-snippet-clipboard-copy-content="npx create-remix --template rphlmr/supa-fly-stack"><pre><code>npx create-remix --template rphlmr/supa-fly-stack
</code></pre></div>
<h2 tabindex="-1" dir="auto">What's in the stack</h2>
<ul dir="auto">
<li><a href="https://fly.io/" rel="nofollow">Fly app deployment</a> with <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">Docker</a></li>
<li>Production-ready <a href="https://supabase.com/" rel="nofollow">Supabase Database</a></li>
<li>Healthcheck endpoint for <a href="https://fly.io/docs/reference/configuration/#services-http_checks" rel="nofollow">Fly backups region fallbacks</a></li>
<li><a href="https://github.com/features/actions">GitHub Actions</a> to deploy on merge to production and staging environments</li>
<li>Email/Password Authentication / Magic Link, with <a href="https://remix.run/docs/en/v1/api/remix#createcookiesessionstorage" rel="nofollow">cookie-based sessions</a></li>
<li>Database ORM with <a href="https://prisma.io/" rel="nofollow">Prisma</a></li>
<li>Forms Schema (client and server sides !) validation with <a href="https://github.com/kiliman/remix-params-helper">Remix Params Helper</a></li>
<li>Styling with <a href="https://tailwindcss.com/" rel="nofollow">Tailwind</a></li>
<li>End-to-end testing with <a href="https://cypress.io/" rel="nofollow">Cypress</a></li>
<li>Local third party request mocking with <a href="https://mswjs.io/" rel="nofollow">MSW</a></li>
<li>Unit testing with <a href="https://vitest.dev/" rel="nofollow">Vitest</a> and <a href="https://testing-library.com/" rel="nofollow">Testing Library</a></li>
<li>Code formatting with <a href="https://prettier.io/" rel="nofollow">Prettier</a></li>
<li>Linting with <a href="https://eslint.org/" rel="nofollow">ESLint</a></li>
<li>Static Types with <a href="https://typescriptlang.org/" rel="nofollow">TypeScript</a></li>
</ul>
<p dir="auto">Not a fan of bits of the stack? Fork it, change it, and use <code>npx create-remix --template your/repo</code>! Make it your own.</p>
<h2 tabindex="-1" dir="auto">Development</h2>
<ul dir="auto">
<li>
<p dir="auto">Create a <a href="https://supabase.com/" rel="nofollow">Supabase Database</a> (free tier gives you 2 databases)</p>
<blockquote>
<p dir="auto"><strong>Note:</strong> Only one for playing around with Supabase or 2 for <code>staging</code> and <code>production</code></p>
</blockquote>
<blockquote>
<p dir="auto"><strong>Note:</strong> Used all your free tiers ? Also works with <a href="https://github.com/supabase/cli">Supabase CLI</a> and local self-hosting</p>
</blockquote>
<blockquote>
<p dir="auto"><strong>Note:</strong> Create a strong database password, but prefer a passphrase, it'll be more easy to use in connection string (no need to escape special char)</p>
<p dir="auto"><em>example : my_strong_passphrase</em></p>
</blockquote>
</li>
<li>
<p dir="auto">Go to <a href="https://app.supabase.io/project/%7BPROJECT%7D/settings/api" rel="nofollow">https://app.supabase.io/project/{PROJECT}/settings/api</a> to find your secrets</p>
</li>
<li>
<p dir="auto">"Project API keys"</p>
</li>
<li>
<p dir="auto">Add your <code>MAPTILER_TOKEN</code>, <code>SUPABASE_URL</code>, <code>SERVER_URL</code>, <code>SUPABASE_SERVICE_ROLE</code> (aka <code>service_role</code> <code>secret</code>), <code>SUPABASE_ANON_PUBLIC</code> (aka <code>anon</code> <code>public</code>) and <code>DATABASE_URL</code> in the <code>.env</code> file</p>
<blockquote>
<p dir="auto"><strong>Note:</strong> <code>SERVER_URL</code> is your localhost on dev. It'll work for magic link login</p>
</blockquote>
</li>
</ul>
<div data-snippet-clipboard-copy-content="DATABASE_URL=&quot;postgres://postgres:{STAGING_POSTGRES_PASSWORD}@db.{STAGING_YOUR_INSTANCE_NAME}.supabase.co:5432/postgres&quot;
SUPABASE_ANON_PUBLIC=&quot;{ANON_PUBLIC}&quot;
SUPABASE_SERVICE_ROLE=&quot;{SERVICE_ROLE}&quot;
SUPABASE_URL=&quot;https://{STAGING_YOUR_INSTANCE_NAME}.supabase.co&quot;
SESSION_SECRET=&quot;super-duper-s3cret&quot;
SERVER_URL=&quot;http://localhost:3000&quot;
MAPTILER_TOKEN=&quot;someToken&quot;
SMTP_HOST=&quot;smtp.yourhost.com&quot;
SMTP_USER=&quot;you@example.com&quot;
SMTP_PWD=&quot;yourSMTPpassword&quot;"><pre lang="en"><code>DATABASE_URL="postgres://postgres:{STAGING_POSTGRES_PASSWORD}@db.{STAGING_YOUR_INSTANCE_NAME}.supabase.co:5432/postgres"
SUPABASE_ANON_PUBLIC="{ANON_PUBLIC}"
SUPABASE_SERVICE_ROLE="{SERVICE_ROLE}"
SUPABASE_URL="https://{STAGING_YOUR_INSTANCE_NAME}.supabase.co"
SESSION_SECRET="super-duper-s3cret"
SERVER_URL="http://localhost:3000"
MAPTILER_TOKEN="someToken"
SMTP_HOST="smtp.yourhost.com"
SMTP_USER="you@example.com"
SMTP_PWD="yourSMTPpassword"
</code></pre></div>
<ul dir="auto">
<li>
<p dir="auto">This step only applies if you've opted out of having the CLI install dependencies for you:</p>

</li>
<li>
<p dir="auto">Initial setup:</p>

</li>
<li>
<p dir="auto">Start dev server:</p>

</li>
</ul>
<p dir="auto">This starts your app in development mode, rebuilding assets on file changes.</p>
<p dir="auto">The database seed script creates a new user with some data you can use to get started:</p>
<ul dir="auto">
<li>Email: <code>hello@supabase.com</code></li>
<li>Password: <code>supabase</code></li>
</ul>
<h3 tabindex="-1" dir="auto">Relevant code:</h3>
<p dir="auto">This is a pretty simple note-taking app, but it's a good example of how you can build a full-stack app with Prisma, Supabase, and Remix. The main functionality is creating users, logging in and out (handling access and refresh tokens + refresh on expiration), and creating and deleting notes.</p>
<ul dir="auto">
<li>auth / session <a href="https://github.com/Shelf-nu/shelf.nu/blob/main/app/modules/auth">./app/modules/auth</a></li>
<li>creating, and deleting notes <a href="https://github.com/Shelf-nu/shelf.nu/blob/main/app/modules/note">./app/modules/note</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Deployment</h2>
<blockquote>
<p dir="auto">Do what you know if you are a Fly.io expert.</p>
</blockquote>
<p dir="auto">This Remix Stack comes with two GitHub Actions that handle automatically deploying your app to production and staging environments.</p>
<p dir="auto">Prior to your first deployment, you'll need to do a few things:</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://fly.io/docs/getting-started/installing-flyctl/" rel="nofollow">Install Fly</a></p>
</li>
<li>
<p dir="auto">Sign up and log in to Fly</p>

<blockquote>
<p dir="auto"><strong>Note:</strong> If you have more than one Fly account, ensure that you are signed into the same account in the Fly CLI as you are in the browser. In your terminal, run <code>fly auth whoami</code> and ensure the email matches the Fly account signed into the browser.</p>
</blockquote>
</li>
<li>
<p dir="auto">Create two apps on Fly, one for staging and one for production:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fly apps create supa-fly-stack-template
fly apps create supa-fly-stack-template-staging  # ** not mandatory if you don't want a staging environnement **"><pre>fly apps create supa-fly-stack-template
fly apps create supa-fly-stack-template-staging  <span><span>#</span> ** not mandatory if you don't want a staging environnement **</span></pre></div>
<blockquote>
<p dir="auto"><strong>Note:</strong> For production app, make sure this name matches the <code>app</code> set in your <code>fly.toml</code> file. Otherwise, you will not be able to deploy.</p>
</blockquote>
<ul dir="auto">
<li>Initialize Empty Git repository.</li>
</ul>

</li>
<li>
<p dir="auto">Create a new <a href="https://repo.new/" rel="nofollow">GitHub Repository</a>, and then add it as the remote for your project. <strong>Do not push your app yet!</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git remote add origin <ORIGIN_URL>"><pre>git remote add origin <span>&lt;</span>ORIGIN_URL<span>&gt;</span></pre></div>
</li>
<li>
<p dir="auto">Add <code>MAPTILER_TOKEN</code> which is needed for rendering the map which shows the last scanned location. For more info and to get an account and token: <a href="https://www.maptiler.com/" rel="nofollow">https://www.maptiler.com/</a></p>
</li>
<li>
<p dir="auto">Add a <code>FLY_API_TOKEN</code> to your GitHub repo. To do this, go to your user settings on Fly and create a new <a href="https://web.fly.io/user/personal_access_tokens/new" rel="nofollow">token</a>, then add it to <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets">your repo secrets</a> with the name <code>FLY_API_TOKEN</code>.</p>
</li>
<li>
<p dir="auto">Add a <code>SESSION_SECRET</code>, <code>SUPABASE_URL</code>, <code>SUPABASE_SERVICE_ROLE</code>,<code>SUPABASE_ANON_PUBLIC</code>, <code>SERVER_URL</code> and <code>DATABASE_URL</code> to your fly app secrets</p>
<blockquote>
<p dir="auto"><strong>Note:</strong> To find your <code>SERVER_URL</code>, go to <a href="https://fly.io/apps/supa-fly-stack-template-3a36" rel="nofollow">your fly.io dashboard</a></p>
</blockquote>
<p dir="auto">To do this you can run the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# production (--app name is resolved from fly.toml)
fly secrets set SESSION_SECRET=$(openssl rand -hex 32)
fly secrets set SUPABASE_URL=&quot;https://{YOUR_INSTANCE_NAME}.supabase.co&quot;
fly secrets set SUPABASE_SERVICE_ROLE=&quot;{SUPABASE_SERVICE_ROLE}&quot;
fly secrets set SUPABASE_ANON_PUBLIC=&quot;{SUPABASE_ANON_PUBLIC}&quot;
fly secrets set DATABASE_URL=&quot;postgres://postgres:{POSTGRES_PASSWORD}@db.{YOUR_INSTANCE_NAME}.supabase.co:5432/postgres&quot;
fly secrets set SERVER_URL=&quot;https://{YOUR_STAGING_SERVEUR_URL}&quot;
fly secrets set MAPTILER_TOKEN=&quot;{YOUR_MAPTILER_TOKEN}&quot;

fly secrets set SMTP_HOST=&quot;smtp.yourhost.com&quot;
fly secrets set SMTP_USER=&quot;you@example.com&quot;
fly secrets set SMTP_PWD=&quot;yourSMTPpassword&quot;


# staging (specify --app name) ** not mandatory if you don't want a staging environnement **
fly secrets set SESSION_SECRET=$(openssl rand -hex 32) --app supa-fly-stack-template-staging
fly secrets set SUPABASE_URL=&quot;https://{YOUR_STAGING_INSTANCE_NAME}.supabase.co&quot; --app supa-fly-stack-template-staging
fly secrets set SUPABASE_SERVICE_ROLE=&quot;{STAGING_SUPABASE_SERVICE_ROLE}&quot; --app supa-fly-stack-template-staging
fly secrets set SUPABASE_ANON_PUBLIC=&quot;{STAGING_SUPABASE_ANON_PUBLIC}&quot; --app supa-fly-stack-template-staging
fly secrets set DATABASE_URL=&quot;postgres://postgres:{STAGING_POSTGRES_PASSWORD}@db.{STAGING_YOUR_INSTANCE_NAME}.supabase.co:5432/postgres&quot; --app supa-fly-stack-template-staging
fly secrets set SERVER_URL=&quot;https://{YOUR_STAGING_SERVEUR_URL}&quot; --app supa-fly-stack-template-staging
"><pre><span><span>#</span> production (--app name is resolved from fly.toml)</span>
fly secrets <span>set</span> SESSION_SECRET=<span><span>$(</span>openssl rand -hex 32<span>)</span></span>
fly secrets <span>set</span> SUPABASE_URL=<span><span>"</span>https://{YOUR_INSTANCE_NAME}.supabase.co<span>"</span></span>
fly secrets <span>set</span> SUPABASE_SERVICE_ROLE=<span><span>"</span>{SUPABASE_SERVICE_ROLE}<span>"</span></span>
fly secrets <span>set</span> SUPABASE_ANON_PUBLIC=<span><span>"</span>{SUPABASE_ANON_PUBLIC}<span>"</span></span>
fly secrets <span>set</span> DATABASE_URL=<span><span>"</span>postgres://postgres:{POSTGRES_PASSWORD}@db.{YOUR_INSTANCE_NAME}.supabase.co:5432/postgres<span>"</span></span>
fly secrets <span>set</span> SERVER_URL=<span><span>"</span>https://{YOUR_STAGING_SERVEUR_URL}<span>"</span></span>
fly secrets <span>set</span> MAPTILER_TOKEN=<span><span>"</span>{YOUR_MAPTILER_TOKEN}<span>"</span></span>

fly secrets <span>set</span> SMTP_HOST=<span><span>"</span>smtp.yourhost.com<span>"</span></span>
fly secrets <span>set</span> SMTP_USER=<span><span>"</span>you@example.com<span>"</span></span>
fly secrets <span>set</span> SMTP_PWD=<span><span>"</span>yourSMTPpassword<span>"</span></span>


<span><span>#</span> staging (specify --app name) ** not mandatory if you don't want a staging environnement **</span>
fly secrets <span>set</span> SESSION_SECRET=<span><span>$(</span>openssl rand -hex 32<span>)</span></span> --app supa-fly-stack-template-staging
fly secrets <span>set</span> SUPABASE_URL=<span><span>"</span>https://{YOUR_STAGING_INSTANCE_NAME}.supabase.co<span>"</span></span> --app supa-fly-stack-template-staging
fly secrets <span>set</span> SUPABASE_SERVICE_ROLE=<span><span>"</span>{STAGING_SUPABASE_SERVICE_ROLE}<span>"</span></span> --app supa-fly-stack-template-staging
fly secrets <span>set</span> SUPABASE_ANON_PUBLIC=<span><span>"</span>{STAGING_SUPABASE_ANON_PUBLIC}<span>"</span></span> --app supa-fly-stack-template-staging
fly secrets <span>set</span> DATABASE_URL=<span><span>"</span>postgres://postgres:{STAGING_POSTGRES_PASSWORD}@db.{STAGING_YOUR_INSTANCE_NAME}.supabase.co:5432/postgres<span>"</span></span> --app supa-fly-stack-template-staging
fly secrets <span>set</span> SERVER_URL=<span><span>"</span>https://{YOUR_STAGING_SERVEUR_URL}<span>"</span></span> --app supa-fly-stack-template-staging
</pre></div>
<p dir="auto">If you don't have openssl installed, you can also use <a href="https://1password.com/generate-password" rel="nofollow">1password</a> to generate a random secret, just replace <code>$(openssl rand -hex 32)</code> with the generated secret.</p>
</li>
</ul>
<p dir="auto">Now that everything is set up you can commit and push your changes to your repo. Every commit to your <code>main</code> branch will trigger a deployment to your production environment, and every commit to your <code>dev</code> branch will trigger a deployment to your staging environment.</p>
<blockquote>
<p dir="auto"><strong>Note:</strong> To deploy manually, just run <code>fly deploy</code> (It'll deploy app defined in fly.toml)</p>
</blockquote>
<h2 tabindex="-1" dir="auto">File Storage</h2>
<p dir="auto">For File storage we use the S3 buckets service provided by supabase. We do this as it makes it easier to manage permissions in relation to our users which are also stored on supabase. To set it up you need to do the following steps:</p>
<h3 tabindex="-1" dir="auto">Profile pictures</h3>
<ol dir="auto">
<li>Create a bucket called <code>profile-pictures</code></li>
<li>Make it a public bucket</li>
<li>Implement a policy for <code>INSERT</code>, <code>UPDATE</code> &amp; <code>DELETE</code>. The policy expression is: <code>((bucket_id = 'profile-pictures'::text) AND ((storage.foldername(name))[1] = (auth.uid())::text))</code> and target roles should be set to <code>authenticated</code></li>
</ol>
<h3 tabindex="-1" dir="auto">Items</h3>
<ol dir="auto">
<li>Create a bucket called <code>items</code></li>
<li>Implement a policy for <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code> &amp; <code>DELETE</code>. The policy expression is: <code>((bucket_id = 'items'::text) AND ((storage.foldername(name))[1] = (auth.uid())::text))</code> and target roles should be set to <code>authenticated</code></li>
</ol>
<h2 tabindex="-1" dir="auto">GitHub Actions</h2>
<blockquote>
<p dir="auto">DISCLAIMER : Github actions ==&gt; I'm not an expert about that. Read carefully before using it</p>
</blockquote>
<p dir="auto">We use GitHub Actions for continuous integration and deployment. Anything that gets into the <code>main</code> branch will be deployed to production after running tests/build/etc. Anything in the <code>dev</code> branch will be deployed to staging.</p>
<p dir="auto"><g-emoji alias="point_right" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f449.png">👉</g-emoji> <strong>You have to add some env secrets for cypress.</strong> <g-emoji alias="point_left" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f448.png">👈</g-emoji></p>
<p dir="auto">Add a <code>SESSION_SECRET</code>, <code>SUPABASE_URL</code>, <code>SUPABASE_SERVICE_ROLE</code>,<code>SUPABASE_ANON_PUBLIC</code>, <code>SERVER_URL</code> and <code>DATABASE_URL</code> to <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets">your repo secrets</a></p>
<h2 tabindex="-1" dir="auto">Testing</h2>
<h3 tabindex="-1" dir="auto">Cypress</h3>
<p dir="auto">We use Cypress for our End-to-End tests in this project. You'll find those in the <code>cypress</code> directory. As you make changes, add to an existing file or create a new file in the <code>cypress/e2e</code> directory to test your changes.</p>
<p dir="auto">We use <a href="https://testing-library.com/cypress" rel="nofollow"><code>@testing-library/cypress</code></a> for selecting elements on the page semantically.</p>
<p dir="auto">To run these tests in development, complete your <code>.env</code> and run <code>npm run test:e2e:dev</code> which will start the dev server for the app as well as the Cypress client. Make sure the database is running in docker as described above.</p>
<p dir="auto">We also have a utility to auto-delete the user at the end of your test. Just make sure to add this in each test file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="afterEach(() => {
  cy.cleanupUser();
});"><pre><span>afterEach</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>cy</span><span>.</span><span>cleanupUser</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">That way, we can keep your test db clean and keep your tests isolated from one another.</p>
<h3 tabindex="-1" dir="auto">Vitest</h3>
<p dir="auto">For lower level tests of utilities and individual components, we use <code>vitest</code>. We have DOM-specific assertion helpers via <a href="https://testing-library.com/jest-dom" rel="nofollow"><code>@testing-library/jest-dom</code></a>.</p>
<h3 tabindex="-1" dir="auto">Type Checking</h3>
<p dir="auto">This project uses TypeScript. It's recommended to get TypeScript set up for your editor to get a great in-editor experience with type checking and auto-complete. To run type checking across the whole project, run <code>npm run typecheck</code>.</p>
<h3 tabindex="-1" dir="auto">Linting</h3>
<p dir="auto">This project uses ESLint for linting. That is configured in <code>.eslintrc.js</code>.</p>
<h3 tabindex="-1" dir="auto">Formatting</h3>
<p dir="auto">We use <a href="https://prettier.io/" rel="nofollow">Prettier</a> for auto-formatting in this project. It's recommended to install an editor plugin (like the <a href="https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode" rel="nofollow">VSCode Prettier plugin</a>) to get auto-formatting on save. There's also a <code>npm run format</code> script you can run to format all files in the project.</p>
<h2 tabindex="-1" dir="auto">Start working with Supabase</h2>
<p dir="auto">You are now ready to go further, congrats!</p>
<p dir="auto">To extend your Prisma schema and apply changes on your supabase database :</p>
<ul dir="auto">
<li>
<p dir="auto">Make your changes in <a href="https://github.com/Shelf-nu/shelf.nu/blob/main/app/database/schema.prisma">./app/database/schema.prisma</a></p>
</li>
<li>
<p dir="auto">Prepare your schema migration</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm run db:prepare-migration"><pre>npm run db:prepare-migration</pre></div>
</li>
<li>
<p dir="auto">Check your migration in <a href="https://github.com/Shelf-nu/shelf.nu/blob/main/app/database">./app/database/migrations</a></p>
</li>
<li>
<p dir="auto">Apply this migration to production</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm run db:deploy-migration"><pre>npm run db:deploy-migration</pre></div>
</li>
</ul>
<h2 tabindex="-1" dir="auto">If your token expires in less than 1 hour (3600 seconds in Supabase Dashboard)</h2>
<p dir="auto">If you have a lower token lifetime than me (1 hour), you should take a look at <code>REFRESH_ACCESS_TOKEN_THRESHOLD</code> in <a href="https://github.com/Shelf-nu/shelf.nu/blob/main/app/modules/auth/session.server.ts">./app/modules/auth/session.server.ts</a> and set what you think is the best value for your use case.</p>
<h2 tabindex="-1" dir="auto">Supabase RLS</h2>
<p dir="auto">You may ask "can I use RLS with Remix".</p>
<p dir="auto">The answer is "Yes" but It has a cost.</p>
<p dir="auto">Using Supabase SDK server side to query your database (for those using RLS features) adds an extra delay due to calling a Gotrue rest API instead of directly calling the Postgres database (and this is fine because at first Supabase SDK is for those who don't have/want backend).</p>
<p dir="auto">In my benchmark, it makes my pages twice slower. (~+200ms compared to a direct query with Prisma)</p>
<h2 tabindex="-1" dir="auto">Supabase login with magic link</h2>
<p dir="auto">In order to make the register/login with magic link work, you will need to add some configuration to your Supabase.
You need to add the site url as well as the redirect urls of your local, test and live app that will be used for oauth
To do that navigate to Authentication &gt; URL configiration and add the folowing values:</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://localhost:3000/oauth/callback" rel="nofollow">https://localhost:3000/oauth/callback</a></p>
</li>
<li>
<p dir="auto"><a href="https://localhost:3000/reset-password" rel="nofollow">https://localhost:3000/reset-password</a></p>
</li>
<li>
<p dir="auto"><a href="https://staging-domain.com/oauth/callback" rel="nofollow">https://staging-domain.com/oauth/callback</a></p>
</li>
<li>
<p dir="auto"><a href="https://staging-domain.com/reset-password" rel="nofollow">https://staging-domain.com/reset-password</a></p>
</li>
<li>
<p dir="auto"><a href="https://live-domain.com/oauth/callback" rel="nofollow">https://live-domain.com/oauth/callback</a></p>
</li>
<li>
<p dir="auto"><a href="https://live-domain.com/reset-password" rel="nofollow">https://live-domain.com/reset-password</a></p>
</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hilbert Transform (122 pts)]]></title>
            <link>https://electroagenda.com/en/hilbert-transform/</link>
            <guid>36666260</guid>
            <pubDate>Mon, 10 Jul 2023 13:39:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electroagenda.com/en/hilbert-transform/">https://electroagenda.com/en/hilbert-transform/</a>, See on <a href="https://news.ycombinator.com/item?id=36666260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

			
<p>The Hilbert transform is a linear operation applied to real signals. In practical terms, the Hilbert transform translates into a phase shift of -90º at the positive frequencies (and +90º at the negative frequencies) that make up the signal. The relevance of the Hilbert transform in telecommunication engineering is due to its contribution in obtaining spectrally efficient signals. For example in the generation of signals with single sideband spectrum or in the generation of the analytical signal.</p>



<p>Next, the basic mathematics of the Hilbert transform and its generic effects on signals in the time and frequency domains are reviewed. Finally, its main applications are discussed. The text is organized with the following table of contents:</p>



<div id="ez-toc-container">

<nav><ul><li><a href="#1_The_Mathematics_of_Hilbert_Transform" title="1. The Mathematics of Hilbert Transform">1. The Mathematics of Hilbert Transform</a><ul><li><a href="#11_Frequency_Domain" title="1.1 Frequency Domain">1.1 Frequency Domain</a></li><li><a href="#12_Time_Domain" title="1.2 Time Domain">1.2 Time Domain</a></li></ul></li><li><a href="#2_Hilbert_Transform_Effects_on_Signals" title="2. Hilbert Transform Effects on Signals">2. Hilbert Transform Effects on Signals</a><ul><li><a href="#21_Baseband_Signals" title="2.1 Baseband Signals">2.1 Baseband Signals</a></li><li><a href="#22_Bandpass_Signals" title="2.2 Bandpass Signals">2.2 Bandpass Signals</a></li></ul></li><li><a href="#3_Applications_of_the_Hilbert_Transform_in_Communications" title="3. Applications of the Hilbert Transform in Communications">3. Applications of the Hilbert Transform in Communications</a><ul><li><a href="#31_Single_Side_Band_Spectrum_SSB" title="3.1 Single Side Band Spectrum (SSB)">3.1 Single Side Band Spectrum (SSB)</a><ul><li><a href="#311_Schematic_Representation" title="3.1.1 Schematic Representation">3.1.1 Schematic Representation</a></li><li><a href="#312_Mathematical_Representation" title="3.1.2 Mathematical Representation">3.1.2 Mathematical Representation</a></li></ul></li><li><a href="#32_Quadrature_Signals" title="3.2 Quadrature Signals">3.2 Quadrature Signals</a><ul><li><a href="#321_Analytic_Signal" title="3.2.1 Analytic Signal">3.2.1 Analytic Signal</a><ul><li><a href="#3211_Mathematical_Representation" title="3.2.1.1 Mathematical Representation">3.2.1.1 Mathematical Representation</a></li><li><a href="#3212_Spectral_Representation" title="3.2.1.2 Spectral Representation">3.2.1.2 Spectral Representation</a></li></ul></li><li><a href="#322_Complex_Envelope" title="3.2.2 Complex Envelope">3.2.2 Complex Envelope</a><ul><li><a href="#3221_Mathematical_Representation" title="3.2.2.1 Mathematical Representation">3.2.2.1 Mathematical Representation</a></li><li><a href="#3222_Spectral_Representation" title="3.2.2.2 Spectral Representation">3.2.2.2 Spectral Representation</a></li></ul></li></ul></li></ul></li><li><a href="#4_Conclusions" title="4. Conclusions">4. Conclusions</a></li></ul></nav></div>




<h2><span id="1_The_Mathematics_of_Hilbert_Transform"></span>1. The Mathematics of Hilbert Transform<span></span></h2>



<p>In this section it is shown that the Hilbert transform  <span data-katex-display="false"> \footnotesize \hat{s}(t) </span> of a real signal <em>s(t)</em> is an operator <span data-katex-display="false"> \footnotesize \mathcal H() </span> equivalent to a linear, noncausal, time invariant filter <a href="http://electroagenda.com/carlson" target="_blank" rel="noreferrer noopener">[1]</a> <a href="http://electroagenda.com/openheim" target="_blank" rel="noreferrer noopener">[2]</a>. The mathematics of the Hilbert transform are explained in both the time and frequency domains. For this purpose, in a generic way, the following notation is used:</p>



<p><span data-katex-display="true">\begin{equation} s(t) \xtofrom[\mathcal{H}^{-1}]{\mathcal{H}} \hat{s}(t) \end{equation}</span> </p>



<p><span data-katex-display="true">\begin{equation} \hat{s}(t) = s(t) * h_{\mathcal{H}}(t)  \end{equation}</span></p>



<p><span data-katex-display="true">\begin{equation} \hat{S}(f) = S(f) · H_{\mathcal{H}}(f)  \end{equation}</span></p>



<p>Where <span data-katex-display="false"> \footnotesize h_{\mathcal{H}}(t) </span> represents the impulse response of the Hilbert transform operator in the time domain, and <span data-katex-display="false"> \footnotesize H_{\mathcal{H}}(f) </span> represents its transfer function in the frequency domain. </p>



<h3><span id="11_Frequency_Domain"></span>1.1 Frequency Domain<span></span></h3>



<p>The analysis in the frequency domain allows a more intuitive interpretation of the Hilbert transform. Given a real signal whose (hermitic) spectrum is <em>S(f)</em>, the transformed spectrum <span data-katex-display="false"> \footnotesize \hat{S}(f) </span> essentially experiences a phase shift of 90°. Specifically, and given the hermiticity of a real signal, this is a phase shift of -90º at positive frequencies and +90º at negative frequencies. Mathematically, therefore, the transfer function of the Hilbert transform is:</p>



<p><span data-katex-display="true">\begin{equation} H_{\mathcal{H}}(f) = -j·sgn(f) = \begin{cases} -j = e^{-j \frac{\pi}{2}} &amp;\text{for } f &gt; 0 \\  0 &amp;\text{for } f = 0 \\ +j= e^{+j \frac{\pi}{2}} &amp;\text{for } f &lt; 0 \end{cases} \end{equation}</span></p>



<p>Thus, the Hilbert transform of the basic trigonometric functions is as follows:</p>



<p><span data-katex-display="true">\begin{equation} \cos(2\pi ft) \xtofrom[\mathcal{H}^{-1}]{\mathcal{H}} \sin(2\pi ft) \xtofrom[\mathcal{H}^{-1}]{\mathcal{H}} -\cos(2\pi ft) \xtofrom[\mathcal{H}^{-1}]{\mathcal{H}} - \sin(2\pi ft) \xtofrom[\mathcal{H}^{-1}]{\mathcal{H}} \cos(2\pi ft) \end{equation}</span> </p>



<p>Note that, in practical terms, the above equation implies that if a signal is represented as a sum of positive frequency components, its Hilbert transform is obtained by adding a phase shift of -90º to these components. </p>



<h3><span id="12_Time_Domain"></span>1.2 Time Domain<span></span></h3>



<p>The impulsional response of the Hilbert transform is:</p>



<p><span data-katex-display="true">\begin{equation} h_{\mathcal{H}}(t) = \cfrac{1}{\pi t}  \end{equation}</span></p>



<p>And, consequently, it is satisfied that its Fourier transform is equal to the transfer function mentioned in the previous section:</p>



<p><span data-katex-display="true">\begin{equation} \cfrac{1}{\pi t} \xtofrom[\mathcal{F}^{-1}]{\mathcal{F}} -j·sgn(f) \end{equation}</span></p>



<p>Proving the above equation directly involves employing the concept of the <a href="https://en.wikipedia.org/wiki/Cauchy_principal_value" target="_blank" rel="noreferrer noopener nofollow">Cauchy Principal Value</a>, which is beyond the scope of this text. Instead, an indirect demonstration is made based on the <a href="https://www.tutorialspoint.com/signals-and-systems-duality-property-of-fourier-transform#" target="_blank" rel="noreferrer noopener nofollow">Duality Property</a> of the Fourier transform, so that it must be satisfied that: </p>



<p><span data-katex-display="true">\begin{equation} -j·sgn(t)  \xtofrom[\mathcal{F}^{-1}]{\mathcal{F}} -\cfrac{1}{\pi f}\end{equation}</span></p>



<p>To prove the above equation, the following concepts must be taken into account:</p>



<ul>
<li>The derivative of the sign function is related to the Dirac delta <em>δ(t)</em> according to the following equation:</li>
</ul>



<p><span data-katex-display="true">\begin{equation} \frac{\partial}{\partial t}sgn(t) = 2\delta(t) \end{equation}</span></p>



<ul>
<li>The Fourier transform of the Dirac delta function is equal to unity so that, from equation (9), it follows:</li>
</ul>



<p><span data-katex-display="true">\begin{equation} {\mathcal{F}} \left[\frac{\partial}{\partial t}sgn(t)\right] = 2 \end{equation}</span></p>



<ul>
<li>The <a href="https://www.tutorialspoint.com/time-differentiation-property-of-fourier-transform" target="_blank" rel="noreferrer noopener nofollow">Fourier transform of the derivative</a> of a generic function <em>g(t)</em> is related to the transform of the function itself such that:</li>
</ul>



<p><span data-katex-display="true">\begin{equation} {\mathcal{F}} \left[\frac{\partial}{\partial t}g(t)\right]= j2\pi f{\mathcal{F}}[g(t)] \end{equation}</span></p>



<p>Applying the generic equation (11) to the function <em>sgn(t)</em> and comparing the result with equation (10), equation (8) follows directly as it was intended to demonstrate. </p>



<h2><span id="2_Hilbert_Transform_Effects_on_Signals"></span>2. Hilbert Transform Effects on Signals<span></span></h2>



<p>This section shows that the effects of the Hilbert transform depend on the spectrum of the original signal. In particular, the cases of baseband and bandpass signals are distinguished. In practice, Hilbert transform applications focus on the spectrum and the spectral efficiency, so the effects on the signal in the time domain may not be relevant.   </p>



<p>For a more generic description of the effect of <a href="https://electroagenda.com/en/frequency-constant-phase-shift-and-distortion/">constant frequency phase shift</a> on real signals, please consult this <a href="https://electroagenda.com/en/frequency-constant-phase-shift-and-distortion/">link</a>.</p>



<h3><span id="21_Baseband_Signals"></span>2.1 Baseband Signals<span></span></h3>



<p>The following image shows the spectrum of a real baseband signal before and after applying the Hilbert transform. The phase shifts of -90º at positive frequencies and 90º at negative frequencies are observed.</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/06/Banda_Base_Signal_mod.png" alt="(ES) Espectro de transformada de Hilbert de señal banda base. (EN) Spectrum of Hilbert transform of baseband signal." width="669" height="365" srcset="https://electroagenda.com/wp-content/uploads/2023/06/Banda_Base_Signal_mod.png 892w, https://electroagenda.com/wp-content/uploads/2023/06/Banda_Base_Signal_mod-300x164.png 300w, https://electroagenda.com/wp-content/uploads/2023/06/Banda_Base_Signal_mod-768x419.png 768w" sizes="(max-width: 669px) 100vw, 669px"></figure></div>


<p>Since each of the frequencies that make up the signal suffers a constant phase shift, which is not <a href="https://electroagenda.com/en/the-mathematics-of-linear-distortion/">linear</a> with frequency, the appearance of the resulting time signal is different from that of the original signal. In other words, <a href="https://electroagenda.com/en/transmission-media/phase-distortion-explanation-and-examples/">phase distortion</a> has occurred. The following graph shows an example of a real baseband signal and its Hilbert transform, in the time domain, where the change of aspect can be appreciated:  </p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_baseband_saved_mod_ES.png" alt="(ES) Efecto en el tiempo de la trnasformada de Hilbert para señal banda base. (EN) Hilbert Transform effect on temporal baseband signal." width="743" height="320" srcset="https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_baseband_saved_mod_ES.png 990w, https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_baseband_saved_mod_ES-300x129.png 300w, https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_baseband_saved_mod_ES-768x331.png 768w" sizes="(max-width: 743px) 100vw, 743px"></figure></div>


<h3><span id="22_Bandpass_Signals"></span>2.2 Bandpass Signals<span></span></h3>



<p>In line with the previous example, the application of the Hilbert transform to a real bandpass signal produces the effect on the spectrum shown in the following image:</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/06/Pass_Band_Signal_mod-1024x469.png" alt="(ES) Efecto de la  transformada de Hilbert en espectro de señal paso banda. (EN) Hilbert transform effect on pass band spectrum." width="768" height="352" srcset="https://electroagenda.com/wp-content/uploads/2023/06/Pass_Band_Signal_mod-1024x469.png 1024w, https://electroagenda.com/wp-content/uploads/2023/06/Pass_Band_Signal_mod-300x138.png 300w, https://electroagenda.com/wp-content/uploads/2023/06/Pass_Band_Signal_mod-768x352.png 768w, https://electroagenda.com/wp-content/uploads/2023/06/Pass_Band_Signal_mod.png 1032w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>


<p>With a reasoning equivalent to the baseband example, it could be deduced that the resulting signal is different from the original signal, presenting <a href="https://electroagenda.com/en/transmission-media/phase-distortion-explanation-and-examples/">phase distortion</a>. The following graph illustrates this behavior:</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_wideband_ES.png" alt="(ES) Efecto temporal de la transformada de Hilbert en señal real paso banda. (EN) Temporal effect of Hilbert Transform on pass band real signal." width="732" height="640" srcset="https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_wideband_ES.png 976w, https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_wideband_ES-300x262.png 300w, https://electroagenda.com/wp-content/uploads/2023/06/phase_cte_wideband_ES-768x671.png 768w" sizes="(max-width: 732px) 100vw, 732px"></figure></div>


<p>However, in the case of bandpass signals there is an important clarification. As shown in the image, the envelope of the transformed signal (in black) is equal to the envelope of the original signal. The envelope is the modulating signal, or the signal that is typically intended to be communicated. The effect of the Hilbert transform can be understood as equivalent to a 90º phase shift in the transmitter’s carrier. Therefore, once the receiver locked to the received signal, the demodulated envelope would be the same as the transmitted envelope. In other words, there would be no distortion in the communication.  </p>



<h2><span id="3_Applications_of_the_Hilbert_Transform_in_Communications"></span>3. Applications of the Hilbert Transform in Communications<span></span></h2>



<p>In telecommunications engineering, the Hilbert transform is a fundamental tool for processing and obtaining spectrally efficient signals. <a href="https://electroagenda.com/hilbert" target="_blank" rel="noreferrer noopener">[3]</a>. This section briefly reviews their main applications.</p>



<h3><span id="31_Single_Side_Band_Spectrum_SSB"></span>3.1 Single Side Band Spectrum (SSB)<span></span></h3>



<p>In this case, the Hilbert transform is used to reduce the transmission bandwidth of a bandpass signal. </p>



<h4><span id="311_Schematic_Representation"></span>3.1.1 Schematic Representation<span></span></h4>



<p>The following graph is used to illustrate this strategy: </p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/07/SSB_thesis_mod-1024x653.png" alt="(ES) Generación de banda lateral única a partir de la transformada de Hilbert. (EN) Single Side Band Generation using Hilbert Transform.  " width="768" height="490" srcset="https://electroagenda.com/wp-content/uploads/2023/07/SSB_thesis_mod-1024x653.png 1024w, https://electroagenda.com/wp-content/uploads/2023/07/SSB_thesis_mod-300x191.png 300w, https://electroagenda.com/wp-content/uploads/2023/07/SSB_thesis_mod-768x490.png 768w, https://electroagenda.com/wp-content/uploads/2023/07/SSB_thesis_mod.png 1109w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>


<p>The starting point is a real baseband signal <em>s(t)</em>. For simplicity, and without loss of generality, the baseband signal in the image consists of a single tone. As seen in the upper branch, when the baseband signal modulates a carrier, frequency components are obtained on both sides of the center frequency <em>ω<sub>c</sub></em> (red and green components in the image). This is known as a double sideband signal (DSB).</p>



<p>However, when adding or subtracting the double-sideband signals obtained by quadrature modulating the original signal <em>s(t)</em> and its Hilbert transform <span data-katex-display="false"> \footnotesize \hat{s}(t) </span>, a single sideband spectrum (SSB) is obtained. Indeed, because the sum of two components with an offset of <em>π</em> radians cancels out, a spectrum can be obtained that only includes frequencies below or above the center frequency (green and red respectively in the image).</p>



<h4><span id="312_Mathematical_Representation"></span>3.1.2 Mathematical Representation<span></span></h4>



<p>It is evident that the above reasoning can be extended to a generic real baseband signal <em>s(t)</em> with a given bandwidth. In this way the Hilbert transform allows to obtain an SSB bandpass signal by the scheme shown in the image. Mathematically:</p>



<p><span data-katex-display="true">\begin{equation} s_{SSB}(t) = s(t)\cos(\omega_ct) \pm \hat{s}(t)\sin(\omega_ct)  \end{equation}</span></p>



<p>The above scheme can be implemented both in an analog form (typically using 90º hybrid couplers and IQ mixers) and with digital signal processing.</p>



<h3><span id="32_Quadrature_Signals"></span>3.2 Quadrature Signals<span></span></h3>



<p>The Hilbert transform is also used in the generation of quadrature signals, i.e. in the complex plane. The advantages of generating and processing these signals are briefly explained below. </p>



<h4><span id="321_Analytic_Signal"></span>3.2.1 Analytic Signal<span></span></h4>



<p>Given a real bandpass signal <em>s(t)</em>, its analytical signal <em>s<sub>a</sub>(t)</em> is complex and incorporates only the positive frequencies of <em>s(t)</em>. In addition <em>s<sub>a</sub><sup><sub>*</sub></sup>(t)</em>, which is also complex, incorporates only the negative frequencies of <em>s(t)</em>. </p>



<h5><span id="3211_Mathematical_Representation"></span>3.2.1.1 Mathematical Representation<span></span></h5>



<p>The analytic signal with the properties described above is obtained by means of the following equation:</p>



<p><span data-katex-display="true">\begin{equation} s_{a}(t) = s(t)+j\hat{s}(t)  \end{equation}</span></p>



<p><span data-katex-display="true">\begin{equation} s_{a}^*(t) = s(t)-j\hat{s}(t)  \end{equation}</span></p>



<p>It is practically immediate to demonstrate that negative frequencies have been eliminated in the generation of the signal <em>s<sub>a</sub>(t)</em>. Mathematically, applying (3) and (4) in (13) gives that:</p>



<p><span data-katex-display="true">\begin{equation} S_a(f) = \begin{cases}S(f)+j[-jS(f)] =2S(f)&amp;\text{for } f &gt;0 \\ S(f)+j0 =S(f)&amp;\text{for } f =0 \\ S(f)+j[jS(f)]=0 &amp;\text{for } f&lt;0  \end{cases}  \end{equation}</span></p>



<p>Similarly:</p>



<p><span data-katex-display="true">\begin{equation} S_a^*(f) = \begin{cases}0&amp;\text{for } f &gt;0 \\ S(f)&amp;\text{for } f =0 \\ 2S(f) &amp;\text{for } f&lt;0  \end{cases}  \end{equation}</span></p>



<h5><span id="3212_Spectral_Representation"></span>3.2.1.2 Spectral Representation<span></span></h5>



<p>Below is an example representing the spectrum of a real bandpass signal and its analytic signal:</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/07/Analytic_Pass_Band_Signal-1024x576.png" alt="(ES) Espectro de señal paso banda y de su señal analítica. (EN) Pass band signal spectrum and its analytic signal spectrum. " width="768" height="432" srcset="https://electroagenda.com/wp-content/uploads/2023/07/Analytic_Pass_Band_Signal-1024x576.png 1024w, https://electroagenda.com/wp-content/uploads/2023/07/Analytic_Pass_Band_Signal-300x169.png 300w, https://electroagenda.com/wp-content/uploads/2023/07/Analytic_Pass_Band_Signal-768x432.png 768w, https://electroagenda.com/wp-content/uploads/2023/07/Analytic_Pass_Band_Signal.png 1058w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>


<p>The main advantage of the analytic signal is to eliminate the negative frequencies of a real signal, which can be considered superfluous due to Hermitic symmetry. Switching to complex notation facilitates many mathematical manipulations, especially in modulation and demodulation techniques. After processing the corresponding application, taking the real part of the post-processed analytical signal allows to obtain the real result signal with all its frequencies, positive and negative.</p>



<h4><span id="322_Complex_Envelope"></span>3.2.2 Complex Envelope<span></span></h4>



<p>The complex envelope is obtained from the analytic signal. It represents the baseband signal resulting from moving the analytic signal from its center frequency to DC. </p>



<h5><span id="3221_Mathematical_Representation"></span>3.2.2.1 Mathematical Representation<span></span></h5>



<p>To transfer a bandpass signal from a center frequency, without creating additional replicas, it is necessary to multiply it by a frequency phasor. Assuming that the analytic signal is centered at the carrier frequency <em>ω<sub>c</sub></em>, the complex envelope can be obtained by the following operation:</p>



<p><span data-katex-display="true">\begin{equation} s_{a\downarrow}(t) = s_{a}(t)e^{-j\omega_c t}  \end{equation}</span></p>



<p><span data-katex-display="true">\begin{equation} s_{a\uparrow}(t) = s_{a}^*(t)e^{j\omega_c t}  \end{equation}</span></p>



<h5><span id="3222_Spectral_Representation"></span>3.2.2.2 Spectral Representation<span></span></h5>



<p>Below is an example representing the spectrum of a real bandpass signal and its complex envelope:</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://electroagenda.com/wp-content/uploads/2023/07/Complex_Envelope-1024x576.png" alt="(ES) Espectros de señal paso banda real y su envolvente compleja. (EN) Spectra of pass band real signal and its complex envelope." width="768" height="432" srcset="https://electroagenda.com/wp-content/uploads/2023/07/Complex_Envelope-1024x576.png 1024w, https://electroagenda.com/wp-content/uploads/2023/07/Complex_Envelope-300x169.png 300w, https://electroagenda.com/wp-content/uploads/2023/07/Complex_Envelope-768x432.png 768w, https://electroagenda.com/wp-content/uploads/2023/07/Complex_Envelope.png 1058w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>


<p>A very important advantage over the previous analytic signal is obtained: the signal bandwidth has been reduced, potentially by half. Therefore signal processing can be performed at a lower sampling rate. However, recovering the bandpass signal is more complex because it also requires a frequency shift: </p>



<p><span data-katex-display="true">\begin{equation} s(t) = \real[s_{a}(t)] = \real[s_{a\downarrow}(t)e^{j\omega_c t}]  \end{equation}</span></p>



<p><span data-katex-display="true">\begin{equation} s(t) = \real[s_{a}^*(t)] = \real[s_{a\uparrow}(t)e^{-j\omega_c t}]  \end{equation}</span></p>



<h2><span id="4_Conclusions"></span>4. Conclusions<span></span></h2>



<p>The conclusions of the text are as follows:</p>



<ul>
<li>The Hilbert transform is a linear operator that produces a phase shift of -90º in the (positive) frequencies of a signal.</li>
</ul>



<ul>
<li>The effect of the Hilbert transform in the time domain depends on the signal spectrum. While in baseband cases the appearance of the signal changes completely, in bandpass cases the signal envelope remains unchanged. </li>
</ul>



<ul>
<li>The main application of the Hilbert transform in communications is the generation of spectrally efficient signals: single sideband signal, analytical signal and complex envelope.  </li>
</ul>







<hr>



<p><strong>Bibliography</strong><br><a href="http://www.electroagenda.com/carlson" target="_blank" rel="noreferrer noopener">[1] <em>Communication Systems</em>, A. Bruce Carlson.</a><br><a href="http://www.electroagenda.com/openheim" target="_blank" rel="noreferrer noopener">[2] <em>Signals and Systems</em>, A. V. Openheim.</a><br><a href="https://electroagenda.com/hilbert" target="_blank" rel="noreferrer noopener">[3] <em>Hilbert Transform in Signal Processing</em>, Stephan Hahn.</a><br></p>



<hr>



<p><strong>Subscription</strong><br>If you liked this contribution, please do not hesitate to subscribe to our newsletter:<br></p>


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox Address Bar Tips (911 pts)]]></title>
            <link>https://wiki.tilde.institute/w/firefox-address-bar-tips</link>
            <guid>36666116</guid>
            <pubDate>Mon, 10 Jul 2023 13:30:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.tilde.institute/w/firefox-address-bar-tips">https://wiki.tilde.institute/w/firefox-address-bar-tips</a>, See on <a href="https://news.ycombinator.com/item?id=36666116">Hacker News</a></p>
<div id="readability-page-1" class="page">

<!--
title: firefox address bar tips
author: erxeto
description: Some useful tips for using the firefox address bar more
efficiently
-->



<p>The address bar has become our entry point to the internet these days.
Firefox in its default configuration does some sort of <em>smart</em> guess on
what you type there.  If it resembles a <a href="https://en.wikipedia.org/wiki/URL">URL</a>
then the browser makes that request.  If not, it sends the string you typed
to your default search engine.  It also includes some fuzzy search matches
from your history and all that, which is fine 90% of the time, but
sometimes you need a bit more control over what results it shows you.</p>

<h2>Changing the address bar behaviour</h2>

<p>This is a list of modifiers you can set at the beginning of the search to
tell firefox what do you want to see on the results, a kind of filtering:</p>

<pre><code>^    to search for matches in your browsing history.
*    to search for matches in your bookmarks.
+    to search for matches in pages you've tagged.
%    to search for matches in your currently open tabs.
#    to search for matches in page titles.
$    to search for matches in web addresses (URLs).
?    to search for matches in suggestions.
</code></pre>

<h2>Examples</h2>

<p>So, if you want to search for the word <code>headphones</code> in your bookmarks only,
you can type on the address bar:</p>

<p><code>*headphones</code></p>

<p>And, if you want to include only the results of your browsing history it
would be:</p>

<p><code>^headphones</code></p>

<p><a href="https://wiki.tilde.institute/">back</a></p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swap Anything Released – Most Flexible AI Swap (110 pts)]]></title>
            <link>https://imgcreator.zmo.ai/ai-generator</link>
            <guid>36666087</guid>
            <pubDate>Mon, 10 Jul 2023 13:27:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://imgcreator.zmo.ai/ai-generator">https://imgcreator.zmo.ai/ai-generator</a>, See on <a href="https://news.ycombinator.com/item?id=36666087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__nuxt"><div data-v-2e02c169=""><header data-v-2e02c169=""><p data-v-2e02c169=""><a target="_blank" href="https://www.producthunt.com/posts/kawaai" data-v-2e02c169=""> ✨ Please support us on product hunt, free credits provided there <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18px" height="18px" fill="currentColor" data-v-2e02c169=""><path d="m10.875 19.3-6.6-6.6q-.15-.15-.213-.325T4 12q0-.2.063-.375t.212-.325l6.6-6.6q.275-.275.688-.287t.712.287q.3.275.313.688T12.3 6.1L7.4 11h11.175q.425 0 .713.288t.287.712q0 .425-.287.713t-.713.287H7.4l4.9 4.9q.275.275.288.7t-.288.7q-.275.3-.7.3t-.725-.3Z"></path></svg></a><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18px" height="18px" fill="currentColor" data-v-2e02c169=""><path d="M12 2c5.53 0 10 4.47 10 10s-4.47 10-10 10S2 17.53 2 12 6.47 2 12 2m3.59 5L12 10.59 8.41 7 7 8.41 10.59 12 7 15.59 8.41 17 12 13.41 15.59 17 17 15.59 13.41 12 17 8.41 15.59 7Z"></path></svg></p><div data-v-2e02c169=""><nav data-v-2e02c169=""><a href="https://imgcreator.zmo.ai/" data-v-2e02c169=""><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 942 200" width="145px" height="32px" data-v-2e02c169=""><path fill="currentColor" d="M337 147.5V51.463h18.85V147.5H337Zm32.532 0V51.463h23.562l13.162 62.074 13.325-62.075h23.4V147.5h-16.575V75.675L412.594 147.5h-12.837l-13.65-71.825V147.5h-16.575Zm107.271 1.787c-3.683 0-7.15-.596-10.4-1.787-3.142-1.192-5.742-3.521-7.8-6.988-2.058-3.575-3.088-8.883-3.088-15.925v-52.65c0-5.633 1.084-10.02 3.25-13.162 2.275-3.142 5.417-5.308 9.425-6.5 4.009-1.3 8.667-1.95 13.975-1.95 5.309 0 9.967.65 13.975 1.95 4.117 1.192 7.313 3.358 9.588 6.5 2.383 3.142 3.575 7.53 3.575 13.162v13.488H490.94V70.962c0-2.6-.379-4.55-1.137-5.85-.65-1.408-1.571-2.329-2.763-2.762-1.191-.433-2.654-.65-4.387-.65-1.625 0-3.088.217-4.388.65-1.191.433-2.166 1.354-2.925 2.762-.65 1.3-.975 3.25-.975 5.85v58.175c0 2.492.325 4.442.975 5.85.759 1.3 1.734 2.221 2.925 2.763 1.3.433 2.763.65 4.388.65 2.491 0 4.496-.759 6.012-2.275 1.517-1.517 2.275-3.846 2.275-6.988v-19.175h-7.8V99.237h26.163V147.5h-14.138l-.975-7.475-.65.975a8.068 8.068 0 0 0-.487.812c-1.084 1.842-2.925 3.575-5.525 5.2-2.492 1.517-6.067 2.275-10.725 2.275Zm70.596.163c-5.309 0-10.021-.65-14.138-1.95-4.008-1.192-7.204-3.738-9.587-7.638-2.275-4.008-3.413-9.912-3.413-17.712V71.775c0-5.742 1.138-10.183 3.413-13.325 2.383-3.142 5.633-5.308 9.75-6.5 4.116-1.3 8.829-1.95 14.137-1.95 5.417 0 10.075.65 13.975 1.95 4.008 1.3 7.096 3.52 9.263 6.662 2.166 3.142 3.25 7.53 3.25 13.163V91.6h-18.85V70.962c0-2.6-.325-4.55-.975-5.85-.65-1.408-1.571-2.329-2.763-2.762-1.083-.433-2.383-.65-3.9-.65-1.516 0-2.871.217-4.062.65-1.192.433-2.113 1.354-2.763 2.762-.65 1.3-.975 3.25-.975 5.85v58.175c0 2.492.325 4.442.975 5.85.65 1.3 1.571 2.221 2.763 2.763 1.191.433 2.546.65 4.062.65 1.517 0 2.817-.217 3.9-.65 1.192-.542 2.113-1.463 2.763-2.763.65-1.408.975-3.358.975-5.85v-19.012h18.85v11.862c0 7.909-1.084 13.867-3.25 17.875-2.167 3.9-5.255 6.446-9.263 7.638-3.9 1.3-8.612 1.95-14.137 1.95Zm38.587-1.95V51.463h35.1c6.391 0 11.212 1.462 14.462 4.387 3.25 2.817 4.875 6.77 4.875 11.862v14.95c0 5.092-1.354 9.371-4.062 12.838-2.709 3.466-6.934 5.471-12.675 6.012 3.683.542 6.283 1.788 7.8 3.738 1.625 1.841 3.033 4.875 4.225 9.1l9.1 33.15h-20.963l-6.987-31.85c-.65-2.6-1.408-4.767-2.275-6.5-.758-1.842-1.896-2.763-3.413-2.763h-5.525V147.5h-19.662Zm19.662-54.275h7.8c3.034 0 5.2-.813 6.5-2.438 1.3-1.733 1.95-4.441 1.95-8.125V71.125c0-3.467-.596-5.904-1.787-7.313-1.192-1.408-3.033-2.112-5.525-2.112h-8.938v31.525Zm48.575 54.275V51.463h44.2v13.324h-24.538v25.675h20.8v14.788h-20.8v29.25h24.538v13h-44.2Zm48.747 0 17.225-96.037h26.975l16.9 96.037h-21.125l-2.925-17.713h-13.975l-2.762 17.713H702.97Zm23.4-27.138h13.488L733.195 68.2l-6.825 52.162Zm50.428 27.138V64.787h-14.95V51.462h48.75v13.325h-14.95V147.5h-18.85Zm66.548 1.95c-5.309 0-9.967-.65-13.975-1.95-4.009-1.192-7.15-3.738-9.425-7.638-2.167-4.008-3.25-9.912-3.25-17.712V71.775c0-5.742 1.083-10.183 3.25-13.325 2.275-3.142 5.416-5.308 9.425-6.5 4.116-1.3 8.829-1.95 14.137-1.95 5.2 0 9.804.65 13.813 1.95 4.116 1.3 7.312 3.52 9.587 6.662 2.383 3.142 3.575 7.53 3.575 13.163v50.212c0 7.909-1.192 13.867-3.575 17.875-2.275 3.9-5.471 6.446-9.587 7.638-4.009 1.3-8.667 1.95-13.975 1.95Zm0-11.05c1.625 0 3.033-.271 4.225-.813 1.3-.541 2.275-1.462 2.925-2.762.758-1.409 1.137-3.304 1.137-5.688V70.962c0-2.383-.379-4.225-1.137-5.525-.65-1.408-1.625-2.383-2.925-2.924-1.192-.542-2.6-.813-4.225-.813-1.625 0-3.034.27-4.225.813-1.192.541-2.167 1.516-2.925 2.925-.65 1.3-.975 3.141-.975 5.524v58.175c0 2.384.325 4.279.975 5.688.758 1.3 1.733 2.221 2.925 2.762 1.191.542 2.6.813 4.225.813Zm39.709 9.1V51.463h35.1c6.392 0 11.213 1.462 14.463 4.387 3.25 2.817 4.875 6.77 4.875 11.862v14.95c0 5.092-1.355 9.371-4.063 12.838-2.708 3.466-6.933 5.471-12.675 6.012 3.683.542 6.283 1.788 7.8 3.738 1.625 1.841 3.033 4.875 4.225 9.1l9.1 33.15h-20.962l-6.988-31.85c-.65-2.6-1.408-4.767-2.275-6.5-.758-1.842-1.896-2.763-3.412-2.763h-5.525V147.5h-19.663Zm19.663-54.275h7.8c3.033 0 5.2-.813 6.5-2.438 1.3-1.733 1.95-4.441 1.95-8.125V71.125c0-3.467-.596-5.904-1.788-7.313-1.192-1.408-3.033-2.112-5.525-2.112h-8.937v31.525Z"></path><path fill="url(#a)" d="M89.764 46.52c0 7.42-6.016 13.436-13.437 13.436-7.421 0-13.437-6.016-13.437-13.437 0-7.42 6.016-13.437 13.437-13.437 7.421 0 13.437 6.016 13.437 13.437Z"></path><path fill="url(#b)" d="M89.764 46.52c0 7.42-6.016 13.436-13.437 13.436-7.421 0-13.437-6.016-13.437-13.437 0-7.42 6.016-13.437 13.437-13.437 7.421 0 13.437 6.016 13.437 13.437Z"></path><path fill="url(#c)" d="M158.811 9.515a9.096 9.096 0 1 1-18.193 0 9.096 9.096 0 0 1 18.193 0Z"></path><path fill="url(#d)" d="M291.115 118.46c0 8.334-6.756 15.091-15.091 15.091-8.334 0-15.091-6.757-15.091-15.091 0-8.335 6.757-15.091 15.091-15.091 8.335 0 15.091 6.756 15.091 15.091Z"></path><path fill="url(#e)" d="M.045 133.138c0 35.164 28.507 63.671 63.672 63.671 10.92 0 21.2-2.749 30.181-7.594 11.348-6.12 19.787-11.512 26.875-11.425 19.805.245 29.07 21.5 61.811 21.5 32.533 0 59.349-24.479 63.033-56.023.449-3.845.741-7.13.443-10.336-1.717-18.462-3.17-23.647 14.248-35.35 14.515-9.754 24.605-24.052 24.605-42.173 0-26.487-21.472-47.96-47.96-47.96-25.829.45-30.489 10.283-38.877 19.432-7.755 8.46-16.24 12.383-27.689 10.59-4.864-.761-10.03-1.907-15.504-1.907-17.51 0-33.529 6.384-45.856 16.951-7.509 6.437-10.811 13.644-15.542 16.125-7.18 3.766-15.495.827-29.768.827-35.165 0-63.672 28.507-63.672 63.672Z"></path><defs><linearGradient id="a" x1="10.175" x2="275.197" y1="124.248" y2="71.533" gradientUnits="userSpaceOnUse"><stop stop-color="#4979F3"></stop><stop offset="1" stop-color="#DF9DDD"></stop></linearGradient><linearGradient id="b" x1="10.175" x2="275.197" y1="124.248" y2="71.533" gradientUnits="userSpaceOnUse"><stop stop-color="#4979F3"></stop><stop offset="1" stop-color="#DF9DDD"></stop></linearGradient><linearGradient id="c" x1="10.175" x2="275.197" y1="124.248" y2="71.533" gradientUnits="userSpaceOnUse"><stop stop-color="#4979F3"></stop><stop offset="1" stop-color="#DF9DDD"></stop></linearGradient><linearGradient id="d" x1="10.175" x2="275.197" y1="124.248" y2="71.533" gradientUnits="userSpaceOnUse"><stop stop-color="#4979F3"></stop><stop offset="1" stop-color="#DF9DDD"></stop></linearGradient><linearGradient id="e" x1="10.175" x2="275.197" y1="124.248" y2="71.533" gradientUnits="userSpaceOnUse"><stop stop-color="#4979F3"></stop><stop offset="1" stop-color="#DF9DDD"></stop></linearGradient></defs></svg></a><ul data-v-2e02c169=""><li data-v-2e02c169=""><p> Products </p></li><li data-v-2e02c169=""><a href="https://imgcreator.zmo.ai/community" data-v-2e02c169="">Community</a></li><li data-v-2e02c169=""><a href="https://imgcreator.zmo.ai/helper/content-policy" data-v-2e02c169=""> Help and Content Policy </a></li><li data-v-2e02c169=""><a href="https://discord.gg/SjCECNdrGk" rel="noopener noreferrer" target="_blank" data-v-2e02c169=""><p> Join Discord <br data-v-2e02c169=""> for Free Credits </p></a></li></ul></nav></div></header></div><!--[--><!--[--><div><div><div><svg width="30" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M39.9965 20C40.1965 32.4138 32.4138 40.1885 20 39.9965C7.58616 40.1885 -0.188492 32.4138 0.00347512 20C-0.188492 7.58616 7.58616 -0.188492 20 0.00347512C32.4138 -0.188492 40.1885 7.58616 39.9965 20Z" fill="white"></path><path d="M13.6008 8.00195H29.598C31.1977 8.00195 31.9976 8.80181 31.9976 10.4015V26.3988C31.9976 27.9985 31.1977 28.7983 29.598 28.7983H13.6008C12.001 28.7983 11.2012 27.9985 11.2012 26.3988V10.4015C11.2012 8.80181 12.001 8.00195 13.6008 8.00195Z" fill="#BDEFD1"></path><path d="M10.4015 11.2012H26.3988C27.9985 11.2012 28.7983 12.001 28.7983 13.6008V29.598C28.7983 31.1977 27.9985 31.9976 26.3988 31.9976H10.4015C8.80181 31.9976 8.00195 31.1977 8.00195 29.598V13.6008C8.00195 12.001 8.80181 11.2012 10.4015 11.2012Z" fill="#4ED89D"></path><path d="M23.5999 15.6006H13.2017C12.8835 15.6006 12.5784 15.727 12.3534 15.952C12.1284 16.177 12.002 16.4822 12.002 16.8004C12.002 17.1186 12.1284 17.4238 12.3534 17.6488C12.5784 17.8738 12.8835 18.0002 13.2017 18.0002H17.201V27.1986C17.2011 27.5167 17.3275 27.8219 17.5525 28.0468C17.7775 28.2718 18.0827 28.3981 18.4008 28.3981C18.719 28.3981 19.0241 28.2718 19.2491 28.0468C19.4741 27.8219 19.6006 27.5167 19.6006 27.1986V18.0002H23.5999C23.9181 18.0002 24.2233 17.8738 24.4483 17.6488C24.6733 17.4238 24.7997 17.1186 24.7997 16.8004C24.7997 16.4822 24.6733 16.177 24.4483 15.952C24.2233 15.727 23.9181 15.6006 23.5999 15.6006Z" fill="white"></path></svg><p> Text Input </p></div><div><svg width="30" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M39.9965 20C40.1965 32.4138 32.4138 40.1885 20 39.9965C7.58616 40.1885 -0.188492 32.4138 0.00347512 20C-0.188492 7.58616 7.58616 -0.188492 20 0.00347512C32.4138 -0.188492 40.1885 7.58616 39.9965 20Z" fill="#fff"></path><path d="M13.4231 10H29.5769C31.1923 10 32 10.6154 32 11.8462V24.1538C32 25.3846 31.1923 26 29.5769 26H13.4231C11.8077 26 11 25.3846 11 24.1538V11.8462C11 10.6154 11.8077 10 13.4231 10Z" fill="#4ED8D0"></path><path d="M28.5714 12.6289H8.85714C8.62981 12.6289 8.4118 12.7192 8.25105 12.88C8.09031 13.0407 8 13.2587 8 13.486V24.2523C8.96457 21.5275 11.5634 19.5755 14.6186 19.5755C17.5451 19.5755 20.0529 21.3669 21.1066 23.9126C21.797 23.4043 22.599 23.0684 23.4456 22.9331C24.2922 22.7978 25.1589 22.8669 25.9734 23.1348C26.7879 23.4026 27.5265 23.8614 28.1275 24.4728C28.7286 25.0842 29.1747 25.8306 29.4286 26.6495V13.486C29.4286 13.2587 29.3383 13.0407 29.1775 12.88C29.0168 12.7192 28.7988 12.6289 28.5714 12.6289ZM24.5457 18.8138C24.1712 18.8131 23.8053 18.7015 23.4942 18.493C23.1831 18.2845 22.9408 17.9884 22.7979 17.6422C22.655 17.296 22.6179 16.9152 22.6914 16.548C22.7648 16.1807 22.9455 15.8435 23.2105 15.5789C23.4755 15.3143 23.8131 15.1342 24.1805 15.0614C24.5478 14.9885 24.9285 15.0262 25.2745 15.1697C25.6204 15.3132 25.9161 15.556 26.1241 15.8674C26.3321 16.1788 26.4431 16.545 26.4431 16.9195C26.443 17.1685 26.3937 17.4149 26.2983 17.6449C26.2028 17.8748 26.063 18.0837 25.8868 18.2596C25.7106 18.4355 25.5015 18.575 25.2714 18.6701C25.0413 18.7652 24.7947 18.814 24.5457 18.8138Z" fill="#5275A9"></path><path d="M22.6484 16.9187C22.6484 17.4211 22.8483 17.9029 23.2042 18.2582C23.56 18.6134 24.0426 18.813 24.5459 18.813C25.0491 18.813 25.5317 18.6134 25.8876 18.2582C26.2434 17.9029 26.4433 17.4211 26.4433 16.9187C26.4433 16.4163 26.2434 15.9345 25.8876 15.5792C25.5317 15.224 25.0491 15.0244 24.5459 15.0244C24.0426 15.0244 23.56 15.224 23.2042 15.5792C22.8483 15.9345 22.6484 16.4163 22.6484 16.9187Z" fill="white"></path><path d="M24.2944 22.8652C23.1473 22.8636 22.0301 23.2306 21.1075 23.9121C21.4647 24.7785 21.6452 25.7075 21.6385 26.6446C21.6318 27.5817 21.4379 28.5081 21.0684 29.3692H28.5724C28.7997 29.3692 29.0177 29.2789 29.1785 29.1182C29.3392 28.9574 29.4295 28.7394 29.4295 28.5121V26.649C29.0894 25.5528 28.4076 24.5942 27.4836 23.9134C26.5596 23.2326 25.4421 22.8653 24.2944 22.8652Z" fill="#73CAE5"></path><path d="M8.85714 29.3714H21.0674C21.437 28.5103 21.6309 27.5839 21.6376 26.6468C21.6443 25.7097 21.4638 24.7807 21.1066 23.9143C20.0529 21.3686 17.5451 19.5771 14.6186 19.5771C11.5634 19.5771 8.96457 21.5291 8 24.254V28.5143C8 28.7416 8.09031 28.9596 8.25105 29.1204C8.4118 29.2811 8.62981 29.3714 8.85714 29.3714Z" fill="#95D9EF"></path></svg><p> Image Input </p></div><div><svg width="30" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M39.9965 20C40.1965 32.4138 32.4138 40.1885 20 39.9965C7.58616 40.1885 -0.188492 32.4138 0.00347512 20C-0.188492 7.58616 7.58616 -0.188492 20 0.00347512C32.4138 -0.188492 40.1885 7.58616 39.9965 20Z" fill="white"></path><path d="M18.6214 12.3303C20.9443 12.3683 22.961 14.92 24.3775 18.0111C21.6594 18.8822 18.9304 23.5399 17.3117 25.8541C15.1461 25.7784 12.9733 24.3142 11.117 25.7165C10.8569 25.9132 10.6075 26.1229 10.37 26.3448C10.0686 26.626 9.67006 26.4449 9.78918 26.0093C12.2946 16.8513 15.2386 12.2916 18.6214 12.3303Z" fill="#EECCFF"></path><path d="M24.9907 17.6338C27.1626 17.6338 30.5307 19.8188 33.095 24.1888C33.3083 24.7282 33.2309 25.1112 32.8629 25.3378C29.0611 26.9707 25.7448 26.9707 22.9138 25.3378C21.3047 24.4098 19.4348 25.7578 17.5273 25.5578C19.3964 22.8576 21.8752 17.6338 24.9907 17.6338Z" fill="#EECCFF"></path><path d="M15.8538 14.0208C18.1768 14.0587 20.1934 16.6104 21.6099 19.7016C18.8918 20.5726 16.1628 25.2304 14.5441 27.5446C12.3785 27.4689 10.2057 26.0046 8.34945 27.4069C8.0893 27.6036 7.83996 27.8133 7.60243 28.0352C7.30106 28.3165 6.90249 28.1353 7.0216 27.6997C9.52698 18.5417 12.471 13.9821 15.8538 14.0208Z" fill="#45B2E0"></path><path d="M27.7671 13.5C27.7921 15.0517 26.8193 16.0236 25.2676 15.9996C23.7158 16.0236 22.744 15.0517 22.768 13.5C22.744 11.9483 23.7158 10.9764 25.2676 11.0004C26.8193 10.9764 27.7911 11.9483 27.7671 13.5Z" fill="#EECCFF"></path><path d="M26.7671 16.5C26.7921 18.0517 25.8193 19.0236 24.2676 18.9996C22.7158 19.0236 21.744 18.0517 21.768 16.5C21.744 14.9483 22.7158 13.9764 24.2676 14.0004C25.8193 13.9764 26.7911 14.9483 26.7671 16.5Z" fill="#BC47E4"></path><path d="M22.2231 19.3242C24.395 19.3242 27.7631 21.5092 30.3274 25.8793C30.5408 26.4186 30.4634 26.8016 30.0953 27.0283C26.2935 28.6611 22.9772 28.6611 20.1462 27.0283C18.5371 26.1002 16.6672 27.4482 14.7598 27.2482C16.6288 24.548 19.1076 19.3242 22.2231 19.3242Z" fill="#B45AFC"></path></svg><p> Background AI </p></div><div><svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M29.9974 15C30.1474 24.3104 24.3104 30.1414 15 29.9974C5.68962 30.1414 -0.141369 24.3104 0.00260634 15C-0.141369 5.68962 5.68962 -0.141369 15 0.00260634C24.3104 -0.141369 30.1414 5.68962 29.9974 15Z" fill="white"></path><path d="M6.00399 14.2808C5.87938 11.2012 8.67078 6 15.1269 6C21.5831 6 24.0474 11.2947 24.0474 15.0251C24.0474 17.7085 22.7836 22.5715 16.6723 24.2871C15.4696 24.6242 14.5462 23.2346 15.3094 22.2466C15.5297 21.9607 15.7411 21.6436 15.9402 21.2876C16.5477 20.204 15.4073 18.9902 14.2714 19.4942C12.8762 20.1128 11.1318 20.4476 9.13694 19.8491C6.01622 18.9123 6.00399 14.2808 6.00399 14.2808Z" fill="#8045CF"></path><path d="M8.48273 14.3734C8.48273 14.7821 8.64507 15.174 8.93404 15.463C9.22302 15.752 9.61495 15.9143 10.0236 15.9143C10.4323 15.9143 10.8242 15.752 11.1132 15.463C11.4022 15.174 11.5645 14.7821 11.5645 14.3734C11.5645 13.9647 11.4022 13.5728 11.1132 13.2838C10.8242 12.9949 10.4323 12.8325 10.0236 12.8325C9.61495 12.8325 9.22302 12.9949 8.93404 13.2838C8.64507 13.5728 8.48273 13.9647 8.48273 14.3734Z" fill="white"></path><path d="M11.1485 10.8798C11.1485 11.2197 11.2835 11.5457 11.5239 11.7861C11.7642 12.0264 12.0902 12.1615 12.4302 12.1615C12.7701 12.1615 13.0961 12.0264 13.3364 11.7861C13.5768 11.5457 13.7118 11.2197 13.7118 10.8798C13.7118 10.7115 13.6787 10.5448 13.6143 10.3893C13.5499 10.2338 13.4555 10.0925 13.3364 9.97354C13.2174 9.85452 13.0761 9.76011 12.9206 9.6957C12.7651 9.6313 12.5985 9.59814 12.4302 9.59814C12.2619 9.59814 12.0952 9.6313 11.9397 9.6957C11.7842 9.76011 11.6429 9.85452 11.5239 9.97354C11.4049 10.0925 11.3105 10.2338 11.2461 10.3893C11.1816 10.5448 11.1485 10.7115 11.1485 10.8798Z" fill="white"></path><path d="M15.1169 9.81508C15.1169 9.94847 15.1432 10.0806 15.1942 10.2038C15.2453 10.327 15.3201 10.439 15.4144 10.5333C15.5087 10.6277 15.6207 10.7025 15.7439 10.7535C15.8672 10.8046 15.9993 10.8308 16.1326 10.8308C16.266 10.8308 16.3981 10.8046 16.5214 10.7535C16.6446 10.7025 16.7566 10.6277 16.8509 10.5333C16.9452 10.439 17.02 10.327 17.0711 10.2038C17.1221 10.0806 17.1484 9.94847 17.1484 9.81508C17.1484 9.68169 17.1221 9.5496 17.0711 9.42636C17.02 9.30313 16.9452 9.19115 16.8509 9.09683C16.7566 9.0025 16.6446 8.92768 16.5214 8.87664C16.3981 8.82559 16.266 8.79932 16.1326 8.79932C15.9993 8.79932 15.8672 8.82559 15.7439 8.87664C15.6207 8.92768 15.5087 9.0025 15.4144 9.09683C15.3201 9.19115 15.2453 9.30313 15.1942 9.42636C15.1432 9.5496 15.1169 9.68169 15.1169 9.81508Z" fill="white"></path><path d="M16.1326 17.2705C15.8723 17.2705 15.6142 17.1592 15.4339 16.9434C15.3573 16.8517 15.2995 16.7458 15.2638 16.6317C15.2281 16.5176 15.2153 16.3976 15.226 16.2786C15.2368 16.1595 15.2709 16.0438 15.3264 15.9379C15.382 15.8321 15.4578 15.7382 15.5496 15.6618L24.6025 8.10082C24.9886 7.77929 25.5627 7.83047 25.8842 8.21653C25.9608 8.30824 26.0187 8.41416 26.0543 8.52824C26.09 8.64232 26.1028 8.76231 26.0921 8.88135C26.0813 9.00039 26.0472 9.11615 25.9917 9.22199C25.9362 9.32784 25.8603 9.42169 25.7685 9.49819L16.7156 17.0591C16.5522 17.196 16.3458 17.2709 16.1326 17.2705Z" fill="#AE64EC"></path><path d="M23.3699 11.5025C23.1474 10.9318 22.867 10.37 22.5254 9.83594L15.5497 15.6624C15.1637 15.985 15.1125 16.5591 15.434 16.9441C15.5193 17.0466 15.6261 17.129 15.7469 17.1855C15.8676 17.2421 15.9994 17.2713 16.1327 17.2711C16.3385 17.2711 16.5455 17.2022 16.7157 17.0598L23.3699 11.5025Z" fill="#7462E6"></path></svg><p> Swap Anything </p></div><div><svg width="30" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M39.9965 20C40.1965 32.4138 32.4138 40.1885 20 39.9965C7.58616 40.1885 -0.188492 32.4138 0.00347512 20C-0.188492 7.58616 7.58616 -0.188492 20 0.00347512C32.4138 -0.188492 40.1885 7.58616 39.9965 20Z" fill="white"></path><path d="M33.482 18.8094C30.2979 15.6547 27.1011 12.5129 23.9041 9.37149C23.4092 8.88545 22.8138 8.60177 22.1045 8.59961C21.3579 8.59961 20.7547 8.876 19.972 9.61114C18.9112 10.6072 17.861 11.6144 16.8061 12.6166C14.6962 14.6207 12.5811 16.6194 10.4795 18.6321C9.92411 19.1641 9.85257 19.9627 10.2577 20.5114C10.6644 21.062 11.4709 21.2583 12.1309 20.9258C12.3932 20.7938 12.6269 20.589 12.8435 20.3854C15.3506 18.0282 17.8451 15.6575 20.3579 13.3065C21.6037 12.141 22.4694 12.16 23.7245 13.3238C23.9278 13.5122 24.1178 13.7148 24.3177 13.907C26.6822 16.1805 29.0428 18.4581 31.4153 20.7233C32.1076 21.3841 33.0768 21.3948 33.6492 20.7895C34.1598 20.25 34.1207 19.442 33.482 18.8094Z" fill="#C9DBFF"></path><path d="M30.6462 22.031C28.2736 19.8019 25.9188 17.5538 23.5414 15.3296C22.5852 14.4352 21.4002 14.4594 20.4369 15.3549C18.0698 17.5552 15.7137 19.7679 13.3398 21.9609C13.0761 22.2045 12.9733 22.4434 12.9766 22.7955C12.9928 24.4355 12.9812 26.0758 12.9847 27.716C12.9874 29.0043 13.3875 29.3976 14.6992 29.3992C17.0787 29.4023 19.4581 29.4001 21.8376 29.4001C24.1941 29.4001 26.5504 29.4004 28.9068 29.4C30.5289 29.4 30.9333 28.9892 30.9333 27.3427C30.9333 25.8411 30.9291 24.3396 30.9367 22.838C30.9383 22.526 30.8955 22.2652 30.6462 22.031Z" fill="#C9DBFF"></path><path d="M31.482 19.8094C28.2979 16.6547 25.1011 13.5129 21.9041 10.3715C21.4092 9.88545 20.8138 9.60177 20.1045 9.59961C19.3579 9.59961 18.7547 9.876 17.972 10.6111C16.9112 11.6072 15.861 12.6144 14.8061 13.6166C12.6962 15.6207 10.5811 17.6194 8.47948 19.6321C7.92411 20.1641 7.85257 20.9627 8.2577 21.5114C8.66438 22.062 9.47092 22.2583 10.1309 21.9258C10.3932 21.7938 10.6269 21.589 10.8435 21.3854C13.3506 19.0282 15.8451 16.6575 18.3579 14.3065C19.6037 13.141 20.4694 13.16 21.7245 14.3238C21.9278 14.5122 22.1178 14.7148 22.3177 14.907C24.6822 17.1805 27.0428 19.4581 29.4153 21.7233C30.1076 22.3841 31.0768 22.3948 31.6492 21.7895C32.1598 21.25 32.1207 20.442 31.482 19.8094Z" fill="#1893FE"></path><path d="M28.6462 23.031C26.2736 20.8019 23.9188 18.5538 21.5414 16.3296C20.5852 15.4352 19.4002 15.4594 18.4369 16.3549C16.0698 18.5552 13.7137 20.7679 11.3398 22.9609C11.0761 23.2045 10.9733 23.4434 10.9766 23.7955C10.9928 25.4355 10.9812 27.0758 10.9847 28.716C10.9874 30.0043 11.3875 30.3976 12.6992 30.3992C15.0787 30.4023 17.4581 30.4001 19.8376 30.4001C22.1941 30.4001 24.5504 30.4004 26.9068 30.4C28.5289 30.4 28.9333 29.9892 28.9333 28.3427C28.9333 26.8411 28.9291 25.3396 28.9367 23.838C28.9383 23.526 28.8955 23.2652 28.6462 23.031ZM22.4299 25.7553C21.8249 26.5188 21.0873 27.1493 20.3081 27.7322C20.0993 27.8882 19.9353 27.9372 19.7012 27.757C18.7649 27.0365 17.8527 26.2947 17.2042 25.2865C16.7108 24.5195 16.4567 23.6997 16.7353 22.7899C16.9292 22.1576 17.3078 21.6856 17.9807 21.5225C18.6683 21.3561 19.1858 21.6286 19.6187 22.156C19.7666 22.3362 19.8964 22.8166 20.2459 22.3125C20.7291 21.6158 21.3606 21.2732 22.2082 21.5855C22.9223 21.8488 23.3301 22.6007 23.3268 23.4888C23.3547 24.4263 22.9359 25.1172 22.4299 25.7553Z" fill="#1893FE"></path></svg><p> Room Design </p></div></div><div><div data-v-d396fead=""><div data-v-d396fead=""><p><i data-v-d396fead=""><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" data-v-d396fead=""><path fill="currentColor" d="M771.776 794.88A384 384 0 0 1 128 512h64a320 320 0 0 0 555.712 216.448H654.72a32 32 0 1 1 0-64h149.056a32 32 0 0 1 32 32v148.928a32 32 0 1 1-64 0v-50.56zM276.288 295.616h92.992a32 32 0 0 1 0 64H220.16a32 32 0 0 1-32-32V178.56a32 32 0 0 1 64 0v50.56A384 384 0 0 1 896.128 512h-64a320 320 0 0 0-555.776-216.384z"></path></svg><!--]--></i> Try an example </p></div><div data-v-d396fead=""><form data-v-d396fead=""><!--[--><div data-v-d396fead=""><!--[--><p><span>0 / 400</span></p><!--]--><!--[--><!--]--></div><!--]--></form><div data-v-d396fead=""><p> Prompt Guide </p></div></div><div data-v-d396fead=""><div data-v-d396fead=""><h6 data-v-d396fead="">Category</h6><div data-v-d396fead=""><!--[--><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/anime.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Anime</h6></div><div data-v-d396fead=""><div data-v-d396fead=""><p> Pro </p><p><img src="https://assets.imgcreator.ai/category/Realistic_photo.webp" data-v-d396fead=""></p></div><h6 data-v-d396fead="">Realistic photo</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Free_form.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Free form</h6></div><div data-v-d396fead=""><div data-v-d396fead=""><p> Pro </p><p><img src="https://assets.imgcreator.ai/category/Illustration.webp" data-v-d396fead=""></p></div><h6 data-v-d396fead="">Vector illustration</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Art.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Art</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Character_text2img.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Character</h6></div><div data-v-d396fead=""><div data-v-d396fead=""><p> Pro </p><p><img src="https://assets.imgcreator.ai/category/3D_design2.webp" data-v-d396fead=""></p></div><h6 data-v-d396fead="">3D design</h6></div><!--]--></div></div><div data-v-d396fead=""><h6 data-v-d396fead="">Add style</h6><div data-v-d396fead=""><!--[--><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/AnimeCrystal.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Anime Vivacity</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Anime_One.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Japanese Anime</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/AnimeDrawing.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Anime Drawing</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/AnimeArtV2.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Anime Art</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/AnimeD.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Fairy Girl</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Anime_Two.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Anime Classic</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Noble.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Gorgeous Girl</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Soda.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Bright Girl</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Makoto_Shinkai.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Makoto Shinkai</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Miyazaki.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Miyazaki</h6></div><div data-v-d396fead=""><p><img src="https://assets.imgcreator.ai/category/Ukiyo-e.webp" data-v-d396fead=""></p><h6 data-v-d396fead="">Ukiyo-e</h6></div><!--]--></div></div></div><div data-v-d396fead=""><h6>Number of images</h6><div><!--[--><p>2 </p><div><p>4 </p><p> Starter </p><!----><!----></div><div><p>6 </p><!----><p> Pro </p><!----></div><div><p>8 </p><!----><!----><p> Boss </p></div><!--]--></div></div><!--[--><div><h6>Output resolution</h6></div><div><h6>Canvas size</h6></div><!--]--></div></div></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nitter is working again (385 pts)]]></title>
            <link>https://github.com/zedeus/nitter/pull/927</link>
            <guid>36665406</guid>
            <pubDate>Mon, 10 Jul 2023 12:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zedeus/nitter/pull/927">https://github.com/zedeus/nitter/pull/927</a>, See on <a href="https://news.ycombinator.com/item?id=36665406">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>
  <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" autocomplete="off" action="/join?return_to=%2Fzedeus%2Fnitter%2Fissues%2Fnew" accept-charset="UTF-8" method="post">    <auto-check src="/signup_check/username">
      <dl><dt><label name="user[login]" autocapitalize="off" autofocus="autofocus" for="user_login_issues">Pick a username</label></dt><dd></dd></dl>
      
    </auto-check>

    <auto-check src="/signup_check/email">
      <dl><dt><label name="user[email]" autocapitalize="off" for="user_email_issues">Email Address</label></dt><dd></dd></dl>
      
    </auto-check>

    <auto-check src="/users/password"><dl><dt><label name="user[password]" for="user_password_issues">Password</label></dt><dd></dd></dl></auto-check>

    
    




      
</form>
  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-ga-click="(Logged out) New issue modal, clicked Sign in, text:sign-in" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/zedeus/nitter/pull/927&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3c875aaf2860d32663fc760f6311cedfea107f42ccc4932e862097b45ba58879" href="https://github.com/login?return_to=%2Fzedeus%2Fnitter%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harvard ethics prof fabricated multiple behavioral science studies (220 pts)]]></title>
            <link>https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/</link>
            <guid>36665247</guid>
            <pubDate>Mon, 10 Jul 2023 12:16:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/">https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/</a>, See on <a href="https://news.ycombinator.com/item?id=36665247">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
				
                				    <img width="370" height="242" src="https://www.thecollegefix.com/wp-content/uploads/2023/06/Gino.YouTubescreenshot-370x242.jpg" alt="" decoding="async" srcset="https://www.thecollegefix.com/wp-content/uploads/2023/06/Gino.YouTubescreenshot-370x242.jpg 370w, https://www.thecollegefix.com/wp-content/uploads/2023/06/Gino.YouTubescreenshot-560x367.jpg 560w, https://www.thecollegefix.com/wp-content/uploads/2023/06/Gino.YouTubescreenshot-135x88.jpg 135w, https://www.thecollegefix.com/wp-content/uploads/2023/06/Gino.YouTubescreenshot.jpg 580w" sizes="(max-width: 370px) 100vw, 370px">								<p>Shockwaves are moving throughout the behavioral science community after distinguished Professor Francesca Gino of Harvard Business School was recently accused of falsifying data in multiple studies.</p>
<p>Calling the situation a “Clusterfake,” on June 17 a trio of professors published “Part 1” of the multiple allegations of fraud in papers spanning over a decade after examining studies co-authored by Gino,&nbsp;author of the 2018 <a href="https://www.amazon.com/Rebel-Talent-Pays-Break-Rules/dp/0062694634" target="_blank" rel="noopener">book</a> “Rebel Talent: Why It Pays to Break the Rules at Work and in Life.”</p>
<p>Professors Joseph Simmons, Uri Simonsohn and Leif Nelson of University of Pennsylvania, Escade Business School in Spain, and University of California, Berkeley, respectively, <a href="https://datacolada.org/109" target="_blank" rel="noopener">accused</a> Gino of the fraud on their blog Data Colada.</p>
<p>“Specifically, we wrote a report about four studies for which we accumulated the strongest evidence of fraud,” they wrote, stating they shared their concerns with Harvard Business School.</p>
<p>Notably, a famous <a href="https://sci-hub.se/10.1073/pnas.1209746109" target="_blank" rel="noopener">article</a> discussing dishonesty was found to contain fabrications, they wrote.</p>
<p>Gino is on administrative leave from Harvard, according to her faculty bio. She did not respond to a request for comment from <em>The College Fix</em>. Simmons and Nelson did not respond to <em>The College Fix’s</em> requests for comment.</p>
<p>Harvard media relations did not respond to<em> The College Fix</em> for a comment on the employment of Gino and the review of her studies.</p>
<p><em>The New York Times</em> <a href="https://www.nytimes.com/2023/06/24/business/economy/francesca-gino-harvard-dishonesty.html" target="_blank" rel="noopener">reported</a> a phone call with a man who identified as Gino’s husband saying “It’s obviously something that is very sensitive that we can’t speak to now.”</p>
<p>Gino’s paper discussing dishonesty has since been retracted. “Signing at the beginning makes ethics salient and decreases dishonest self-reports in comparison to signing at the end” had been published by <em>Proceedings of the National Academy of Sciences</em> in July 2012.</p>
<p>The study was run at the University of North Carolina in 2010, where Gino was a professor before joining Harvard; she was the only author involved in collecting and analyzing data for it, the trio <a href="https://datacolada.org/109" target="_blank" rel="noopener">reported</a>.</p>
<p>However, another study under scrutiny was supervised by Professor Dan Ariely at Duke University and conducted by an auto insurance company.</p>
<p>Ariely is famous in behavioral science. He founded the Center for Advanced Hindsight at Duke, wrote multiple New York Times bestsellers, and had given many TED Talks.</p>
<p>“Two different people independently faked data for two different studies in a paper about dishonesty,” the three professors allege on their blog post.</p>
<p>Ariely denies making up any data but said he has no proof to clear his name, according to Cathleen O’Grady in a <em>Science</em> <a href="https://www.science.org/content/article/fraudulent-data-set-raise-questions-about-superstar-honesty-researcher" target="_blank" rel="noopener">article</a>. Ariely told <em>Science</em> “I wish I had a good story, and I just don’t.”</p>
<p>He said “he made a mistake in not checking the data he received from the insurance company, and that he no longer has the company’s original file.”</p>
<p>The three Data Colada professors have continued to publish the series of posts on their blog accusing Gino of fraud. The posts have <a href="https://twitter.com/DataColada" target="_blank" rel="noopener">spread via Twitter</a>.</p>
<blockquote data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Second post of a four-post series on Data Falsificada.<a href="https://t.co/cbyaP9F2yn">https://t.co/cbyaP9F2yn</a></p>
<p>Includes message to 148 Gino Co-Authors <a href="https://t.co/IIISKwrw9M">pic.twitter.com/IIISKwrw9M</a></p>
<p>— Data Colada (@<a href="https://www.thecollegefix.com/cdn-cgi/l/email-protection" data-cfemail="197d786d787a7675787d785974786a376d76">[email&nbsp;protected]</a>) (@DataColada) <a href="https://twitter.com/DataColada/status/1671130691415969799?ref_src=twsrc%5Etfw">June 20, 2023</a></p></blockquote>

<p>“It is worth reiterating that to the best of our knowledge, none of Gino’s co-authors carried out or assisted with the data collection for the studies in this series,” they wrote.</p>
<p>A <a href="https://datacolada.org/110" target="_blank" rel="noopener">second</a> article posted June 20 titled “Data Falsificada (Part 2): ‘My Class Year Is Harvard’” discussed a study conducted at Harvard where students would write argumentative essays and subsequently rate their desire for cleansing products.</p>
<p>The study was based on a <a href="https://www.hbs.edu/ris/Publication%20Files/Moral%20Virtue_7caef67d-e4c7-4b38-88c7-b98da81826a5.pdf" target="_blank" rel="noopener">paper</a> titled “The Moral Virtue of Authenticity: How Inauthenticity Produces Feelings of Immorality and Impurity,” published in Psychological Science in 2015. The paper was co-authored by Maryam Kouchaki and Adam Galinsky from Northwestern University and Columbia University, respectively.</p>
<p>A third <a href="https://datacolada.org/111" target="_blank" rel="noopener">article</a> posted June 23 is titled “Data Falsificada (Part 3): ‘The Cheaters Are Out of Order,’” where the authors commented on the sorting methods of data for a study about cheating.</p>
<p>The alleged fraud dealt with the <a href="https://journals.sagepub.com/doi/10.1177/0956797614520714" target="_blank" rel="noopener">research paper</a> “Evil Genius? How Dishonesty Can Lead to Greater Creativity,” published in 2014 in Psychological Science. It was co-authored by Scott Wiltermuth from the University of Southern California.</p>
<p>The fourth part of the series has yet to be posted.</p>
<p><em>The New York Times</em> <a href="https://www.nytimes.com/2023/06/24/business/economy/francesca-gino-harvard-dishonesty.html" target="_blank" rel="noopener">reported</a> that Maurice Schweitzer of Wharton Business School at the University of Pennsylvania said the accusations were having large “reverberations in the academic community” due to the amount of collaborators on many articles.</p>
<p>Schweitzer co-authored multiple papers with Gino and stated that none of the accused studies are his, <a href="https://www.chronicle.com/article/a-dishonesty-expert-stands-accused-of-fraud-scholars-who-worked-with-her-are-scrambling?sra=true&amp;cid=gen_sign_in" target="_blank" rel="noopener">according</a> to the <em>Chronicle of Higher Education.</em></p>
<p>However, Schweitzer reported feeling uncertain about the viability of his work with Gino. He told the <em>Chronicle</em> that Gino was very efficient to work with and executed the studies and provided results very fast.</p>
<p>Schweitzer did not respond to <em>The College Fix’s</em> request for comment.</p>
<p><strong>MORE: <a href="https://www.thecollegefix.com/concern-over-academic-research-fraud-grows-after-scholar-cooked-data-on-racism/" target="_blank" rel="noopener">Concern over academic research fraud grows after scholar cooked data on racism</a></strong></p>
<p>IMAGE: YouTube <a href="https://www.youtube.com/watch?v=zTmFFmAqbEc" target="_blank" rel="noopener">screenshot</a></p>
            

                    <p><a href="https://www.facebook.com/TheCollegeFix/" target="_blank" rel="noopener noreferrer">Like <em>The College Fix</em> on Facebook</a> / <a href="https://twitter.com/CollegeFix" target="_blank" rel="noopener noreferrer">Follow us on Twitter</a></p>
        
				<!-- <div class="social-bar">
					    <span class="share-total">
        Share this article:
    </span>
    <a class="social-link facebook"
       href="http://www.facebook.com/sharer/sharer.php?u=https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/&title=Harvard+ethics+professor+allegedly+fabricated+multiple+behavioral+science+studies"
       target="_blank">
        <span class="screen-reader-text">The College Fix on Facebook</span>
        <span class="count">
                    </span>
    </a>
    <a class="social-link twitter"
       href="http://twitter.com/intent/tweet?text=Harvard+ethics+professor+allegedly+fabricated+multiple+behavioral+science+studies+https%3A%2F%2Fwww.thecollegefix.com%2Fharvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies%2F+via+%40collegefix"
       
       target="_blank">
        <span class="screen-reader-text">The College Fix on Twitter</span>
    </a>
    <a class="social-link reddit"
       href="http://www.reddit.com/submit?url=https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/&title=Harvard+ethics+professor+allegedly+fabricated+multiple+behavioral+science+studies"
       target="_blank">
        <span class="screen-reader-text">The College Fix on Reddit</span>
    </a>
    <a class="social-link parler"
       href="https://parler.com/new-post?url=https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/"
       target="_blank">
        <span class="screen-reader-text">The College Fix on Parler</span>
    </a>
    <a class="social-link email" href="mailto:?subject=thecollegefix.com: Harvard ethics professor allegedly fabricated multiple behavioral science studies&body=https://www.thecollegefix.com/harvard-ethics-professor-allegedly-fabricated-multiple-behavioral-science-studies/">
        <span class="screen-reader-text">Share on Email</span>
    </a>

				</div> -->
				
				
				
				

	
				
				<!-- /1011927/thecollegefix_Leaderboard_2 -->
				
				
			</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debate over 'fake work' in tech industry misses the real culprit: lazy managers (239 pts)]]></title>
            <link>https://www.businessinsider.com/tech-industry-fake-work-problem-bad-managers-bosses-layoffs-jobs-2023-7</link>
            <guid>36664909</guid>
            <pubDate>Mon, 10 Jul 2023 11:32:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/tech-industry-fake-work-problem-bad-managers-bosses-layoffs-jobs-2023-7">https://www.businessinsider.com/tech-industry-fake-work-problem-bad-managers-bosses-layoffs-jobs-2023-7</a>, See on <a href="https://news.ycombinator.com/item?id=36664909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <p>When Graham was hired by Amazon, it sounded like his dream job. He was brought on as a research scientist to help develop features for Alexa, the company's ubiquitous voice assistant. Graham, whose name has been changed to protect his identity, assumed he would soon be using his expertise in machine learning to work on cool, new features that would make Alexa more personal to every user. But within four months of his start at the company, it became clear that Amazon had no idea what to do with him.</p><p>He spent the next two years bouncing around — switching teams, watching project leaders get promoted despite, he said, producing nothing of substance, and generally spinning his wheels. Graham was paid more than $300,000 a year but had little work to show for it. Feeling adrift with nothing to do, he gradually disengaged from his job and was eventually put on Amazon's formal performance-management plan.</p><p>Facing the threat of firing, Graham was finally put on a project to use machine learning to improve Amazon's music recommendations, which he described as "the first really interesting thing I worked on." He was happy to feel like a valuable member of the team, but Graham's manager told him something stunning: The finished project, which Graham worked on for more than a month, wouldn't see the light of day. It was simply an exercise to satisfy the terms of his performance plan and string out his employment, he was told. Graham left Amazon soon after.</p>
                          
                          <p>As tech companies have <a href="https://www.businessinsider.com/layoffs-sweeping-the-us-these-are-the-companies-making-cuts-2023" data-analytics-product-module="body_link" rel="">laid off</a> tens of thousands of employees this year, venture capitalists and executives have <a href="https://www.businessinsider.com/silicon-valley-debates-tech-employees-doing-fake-work-2023-3" data-analytics-product-module="body_link" rel="">leaned on the term "fake work"</a> to describe the output of employees like Graham. The layoffs are necessary and even prudent, the argument goes, because thousands of workers at Big Tech firms such as Google and Meta are sitting around trying to look busy while doing very little productive work.</p><p>"There's nothing for these people to do — it's all fake work," Keith Rabois, a famous tech investor, <a href="https://www.businessinsider.com/google-meta-staff-do-fake-work-says-vc-keith-rabois-2023-3" data-analytics-product-module="body_link" rel="">opined at a March event</a> hosted by the investment bank Evercore. "Now that's being exposed, what do these people actually do? They go to meetings."</p><p>Some tech workers <a href="https://www.businessinsider.com/fired-from-my-job-at-meta-for-posting-on-tiktok-2023-3" data-analytics-product-module="body_link" rel="">seemed to confirm</a> Rabois' claims on social media, sharing stories of being paid by giant tech firms to do very little. In one viral TikTok video, Brit Levy, Meta's former diversity, equity, and inclusion policy analyst, said she had to <a href="https://www.businessinsider.com/laid-off-meta-employee-says-paid-not-to-work-2023-3" data-analytics-product-module="body_link" rel="">"basically fight to find work"</a> and the company was simply holding on to employees "like Pokémon cards."</p><p>But based on conversations with over 30 people involved in the tech industry, including current and former tech employees, some in management positions, the conception of <a href="https://www.businessinsider.com/silicon-valley-debates-tech-employees-doing-fake-work-2023-3" data-analytics-product-module="body_link" rel="">lazy employees raking in big paychecks to do little</a> lays the blame in the wrong place. Oftentimes, employees are getting plenty of work done; it's just that the projects are of little to no importance to the company's bottom line. The tech employees spoke with us on the condition of anonymity to avoid professional reprisal.</p><p>"Most workers want to come and work. They want to show up, give a fair eight hours of work, and they want to feel good about themselves," said Scott Latham, a strategic-management professor at the University of Massachusetts Lowell who worked in the tech industry during the start of the internet boom.&nbsp;</p><p>There's only one real culprit for the culture of "fake work," he said. "It's lazy management."</p><h2>What we talk about when we talk about 'fake work'</h2><p>"Fake work," as consultants Brent Peterson and Gaylan Nielson define it in their 2009 book of the same name, is "effort under the illusion of value." The crimes, they wrote, include pointless meetings, reports, and presentations. In the tech industry, specifically, the term "fake work" is used to conjure up an image of lazy engineers "resting and vesting" — long-tenured, high-paid employees doing very little work while waiting on a lucrative payday from their company stock.</p><p>Rich Moran, a venture capitalist, consultant, and author of several books about the workplace, prefers to call it a "false sense of activity" and said it's "more rampant" among tech companies. "The tech sector is more willing to try different things," he told us. "And so you get assigned to a project that you know may be going nowhere, but they have a hard time saying, well this isn't going anywhere."</p>
                          
                          <p>The latest version of fake work emerged as part of the tech industry's <a href="https://www.businessinsider.com/big-tech-moonshots-over-amazon-facebook-google-microsoft-2022-9" data-analytics-product-module="body_link" rel="">pandemic-driven boom and bust</a>. Lockdowns and work from home meant Amazon, Google, Meta, Shopify, and many other giants saw an explosion of demand for their products. Assuming the consumer shift was a harbinger of a new normal of shopping, socializing, and working online all the time, companies aggressively hired thousands of recruits. But firms often gave little thought about where to place them or what their role would be, insiders say.</p><p>"I think COVID was an accelerator for fake work because a lot of these tech companies hired. Then they weren't sure what to do with a lot of the people," Moran said.</p><p>One former Google manager told us she was instructed to lower her standards for hiring earlier in the pandemic and watched as teams she worked with doubled in size. As new hires flooded in, it felt as if teams were reorganized on a weekly basis, making it harder for people to do solid work.&nbsp;</p><blockquote><q>Most workers want to come and work. They want to show up</q></blockquote><p>The sudden head-count increase was destabilizing, but the real trouble began when business started to slow down. Rather than a permanent reorientation, many of the behaviors people adopted turned out to be short-term modifications. And as the economy turned on the tech industry, companies scrambled to figure out what to do with all the employees they no longer needed. That's when the "fake work" talk, finger-pointing, and unceremonious layoffs took off.</p><p>"There was just no guidance at all," an ex-Meta worker said of his two months at the company, when he was waiting to be placed on a team as an entry-level data scientist. "I remember one day literally having absolutely nothing to do, and I just went surfing instead because I'm remote. I have no one to report to. It seems like no one knows I'm here."</p><figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/64a84d368ed31300199e1ea8&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:5333,&quot;aspectRatioH&quot;:4000}}" alt="A man with a backpack walks up to a glass building with the Google logo on it" itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  One former Google employee said many employees were assigned work that served no purpose for the company.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          Melina Mara/The Washington Post via Getty Images
                          
                          </span>
                              </span>
                          </figure><p>Another ex-Meta employee said that there were so many workers in his department when he joined in 2022 that on multiple occasions, he'd complete a project to learn that as many as four other people had been given the same assignment separately. The former employee described the work he did at Meta as "intern-level' — putting together graphs based on preexisting data, polishing presentations, or practicing how to "work a problem backward" — despite having nearly a decade of experience in tech. He said he found the environment "stifling" and was often deterred from trying to increase the scope of his work.</p><p>Sure, there were some employees, as pundits and executives have suggested, who could have helped tackle projects but chose not to. But for the most part, insiders told us, workers were stuck in circumstances beyond their control.</p><p>"I think there's very few people sitting around doing nothing," Moran said. "I think people are very skilled at filling their time. Whether or not it helps the organization is another question."</p>
                          
                          <p>Some people were assigned plenty of tasks, but they ended up serving no mission-critical purpose. The former Google program manager said that people were working hard but what qualified as work had seemingly changed. "They gave us a lot of work that was just a waste of time," she said.</p><p>Others, like Graham, were assigned to seemingly key parts of the company, only to find that there wasn't enough work to go around. The former Googler also noticed this type of fake work. "There were so many of us, people just started trying to look busy," she told us. "There were too many chefs in the kitchen," she added.</p><p>One former contract worker hired by Meta during the pandemic became so frustrated with feeling idle that she took on a second contract job at Microsoft at the same time (neither company knew she was working for the other). She decided if "they're not going to give me anything to do then I guess I'm just getting paid."</p><p>"It's a little bit of a symbiotic relationship where the people that you report to aren't saying that you're not doing anything and you're not saying that you're not doing anything," she told us.&nbsp;</p><h2>Empty empires</h2><p>While the pandemic's boom and bust brought the issue into stark relief, the various types of fake work have been growing within tech companies for years. Many of these issues come down to one fundamental problem: managers trying to get ahead.</p><p>At almost all tech companies, current and former employees said, bosses were rewarded for overhiring since it made them look important. Bloated org charts resulted in too many people fighting for work, a poor understanding of what each segment of the company was doing, and a rise in projects spun up merely to help managers get themselves promoted.</p><p>"People are often measured not in contribution but in head count." Moran said.</p><p>"The bigger your team you have, the more qualified people you have in your team, the more weight you have in the company," Graham, the former Amazon employee, said. "It's what we call empire building. You're not focused on building a product; you're focused on building an empire. That leads to fake work and unnecessary bloating."</p>
                          
                          <blockquote><q>The more people who report to you, the higher your prestige, the more your power in the organization.</q></blockquote><p>To create an empire, managers simply add employees underneath them with little sense of what they should be doing. "Instead of planning in the most efficient way, they just say, 'I need a head count,'" Anna Tavis, a clinical professor of human-capital management at New York University's School of Professional Studies, said.</p><p>The former Meta employee who joined the company in 2022 felt that stuffing teams was a byproduct of middle managers looking for a promotion, leading to employees having less to do. One of his managers hired so many people that within three months, there became four levels between him and the person who was supposed to be managing him. "A lot of the time, my managers had no idea what I was doing," he said.</p><p>In addition to the incentive structure encouraging projects to nowhere, there's a lack of oversight from the top into how these miniature empires are being run, employees said. And in many cases, executives are oblivious to the value of the work that's presented to them. Some executives have even admitted that there seems to be little incentive to address company bloat. Former Slack CEO Stewart Butterfield told Bloomberg's "Odd Lots" <a href="https://omny.fm/shows/odd-lots/slack-founder-stewart-butterfield-on-ai-software-a" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">podcast</a> that without financial hurdles, managers had every reason to keep hiring.</p><p>"The more people who report to you, the higher your prestige, the more your power in the organization," he said.</p><p>To secure their fiefdoms, managers often pitch projects they created that are sometimes referred to as "vanity projects" or "promo projects." These may ultimately contribute zero to a company's top line, but the flashy presentations and demos associated with the projects often lead to a promotion and nice pay bump for the person leading the work. One Google manager who recently left the company said the head-count process at Google "rewards bad behavior" by promoting people based on "having a bigger team and creating decks." Google had "dozens" of teams, he said, that did "think tank-like strategy work with no real practical way of impacting the business or a customer or user."</p><p>"I do think that process favored the people who were better at bullshitting and storytelling," he told us.</p><figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/64a84df48ed31300199e1ed0&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:5119,&quot;aspectRatioH&quot;:3840}}" alt="Amazon employees at the Spheres next to its Seattle headquarters" itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Graham, a former Amazon employee, said the incentive structure at the company led to "fake work and unnecessary bloating."
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          LINDSEY WASSON/Reuters
                          
                          </span>
                              </span>
                          </figure><p>At Meta, one current employee said it was common to see employees all the way up to vice presidents invent workshops or "sprints" to set "strategic visions" for projects, while only a small fraction made it onto a road map, an actual timeline for a product to launch to the public, the employee said.&nbsp;</p><p>"I've rarely seen a large-scale vision be referenced after it's presented, despite the fact that upwards of 20 people are called to participate, usually by making and remaking decks for leadership," they added. "You can always tell when performance reviews are about to happen because there's almost always one or two workshops on the calendar a month before."</p>
                          
                          <p>When that manager gets promoted — or the project falls apart — the team is sometimes shuffled into other parts of the business. Several tech employees told us these situations led to a lot of work that ultimately made little or no material impact on the business.</p><p>"One reorg after another led to fake work," a former longtime Google employee said. "I got used to getting introduced to a multiyear product, for a project I would look at and say, 'This is a poster piece for some executive to implement while job hunting for another role so they can go be a CEO somewhere.' They were show products."</p><blockquote><q>I do think that process favored the people who were better at bullshitting and storytelling.</q></blockquote><p>The power-jockeying adds layers of unnecessary complication, making it nearly impossible to complete simple tasks. One former manager at Salesforce said the company had in recent years become stuffed with middle managers and power structures that sucked up resources but made it hard to get anything of substance done.</p><p>"Trying to get anything done in that organization takes 40 people to get aligned," the former employee told us. He said the meeting culture at the company had also gotten out of hand and "work" was defined as "making slide decks and giving speeches and having a really full calendar that shows you're in a lot of meetings."</p><h2>What's next?</h2><p>Over the past year, tech companies have made it very clear how they plan to deal with fake work — layoffs</p><p>In almost every layoff announcement — those from Amazon, Microsoft, Google, Salesforce, and others — executives have focused on the need to get more efficient. After announcing the company's <a href="https://www.businessinsider.com/meta-layoffs-employees-facebook-mark-zuckerberg-metaverse-bet-2022-11" data-analytics-product-module="body_link" rel="">first round of job cuts</a> last year, Meta CEO Mark Zuckerberg <a href="https://www.businessinsider.com/mark-zuckerberg-year-efficiency-meta-facebook-could-mean-more-layoffs-2023-2" data-analytics-product-module="body_link" rel="">declared</a> 2023 would be the "year of efficiency." Other tech CEOs, such as Alphabet's Sundar Pichai, have also talked of <a href="https://www.businessinsider.com/google-productivity-sundar-pichai-improved-ceo-2022-8" data-analytics-product-module="body_link" rel="">increasing their companies' productivity.&nbsp;</a></p><p>Some companies have also shown signs that they're trying to curb busywork. In September, Google told staff it would <a href="https://www.businessinsider.com/google-cut-back-meetings-distractions-okrs-goals-simplicity-sprint-2022-9" data-analytics-product-module="body_link" rel="">cut down "redundant meetings"</a> and asked employees to make stronger and specific agendas for the meetings they did have. In January, Zuckerberg told staff that he could no longer tolerate a company structure of "managers managing managers," the newsletter Command Line reported. He also told middle managers to <a href="https://www.businessinsider.com/meta-facebook-mark-zuckerberg-layoffs-managers-asked-to-move-quit-2023-2" data-analytics-product-module="body_link" rel="">find roles as individual contributors or leave</a>.</p><p>While many big tech companies have emphasized the need for more "efficiency" over the past six months, they have also generally downplayed concerns about their workplace cultures. In a statement, Amazon spokesperson Brad Glasser said that Graham's story "doesn't reflect the experience of most employees." A Google spokesperson denied that managers had been told to lower hiring standards during the pandemic and pointed us to to an interview with Bloomberg where CEO Sundar Pichai remarked that the company was "sharpening its focus." Representatives from Salesforce, and Microsoft declined to comment. Meta did not respond to requests for comment.</p>
                          
                          <p>Greg Selker, a managing director at the executive-search and consulting firm Stanton Chase, said he thought the fake-work phenomenon was already reaching a natural conclusion. The "smartest companies" that overhired have already gone through significant bloodletting, while others will soon realize they have to do the same, he said</p><p>But not all insiders are convinced. Some said these companies would need to make more drastic changes to the culture if they wanted to undo years of "fake work." "The dirty secret of these layoffs is that they're not materially changing these businesses," a former longtime Google executive said.</p><p>Addressing the issue of bloat and poor management takes more than a few layoffs. Jessica Kennedy, an organizational expert out of Vanderbilt University, said it came down to clear communication and proper incentives, adding that the issue could be solved with better organization and a clearer, more transparent differentiation between roles.</p><blockquote><q>We have a good leader, which makes all the difference.</q></blockquote><p>"It's natural for a worker to try and find a way to increase their status or differentiate themselves, but cultures are set by the people at the top of the organization, and it's their job to incentivize the right things," Kennedy said. "This is probably an issue a company would face if it focused too much on rewarding social status instead of performance. It's important employees understand the overlying purpose of the work they do. Good leaders know how to properly motivate their employees."</p><p>Some level of redundancy is a good thing if companies want to "build for resilience and innovation," but there needs to be careful thought given to it, NYU's Tavis said. "Companies making profits can become lazy around really planning for what they want," she told us. "Yes, you need to create resilience and innovation, but you need to plan for it."</p><p>As for Graham, he's since moved to another tech company, where he said he felt his contributions were more valued. "It's really good work so far," he said. "We have a good leader, which makes all the difference."</p><hr><p><em><a href="https://www.businessinsider.com/author/hugh-langley" rel="" data-analytics-product-module="body_link" data-analytics-post-depth="100" data-uri="2b64df0f6372b793adf44f92de551127">Hugh Langley</a> is a senior correspondent at Insider covering Alphabet and tech investigations. He can be reached via encrypted messaging app Signal at +1 628-228-1836 and email at hlangley@insider.com</em></p><p><em><a href="https://www.businessinsider.com/author/grace-kay" data-analytics-product-module="body_link" rel="">Grace Kay</a> is a reporter on Insider's business news team. You can contact her at gkay@insider.com</em></p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Easy SVG sparklines (307 pts)]]></title>
            <link>https://alexplescan.com/posts/2023/07/08/easy-svg-sparklines/</link>
            <guid>36664604</guid>
            <pubDate>Mon, 10 Jul 2023 10:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexplescan.com/posts/2023/07/08/easy-svg-sparklines/">https://alexplescan.com/posts/2023/07/08/easy-svg-sparklines/</a>, See on <a href="https://news.ycombinator.com/item?id=36664604">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
        <article role="article">
  

  <div>
    <p><a href="https://en.wikipedia.org/wiki/Sparkline">Sparkline charts</a> are compact, simple charts showing a general trend without getting into the nitty-gritty of a more complete solution.</p>

<p>On <a href="https://mailgrip.io/">Mailgrip</a>, I use them as a UI flourish to give a visual indication of how many emails an inbox has received over time:</p>

<picture><source srcset="https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-500-965b47029.webp 1.0x, https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-1000-965b47029.webp 2.0x, https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-1116-965b47029.webp 2.23x" type="image/webp"><source srcset="https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-500-965b47029.jpg 1.0x, https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-1000-965b47029.jpg 2.0x, https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-1116-965b47029.jpg 2.23x" type="image/jpeg"><img src="https://alexplescan.com/generated/assets/posts/easy-svg-sparklines/mailgrip-sparkline-800-6e055d663.png" alt="a screenshot showing an example of a sparkline"></picture>

<p>This post will explain how to use SVG to create minimal sparklines in a really easy and fast way.</p>

<h2 id="hand-crafting-the-svg">Hand crafting the SVG</h2>

<p>Let’s start by writing the SVG by hand, and then I’ll show you an example of the Elixir code I use to generate sparklines in Mailgrip.</p>

<p>Say we’ve got this series of 10 data points to display:</p>

<div><pre><code>1, 0, 5, 4, 8, 10, 15, 10, 5, 4
</code></pre></div>

<h3 id="drawing-a-line">Drawing a line</h3>

<p>Everything has a starting point, including our sparkline. So let’s begin by drawing a line.</p>

<p>SVGs use a set of primitive commands (<a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/d#path_commands">docs</a>) to draw shapes. The ones we’re interested in are:</p>

<ul>
  <li>M (<code>moveto</code>): Sets a new starting point. It takes two parameters: X and Y.</li>
  <li>L (<code>lineto</code>): Draws a line from the current position to a new one, specified by X and Y parameters.</li>
  <li>Z (<code>closepath</code>): Draws a line from the current position back to the starting position.</li>
</ul>

<p>We’ll use these commands to draw our lines based on X and Y coordinates.</p>

<p>In SVG, the origin coordinates (0, 0) are at the top left. However we want our chart’s coordinates to start at the bottom left.</p>

<p>To adjust the Y position for a point, we’ll substract it from the largest (max) point in our data set. This flips our Y positions to:</p>

<div><pre><code>14, 15, 10, 11, 7, 5, 0, 5, 10, 11
</code></pre></div>

<p>Figuring out the X positions is straightforward; they’re just the index of the point we’re drawing:</p>

<div><pre><code>0, 1, 2, 3, 4, 5, 6, 7, 8, 9
</code></pre></div>

<p>Now, let’s put these coordinates to work and draw our sparkline:</p>

<div><pre><code><span>&lt;svg</span> <span>height=</span><span>"180px"</span> <span>width=</span><span>"500px"</span><span>&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke-width=</span><span>"2"</span>
    <span>stroke=</span><span>"red"</span>
    <span>fill=</span><span>"transparent"</span>
  <span>/&gt;</span>
<span>&lt;/svg&gt;</span>
</code></pre></div>

<p>Behold our beautiful creation:</p>



<p>Okay that’s a bit sad, we’ve got a few more steps to go still…</p>

<h3 id="scaling">Scaling</h3>

<p>We’ve defined that our SVG should have a height of 180px and width of 500px, but the line we drew is rendering at one pixel per X/Y coordinate.</p>

<p>Here’s where SVG’s ability to <em>Scale</em> Vector Graphics really helps out. Instead of having to transpose our data to screen space coordinates, we can let SVG do it for us!</p>

<p>We use the <code>viewBox</code> attribute (<a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/viewBox">docs</a>) on the SVG element to set the coordinate space of the chart. <code>viewBox</code> values are zero-indexed, so our width will be <code>9</code> (because we have a total of 10 points) and our height will be <code>15</code> (because our max point value is 15).</p>

<div><pre><code><span>&lt;svg</span> <span>height=</span><span>"180px"</span> <span>width=</span><span>"500px"</span> <span>viewBox=</span><span>"0 0 9 15"</span><span>&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke-width=</span><span>"2"</span>
    <span>stroke=</span><span>"red"</span>
    <span>fill=</span><span>"transparent"</span>
  <span>/&gt;</span>
<span>&lt;/svg&gt;</span>
</code></pre></div>



<p>Ah, but now a couple of other funky things have happened:</p>

<ul>
  <li>The <code>stroke-width</code> of 2px has scaled up with the image. We can tell SVG to keep the stroke consistent by setting the <code>vector-effect</code> (<a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/vector-effect">docs</a>) property on our path.</li>
  <li>The image scaled up using the aspect ratio of the 9 x 15 <code>viewBox</code>, which is different to that of our image. We can tell SVG to maintain the aspect ratio of the <code>svg</code> element by setting <code>preserveAspectRatio</code> to <code>none</code> (<a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/preserveAspectRatio">docs</a>).</li>
</ul>

<div><pre><code><span>&lt;svg</span> <span>height=</span><span>"180px"</span> <span>width=</span><span>"500px"</span> <span>viewBox=</span><span>"0 0 9 15"</span> <span>preserveAspectRatio=</span><span>"none"</span><span>&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke-width=</span><span>"2"</span>
    <span>stroke=</span><span>"red"</span>
    <span>fill=</span><span>"transparent"</span>
    <span>vector-effect=</span><span>"non-scaling-stroke"</span>
  <span>/&gt;</span>
<span>&lt;/svg&gt;</span>
</code></pre></div>



<p>That’s better, now for some more… flare… let’s add a fill to the SVG as well:</p>

<h3 id="adding-a-fill">Adding a fill</h3>

<p>To do this, we copy our existing line but set a <code>fill</code> on it instead of a <code>stroke</code>:</p>

<div><pre><code><span>&lt;svg</span> <span>height=</span><span>"180px"</span> <span>width=</span><span>"500px"</span> <span>viewBox=</span><span>"0 0 9 15"</span> <span>preserveAspectRatio=</span><span>"none"</span><span>&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke=</span><span>"transparent"</span>
    <span>fill=</span><span>"pink"</span>
  <span>/&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke-width=</span><span>"2"</span>
    <span>stroke=</span><span>"red"</span>
    <span>fill=</span><span>"transparent"</span>
    <span>vector-effect=</span><span>"non-scaling-stroke"</span>
  <span>/&gt;</span>
<span>&lt;/svg&gt;</span>
</code></pre></div>



<p>Almost there! Let’s close that unsightly white gap. To do so, we need to extend our line to the bottom right of the graphic (<code>L 9 15</code>), then to the bottom left (<code>L 0 15</code>), then back up to the starting point (<code>Z</code>).</p>

<p>This creates a closed line that nicely encapsulates the area we want to fill in:</p>

<div><pre><code><span>&lt;svg</span> <span>height=</span><span>"180px"</span> <span>width=</span><span>"500px"</span> <span>viewBox=</span><span>"0 0 9 15"</span> <span>preserveAspectRatio=</span><span>"none"</span><span>&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11 L 9 15 L 0 15 Z"</span>
    <span>stroke=</span><span>"transparent"</span>
    <span>fill=</span><span>"pink"</span>
  <span>/&gt;</span>
  <span>&lt;path</span>
    <span>d=</span><span>"M 0 14 L 1 15 L 2 10 L 3 11 L 4 7 L 5 5 L 6 0 L 7 5 L 8 10 L 9 11"</span>
    <span>stroke-width=</span><span>"2"</span>
    <span>stroke=</span><span>"red"</span>
    <span>fill=</span><span>"transparent"</span>
    <span>vector-effect=</span><span>"non-scaling-stroke"</span>
  <span>/&gt;</span>
<span>&lt;/svg&gt;</span>
</code></pre></div>



<p>That’s looking pretty good now - especially considering how simple it was to draw. Now let’s move on to rendering these on the server…</p>

<h2 id="rendering-sparklines-on-the-server">Rendering Sparklines on the server</h2>

<p>One of my favourite things about creating sparklines like this is that I can create the SVGs entirely on the backend. I don’t need to worry about using a JavaScript charting library, or sending the “points” data to the frontend. The browser requests an SVG. The server returns it. Simple!</p>

<p>Mailgrip is written in Elixir and uses the Phoenix framework, so the code I’m sharing is in Elixir too - but this approach could be adapted to any programming language.</p>

<p>The Phoenix controller defines a route that looks like:</p>

<div><pre><code><span>defmodule</span> <span>MailgripWeb</span><span>.</span><span>InboxController</span> <span>do</span>
  <span>def</span> <span>activity_svg</span><span>(</span><span>conn</span><span>,</span> <span>_params</span><span>)</span> <span>do</span>
    <span>points</span> <span>=</span>
      <span>Emails</span><span>.</span><span>message_stats</span><span>(</span><span>conn</span><span>.</span><span>assigns</span><span>.</span><span>inbox</span><span>,</span> <span>30</span><span>)</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>stat</span> <span>-&gt;</span> <span>Map</span><span>.</span><span>fetch!</span><span>(</span><span>stat</span><span>,</span> <span>:count</span><span>)</span> <span>end</span><span>)</span>

    <span>conn</span>
    <span>|&gt;</span> <span>put_resp_content_type</span><span>(</span><span>"image/svg+xml"</span><span>)</span>
    <span>|&gt;</span> <span>send_resp</span><span>(</span><span>200</span><span>,</span> <span>MailgripWeb</span><span>.</span><span>Sparkline</span><span>.</span><span>draw</span><span>(</span><span>100</span><span>,</span> <span>20</span><span>,</span> <span>points</span><span>))</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>Which in turn calls this module (heavily inspired by the <a href="https://github.com/mindok/contex">Contex</a> package):</p>

<div><pre><code><span>defmodule</span> <span>MailgripWeb</span><span>.</span><span>Sparkline</span> <span>do</span>
  <span>@fill</span> <span>"#dcfce7"</span>
  <span>@stroke</span> <span>"#bbf7d0"</span>
  <span>@stroke_width</span> <span>4</span>

  <span>def</span> <span>draw</span><span>(</span><span>width</span><span>,</span> <span>height</span><span>,</span> <span>points</span><span>)</span> <span>do</span>
    <span>vb_width</span> <span>=</span> <span>length</span><span>(</span><span>points</span><span>)</span> <span>-</span> <span>1</span>
    <span>vb_height</span> <span>=</span> <span>Enum</span><span>.</span><span>max</span><span>(</span><span>points</span><span>)</span>

    <span>"""
    &lt;svg height="#{height}" width="#{width}" viewBox="0 0 #{vb_width} #{vb_height}" preserveAspectRatio="none" role="img" xmlns="http://www.w3.org/2000/svg"&gt;
      &lt;path d="#{closed_path(points, vb_width, vb_height)}" stroke="transparent" fill="#{@fill}" /&gt;
      &lt;path d="#{path(points, vb_width, vb_height)}" stroke-width="#{@stroke_width}" vector-effect="non-scaling-stroke" stroke="#{@stroke}" fill="transparent" /&gt;
    &lt;/svg&gt;
    """</span>
  <span>end</span>

  <span>defp</span> <span>path</span><span>(</span><span>points</span><span>,</span> <span>vb_width</span><span>,</span> <span>vb_height</span><span>)</span> <span>do</span>
    <span>[</span>
      <span>"M"</span><span>,</span>
      <span>points</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>with_index</span><span>()</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>{</span><span>value</span><span>,</span> <span>i</span><span>}</span> <span>-&gt;</span>
        <span>x</span> <span>=</span> <span>i</span>
        <span>y</span> <span>=</span> <span>vb_height</span> <span>-</span> <span>value</span>
        <span>"</span><span>#{</span><span>x</span><span>}</span><span> </span><span>#{</span><span>y</span><span>}#{</span><span>if</span> <span>i</span> <span>&lt;</span> <span>vb_width</span><span>,</span> <span>do</span><span>:</span> <span>" L "</span><span>}</span><span>"</span>
      <span>end</span><span>)</span>
    <span>]</span>
  <span>end</span>

  <span>defp</span> <span>closed_path</span><span>(</span><span>points</span><span>,</span> <span>vb_width</span><span>,</span> <span>vb_height</span><span>)</span> <span>do</span>
    <span>[</span><span>path</span><span>(</span><span>points</span><span>,</span> <span>vb_width</span><span>,</span> <span>vb_height</span><span>),</span> <span>" L </span><span>#{</span><span>vb_width</span><span>}</span><span> </span><span>#{</span><span>vb_height</span><span>}</span><span> L 0 </span><span>#{</span><span>vb_height</span><span>}</span><span> Z"</span><span>]</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>That’s all it takes for minimal sparklines to add some flourish to your user interfaces!</p>

<p>My use of sparklines is gonna go:</p>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What’s New in Thunderbird 115 (510 pts)]]></title>
            <link>https://www.thunderbird.net/en-US/thunderbird/115.0/whatsnew/</link>
            <guid>36664113</guid>
            <pubDate>Mon, 10 Jul 2023 09:58:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thunderbird.net/en-US/thunderbird/115.0/whatsnew/">https://www.thunderbird.net/en-US/thunderbird/115.0/whatsnew/</a>, See on <a href="https://news.ycombinator.com/item?id=36664113">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  <section>
    <figure>
      
      
      
      
    </figure>
    <figcaption>115 | 102</figcaption>
  </section>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <div>
        
        <p>
          Supernova features a single dynamic toolbar, presenting frequently used and contextual options based on the tab
          or Space that is currently active. Take full control by customizing the toolbar and window layout to perfectly fit your
          workflow.
        </p>
      </div>
      <p><img src="https://www.thunderbird.net/media/img/thunderbird/whatsnew/115/utb.png" alt="The all new Unified Toolbar">
      </p>
    </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <div>
        
        <p>
          More than just a refreshed set of graphics, Supernova introduces beautiful icons with a more consistent visual
          style unique to Thunderbird. Our new designs remain sharp and pixel-perfect at any density setting.
        </p>
      </div>
      <p><img src="https://www.thunderbird.net/media/img/thunderbird/whatsnew/115/iconography.png" alt="The improved icons">
      </p>
    </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
        
        <p>
          Working with multiple monitors and display resolutions? Supernova lets you dial in the perfect density settings
          and font sizes for the entire application, with just a single click from the App Menu.
        </p>
      </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <div>
          
          <p>
            Supernova gives you more control by introducing sortable Folder Modes. Display all of your Tags in the Folder
            Pane, turn on and off Local Folders, or move your favorite Folder Mode sections up and down with one click. Less
            scrolling, more productivity.
          </p>
        </div>

      <p><img src="https://www.thunderbird.net/media/img/thunderbird/whatsnew/115/folderpane.png" alt="The improved folder pane">
      </p>
    </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <div>
        
        <p>
          Supernova continues to iterate on the modernized Address Book introduced in Thunderbird 102. You’ll enjoy a new
          tabular view, an improved Edit view, delete buttons, and better accessibility.
        </p>
      </div>
      <p><img src="https://www.thunderbird.net/media/img/thunderbird/whatsnew/115/ab.png" alt="The improved address book edit pane">
      </p>
    </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
        
        <p>
          Supernova substantially improves Thunderbird’s keyboard navigation and screen reader accessibility across the
          entire application. We’ve also greatly expanded the ability to navigate Mail content and buttons using the TAB and
          arrow keys.
        </p>
      </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <div>
        
        <p>
          As part of an ongoing effort to modernize and upgrade Thunderbird’s Calendar, Supernova introduces an improved
          “mini-month” layout, improvements to the day/week/month grid, a pleasing color palette, and several more minor changes.
        </p>
      </div>
      <p><img src="https://www.thunderbird.net/media/img/thunderbird/whatsnew/115/cal.png" alt="The improved calendar">
      </p>
    </div>

  <p><img src="https://www.thunderbird.net/media/img/thunderbird/backgrounds/nebula.png" alt="A nebula of stars"></p>

  <div>
      <h3>More to come!</h3>
      <p>
        Supernova is constantly evolving. Throughout the next year, we’ll deliver many improvements to existing Supernova
        features and introduce brand new ones. Upgrade to version 115 and experience the future of Thunderbird!
      </p>
    </div>

  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The controller pattern is awful, and other OO heresy (2013) (131 pts)]]></title>
            <link>https://eev.ee/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/</link>
            <guid>36663509</guid>
            <pubDate>Mon, 10 Jul 2023 08:27:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eev.ee/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/">https://eev.ee/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/</a>, See on <a href="https://news.ycombinator.com/item?id=36663509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p>Almost a year ago now, <a href="http://jackdied.blogspot.com/">Jack Diederich</a> gave a talk entitled “<a href="http://www.youtube.com/watch?v=o9pEzgHorH0">Stop Writing Classes</a>“, in which he implores Python programmers to stop creating classes just for the hell of it, and specifically calls out the common pattern of a class with only a constructor/initializer and a single method—which should, of course, just be a&nbsp;function.</p>
<p>A few weeks ago, <a href="http://lucumr.pocoo.org/2013/2/13/moar-classes/">Armin Ronacher</a> wrote a rebuttal entitled “<a href="http://lucumr.pocoo.org/2013/2/13/moar-classes/">Start Writing More Classes</a>“, which argues that classes are essential for both writing extensible code and smoothing over crappy interfaces.  (Hm.  Now that I look at it again, if you read the post backwards, it almost sounds like he’s suggesting writing a class to smooth out the crappy interface you get from using too many&nbsp;classes…)</p>
<p>I’m having some trouble here, because I agree with both points of view.  There must be a way to resolve this contradiction, a message that resonates with&nbsp;everyone.</p>
<p>I think I’ve found&nbsp;it.</p>
<p><strong>Stop writing <em>stupid</em>&nbsp;classes.</strong></p>


<h2 id="some-context"><a href="#some-context">Some&nbsp;context</a></h2>
<p>Before I clarify what I mean, I need to establish some definitions.  Quick: off the top of your head, what is object-oriented programming <em>about</em>?</p>
<p>Got an idea&nbsp;yet?</p>
<p>If you thought any of the words “encapsulation”, “inheritance”, “polymorphism”, “information hiding”, “abstraction”, or “vtables”, you are <em>wrong</em>.</p>
<p>If you thought any of the words “class”, “prototype”, or “type”, you are <em>still wrong</em>.</p>
<p><strong>Object-oriented programming is about <em>objects</em>: bundles of state and behavior.</strong>  The rest is optional fluff.  And object-oriented <em>languages</em> are defined only by having built-in support for bundling state and behavior, <em>not</em> by having built-in support for classes.  You may notice we don’t call it “class-oriented&nbsp;programming”.</p>
<p>Quick: off the top of your head, what makes JavaScript an object-oriented&nbsp;language?</p>
<p>If you thought “what?  it’s not!” then there is no hope for you and you should go back to&nbsp;C++.</p>
<p>If you thought “prototypes” or “the <code>new</code> operator”, you are&nbsp;wrong!</p>
<p>The key and <em>only</em> feature that makes JavaScript object-oriented is the humble and error-prone <code>this</code>.&nbsp;Observe:</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>var</span> <span>date</span> <span>=</span> <span>{</span>
    <span>year</span><span>:</span> <span>2013</span><span>,</span>
    <span>month</span><span>:</span> <span>3</span><span>,</span>
    <span>day</span><span>:</span> <span>3</span><span>,</span>
    <span>to_iso8601</span><span>:</span> <span>function</span><span>()</span> <span>{</span>
        <span>// we'll pretend this function exists</span>
        <span>return</span> <span>sprintf</span><span>(</span><span>"%04d-%02d-%02d"</span><span>,</span> <span>this</span><span>.</span><span>year</span><span>,</span> <span>this</span><span>.</span><span>month</span><span>,</span> <span>this</span><span>.</span><span>day</span><span>);</span>
    <span>},</span>
<span>};</span>
</code></pre></div>
</td></tr></tbody></table>
<p>There’s no <code>new</code> here.  There’s no prototype.  There’s just state and behavior, and that makes it an object.  What it <em>is</em> and what it <em>does</em>.  Even if JavaScript lacked prototypes entirely, it would <em>still</em> be object-oriented as long as you could use <code>this</code>.</p>
<p><span>“</span>But what about classes?”  Who cares?  Worst case, you could <em>build your own class implementation</em> by copying the method definitions into every new object you created.  Maybe you’d make a master object containing those methods, for ease of copying.  Maybe you’d make the master object track all the objects derived from it, so you could propagate any changes to the master object.  You could even give the master object a special method all its own for generating new objects based on it.  And then the master object would itself be an object, so it could be an implementation of itself.  Wow, this sounds kinda like&nbsp;classes!</p>
<p>For similar reasons, C is <em>not</em> object-oriented.  You can write object-oriented <em>code</em> in C, but no matter what tricks you do with storing function pointers in structs, you still have to pass the struct itself as an explicit argument.  The behavior is completely divorced from and unaware of the&nbsp;state.</p>
<p>State and&nbsp;behavior.</p>
<p>I keep repeating this in the hopes that it sticks, because too much <span>OO</span> code is written like Java, and too many programmers believe that <span>OO</span> is defined <em>by</em> Java.  Well, you know, fuck&nbsp;Java.</p>
<p>Last pop quiz: what makes Python an object-oriented&nbsp;language?</p>
<p>Ah, hm.  It can’t be classes, or I’d tell you you’re wrong.  So what is it?  Attributes?  Those are just sugar for <code>__dict__</code> lookups.  <code>self</code>?  No, that’s not a keyword or anything; it’s just the de facto standard name for the first argument.  So what makes <code>self</code> work?</p>
<p>That’s close enough, really.  The answer is <a href="http://me.veekun.com/blog/2012/05/23/python-faq-descriptors/">descriptors</a>, which are basically “the things that make <code>self</code> work”.  A descriptor object is an attribute of a <em>class</em>, and it’s invoked whenever that attribute is accessed on an <em>instance</em> of that class.  Methods are, in fact, very simple descriptors that effectively return <code>partial(method, instance)</code>!</p>
<p>Descriptors are the <em>only</em> part of Python <span>OO</span> that cannot be semantically reimplemented in Python itself.  Methods are easy; I just told you how to do it.  Objects are just dicts with sugar (and descriptors!) on top.  Classes are sugar for dumping a scope into a dict; you could just as well do it manually with <code>locals()</code>.  Inheritance is just chained attribute lookup.  Metaclasses are just more objects in much the same way as the JavaScript example above.  These are all convenient patterns baked into the syntax, but descriptors are what make it <em>work</em>.</p>
<p>State and&nbsp;behavior.</p>
<h2 id="stupid-classes"><a href="#stupid-classes">Stupid&nbsp;classes</a></h2>
<p>This almost brings me back to my thesis, but first I need some examples of stupid classes.  I’m going to be writing these examples in Python because it has the local minimum of syntactic noise, but the idea’s the same basically&nbsp;anywhere.</p>
<h3 id="the-im-too-good-for-functions-antipattern"><a href="#the-im-too-good-for-functions-antipattern">The "I'm too good for functions"&nbsp;antipattern</a></h3>
<p>A shockingly common form is the humble “job”—a task to be scheduled and performed.  Cron job, batch job, whatever it may be.  You generally have some <code>Job</code> master class (or “abstract base class” or whatever frilly name the documentation gives&nbsp;it):</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>class</span> <span>CleanupJob</span><span>(</span><span>Job</span><span>):</span>
    <span># configuration: run at 5am</span>
    <span>run_at</span> <span>=</span> <span>'05:00'</span>

    <span># implementation: nuke expired sessions</span>
    <span>def</span> <span>run</span><span>(</span><span>self</span><span>):</span>
        <span>delete_expired_stuff</span><span>()</span>
</code></pre></div>
</td></tr></tbody></table>
<p>If you’ve watched “Stop Writing Classes”, you may immediately recognize this as one of the major sins he covered: a class that only has one method, which should instead be a function.  He’s right about that, but I have a different take on <em>why</em> this is so wrong, and I think my reasoning extends better to other kinds of stupid&nbsp;classes.</p>
<p>Here’s my question for you: <strong>what is a <code>CleanupJob</code> object?</strong></p>
<p>You might say “it’s a job for cleaning up stuff”.  That sure <em>sounds</em> reasonable—but then what is its state, and what is its behavior?  Its behavior appears to be deleting old things, but what does this have to do with the notion of a “job”?  What state does it have that’s relevant to deleting things?  I suppose if <code>Job</code> provides a database connection, the function could make use of it, but isn’t the connection itself more a part of “the job” or “your app configuration”, not so much the specific task of&nbsp;cleanup?</p>
<p>This is all a little murky.  Yet <code>Job</code> itself seems self-contained and clearly defined.  Presumably it has behavior like checking the time and setting up some resources and other bookkeeping—that is, its <em>behavior</em> is to set up some <em>state</em> and then call this <code>run</code> method.  It almost seems like <em>the class itself</em> is trying to be “a job for cleaning up&nbsp;stuff”.</p>
<p>And we’ve stumbled upon the problem here: the implementation, the <code>run</code> method, <strong>isn’t behavior</strong>.  It’s the <em>state</em>!  The behavior is to <em>run</em> this function, granted, but the function itself has <em>nothing to do</em> with jobs.  We’ve just turned it into a method because…  wait, why <em>did</em> we do that?  It’s not like passing functions around as data is particularly difficult in&nbsp;Python.</p>
<p>I have a hypothesis: this pattern is so common for the simple reason that <strong>Java doesn’t have first-class functions</strong>.  Java is one of the most common environments from which the current generation of programmers learned about object-orientation, but its inherent deficiencies mean that this simple job concept <em>cannot</em> be implemented correctly.  And I’m not only ragging on Java: I would put C++ and <span>PHP</span> in second and third place, and they have the <em>same flaw</em>.  (Yes, yes, you <em>can</em> pass function pointers around in C++, but it’s so awkward that it might as well be black&nbsp;magic.)</p>
<p>What’s my alternative?  Hard to say; it depends on your language’s idioms.  In the case of Python,&nbsp;decorators.</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>cleanup_job</span> <span>=</span> <span>Job</span><span>(</span><span>run_at</span><span>=</span><span>'05:00'</span><span>)</span>

<span>@cleanup_job</span><span>.</span><span>run</span>
<span>def</span> <span>do_cleanup</span><span>(</span><span>job</span><span>):</span>
    <span>delete_expired_stuff</span><span>()</span>
</code></pre></div>
</td></tr></tbody></table>
<p>You may notice that this looks <em>pretty</em> similar.  <strong>That’s good!</strong>  It means doing this the right way is really easy.  But look what we’ve gained&nbsp;here.</p>
<ul>
<li>With classes like this that try to use inheritance as a configuration mechanism, you often want to reuse the same configuration.  So you make an intermediate class that has just the shared configuration.  Now you need something <em>slightly</em> different sometimes, so you add a mixin, and now you have multiple inheritance, and overrides propagate in weird ways, and who even knows what’s&nbsp;happening.</li>
<li>The same implementation can rather naturally be attached to multiple jobs, without making even more of a mess of that artificial inheritance&nbsp;hierarchy.</li>
<li>Need to add another kind of callback, like common pre-run bookkeeping, that only some subset of jobs share?  No problem: <code>cleanup_job.add_pre_run(setup_logging)</code>.</li>
<li>You can test <code>Job</code> itself and particular jobs independently, and rather easily.  Create a <code>Job</code>-like class that has only the resources a particular job needs, and pass it in.  No need to, say, mock out all the internals to force the job to run immediately instead of at a specified&nbsp;time.</li>
</ul>
<p>There’s a common theme among these bullet points.  By making implementations of <code>Job</code> be subclasses instead of instances, the only tools available for factoring out common code or adding new behaviors are the tools built into the core of the class system: primarily, inheritance.  By using instances, <em>the entire language</em> can be used however you want, because they’re just objects.  The parts are clearly defined, easy to reason about, and easy to&nbsp;reuse.</p>
<p>Not convinced by any of these bullet points?  Doesn’t matter; they, too, are just fluff.  The real reason here is that this is the <em>right</em> way to structure a program, and shoehorning functions into methods is <em>wrong</em>, and that’s <a href="http://me.veekun.com/blog/2012/03/24/on-principle/">good enough for me</a>.</p>
<p>After all, there’s probably a good reason we don’t all do&nbsp;this.</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>class</span> <span>StudentGrades</span><span>(</span><span>object</span><span>):</span>
    <span>alice</span> <span>=</span> <span>100</span>
    <span>bob</span> <span>=</span> <span>96</span>
    <span>charles</span> <span>=</span> <span>62</span>
    <span>david</span> <span>=</span> <span>85</span>
</code></pre></div>
</td></tr></tbody></table>
<p>Exactly the same&nbsp;thing.</p>
<h3 id="the-controller-antipattern"><a href="#the-controller-antipattern">The controller&nbsp;antipattern</a></h3>
<p>Here’s the good part: the “state and behavior” mantra doesn’t just apply to one-method wonders.  I bet you’ve seen this&nbsp;before:</p>
<table><tbody><tr><td><div><pre><span> 1</span>
<span> 2</span>
<span> 3</span>
<span> 4</span>
<span> 5</span>
<span> 6</span>
<span> 7</span>
<span> 8</span>
<span> 9</span>
<span>10</span>
<span>11</span>
<span>12</span></pre></div></td><td><div><pre><span></span><code><span>class</span> <span>LoginController</span><span>(</span><span>Controller</span><span>):</span>
    <span>def</span> <span>register</span><span>(</span><span>self</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>render_template</span><span>(</span><span>'/register.mako'</span><span>)</span>

    <span>def</span> <span>login</span><span>(</span><span>self</span><span>):</span>
        <span>if</span> <span>self</span><span>.</span><span>request</span><span>.</span><span>method</span> <span>==</span> <span>'POST'</span><span>:</span>
            <span># ...</span>
        <span>else</span><span>:</span>
            <span>return</span> <span>self</span><span>.</span><span>render_template</span><span>(</span><span>'/login.mako'</span><span>)</span>

    <span>def</span> <span>logout</span><span>(</span><span>self</span><span>):</span>
        <span># ...</span>
</code></pre></div>
</td></tr></tbody></table>
<p>This is the controller pattern.  At first glance, this might seem perfectly reasonable: there are, clearly, multiple methods&nbsp;here.</p>
<p>I ask once more: what is a <code>LoginController</code> object, and what does it&nbsp;do?</p>
<p>I can tell you what it does: it handles various auth-related page requests.  That’s a little hokey, but okay.  <em>What <strong>is</strong>&nbsp;it?</em></p>
<p>It’s nothing.  There’s no way to describe it without sounding like a blowhard.  It’s not “a controller for some <span>URL</span> space”, because <em>that’s what the class is</em>.  An instance of it is utterly&nbsp;meaningless!</p>
<p>Once again, these “methods” are actually state, not behavior.  They’re all attributes of some application object whose <em>behavior</em> is to receive requests and dispatch them to the appropriate handler functions.  Turning those functions into methods muddies the distinction between your framework and your particular&nbsp;app.</p>
<p>Look at how <a href="http://flask.pocoo.org/">Flask</a> does&nbsp;it:</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>hello</span><span>():</span>
    <span>return</span> <span>u</span><span>"Hello world!"</span>
</code></pre></div>
</td></tr></tbody></table>
<p>The app is the object, and the various <span>URL</span> handlers are its state.  <a href="http://www.pylonsproject.org/projects/pyramid/about">Pyramid</a> does the&nbsp;same:</p>
<h6 id="viewspy"><a href="#viewspy">views.py</a></h6>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>@view_config</span><span>(</span><span>route_name</span><span>=</span><span>'home'</span><span>)</span>
<span>def</span> <span>home</span><span>(</span><span>request</span><span>):</span>
    <span>return</span> <span>Response</span><span>(</span><span>u</span><span>"Hello world!"</span><span>)</span>
</code></pre></div>
</td></tr></tbody></table>
<h6 id="apppy"><a href="#apppy">app.py</a></h6>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>config</span> <span>=</span> <span>Configurator</span><span>()</span>
<span>config</span><span>.</span><span>scan</span><span>()</span>  <span># picks up the decorated function in views.py</span>
<span>app</span> <span>=</span> <span>config</span><span>.</span><span>make_wsgi_app</span><span>()</span>
</code></pre></div>
</td></tr></tbody></table>
<p>The app is the object, and the various <span>URL</span> handlers are its&nbsp;state.</p>
<p>Think this only applies to Web frameworks?  I bet you’ve seen this before,&nbsp;too:</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>class</span> <span>TestSomething</span><span>(</span><span>UnitTest</span><span>):</span>
    <span>def</span> <span>test_one</span><span>(</span><span>self</span><span>):</span>
        <span>assert</span> <span>True</span>

    <span>def</span> <span>test_two</span><span>(</span><span>self</span><span>):</span>
        <span>assert</span> <span>True</span>
</code></pre></div>
</td></tr></tbody></table>
<p>You already know what I’m going to ask: what is a <code>TestSomething</code> object?  Less than nothing.  Does it even have any state?  It looks like it’s only instantiated at all so its “methods” can be&nbsp;called!</p>
<p>I have seen some <em>royal</em> messes result from this pattern, especially when combined with multiple-inheritance-for-sharing and extras like teardown methods.  If you get the <code>super</code>s wrong, you might not be tearing your tests&nbsp;down.</p>
<p>Here’s the same test suite, rewritten with <a href="http://pytest.org/latest/">py.test</a>:</p>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>def</span> <span>test_one</span><span>():</span>
    <span>assert</span> <span>True</span>

<span>def</span> <span>test_two</span><span>():</span>
    <span>assert</span> <span>True</span>
</code></pre></div>
</td></tr></tbody></table>
<p>py.test does support test classes, but <em>everything</em> it can do works just as well with plain functions.  Need setup, teardown, resources, sharing?  No problem; you can define it all, scoped however you want, <a href="http://pytest.org/latest/fixture.html#fixture">far far away from your actual tests</a>.</p>
<h3 id="and-so"><a href="#and-so">And&nbsp;so</a></h3>
<p>What’s a stupid class, then?  One that produces <em>stupid objects</em>—ones that lack clear and meaningful <em>state and behavior</em>.  State and behavior.  State and behavior.  If it doesn’t bundle state and behavior in a sensible way, it should not be an object, and there should not be a class that produces&nbsp;it.</p>
<p>Easy litmus test: what is an instance of your class, in no more than five words?  Most stupid classes require explanations that begin “it’s an object that…” and then you only have one word left.  Sensible objects should have a <em>description</em>.  They should <em>be</em> something.  Lists <em>are</em> sequences of items.  Modules <em>are</em> containers for related code.  Jobs <em>are</em> scheduled maintenance tasks.  Applications <em>are</em> dispatchers for an entire&nbsp;site.</p>
<h2 id="but-armin-is-right-too"><a href="#but-armin-is-right-too">But Armin is right&nbsp;too</a></h2>
<p>I hope I’ve made an inkling of a point by now.  If not about object design in general, at least about controller classes.  But before you run off with the impression that I think all classes are evil: remember, I agree with “Start Writing More Classes”&nbsp;too.</p>
<p>The difference is all in the examples.  Armin cites parts of&nbsp;Flask.</p>
<h6 id="jinjapy"><a href="#jinjapy">jinja.py</a></h6>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>def</span> <span>get_template</span><span>(</span><span>self</span><span>,</span> <span>name</span><span>,</span> <span>parent</span><span>=</span><span>None</span><span>,</span> <span>globals</span><span>=</span><span>None</span><span>):</span>
    <span>if</span> <span>parent</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>name</span> <span>=</span> <span>self</span><span>.</span><span>join_path</span><span>(</span><span>name</span><span>,</span> <span>parent</span><span>)</span>
    <span>return</span> <span>self</span><span>.</span><span>loader</span><span>.</span><span>load</span><span>(</span><span>self</span><span>,</span> <span>name</span><span>,</span> <span>globals</span><span>)</span>
</code></pre></div>
</td></tr></tbody></table>
<h6 id="loaderpy"><a href="#loaderpy">loader.py</a></h6>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>def</span> <span>load</span><span>(</span><span>self</span><span>,</span> <span>environment</span><span>,</span> <span>name</span><span>,</span> <span>globals</span><span>=</span><span>None</span><span>):</span>
    <span>if</span> <span>globals</span> <span>is</span> <span>None</span><span>:</span>
        <span>globals</span> <span>=</span> <span>{}</span>
    <span>source</span><span>,</span> <span>filename</span><span>,</span> <span>uptodate</span> <span>=</span> <span>self</span><span>.</span><span>get_source</span><span>(</span><span>environment</span><span>,</span> <span>name</span><span>)</span>
    <span>code</span> <span>=</span> <span>environment</span><span>.</span><span>compile</span><span>(</span><span>source</span><span>,</span> <span>name</span><span>,</span> <span>filename</span><span>)</span>
    <span>return</span> <span>environment</span><span>.</span><span>template_class</span><span>.</span><span>from_code</span><span>(</span><span>environment</span><span>,</span> <span>code</span><span>,</span>
                                                <span>globals</span><span>,</span> <span>uptodate</span><span>)</span>
</code></pre></div>
</td></tr></tbody></table>
<h6 id="environmentpy"><a href="#environmentpy">environment.py</a></h6>
<table><tbody><tr><td></td><td><div><pre><span></span><code><span>def</span> <span>compile</span><span>(</span><span>self</span><span>,</span> <span>source</span><span>,</span> <span>name</span><span>,</span> <span>filename</span><span>=</span><span>None</span><span>):</span>
    <span># template code to jinja's abstract syntax tree</span>
    <span>source</span> <span>=</span> <span>self</span><span>.</span><span>_parse</span><span>(</span><span>source</span><span>,</span> <span>name</span><span>,</span> <span>filename</span><span>)</span>
    <span># jinja's abstract syntax tree to python source</span>
    <span>source</span> <span>=</span> <span>self</span><span>.</span><span>_generate</span><span>(</span><span>source</span><span>,</span> <span>name</span><span>,</span> <span>filename</span><span>)</span>
    <span># python source to bytecode</span>
    <span>return</span> <span>self</span><span>.</span><span>_compile</span><span>(</span><span>source</span><span>,</span> <span>filename</span><span>)</span>
</code></pre></div>
</td></tr></tbody></table>
<p>The <a href="http://lucumr.pocoo.org/2013/2/13/moar-classes/">actual article</a> has some commentary on what these parts actually <em>are</em>, but I’m interested in how they’re <em>written</em>.</p>
<p>Because, you see, these methods are <strong>all on different objects</strong>.  Each of them implements a tiny fraction of a <em>different thing</em>‘s behavior.  The Flask app itself knows how to get a template, but only by consulting a template loader it owns.  The template loader knows the mechanics of finding a template, but it needs to consult an environment object to know where to actually look.  The environment object knows how to compile a template, but breaks it into meaningful and independent&nbsp;steps.</p>
<p>These are all independent things that I can talk about meaningfully.  I can work on them without needing to understand the context of how they’re used or what they use themselves.  I could test them without concerning myself with a thousand other intertwined code paths.  They all have <em>state and behavior</em> that I could describe in a sentence or two, and you’d have a pretty good idea of everything they do and how they do&nbsp;it.</p>
<p>These are good classes, <strong>because they produce good objects.</strong>  And when you have a lot of good objects, you can certainly replace them and change them and reuse them and recombine them as Armin wishes he could do more often.  Remember py.test?  All of its shenanigans are built on objects, even if the tests themselves are not.  You know <span>WSGI</span>?  It’s all defined in terms of callables, yet most of the time we use classes with <code>__call__</code> methods instead.  Pyramid uses <em>mountains</em> of objects and hooks under the hood, but you’ll never notice until the day you realize you need to toy with some of&nbsp;them.</p>
<h2 id="so"><a href="#so">So</a></h2>
<p>So please stop using classes as shapeless bags in which to dump functions.  Chances are, either that big ol’ function is actually the state of a different kind of object entirely, or there are several smaller concerns in there you could break&nbsp;apart.</p>
<p>Hell, if you can manage it, forget about classes entirely.  They’re just a convenient way to factor common behavior out of objects.  Let’s design useful, scoped, meaningful objects, and <em>then</em> write classes that produce&nbsp;them.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A biological camera that captures and stores images directly into DNA (168 pts)]]></title>
            <link>https://www.nature.com/articles/s41467-023-38876-w</link>
            <guid>36663498</guid>
            <pubDate>Mon, 10 Jul 2023 08:26:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41467-023-38876-w">https://www.nature.com/articles/s41467-023-38876-w</a>, See on <a href="https://news.ycombinator.com/item?id=36663498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <div id="Sec1-section" data-title="Introduction"><h2 id="Sec1">Introduction</h2><div id="Sec1-content"><p>DNA is a key biomaterial that forms the basis of biological life on earth. It serves as the storage of genetic information that encodes for the multitude of proteins which fulfil various functions of life. Due to this ability to act as a storage of information, along with its simple, repeating code of 4 nucleotides, ATCG, DNA has been proposed and subsequently explored as a form of digital information storage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Church, G. M., Gao, Y. &amp; Kosuri, S. Next-generation digital information storage in DNA. Science 337, 1628–1628 (2012)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR1" id="ref-link-section-d8717801e470">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Goldman, N. et al. Towards practical, high-capacity, low-maintenance information storage in synthesized DNA. Nature 494, 77–80 (2013)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR2" id="ref-link-section-d8717801e473">2</a></sup>. This is due to its extreme density (petabytes per gram<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Zhirnov, V., Zadegan, R. M., Sandhu, G. S., Church, G. M. &amp; Hughes, W. L. Nucleic acid memory. Nat. Mater. 15, 366–370 (2016)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR3" id="ref-link-section-d8717801e477">3</a></sup>), longevity (DNA has been retrieved from samples millions of years old<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="van der Valk, T. et al. Million-year-old DNA sheds light on the genomic history of mammoths. Nature, 1–5. 
                  https://doi.org/10.1038/s41586-021-03224-9
                  
                 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR4" id="ref-link-section-d8717801e481">4</a></sup>), and continued relevance to study due to its underpinning of biological life. These properties have led to a recent boom in developing different workflows<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lim, C. K., Nirantar, S., Yew, W. S. &amp; Poh, C. L. Novel Modalities in DNA Data Storage. Trends Biotechnol. 39, 990–1003 (2021)." href="#ref-CR5" id="ref-link-section-d8717801e485">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tabatabaei, S. K. et al. DNA punch cards for storing data on native DNA sequences via enzymatic nicking. Nat. Commun. 11, 1–10 (2020)." href="#ref-CR6" id="ref-link-section-d8717801e485_1">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chen, K., Zhu, J., Bošković, F. &amp; Keyser, U. F. Nanopore-based DNA hard drives for rewritable and secure data storage. Nano Lett. 
                  https://doi.org/10.1021/acs.nanolett.0c00755
                  
                 (2020)." href="#ref-CR7" id="ref-link-section-d8717801e485_2">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tomek, K. J. et al. Driving the scalability of DNA-based information storage systems. ACS Synth. Biol. 8, 1241–1248 (2019)." href="#ref-CR8" id="ref-link-section-d8717801e485_3">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Yim, S. S. et al. Robust direct digital-to-biological data storage in living cells. Nat. Chem. Biol. 17, 1–8 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR9" id="ref-link-section-d8717801e488">9</a></sup> for converting digital data into DNA and vice versa, which has been increasingly relevant and urgent due to the impending shortage of silica necessary for manufacturing storage devices required to accommodate our projected data storage requirements<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Zhirnov, V., Zadegan, R. M., Sandhu, G. S., Church, G. M. &amp; Hughes, W. L. Nucleic acid memory. Nat. Mater. 15, 366–370 (2016)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR3" id="ref-link-section-d8717801e492">3</a></sup>.</p><p>Current DNA storage workflows largely rely on in vitro synthesis of DNA strands, which are costly and require complex instrumentation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ceze, L., Nivala, J. &amp; Strauss, K. Molecular digital data storage using DNA. Nat. Rev. Genet. 20, 456–466 (2019)." href="#ref-CR10" id="ref-link-section-d8717801e499">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lee, H. H., Kalhor, R., Goela, N., Bolot, J. &amp; Church, G. M. Terminator-free template-independent enzymatic DNA synthesis for digital information storage. Nat. Commun. 10, 1–12 (2019)." href="#ref-CR11" id="ref-link-section-d8717801e499_1">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Takahashi, C. N., Nguyen, B. H., Strauss, K. &amp; Ceze, L. Demonstration of end-to-end automation of DNA Data Storage. Sci. Rep. 9, 1–5 (2019)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR12" id="ref-link-section-d8717801e502">12</a></sup>. Errors in the synthesis process are also common. While there have been substantial advances in accelerating this process by developing enzymatic synthesis methods<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Palluk, S. et al. De novo DNA synthesis using polymerase-nucleotide conjugates. Nat. Biotechnol. 36, 645–650 (2018)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR13" id="ref-link-section-d8717801e506">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lu, X. et al. Enzymatic DNA synthesis by engineering terminal deoxynucleotidyl transferase. ACS Catal. 2988–2997. 
                  https://doi.org/10.1021/acscatal.1c04879
                  
                 (2022)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR14" id="ref-link-section-d8717801e509">14</a></sup>, miniaturizing electrochemical synthesis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Xu, C. et al. Electrochemical DNA synthesis and sequencing on a single electrode with scalability for integrated data storage. Sci. Adv. 7, eabk0100 (2021)." href="#ref-CR15" id="ref-link-section-d8717801e513">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Nguyen, B. H. et al. Scaling DNA data storage with nanoscale electrode wells. Sci. Adv. 7, eabi6714 (2021)." href="#ref-CR16" id="ref-link-section-d8717801e513_1">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Antkowiak, P. L. et al. Low cost DNA data storage using photolithographic synthesis and advanced information reconstruction and error correction. Nat. Commun. 11, 5345 (2020)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR17" id="ref-link-section-d8717801e516">17</a></sup>, or developing more robust encoding methods<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Erlich, Y. &amp; Zielinski, D. DNA Fountain enables a robust and efficient storage architecture. Science 355, 950–954 (2017)." href="#ref-CR18" id="ref-link-section-d8717801e520">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wang, Y. et al. High capacity DNA data storage with variable-length Oligonucleotides using repeat accumulate code and hybrid mapping. J. Biol. Eng. 13, 89 (2019)." href="#ref-CR19" id="ref-link-section-d8717801e520_1">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Anavy, L., Vaknin, I., Atar, O., Amit, R. &amp; Yakhini, Z. Data storage in DNA with fewer synthesis cycles using composite DNA letters. Nat. Biotechnol. 37, 1229–1236 (2019)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR20" id="ref-link-section-d8717801e523">20</a></sup>, DNA synthesis remains a bottleneck in the adoption of DNA as a data storage medium. There is thus significant interest in developing ways of encoding information into DNA that can either supersede or circumvent DNA synthesis in its current form.</p><p>The abundance of DNA in living cells have been considered as a potential source of DNA that can be encoded with information via the use of molecular biology tools and biological systems. Utilizing living cells as a way to incorporate and record external signals such as the presence of chemicals or electrical inputs into DNA have also been demonstrated, with recording systems ranging from recombinases<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Sheets, M. B., Wong, W. W. &amp; Dunlop, M. J. Light-inducible recombinases for bacterial optogenetics. ACS Synth. Biol. 9, 227–235 (2020)." href="#ref-CR21" id="ref-link-section-d8717801e530">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yang, L. et al. Permanent genetic memory with >1-byte capacity. Nat. Methods 11, 1261–1266 (2014)." href="#ref-CR22" id="ref-link-section-d8717801e530_1">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Bonnet, J., Subsoontorn, P. &amp; Endy, D. Rewritable digital data storage in live cells via engineered control of recombination directionality. Proc. Natl Acad. Sci. USA 109, 8884–8889 (2012)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR23" id="ref-link-section-d8717801e533">23</a></sup> to CRISPR-based modifications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. Molecular recordings by directed CRISPR spacer acquisition. Science 353, aaf1175 (2016)." href="#ref-CR24" id="ref-link-section-d8717801e537">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. CRISPR–Cas encoding of a digital movie into the genomes of a population of living bacteria. Nature 547, 345–349 (2017)." href="#ref-CR25" id="ref-link-section-d8717801e537_1">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Tang, W. &amp; Liu, D. R. Rewritable multi-event analog recording in bacterial and mammalian cells. Science 360, eaap8992 (2018)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR26" id="ref-link-section-d8717801e540">26</a></sup>. Most notably, recent work has showcased the storage of 72 bits of information directly into the genomic DNA of living cells via external electrical input signals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Yim, S. S. et al. Robust direct digital-to-biological data storage in living cells. Nat. Chem. Biol. 17, 1–8 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR9" id="ref-link-section-d8717801e544">9</a></sup>, as well as the use of DNA structural barcodes that bind to the M13mp18 bacteriophage DNA scaffold to encode information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Chen, K., Zhu, J., Bošković, F. &amp; Keyser, U. F. Nanopore-based DNA hard drives for rewritable and secure data storage. Nano Lett. 
                  https://doi.org/10.1021/acs.nanolett.0c00755
                  
                 (2020)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR7" id="ref-link-section-d8717801e548">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Chen, K. et al. Digital data storage using DNA nanostructures and solid-state nanopores. Nano Lett. 19, 1210–1215 (2019)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR27" id="ref-link-section-d8717801e551">27</a></sup>. However, such systems have not been able to accurately capture spatial information, due to the lack of mechanisms that can simultaneously encode spatial information as well as external input signals. Furthermore, existing encoding systems also tend to utilize low-throughput chemical processes, which severely limits scalability.</p><p>In this paper, we present a workflow that allows the direct capture of both spatial information and input signals via light into DNA itself as a means to store digital information such as images into DNA. We utilize a blue light-responsive recombinase system that responds to the presence or absence of blue light as an external signal, and subsequently records that response into DNA itself via site-specific DNA editing. To enable the encoding of spatial information along with the recorded signal, we implemented a barcoding scheme to enable differentiation of individual wells containing cells with records of light exposure, thereby ‘digitizing’ the recorded image and allowing for deconvolution upon retrieval of the DNA sequences by sequencing. As a result, this recombinase-based DNA recorder, coupled with the aforementioned barcoding scheme that can preserve spatial information, enables the direct capture of both spatial information as well as input signals via light into DNA itself. While previous work has demonstrated the usage of light-responsive systems that can capture light and display this input as a corresponding light output, akin to an analogue camera<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Fernandez-Rodriguez, J., Moser, F., Song, M. &amp; Voigt, C. A. Engineering RGB color vision into Escherichia coli. Nat. Chem. Biol. 13, 706–708 (2017)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR28" id="ref-link-section-d8717801e558">28</a></sup>, our process instead creates a biological analogue to a digital camera which we term as ‘BacCam’. As the DNA encoded with different images can be pooled and stored together, we further characterize this workflow by demonstrating random access and multiplexing, and utilize outlier detection and reassignment techniques, along with unsupervised clustering algorithms from the field of machine learning to accurately reconstruct the stored data. Taking advantage of the multiplexing capabilities offered by light, we further layer an orthogonal red light system with the blue light system to allow encoding of 2 images simultaneously, increasing the scalability and density of the workflow and enabling multicolor image capture. Utilizing molecular biology methods, optogenetics, barcoding techniques, and biological systems, we thus provide a framework for the integration of biological and digital interfaces.</p></div></div><div id="Sec2-section" data-title="Results"><h2 id="Sec2">Results</h2><div id="Sec2-content"><h3 id="Sec3">BacCam enables the direct-to-DNA storage and retrieval of images</h3><p>Light has the distinct advantages of being cheap, massively parallelizable, rapid, highly programmable, and easily multiplexed, with little effort or cost needed to scale or generate patterns of increasing complexity. There is therefore an interest in utilizing light as a patterning mechanism in biology, such as in photolithographic DNA synthesis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Antkowiak, P. L. et al. Low cost DNA data storage using photolithographic synthesis and advanced information reconstruction and error correction. Nat. Commun. 11, 5345 (2020)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR17" id="ref-link-section-d8717801e574">17</a></sup>, as well as optogenetic circuits for multiple purposes such as bioproduction or controlling cellular behavior on a spatiotemporal level<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jayaraman, P. et al. Blue light-mediated transcriptional activation and repression of gene expression in bacteria. Nucleic Acids Res. 44, 6994–7005 (2016)." href="#ref-CR29" id="ref-link-section-d8717801e578">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pouzet, S. et al. The promise of optogenetics for bioproduction: dynamic control strategies and scale-up instruments. Bioengineering 7, 151 (2020)." href="#ref-CR30" id="ref-link-section-d8717801e578_1">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Mansouri, M. &amp; Fussenegger, M. Synthetic biology-based optogenetic approaches to control therapeutic designer cells. Curr. Opin. Syst. Biol. 28, 100396 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR31" id="ref-link-section-d8717801e581">31</a></sup>. We therefore sought a way to utilize light as an input to encode information into DNA. We hypothesized that cells containing optogenetic circuits that can record the presence or absence of light within DNA can be perceived as analogous to a digital camera that captures images via light exposure and records said exposure in a digital format. We thus utilized an Opto-Cre-Vvd recombinase system, whereby a Cre-Lox recombinase protein was engineered to be light inducible by splitting the recombinase and attaching photodimers that bring the split protein together upon exposure to blue light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Sheets, M. B., Wong, W. W. &amp; Dunlop, M. J. Light-inducible recombinases for bacterial optogenetics. ACS Synth. Biol. 9, 227–235 (2020)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR21" id="ref-link-section-d8717801e585">21</a></sup>. The recombinase, upon activation, excises a predefined section of DNA that are flanked by LoxP sites, resulting in an alteration in the sequence. We posited that this alteration is analogous to the encoding of a bit. To determine whether a bit has been encoded, upon sequencing, the total number of reads that possess the excised LoxP sequence is compared to the total number of reads with the full LoxP sequence. A high ratio of excised reads to unexcised ones would correspond to a bit state of ‘1’ being encoded, while the opposite would correspond to a bit state of ‘0’.</p><p>We then posited that a 96-well plate, with each well being appropriately barcoded, and containing cells with the Opto-Cre-Vvd and LoxP genetic circuits, would be analogous to a digital camera with image sensors each containing individual pixels that have their own unique identifier, storing information corresponding to light exposure. To scale the one-bit digital drive within each cell to that of a multi-pixel image, a population of <i>Escherichia</i> <i>coli</i> (<i>E. coli</i>) bacteria containing the above-mentioned circuit was spatially separated in individual wells of a black, clear-bottomed 96-well plate, upon which a predefined pattern of 465 nm wavelength light was projected from below.</p><p>The projected pattern is then preserved by the addition of unique oligonucleotide barcodes, which we term as ‘well-codes’, that bind at the region preceding the LoxP recording site. The nucleotide sequence of the well-code is mapped to predefined spatial locations, with said mappings saved in a separate table, thereby resulting in the linkage of the spatial location of the recording bacteria in each isolated well along with the recorded digital drive that each bacteria possesses. The addition of the well-code to the recording sequence is conducted via PCR. Further oligonucleotide sequences were then appended via PCR to prepare the individual samples for Next-Generation Sequencing (NGS). Subsequently, all samples are then pooled together for storage, which obviates the need for preserving the original well configuration as the unique well-codes have tied this configuration with the recorded bit state. This results in a pool of DNA oligonucleotide sequences that stores the information of the image that was captured (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig1">1</a>). In practice, this barcoding system enables the capture of 2-dimensional images, where each pixel’s location is represented by a well-code, and the bit state of the pixel is determined by the presence or absence of the DNA excision site. This resulting data can be stored robustly in dried form on a benchtop at room temperature, or frozen in a −20 °C fridge.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Workflow of BacCam."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Workflow of BacCam.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="427"></picture></a></div><p><b>A</b> Encoding of light into bacteria and barcoding for preservation of spatial information. <b>B</b> Sequencing and decoding of stored DNA back into original image. <b>C</b> Initial proof of concept of BacCam using the ‘BACCAM’ pattern. Successful reconstruction of the image was done with 93/96 accuracy. Source data are provided as a Source Data file.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>To retrieve the image, sequencing of the pooled DNA was then conducted. The resulting sequencing data generated was then deconvoluted by determining the total number of sequences retrieved for each barcode, and the bit state determined by the ratio of sequences lacking the region between the LoxP sites to sequences containing the region. These ratios indicate the proportion of DNA that were excised compared to ones that were intact. High ratios would thus indicate that a larger proportion of DNA was excised, which would then imply that light exposure was ‘recorded’ and so recording a ‘1’ signal, and vice versa for lower ratios, which would then record a ‘0’ signal. The threshold determining the ratio that demarcates assignment of a ‘1’ or a ‘0’ signal was derived using clustering methods that compare ratios across each plate. This deconvolution was done for all well-codes used, and the resulting bit-well-code pairs were then reassembled back, according to a previously stored mapping table of well-codes to spatial locations, to form a digitized version of the projected image.</p><p>Utilizing the above-mentioned process, we have successfully demonstrated the viability of various aspects of the workflow detailed above. We demonstrated the recording of a predefined pattern into DNA and retrieved it via sequencing (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig1">1</a>). Deconvolution of the sequenced reads was done by mapping the well-code back to its spatial location, counting the number of excised and intact LoxP reads corresponding to each well-code, and determining the bit state of each well via the above-mentioned ratio of excised to intact LoxP reads.</p><h3 id="Sec4">Multiple images can be stored in a complex pool and retrieved with high accuracy</h3><p>We subsequently tested the multiplexing capability of our workflow, generating multiple images and pooling them together, and deconvoluting each image from the DNA sequencing data generated via sequencing of said pool. We hypothesized that each full image can also be barcoded with its own ‘meta-barcode’ that separates images from one another in a heterogenous DNA pool of multiple images, despite using the same well-codes that separate individual wells, allowing for multiplexing. We thus incorporated this second layer of indexing using indexing barcodes provided by Illumina. Each 96 well&nbsp;plate, after the addition of the initial well-codes, has the same&nbsp;2 indexing barcodes appended on the 5′ and 3′&nbsp;end of the sequence&nbsp;in each well. These barcodes are combinatorial in nature, thus increasing the possible number of total images that can be stored together.</p><p>To determine if this second indexing layer can be used to deconvolute multiple images from the same sample, we exposed 5 unique patterns to 5 different 96-well plates, thereby creating a set of 5 images (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig2">2A</a>). 4 of these patterns (NUS, SYNCTI, BacCam, and Smiley) illustrate the ability of the system to capture images. The last pattern, ‘Heloo wo{|d!’ serves to illustrate the ability of BacCam to encode information (such as letters and symbols represented in 8-bit ASCII code format) by allocating each well as a bit and encoding the information in a 96-well format. Hence, each column (8 wells) will encode one ASCII code. In this case, BacCam can also serve to encode any sort of information, as long as it is projected with the appropriate pattern.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Storage and retrieval of multiple images in a single complex pool."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Storage and retrieval of multiple images in a single complex pool.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="553"></picture></a></div><p>Red boxes indicate wells with allocated bits that do not correspond with the projected image. <b>A</b> Projected patterns that are stored with the BacCam process. Images are projected on different plates, barcoded individually with index sequences corresponding to each image, and resulting products are pooled together into a single tube. <b>B</b> Retrieved images from a single sequencing run of a mixed pool, deconvoluted with the corresponding indexes of each image. <b>C</b> Retrieved images from multiple sequencing runs, whereby random access of each image was conducted from the mixed pool by using specific primers to amplify desired images before sequencing. <b>D</b> Reconstruction of selectively amplified single images from mixed libraries of increasing dilutions, demonstrating robustness of the&nbsp;amplification technique in selecting specific images from an ever-decreasing initial amount of DNA. Source data are provided as a Source Data file.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>We then added the same set of well-codes to each of them via PCR, before extending each image with indexing barcodes. Each image used a different combination of indexing barcodes, which were then saved in a mapping table that links the unique index sequences with its corresponding image. These indexed images were then pooled together into the same pool of DNA. We then determined if a mixed, heterogenous pool of DNA can be sequenced as a whole library, with the individual images deconvoluted from the total raw reads that are produced by sequencing. We demonstrate that a mixed pool of at least 5 different images can be deconvoluted and reconstructed with an accuracy of at least 90% for all images, showcasing the multiplexing capability of our workflow (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig2">2B</a>).</p><p>We subsequently tested the ability of our workflow to implement random access of images, whereby each image can be selectively amplified and decoded without the need to sequence the entire mixed DNA pool. We hypothesized that designing primers that selectively bind to the indexed sequences corresponding to the desired image would be sufficient for random access, adequately amplifying each individual ‘pixel’ associated with the image, while avoiding amplification of sequences that do not possess the selected index. To test the hypothesis, we demonstrated that all images (with accuracy &gt; 80%) in a mixed pool of 5 can be selectively amplified and accessed by using the corresponding indexing primers and conducting a touchdown PCR to ensure precise binding and amplification of desired sequences<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Korbie, D. J. &amp; Mattick, J. S. Touchdown PCR for increased specificity and sensitivity in PCR amplification. Nat. Protoc. 3, 1452–1456 (2008)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR32" id="ref-link-section-d8717801e700">32</a></sup> (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig2">2C</a>), thus obviating the need to sequence the entire pool of DNA. Taken together, these results show that multiple images can be easily tagged, stored together and subsequently demultiplexed by using a simple indexing process that complements existing NGS workflows.</p><h3 id="Sec5">Information can be accurately reconstructed from small initial quantity of samples</h3><p>To determine the minimum amount of DNA required to reconstruct images accurately, we conducted a series of dilution experiments. We diluted a mixed pool of samples progressively, with each dilution being tenfold less than the previous. Sequencing of each dilution for a particular image for deconvolution and reconstruction demonstrated that images were accurately reconstructed at dilutions of a hundred-fold from the initial concentration (2.66 nM). At dilutions of a 1000-fold (2.66 pM), individual reads for each barcode numbered in the low single digits, with many having no reads at all. As a result, the fidelity of the image drops significantly (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig3">3A</a>). For large scale multiplexing of images, the concentration of DNA representing a single image drops as the number of images in each pool increases. This dilution assay thus provides us with an approximate proxy for the number of images that can be concurrently retrieved in a sequencing run, assuming a fixed volume of the pooled library was sequenced, and sequencing coverage remained the same. The results imply that the number of different images that can be stored in a pool and retrieved in a single run is between 100 and 1000. Increasing the number of distinct images that can be retrieved this way would therefore require an increase in sequencing coverage and/or increasing concentrations of each image.</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Testing the boundaries of BacCam."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Testing the boundaries of BacCam.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="237"></picture></a></div><p><b>A</b> Dilution experiments demonstrating the theoretical maximum information capacity of BacCam. Images can be successfully retrieved up to a dilution of 100× from the original fully amplified pool, with 1000x dilution having significantly higher number of errors due to the low number of reads. <b>B</b> No loss in information for ‘Smiley’ stored in both liquid and dried form. <b>C</b> No loss of information in ‘Heloo wo{|d!’ stored in varying conditions for extended periods of time. Source data are provided as a Source Data file.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>However, we also hypothesized that PCR amplification of diluted reads via random access might be sufficient to overcome the above-mentioned limit without an increase in sequencing coverage, saving costs while still allowing for multiplexed storage in the same pool. We therefore conducted serial dilutions on the mixed pool of images and utilized indexing primers for random access of selected images via PCR, amplifying the diluted DNA and sending it for sequencing. We demonstrated that the NUS image was selectively amplified with the N701 and N501 indexes (index sequences in Supplementary Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">1</a>), from a 50× dilution of an initial concentration of 17.98 nM to&nbsp;0.36 nM, up to a dilution of 50,000× (0.36 pM), showcasing the robustness of image retrieval from a complex pool of 5 images, and demonstrating consistent re-amplification of images from a small quantity of initial samples (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig2">2D</a>). Attempts to retrieve the other images contained in the mixed library after selective amplification were unsuccessful, demonstrating the capabilities of targeted amplification of selective images. It is also apparent that at lower dilutions, there is an increasing skew in terms of the ratio values—suggesting that amplification from minute amounts of sample tends to dramatically increase the contrast of reads that are excised compared to unexcised ones.</p><h3 id="Sec6">Images stored are durable in varying environmental conditions</h3><p>We further explored the limits of BacCam by subjecting it to a battery of physical challenges. One way to improve the density and stability of DNA is to dry it, due to the hydrolytic activity of water molecules on the phosphate backbone. This also has the effect of reducing volume, resulting in a higher overall density. To test the viability of our workflow for drying, we spun dried a volume of DNA corresponding to the ‘Smiley’ image before rehydration and sequencing. We showed that images in dried form could be successfully retrieved with zero loss in accuracy compared to liquid, frozen images (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig3">3B</a>).</p><p>We also subjected a DNA sample with the ‘Heloo wo{|d!’ image to accelerated aging experiments. This was done by comparing identical samples, both in aqueous form with one at room temperature (RT) and another that was kept in a 60 °C oven, both for a duration of 1 week. We also exposed a freshly thawed frozen sample to UV light for 1 hr. It was previously demonstrated that data encoded in dried DNA stored at a temperature of 70 °C for a duration of 7 days was not able to be retrieved, and that duration was equivalent to storing DNA at 9.4 °C for 2000 years<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Grass, R. N., Heckel, R., Puddu, M., Paunescu, D. &amp; Stark, W. J. Robust chemical preservation of digital information on DNA in silica with error-correcting codes. Angew. Chem. Int. Ed. 54, 2552–2555 (2015)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR33" id="ref-link-section-d8717801e769">33</a></sup>. We demonstrated a successful retrieval of said image from all samples, with no loss of information despite varying conditions, showcasing the inherent robustness and redundancy of the workflow (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig3">3C</a>).</p><h3 id="Sec7">Optimization of image deconvolution with computational methods</h3><p>Upon receipt of sequencing data, proportions of excised and unexcised DNA was calculated and allocated to appropriate wells. To determine the correct threshold that will allow for accurate separation of recorded light signals, we utilized a manual thresholding process based on foreknowledge of the encoded image. This method was used to assess the accuracy of the overall workflow in storing a projected image into DNA. While this method suffices due to foreknowledge of the pattern encoded, to enable a true information encoding and retrieval system, a method that can reconstruct a potential image solely from the sequenced data would be necessary. We theorized that computational clustering methods such as unsupervised machine learning techniques could be utilized to automatically identify the distinct groups/clusters. To preprocess the sequencing data before implementing the clustering methods, we applied an outlier detection technique also known as unsupervised anomaly detection to detect the outliers located at the low-density regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Breunig, M. M., Kriegel, H.-P., Ng, R. T. &amp; Sander, J. LOF: identifying density-based local outliers. ACM SIGMOD Rec. 29, 93–104 (2000)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR34" id="ref-link-section-d8717801e785">34</a></sup>. We proceeded to reassign the outliers with the nearest values detected from the inliers. This outlier detection and reassignment data preprocessing demonstrated improvement in removing small low-density clusters and enhancing the edges among larger clusters. Post-processing techniques were also implemented to satisfy the&nbsp;edge cases of having fully ‘ON’ or ‘OFF’&nbsp;images and to perform cluster grouping to retrieve these final binary state images. The entire automated workflow for image deconvolution is outlined in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig4">4A</a>.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Developing a machine learning clustering-based workflow for automated image deconvolution."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Developing a machine learning clustering-based workflow for automated image deconvolution.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="487"></picture></a></div><p><b>A</b> An automated workflow incorporating outlier detection and reassignment method, machine learning unsupervised clustering technique, full ON-OFF criteria assessment, and cluster grouping for automated image deconvolution. <b>B</b> An example implemented using GMM to demonstrate the results acquired at different phases. The dots in the graphs represent the raw data or the curated data from the 96 wells. The ‘1’ and ‘−1’ obtained from the Local Outlier Factor denote the inliers and outliers detected respectively from the raw data. The curated data were acquired after reassigning the outliers to the nearest values of inliers. The M0–M2 indicate the computed mean values of the individual clusters for full ON–OFF criteria assessment. The deconvoluted image was then plotted based on the three clusters and after clusters grouping into the final binary state image (‘0’: light blue; ‘1’: dark blue) with 3 error bits (orange). <b>C</b> Validation of the automated workflow on other patterns including full ‘ON’ and ‘OFF’ datasets.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>We tested multiple clustering methods under different parameter settings on the existing datasets, and compared the accuracy of the automated clustering methods with manual thresholding based on foreknowledge of the existing image (Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Tab1">1</a>). The results showed that the OPTICS clustering method and 3-component Gaussian Mixture Model (GMM) produced clusters that most closely emulated manual thresholds, with near perfect accuracy (Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S2</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S3</a>). We tested the results acquired using GMM at different phases of the workflow (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig4">4B</a>), showing how each phase contributes to building an accurate end result, and demonstrated the robustness of the automated workflow by showcasing all the successfully deconvoluted images with high accuracy (&gt;0.9) (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig4">4C</a>, Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S2</a>).</p><div data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption><b id="Tab1" data-test="table-caption">Table 1 Comparison of methods used for automated thresholding</b></figcaption><p><a data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://www.nature.com/articles/s41467-023-38876-w/tables/1" aria-label="Full size table 1"><span>Full size table</span></a></p></figure></div><h3 id="Sec8">Multiplexing with multiple colors of light</h3><p>One significant advantage of using light is the ability to multiplex in a simple fashion with the addition of different light wavelengths. We redesigned a red light sensitive Cre&nbsp;recombinase (pBbS5a-RLCre) initially developed in yeast systems to add the red wavelength to the existing blue light BacCam workflow<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Hochrein, L., Mitchell, L. A., Schulz, K., Messerschmidt, K. &amp; Mueller-Roeber, B. L-SCRaMbLE as a tool for light-controlled Cre-mediated recombination in yeast. Nat. Commun. 9, 1931 (2018)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR35" id="ref-link-section-d8717801e1307">35</a></sup>. To allow for differentiation between the two light systems in the workflow, we designed another recording plasmid&nbsp;(pBbAW4k-Spacer1Barcoding-loxP-TT-loxP-ho1-pcyA) that contained another intermediate barcode, thus differentiating edits caused by red light exposure to those caused by blue light exposure (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig5">5A</a>, Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S1</a>). We also designed a programmable light illumination device (OptoBox, Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S8</a>) to project multiple colors of light in the same well. We show that a co-culture of the blue light and red light-responsive bacteria in the same well is able to sense multiple wavelengths of light at the same time, and encode 2 separate images simultaneously. Images were encoded in two separate ways. One way involved the overnight projection of a blue light pattern along with a different red light pattern in an alternating fashion, with each pattern being projected for 10 min before switching. Another way involved projecting both images simultaneously (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig5">5B</a>). We demonstrate the successful encoding and retrieval of two different images with different wavelengths of light, with both methods of projection being viable approaches, with a minimum accuracy of more than 90% for each image encoded (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Fig5">5C</a>, Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S5</a>–<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S7</a>). These results demonstrate high orthogonality of both light systems (Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S9</a>).</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Multiplexing the BacCam workflow using multiple colors of light."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Multiplexing the BacCam workflow using multiple colors of light.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-38876-w/MediaObjects/41467_2023_38876_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="1289"></picture></a></div><p><b>A</b> Design of a co-culture of engineered <i>E. coli</i> with blue and red light sensitive recombinases respectively. The blue light Opto-Cre-Vvd system and the redesigned red light recombinase&nbsp;recording system were separately transformed into <i>E. coli</i>. <b>B</b> Experimental workflow of the co-culture. Both resulting strains of <i>E. coli</i> were co-cultured together on the same plate, and exposed to either alternating blue and red light projections, or simultaneous projections of both blue and red light. <b>C</b> Images obtained after sequencing and deconvolution, separating red and blue with the red light specific barcode and subsequently subjecting it to our deconvolution algorithm workflow based on 3-component Gaussian Mixture Model (GMM). Source data are provided as a Source Data file.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41467-023-38876-w/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span></a></p></figure></div></div></div><div id="Sec9-section" data-title="Discussion"><h2 id="Sec9">Discussion</h2><div id="Sec9-content"><p>In this work, we have proposed and demonstrated an alternative workflow for DNA data storage—a direct capture of images into DNA that is analogous to the creation of a digital camera. We demonstrated scaling of this workflow using a single color light (blue) wavelength to five 96 bit images, totaling 60 bytes, and showed that the theoretical limits of this system potentially scales to more than one hundred 96 bit images in a single heterogenous pool. We have also shown the ability for random access of individual images, even from a highly dilute concentration of 50,000x lesser than the initial concentration, and the reliable recovery of data from diluted, heat treated, UV-exposed and dried pools. We have implemented computational pipelines that serve to deconvolute the encoded information and correct for errors in a reliable fashion. To scale this workflow beyond a single wavelength of light, we incorporated an additional wavelength of light, doubling the amount of data that can be stored in a single, simultaneous capture and demonstrating the multiplexing potential of the system. This system further expands the boundaries of the field outside of preexisting DNA synthesis and sequencing workflows.</p><p>We have utilized living cells as the encoder for DNA data storage in this work. This offers several advantages over de novo in vitro DNA synthesis-based data storage formats. Living cells are an ever-renewing source of DNA, making it cost effective to produce at scale. Cells also possess a multitude of systems that can interface with DNA, such as transcription factor binding proteins, and are also able to respond to a multitude of stimuli ranging from chemical to light and electrical means that can also be recorded into DNA in vivo. Furthermore, in BacCam, the writing step is done in parallel, as each bit is encoded at the same time. As such, latency of writing is greatly reduced.</p><p>While living cells have been previously used as encoders for storing images, BacCam differs primarily from existing work by combining spatial addressability along with optogenetic systems to digitally encode information directly into DNA. This is in contrast to previous work such as that of Shipman et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. Molecular recordings by directed CRISPR spacer acquisition. Science 353, aaf1175 (2016)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR24" id="ref-link-section-d8717801e1388">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. CRISPR–Cas encoding of a digital movie into the genomes of a population of living bacteria. Nature 547, 345–349 (2017)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR25" id="ref-link-section-d8717801e1391">25</a></sup>, in which image information was encoded via de novo DNA synthesis before insertion into the bacterial genome. Furthermore, the multiplexing ability of light allows us to utilize different wavelengths of light to encode additional layers of information, providing significant flexibility in encoding and offering potential avenues for capacity expansion.</p><p>The resolution of images encoded is a function of the number of unique well-codes generated, as well as the physical separation and isolation of individually addressable bacterial populations. As a proof of concept, we have thus far utilized 96-well plates for convenience and cost. However, we envision that subsequent implementations of the workflow can be further miniaturized and scaled up to 384, 1536 or even higher resolution systems, leveraging advances in liquid handling devices, microchips<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Chen, B. et al. High-throughput analysis and protein engineering using microcapillary arrays. Nat. Chem. Biol. 12, 76–81 (2016)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR36" id="ref-link-section-d8717801e1398">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Zhang, Y. et al. Accurate high-throughput screening based on digital protein synthesis in a massively parallel femtoliter droplet array. Sci. Adv. 5, eaav8185 (2019)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR37" id="ref-link-section-d8717801e1401">37</a></sup>, as well as microfluidic setups<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Antkowiak, P. L. et al. Integrating DNA encapsulates and digital microfluidics for automated data storage in DNA. Small 18, 2107381 (2022)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR38" id="ref-link-section-d8717801e1405">38</a></sup>. The robustness of PCR amplification in retrieving information from a complex pool of oligonucleotides has been demonstrated earlier, and indicates that there is still significant potential capacity for data storage. Implementation of various PCR or DNA assembly methods that do not require thermocycling for appending well-codes and indexing barcodes can also increase the throughput of the process while reducing the footprint and complexity of the workflow<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Lin, K. N., Volkel, K., Tuck, J. M. &amp; Keung, A. J. Dynamic and scalable DNA-based information storage. Nat. Commun. 11, 2981 (2020)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR39" id="ref-link-section-d8717801e1409">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Banal, J. L. et al. Random access DNA memory using Boolean search in an archival file storage system. Nat. Mater. 1–9. 
                  https://doi.org/10.1038/s41563-021-01021-3
                  
                 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR40" id="ref-link-section-d8717801e1412">40</a></sup>. Advances in barcode multiplexing methods, as well as metadata tagging, can potentially lead to a searchable image database, as proposed by previous groups<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Banal, J. L. et al. Random access DNA memory using Boolean search in an archival file storage system. Nat. Mater. 1–9. 
                  https://doi.org/10.1038/s41563-021-01021-3
                  
                 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR40" id="ref-link-section-d8717801e1416">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Bee, C. et al. Molecular-level similarity search brings computing to DNA data storage. Nat. Commun. 12, 4764 (2021)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR41" id="ref-link-section-d8717801e1419">41</a></sup>.</p><p>While we utilize light-responsive recombinases in our workflow as the main interface between light and DNA recording, it is by no means the only DNA writing system that can be used. Other advances in DNA writing and editing tools can also serve to act as the intermediary for the conversion of light to information stored in DNA, and possess further advantages such as increased orthogonality. This could lead to an increase in density and the expansion in the types of images that can be stored.</p><p>As the field of DNA data storage continues to progress, there is an increasing interest in bridging the interface between biological and digital systems. Our work showcases further applications of DNA data storage that recreate existing information capture devices in a biological form, providing the basis for continued innovation in information recording and storage.</p></div></div><div id="Sec10-section" data-title="Methods"><h2 id="Sec10">Methods</h2><div id="Sec10-content"><h3 id="Sec11">Capturing of blue light patterns into DNA</h3><p>Two plasmids, pBbAW4k-loxP-TT-loxP-mRFP1 (pLoxP) and pBbE5a-Opto-Cre-Vvd-2 (pOptoCre) were used. pBbAW4k-loxP-TT-loxP-mRFP1 was a gift from Mary Dunlop (Addgene plasmid # 134405; <a href="http://n2t.net/addgene:134405">http://n2t.net/addgene:134405</a>; RRID:Addgene_134405) and pBbS5a-Opto-Cre-Vvd-2 was a gift from Mary Dunlop (Addgene plasmid # 160400; <a href="http://n2t.net/addgene:160400">http://n2t.net/addgene:160400</a>; RRID:Addgene_160400). These plasmids were transformed together into XL1-Blue <i>E.&nbsp; coli</i> chemically competent cells. pLoxP contains two LoxP sites within the plasmid in the same orientation, with an intervening sequence containing 2 terminator sequences. pOptoCre contains a genetic circuit that utilizes the Lac promoter to control production of the Opto-Cre-Vvd-2 construct. The transformed strain was inoculated into a culture tube with 5 ml of LB medium supplemented with 100 mg/ml of ampicillin and 50 mg/ml of kanamycin and grown overnight in a shaking incubator at 37 °C, aerobically. The culture was diluted 1:100 into a fresh culture tube with 10 ml of LB medium supplemented with 100 mg/ml of ampicillin and 50 mg/ml of kanamycin and induced with 0.1 µM of IPTG for 2 h in a 37 °C shaking incubator. Eighty microliters of refreshed and induced cells were aliquoted into each well of a 96-well, black and flat clear-bottomed plate. A light pattern was created by selectively blocking out the bottoms of wells with aluminum foil, and the plate was exposed to light from the bottom with a blue LED light pane (HQRP). The plate was incubated atop the device overnight at room temperature to ensure sufficient exposure to light. However, this duration can be shortened to 30 min if necessary as demonstrated in Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S4</a>.</p><h3 id="Sec12">Barcoding of DNA and library prep for illumina sequencing</h3><p>Ninety-six different PCR reactions were set up. Each reaction well contains 0.5 µl of a specific known well-code at a concentration of 10 µM that is mapped to the <i>X</i>–<i>Y</i> coordinates of that well. The unique barcoding sequences were generated computationally using the ‘DNABarcodes’ R package in Bioconductor (version 1.28.0)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Buschmann, T. &amp; Bystrykh, L. V. Levenshtein error-correcting barcodes for multiplexed DNA sequencing. BMC Bioinforma. 14, 272 (2013)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR42" id="ref-link-section-d8717801e1476">42</a></sup>. One microliter of cells from each well of the 96-well plate was then used for the PCR reactions. PCRs were performed using Taq DNA polymerase (NEB) with each reaction containing 2 µl of 10X ThermoPol buffer (NEB), 0.1 µl of 100 µM of each forward and reverse primer pair (IDT), 0.2 µl of Taq DNA polymerase (NEB), 0.2 µl of 20 mM dNTP mix (BioBasic), 1 µl of cells, and topped up with ddH<sub>2</sub>O for a total reaction volume of 20 µl. Individual reactions were run on 1.2% agarose gels for product verification. Appending of adapter ends for sequencing was also done using PCR, with 0.2 µl of each barcoded mix from the previous reaction added into a reaction containing 0.2 µl Taq DNA polymerase (NEB), 2 µl of 10X ThermoPol buffer (NEB), 0.1 µl each of 100 µM inner sequencing index primers (IDT), 0.3 µl of 100 µM outer sequencing index primers (IDT), 0.2 µl of 20 mM dNTP mix (BioBasic), and topped up with ddH<sub>2</sub>O to a total volume of 20 µl for each reaction. Products were subsequently verified on agarose gel before aliquoting 10 µl from each reaction and pooled together into a single tube. Two hundred microliters of this mixed pool was sent for NovaSeq dual index paired-end sequencing with an external sequencing service provider (NovogeneAIT).</p><h3 id="Sec13">Deconvolution of raw reads into images</h3><p>The resulting raw data generated was deconvoluted with appropriate index sequences and separated accordingly by the external sequencing provider. Subsequent analysis of the data was done using an in-house R script (code provided in the Supplementary&nbsp;Software file) (R version 4.2.2<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="R Core Team. R: the R project for statistical computing. 
                  https://www.r-project.org/
                  
                 (2022)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR43" id="ref-link-section-d8717801e1492">43</a></sup>, Bioconductor version 3.16<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Huber, W. et al. Orchestrating high-throughput genomic analysis with Bioconductor. Nat. Methods 12, 115–121 (2015)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR44" id="ref-link-section-d8717801e1496">44</a></sup>, Biostrings version 2.66.0<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Pagès, H., Aboyoun, P., Gentleman, R. &amp; DebRoy, S. Biostrings: efficient manipulation of biological strings. 
                  https://doi.org/10.18129/B9.bioc.Biostrings
                  
                 (2023)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR45" id="ref-link-section-d8717801e1500">45</a></sup>, ShortRead version 1.56.1<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Morgan, M. et al. ShortRead: a bioconductor package for input, quality assessment and exploration of high-throughput sequence data. Bioinformatics 25, 2607–2608 (2009)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR46" id="ref-link-section-d8717801e1504">46</a></sup> and stringr version 1.5.0<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Wickham, H. stringr: Simple, Consistent Wrappers for Common String Operations. 
                  https://stringr.tidyverse.org
                  
                , 
                  https://github.com/tidyverse/stringr
                  
                 (2022)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR47" id="ref-link-section-d8717801e1508">47</a></sup> packages). Briefly, the script derived the total number of reads, the number of reads with excised intervening LoxP sequences, and number of reads with full LoxP sequences, that were linked to each unique well-code. To determine whether that unique barcoded population was exposed to light or not, the ratio of truncated to full reads was determined. This ratio is calculated for each well in the entire plate, and serves to define the bit state of the well. A higher ratio indicates a larger proportion of truncated reads, which implies that a large number of the population of cells that were barcoded was exposed to light and vice versa. To reconstruct the images, each the aforementioned ratio was converted to either 1 or 0, with the threshold between both determined with GMM clustering to define the two clusters and the threshold set via the boundary between the two clusters with the lowest variance score. This is then linked back to the well-code, which was then mapped to its predefined spatial location, thus creating an image with a pixel depth of 1 bit and a resolution of 96 pixels. Accuracy of the final image was defined as the number of wells that were appropriately demarcated as 1 or 0 as compared to the original projected pattern. Differentiating between two colors of light was done by calculating ratios of sequences specific to the blue light recording plasmid as well as the red light recording plasmid separately from one another.</p><h3 id="Sec14">Random access of images</h3><p>Primers specifically designed for random access with index sequences targeted at selected indexes were synthesized and used to enable random access. Eight PCR reactions with the same conditions were set up to generate sufficient DNA for sequencing. 1&nbsp;µl of template from the mixed pool was used for each reaction totaling 50 µl, and a touchdown PCR with decreasing annealing temperatures from 65 to 55 °C for eight cycles and constant annealing temperatures for 20 cycles was conducted, using specific random access primers that bind to desired image to be amplified. Resulting samples were appended with Illumina adapter sequences and sent for sequencing. Diluting experiments were conducted by taking 1 µl of template from&nbsp;the mixed pool and diluting in 9, 99, and 999 µl of PBS before taking 1 µl from each dilution for PCR as per the above protocol. N701 and N501 indexing primers selective for the ‘NUS’ pattern were used for this particular random access dilution.</p><h3 id="Sec15">Environmental challenge experiments</h3><p>A pool of DNA containing the ‘Smiley’ pattern was used for drying and resuspension experiments. Twenty microliters of the pool was spun dry using a centrifuge, and subsequently resuspended in 50 µl ddH<sub>2</sub>O before being submitted for sequencing.</p><p>For environmental challenge experiments, 200 µl of the ‘Heloo wo{|d!’ pool was kept in varying conditions in a cryotube, wrapped in aluminum foil. Conditions included frozen in −20 °C, at room temperature, and in a 60 °C oven, all for 7 days. One last sample was kept in a 1.5 ml Eppendorf tube which was then exposed to UV light for 1 hour. Samples were then sent for sequencing.</p><h3 id="Sec16">Dilution experiments</h3><p>Two forms of dilution experiments were conducted. One involved diluting a pool of DNA containing the ‘Smiley’ pattern 3 consecutive times, at a 10 times dilution each, with each dilution being sent for sequencing. The other involved diluting a mixed pool of DNA with multiple samples 3 consecutive times, with each dilution being a 10 times dilution&nbsp;as described above. Random access was then conducted on each dilution as detailed above before sending the amplified products for sequencing.</p><h3 id="Sec17">Clustering of deconvoluted images</h3><p>The clustering workflow was developed and implemented in Python 3<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="The Python Language Reference. Python documentation. 
                  https://docs.python.org/3/reference/index.html
                  
                ." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR48" id="ref-link-section-d8717801e1550">48</a></sup> (version 3.11.1) (code provided in the Supplementary Software file). Four unsupervised clustering techniques (K-means algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Arthur, D. &amp; Vassilvitskii, S. k-means++: the advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms 1027–1035 (Society for Industrial and Applied Mathematics, 2007)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR49" id="ref-link-section-d8717801e1554">49</a></sup>, DBSCAN<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Schubert, E., Sander, J., Ester, M., Kriegel, H. P. &amp; Xu, X. DBSCAN revisited, revisited: why and how you should (Still) use DBSCAN. ACM Trans. Database Syst. 42, 1–21 (2017)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR50" id="ref-link-section-d8717801e1558">50</a></sup>, OPTICS<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Ankerst, M., Breunig, M. M., Kriegel, H.-P. &amp; Sander, J. OPTICS: ordering points to identify the clustering structure. ACM SIGMOD Rec. 28, 49–60 (1999)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR51" id="ref-link-section-d8717801e1562">51</a></sup>, and Gaussian Mixture Model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Yang, M.-S., Lai, C.-Y. &amp; Lin, C.-Y. A robust EM clustering algorithm for Gaussian mixture models. Pattern Recognit. 45, 3950–3961 (2012)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR52" id="ref-link-section-d8717801e1566">52</a></sup>) were adopted from scikit-learn (version 1.2.0) machine learning packages under cluster and mixture modules<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Pedregosa, F. et al. Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR53" id="ref-link-section-d8717801e1571">53</a></sup>. The unsupervised outlier detection algorithm was implemented using Local Outlier Factor (LOF) from scikit-learn neighbors module. The parameter ‘n_neighbors’ (blue light = 20; red light = 10) was tuned accordingly to improve the deconvolution accuracy through better reassignment of outliers near to the cutoff threshold for better clustering performance (Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S6</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S7</a>). The cutoff threshold for the full ‘ON’ and ‘OFF’ was determined from the means computed from clusters from all existing datasets. The dataset would be classified as full ‘ON’ or ‘OFF’ when the lowest mean of clusters is above the cutoff threshold, or the highest mean is below the cutoff threshold. To generate the final binary ‘0’ or ‘1’ images, cluster grouping was executed for clustering techniques that identified more than 2 clusters to group them into two clusters designated as ‘ON’ and ‘OFF’ states. For the blue light patterns, the second and higher mean clusters were grouped into a single ‘ON’ cluster whereas the initial cluster with the lowest mean would be considered as ‘OFF’ states. Meanwhile, for the red light patterns, the two clusters with the lower mean were considered as a single ‘OFF’ cluster instead whereas the rest of the clusters would be considered as ‘ON’ states due to differences in the distribution of the raw data.</p><h3 id="Sec18">Development of the red light bacterial recombinase system</h3><p>Two plasmids were designed for the red light bacterial recombinase system. pBbS5a-RLCre, a red light sensitive split Cre-recombinase based off the L-SCRaMbLE system previously developed in yeast<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Hochrein, L., Mitchell, L. A., Schulz, K., Messerschmidt, K. &amp; Mueller-Roeber, B. L-SCRaMbLE as a tool for light-controlled Cre-mediated recombination in yeast. Nat. Commun. 9, 1931 (2018)." href="https://www.nature.com/articles/s41467-023-38876-w#ref-CR35" id="ref-link-section-d8717801e1589">35</a></sup> was designed, codon-optimized for <i>E. coli</i> and synthesized (Twist Bioscience). pBbAW4k-Spacer1Barcoding-loxP-TT-loxP-ho1-pcyA, a recording plasmid, was also designed, consisting of LoxP recognition sites, a unique preceding barcode (Spacer1Barcoding), as well a ho1-pcyA component that produces phycocyanobilin necessary for the function of the red light split recombinase. Both plasmids were transformed simultaneously into XL1 Blue <i>E. coli</i> chemically competent cells.</p><h3 id="Sec19">Design and construction of a custom light illumination device (OptoBox)</h3><p>To test the co-culture of red and blue light-responsive <i>E. coli</i> under various blue and red light patterns, a 96-well programmable LED device was developed (design illustrated in Supplementary&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">S8</a>). This device is powered and controlled by an Arduino Uno Microcontroller and includes 8 strips of 12 Adafruit Neopixel SMD 5050 RGB LEDs totalling 96 individual LEDs. Each of these LEDs corresponds to each well of the 96-well plate. The overall construction of the device comprises a 96-tip pipette tip container. These pipette tip containers comprise two separable layers stacked on top of one another. This setup allows the LED strips to be immobilized between the layers. The wells of the pipette tip container also prevent residual light spillover from the LEDs, resulting in spatial isolation when coupled with a clear-bottomed black 96-well plate.</p><p>For our application, these hollow tip-holes are used to fit and secure the SMD 5050 LEDs in place by fitting the LED chips into the underside of each of these corresponding holes. This allows each individual LED to be held in place through a friction fit, with the diodes that make up the SMD 5050 LED centered to the wells of the 96-well plate. The LED strips were soldered to wires supplying power and electrical control. Each strip’s data-wire was connected to an individual Arduino Uno data pin, allowing individual control of each LED. Programming of the LEDs was done using the available FastLED Arduino library.</p><h3 id="Sec20">Capture of multicolor images with a co-culture</h3><p>Strains containing the red light and blue light recombinase systems were inoculated separately into culture tubes with 5 ml of LB medium supplemented with 100 mg/ml of ampicillin and 50 mg/ml of kanamycin and grown overnight in a shaking incubator at 37 °C, aerobically. These cultures were diluted 1:100 into fresh culture tubes with 10 ml of LB medium supplemented with 100 mg/ml of ampicillin and 50 mg/ml of kanamycin and induced with 0.1 µM of IPTG for 2 h in a 37 °C shaking incubator. 40&nbsp;µl of each culture were aliquoted into each well of a 96-well, black and flat clear-bottomed plate. A red (620 nm) and a blue (465 nm) light pattern was created by the in-house custom-built light illumination device (OptoBox), and either projected periodically for 10 min in an alternating fashion overnight, or projected simultaneously overnight, both from the bottom of the plate and at equal intensities. Barcoding, sequencing and deconvolution follows the same procedure as detailed in the preceding sections.</p><h3 id="Sec21">Statistics and reproducibility</h3><p>No statistical method was used to predetermine sample size. No data were excluded from the analyses. The experiments were not randomized. The Investigators were not blinded to allocation during experiments and outcome assessment.</p><h3 id="Sec22">Reporting summary</h3><p>Further information on research design is available in the&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM2">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div>
                </div><div>
            <div id="data-availability-section" data-title="Data availability"><h2 id="data-availability">Data availability</h2><p>The sequencing data generated in this study have been deposited in a Figshare repository at: <a href="https://doi.org/10.6084/m9.figshare.22678534">https://doi.org/10.6084/m9.figshare.22678534</a>. The same data have also been deposited in the NCBI Sequence Read Archive under the PRJNA970212 BioProject at <a href="https://www.ncbi.nlm.nih.gov/bioproject/PRJNA970212">https://www.ncbi.nlm.nih.gov/bioproject/PRJNA970212</a>, with the individual accession numbers available in the supplementary file under Supplementary Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM1">2</a>. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41467-023-38876-w#Sec24">Source data</a> are provided with this paper. Barcodes and primers used in this work are detailed in the Source Data file.</p></div><div id="code-availability-section" data-title="Code availability"><h2 id="code-availability">Code availability</h2><p>The code used for deconvolution of reads as well as clustering is available in the&nbsp;<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41467-023-38876-w#MOESM5">Supplementary Software</a> file.</p></div><div id="MagazineFulltextArticleBodySuffix" aria-labelledby="Bib1" data-title="References"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Church, G. M., Gao, Y. &amp; Kosuri, S. Next-generation digital information storage in DNA. <i>Science</i> <b>337</b>, 1628–1628 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1226355" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1226355" aria-label="Article reference 1" data-doi="10.1126/science.1226355">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012Sci...337.1628C" aria-label="ADS reference 1">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38Xhtl2ntrrL" aria-label="CAS reference 1">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22903519" aria-label="PubMed reference 1">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Next-generation%20digital%20information%20storage%20in%20DNA&amp;journal=Science&amp;doi=10.1126%2Fscience.1226355&amp;volume=337&amp;pages=1628-1628&amp;publication_year=2012&amp;author=Church%2CGM&amp;author=Gao%2CY&amp;author=Kosuri%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Goldman, N. et al. Towards practical, high-capacity, low-maintenance information storage in synthesized DNA. <i>Nature</i> <b>494</b>, 77–80 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature11875" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature11875" aria-label="Article reference 2" data-doi="10.1038/nature11875">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2013Natur.494...77G" aria-label="ADS reference 2">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXhsVygsLg%3D" aria-label="CAS reference 2">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23354052" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3672958" aria-label="PubMed Central reference 2">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20practical%2C%20high-capacity%2C%20low-maintenance%20information%20storage%20in%20synthesized%20DNA&amp;journal=Nature&amp;doi=10.1038%2Fnature11875&amp;volume=494&amp;pages=77-80&amp;publication_year=2013&amp;author=Goldman%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Zhirnov, V., Zadegan, R. M., Sandhu, G. S., Church, G. M. &amp; Hughes, W. L. Nucleic acid memory. <i>Nat. Mater.</i> <b>15</b>, 366–370 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nmat4594" data-track-action="article reference" href="https://doi.org/10.1038%2Fnmat4594" aria-label="Article reference 3" data-doi="10.1038/nmat4594">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016NatMa..15..366Z" aria-label="ADS reference 3">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XkvVCitb0%3D" aria-label="CAS reference 3">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27005909" aria-label="PubMed reference 3">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6361517" aria-label="PubMed Central reference 3">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Nucleic%20acid%20memory&amp;journal=Nat.%20Mater.&amp;doi=10.1038%2Fnmat4594&amp;volume=15&amp;pages=366-370&amp;publication_year=2016&amp;author=Zhirnov%2CV&amp;author=Zadegan%2CRM&amp;author=Sandhu%2CGS&amp;author=Church%2CGM&amp;author=Hughes%2CWL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="4."><p id="ref-CR4">van der Valk, T. et al. Million-year-old DNA sheds light on the genomic history of mammoths. <i>Nature</i>, 1–5. <a href="https://doi.org/10.1038/s41586-021-03224-9">https://doi.org/10.1038/s41586-021-03224-9</a> (2021).</p></li><li data-counter="5."><p id="ref-CR5">Lim, C. K., Nirantar, S., Yew, W. S. &amp; Poh, C. L. Novel Modalities in DNA Data Storage. <i>Trends Biotechnol</i>. <b>39</b>, 990–1003 (2021).</p></li><li data-counter="6."><p id="ref-CR6">Tabatabaei, S. K. et al. DNA punch cards for storing data on native DNA sequences via enzymatic nicking. <i>Nat. Commun.</i> <b>11</b>, 1–10 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-020-15588-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-020-15588-z" aria-label="Article reference 6" data-doi="10.1038/s41467-020-15588-z">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=DNA%20punch%20cards%20for%20storing%20data%20on%20native%20DNA%20sequences%20via%20enzymatic%20nicking&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-020-15588-z&amp;volume=11&amp;pages=1-10&amp;publication_year=2020&amp;author=Tabatabaei%2CSK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="7."><p id="ref-CR7">Chen, K., Zhu, J., Bošković, F. &amp; Keyser, U. F. Nanopore-based DNA hard drives for rewritable and secure data storage. <i>Nano Lett</i>. <a href="https://doi.org/10.1021/acs.nanolett.0c00755">https://doi.org/10.1021/acs.nanolett.0c00755</a> (2020).</p></li><li data-counter="8."><p id="ref-CR8">Tomek, K. J. et al. Driving the scalability of DNA-based information storage systems. <i>ACS Synth. Biol.</i> <b>8</b>, 1241–1248 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1021/acssynbio.9b00100" data-track-action="article reference" href="https://doi.org/10.1021%2Facssynbio.9b00100" aria-label="Article reference 8" data-doi="10.1021/acssynbio.9b00100">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXpvVCmur4%3D" aria-label="CAS reference 8">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31117362" aria-label="PubMed reference 8">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Driving%20the%20scalability%20of%20DNA-based%20information%20storage%20systems&amp;journal=ACS%20Synth.%20Biol.&amp;doi=10.1021%2Facssynbio.9b00100&amp;volume=8&amp;pages=1241-1248&amp;publication_year=2019&amp;author=Tomek%2CKJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="9."><p id="ref-CR9">Yim, S. S. et al. Robust direct digital-to-biological data storage in living cells. <i>Nat. Chem. Biol.</i> <b>17</b>, 1–8 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41589-020-00711-4" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41589-020-00711-4" aria-label="Article reference 9" data-doi="10.1038/s41589-020-00711-4">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20direct%20digital-to-biological%20data%20storage%20in%20living%20cells&amp;journal=Nat.%20Chem.%20Biol.&amp;doi=10.1038%2Fs41589-020-00711-4&amp;volume=17&amp;pages=1-8&amp;publication_year=2021&amp;author=Yim%2CSS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="10."><p id="ref-CR10">Ceze, L., Nivala, J. &amp; Strauss, K. Molecular digital data storage using DNA. <i>Nat. Rev. Genet.</i> <b>20</b>, 456–466 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41576-019-0125-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41576-019-0125-3" aria-label="Article reference 10" data-doi="10.1038/s41576-019-0125-3">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXptFeqsrs%3D" aria-label="CAS reference 10">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31068682" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular%20digital%20data%20storage%20using%20DNA&amp;journal=Nat.%20Rev.%20Genet.&amp;doi=10.1038%2Fs41576-019-0125-3&amp;volume=20&amp;pages=456-466&amp;publication_year=2019&amp;author=Ceze%2CL&amp;author=Nivala%2CJ&amp;author=Strauss%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Lee, H. H., Kalhor, R., Goela, N., Bolot, J. &amp; Church, G. M. Terminator-free template-independent enzymatic DNA synthesis for digital information storage. <i>Nat. Commun.</i> <b>10</b>, 1–12 (2019).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Terminator-free%20template-independent%20enzymatic%20DNA%20synthesis%20for%20digital%20information%20storage&amp;journal=Nat.%20Commun.&amp;volume=10&amp;pages=1-12&amp;publication_year=2019&amp;author=Lee%2CHH&amp;author=Kalhor%2CR&amp;author=Goela%2CN&amp;author=Bolot%2CJ&amp;author=Church%2CGM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Takahashi, C. N., Nguyen, B. H., Strauss, K. &amp; Ceze, L. Demonstration of end-to-end automation of DNA Data Storage. <i>Sci. Rep.</i> <b>9</b>, 1–5 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41598-019-41228-8" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-019-41228-8" aria-label="Article reference 12" data-doi="10.1038/s41598-019-41228-8">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Demonstration%20of%20end-to-end%20automation%20of%20DNA%20Data%20Storage&amp;journal=Sci.%20Rep.&amp;doi=10.1038%2Fs41598-019-41228-8&amp;volume=9&amp;pages=1-5&amp;publication_year=2019&amp;author=Takahashi%2CCN&amp;author=Nguyen%2CBH&amp;author=Strauss%2CK&amp;author=Ceze%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="13."><p id="ref-CR13">Palluk, S. et al. De novo DNA synthesis using polymerase-nucleotide conjugates. <i>Nat. Biotechnol.</i> <b>36</b>, 645–650 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nbt.4173" data-track-action="article reference" href="https://doi.org/10.1038%2Fnbt.4173" aria-label="Article reference 13" data-doi="10.1038/nbt.4173">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhtFGjs7%2FI" aria-label="CAS reference 13">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29912208" aria-label="PubMed reference 13">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=De%20novo%20DNA%20synthesis%20using%20polymerase-nucleotide%20conjugates&amp;journal=Nat.%20Biotechnol.&amp;doi=10.1038%2Fnbt.4173&amp;volume=36&amp;pages=645-650&amp;publication_year=2018&amp;author=Palluk%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="14."><p id="ref-CR14">Lu, X. et al. Enzymatic DNA synthesis by engineering terminal deoxynucleotidyl transferase. <i>ACS Catal</i>. 2988–2997. <a href="https://doi.org/10.1021/acscatal.1c04879">https://doi.org/10.1021/acscatal.1c04879</a> (2022).</p></li><li data-counter="15."><p id="ref-CR15">Xu, C. et al. Electrochemical DNA synthesis and sequencing on a single electrode with scalability for integrated data storage. <i>Sci. Adv.</i> <b>7</b>, eabk0100 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/sciadv.abk0100" data-track-action="article reference" href="https://doi.org/10.1126%2Fsciadv.abk0100" aria-label="Article reference 15" data-doi="10.1126/sciadv.abk0100">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021SciA....7..100X" aria-label="ADS reference 15">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXis1Ghsb3E" aria-label="CAS reference 15">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34767438" aria-label="PubMed reference 15">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589306" aria-label="PubMed Central reference 15">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrochemical%20DNA%20synthesis%20and%20sequencing%20on%20a%20single%20electrode%20with%20scalability%20for%20integrated%20data%20storage&amp;journal=Sci.%20Adv.&amp;doi=10.1126%2Fsciadv.abk0100&amp;volume=7&amp;publication_year=2021&amp;author=Xu%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="16."><p id="ref-CR16">Nguyen, B. H. et al. Scaling DNA data storage with nanoscale electrode wells. <i>Sci. Adv.</i> <b>7</b>, eabi6714 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/sciadv.abi6714" data-track-action="article reference" href="https://doi.org/10.1126%2Fsciadv.abi6714" aria-label="Article reference 16" data-doi="10.1126/sciadv.abi6714">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021SciA....7.6714N" aria-label="ADS reference 16">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXislCntLrK" aria-label="CAS reference 16">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34818035" aria-label="PubMed reference 16">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8612674" aria-label="PubMed Central reference 16">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Scaling%20DNA%20data%20storage%20with%20nanoscale%20electrode%20wells&amp;journal=Sci.%20Adv.&amp;doi=10.1126%2Fsciadv.abi6714&amp;volume=7&amp;publication_year=2021&amp;author=Nguyen%2CBH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="17."><p id="ref-CR17">Antkowiak, P. L. et al. Low cost DNA data storage using photolithographic synthesis and advanced information reconstruction and error correction. <i>Nat. Commun.</i> <b>11</b>, 5345 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-020-19148-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-020-19148-3" aria-label="Article reference 17" data-doi="10.1038/s41467-020-19148-3">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020NatCo..11.5345A" aria-label="ADS reference 17">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXitF2js7rI" aria-label="CAS reference 17">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33093494" aria-label="PubMed reference 17">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7582880" aria-label="PubMed Central reference 17">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Low%20cost%20DNA%20data%20storage%20using%20photolithographic%20synthesis%20and%20advanced%20information%20reconstruction%20and%20error%20correction&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-020-19148-3&amp;volume=11&amp;publication_year=2020&amp;author=Antkowiak%2CPL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="18."><p id="ref-CR18">Erlich, Y. &amp; Zielinski, D. DNA Fountain enables a robust and efficient storage architecture. <i>Science</i> <b>355</b>, 950–954 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aaj2038" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aaj2038" aria-label="Article reference 18" data-doi="10.1126/science.aaj2038">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017Sci...355..950E" aria-label="ADS reference 18">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXjsVCgsrc%3D" aria-label="CAS reference 18">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28254941" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=DNA%20Fountain%20enables%20a%20robust%20and%20efficient%20storage%20architecture&amp;journal=Science&amp;doi=10.1126%2Fscience.aaj2038&amp;volume=355&amp;pages=950-954&amp;publication_year=2017&amp;author=Erlich%2CY&amp;author=Zielinski%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Wang, Y. et al. High capacity DNA data storage with variable-length Oligonucleotides using repeat accumulate code and hybrid mapping. <i>J. Biol. Eng.</i> <b>13</b>, 89 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1186/s13036-019-0211-2" data-track-action="article reference" href="https://doi.org/10.1186%2Fs13036-019-0211-2" aria-label="Article reference 19" data-doi="10.1186/s13036-019-0211-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31832092" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6868767" aria-label="PubMed Central reference 19">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=High%20capacity%20DNA%20data%20storage%20with%20variable-length%20Oligonucleotides%20using%20repeat%20accumulate%20code%20and%20hybrid%20mapping&amp;journal=J.%20Biol.%20Eng.&amp;doi=10.1186%2Fs13036-019-0211-2&amp;volume=13&amp;publication_year=2019&amp;author=Wang%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Anavy, L., Vaknin, I., Atar, O., Amit, R. &amp; Yakhini, Z. Data storage in DNA with fewer synthesis cycles using composite DNA letters. <i>Nat. Biotechnol.</i> <b>37</b>, 1229–1236 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41587-019-0240-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41587-019-0240-x" aria-label="Article reference 20" data-doi="10.1038/s41587-019-0240-x">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXhsleltLvL" aria-label="CAS reference 20">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31501560" aria-label="PubMed reference 20">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Data%20storage%20in%20DNA%20with%20fewer%20synthesis%20cycles%20using%20composite%20DNA%20letters&amp;journal=Nat.%20Biotechnol.&amp;doi=10.1038%2Fs41587-019-0240-x&amp;volume=37&amp;pages=1229-1236&amp;publication_year=2019&amp;author=Anavy%2CL&amp;author=Vaknin%2CI&amp;author=Atar%2CO&amp;author=Amit%2CR&amp;author=Yakhini%2CZ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="21."><p id="ref-CR21">Sheets, M. B., Wong, W. W. &amp; Dunlop, M. J. Light-inducible recombinases for bacterial optogenetics. <i>ACS Synth. Biol.</i> <b>9</b>, 227–235 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1021/acssynbio.9b00395" data-track-action="article reference" href="https://doi.org/10.1021%2Facssynbio.9b00395" aria-label="Article reference 21" data-doi="10.1021/acssynbio.9b00395">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXht1Wiu74%3D" aria-label="CAS reference 21">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31961670" aria-label="PubMed reference 21">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393974" aria-label="PubMed Central reference 21">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Light-inducible%20recombinases%20for%20bacterial%20optogenetics&amp;journal=ACS%20Synth.%20Biol.&amp;doi=10.1021%2Facssynbio.9b00395&amp;volume=9&amp;pages=227-235&amp;publication_year=2020&amp;author=Sheets%2CMB&amp;author=Wong%2CWW&amp;author=Dunlop%2CMJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="22."><p id="ref-CR22">Yang, L. et al. Permanent genetic memory with &gt;1-byte capacity. <i>Nat. Methods</i> <b>11</b>, 1261–1266 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nmeth.3147" data-track-action="article reference" href="https://doi.org/10.1038%2Fnmeth.3147" aria-label="Article reference 22" data-doi="10.1038/nmeth.3147">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvVSqsbnE" aria-label="CAS reference 22">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25344638" aria-label="PubMed reference 22">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4245323" aria-label="PubMed Central reference 22">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Permanent%20genetic%20memory%20with%20%3E1-byte%20capacity&amp;journal=Nat.%20Methods&amp;doi=10.1038%2Fnmeth.3147&amp;volume=11&amp;pages=1261-1266&amp;publication_year=2014&amp;author=Yang%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="23."><p id="ref-CR23">Bonnet, J., Subsoontorn, P. &amp; Endy, D. Rewritable digital data storage in live cells via engineered control of recombination directionality. <i>Proc. Natl Acad. Sci. USA</i> <b>109</b>, 8884–8889 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1202344109" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1202344109" aria-label="Article reference 23" data-doi="10.1073/pnas.1202344109">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012PNAS..109.8884B" aria-label="ADS reference 23">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XovF2gt70%3D" aria-label="CAS reference 23">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22615351" aria-label="PubMed reference 23">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384180" aria-label="PubMed Central reference 23">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Rewritable%20digital%20data%20storage%20in%20live%20cells%20via%20engineered%20control%20of%20recombination%20directionality&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1202344109&amp;volume=109&amp;pages=8884-8889&amp;publication_year=2012&amp;author=Bonnet%2CJ&amp;author=Subsoontorn%2CP&amp;author=Endy%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. Molecular recordings by directed CRISPR spacer acquisition. <i>Science</i> <b>353</b>, aaf1175 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aaf1175" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aaf1175" aria-label="Article reference 24" data-doi="10.1126/science.aaf1175">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27284167" aria-label="PubMed reference 24">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4994893" aria-label="PubMed Central reference 24">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular%20recordings%20by%20directed%20CRISPR%20spacer%20acquisition&amp;journal=Science&amp;doi=10.1126%2Fscience.aaf1175&amp;volume=353&amp;publication_year=2016&amp;author=Shipman%2CSL&amp;author=Nivala%2CJ&amp;author=Macklis%2CJD&amp;author=Church%2CGM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="25."><p id="ref-CR25">Shipman, S. L., Nivala, J., Macklis, J. D. &amp; Church, G. M. CRISPR–Cas encoding of a digital movie into the genomes of a population of living bacteria. <i>Nature</i> <b>547</b>, 345–349 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature23017" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature23017" aria-label="Article reference 25" data-doi="10.1038/nature23017">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017Natur.547..345S" aria-label="ADS reference 25">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXhtFOjtrfN" aria-label="CAS reference 25">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28700573" aria-label="PubMed reference 25">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5842791" aria-label="PubMed Central reference 25">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=CRISPR%E2%80%93Cas%20encoding%20of%20a%20digital%20movie%20into%20the%20genomes%20of%20a%20population%20of%20living%20bacteria&amp;journal=Nature&amp;doi=10.1038%2Fnature23017&amp;volume=547&amp;pages=345-349&amp;publication_year=2017&amp;author=Shipman%2CSL&amp;author=Nivala%2CJ&amp;author=Macklis%2CJD&amp;author=Church%2CGM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="26."><p id="ref-CR26">Tang, W. &amp; Liu, D. R. Rewritable multi-event analog recording in bacterial and mammalian cells. <i>Science</i> <b>360</b>, eaap8992 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aap8992" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aap8992" aria-label="Article reference 26" data-doi="10.1126/science.aap8992">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29449507" aria-label="PubMed reference 26">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5898985" aria-label="PubMed Central reference 26">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Rewritable%20multi-event%20analog%20recording%20in%20bacterial%20and%20mammalian%20cells&amp;journal=Science&amp;doi=10.1126%2Fscience.aap8992&amp;volume=360&amp;publication_year=2018&amp;author=Tang%2CW&amp;author=Liu%2CDR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="27."><p id="ref-CR27">Chen, K. et al. Digital data storage using DNA nanostructures and solid-state nanopores. <i>Nano Lett.</i> <b>19</b>, 1210–1215 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1021/acs.nanolett.8b04715" data-track-action="article reference" href="https://doi.org/10.1021%2Facs.nanolett.8b04715" aria-label="Article reference 27" data-doi="10.1021/acs.nanolett.8b04715">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2019NanoL..19.1210C" aria-label="ADS reference 27">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXisFyksrfO" aria-label="CAS reference 27">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30585490" aria-label="PubMed reference 27">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Digital%20data%20storage%20using%20DNA%20nanostructures%20and%20solid-state%20nanopores&amp;journal=Nano%20Lett.&amp;doi=10.1021%2Facs.nanolett.8b04715&amp;volume=19&amp;pages=1210-1215&amp;publication_year=2019&amp;author=Chen%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="28."><p id="ref-CR28">Fernandez-Rodriguez, J., Moser, F., Song, M. &amp; Voigt, C. A. Engineering RGB color vision into <i>Escherichia coli</i>. <i>Nat. Chem. Biol.</i> <b>13</b>, 706–708 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nchembio.2390" data-track-action="article reference" href="https://doi.org/10.1038%2Fnchembio.2390" aria-label="Article reference 28" data-doi="10.1038/nchembio.2390">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXotVOltL0%3D" aria-label="CAS reference 28">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28530708" aria-label="PubMed reference 28">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Engineering%20RGB%20color%20vision%20into%20Escherichia%20coli&amp;journal=Nat.%20Chem.%20Biol.&amp;doi=10.1038%2Fnchembio.2390&amp;volume=13&amp;pages=706-708&amp;publication_year=2017&amp;author=Fernandez-Rodriguez%2CJ&amp;author=Moser%2CF&amp;author=Song%2CM&amp;author=Voigt%2CCA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="29."><p id="ref-CR29">Jayaraman, P. et al. Blue light-mediated transcriptional activation and repression of gene expression in bacteria. <i>Nucleic Acids Res</i>. <b>44</b>, 6994–7005 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/nar/gkw548" data-track-action="article reference" href="https://doi.org/10.1093%2Fnar%2Fgkw548" aria-label="Article reference 29" data-doi="10.1093/nar/gkw548">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XhslWrsLzF" aria-label="CAS reference 29">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27353329" aria-label="PubMed reference 29">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001607" aria-label="PubMed Central reference 29">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Blue%20light-mediated%20transcriptional%20activation%20and%20repression%20of%20gene%20expression%20in%20bacteria&amp;journal=Nucleic%20Acids%20Res&amp;doi=10.1093%2Fnar%2Fgkw548&amp;volume=44&amp;pages=6994-7005&amp;publication_year=2016&amp;author=Jayaraman%2CP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="30."><p id="ref-CR30">Pouzet, S. et al. The promise of optogenetics for bioproduction: dynamic control strategies and scale-up instruments. <i>Bioengineering</i> <b>7</b>, 151 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/bioengineering7040151" data-track-action="article reference" href="https://doi.org/10.3390%2Fbioengineering7040151" aria-label="Article reference 30" data-doi="10.3390/bioengineering7040151">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXmsVSjsro%3D" aria-label="CAS reference 30">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33255280" aria-label="PubMed reference 30">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7712799" aria-label="PubMed Central reference 30">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20promise%20of%20optogenetics%20for%20bioproduction%3A%20dynamic%20control%20strategies%20and%20scale-up%20instruments&amp;journal=Bioengineering&amp;doi=10.3390%2Fbioengineering7040151&amp;volume=7&amp;publication_year=2020&amp;author=Pouzet%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="31."><p id="ref-CR31">Mansouri, M. &amp; Fussenegger, M. Synthetic biology-based optogenetic approaches to control therapeutic designer cells. <i>Curr. Opin. Syst. Biol.</i> <b>28</b>, 100396 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.coisb.2021.100396" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.coisb.2021.100396" aria-label="Article reference 31" data-doi="10.1016/j.coisb.2021.100396">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XhtlSmt7fN" aria-label="CAS reference 31">CAS</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Synthetic%20biology-based%20optogenetic%20approaches%20to%20control%20therapeutic%20designer%20cells&amp;journal=Curr.%20Opin.%20Syst.%20Biol.&amp;doi=10.1016%2Fj.coisb.2021.100396&amp;volume=28&amp;publication_year=2021&amp;author=Mansouri%2CM&amp;author=Fussenegger%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="32."><p id="ref-CR32">Korbie, D. J. &amp; Mattick, J. S. Touchdown PCR for increased specificity and sensitivity in PCR amplification. <i>Nat. Protoc.</i> <b>3</b>, 1452–1456 (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nprot.2008.133" data-track-action="article reference" href="https://doi.org/10.1038%2Fnprot.2008.133" aria-label="Article reference 32" data-doi="10.1038/nprot.2008.133">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXhtVOnsL7F" aria-label="CAS reference 32">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18772872" aria-label="PubMed reference 32">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Touchdown%20PCR%20for%20increased%20specificity%20and%20sensitivity%20in%20PCR%20amplification&amp;journal=Nat.%20Protoc.&amp;doi=10.1038%2Fnprot.2008.133&amp;volume=3&amp;pages=1452-1456&amp;publication_year=2008&amp;author=Korbie%2CDJ&amp;author=Mattick%2CJS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="33."><p id="ref-CR33">Grass, R. N., Heckel, R., Puddu, M., Paunescu, D. &amp; Stark, W. J. Robust chemical preservation of digital information on DNA in silica with error-correcting codes. <i>Angew. Chem. Int. Ed.</i> <b>54</b>, 2552–2555 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/anie.201411378" data-track-action="article reference" href="https://doi.org/10.1002%2Fanie.201411378" aria-label="Article reference 33" data-doi="10.1002/anie.201411378">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXis1Snsr8%3D" aria-label="CAS reference 33">CAS</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20chemical%20preservation%20of%20digital%20information%20on%20DNA%20in%20silica%20with%20error-correcting%20codes&amp;journal=Angew.%20Chem.%20Int.%20Ed.&amp;doi=10.1002%2Fanie.201411378&amp;volume=54&amp;pages=2552-2555&amp;publication_year=2015&amp;author=Grass%2CRN&amp;author=Heckel%2CR&amp;author=Puddu%2CM&amp;author=Paunescu%2CD&amp;author=Stark%2CWJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="34."><p id="ref-CR34">Breunig, M. M., Kriegel, H.-P., Ng, R. T. &amp; Sander, J. LOF: identifying density-based local outliers. <i>ACM SIGMOD Rec.</i> <b>29</b>, 93–104 (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1145/335191.335388" data-track-action="article reference" href="https://doi.org/10.1145%2F335191.335388" aria-label="Article reference 34" data-doi="10.1145/335191.335388">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=LOF%3A%20identifying%20density-based%20local%20outliers&amp;journal=ACM%20SIGMOD%20Rec.&amp;doi=10.1145%2F335191.335388&amp;volume=29&amp;pages=93-104&amp;publication_year=2000&amp;author=Breunig%2CMM&amp;author=Kriegel%2CH-P&amp;author=Ng%2CRT&amp;author=Sander%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="35."><p id="ref-CR35">Hochrein, L., Mitchell, L. A., Schulz, K., Messerschmidt, K. &amp; Mueller-Roeber, B. L-SCRaMbLE as a tool for light-controlled Cre-mediated recombination in yeast. <i>Nat. Commun.</i> <b>9</b>, 1931 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-017-02208-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-017-02208-6" aria-label="Article reference 35" data-doi="10.1038/s41467-017-02208-6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018NatCo...9.1931H" aria-label="ADS reference 35">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29789561" aria-label="PubMed reference 35">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5964156" aria-label="PubMed Central reference 35">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=L-SCRaMbLE%20as%20a%20tool%20for%20light-controlled%20Cre-mediated%20recombination%20in%20yeast&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-017-02208-6&amp;volume=9&amp;publication_year=2018&amp;author=Hochrein%2CL&amp;author=Mitchell%2CLA&amp;author=Schulz%2CK&amp;author=Messerschmidt%2CK&amp;author=Mueller-Roeber%2CB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="36."><p id="ref-CR36">Chen, B. et al. High-throughput analysis and protein engineering using microcapillary arrays. <i>Nat. Chem. Biol.</i> <b>12</b>, 76–81 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nchembio.1978" data-track-action="article reference" href="https://doi.org/10.1038%2Fnchembio.1978" aria-label="Article reference 36" data-doi="10.1038/nchembio.1978">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhvFemsbrL" aria-label="CAS reference 36">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26641932" aria-label="PubMed reference 36">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=High-throughput%20analysis%20and%20protein%20engineering%20using%20microcapillary%20arrays&amp;journal=Nat.%20Chem.%20Biol.&amp;doi=10.1038%2Fnchembio.1978&amp;volume=12&amp;pages=76-81&amp;publication_year=2016&amp;author=Chen%2CB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="37."><p id="ref-CR37">Zhang, Y. et al. Accurate high-throughput screening based on digital protein synthesis in a massively parallel femtoliter droplet array. <i>Sci. Adv.</i> <b>5</b>, eaav8185 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/sciadv.aav8185" data-track-action="article reference" href="https://doi.org/10.1126%2Fsciadv.aav8185" aria-label="Article reference 37" data-doi="10.1126/sciadv.aav8185">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2019SciA....5.8185Z" aria-label="ADS reference 37">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhtlars7%2FM" aria-label="CAS reference 37">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31457078" aria-label="PubMed reference 37">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6703874" aria-label="PubMed Central reference 37">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Accurate%20high-throughput%20screening%20based%20on%20digital%20protein%20synthesis%20in%20a%20massively%20parallel%20femtoliter%20droplet%20array&amp;journal=Sci.%20Adv.&amp;doi=10.1126%2Fsciadv.aav8185&amp;volume=5&amp;publication_year=2019&amp;author=Zhang%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="38."><p id="ref-CR38">Antkowiak, P. L. et al. Integrating DNA encapsulates and digital microfluidics for automated data storage in DNA. <i>Small</i> <b>18</b>, 2107381 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/smll.202107381" data-track-action="article reference" href="https://doi.org/10.1002%2Fsmll.202107381" aria-label="Article reference 38" data-doi="10.1002/smll.202107381">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XlvVaksrk%3D" aria-label="CAS reference 38">CAS</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Integrating%20DNA%20encapsulates%20and%20digital%20microfluidics%20for%20automated%20data%20storage%20in%20DNA&amp;journal=Small&amp;doi=10.1002%2Fsmll.202107381&amp;volume=18&amp;publication_year=2022&amp;author=Antkowiak%2CPL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="39."><p id="ref-CR39">Lin, K. N., Volkel, K., Tuck, J. M. &amp; Keung, A. J. Dynamic and scalable DNA-based information storage. <i>Nat. Commun.</i> <b>11</b>, 2981 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-020-16797-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-020-16797-2" aria-label="Article reference 39" data-doi="10.1038/s41467-020-16797-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020NatCo..11.2981L" aria-label="ADS reference 39">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhtFylsL3I" aria-label="CAS reference 39">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32532979" aria-label="PubMed reference 39">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7293219" aria-label="PubMed Central reference 39">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20and%20scalable%20DNA-based%20information%20storage&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-020-16797-2&amp;volume=11&amp;publication_year=2020&amp;author=Lin%2CKN&amp;author=Volkel%2CK&amp;author=Tuck%2CJM&amp;author=Keung%2CAJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="40."><p id="ref-CR40">Banal, J. L. et al. Random access DNA memory using Boolean search in an archival file storage system. <i>Nat. Mater</i>. 1–9. <a href="https://doi.org/10.1038/s41563-021-01021-3">https://doi.org/10.1038/s41563-021-01021-3</a> (2021).</p></li><li data-counter="41."><p id="ref-CR41">Bee, C. et al. Molecular-level similarity search brings computing to DNA data storage. <i>Nat. Commun.</i> <b>12</b>, 4764 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-021-24991-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-021-24991-z" aria-label="Article reference 41" data-doi="10.1038/s41467-021-24991-z">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021NatCo..12.4764B" aria-label="ADS reference 41">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhvVSls73J" aria-label="CAS reference 41">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34362913" aria-label="PubMed reference 41">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8346626" aria-label="PubMed Central reference 41">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular-level%20similarity%20search%20brings%20computing%20to%20DNA%20data%20storage&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-021-24991-z&amp;volume=12&amp;publication_year=2021&amp;author=Bee%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="42."><p id="ref-CR42">Buschmann, T. &amp; Bystrykh, L. V. Levenshtein error-correcting barcodes for multiplexed DNA sequencing. <i>BMC Bioinforma.</i> <b>14</b>, 272 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1186/1471-2105-14-272" data-track-action="article reference" href="https://doi.org/10.1186%2F1471-2105-14-272" aria-label="Article reference 42" data-doi="10.1186/1471-2105-14-272">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Levenshtein%20error-correcting%20barcodes%20for%20multiplexed%20DNA%20sequencing&amp;journal=BMC%20Bioinforma.&amp;doi=10.1186%2F1471-2105-14-272&amp;volume=14&amp;publication_year=2013&amp;author=Buschmann%2CT&amp;author=Bystrykh%2CLV">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="43."><p id="ref-CR43">R Core Team. R: the R project for statistical computing. <a href="https://www.r-project.org/">https://www.r-project.org/</a> (2022).</p></li><li data-counter="44."><p id="ref-CR44">Huber, W. et al. Orchestrating high-throughput genomic analysis with Bioconductor. <i>Nat. Methods</i> <b>12</b>, 115–121 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nmeth.3252" data-track-action="article reference" href="https://doi.org/10.1038%2Fnmeth.3252" aria-label="Article reference 44" data-doi="10.1038/nmeth.3252">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXjvVCrurg%3D" aria-label="CAS reference 44">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25633503" aria-label="PubMed reference 44">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4509590" aria-label="PubMed Central reference 44">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Orchestrating%20high-throughput%20genomic%20analysis%20with%20Bioconductor&amp;journal=Nat.%20Methods&amp;doi=10.1038%2Fnmeth.3252&amp;volume=12&amp;pages=115-121&amp;publication_year=2015&amp;author=Huber%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="45."><p id="ref-CR45">Pagès, H., Aboyoun, P., Gentleman, R. &amp; DebRoy, S. Biostrings: efficient manipulation of biological strings. <a href="https://doi.org/10.18129/B9.bioc.Biostrings">https://doi.org/10.18129/B9.bioc.Biostrings</a> (2023).</p></li><li data-counter="46."><p id="ref-CR46">Morgan, M. et al. ShortRead: a bioconductor package for input, quality assessment and exploration of high-throughput sequence data. <i>Bioinformatics</i> <b>25</b>, 2607–2608 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/bioinformatics/btp450" data-track-action="article reference" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtp450" aria-label="Article reference 46" data-doi="10.1093/bioinformatics/btp450">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1MXhtFyhur7I" aria-label="CAS reference 46">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19654119" aria-label="PubMed reference 46">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2752612" aria-label="PubMed Central reference 46">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=ShortRead%3A%20a%20bioconductor%20package%20for%20input%2C%20quality%20assessment%20and%20exploration%20of%20high-throughput%20sequence%20data&amp;journal=Bioinformatics&amp;doi=10.1093%2Fbioinformatics%2Fbtp450&amp;volume=25&amp;pages=2607-2608&amp;publication_year=2009&amp;author=Morgan%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="47."><p id="ref-CR47">Wickham, H. stringr: Simple, Consistent Wrappers for Common String Operations. <a href="https://stringr.tidyverse.org/">https://stringr.tidyverse.org</a>, <a href="https://github.com/tidyverse/stringr">https://github.com/tidyverse/stringr</a> (2022).</p></li><li data-counter="48."><p id="ref-CR48">The Python Language Reference. <i>Python documentation.</i> <a href="https://docs.python.org/3/reference/index.html">https://docs.python.org/3/reference/index.html</a>.</p></li><li data-counter="49."><p id="ref-CR49">Arthur, D. &amp; Vassilvitskii, S. k-means++: the advantages of careful seeding. In <i>Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms</i> 1027–1035 (Society for Industrial and Applied Mathematics, 2007).</p></li><li data-counter="50."><p id="ref-CR50">Schubert, E., Sander, J., Ester, M., Kriegel, H. P. &amp; Xu, X. DBSCAN revisited, revisited: why and how you should (Still) use DBSCAN. <i>ACM Trans. Database Syst.</i> <b>42</b>, 1–21 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1145/3068335" data-track-action="article reference" href="https://doi.org/10.1145%2F3068335" aria-label="Article reference 50" data-doi="10.1145/3068335">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3622239" aria-label="MathSciNet reference 50">MathSciNet</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=DBSCAN%20revisited%2C%20revisited%3A%20why%20and%20how%20you%20should%20%28Still%29%20use%20DBSCAN&amp;journal=ACM%20Trans.%20Database%20Syst.&amp;doi=10.1145%2F3068335&amp;volume=42&amp;pages=1-21&amp;publication_year=2017&amp;author=Schubert%2CE&amp;author=Sander%2CJ&amp;author=Ester%2CM&amp;author=Kriegel%2CHP&amp;author=Xu%2CX">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="51."><p id="ref-CR51">Ankerst, M., Breunig, M. M., Kriegel, H.-P. &amp; Sander, J. OPTICS: ordering points to identify the clustering structure. <i>ACM SIGMOD Rec.</i> <b>28</b>, 49–60 (1999).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1145/304181.304187" data-track-action="article reference" href="https://doi.org/10.1145%2F304181.304187" aria-label="Article reference 51" data-doi="10.1145/304181.304187">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=OPTICS%3A%20ordering%20points%20to%20identify%20the%20clustering%20structure&amp;journal=ACM%20SIGMOD%20Rec.&amp;doi=10.1145%2F304181.304187&amp;volume=28&amp;pages=49-60&amp;publication_year=1999&amp;author=Ankerst%2CM&amp;author=Breunig%2CMM&amp;author=Kriegel%2CH-P&amp;author=Sander%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="52."><p id="ref-CR52">Yang, M.-S., Lai, C.-Y. &amp; Lin, C.-Y. A robust EM clustering algorithm for Gaussian mixture models. <i>Pattern Recognit.</i> <b>45</b>, 3950–3961 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.patcog.2012.04.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.patcog.2012.04.031" aria-label="Article reference 52" data-doi="10.1016/j.patcog.2012.04.031">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012PatRe..45.3950Y" aria-label="ADS reference 52">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="math reference" href="http://www.emis.de/MATH-item?1242.68260" aria-label="MATH reference 52">MATH</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20robust%20EM%20clustering%20algorithm%20for%20Gaussian%20mixture%20models&amp;journal=Pattern%20Recognit.&amp;doi=10.1016%2Fj.patcog.2012.04.031&amp;volume=45&amp;pages=3950-3961&amp;publication_year=2012&amp;author=Yang%2CM-S&amp;author=Lai%2CC-Y&amp;author=Lin%2CC-Y">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="53."><p id="ref-CR53">Pedregosa, F. et al. Scikit-learn: Machine Learning in Python. <i>J. Mach. Learn. Res</i>. <b>12</b>, 2825–2830 (2011).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41467-023-38876-w?format=refman&amp;flavour=references">Download references</a></p></div></div><div id="Ack1-section" data-title="Acknowledgements"><h2 id="Ack1">Acknowledgements</h2><p>We thank the Yew and Poh Lab members for constructive criticism critical to the research. This work was supported by Ministry of Education, Singapore, under its AcRF Tier 2 Grant (MOE-T2EP30221-0014). C.K.L. is funded by the NUS Integrative Sciences and Engineering Programme.</p></div><div id="author-information-section" aria-labelledby="author-information" data-title="Author information"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Synthetic Biology for Clinical and Technological Innovation, National University of Singapore, 28 Medical Drive, Singapore, 117456, Singapore</p><p>Cheng Kai Lim,&nbsp;Jing Wui Yeoh,&nbsp;Aurelius Andrew Kunartama,&nbsp;Wen Shan Yew&nbsp;&amp;&nbsp;Chueh Loo Poh</p></li><li id="Aff2"><p>Synthetic Biology Translational Research Programme, Yong Loo Lin School of Medicine, National University of Singapore, 14 Medical Drive, Singapore, 117599, Singapore</p><p>Cheng Kai Lim&nbsp;&amp;&nbsp;Wen Shan Yew</p></li><li id="Aff3"><p>Department of Biochemistry, Yong Loo Lin School of Medicine, National University of Singapore, 8 Medical Drive, Singapore, 117597, Singapore</p><p>Cheng Kai Lim&nbsp;&amp;&nbsp;Wen Shan Yew</p></li><li id="Aff4"><p>Department of Biomedical Engineering, College of Design and Engineering, National University of Singapore, Singapore, Singapore</p><p>Cheng Kai Lim,&nbsp;Jing Wui Yeoh,&nbsp;Aurelius Andrew Kunartama&nbsp;&amp;&nbsp;Chueh Loo Poh</p></li><li id="Aff5"><p>Integrative Sciences and Engineering Programme (ISEP), NUS Graduate School, National University of Singapore, Singapore, Singapore</p><p>Cheng Kai Lim</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Cheng_Kai-Lim"><span>Cheng Kai Lim</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Cheng%20Kai%20Lim" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Cheng%20Kai%20Lim%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Jing_Wui-Yeoh"><span>Jing Wui Yeoh</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jing%20Wui%20Yeoh" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jing%20Wui%20Yeoh%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Aurelius_Andrew-Kunartama"><span>Aurelius Andrew Kunartama</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Aurelius%20Andrew%20Kunartama" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Aurelius%20Andrew%20Kunartama%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Wen_Shan-Yew"><span>Wen Shan Yew</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wen%20Shan%20Yew" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wen%20Shan%20Yew%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Chueh_Loo-Poh"><span>Chueh Loo Poh</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Chueh%20Loo%20Poh" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Chueh%20Loo%20Poh%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li></ol></div><h3 id="contributions">Contributions</h3><p>C.K.L. and C.L.P. developed the initial concept. C.K.L. performed the experiments and analyzed the results under the supervision of C.L.P. and W.S.Y. C.K.L., J.W.Y. and C.L.P. developed and constructed the computational pipeline for image reconstruction. A.A.K. designed and developed the OptoBox device. C.K.L., J.W.Y., A.A.K. and C.L.P. wrote the manuscript with input from all authors.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:poh.chuehloo@nus.edu.sg">Chueh Loo Poh</a>.</p></div></div><div id="ethics-section" data-title="Ethics declarations"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar2">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div><div id="peer-review-section" data-title="Peer review"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar1">Peer review information</h3>
                <p><i>Nature Communications</i> thanks the anonymous reviewer(s) for their contribution to the peer review of this work. A peer review file is available.</p>
              
            </div></div><div id="additional-information-section" data-title="Additional information"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div><div id="Sec23-section" data-title="Supplementary information"><h2 id="Sec23">Supplementary information</h2></div><div id="Sec24-section" data-title="Source data"><h2 id="Sec24">Source data</h2></div><div id="rightslink-section" data-title="Rights and permissions"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20biological%20camera%20that%20captures%20and%20stores%20images%20directly%20into%20DNA&amp;author=Cheng%20Kai%20Lim%20et%20al&amp;contentID=10.1038%2Fs41467-023-38876-w&amp;copyright=The%20Author%28s%29&amp;publication=2041-1723&amp;publicationDate=2023-07-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div><div id="article-info-section" aria-labelledby="article-info" data-title="About this article"><h2 id="article-info">About this article</h2><div id="article-info-content"><p><a data-crossmark="10.1038/s41467-023-38876-w" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41467-023-38876-w" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></p><div><h3 id="citeas">Cite this article</h3><p>Lim, C.K., Yeoh, J.W., Kunartama, A.A. <i>et al.</i> A biological camera that captures and stores images directly into DNA.
                    <i>Nat Commun</i> <b>14</b>, 3921 (2023). https://doi.org/10.1038/s41467-023-38876-w</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41467-023-38876-w?format=refman&amp;flavour=citation">Download citation</a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-04-19">19 April 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2023-05-19">19 May 2023</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2023-07-03">03 July 2023</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41467-023-38876-w</span></p></li></ul></div></div></div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber, DoorDash Sue NYC to Stop Delivery Drivers from Getting a Minimum Wage (107 pts)]]></title>
            <link>https://www.vice.com/en/article/93k3ve/uber-doordash-sue-nyc-to-stop-delivery-drivers-from-getting-a-minimum-wage</link>
            <guid>36663312</guid>
            <pubDate>Mon, 10 Jul 2023 07:57:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/93k3ve/uber-doordash-sue-nyc-to-stop-delivery-drivers-from-getting-a-minimum-wage">https://www.vice.com/en/article/93k3ve/uber-doordash-sue-nyc-to-stop-delivery-drivers-from-getting-a-minimum-wage</a>, See on <a href="https://news.ycombinator.com/item?id=36663312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Image Credit: Getty Images</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>Gig economy companies DoorDash, Grubhub, and Uber sued New York City on Thursday over a new minimum wage law for app-based delivery workers that would raise their minimum wage to $17.96 per hour. The law, which was <a href="https://www.vice.com/en/article/ak33jp/the-minimum-wage-for-delivery-drivers-in-nyc-is-now-dollar1796-an-hour">implemented in mid-June</a>, is the first of its kind in the U.S, and would go into effect July 12.&nbsp;</p></span><span></span><span data-component="TextBlock"><p>DoorDash and Grubhub, which specialize in food delivery, filed a <a href="https://iapps.courts.state.ny.us/nyscef/ViewDocument?docIndex=ub_PLUS_fhjvQeK4Hz6rTVkD/Pw==" target="_blank">joint lawsuit</a> against the city’s Department of Consumer and Worker Protection (DCWP) and its commissioner. Uber, which deals both in food delivery and ridesharing, filed a separate lawsuit on the same day.&nbsp;</p></span><span data-component="TextBlock"><p>“Bad policies cannot go unchallenged, and we will not stand by and let the harmful impacts of this earnings standard on New York City customers, merchants, and the delivery workers it was intended to support go unchecked,” a DoorDash spokesperson told Motherboard in an email. “We—and others—clearly and repeatedly warned the city that using such a flawed process to underpin its rulemaking would have lasting and harmful impacts for all New Yorkers who use these platforms, but the approach that DCWP took was sadly not one that reflected this, and has left us no choice but to take our concerns to court.”</p></span><span data-component="TextBlock"><p>DCWP Commissioner Vilda Vera Mayuga told Motherboard in a statement, “Delivery workers, like all workers, deserve fair pay for their labor, and we are disappointed that Uber, DoorDash, GrubHub, and Relay disagree. These workers brave thunderstorms, extreme heat events, and risk their lives to deliver for New Yorkers—and we remain committed to delivering for them. The minimum pay rate will help uplift thousands of working New Yorkers and their families out of poverty. We look forward to the court’s decision and to apps beginning to pay these workers a dignified rate.”</p></span><span></span><span data-component="TextBlock"><p>The new law planned to raise the minimum wage of app-based delivery workers in the city to $17.96 per hour on July 12, and subsequently to $19.96 per hour by April 2025, when it would be fully phased in. A <a href="https://www.nyc.gov/office-of-the-mayor/news/405-23/mayor-adams-dcwp-commissioner-mayuga-nation-s-first-minimum-pay-rate-app-based#/0" target="_blank">press release</a> from the city at the time stated that delivery workers currently earn around $7 per hour on average. Most food delivery apps pay workers by the delivery and drivers often greatly rely on customer tips to be their main source of income. Motherboard has <a href="https://www.vice.com/en/article/3akd8j/reddit-is-full-of-doordashers-begging-customers-for-tips">previously reported</a> that DoorDashers, for example, often only get a base pay of $2 or $3 per delivery, and get about two-thirds of their income from customer tips. The law, then, would mean an overall increase of around $13 per hour.&nbsp;</p></span></p><p><span data-component="TextBlock"><p>DoorDash argues in its <a href="https://iapps.courts.state.ny.us/nyscef/ViewDocument?docIndex=ub_PLUS_fhjvQeK4Hz6rTVkD/Pw==" target="_blank">lawsuit</a>, however, that the law is improperly implemented, because it would force companies to pay workers for any time logged into the app, regardless of whether they were delivering or not, and that the DCWP ignored “mountains of hard data and analysis, and over emphatic objections from a range of constituents” in order to implement it.&nbsp;</p></span><span></span><span data-component="TextBlock"><p>“Although Petitioners are not opposed to a well-constructed minimum-pay standard for delivery workers (and, indeed, have supported such standards in other jurisdictions), the implementation of this ill-conceived Rule will have drastic—and immediate—consequences for all concerned parties,” the lawsuit states.&nbsp;</p></span><span data-component="TextBlock"><p>In a <a href="https://doordash.news/get-the-facts/why-were-filing-a-lawsuit-on-the-nyc-earnings-standard/" target="_blank">post on its website</a>, DoorDash further explained its claim. “The earnings standard does not reflect the way the industry operates,” the post reads. “For instance, why would the agency choose to purposefully exclude companies that only facilitate grocery deliveries from its study and rulemaking, when those that facilitate both restaurant and grocery deliveries from local businesses would have these rules apply to them? A worker can now be subject to different legal standards for identical orders from identical local businesses, based solely on the platform they choose to accept the order from.”</p></span><span data-component="TextBlock"><p>DoorDash and Grubhub are seeking a temporary restraining order and preliminary injunction against the rule before it goes into effect.&nbsp;</p></span><span data-component="TextBlock"><p>“If allowed to stand, this rule will have serious adverse consequences for delivery partners, consumers and independent businesses,” a Grubhub spokesperson told Motherboard in an email. “Grubhub commends the City’s attention to this issue, but we cannot support a solution that has such unintended implications for those who rely on food delivery.”</p></span><span data-component="TextBlock"><p>An Uber spokesperson did not immediately respond to a request for comment.</p></span></p></div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kubernetes SidecarContainers feature is merged (177 pts)]]></title>
            <link>https://github.com/kubernetes/kubernetes/pull/116429</link>
            <guid>36663060</guid>
            <pubDate>Mon, 10 Jul 2023 07:18:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kubernetes/kubernetes/pull/116429">https://github.com/kubernetes/kubernetes/pull/116429</a>, See on <a href="https://news.ycombinator.com/item?id=36663060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      
<h4 dir="auto">What type of PR is this?</h4>
<p dir="auto">/kind feature<br>
/kind api-change</p>

<h4 dir="auto">What this PR does / why we need it:</h4>
<p dir="auto">This adds the Sidecar Containers feature to kubernetes.</p>
<ul>
<li>  API change - add restartPolicy to Init containers</li>
<li>  API validation - only allow restartPolicy for Init containers and allow startupProbe for the sidecar containers</li>
<li>  Startup: wait for Started, not for completion.</li>
<li>  Reconciling status of Sidecar container with the runtime</li>
<li>  Termination: Pod is terminated even if sidecar is still running</li>
<li>  Resources calculation update</li>
<li>  Restart sidecar on sidecar failure/completion while pod is still running</li>
<li> <del>Topology/CPU managers update</del></li>
</ul>
<h4 dir="auto">Which issue(s) this PR fixes:</h4>

<p dir="auto">Fixes #</p>
<p dir="auto">ref: <a data-error-text="Failed to load title" data-id="1594100455" data-permission-text="Title is private" data-url="https://github.com/kubernetes/kubernetes/issues/115934" data-hovercard-type="issue" data-hovercard-url="/kubernetes/kubernetes/issues/115934/hovercard" href="https://github.com/kubernetes/kubernetes/issues/115934">#115934</a></p>
<h4 dir="auto">Special notes for your reviewer:</h4>
<h4 dir="auto">Does this PR introduce a user-facing change?</h4>

<div data-snippet-clipboard-copy-content="The new feature gate &quot;SidecarContainers&quot; is now available. This feature introduces sidecar containers, a new type of init container that starts before other containers but remains running for the full duration of the pod's lifecycle and will not block pod termination."><pre lang="release-note"><code>The new feature gate "SidecarContainers" is now available. This feature introduces sidecar containers, a new type of init container that starts before other containers but remains running for the full duration of the pod's lifecycle and will not block pod termination.
</code></pre></div>
<h4 dir="auto">Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.:</h4>

<div data-snippet-clipboard-copy-content="- [KEP]: https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/753-sidecar-containers"><pre lang="docs"><code>- [KEP]: https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/753-sidecar-containers
</code></pre></div>
<p dir="auto">/cc <a data-hovercard-type="user" data-hovercard-url="/users/SergeyKanzhelev/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SergeyKanzhelev">@SergeyKanzhelev</a> <a data-hovercard-type="user" data-hovercard-url="/users/matthyx/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/matthyx">@matthyx</a></p>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Workout.lol – a web app to easily create a workout routine (749 pts)]]></title>
            <link>https://workout.lol</link>
            <guid>36662655</guid>
            <pubDate>Mon, 10 Jul 2023 06:01:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workout.lol">https://workout.lol</a>, See on <a href="https://news.ycombinator.com/item?id=36662655">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>