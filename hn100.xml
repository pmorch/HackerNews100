<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 11 Dec 2024 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The PayPal Mafia is taking over America's government (125 pts)]]></title>
            <link>https://www.economist.com/business/2024/12/10/the-paypal-mafia-is-taking-over-americas-government</link>
            <guid>42387549</guid>
            <pubDate>Wed, 11 Dec 2024 13:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2024/12/10/the-paypal-mafia-is-taking-over-americas-government">https://www.economist.com/business/2024/12/10/the-paypal-mafia-is-taking-over-americas-government</a>, See on <a href="https://news.ycombinator.com/item?id=42387549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><p><span><a href="https://www.economist.com/business" data-analytics="sidebar:section"><span>Business</span></a></span><span> | <!-- -->All-in on Donald Trump</span></p><h2>America’s right-wing tech bros are celebrating Donald Trump’s victory</h2></section><section><figure><img alt="Palace of Fine Arts at night with the Golden Gate Bridge in the background, San Francisco, California, USA. " fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20241214_WBP501.jpg"><figcaption><span>Photograph: Getty Images</span></figcaption></figure></section><div><div><p><time datetime="2024-12-10T17:55:20.458Z"> <!-- -->Dec 10th 2024</time><span>|</span><span>SAN FRANCISCO</span></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">O</span><small>n the night</small> of December 7th San Francisco’s Palace of Fine Arts, with its lakeside colonnade echoing a Roman ruin, turned into Mar-a-Lago, as <a href="https://www.economist.com/united-states/2024/11/21/how-donald-trump-could-win-the-future">Silicon Valley’s newly emboldened right-wingers</a> gathered for a Christmas bash organised by the All-In podcast. The festive good cheer did not extend to everyone;&nbsp;<i>The Economist</i> was made to feel most unwelcome. But not before being privy to a riotous celebration of how a clique of billionaires—the so-called PayPal Mafia—helped clinch Donald Trump’s election victory and has taken Washington by storm.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/elon-musk" data-analytics="tags:elon_musk"><span>Elon Musk</span></a><a href="https://www.economist.com/topics/donald-trump" data-analytics="tags:donald_trump"><span>Donald Trump</span></a><a href="https://www.economist.com/topics/united-states" data-analytics="tags:united_states"><span>United States</span></a></nav></p></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making memcpy(NULL, NULL, 0) well-defined (114 pts)]]></title>
            <link>https://developers.redhat.com/articles/2024/12/11/making-memcpynull-null-0-well-defined</link>
            <guid>42387013</guid>
            <pubDate>Wed, 11 Dec 2024 12:19:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.redhat.com/articles/2024/12/11/making-memcpynull-null-0-well-defined">https://developers.redhat.com/articles/2024/12/11/making-memcpynull-null-0-well-defined</a>, See on <a href="https://news.ycombinator.com/item?id=42387013">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>Undefined behavior (UB) in the C programming language is a regular source of heated discussions among programmers. On the one hand, UB can be important for compiler optimizations. On the other hand, it makes is easy to introduce bugs that lead to security issues.</p><p>The good news is that <a href="https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3322.pdf">N3322</a> has been accepted for C2y, which will remove undefined behavior from one particular corner of the C language, making all of the following well-defined:</p><pre><code>memcpy(NULL, NULL, 0);
memcmp(NULL, NULL, 0);
(int *)NULL + 0;
(int *)NULL - 0;
(int *)NULL - (int *)NULL;</code></pre><p>This only applies when a null pointer is combined with a "zero-length" operation. The following are still undefined:</p><pre><code>memcpy(NULL, NULL, 4);
(int *)NULL + 4;</code></pre><p>The removal of this undefined behavior is not expected to have any negative impact on performance. In fact, the reverse is true.</p><h2>Motivation</h2><p>The examples above are somewhat silly because they hard-code a <code>NULL</code>/<code>nullptr</code> constant. However, it is easy to run into this situation with a pointer that is only sometimes null. For example, consider a typical representation for a string with a known length:</p><pre><code>struct str {
   char *data;
   size_t len;
};</code></pre><p>An empty string would usually be represented as <code>(struct str) { .data = NULL, .len = 0 }</code>, with the <code>data</code> pointer being <code>NULL</code>. Now, consider a function that checks if two strings are equal:</p><pre><code>bool str_eq(const struct str *str1, const struct str *str2) {
   return str1-&gt;len == str2-&gt;len &amp;&amp;
          memcmp(str1-&gt;data, str2-&gt;data, str1-&gt;len) == 0;
}</code></pre><p>This implementation looks very reasonable at first glance. However, it exhibits undefined behavior if both of the inputs are empty strings. In that case, we will call <code>memcmp(NULL, NULL, 0)</code>, which is undefined behavior according to the C standard.</p><p>This kind of UB introduces the risk that the compiler will optimize away following null pointer checks. For example, GCC will happily remove the <code>dest == NULL</code> branch in the following code, while Clang deliberately does not perform this optimization:</p><pre><code>int test(char *dest, const char *src, size_t len) {
   memcpy(dest, src, len);
   if (dest == NULL) {
       // This branch will be removed by GCC due to undefined behavior.
   }
}</code></pre><p>The correct way to write the <code>str_eq</code> function is as follows:</p><pre><code>bool str_eq(const struct str *str1, const struct str *str2) {
   return str1-&gt;len == str2-&gt;len &amp;&amp;
          (str1-&gt;len == 0 ||
           memcmp(str1-&gt;data, str2-&gt;data, str1-&gt;len) == 0);
}</code></pre><p>The new code is correct, but worse in every other way:</p><ul><li>It increases code size, by requiring an extra check at each inlined call-site.</li><li>It decreases performance, by redundantly checking something <code>memcmp</code> has to handle anyway.</li><li>It increases code complexity.</li></ul><p>At the same time, there is no useful way in which the C library can make use of this undefined behavior to provide a more efficient implementation. This is the kind of UB that benefits nobody, and should be removed from the language.</p><h2>Null pointer arithmetic</h2><p>The original proposal was focused on removing UB for memory library calls, but an early reviewer pointed out that this is not sufficient. After all, we also need to take into account how these library functions are implemented.</p><p>For example, let's consider a typical implementation for a <code>memcpy</code>-like function:</p><pre><code>void copy(char *dst, const char *src, size_t n) {
   for (const char *end = src + n; src &lt; end; src++) {
       *dst++ = *src;
   }
}</code></pre><p>This function exhibits undefined behavior when called as <code>copy(NULL, NULL, 0)</code>, because <code>NULL + 0</code> is undefined behavior in C.</p><p>To avoid this, and make the overall language self-consistent, we need to define <code>NULL + 0</code> as returning <code>NULL</code> and <code>NULL - NULL</code> as returning 0. This also aligns C with C++ semantics, where this was already well-defined.</p><h2>Opposition</h2><p>When this proposal was discussed at two WG14 meetings, the opposition didn't come from the direction I expected.</p><p>The most broadly controversial part of the proposal was to define <code>NULL - NULL</code> as returning 0. The reason for this is that when address spaces get involved (which are not part of standard C, but may be implemented as an extension), there may be multiple representations of a null pointer. Making sure that subtracting two "different" nulls still results in zero might require the generation of additional code, breaking the premise that this change is entirely free.</p><p>However, the most vocal opposition came from a static analysis perspective: Making null pointers well-defined for zero length means that static analyzers can no longer unconditionally report <code>NULL</code> being passed to functions like <code>memcpy</code>—they also need to take the length into account now. If an <a href="https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3089.pdf"><code>_Optional</code> qualifier</a> is introduced in the future, <code>memcpy</code> arguments would have to be qualified with it. GCC is considering the introduction of a <a href="https://gcc.gnu.org/pipermail/gcc-patches/2024-November/668505.html"><code>nonnull_if_nonzero</code></a> attribute to represent the new pre-condition.</p><p>After the seemingly negative discussion, I was somewhat surprised that the vote not only went strongly in favor of the change, but also came with a recommendation to implementers to apply the change <a href="https://www.open-std.org/jtc1/sc22/wg14/www/previous.html">retroactively</a> to old standard versions. This means that, once compilers and C libraries have implemented the change, it should apply even without specifying the <code>-std=c2y</code> flag.</p><h2>Compiler builtins</h2><p>I work on the middle-end of the <a href="https://llvm.org/">LLVM</a> compiler toolchain. Being far removed from any "user-facing" parts of the compiler, I am generally not involved with standardization efforts.</p><p>The reason I got involved here at all is the specification for LLVM's internal memcpy intrinsic:</p><blockquote><div><p>The <code>llvm.memcpy.*</code> intrinsics copy a block of memory from the source location to the destination location, which must either be equal or non-overlapping. [...]</p><p>If <code>&lt;len&gt;</code> is 0, it is no-op modulo the behavior of attributes attached to the arguments. [...]</p></div></blockquote><p>The <code>llvm.memcpy</code> intrinsic may lower to a call to the <code>memcpy</code> function, which is treated as a "compiler runtime builtin" here, even though it is ultimately also provided by the C library.</p><p>When used as a builtin, LLVM requires that both <code>memcpy(x, x, s)</code> and <code>memcpy(NULL, NULL, 0)</code> are well-defined, even though the C standard says they are UB. GCC and MSVC have similar assumptions.</p><p>Making <code>memcpy(NULL, NULL, 0)</code> officially well-defined removes one of the assumptions, while the <code>memcpy(x, x, s)</code> case remains for now. Allowing this was originally also part of the proposal, but was later dropped, because it didn't fit well with the other changes.</p><p>In a weird turn of events, this change to the C standard came about because Rust developers kept nagging me about the mismatch between LLVM and C semantics.</p><h2>Acknowledgements</h2><p>This paper was a collaboration with Aaron Ballman, who also drove the discussion during the actual WG14 meetings. Special thanks go to David Stone, whose early feedback radically changed the direction of the proposal from memory library calls in particular to "zero-length" operations in general.</p>
          
                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astronomy Photographer of the Year 2024 winners (109 pts)]]></title>
            <link>https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/overall-winners-2024</link>
            <guid>42385761</guid>
            <pubDate>Wed, 11 Dec 2024 07:56:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/overall-winners-2024">https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/overall-winners-2024</a>, See on <a href="https://news.ycombinator.com/item?id=42385761">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-off-canvas-main-canvas="">
    
  

  



  




  

  

  

  <main role="main">
    
    <div id="block-rmg-theme-content">
  
    
      <article data-content-type="topic">

  
    

  
  <div>
              
              <div>
              <p>
          <h2>
            The overall winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-09/OS-348550-1%20Distorted%20Shadows%20of%20the%20Moon%27s%20Surface%20Created%20by%20an%20Annular%20Eclipse%20v2_0.jpg?itok=NnUAJz-h" width="1200" height="675" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Ryan Imperio
      </span>
                  </p></div>
      <div>
                  <h3>
            Distorted Shadows of the Moon's Surface Created by an Annular Eclipse by Ryan Imperio
      </h3>
                <div>
          
            <p>Photographer Ryan Imperio from the United States has been named the overall winner of Astronomy Photographer of the Year 16.</p><p>The image is a <a href="https://www.rmg.co.uk/stories/topics/beads-sunlight-photographing-annular-solar-eclipse-astronomy-photographer-year" data-entity-type="node" data-entity-uuid="415695bc-72b7-4740-a1af-726249f49004" data-entity-substitution="canonical" title="Beads of sunlight: photographing an annular solar eclipse" data-gtm-name="CTA" data-gtm-detail="formatted content">composite of more than 30 separate photographs of the Sun</a>, taken in Texas during the annular solar eclipse of 14 October 2023.</p><p>Together the photographs capture the fleeting optical illusion known as 'Baily's beads', which occurs when sunlight shines through the valleys and craters of the Moon.</p><p>“What an innovative way to map the Moon’s topography at the point of third contact during an annular solar eclipse," competition judge Kerry-Ann Lecky Hepburn says. "This is an impressive dissection of the fleeting few seconds during the visibility of the Baily’s beads. This image left me captivated and amazed. It’s exceptional work deserving of high recognition. Congratulations!”</p><p><a href="https://www.rmg.co.uk/stories/topics/beads-sunlight-photographing-annular-solar-eclipse-astronomy-photographer-year" data-entity-type="node" data-entity-uuid="415695bc-72b7-4740-a1af-726249f49004" data-entity-substitution="canonical" title="Beads of sunlight: photographing an annular solar eclipse" data-gtm-name="CTA" data-gtm-detail="formatted content">Learn more about the winning image</a></p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/our-sun-2024" data-entity-type="node" data-entity-uuid="9ce1c711-01dc-45a0-afc0-966a5252bb2f" data-entity-substitution="canonical" title="Our Sun 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Our Sun shortlist</a><br>&nbsp;</p>
      
                      
                  </div>
      </div>
    </div>
              <div>
        <h2>
            Never miss a shooting star
      </h2>        
            <p><span>Sign up to our monthly space newsletter for amazing space stories, astronomy guides and more from Royal Museums Greenwich.</span></p>
      
      </div>
              <div>
              <p>
          <h2>
            Skyscapes category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/Tasman%20Gems%20%C2%A9%20Tom%20Rae%20%E2%80%93%20Astronomy%20Photographer%20of%20the%20Year%202024%20Skyscapes%20.jpg?itok=aKcF1NY1" width="1200" height="761" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Tom Rae
      </span>
                  </p></div>
      <div>
                  <h3>
            Tasman Gems by Tom Rae
      </h3>
                <div>
          
            <p>"It’s very challenging to create this sort of composition without tipping the balance in favour of either foreground or background. Here, the grass and central rock retain wonderful detail, as do the midground mountains, but the vibrance and detail in the cosmic background shine through as well.&nbsp;</p><p>"Even the airglow adds to the image, which is no easy feat! As well as being technically impressive, the balance also produces a sort of surreal quality. A slightly dream-like connection between the Earth-bound and the celestial."</p><p>– Ed Bloomer, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/skyscapes-2024" data-entity-type="node" data-entity-uuid="144ebd7a-1f52-4905-affd-4eaa7e2fb0b9" data-entity-substitution="canonical" title="Skyscapes 2024 – Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Skyscapes shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Galaxies category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/G-68776-63-03518%20Echoes%20of%20the%20Past%20%C2%A9%20Bence%20T%C3%B3th%20and%20P%C3%A9ter%20Felt%C3%B3ti.jpg?itok=J4yknJ6w" width="1200" height="705" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Bence Tóth and Péter Feltóti
      </span>
                  </p></div>
      <div>
                  <h3>
            Echoes of the Past by Bence Tóth and Péter Feltóti
      </h3>
                <div>
          
            <p>"Galaxies are among the most amazing phenomena you can observe with a telescope. Each is unique, but some are more special than others. Centaurus A is one of the most extraordinary of its kind, and this image certainly stands out among galaxy photos. Thanks to accurate photon collection, precise image processing and cooperation between fellow astrophotographers, a photo taken on a challenging expedition has become one of the best captures of this object to date."</p><p>– László Francsics, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/galaxies-2024" data-entity-type="node" data-entity-uuid="6afa0eb3-4926-4ec9-9dce-41a80bb8e208" data-entity-substitution="canonical" title="Galaxies 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Galaxies shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Our Moon category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/Shadow%20Peaks%20of%20Sinus%20Iridum%20%C2%A9%20G%C3%A1bor%20Bal%C3%A1zs%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20Our%20Moon.jpg?itok=86_Tl91h" width="1200" height="865" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Gábor Balázs
      </span>
                  </p></div>
      <div>
                  <h3>
            Shadow Peaks of Sinus Iridum by Gábor Balázs
      </h3>
                <div>
          
            <p>"This is a very impressive image. Sinus Iridum, known as the 'Bay of Rainbows', is about 260 km in diameter and is bordered by several smaller craters, showcasing the Moon’s rugged terrain.</p><p>"The detailed capture of Pythagoras, noted for its depth and complex features, is enhanced by the phenomenon of libration, where slight oscillations in the Moon’s orientation allow Earth-bound observers a glimpse of areas typically hidden from view. This image not only highlights the capabilities of modern astrophotography equipment but also offers a vivid illustration of lunar surface features, contributing valuable insights into lunar geology."</p><p>– Yuri Beletsky, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/our-moon-2024" data-entity-type="node" data-entity-uuid="87bb24ef-6d32-4c1f-8e29-4f969533135c" data-entity-substitution="canonical" title="Our Moon 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Our Moon shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Aurorae category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/Queenstown%20Aurora%20%C2%A9%20Larryn%20Rae%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20Aurorae.jpg?itok=D3ZS7yl8" width="1200" height="722" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Larryn Rae
      </span>
                  </p></div>
      <div>
                  <h3>
            Queenstown Aurora by Larryn Rae
      </h3>
                <div>
          
            <p>"This extraordinary panoramic image captures an aurora with rare red and pink hues over New Zealand. This is a phenomenon typically seen near the poles but appears here due to intense solar activity. The vivid red colours are produced at high altitudes when charged particles from solar flares and coronal mass ejections interact with oxygen in Earth’s atmosphere.&nbsp;</p><p>"Red aurorae are less common than green ones, which occur at lower altitudes where there is more oxygen to interact with and a higher density of atoms. This makes the observation more unique and special; an event typically associated with significant solar activity and usually only visible under clear, dark sky conditions."</p><p>– Yuri Beletsky, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/aurorae-2024" data-entity-type="node" data-entity-uuid="c5015161-7fe5-4911-b5b0-06d2f5c94be0" data-entity-substitution="canonical" title="Aurorae 2024 – Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Aurorae shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Planets, Comets and Asteroids category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/PCA-195480-170%20On%20Approach%20%C2%A9%20Tom%20Williams%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20Planets%20Comets%20and%20Asteroids.jpg?itok=KQkif32_" width="1200" height="1200" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Tom Williams
      </span>
                  </p></div>
      <div>
                  <h3>
            On Approach by Tom Williams
      </h3>
                <div>
          
            <p>"Venus shares very little with Earth-bound observers. Its highly reflective clouds show no detail when using conventional imaging methods. This photographer, however, has managed to tease a startling level of detail out of the phases shown here. Although the colours used are false, they are not too far from the natural colour of the planet. The thoughtful compositional work in the accurate scaling of the three phases is just the icing on the cake."</p><p>– Steve Marsh, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/planets-comets-asteroids-2024" data-entity-type="node" data-entity-uuid="e5ad6088-ae9e-4510-9af1-7b24fa53ffd9" data-entity-substitution="canonical" title="Planets, Comets and Asteroids 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Planets, Comets and Asteroids shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            People and Space category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/High-tech%20Silhouette%20%C2%A9%20Tom%20Williams%20%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20People%20and%20Space.jpg?itok=jM2P8Gei" width="935" height="1200" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Tom Williams
      </span>
                  </p></div>
      <div>
                  <h3>
            High-tech Silhouette by Tom Williams
      </h3>
                <div>
          
            <p>"This dramatic image serves as a powerful reminder of humanity’s ongoing presence in space. The photographer has done a great job in perfectly timing this shot so that the International Space Station is silhouetted against the backdrop of the Sun’s eastern solar limb.&nbsp;</p><p>"The photograph beautifully showcases the dynamic and active nature of the Sun, bringing it to life in a captivating way. Yet among that, your eye is permanently fixed on the tiny human-made spacecraft making its way across, emphasizing its significance amid the grandeur of the Sun. It’s a worthy winner of this category."</p><p>– Melissa Brobby, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/people-space-2024" data-entity-type="node" data-entity-uuid="2da63a75-3b58-440b-829c-032441f64fbb" data-entity-substitution="canonical" title="People and Space 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full People and Space shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Stars and Nebulae category winner
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/SNR%20G107.5-5.2%2C%20Unexpected%20Discovery%20%28the%20Nereides%20Nebula%20in%20Cassiopeia%29%20%C2%A9%20Marcel%20Drechsler%2C%20Bray%20Falls%2C%20Yann%20Sainty%2C%20Nicolas%20Martino%20and%20Richard%20Galli.jpg?itok=8-dm1sfe" width="1099" height="1200" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Marcel Drechsler, Bray Falls, Yann Sainty, Nicolas Martino and Richard Galli
      </span>
                  </p></div>
      <div>
                  <h3>
            SNR G107.5-5.2, Unexpected Discovery (the Nereides Nebula in Cassiopeia) by Marcel Drechsler, Bray Falls, Yann Sainty, Nicolas Martino and Richard Galli
      </h3>
                <div>
          
            <p>"The hits keep on coming from this team with another stunning revelation for us. Who knew this fantastic and delicate structure was there all along in one of the best-known constellations in the night sky? The thoughtful processing and clever use of colouring really make the supernova remnant pop against its background. It’s one of those images that you can stare into for hours and still find more detail. Stunning!"</p><p>– Steve Marsh, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/stars-nebulae-2024" data-entity-type="node" data-entity-uuid="6f020dfb-7c21-4b6a-881d-a9d37c656966" data-entity-substitution="canonical" title="Stars and Nebulae 2024 – Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Stars and Nebulae shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            The Sir Patrick Moore Prize for Best Newcomer
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/BN-312741-1%20SH2-308%20Dolphin%20Head%20Nebula%20%C2%A9%20Xin%20Feng%20and%20Miao%20Gong%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20Best%20Newcomer.jpg?itok=xhy4VGLX" width="1200" height="799" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Xin Feng and Miao Gong
      </span>
                  </p></div>
      <div>
                  <h3>
            SH2-308: Dolphin Head Nebula by Xin Feng and Miao Gong
      </h3>
                <div>
          
            <p>"The Dolphin Head Nebula is a bubble of hydrogen pushed out from a very luminous Wolf-Rayet star. Stellar winds of over 1,500 km per second make the region rather more lively than even its animal namesake.</p><p>"This image is wonderfully detailed, and really displays the three-dimensional nature of the nebula. It is vibrant, without losing the very delicate surrounding structures, and you can clearly make out another little planetary nebula bubble (called PN G234.9-09.7) towards the bottom of the dolphin’s head, which is rarely imaged with any clarity. Very, very impressive work from any astrophotographer, let alone a newcomer."</p><p>– Ed Bloomer, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/best-newcomer-2024" data-entity-type="node" data-entity-uuid="edf7197f-cdc7-44b1-87f6-d96c3da5f132" data-entity-substitution="canonical" title="Best Newcomer 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Best Newcomer shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            The Annie Maunder Prize for Image Innovation
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-09/Anatomy%20of%20a%20Habitable%20Planet%20%C2%A9%20Sergio%20Di%CC%81az%20Ruiz%20-%20Astronomy%20Photographer%20of%20the%20Year%202024%20Annie%20Maunder%20Prize.jpg?itok=xMIVsv5Y" width="1200" height="1200" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Sergio Díaz Ruiz
      </span>
                  </p></div>
      <div>
                  <h3>
            Anatomy of a Habitable Planet by Sergio Díaz Ruiz 
      </h3>
                <div>
          
            <p>"This strangely familiar representation of the Earth transforms scientific data through colour mapping to highlight the devastation already inflicted on our world. The image poignantly emphasizes the significant environmental challenges we face and the urgent need to protect and preserve our planet."</p><p>– Victoria Lane, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/image-innovation-prize-2024" data-entity-type="node" data-entity-uuid="637e10c4-4c30-4c15-8aa0-3935111d2857" data-entity-substitution="canonical" title="Annie Maunder Prize for Image Innovation 2024 – Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Annie Maunder Prize shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
              <p>
          <h2>
            Young Competition
      </h2>
        </p>
            <div>
          <div>
            
            <article>
  
      
  <div>
    <p>Image</p>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/large_no_alt/public/2024-08/NGC%201499%2C%20a%20Dusty%20California%20%C2%A9%20Daniele%20Borsari%20-%20Astronomy%20Photographer%20of%20the%20Year%20Young.jpg?itok=33mHEQiH" width="1200" height="995" alt="" loading="lazy">


</p>
          </div>

  </article>

      
          </div>
                      <p><span>
            © Daniele Borsari
      </span>
                  </p></div>
      <div>
                  <h3>
            NGC 1499, a Dusty California by Daniele Borsari
      </h3>
                <div>
          
            <p>"This incredibly beautiful image was very popular with the panel. Not least because it captures a nebula, atmospheric gases and has extraordinary balance of light, composition and structure. The future of astronomy photography being fearlessly, and openly, taken forward by a new generation."</p><p>– Neal White, competition judge</p><p><a href="https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/young-competition-2024" data-entity-type="node" data-entity-uuid="9792c8b9-097c-4d3c-b3e5-4bbfb43fee7f" data-entity-substitution="canonical" title="Young Competition 2024 - Astronomy Photographer of the Year" data-gtm-name="CTA" data-gtm-detail="formatted content">See the full Young Competition shortlist</a></p>
      
                      
                  </div>
      </div>
    </div>
              <div>
                  <h2>
            Find out more about the competition
      </h2>
                        <div>
                                                <div>
                  <div>
                     <p><img src="https://www.rmg.co.uk/sites/default/files/styles/slider_image/public/2020-11/PS-8826-5_Ineffable%20%C2%A9%20Alyn%20Wallace_0.jpg?itok=TNy3jqPy" alt="" loading="lazy"></p><p>Competition</p>                                      </div>
                  <div>
                      
                                            <p>
                        Key dates, prizes and details on how to enter Astronomy Photographer of the Year
                      </p>
                    </div>
                                  </div>
                                                            <div>
                  <div>
                     <p><img src="https://cdn.shopify.com/s/files/1/2459/8861/files/Collection-13-cover-rmg-publication-banner.jpg?v=1730196645" alt="" loading="lazy"></p><p>Shop</p>                                                                                </div>
                  <div>
                      
                                              <p>
                                                                                    £30.00
                                                                              </p>
                                            <p>
                        Astronomy Photographer of the Year: Collection 13 is a stunning gift for admirers of astrophotography. The competition's official book, this spectacular astronomy photography book showcases the most spectacular space photography, taken from locations across the globe...
                      </p>
                    </div>
                                    
                                  </div>
                                                            <div>
                  <div>
                     <p><img src="https://www.rmg.co.uk/sites/default/files/styles/slider_image/public/migrations/G-28529-27_Winner%20and%20Overall%20Winner_Andromeda%20Galaxy%20at%20Arm_s%20Length%20%C2%A9%20Nicolas%20Lefaudeux_2.jpg?itok=QhE33xgR" alt="" loading="lazy"></p><p>Past winners</p>                                      </div>
                  <div>
                      
                                            <p>
                        Astronomy Photographer of the Year has been held every year since 2009. Take a journey back in space and time and explore all the past winning images
                      </p>
                    </div>
                                  </div>
                              </div>
      </div>
              <div>
                  <h2>
            Get into astrophotography
      </h2>
                        <div>
                                                <div>
                  <div>
                     <p><img src="https://www.rmg.co.uk/sites/default/files/styles/slider_image/public/2023-09/Monika%20Deviat%20silhouetted%20taking%20a%20photo%20at%20night.png?itok=85Mib32v" alt="" loading="lazy"></p><p>Course</p>                                      </div>
                  <div>
                      
                                            <p>
                        Learn how to take images of the night sky in the Royal Observatory Greenwich's online introductory astrophotography course
                      </p>
                    </div>
                                  </div>
                                                            <div>
                  <div>
                     <p><img src="https://cdn.shopify.com/s/files/1/2459/8861/files/2025-GTTNS-RMG-publication.jpg?v=1730285783" alt="" loading="lazy"></p><p>Shop</p>                                                                                </div>
                  <div>
                      
                                              <p>
                                                                                    £6.99
                                                                              </p>
                                            <p>
                        
Annually, Guide to the Night Sky is the bestselling stargazing handbook to the planets, stars, and constellations visible from the northern hemisphere...
                      </p>
                    </div>
                                    
                                  </div>
                                                            <div>
                  <div>
                     <p><img src="https://www.rmg.co.uk/sites/default/files/styles/slider_image/public/2024-06/A%20woman%20looks%20at%20the%20photographs%20on%20display%20in%20the%20Astronomy%20Photographer%20of%20the%20Year%20exhibition%20at%20the%20National%20Maritime%20Museum%20%28T3782-127%29.jpg?itok=JEquG48o" alt="" loading="lazy"></p><p>Inspiration</p>                                      </div>
                  <div>
                      
                                            <p>
                        Want to get into astrophotography but don’t know where to begin? Photographers from Astronomy Photographer of the Year reveal their top tips
                      </p>
                    </div>
                                  </div>
                              </div>
      </div>
              <div>
      <div>
                      <p>
      <h2>
            Our partners
      </h2>
    </p>
                    </div>
      <div>
                              <div>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/logo/public/2021-08/Liberty_Specialty_Markets_black%5B22%5D.png?itok=8_BWwpaC" width="277" height="96" alt="Liberty Specialty Markets black" loading="lazy">



      
</p>
            </div>
                      <div>
              <p><img src="https://www.rmg.co.uk/sites/default/files/styles/logo/public/2022-06/BBC%20Sky%20At%20Night%20logo.png?itok=aLkJU--4" width="193" height="96" alt="BBC Sky at Night logo in black" loading="lazy">



      
</p>
            </div>
                        </div>
    </div>
          </div>

</article>


  </div>  </main>

  
    

  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge Refuses to Allow Sale of Infowars to The Onion (267 pts)]]></title>
            <link>https://www.nytimes.com/2024/12/10/business/media/the-onion-infowars-alex-jones.html</link>
            <guid>42384921</guid>
            <pubDate>Wed, 11 Dec 2024 04:53:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/12/10/business/media/the-onion-infowars-alex-jones.html">https://www.nytimes.com/2024/12/10/business/media/the-onion-infowars-alex-jones.html</a>, See on <a href="https://news.ycombinator.com/item?id=42384921">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/12/10/business/media/the-onion-infowars-alex-jones.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Alzheimer's study shows ketone bodies help clear misfolded proteins (158 pts)]]></title>
            <link>https://www.genengnews.com/topics/translational-medicine/ketone-body-role-in-regulating-misfolded-proteins-may-inform-strategies-targeting-aging-alzheimers-disease/</link>
            <guid>42383840</guid>
            <pubDate>Wed, 11 Dec 2024 01:48:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.genengnews.com/topics/translational-medicine/ketone-body-role-in-regulating-misfolded-proteins-may-inform-strategies-targeting-aging-alzheimers-disease/">https://www.genengnews.com/topics/translational-medicine/ketone-body-role-in-regulating-misfolded-proteins-may-inform-strategies-targeting-aging-alzheimers-disease/</a>, See on <a href="https://news.ycombinator.com/item?id=42383840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ketone bodies are produced by the body to provide fuel during fasting, and are thought to have roles in regulating cellular processes and aging mechanisms beyond energy production. Research by Buck Institute scientists, including experiments in the nematode <em>Caenorhabditis elegans</em>, and in mouse models, provides what they suggest is a direct molecular mechanism for the regulation of misfolded proteins by ketone bodies and related metabolites. The results, they said, indicate that ketone bodies, including β-hydroxybutyrate (βHB), may be considered powerful signaling metabolites affecting brain function in aging and Alzheimer’s disease (AD). The findings also point to potential metabolism-related mechanistic targets for therapeutic development in aging and in AD.</p>
<p>Reporting on their work in <em>Cell Chemical Biology</em> (“<a href="http://dx.doi.org/10.1016/j.chembiol.2024.11.001" target="_blank" rel="noopener">β-hydroxybutyrate is a metabolic regulator of proteostasis in the aged and Alzheimer disease brain</a>”), senior author John Newman, MD, PhD, a Buck Institute assistant professor, and colleagues stated, “Here, we provide a direct molecular mechanism for the regulation of misfolded proteins by ketone bodies and related metabolites … Together, these data provide foundational evidence for a novel mechanistic component of ketone body biology.”</p>
<p>Ketone bodies are a class of lipid-derived small molecule metabolites that include acetone, acetoacetate, and (R)-β-hydroxybutyrate (R-βHB), the authors noted. “The primary function of acetoacetate and R-βHB production is to provide cellular energy to extrahepatic tissues during periods of reduced&nbsp;glucose availability, such as fasting, starvation, high-intensity exercise, and ketogenic diet.”</p>
<p>Previous studies have shown that boosting ketone bodies through diet, exercise, and supplementation can be good for brain health and cognition, both in rodents and humans. “There is clear preclinical literature support, and early clinical data, for ketogenic therapies in aging and AD. … ketogenic diet and exogenous ketones have been shown to improve cognitive and motor behavior in several mouse models of AD,” the authors stated. “Early human studies of ketogenic compounds have improved cognitive scores in patients with mild to moderate AD.”</p>
<p>The researcher’s newly reported work demonstrated that ketone bodies and similar metabolites have profound effects on the proteome and protein quality control in the brain. Working in cells, in mouse models of AD and aging, and in the model organism <em>C. elegans,</em>&nbsp;the findings indicated that the ketone body β-hydroxybutyrate (βHB) interacts directly with misfolded proteins, altering their solubility and structure so they can be cleared from the brain through the process of autophagy.</p>
<p>In addition to testing the changing solubility and structure of proteins in test tubes, the researchers also studied the effects of ketone bodies in model organisms. To assess whether the solubility changes caused by ketone bodies helped improve models of pathological aggregation, the&nbsp;investigators fed ketone bodies to nematode worms that were genetically modified to express the human equivalent of amyloid beta, which causes amyloid plaques. “The amyloid beta affects muscles and paralyzes the worms,” said Sidharth Madhavan, a PhD candidate and lead author on the study. “Once they were treated with ketone bodies the animals recovered their ability to swim. It was really exciting to see such a dramatic impact in a whole animal.”</p>
<p>When the team fed a ketone ester to mice, they found that the ketone ester treatment resulted in clearance rather than pathological aggregation of insoluble proteins. The investigators in addition generated detailed proteome-wide solubility maps from their experiments in test tubes and from their mouse experiments.</p>
<figure id="attachment_305108" aria-describedby="caption-attachment-305108"><img fetchpriority="high" decoding="async" src="https://www.genengnews.com/wp-content/uploads/2024/12/low-res-300x300.jpeg" alt="B-hydroxybutyrate is a metabolic regulator of proteostasis in the aged and Alzheimer’s disease brain. [Sid Madhavan, Buck Institute for Research on Aging]" width="300" height="300" srcset="https://www.genengnews.com/wp-content/uploads/2024/12/low-res-300x300.jpeg 300w, https://www.genengnews.com/wp-content/uploads/2024/12/low-res-150x150.jpeg 150w, https://www.genengnews.com/wp-content/uploads/2024/12/low-res-420x420.jpeg 420w, https://www.genengnews.com/wp-content/uploads/2024/12/low-res-696x696.jpeg 696w, https://www.genengnews.com/wp-content/uploads/2024/12/low-res-600x600.jpeg 600w, https://www.genengnews.com/wp-content/uploads/2024/12/low-res.jpeg 700w" sizes="(max-width: 300px) 100vw, 300px"><figcaption id="caption-attachment-305108">B-hydroxybutyrate is a metabolic regulator of proteostasis in the aged and Alzheimer’s disease brain. [Sid Madhavan, Buck Institute for Research on Aging]</figcaption></figure><p>Newman noted an existing theory that the ketone body-based improvements are caused by increased energy to the brain or a reduction in brain inflammation, with reported improvements in amyloid plaques in mouse models being an indirect by-product. “Now we know that’s not the whole story,” he said. “Ketone bodies interact with damaged and misfolded proteins directly, making them insoluble so they can be pulled from the cell and recycled.”</p>
<p>Newman said the study highlights a new form of metabolic regulation of protein quality control. “This is not just about ketone bodies,” he said. “We tested similar metabolites in test tubes and a bunch of them had similar effects. In some cases, they performed better than β-hydroxybutyrate. It’s beautiful to imagine that changing metabolism results in this symphony of molecules cooperating together to improve brain function.”</p>
<p>While acknowledging that other mechanisms like energy supply are also important to brain health, Newman calls the discovery new biology. “It’s a new link between metabolism in general, ketone bodies, and aging,” he said. “Directly linking changes in a cell’s metabolic state to changes in the proteome is really exciting.”</p>
<p>Given that proteostatic mechanisms such as autophagy are known to be activated by nutrient deprivation, the authors noted, it’s not surprising that evolutionary pressures would encourage the clearance of pathogenic proteins during ketosis to promote cellular health in organisms needing additional substrate for ATP production. “In this situation, ketone bodies are janitors of damaged proteins, chaperoning away molecular waste so organisms can operate at peak molecular fitness,” they pointed out.</p>
<p>Noting that ketone bodies are easy to manipulate experimentally and therapeutically, Newman added, “This might be a powerful avenue to assist with global clearing of damaged proteins. We’re just scratching the surface as to how this might be applied to brain aging and neurodegenerative disease.”</p>
<p>In their paper, the team further concluded, “We show that βHB-induced insolubility leads to clearance of highly insolubilized proteins in vivo, likely via βHB communication with cellular protein degradation pathways. This work identifies βHB as a global regulator of cytosolic protein solubility, and identifies new metabolism-related mechanistic targets for therapeutic development in aging and AD.”</p>
<p>Madhavan is now pursuing whether ketone bodies and related metabolites have similar effects outside the brain, such as in the gut, and suggests that the key next step will be to test this new protein quality control mechanism in people to help guide how best to apply it therapeutically.</p>
		    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Electric (Postgres sync engine) beta release (263 pts)]]></title>
            <link>https://electric-sql.com/blog/2024/12/10/electric-beta-release</link>
            <guid>42383136</guid>
            <pubDate>Wed, 11 Dec 2024 00:04:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electric-sql.com/blog/2024/12/10/electric-beta-release">https://electric-sql.com/blog/2024/12/10/electric-beta-release</a>, See on <a href="https://news.ycombinator.com/item?id=42383136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-3d98f719=""><p>With version <a href="https://github.com/electric-sql/electric/releases" target="_blank" rel="noreferrer"><code>1.0.0-beta.1</code></a> the Electric sync engine is now in BETA!</p><p>If you haven't checked out Electric recently, it's a great time to <a href="https://electric-sql.com/docs/intro">take another look</a>.</p><h2 id="what-is-electric" tabindex="-1">What is Electric? <a href="#what-is-electric" aria-label="Permalink to &quot;What is Electric?&quot;">​</a></h2><p><a href="https://electric-sql.com/product/electric">Electric</a> is a Postgres sync engine. We do real-time <a href="https://electric-sql.com/docs/guides/shapes">partial replication</a> of Postgres data into local apps and services.</p><p>Use Electric to swap out data <em>fetching</em> for <a href="https://electric-sql.com/use-cases/data-sync">data <em>sync</em></a>. Build apps on instant, real-time, local data. Without having to roll your own sync engine or change your stack.</p><p>We also develop <a href="https://electric-sql.com/product/pglite">PGlite</a>, a lightweight WASM Postgres you can run in the browser.</p><h2 id="the-path-to-beta" tabindex="-1">The path to BETA <a href="#the-path-to-beta" aria-label="Permalink to &quot;The path to BETA&quot;">​</a></h2><p>Six months ago, we <a href="https://electric-sql.com/blog/2024/07/17/electric-next">took on a clean re-write</a>.</p><p><a href="https://github.com/electric-sql/archived-electric-next/commit/fc406d77caca923d1fb595d921102f25c7ce3856" target="_blank" rel="noreferrer">First commit</a> was on the 29th June 2024. <a href="https://github.com/electric-sql/electric/pulls?q=is%3Apr+is%3Aclosed" target="_blank" rel="noreferrer">600 pull requests later</a>, we're ready for adoption into production apps.</p><h2 id="production-ready" tabindex="-1">Production ready <a href="#production-ready" aria-label="Permalink to &quot;Production ready&quot;">​</a></h2><figure><img src="https://electric-sql.com/assets/logo-strip.ByW8Eccm.svg"><img src="https://electric-sql.com/assets/logo-strip.sm.BZnVxeMp.svg"><img src="https://electric-sql.com/assets/logo-strip.xs.CqHd4PCW.svg"><img src="https://electric-sql.com/assets/logo-strip.xxs.CX2ul4h3.svg"></figure><p>Electric and PGlite are being used in production by companies including <a href="https://firebase.google.com/docs/data-connect" target="_blank" rel="noreferrer">Google</a>, <a href="https://database.build/" target="_blank" rel="noreferrer">Supabase</a>, <a href="https://trigger.dev/launchweek/0/realtime" target="_blank" rel="noreferrer">Trigger.dev</a>, <a href="https://ottogrid.ai/" target="_blank" rel="noreferrer">Otto</a> and <a href="https://www.doorboost.com/" target="_blank" rel="noreferrer">Doorboost</a>.</p><blockquote><p>We use ElectricSQL to power <a href="https://trigger.dev/launchweek/0/realtime" target="_blank" rel="noreferrer">Trigger.dev Realtime</a>, a core feature of our product. When we execute our users background tasks they get instant updates in their web apps. It's simple to operate since we already use Postgres, and it scales to millions of updates per day.<br><em>— <a href="https://www.linkedin.com/in/mattaitken1985" target="_blank" rel="noreferrer">Matt Aitken</a>, Founder &amp; CEO, <a href="https://trigger.dev/" target="_blank" rel="noreferrer">Trigger.dev</a></em></p></blockquote><blockquote><p>At <a href="https://ottogrid.ai/" target="_blank" rel="noreferrer">Otto</a>, we built a spreadsheet product where every cell operates as its own AI agent. ElectricSQL enables us to reliably stream agent updates to our spreadsheet in real-time and efficiently manage large spreadsheets at scale. It has dramatically simplified our architecture while delivering the performance we need for cell-level reactive updates.<br><em>— <a href="https://x.com/SullyOmarr" target="_blank" rel="noreferrer">Sully Omar</a>, Co-founder &amp; CEO, <a href="https://ottogrid.ai/" target="_blank" rel="noreferrer">Otto</a></em></p></blockquote><blockquote><p>At <a href="https://www.doorboost.com/" target="_blank" rel="noreferrer">Doorboost</a> we aggregate millions of rows from a dozen platforms, all of which gets distilled down to a simple dashboard. With Electric we have been able to deliver this dashboard in milliseconds and update live. Moving forward, we will be building all our products using Electric.<br><em>— <a href="https://am.linkedin.com/in/vacheasatryan" target="_blank" rel="noreferrer">Vache Asatryan</a>, CTO, <a href="https://doorboost.com/" target="_blank" rel="noreferrer">Doorboost</a></em></p></blockquote><h3 id="scalable" tabindex="-1">Scalable <a href="#scalable" aria-label="Permalink to &quot;Scalable&quot;">​</a></h3><p>So many real-time sync systems demo well but break under real load.</p><p>Electric has been <a href="https://electric-sql.com/docs/api/http">engineered from the ground up</a> to handle high-throughput workloads, like <a href="https://trigger.dev/launchweek/0/realtime" target="_blank" rel="noreferrer">Trigger.dev</a>, with low latency and flat resource use. You can stream real-time data to <strong>millions of concurrent users</strong> from a single commodity Postgres.</p><p>The chart below is from our cloud <a href="https://electric-sql.com/docs/reference/benchmarks">benchmarks</a>, testing Electric's memory usage and latency with a single Electric service scaling real-time sync from 100k to 1 million concurrent clients under a sustained load of 960 writes/minute. Both memory usage and latency are essentially <em>flat</em>:</p><figure></figure><p>You can also see how large-scale apps built with Electric feel to use with our updated <a href="https://electric-sql.com/demos/linearlite"> Linearlite</a> demo. This is a <a href="https://linear.app/" target="_blank" rel="noreferrer">Linear</a> clone that loads 100,000k issues and their comments through Electric into PGlite (~150mb of data). Once loaded, it's fully interactive and feels instant to use:</p><figure><p><a href="https://linearlite.examples.electric-sql.com/" target="_blank"><img src="https://electric-sql.com/assets/linearlite-screenshot.-uynhOsT.png"></a></p><figcaption> Screenshot of Linearlite. <a href="https://linearlite.examples.electric-sql.com/" target="_blank"> Open the demo</a></figcaption></figure><h2 id="easy-to-adopt" tabindex="-1">Easy to adopt <a href="#easy-to-adopt" aria-label="Permalink to &quot;Easy to adopt&quot;">​</a></h2><p>We've iterated a lot on our APIs to make them as simple and powerful as possible. There should be no breaking changes in minor or patch releases moving forward.</p><p>We've updated our <a href="https://electric-sql.com/docs/intro">Documentation</a>, with a new <a href="https://electric-sql.com/docs/quickstart">Quickstart</a> and guides for topics like:</p><ul><li>how to do <a href="https://electric-sql.com/docs/guides/auth">auth</a></li><li>how to handle <a href="https://electric-sql.com/docs/guides/writes">local writes</a></li><li>how to do <a href="https://electric-sql.com/docs/guides/shapes">partial replication with Shapes</a></li><li>how to <a href="https://electric-sql.com/docs/guides/deployment">deploy Electric</a></li><li>how to <a href="https://electric-sql.com/docs/guides/client-development">write your own client</a> for any language or environment</li></ul><p>We have <a href="https://electric-sql.com/docs/api/clients/typescript">client libraries</a>, <a href="https://electric-sql.com/docs/integrations/react">integration docs</a>, <a href="https://electric-sql.com/demos">demo apps</a> and <a href="https://electric-sql.com/demos#technical-examples">technical examples</a> showing how to use Electric with different patterns and frameworks:</p><h4 id="interactive-demos" tabindex="-1">Interactive demos <a href="#interactive-demos" aria-label="Permalink to &quot;Interactive demos&quot;">​</a></h4><div><div target="_blank"><p><a href="https://electric-sql.com/demos/notes"><img src="https://electric-sql.com/img/demos/notes-demo.png"></a></p></div><div target="_blank"><p><a href="https://electric-sql.com/demos/pixel-art"><img src="https://electric-sql.com/img/demos/pixel-art-demo.png"></a></p></div></div><h3 id="incrementally" tabindex="-1">Incrementally <a href="#incrementally" aria-label="Permalink to &quot;Incrementally&quot;">​</a></h3><p>You can adopt Electric one component and one route at a time. Wherever you have code doing something like this:</p><div><p><span>tsx</span></p><pre tabindex="0"><code><span><span>import</span><span> React, { useState, useEffect } </span><span>from</span><span> 'react'</span></span>
<span></span>
<span><span>const</span><span> MyComponent</span><span> =</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>  const</span><span> [</span><span>items</span><span>, </span><span>setItems</span><span>] </span><span>=</span><span> useState</span><span>([])</span></span>
<span></span>
<span><span>  useEffect</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>    const</span><span> fetchItems</span><span> =</span><span> async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>      const</span><span> response</span><span> =</span><span> await</span><span> fetch</span><span>(</span><span>'https://api.example.com/v1/items'</span><span>)</span></span>
<span><span>      const</span><span> data</span><span> =</span><span> await</span><span> response.</span><span>json</span><span>()</span></span>
<span></span>
<span><span>      setItems</span><span>(data)</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    fetchItems</span><span>()</span></span>
<span><span>  }, [])</span></span>
<span></span>
<span><span>  return</span><span> (</span></span>
<span><span>    &lt;</span><span>List</span><span> items</span><span>=</span><span>{ items } /&gt;</span></span>
<span><span>  )</span></span>
<span><span>}</span></span></code></pre></div><p>Swap it out for code like this (replacing the <code>fetch</code> in the <code>useEffect</code> with <a href="https://electric-sql.com/docs/integrations/react"><code>useShape</code></a>):</p><div><p><span>tsx</span></p><pre tabindex="0"><code><span><span>import</span><span> { useShape } </span><span>from</span><span> '@electric-sql/react'</span></span>
<span></span>
<span><span>const</span><span> MyComponent</span><span> =</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>  const</span><span> { </span><span>data</span><span>: </span><span>items</span><span> } </span><span>=</span><span> useShape</span><span>({</span></span>
<span><span>    url: </span><span>'https://electric.example.com/v1/shapes'</span><span>,</span></span>
<span><span>    params: {</span></span>
<span><span>      table: </span><span>'items'</span></span>
<span><span>    }</span></span>
<span><span>  })</span></span>
<span></span>
<span><span>  return</span><span> (</span></span>
<span><span>    &lt;</span><span>List</span><span> items</span><span>=</span><span>{ items } /&gt;</span></span>
<span><span>  )</span></span>
<span><span>}</span></span></code></pre></div><p>This works with <em>any</em> Postgres <a href="https://electric-sql.com/docs/guides/deployment">data model and host</a>, any data type, extension and Postgres feature. Including <a href="https://github.com/pgvector/pgvector" target="_blank" rel="noreferrer">pgvector</a>, <a href="https://postgis.net/" target="_blank" rel="noreferrer">PostGIS</a>, sequential IDs, unique constraints, etc. You don't have to change your data model or your migrations to use Electric.</p><h3 id="with-your-existing-api" tabindex="-1">With your existing API <a href="#with-your-existing-api" aria-label="Permalink to &quot;With your existing API&quot;">​</a></h3><p>Because Electric syncs <a href="https://electric-sql.com/docs/api/http">over HTTP</a>, you can use it together <a href="https://electric-sql.com/blog/2024/11/21/local-first-with-your-existing-api">with your existing API</a>.</p><p>This allows you to handle concerns like <a href="https://electric-sql.com/docs/guides/auth">auth</a> and <a href="https://electric-sql.com/docs/guides/writes">writes</a> with your existing code and web service integrations. You don't need to codify your auth logic into database rules. You don't need to replace your API endpoints and middleware stack.</p><h2 id="take-another-look" tabindex="-1">Take another look <a href="#take-another-look" aria-label="Permalink to &quot;Take another look&quot;">​</a></h2><p>With this BETA release, Electric is stable and ready for prime time use. If you haven't checked it out recently, it's a great time to take another look.</p><h3 id="signup-for-early-access-to-electric-cloud" tabindex="-1">Signup for early access to Electric Cloud <a href="#signup-for-early-access-to-electric-cloud" aria-label="Permalink to &quot;Signup for early access to Electric Cloud&quot;">​</a></h3><p>We're also building <a href="https://electric-sql.com/product/cloud">Electric Cloud</a>, which provides managed Electric hosting (for those that don't want to <a href="https://electric-sql.com/docs/guides/deployment">host Electric themselves</a>).</p><p>If you're interested in using Electric Cloud, you can sign up for early access here:</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WPEngine, Inc. vs. Automattic– Order on Motion for Preliminary Injunction (254 pts)]]></title>
            <link>https://www.courtlistener.com/docket/69221176/64/wpengine-inc-v-automattic-inc/</link>
            <guid>42382829</guid>
            <pubDate>Tue, 10 Dec 2024 23:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.courtlistener.com/docket/69221176/64/wpengine-inc-v-automattic-inc/">https://www.courtlistener.com/docket/69221176/64/wpengine-inc-v-automattic-inc/</a>, See on <a href="https://news.ycombinator.com/item?id=42382829">Hacker News</a></p>
Couldn't get https://www.courtlistener.com/docket/69221176/64/wpengine-inc-v-automattic-inc/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Don't let your billion-dollar ideas die (125 pts)]]></title>
            <link>https://ideaharbor.xyz</link>
            <guid>42382506</guid>
            <pubDate>Tue, 10 Dec 2024 22:45:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ideaharbor.xyz">https://ideaharbor.xyz</a>, See on <a href="https://news.ycombinator.com/item?id=42382506">Hacker News</a></p>
Couldn't get https://ideaharbor.xyz: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Arctic tundra is now emitting more carbon than it absorbs, US agency says (127 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/dec/10/arctic-tundra-carbon-shift</link>
            <guid>42382470</guid>
            <pubDate>Tue, 10 Dec 2024 22:42:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/dec/10/arctic-tundra-carbon-shift">https://www.theguardian.com/world/2024/dec/10/arctic-tundra-carbon-shift</a>, See on <a href="https://news.ycombinator.com/item?id=42382470">Hacker News</a></p>
Couldn't get https://www.theguardian.com/world/2024/dec/10/arctic-tundra-carbon-shift: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[GM exits robotaxi market, will bring Cruise operations in house (341 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/10/gm-halts-funding-of-robotaxi-development-by-cruise.html</link>
            <guid>42381637</guid>
            <pubDate>Tue, 10 Dec 2024 21:19:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/10/gm-halts-funding-of-robotaxi-development-by-cruise.html">https://www.cnbc.com/2024/12/10/gm-halts-funding-of-robotaxi-development-by-cruise.html</a>, See on <a href="https://news.ycombinator.com/item?id=42381637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ArticleBody-InlineImage-108024233" data-test="InlineImage"><p>A in San Francisco, California, US, on Thursday Aug. 10, 2023.</p><p>David Paul Morris | Bloomberg | Getty Images</p></div><div><p>After spending more than $10 billion on its robotaxi unit, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/GM/">General Motors</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> is abandoning its Cruise driverless ride-hailing service.</p><p>The Detroit automaker on Tuesday said it will no longer fund its Cruise division's robotaxi development and will instead fold the unit into its broader tech team. GM shares rose 2.3% in extended trading. </p><p>"Cruise was well on its way to a robotaxi business — but when you look at the fact you're deploying a fleet, there's a whole operations piece of doing that," GM CEO Mary Barra said on a call Tuesday. Barra said GM would instead focus on the development of autonomous systems for use in personal vehicles.</p><p>GM cited the increasingly competitive robotaxi market, capital allocation priorities and the considerable time and resources necessary to grow the business as reasons for its decision.</p><p>The company will combine the majority-owned Cruise LLC with GM technical teams. Barra, who also serves as board chair of Cruise, said the companies have yet to determine how many employees will move to GM. Cruise has nearly 2,300 employees, a GM spokesperson told CNBC.</p><p>GM acquired Cruise in 2016. The automaker currently owns about 90% of Cruise and has agreements with other shareholders that will raise its ownership to more than 97%, GM said <a href="https://news.gm.com/home.detail.html/Pages/news/us/en/2024/dec/1210-gm.html" target="_blank">in a statement</a>. GM anticipates it will complete the acquisition of remaining Cruise shares from outside shareholders by early 2025, CFO Paul Jacobson said Tuesday.</p><p>GM's current annual expenditure on Cruise amounted to about $2 billion, and the restructuring would cut that by more than half, Jacobson said.</p><p>Honda, an outside investor in Cruise, told CNBC that it had planned to launch a driverless ride-hail service in Japan in early 2026, but will now re-assess those plans and make adjustments if needed.</p><p>"Honda remains committed to various research and development initiatives aimed at providing new mobility solutions to our customers in Japan," a Honda spokesperson said on Tuesday. Honda said its total investment in Cruise was $852 million.</p><p>Cruise founder Kyle Vogt, who left the company in November 2023, <a href="https://x.com/kvogt/status/1866612270815494639" target="_blank">posted on X</a> after the announcement, "In case it was unclear before, it is clear now: GM are a bunch of dummies." </p><p>An early entrant in the U.S. robotaxi market, Cruise <a href="https://www.cnbc.com/2023/10/26/cruise-pauses-all-driverless-operations-after-collisions-suspensions.html">grounded its driverless operations</a> in October 2023, shortly before Vogt's departure. The National Highway Traffic Safety Administration fined Cruise $1.5 million after the company failed to disclose details of a <a href="https://www.cnbc.com/2023/10/03/driverless-cruise-car-traps-woman-after-hit-and-run-incident.html">serious crash</a> that month involving a pedestrian.</p><p>A third-party probe into the <a href="https://www.cnbc.com/2024/01/25/gm-cruise-probe-finds-poor-leadership-at-center-of-incident-response.html">incident</a> ordered by GM and Cruise found that culture issues, ineptitude and poor leadership fueled regulatory oversights that led to the accident. The probe also investigated allegations of a cover-up by Cruise leadership but found no evidence to support those claims.</p><p>In July of this year, GM announced that it would <a href="https://www.cnbc.com/2024/07/23/gm-cruise-origin-autonomous-vehicle-indefinitely-delayed.html">indefinitely delay</a> production of the Origin autonomous vehicle as its Cruise self-driving unit attempted&nbsp;<a href="https://www.cnbc.com/2024/04/09/gms-cruise-to-relaunch-vehicles-with-human-drivers-in-phoenix.html">to relaunch operations.</a> At that point, Cruise began to focus on using the next-generation Chevrolet Bolt for development of its autonomous vehicles.</p><p>As Cruise's operations were on hold, its robotaxi rivals gained ground.</p><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-9"><a href="https://www.cnbc.com/quotes/GOOGL/">Alphabet</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>-owned Waymo has begun to operate commercial robotaxi services across several major U.S. metro areas, with the company last week announcing its plans to <a href="https://www.cnbc.com/2024/12/05/waymo-announces-robotaxi-expansion-to-miami.html">expand into Miami</a>. Chinese autonomous vehicle makers including Pony.ai and WeRide have rolled out in overseas markets as well.</p><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-11"><a href="https://www.cnbc.com/quotes/TSLA/">Tesla</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, meanwhile, showed off design concepts for a self-driving Cybercab at <a href="https://www.cnbc.com/2024/10/10/elon-musk-hypes-a-30000-tesla-cybercab-robovan-at-robotaxi-event.html">an event in October</a>. Tesla still classifies the Autopilot and Full Self-Driving software in its vehicles as "partially automated driving systems," which require a human to be ready to steer or brake at all times. In an&nbsp;<a href="https://www.cnbc.com/2024/10/23/tesla-tsla-q3-2024-earnings-report.html">October earnings call</a>, Tesla CEO <a href="https://www.cnbc.com/elon-musk/">Elon Musk</a> said the company will launch a self-driving ride-hailing service in California and Texas as early as 2025.</p><p>SoftBank-funded Wayve is testing its autonomous vehicles in San Francisco, and&nbsp;<a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a>-owned Zoox is also testing its autonomous vehicles, which do not feature steering wheels, in several U.S. cities including San Francisco.</p><p>SoftBank's Vision Fund was also an investor in Cruise, with a nearly 20% stake, until GM <a href="https://www.cnbc.com/2022/03/18/gm-to-buy-softbanks-stake-in-cruise-self-driving-unit.html">repurchased</a> the shares for $2.1 billion in 2022.</p><p><strong>WATCH: </strong><a href="https://www.cnbc.com/video/2024/12/05/uber-and-lyft-drop-on-news-waymo-is-expanding-to-miami.html">Uber and Lyft drop on news Waymo is expanding to Miami</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD's trusted execution environment blown wide open by new BadRAM attack (135 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2024/12/new-badram-attack-neuters-security-assurances-in-amd-epyc-processors/</link>
            <guid>42381406</guid>
            <pubDate>Tue, 10 Dec 2024 20:59:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2024/12/new-badram-attack-neuters-security-assurances-in-amd-epyc-processors/">https://arstechnica.com/information-technology/2024/12/new-badram-attack-neuters-security-assurances-in-amd-epyc-processors/</a>, See on <a href="https://news.ycombinator.com/item?id=42381406">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2065895">
  
  <header>
  <div>
      

      

      <p>
        Attack bypasses AMD protection promising security, even when a server is compromised.
      </p>

      
    </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>One of the oldest maxims in hacking is that once an attacker has physical access to a device, it’s game over for its security. The basis is sound. It doesn’t matter how locked down a phone, computer, or other machine is; if someone intent on hacking it gains the ability to physically manipulate it, the chances of success are all but guaranteed.</p>
<p>In the age of cloud computing, this widely accepted principle is no longer universally true. Some of the world’s most sensitive information—health records, financial account information, sealed legal documents, and the like—now often resides on servers that receive day-to-day maintenance from unknown administrators working in cloud centers thousands of miles from the companies responsible for safeguarding it.</p>
<h2>Bad (RAM) to the bone</h2>
<p>In response, chipmakers have begun baking protections into their silicon to provide assurances that even if a server has been physically tampered with or infected with malware, sensitive data funneled through virtual machines can’t be accessed without an encryption key that’s known only to the VM administrator. Under this scenario, admins inside the cloud provider, law enforcement agencies with a court warrant, and hackers who manage to compromise the server are out of luck.</p>
<p>On Tuesday, an international team of researchers unveiled BadRAM, a proof-of-concept attack that completely undermines security assurances that chipmaker AMD makes to users of one of its most expensive and well-fortified microprocessor product lines. Starting with the AMD Epyc 7003 processor, a feature known as SEV-SNP—short for <a href="https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/white-papers/SEV-SNP-strengthening-vm-isolation-with-integrity-protection-and-more.pdf">Secure Encrypted Virtualization and Secure Nested Paging</a>—has provided the cryptographic means for certifying that a VM hasn’t been compromised by any sort of backdoor installed by someone with access to the physical machine running it.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>If a VM has been backdoored, the cryptographic <a href="https://www.redhat.com/en/blog/attestation-confidential-computing">attestation</a> will fail and immediately alert the VM admin of the compromise. Or at least that’s how SEV-SNP is designed to work. BadRAM is an attack that a server admin can carry out in minutes, using either about $10 of hardware, or in some cases, software only, to cause DDR4 or DDR5 memory modules to misreport during bootup the amount of memory capacity they have. From then on, SEV-SNP will be permanently made to suppress the cryptographic hash attesting its integrity even when the VM has been badly compromised.</p>
<p>“BadRAM completely undermines trust in AMD's latest Secure Encrypted Virtualization (SEV-SNP) technology, which is widely deployed by major cloud providers, including Amazon AWS, Google Cloud, and Microsoft Azure,” members of the research team wrote in an email. “BadRAM for the first time studies the security risks of bad RAM—rogue memory modules that deliberately provide false information to the processor during startup. We show how BadRAM attackers can fake critical remote attestation reports and insert undetectable backdoors into _any_ SEV-protected VM.”</p>
<h2>Compromising the AMD SEV ecosystem</h2>
<p>On a <a href="https://badram.eu/">website</a> providing more information about the attack, the researchers wrote:</p>
<blockquote><p>Modern computers increasingly use encryption to protect sensitive data in DRAM, especially in shared cloud environments with pervasive data breaches and insider threats. AMD's Secure Encrypted Virtualization (SEV) is a cutting-edge technology that protects privacy and trust in cloud computing by encrypting a virtual machine's (VM's) memory and isolating it from advanced attackers, even those compromising critical infrastructure like the virtual machine manager or firmware.</p>
<p>We found that tampering with the embedded SPD chip on commercial DRAM modules allows attackers to bypass SEV protections—including AMD’s latest SEV-SNP version. For less than $10 in off-the-shelf equipment, we can trick the processor into allowing access to encrypted memory. We build on this BadRAM attack primitive to completely compromise the AMD SEV ecosystem, faking remote attestation reports and inserting backdoors into any SEV-protected VM.</p>
<p>In response to a vulnerability report filed by the researchers, AMD has already shipped patches to affected customers, a company spokesperson said. The researchers say there are no performance penalties, other than the possibility of additional time required during boot up. The BadRAM vulnerability is tracked in the industry as CVE-2024-21944 and AMD-SB-3015 by the chipmaker.</p></blockquote>

<h2>A stroll down memory lane</h2>
<p>Modern dynamic random access memory for servers typically comes in the form of DIMMs, short for <a href="https://en.wikipedia.org/wiki/DIMM">Dual In-Line Memory Modules</a>. The basic building block of these rectangular sticks are capacitors, which, when charged, represent a binary 1 and, when discharged, represent a 0. The capacitors are organized into cells, which are organized into arrays of rows and columns, which are further arranged into ranks and banks. The more capacitors that are stuffed into a DIMM, the more capacity it has to store data. Servers usually have multiple DIMMs that are organized into channels that can be processed in parallel.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>For a server to store or access a particular piece of data, it first must locate where the bits representing it are stored in this vast configuration of transistors. Locations are tracked through addresses that map the channel, rank, bank row, and column. For performance reasons, the task of translating these physical addresses to DRAM address bits—a job assigned to the memory controller—isn’t a one-to-one mapping. Rather, consecutive addresses are spread across different channels, ranks, and banks.</p>
<p>Before the server can map these locations, it must first know how many DIMMs are connected and the total capacity of memory they provide. This information is provided each time the server boots, when the BIOS queries the SPD—short for <a href="https://en.wikipedia.org/wiki/Serial_presence_detect">Serial Presence Detect</a>—chip found on the surface of the DIMM. This chip is responsible for providing the BIOS basic information about available memory. BadRAM causes the SPD chip to report that its capacity is twice what it actually is. It does this by adding an extra addressing bit.</p>
<p>To do this, a server admin need only briefly connect a specially programmed <a href="https://www.raspberrypi.com/">Raspberry Pi</a> to the SPD chip just once.</p>
<figure>
    <p><img width="1993" height="1219" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper.jpg 1993w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-640x391.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-1024x626.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-768x470.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-1536x939.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-980x599.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/badram-hardware-spd-tamper-1440x881.jpg 1440w" sizes="auto, (max-width: 1993px) 100vw, 1993px">
                  </p>
          <figcaption>
        <div>
    
    <p>
      The researchers' Raspberry Pi connected to the SPD chip of a DIMM.

              <span>
          Credit:

          
          De Meulemeester et al.

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<h2>Hacking by numbers, 1, 2, 3</h2>
<p>In some cases, with certain DIMM models that don't adequately lock down the chip, the modification can likely be done through software. In either case, the modification need only occur once. From then on, the SPD chip will falsify the memory capacity available.</p>
<p>Next, the server admin configures the operating system to ignore the newly created "ghost memory," meaning the top half of the capacity reported by the compromised SPD chip, but continue to map to the lower half of the real memory. On Linux, this configuration can be done with the `memmap` kernel command-line&nbsp;parameter. The researchers' paper, titled <a href="https://badram.eu/badram.pdf">BadRAM: Practical Memory Aliasing Attacks on Trusted Execution Environments</a>, provides many more details about the attack.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>Next, a script developed as part of BadRAM allows the attacker to quickly find the memory locations of ghost memory bits. These aliases give the attacker access to memory regions that SEV-SNP is supposed to make inaccessible. This allows the attacker to read and write to these protected memory regions.</p>
<p>Access to this normally fortified region of memory allows the attacker to copy the cryptographic hash SEV-SNP creates to attest to the integrity of the VM. The access also permits the attacker to boot an SEV-compliant VM that has been backdoored. Normally, this malicious VM would trigger a warning in the form of a cryptographic hash. BadRAM allows the attacker to replace this attestation failure hash with the attestation success hash collected earlier.</p>
<p>The primary steps involved in BadRAM attacks are:</p>
<ol>
<li>Compromise the memory module to lie about its size and thus trick the CPU into accessing the nonexistent ghost addresses that have been silently mapped to existing memory regions.</li>
<li>Find aliases. These addresses map to the same DRAM location.</li>
<li>Bypass CPU Access Control. The aliases allow the attacker to bypass memory protections that are supposed to prevent the reading of and writing to regions storing sensitive data.</li>
</ol>

<h2>Beware of the ghost bit</h2>
<p>For those looking for more technical details, Jesse De Meulemeester, who along with Luca Wilke was lead co-author of the paper, provided the following, which more casual readers can skip:</p>
<blockquote><p>In our attack, there are two addresses that go to the same DRAM location; one is the original address, the other one is what we call the alias.</p>
<p>When we modify the SPD, we double its size. At a low level, this means all memory addresses now appear to have one extra bit. This extra bit is what we call the "ghost" bit, it is the address bit that is used by the CPU, but is not used (thus ignored) by the DIMM. The addresses for which this "ghost" bit is 0 are the original addresses, and the addresses for which this bit is 1 is the "ghost" memory.</p>
<p>This explains how we can access protected data like the launch digest. The launch digest is stored at an address with the ghost bit set to 0, and this address is protected; any attempt to access it is blocked by the CPU. However, if we try to access the same address with the ghost bit set to 1, the CPU treats it as a completely new address and allows access. On the DIMM side, the ghost bit is ignored, so both addresses (with ghost bit 0 or 1) point to the same physical memory location.</p>
<p>A small example to illustrate this:</p>
<p>Original SPD: 4 bit addresses:<br>
CPU: address 1101 -&gt; DIMM: address 1101</p>
<p>Modified SPD: Reports 5 bits even though it only has 4:<br>
CPU: address 01101 -&gt; DIMM: address 1101<br>
CPU: address 11101 -&gt; DIMM: address 1101</p>
<p>In this case 01101 is the protected address, 11101 is the alias. Even though to the CPU they seem like two different addresses, they go to the same DRAM location.</p></blockquote>
<p>As noted earlier, some DIMM models don't lock down the SPD chip, a failure that likely makes software-only modifications possible. Specifically, the researchers found that two DDR4 models made by Corsair contained this flaw.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>In a statement, AMD officials wrote:</p>
<blockquote><p>AMD believes exploiting the disclosed vulnerability requires an attacker either having physical access to the system, operating system kernel access on a system with unlocked memory modules, or installing a customized, malicious BIOS. AMD recommends utilizing memory modules that lock Serial Presence Detect (SPD), as well as following physical system security best practices. AMD has also released firmware updates to customers to mitigate the vulnerability.</p></blockquote>
<p>Members of the research team are from KU Leuven, the University of Lübeck, and the University of Birmingham. Specifically, they are:</p>
<ul>
<li><a href="https://www.esat.kuleuven.be/cosic/people/person/?u=u0156850">Jesse De Meulemeester</a> (<a href="https://www.esat.kuleuven.be/cosic/">COSIC</a>, <a href="https://www.esat.kuleuven.be/english">Department of Electrical Engineering</a>, <a href="https://www.kuleuven.be/english/kuleuven/index.html">KU Leuven</a>)</li>
<li><a href="https://luca-wilke.com/">Luca Wilke</a> (<a href="https://www.its.uni-luebeck.de/en/institute">University of Lübeck</a>)</li>
<li><a href="https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/oswald-david">David Oswald</a> (<a href="https://www.birmingham.ac.uk/">University of Birmingham</a>)</li>
<li><a href="https://www.its.uni-luebeck.de/en/staff/thomas-eisenbarth">Thomas Eisenbarth</a> (<a href="https://www.its.uni-luebeck.de/en/institute">University of Lübeck</a>)</li>
<li><a href="https://www.esat.kuleuven.be/cosic/people/person/?u=u0018159">Ingrid Verbauwhede</a> (<a href="https://www.esat.kuleuven.be/cosic/">COSIC</a>, <a href="https://www.esat.kuleuven.be/english">Department of Electrical Engineering</a>, <a href="https://www.kuleuven.be/english/kuleuven/index.html">KU Leuven</a>)</li>
<li><a href="https://vanbulck.net/">Jo Van Bulck</a> (<a href="https://distrinet.cs.kuleuven.be/">DistriNet</a>, <a href="https://wms.cs.kuleuven.be/cs/english">Department of Computer Science</a>, <a href="https://www.kuleuven.be/english/kuleuven/index.html">KU Leuven</a>)</li>
</ul>
<p>The researchers tested BadRAM against the Intel SGX, a competing microprocessor sold by AMD's much bigger rival promising integrity assurances comparable to SEV-SNP. The classic, now-discontinued version of the SGX did allow reading of protected regions, but not writing to them. The current Intel Scalable SGX and Intel TDX processors, however, allowed no reading or writing. Since a comparable Arm processor wasn't available for testing, it's unknown if it's vulnerable.</p>
<p>Despite the lack of universality, the researchers warned that the design flaws underpinning the BadRAM vulnerability may creep into other systems and should always use the mitigations AMD has now put in place.</p>
<p>"Since our BadRAM primitive is generic, we argue that such countermeasures should be considered when designing a system against untrusted DRAM," the researchers wrote in their paper. "While advanced hardware-level attacks could potentially circumvent the currently used countermeasures, further research is required to judge whether they can be carried out in an impactful attacker model."</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/dan-goodin/"><img src="https://arstechnica.com/wp-content/uploads/2018/10/Dang.jpg" alt="Photo of Dan Goodin"></a></p>
  </div>

  <div>
    

    <p>
      Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene. Dan is based in San Francisco. Follow him at <a href="https://infosec.exchange/@dangoodin" rel="me">here</a> on Mastodon and <a href="https://bsky.app/profile/dangoodin.bsky.social">here</a> on Bluesky. Contact him on Signal at DanArs.82.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/information-technology/2024/12/new-badram-attack-neuters-security-assurances-in-amd-epyc-processors/#comments" title="80 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    80 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2024/12/intrigue-swirls-as-blue-origin-races-toward-year-end-deadline-for-new-glenn/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/1733771570623-768x432.jpg" alt="Listing image for first story in Most Read: In a not-so-subtle signal to regulators, Blue Origin says New Glenn is ready" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>


  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running Durable Workflows in Postgres Using DBOS (168 pts)]]></title>
            <link>https://supabase.com/blog/durable-workflows-in-postgres-dbos</link>
            <guid>42379974</guid>
            <pubDate>Tue, 10 Dec 2024 18:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://supabase.com/blog/durable-workflows-in-postgres-dbos">https://supabase.com/blog/durable-workflows-in-postgres-dbos</a>, See on <a href="https://news.ycombinator.com/item?id=42379974">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p><img alt="Running Durable Workflows in Postgres using DBOS" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" srcset="https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=256&amp;q=100 256w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=384&amp;q=100 384w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=640&amp;q=100 640w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=750&amp;q=100 750w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=828&amp;q=100 828w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=1080&amp;q=100 1080w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=1200&amp;q=100 1200w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=1920&amp;q=100 1920w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=2048&amp;q=100 2048w, https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=3840&amp;q=100 3840w" src="https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fdbos%2Fog.png&amp;w=3840&amp;q=100"></p><p>Michael Stonebraker is the inventor of Postgres and a Turing Award winner. His latest venture is <a href="https://www.dbos.dev/">DBOS</a>, a three-year joint research project between Stanford and MIT. The DBOS team have built a Durable Workflow engine using Postgres. It's one of the of the more elegant designs I've seen, leveraging the features of Postgres to keep it lightweight and fast.</p>
<p>The DBOS team have released a Supabase integration, so you can use your Postgres database as a durable workflow engine.</p>
<!-- -->
<p><strong>Continue reading or just get started?</strong></p>
<p>I really love the design of DBOS, so I'm going to write more below. Their design is aligned with our philosophy at Supabase: “just use Postgres”. I'll take you through the lower-level details in the rest of this post. If you just want to get started using DBOS with Supabase, get started using their tutorial:</p>
<p><a href="https://docs.dbos.dev/integrations/supabase">Use DBOS With Supabase →</a></p>

<p>Let's start with a common situation where a workflow is useful: you're running an e-commerce platform where an order goes through multiple “steps”:</p>
<!-- -->
<p>The process is simple, but writing a <em>robust</em> program for this is surprisingly difficult. Some potential problems:</p>
<ul>
<li>You get to step 2, “Check Inventory”, and you're out of stock. You need to wait 24 hours for the new inventory before you can ship it. You need that “step” to sleep for a day.</li>
<li>Your program crashes during step 3, “Ship Order”, and it doesn't record that you've shipped the inventory. You end up sending the same order twice.</li>
</ul>
<p>A Durable Workflow Engine helps with these problems (and more). There are a few on the market that provide different architectures like <a href="https://trigger.dev/">Trigger.dev</a>, <a href="https://www.inngest.com/">Inngest</a>, <a href="https://www.windmill.dev/">Windmill</a>, <a href="https://temporal.io/">Temporal</a>, and <a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a>.</p>
<p>DBOS offers a relatively unique approach to Workflows, storing the state in your own Postgres database. Let's explore how DBOS does it.</p>

<p>DBOS is a platform where you can write your programming logic in serverless functions (similar to Supabase Edge Functions). Functions can be written in either <a href="https://docs.dbos.dev/python/programming-guide">Python</a> or <a href="https://docs.dbos.dev/typescript/programming-guide">TypeScript</a>.</p>
<h3 id="creating-workflows-with-decorators">Creating workflows with decorators</h3>
<p>One thing that's different to Supabase Edge Functions is the ability to add <strong>decorators</strong> to your Functions with <code>DBOS.step()</code> and <code>DBOS.workflow()</code>:</p>
<!-- -->
<p>When you do this, DBOS stores the “state” of every step in Postgres:</p>
<!-- -->
<p>This is the part I find the most interesting! If you're a gamer, it's a bit like having a “<a href="https://en.wikipedia.org/wiki/Saved_game">save point</a>” in your programs. If a Function fails at any point, a new Function can start, picking up at the last checkpoint.</p>
<!-- -->
<h3 id="storing-function-state-in-postgres">Storing function state in Postgres</h3>
<p>When you create an application with DBOS, they create a new database inside your Postgres cluster for storing this state.</p>
<p>Using their “Widget Store” example, you can see two new databases -</p>
<ol>
<li><code>widget_store</code>: for storing the application data</li>
<li><code>widget_store_dbos_sys</code>: for storing the workflow state.</li>
</ol>
<!-- -->
<p>The <code>widget_store_dbos_sys</code> database holds the workflow state:</p>
<!-- -->
<h3 id="workflow-logic"><strong>Workflow logic</strong></h3>
<p>The DBOS team were kind enough to share some of the logic with me about how their workflow engine works:</p>
<ol>
<li>When a workflow starts, it generates a unique ID and stores it in a Postgres <code>workflow_status</code> table with a <code>PENDING</code> status. It also stores its inputs in Postgres.</li>
<li>Each time a step completes, it stores its output in a Postgres <code>operation_outputs</code> table.</li>
<li>When a workflow completes, it updates its status in the Postgres <code>workflow_status</code> table to <code>SUCCESS</code> (or to <code>ERROR</code>, if it threw an uncaught exception).</li>
</ol>
<h3 id="error-logic">Error logic</h3>
<p>If a program is interrupted, on restart the DBOS library launches a background thread that resumes all incomplete workflows from the last completed step.</p>
<ol>
<li>It queries Postgres to find all <code>PENDING</code> workflows, then starts each one. Because workflows are just Python functions, it can restart a workflow by simply calling the workflow function with its original inputs, retrieved from Postgres.</li>
<li>As a workflow re-executes, before trying each step, it first checks Postgres to see if that step was previously executed. If it finds the step in Postgres, it doesn't re-execute the step, instead re-using its original output.</li>
<li>Eventually, the workflow reaches the first step whose output isn't stored in Postgres and resumes execution from there - “resuming from the last completed step.”</li>
</ol>
<p>All this works because workflows are deterministic, so they can re-execute them using stored step outputs to recover their pre-interruption state.</p>
<h2 id="the-benefits-of-using-postgres">The benefits of using Postgres</h2>
<p>DBOS isn't the first to create a workflow engine. Others in the market include <a href="https://temporal.io/">Temporal</a> and <a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a>. DBOS provides a number of benefits over workflow engines that use external orchestrators like AWS Step Functions:</p>
<h3 id="performance">Performance</h3>
<p>Because a step transition is just a Postgres write (~1ms) versus an async dispatch from an external orchestrator (~100ms), it means DBOS is <a href="https://www.dbos.dev/blog/dbos-vs-aws-step-functions-benchmark">25x faster than AWS Step Functions</a>:</p>
<!-- -->
<h3 id="exactly-once-execution">Exactly-once execution</h3>
<p>DBOS has a special <code>@DBOS.Transaction</code> decorator. This runs the entire step inside a Postgres transaction. This guarantees exactly-once execution for databases transactional steps.</p>
<h3 id="idempotency">Idempotency</h3>
<p>You can set an idempotency key for a workflow to guarantee it executes only once, even if called multiple times with that key. Under the hood, this works by setting the workflow's unique ID to your idempotency key.</p>
<h3 id="other-postgres-features">Other Postgres features</h3>
<p>Since it's all in Postgres, you get all the tooling you're familiar with. Backups, GUIs, CLI tools - you name it. It all “just works”.</p>

<p>To get started with DBOS and Supabase, check out their official integration docs:</p>
<p><a href="https://docs.dbos.dev/integrations/supabase">Use DBOS With Supabase →</a></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Digital consumption keeps me from getting better at my job (286 pts)]]></title>
            <link>http://sibervepunk.com/digital-consumption.html</link>
            <guid>42379970</guid>
            <pubDate>Tue, 10 Dec 2024 18:46:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://sibervepunk.com/digital-consumption.html">http://sibervepunk.com/digital-consumption.html</a>, See on <a href="https://news.ycombinator.com/item?id=42379970">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>
    <time datetime="2024-07-31 00:00:00 +0000">31.07.2024</time>
  </p>

  

  <blockquote>
  <p>know thyself</p>
</blockquote>

<p>There is a new lifestyle imposed on almost the entire world, willingly or unwillingly, perhaps by powerful people or by many small people that want to be powerful, which somehow affects all ordinary people: a consumption-oriented life. Fast consumption, constant consumption, more consumption.</p>

<p>I don’t have much to say about the “shopping” side of this consumption craze because it’s a topic that’s been around for many years, born out of  <em>-ism</em> movements and studied numerous times through  <em>-ology</em> disciplines. It has been the subject of public service announcements, romantic comedies, and personal development books. The public has been constantly educated about it for years. Two guys known as The Minimalists and some “smart” people like Marie Kondo made a fortune out of this movement. Personally, I believe I am a conscious consumer, and the shopping craze doesn’t affect me much, so I want to look at the other, often-discussed side of the issue.</p>

<p>The consumption I will discuss is digital content, information, and emotion/thought consumption. I know there are social science studies that delve into the intersections and background connections of all these consumptions, but as an ordinary person, I want to talk about the effects on my own life, particularly my professional development.</p>

<p>Although it has been on my mind for a long time, I haven’t been able to read a comprehensive book based on these studies (<em>the reason being the vicious cycle based on this topic</em>), but I have consumed plenty of content… I’ve watched various TED talks, several indie YouTuber videos with a wholesome background, selling personal development under the hood on their newly launched channels, and of course, read tweets… I’ve also had plenty of opportunities to observe myself.</p>

<p>At this point I am convinced that fast consumption is harmful to the brain, mind, and soul.</p>

<p>The main reason I pursue this topic is that, aside from all the side effects in personal life, it also prevents me from being better at my profession as a brain-worker as Jules Payot puts it.</p>

<p>In disciplines like software engineering, constantly improving oneself and being in a state of continuous learning is an inevitable process. Even if you don’t put in extra effort and just try to do your job, you have to learn a new concept or technology. If you do put in the extra effort, you become someone who does their job better. Since graduating from undergraduate studies <em>(which marks exactly one year as I write this post)</em>, putting in extra effort has been my top priority. Working more, reading more, knowing more. In addition to technical studies, I also read about and received advice on soft skills related to “software crafting.” One of my first mistakes, I think, was taking every kind of advice from everyone. Even if I didn’t implement them directly, these pieces of advice took up space in my mind, and thinking “what if that’s better” prevented me from putting any of them into practice.</p>

<p>The problem with online advice is that the person writing the blog post is doing so entirely from their own perspective and lifestyle. They have no idea about you, and you have no idea about them. There’s no guarantee that what works for them will work for you. Moreover, you don’t get a chance to question causality, you just read the advice, consume it, and move on. It takes up space in your mind and on your to-do list, but you don’t get a chance to internalize or filter this topic. You don’t even realize that you should actually do so.</p>

<p>One of the pieces of advice I took without realizing it was to systematize the mentioned studies, work regularly, and similar. Once that idea put in my mind, things became complicated for me. While working full-time, I had to balance my personal life and stick to the plan.</p>

<p>No matter how much your willpower sticks to the plan, your health, developments in your life, and your brain, which sometimes refuses to accept more information, don’t always stick to the plan. When this happens, it becomes difficult to establish the system I mentioned, and you start looking for more advice, reading more blogs. <strong>You find yourself in a quest for productivity, feeling productive because of the quest, but not really doing any productive work.</strong></p>

<p>Advice also has the effect of reducing creativity and problem-solving skills. When I have a problem, technical or other, the first thing I do is research the solution. As a result, I don’t get enough chance to think about my problem, let alone produce a solution, and I don’t fully understand the problem.</p>

<p>I’ve “consumed” what I should do and how I should do it many times from different people. With all this information occupying my brain, I no longer had the energy and resources to produce a tangible output.</p>

<hr>

<p>Because of my profession, I like learning different concepts from different fields. I am particularly curious about the low-level infrastructures and systems behind high-level tools, and I am aware of the contribution of knowing these to doing my job well. However, because of the constant rush and haste imposed by social media in my life, I can’t devote enough time to these resources. Because I am so used to seeing information, quickly taking it in, and moving on to another topic. Because the short content I constantly consume, whether written or visual, has made me accustomed to this. <br>
While reading a technically deep book, re-reading the same page feels like a waste of time; every piece of information I have to go over because I couldn’t understand it at once makes me feel inadequate and late because I can’t just scroll past it.</p>

<p>I want to know everything, immediately, quickly. Since this is not humanly possible, I end up doing nothing.</p>

<p>I can’t think long-term; I can’t stop myself from thinking that working on a book for 6 months, doing its projects, is a huge waste of time for me, and because I already feel late, I find myself, yet again, in a cycle.</p>

<hr>

<p>When I’m focused solely on consuming, my ability to produce naturally decreases. I include speaking, being able to express oneself, and having a good command of words in this context. After knowing myself as someone who has always been good with words for years, seeing that I can’t choose the right word when speaking, or that I can’t convey the message or information I want to give more clearly and simply when writing, naturally bothers me. Although it is said that software development is an antisocial job, you constantly need to communicate with people, either in writing or verbally, and you need to express what you have done and what you will do well. I am approaching the point of losing this skill by consuming instead of producing.</p>

<hr>

<p>While all this disrupts progress and confuses my mind, I also have to deal with the physical and mental side effects of fast consumption. Difficulty concentrating, lack of focus, inability to understand what I read, stress, anxiety. I see these kinds of complaints from many people lately, and in my opinion, our biggest common ground is digital content consumption.</p>

<p>The relativity of time is a reality I feel to the core while doom scrolling. Besides the lost time, there’s the confusion after realizing it and putting the phone down, trying to get my dazed mind back to normal. And then, not finding anything to do, not being able to putting yourself together, and reaching for the phone again.</p>

<p>Everyone has seen the articles about the brain’s approach to social media content, which offers a quick, easily accessible way that makes you happy or, even if it doesn’t make you happy, offers an escape from the thing that makes you unhappy.</p>

<p>When you put these into words or write them down, it bothers you a lot, but I think knowing yourself is the most important thing to do before changing yourself. I know what I’m doing wrong, and now it’s documented in front of me. I also know what I need to work on.</p>



<p>We are talking about the harms, but I have always been fascinated by the opportunities the internet offers. Being able to communicate and chat with someone from anywhere in the world within seconds is an invaluable blessing. It just takes a little effort to filter to see and reach the right people’s content. Otherwise, I don’t think completely withdrawing would be very beneficial in my industry and the era I live in.</p>

<hr>

<p>I won’t go against what I mentioned so I won’t end this problem-filled post with advice or plans. That’s why I started with the quote “know thyself.” I just tried to see and make the problem tangible. I will stop researching what I can do for a while. First, I plan to clear my mind of clutter, quit this fast and excessive consumption habit I have acquired without realizing it, and then learn how to consume slowly and gradually. I have enough raw information to discover how to do all this myself; I will now give myself the opportunity to process it.</p>

</article><p>
    Thanks for reading. If you have any feedback or would like to discuss
    further, I would be happy to hear from you. <br>
    <!-- insert social links (twitter and email) -->
    </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canvas (160 pts)]]></title>
            <link>https://openai.com/index/introducing-canvas/</link>
            <guid>42379361</guid>
            <pubDate>Tue, 10 Dec 2024 18:01:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-canvas/">https://openai.com/index/introducing-canvas/</a>, See on <a href="https://news.ycombinator.com/item?id=42379361">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-canvas/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Devin is now generally available (144 pts)]]></title>
            <link>https://www.cognition.ai/blog/devin-generally-available</link>
            <guid>42378994</guid>
            <pubDate>Tue, 10 Dec 2024 17:30:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cognition.ai/blog/devin-generally-available">https://www.cognition.ai/blog/devin-generally-available</a>, See on <a href="https://news.ycombinator.com/item?id=42378994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
<p><img src="https://www.cognition.ai/_astro/generally-available.CHJ0T34J_Z1rnVDi.webp" alt="Devin is generally available" width="1600" height="900" loading="lazy" decoding="async"></p>
<p> Today we’re making Devin generally available starting at $500 a month for engineering teams, which includes: </p>
<ul>
<li>No seat limits</li>
<li>Access to Devin’s Slack integration, IDE extension, and <a href="https://www.cognition.ai/blog/dec-24-product-update#for-repetitive-engineering-tasks-try-the-devin-api-with-structured-inputoutput">API</a></li>
<li>Onboarding session &amp; support from the Cognition engineering team</li>
</ul>
<p> All engineering teams can now start working with Devin at <a href="https://app.devin.ai/" rel="noopener noreferrer" target="_blank">app.devin.ai</a>. </p>
<h2>  </h2> 
<p> While Devin can be an all-purpose tool, we recommend starting with: </p>
<ul>
<li><strong>Small frontend bugs and edge cases</strong> - tag Devin in Slack threads</li>
<li><strong>Creating first-draft PRs for backlog tasks</strong> - assign Devin tasks from your todo list at the start of your day</li>
<li><strong>Making targeted code refactors</strong> - use the Devin IDE extension (for VSCode and forks) to point Devin to parts of the code you want edited or upgraded</li>
</ul>
<p> Devin has helped teams with everything from building integrations to migrating and maintaining documentation. Devin is versatile, but works best when you: </p>
<ul>
<li>Give Devin tasks that you know how to do yourself</li>
<li>Tell Devin how to test or check its own work</li>
<li>Keep sessions under ~3 hours and break down large tasks</li>
<li>Share detailed requirements upfront</li>
<li>Invest in coaching Devin by providing feedback in chat and accepting suggested <a href="https://docs.devin.ai/Onboard_Devin/knowledge">Knowledge</a>, or adding your own Knowledge manually</li>
</ul>
<h2>  </h2> 
<p> Slack is the primary interface for spinning up Devin sessions, so you can quickly tag @devin to offload smaller tasks and fix bugs when they’re reported. </p>
<p> Try asking Devin to do the first pass on the next 3rd party integration, refactor, or codebase question you have. Devin messages you when it’s done, so you can review Devin’s PR whenever convenient. Devin responds automatically to your Github PR comments. </p>
<lite-youtube videoid="xTbpGq09g88"> <a href="https://youtube.com/watch?v=xTbpGq09g88"> <span></span> </a> </lite-youtube>  

<p> Hand off async work to Devin directly from your IDE with ⌘ G. The Devin extension (Beta Feature available for VScode and forks) allows you to checkout Devin’s PRs and review and accept Devin’s code directly in your IDE. </p>
<lite-youtube videoid="0e6Vx4rngm8"> <a href="https://youtube.com/watch?v=0e6Vx4rngm8"> <span></span> </a> </lite-youtube>  
<h2>  </h2> 
<p> To showcase Devin in action, we’re sharing sessions where Devin resolves issues on a few of our favorite open-source repositories. Devin often needs guidance but we share these examples to show how we use Devin to speed our own workflows. </p>
<p> <em><strong>Anthropic MCP</strong></em> </p>
<p> In this session, Devin identifies the cause of a user-reported issue. We liked how it read the MCP spec in the browser to understand “capability negotiation” and tested its changes end-to-end in the browser. The changes weren’t perfect, so the maintainers gave some feedback on the PR which we addressed with a second Devin session. </p>
<p> First session: <a href="https://app.devin.ai/sessions/266955553baf40cfa7fdd32d42ab219d">https://app.devin.ai/sessions/266955553baf40cfa7fdd32d42ab219d</a> </p>
<p> Second session: <a href="https://app.devin.ai/sessions/807168f5f9874d47a4c1965bf7afc9df">https://app.devin.ai/sessions/807168f5f9874d47a4c1965bf7afc9df</a> </p>
<p> <a href="https://github.com/modelcontextprotocol/inspector/pull/105">https://github.com/modelcontextprotocol/inspector/pull/105</a> </p>
<p> <img src="https://cdn.sanity.io/images/2mc9cv2v/production/c7c887019189c18355d40cf904fba5448f21d5f5-2014x168.png?w=1600&amp;fit=max" alt="Devin's PR to Anthropic MCP"> </p>

<p> <em><strong>Zod</strong></em> </p>
<p> This PR adds a new feature to the popular library Zod. Devin planned collaboratively with the user, implemented the feature across multiple files and wrote tests – we were very impressed! There was a merge conflict which we manually resolved because Devin tends to struggle with that. </p>
<p> <a href="https://app.devin.ai/sessions/51826709fcd3457abc4be25e587c790c">https://app.devin.ai/sessions/51826709fcd3457abc4be25e587c790c</a> </p>
<p> <a href="https://github.com/colinhacks/zod/pull/3893">https://github.com/colinhacks/zod/pull/3893</a> </p>
<p> <img src="https://cdn.sanity.io/images/2mc9cv2v/production/3411a1a87aa611878f7658e15649177b428bf706-1736x168.png?w=1600&amp;fit=max" alt="Devin's PR to Zod"> </p>

<p> <em><strong>Google</strong></em> </p>
<p> A user of the Go Github client wished it propagated response objects even on HTTP errors. These small chores are annoying for human engineers because testing is often more effort than the fix itself. Devin required a few iterations to get it right and we manually cleaned up a few stray edits using the VS Code extension. The biggest timesaver here was Devin writing and running the unit tests. </p>
<p> <a href="https://app.devin.ai/sessions/1b2f7ce6e3b44942b3ac1f518eac7c22">https://app.devin.ai/sessions/1b2f7ce6e3b44942b3ac1f518eac7c22</a> </p>
<p> <a href="https://github.com/google/go-github/pull/3369">https://github.com/google/go-github/pull/3369</a> </p>
<p> <img src="https://cdn.sanity.io/images/2mc9cv2v/production/18a73299e1ab51f155303433d963ed6069e18480-1854x168.png?w=1600&amp;fit=max" alt="Devin's PR to Google"> </p>

<p> <em><strong>Llama Index</strong></em> </p>
<p> Devin fixes a bug where the implementation of the Anthropic tokenizer followed the protocol incorrectly. It found the correct fix first try and wrote a unit test too. A PR comment from the maintainer requested a small stylistic change which we fixed manually. </p>
<p> <a href="https://app.devin.ai/sessions/3d66de6feed946efbadf8a58698caafc">https://app.devin.ai/sessions/3d66de6feed946efbadf8a58698caafc</a> </p>
<p> <a href="https://github.com/run-llama/llama_index/pull/17201">https://github.com/run-llama/llama_index/pull/17201</a> </p>
<p> <img src="https://cdn.sanity.io/images/2mc9cv2v/production/dc90640bf91bd47cdea29e98fc3b60aaf7cd8107-2042x168.png?w=1600&amp;fit=max" alt="Devin's PR to Llama Index"> </p>

<p> <em><strong>Karpathy’s nanoGPT</strong></em> </p>
<p> This change is just a one-liner. But we wouldn’t trust this change without testing – which Devin did nicely by writing an ad-hoc testing script. </p>
<p> <a href="https://app.devin.ai/sessions/9e0c3255385c463f838f5b2f4413b92f">https://app.devin.ai/sessions/9e0c3255385c463f838f5b2f4413b92f</a> </p>
<p> <a href="https://github.com/karpathy/nanoGPT/pull/578">https://github.com/karpathy/nanoGPT/pull/578</a> </p>
<p> <img src="https://cdn.sanity.io/images/2mc9cv2v/production/5a31675b672e516ea4fcb974ecfedb90b78a0c01-1712x168.png?w=1600&amp;fit=max" alt="Devin's PR to Karpathy's nanoGPT"> </p>
<h2>  </h2> 
<p> You can start working with Devin today at <a href="https://app.devin.ai/" rel="noopener noreferrer" target="_blank">app.devin.ai</a>. </p>
<p> For more information about <a href="https://devin.ai/enterprise">Devin Enterprise</a>, reach out to our Sales team <a href="https://cognition.ai/get-started#company">here</a>. </p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. math scores drop on major international test (323 pts)]]></title>
            <link>https://www.chalkbeat.org/2024/12/04/timss-international-test-result-us-math-scores-decline-post-pandemic/</link>
            <guid>42378929</guid>
            <pubDate>Tue, 10 Dec 2024 17:24:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chalkbeat.org/2024/12/04/timss-international-test-result-us-math-scores-decline-post-pandemic/">https://www.chalkbeat.org/2024/12/04/timss-international-test-result-us-math-scores-decline-post-pandemic/</a>, See on <a href="https://news.ycombinator.com/item?id=42378929">Hacker News</a></p>
Couldn't get https://www.chalkbeat.org/2024/12/04/timss-international-test-result-us-math-scores-decline-post-pandemic/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Limbo: A complete rewrite of SQLite in Rust (336 pts)]]></title>
            <link>https://turso.tech/blog/introducing-limbo-a-complete-rewrite-of-sqlite-in-rust</link>
            <guid>42378843</guid>
            <pubDate>Tue, 10 Dec 2024 17:16:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://turso.tech/blog/introducing-limbo-a-complete-rewrite-of-sqlite-in-rust">https://turso.tech/blog/introducing-limbo-a-complete-rewrite-of-sqlite-in-rust</a>, See on <a href="https://news.ycombinator.com/item?id=42378843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>2 years ago, we forked SQLite. We were huge fans of the embedded nature of SQLite, but longed for a more open model of development. <a href="https://github.com/tursodatabase/libsql">libSQL</a> was born as an Open Contribution project, and we invited the community to build it with us.</p>
<p>As a result, libSQL is an astounding success. With over 12k Github stars, 85 contributors, and features like native replication and vector search, libSQL is the engine that powers the <a href="https://turso.tech/">Turso</a> platform.</p>
<p>Today we are announcing a more ambitious experiment: what could we achieve, if we were to completely <em>rewrite</em> SQLite in a memory-safe language (Rust)? With the Limbo project, now available at <a href="https://github.com/tursodatabase/limbo">github.com/tursodatabase/limbo</a>, we are now trying to answer that question.</p>
<h2 id="the-pros-and-cons-of-forking"><a href="#the-pros-and-cons-of-forking">#</a>The pros and cons of forking</h2>
<p>When we forked SQLite, forking was not the only alternative. We considered rewriting it entirely, but were concerned about the huge lead time needed to have something production-ready, and the toil involved in keeping compatibility. A fork would also allow us to keep back-merging from SQLite, adopting new features as they come.</p>
<p>On the other hand, there are disadvantages as well: SQLite’s test suite is proprietary, meaning that it is hard to achieve the confidence to make very large changes. It is also written in C, an unsafe language, which makes evolving the codebase with confidence even harder.</p>
<p>Weighing the pros and cons, forking was the way to go, and the libSQL project was born.</p>
<h2 id="a-new-approach"><a href="#a-new-approach">#</a>A new approach</h2>
<p>Adding Vector search to SQLite was an eye opener. We didn’t want to do this as an extension, since we wanted to make the syntax as straightforward and natural as possible. That would require changes to the bytecode generation, which we did. We are able to expose vectors as a data type, query relational and vector data together in the same table, and as long as the query doesn’t need an index, use perfectly boring SQL syntax.</p>
<p>But for searches with an index, without making very invasive changes, it was hard to achieve the syntax that we wanted:</p>
<pre><code><span>SELECT</span> title, <span>year</span>
   <span>FROM</span> movies
   <span>ORDER</span> <span>BY</span> vector_distance_cos(embedding, vector(<span>'[4,5,6]'</span>))
   LIMIT <span>3</span>;
</code></pre>
<p>And we ended up settling for</p>
<pre><code><span>SELECT</span> title, <span>year</span>
   <span>FROM</span> vector_top_k(<span>'movies_idx'</span>, vector(<span>'[4,5,6]'</span>), <span>3</span>)
   <span>JOIN</span> movies
   <span>ON</span> movies.rowid <span>=</span> id;
</code></pre>
<p>The index is represented as a separate table, and we have to explicitly join it with the main table.</p>
<p>At that point, we decided to try a new approach and answer the question: how much effort was it <em>really</em> involved in rewriting SQLite from scratch ? And can we do it in a way that effortlessly keeps compatibility? Would that make it easier for us to be more aggressive and do some of the things we wanted to do in our fork (like asynchronous I/O) with a high degree of confidence?</p>
<p>To answer those questions, Pekka started an ambitious experiment on hist <a href="https://github.com/penberg/limbo">personal github account</a>. It was named Limbo as a codename temporarily, and it did extremely well. Without much press, just me talking about it on 𝕏, the project grew to 1,000 github stars, and attracted more than 30 contributors organically.</p>
<h2 id="the-next-step"><a href="#the-next-step">#</a>The next step</h2>
<p>With the success of this experiment, we have decided to turn Limbo into an official project at Turso. It is still an experiment, but now an official Turso experiment, which will allow us to pour more resources into it, including more time from other engineers in the company.</p>
<p>Our goal is to build a reimplementation of SQLite from scratch, fully compatible at the language and file format level,  with the same or higher reliability SQLite is known for, but with full memory safety and on a new, modern architecture.</p>
<p>That is not to say that we’re building a competitor or alternative to libSQL: if it succeeds, this codebase just becomes libSQL. The code is available under the same license as libSQL (MIT), and with the same community-friendly attitude that defined our project.</p>
<h2 id="can-we-match-sqlite-s-world-famous-reliability-"><a href="#can-we-match-sqlite-s-world-famous-reliability-">#</a>Can we match SQLite’s world-famous reliability?</h2>
<p>Since this is a reimplementation, doesn’t that mean that testing is now even harder? The reality is that it is the other way around. Since we are reimplementing it from scratch, we are doing it with Deterministic Simulation Testing (DST) built-in from the get-go. We have both added DST facilities to the core of the database, and partnered with Antithesis to achieve a level of reliability in the database that lives up to SQLite’s reputation.</p>
<p>Deterministic Simulation Testing is a paradigm made famous by the folks at <a href="https://tigerbeetle.com/">TigerBeetle</a>, that we at Turso already dipped our toes into with our <a href="https://turso.tech/blog/a-deep-look-into-our-new-massive-multitenant-architecture">server-side code</a>. With DST, we believe we can achieve an even higher degree of robustness than SQLite, since it is easier to simulate unlikely scenarios in a simulator, test years of execution with different event orderings, and upon finding issues, reproduce them 100% reliably.</p>
<p>In the DST world, writing our own simulator is akin to writing unit tests: they allow us to move fast, experiment easily, and stress changes thoroughly. But much as unit testing does not do away with the need for higher level integration testing that tests the behavior of the system at a higher level, we felt like we needed to go the extra mile to achieve the levels of reliability that we wanted.</p>
<p>To complete the puzzle, we wanted to deterministically test the behavior of the database when interacting with the operating system and other components. To do that, we are partnering with <a href="https://antithesis.com/">Antithesis</a>, a company that provides a system-level Deterministic Simulation Testing framework, and can simulate all sorts of hardware and software failures. Antithesis does that by providing a deterministic hypervisor that runs many fuzzing threads in parallel, allowing us to quickly search the input space.</p>
<p>As an example of why this is important, they have already helped us find issues in our <code>io_uring</code> implementation under partial writes. Our own DST framework would not have caught this, since the actual I/O loop is replaced by the simulated I/O loop in testing. Partial writes are an extremely rare condition, and therefore, hard to test in an automated fashion.</p>
<p>Aside from Deterministic simulation testing, we also routinely fuzz inputs, and then make sure that the generated bytecode is the same, for both Limbo and SQLite.</p>
<h2 id="the-current-status"><a href="#the-current-status">#</a>The current status</h2>
<p>While Limbo is still in early stages, it has already achieved some important milestones that are already a couple of things worth noting:</p>
<h3 id="fully-asynchronous-i-o"><a href="#fully-asynchronous-i-o">#</a>Fully asynchronous I/O</h3>
<p>Limbo is designed to be fully asynchronous. SQLite itself has a synchronous interface, meaning driver authors who want asynchronous behavior need to have the extra complication of using helper threads. Because SQLite queries <em>tend</em> to be fast, since no network round trips are involved, a lot of those drivers just settle for a synchronous interface. However, this has two fundamental problems:
Not all SQLite queries are fast. Aggregations over large data, for example, will always be slow, even if the data is fully local.
In modern environments, it is actually desirable that queries go over the network. One example is Turso, which serves SQLite over HTTP. Another example are implementations of SQLite over S3 providing the illusion of infinite storage space, where data <em>can</em> be cached locally, but parts of it may be remote.</p>
<p>Limbo is designed to be asynchronous from the ground up. It extends <code>sqlite3_step</code>, the main entry point API to SQLite, to be asynchronous, allowing it to return to the caller if data is not ready to consume immediately. On Linux, Limbo uses <code>io_uring</code>, a performant API for asynchronous system calls.</p>
<h3 id="designed-for-wasm"><a href="#designed-for-wasm">#</a>Designed for WASM</h3>
<p>While SQLite can compile to WASM, it is mostly an afterthought for SQLite. In practice, projects like wa-sqlite exist to extend SQLite and allow it to function in WASM environments like <a href="https://stackblitz.com/">Stackblitz</a> . Limbo is designed from the ground up to have a WASM build, and already has a VFS implementation that works with popular tools like Drizzle without any changes. For example, it is possible to write:</p>
<pre><code><span>import</span> { drizzle } <span>from</span> <span>'drizzle-orm/better-sqlite3'</span>;
<span>import</span> * <span>as</span> s <span>from</span> <span>'drizzle-orm/sqlite-core'</span>;
<span>import</span> { <span>Database</span> } <span>from</span> <span>'limbo-wasm'</span>;

<span>const</span> sqlite = <span>new</span> <span>Database</span>(<span>'sqlite.db'</span>);
<span>const</span> db = <span>drizzle</span>({ <span>client</span>: sqlite });
<span>const</span> users = s.<span>sqliteTable</span>(<span>"users"</span>, {
  <span>id</span>: s.<span>integer</span>(),
  <span>name</span>: s.<span>text</span>(),
})

<span>const</span> result = db.<span>select</span>().<span>from</span>(users).<span>all</span>();

<span>console</span>.<span>log</span>(result);
</code></pre>
<p>Browser support is in the works.</p>
<h3 id="performance"><a href="#performance">#</a>Performance</h3>
<p>SQLite is known for its stellar performance, but in many operations, Limbo is already on par or faster than SQLite. Executing <code>cargo bench</code> on Limbo’s main directory, we can compare SQLite running <code>SELECT * FROM users LIMIT 1</code> (620ns on my Macbook Air M2), with Limbo executing the same query (506ns), which is 20% faster.</p>
<h3 id="simplicity"><a href="#simplicity">#</a>Simplicity</h3>
<p>Despite the fact that SQLite’s file-based nature makes working with it extremely simple, SQLite grew a considerable amount of tunables over the years, which make getting top performance out of it non-obvious (the SQLite numbers on the benchmark above are after tuning). For maximum performance, users have to choose WAL mode over journal mode, disable POSIX advisory locks, etc.</p>
<p>Limbo, while maintaining compatibility with SQLite’s bytecode and file format, drops a lot of the features that we consider less important for modern environments (including SQLite’s “amalgamation”, the build system that generates a single C file), providing a better out-of-the-box experience.</p>
<h2 id="interested-in-learning-more-"><a href="#interested-in-learning-more-">#</a>Interested in learning more?</h2>
<p>Limbo is available under the MIT license <a href="https://github.com/tursodatabase/limbo">on our Github</a>. If you are interested in building an embedded database with the bold vision of taking the promise of SQLite to the next level, come build with us.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI slop is already invading Oregon's local journalism (204 pts)]]></title>
            <link>https://www.opb.org/article/2024/12/09/artificial-intelligence-local-news-oregon-ashland/</link>
            <guid>42378673</guid>
            <pubDate>Tue, 10 Dec 2024 17:01:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opb.org/article/2024/12/09/artificial-intelligence-local-news-oregon-ashland/">https://www.opb.org/article/2024/12/09/artificial-intelligence-local-news-oregon-ashland/</a>, See on <a href="https://news.ycombinator.com/item?id=42378673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you believe the internet, in his first month at the Ashland Daily Tidings, reporter Joe Minihane skied the slopes of Mount Ashland, ate at 15 restaurants in Roseburg, hiked the Owyhee Canyonlands in Malheur County, took in Autzen Stadium and Multnomah Falls, and visited the Neskowin Ghost Forest on the Oregon Coast. </p><p>And sure, more than 1,200 miles of travel to write 10 stories in a month might seem excessive for a local outdoors reporter who was new to his Southern Oregon job, but who could argue with his output?</p><p>Minihane could. </p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/ZRZGWWXGQBAO7AWJWT53EQJHYQ.JPG?auth=dc0a9a5a9a7df08c03ef418d4a3470306cb18a294c325dc6ecd3d917970edaea&amp;width=150" alt="U.K.-based journalist and author Joe Minihane poses inside Powell's Books in Portland, Oregon, during a vacation to the city."></picture><figcaption><p>U.K.-based journalist and author Joe Minihane poses inside Powell's Books in Portland, Ore., during a vacation to the city. Minihane had his identity stolen by fraudulent articles posted to the Ashland Daily Tidings website in 2024</p><p><em>Joe Minihane / Contributed</em></p></figcaption></figure><p>“I mean, the bylines are just bizarre because they’re on topics a) of which I have no understanding and b) I’ve been to Oregon once in my life for a very, very lovely holiday in Portland,” the United Kingdom-based writer told OPB. </p><p>The Ashland Daily Tidings — established as a newspaper in 1876 — ceased operations in 2023, but if you were a local reader, you may not have known. Almost as soon as it closed, a website for the Tidings reemerged, boasting a team of eight reporters, Minihane included, who cranked out densely reported stories every few days. </p><p>And those reporters were covering a lot more than local news. They dove into Oregon’s fentanyl crisis (“Measure 110 might be in for a repeal”), homelessness in Eugene (“All In Lane County homeless program delivers impressive results”), and the food scene in Portland (“The fourth best burger in the U.S. is in Portland”) — essentially any issue that might draw attention from Oregonians. </p><p>The reality was that none of the people allegedly working for the Ashland Daily Tidings existed, or at least were who they claimed to be. The bylines listed on Daily Tidings articles were put there by scammers using artificial intelligence, and in some cases stolen identities, to dupe local readers. </p><p>“It seems quite terrifying,” said Minihane, an actual journalist and author who learned he had his identity stolen after OPB contacted him. “I have friends who live in Portland, but I’ve never been to another part of the state, so I just don’t know quite how it came to pass.”</p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/TPGUMSNJ45A2RHT7GNXZIJY3T4.jpg?auth=8891639b8e9c97f24c4084501b171f7792505289ceb7eb74e2b06e7443ab702b&amp;width=150" alt="The Ashland Daily Tidings ceased operations in 2023, but a website with the company name still continues publishing online, as seen Nov. 8, 2024."></picture><figcaption><p>The Ashland Daily Tidings ceased operations in 2023, but a website with the company name still continues publishing online, as seen Nov. 8, 2024.</p><p><em>Kristyna Wentz-Graff / OPB</em></p></figcaption></figure><p>The mysterious takeover of a more than 140-year-old news outlet offers a warning of how local news is at risk of disappearing in Oregon’s rural communities, and what an online future supercharged by the next unregulated wave of technology from Silicon Valley companies may hold for news consumers. </p><h2>From the ashes, more ashes</h2><p>The number of people working in journalism in Jackson County, like the entire country, has been precipitously declining since adoption of the internet began to grow in the early 2000s. Most analyses of this era point to the rise of consumer-focused tools like Craigslist, which took a <a href="https://hbr.org/2014/03/craigslist-saved-consumers-a-lot-of-money-while-crippling-newspapers"><u>roughly $5 billion bite out of local news</u></a> through the loss of classified ads, as the start of a long slide in the news business. Fact-based news reporting, which takes time, also has <a href="https://www.newyorker.com/magazine/2008/03/31/out-of-print"><u>failed to keep up with online demands</u></a> for the latest content available at the touch of a device. Readers and the advertising dollars that follow them have flocked to social media and other online platforms. </p><p>Jackson County’s current phase of local media, including the ongoing, bizarre operation of the Ashland Daily Tidings, could be seen as beginning in 2017. That’s when Rosebud Media and its owner — an entrepreneur with technology, broadcast and advertising experience — <a href="https://www.oregonlive.com/business/2023/01/mail-tribune-owners-push-to-reshape-local-news-cost-medford-its-daily-newspaper.html"><u>plucked the Mail Tribune and the Daily Tidings</u></a> from the grip of the hedge fund-backed GateHouse Media, which later <a href="https://www.nytimes.com/2019/11/19/business/media/gannett-gatehouse-merger.html" rel="" title="https://www.nytimes.com/2019/11/19/business/media/gannett-gatehouse-merger.html">merged with another powerhouse publisher</a>, Gannett. </p><p>The move offered some hope that Rosebud Media’s vision would preserve what remained of the local journalism that had been pared back by large companies focused primarily on profits. </p><p><strong>Related:</strong> <a href="https://www.opb.org/article/2024/12/09/local-news-job-loss-oregon/">The state of Oregon's local media in 4 charts</a></p><p>The hope didn’t last. In January 2023, after several initiatives meant to stabilize the papers, Rosebud Media <a href="https://www.oregonlive.com/business/2023/01/mail-tribune-storied-newspaper-in-medford-to-abruptly-shut-down.html"><u>closed down </u></a>both for good. The move meant an unceremonious end to Oregon’s first Pulitzer Prize-winning newspaper, the Mail Tribune, which earned the award in 1934 for public service by condemning local politicians who supported racial grievances of the Ku Klux Klan and the violent takeover of local government coming out of the Great Depression. </p><p>The East Oregonian Media Group — a family-owned newspaper chain across rural parts of Oregon and Southwest Washington — stepped in after Rosebud’s closure, and earned heaps of praise when it announced plans to open a local newspaper that would replace the Mail Tribune. </p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/YCFFR7JUQBGBLBA67TOGSA4VN4.jpg?auth=ae6d70e658a5a8c372127b4a91da37ff8f8582e5059f7729e22756c2bdd41a48&amp;width=150" alt="The Ashland Tidings, Dec. 23, 1912, part of the Library of Congress Chronicling America online collection."></picture><figcaption><p>The Ashland Tidings, Dec. 23, 1912, part of the Library of Congress Chronicling America online collection.</p><p><em>Courtesy of Library of Congress</em></p></figcaption></figure><p>That hope didn’t last either. In late October, EO Media Group announced it was <a href="https://www.opb.org/article/2024/10/23/east-oregon-bulletin-bend-eo-media-group/"><u>selling its roughly dozen newspapers</u></a>, including the Rogue Valley Times in Medford, to Carpenter Media Group. The Mississippi-based company — now the fourth-largest newspaper owner in the country — had been on a Northwest newspaper buying spree and boasted of its commitment to “<a href="https://www.nna.org/carpenter-media-group-to-acquire-eo-media-group#:~:text=PENDLETON%2C%20Oregon%20%E2%80%93%20Carpenter%20Media%20Group,roots%20in%20the%20Pacific%20Northwest."><u>high quality, community focused journalism</u></a>” before laying off an untold number of reporters and editors in the <a href="https://www.oregonlive.com/business/2024/07/new-owner-of-portland-tribune-other-oregon-newspapers-lays-off-some-staff.html"><u>Portland suburbs</u></a>, Central Oregon, Eastern Oregon, Southern Oregon and <a href="https://www.heraldnet.com/news/everett-herald-newsroom-strikes-amid-layoffs/"><u>Everett, Washington</u></a>. </p><p>This cycle of a new owner buying a local newspaper every few years — only for more journalists to lose their jobs shortly after the sale — is not unique to Jackson County. Northwestern University’s Medill School of Journalism, which tracks media outlet sales and layoffs in an annual report, estimates the year from 2022 to 2023 saw a rapid loss of 7,000 newspaper-related jobs across the country compared to just a few hundred the year before. According to Medill’s data, nearly every county east of the Cascades in Oregon has <a href="https://localnewsinitiative.northwestern.edu/projects/state-of-local-news/explore/#/state-localnewslandscape?state=OR&amp;stateCode=41"><u>two or fewer local news sources</u></a>. Most have a single source, and six counties have no local news outlet at all. </p><p>The result of all these consolidations and job losses is less information being reported locally for Oregonians, particularly those in rural communities who are seeing papers close at troubling rates, according to Medill’s mapping of news deserts. </p><h2>Plagiarism, by any other name</h2><p>The mysterious emergence of AI invaders on the local news scene is a new development in Oregon, and the Ashland Daily Tidings website appears designed to hide its true operators.</p><p>After Rosebud Media closed in 2023, the Daily Tidings website emerged again with a claimed staff of eight contributors, none of whom are reporters working in Southern Oregon. Two of the writers have sparse social media presences that suggest they live in South Africa. Neither responded to a request for comment from OPB, though one did share a social media post in November praising artificial intelligence. “Try to learn Artificial intelligence and don’t curse in AI. Do your hard work and Update your skills,” they wrote in a LinkedIn post. </p><p>Two of the writers on the Daily Tidings website are actually correspondents for the London-based Daily Mail. Another two have actually worked as journalists in Southern Oregon. One supposed writer has no online presence as a journalist outside the Daily Tidings website.</p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/OA7IBK6IR5D2HNGZHI5KKXBAFM.jpg?auth=b30b3a1c583fc5a1a115f9515fa0ab3d9578a0bca4de00e7e2cd32c373290508&amp;width=150" alt="An Oct. 25, 2024, screenshot of the Ashland Daily Tidings' contributor page. It lists eight people as working for the small Southern Oregon media outlet. The majority of the writers had their names and images stolen and did not work for the company."></picture><figcaption><p>An Oct. 25, 2024, screenshot of the Ashland Daily Tidings' contributor page. During OPB's reporting on the use of artificial intelligence by the website's operators, many of these contributors were removed from the page.</p><p><em>Ryan Haas / OPB</em></p></figcaption></figure><p>OPB used various methods to track down all of the listed reporters on the Southern Oregon webpage, including searching social media and contacting former employers. After OPB began reaching out to people credited on the Tidings’ stories, more than half the staff disappeared from the page and their bylines were replaced on existing stories. Three journalists who responded to OPB’s requests for comment said they had no idea their names or images were being used to produce stories for the Daily Tidings. </p><p>“Plagiarism, I think it’s called,” quipped Bert Etling, the former editor of the Daily Tidings who now runs the digital nonprofit media outlet <a href="https://ashland.news/" title="https://ashland.news/"><u>Ashland.news</u></a>. </p><p>Etling, who started his local journalism career in 1982 and was laid off in 2019 by Rosebud Media, noticed the revived Daily Tidings soon after it emerged because his own reporters saw work remarkably similar to their own appearing on the webpage. The stories would have fresh headlines and the writing would be tweaked, but the reporting and quotes from sources would closely match work Ashland.news had previously published. OPB staff members have also <a href="https://www.opb.org/article/2024/10/03/josephine-county-jail-wellpath/"><u>had their work</u></a> taken and <a href="https://www.dailytidings.com/court-finds-oregon-healthcare-provider-destroyed-evidence/"><u>republished on the Daily Tidings</u></a> website with marginally changed sentences. </p><p>“They just put it in a blender and then pour it out on their page,” Etling said. “It’s maddening.”</p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/6NX5HUYVR5FJROAZ24DYGEKZJQ.jpg?auth=c375a0f6c300e10f18ba0cacfb8ed320b531482f5adf249add13eb5385e96a32&amp;width=150" alt="Ashland News Executive Editor Bert Etling at an announcement for the launch of the news site."></picture><figcaption><p>Ashland News Executive Editor Bert Etling at an announcement Dec. 17, 2021, for the launch of the news site.</p><p><em>Erik Neumann  / JPR News</em></p></figcaption></figure><p>Since artificial intelligence’s wider adoption by the public in the past two years, journalism has been a regular target for scams that further threaten the business of producing news. A New York-based journalist collective, 404 Media, was <a href="https://www.404media.co/why-404-media-needs-your-email-address/"><u>among the first to notice a trend of fraudulent websites</u></a> taking real stories and using AI “spinners” to rewrite the articles with the goal of grabbing web traffic. Other reporting revealed a Serbian DJ who <a href="https://racketmn.com/southwest-journal-minneapolis-mn-vujo-ai"><u>pretended to operate a news outlet in a Minneapolis suburb</u></a>, only to leave local readers confused when they’d click stories to find AI-generated content that had nothing to do with Minnesota.</p><p>The Daily Tidings appears to be the first time an Oregon news outlet has stolen the identities of real journalists to trick local readers with AI-generated content. The goal is apparently to deceive Oregonians into giving clicks — and the resulting ad revenue — to whoever is behind the website. </p><h2>The source</h2><p>The Daily Tidings wasn’t the first time Joe Minihane had his work, or his identity, ripped off using AI. </p><p>In March, someone took over the webpage domain for Minihane’s personal website after he didn’t pay to renew his ownership. Whoever grabbed the site filled it with mundane prose that vaunted Minihane’s ability as a journalist — and his ability to write essays. The purpose for the website takeover appears in links subtly embedded throughout, which offer to sell high school students essays for their homework. </p><p>“I find it fascinating when the bots write about you in the third person,” he told OPB. “I can’t get to the bottom of these things.”</p><p>A similar type of theft may be behind whatever is happening at the Ashland Daily Tidings. </p><p>The Daily Tidings claims on its website that it was acquired by Difference Media, LLC, in 2021. Difference Media was founded by a father and son in Texas to promote Christian music. Speaking to OPB, a company official said they were not aware of the Daily Tidings and that the company owns no newspapers. </p><p>OPB reached out to the operators of the Daily Tidings through the website’s contact form and listed email for the paper’s news desk, but received no reply. </p><p>The alleged timeline of the Difference Media purchase also does not line up with the Daily Tidings’ prior ownership. </p><p>When owner Steve Saslow closed Rosebud Media in 2023, the web domain for the Ashland Daily Tidings and the Medford Mail Tribune became inactive, creating an opportunity for the fraudulent version to replace it.</p><p>In his first interview since closing the papers, Saslow told OPB he had his attorneys pursue litigation against whomever is behind the AI-written stories for copyright infringement. The lawyers told him the fraudulent acts are coming from outside the United States, likely in China, and they described the legal quest as akin to “pursuing a phantom.”</p><p>“They do this apparently with either existing or defunct newspapers around the world,” Saslow said. “[My lawyers] said you could go and spend all kinds of money, and trying to find them would be a needle in a haystack if we could do it at all.”</p><p>Saslow opted not to spend that money chasing down the fraudsters. There’s little doubt money is the reason behind the fraud, however. </p><p>The Daily Tidings website, despite its reliance on copyright infringement and stolen identities, presents readers with banners and pop-up videos from major advertisement-serving companies on the internet, such as Google, YieldMo and the Trade Desk. Display ads like those on the website can earn the site’s operators a few dollars for each 1,000 appearances the ads make, potentially making the endless churn of stolen stories a lucrative business. It’s unclear exactly how much money the Daily Tidings is generating each year from such ad placements. </p><p>After being alerted to the scam by OPB, Google took action against the Daily Tidings website by removing its ads from specific pages on the website the tech giant viewed as violating its terms of service. </p><p>“We have strict publisher policies that govern the types of content we allow to monetize. Upon reviewing the site in question, we have taken action to demonetize the pages where we identified violations of these policies,” spokesperson Nate Funkhouser said in an email. </p><p>The main landing page of the Daily Tidings continued to serve advertisements from Google and other companies as of Dec. 2. Other advertisement-serving companies that appear to be providing income to the Daily Tidings did not respond to OPB’s requests for comment. </p><h2>The future of local journalism</h2><p>Saslow said he started Rosebud Media because he saw the old models for local journalism had created a business that only seemed to recede as online platforms advanced. From his perspective, local readers would be the big losers if nothing changed.</p><p>“It really was about the true sense of journalism,” he said. “That’s why I named the thing Rosebud. It was a joke from the movie ‘Citizen Kane.’ He thought he could control everything and the answer was no, that’s what you don’t want.”</p><p>A desire to experiment led Saslow to partner with Sinclair Broadcast Group to produce some video content with his former reporters. Saslow hoped the experimentation with print, video and online stories would be an attractive package for advertisers who want the maximum number of eyeballs for their dollars. While that effort didn’t translate to advertisers writing bigger checks, Saslow said he isn’t giving up his goal of finding a formula that makes local journalism financially stable. As early as 2025, he said, he’d like to return to Southern Oregon with a new venture that ties together local and national issues in a way that could be a single stop for readers inundated with information. </p><p>“You’ve got to have this mix of everything that would affect a person’s life,” Saslow said. “There’s going to be a breakthrough where somebody basically is able to evolve news to something that is completely different.”</p><p>The future of local journalism in Oregon likely depends on whether its decadeslong retrenchment continues under the <a href="https://www.nytimes.com/2024/06/01/technology/google-ai-search-publishers.html"><u>growing pressures of Silicon Valley’s push into artificial intelligence</u></a>, or if the remaining media outlets in the state can convince their readers that human-verified information is a necessity. Ashland.news, the digital startup led by Etling, is taking some decidedly old-school approaches to help his publication. Even as his reporters are competing with social media posts from the zombified Daily Tidings, Etling said he is constantly thinking about how he can prove to the people living in the Rogue Valley that local journalism is worth saving. </p><p>“People had it easy with the subsidized newspaper,” he said. “It was subsidized by capitalism-assisted democracy — by selling sofas and mattresses on the pages of your newspaper and making it really cheap to get. That’s gone away, and it’s not coming back.”</p><p>Etling doesn’t know what will replace journalism’s long dead revenue sources of classified advertisements and public notices, but he believes the nonprofit model Ashland.news follows — one built on giving well-reported local stories to a local audience — could hold some clues. </p><p>Rather than chasing profits, the company has tried to offer its readers a simple value proposition: We live here, and we want to tell you stories about this community. </p><p>Ashland.news doesn’t have billions of dollars in venture capital behind it like the largest artificial intelligence companies, but it does have an edge those companies don’t have: people who live in the community they’re covering. This year, the outlet’s staff marched in the Fourth of July parade. The response surprised Etling. </p><p>“People were hollering out, ‘We love Ashland News!’ and ‘Thank you!’” he said. “It was really gratifying.”</p><p>The company also recently sent a print edition — a surprising move for a digital outlet — to 17,000 mailboxes in Ashland and nearby Talent as another way to reach people who may not know their local journalism is at risk of going away. </p><p>Those curated appeals to local readers may be working, too. Etling estimates Ashland.news has around 4,750 newsletter subscribers — more than three times the number of people who subscribed to the Daily Tidings when he was editor. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI model for near-instant image creation on consumer-grade hardware (163 pts)]]></title>
            <link>https://www.surrey.ac.uk/news/surrey-announces-worlds-first-ai-model-near-instant-image-creation-consumer-grade-hardware</link>
            <guid>42378519</guid>
            <pubDate>Tue, 10 Dec 2024 16:44:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.surrey.ac.uk/news/surrey-announces-worlds-first-ai-model-near-instant-image-creation-consumer-grade-hardware">https://www.surrey.ac.uk/news/surrey-announces-worlds-first-ai-model-near-instant-image-creation-consumer-grade-hardware</a>, See on <a href="https://news.ycombinator.com/item?id=42378519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A groundbreaking AI model that creates images as the user types, using only modest and affordable hardware, has been announced by the&nbsp;Surrey Institute for People-Centred Artificial Intelligence (PAI) at the University of Surrey. &nbsp;</p></div><div><p>The model, NitroFusion, represents a world first and has been made open source by its developers – SketchX, a lab within PAI – a move that fundamentally transforms access to AI-enabled image creation models for creative professionals.&nbsp;</p></div><div><p>Typically, similar&nbsp;technology is available only to corporate giants with vast computing resources. However, NitroFusion runs on a single consumer-grade graphics card – marking a decisive step forward in bringing advanced AI capabilities to individual creators, small studios, and educational institutions. The almost instant creation of images allows rapid artistic iterations and greater control over the generated imagery. &nbsp;</p></div><div><p><strong>Notes to editors</strong>&nbsp;</p><p>Taking a different approach to much AI activity in the UK, the Surrey Institute for People-Centred AI puts the needs of individuals and society at the very heart of everything it does: we believe that the starting point for AI should be people rather than technology. &nbsp;&nbsp;</p><p>This people-centred approach drives our research and enables us to design AI technologies and systems that are ethical, responsible, and inclusive. The pan-University Institute brings together Surrey's core AI-related expertise in vision, speech and signal processing, computer science, and mathematics, with its domain expertise across engineering and physical sciences, human and animal health, law and regulation, business, finance and the arts and social sciences. With this distinctive approach, PAI builds on Surrey's track record of collaboration with industry, the public sector, government and other relevant institutions to develop solutions to shared challenges.&nbsp; &nbsp;</p><p>To find more details, visit <a href="https://www.surrey.ac.uk/artificial-intelligence" target="_blank"><strong>surrey.ac.uk/ai</strong></a> or follow @peoplecentredai&nbsp;</p><p><strong>About SketchX&nbsp;</strong>&nbsp;</p><p>SketchX is a world-leading computer vision and AI research group within the Institute for People-Centred AI and the Centre for Vision, Speech and Signal Processing at the University of Surrey. &nbsp;The group is led by Prof. Yi-Zhe SonG and specialises in pioneering AI technologies that push the boundaries of creative and interactive applications. About the Surrey Institute for People-Centred AI.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From where I left (1093 pts)]]></title>
            <link>https://antirez.com/news/144</link>
            <guid>42378488</guid>
            <pubDate>Tue, 10 Dec 2024 16:41:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/144">https://antirez.com/news/144</a>, See on <a href="https://news.ycombinator.com/item?id=42378488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="144-" id="144-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 51 minutes ago. 15113 views.  </span><pre>I’m not the kind of person that develops a strong attachment to their own work. When I decided to leave Redis, about 1620 days ago (~ 4.44 years), I never looked at the source code, commit messages, or anything related to Redis again. From time to time, when I needed Redis, I just downloaded it and compiled it. I just typed “make” and I was very happy to see that, after many years, building Redis was still so simple.

My detachment was not the result of me hating my past work. While in the long run my creative work was less and less important and the “handling the project” activities became more and more substantial — a shift that many programmers are able to do, but that’s not my bread and butter — well, I still enjoyed doing Redis stuff when I left. However, I don’t share the vision that most people at my age (I’m 47 now) have: that they are still young. I wanted to do new stuff, especially writing. I wanted to stay more with my family and help my relatives. I definitely needed a break.

However, during the “writing years” (I’m still writing, by the way), I often returned to coding, as a way to take breaks from intense writing sessions (writing is the only mental activity I found to be a great deal more taxing than coding): I did a few embedded projects; played more with neural networks; built Telegram bots: a bit of everything. Hacking randomly was cool but, in the long run, my feeling was that I was lacking a real purpose, and every day I started to feel a bigger urgency to be part of the tech world again. At the same time, I saw the Redis community fragmenting, something that was a bit concerning to me, even as an outsider.

So I started to think that maybe, after all, I could have a role back in the Redis ecosystem. Perhaps I could be able to reshape the company's attitude towards the community. Maybe I could even help to take back the role of the Redis core as the primary focus of new developments. Basically I could be some kind of “evangelist” (I don’t love the name of this role, but… well, you get it), that is, on one side, a bridge between the company and the community, but also somebody that could produce programming demos, invent and describe new patterns, write documentation, videos and blog posts about new and old stuff. And, what about the design of new stuff? I could learn from the work of people in the wild, from their difficulties, distill it, and report back design ideas, in order for Redis to evolve.

# Time in NY

At some point my daughter, who is now 12, and is a crucial person in my life, enlightening my days with her intelligence, creativity and love, wanted to visit NYC for her birthday. We decided that yes, this was a good idea after all, we had a couple very difficult years recently, so, why not? My daughter is now more of a girl than a child. So, in NYC, I thought: maybe this is the right time, I can do a part time job. I met the new Redis CEO, Rowan Trollope, very recently, in a video call. I had the feeling that I could work with him to tune the future of the company’s relationships with the community and the codebase direction. So I wrote him an email saying: do you think I could be back in some kind of capacity? Rowan showed interest in my proposal, and quickly we found some agreement.

# About the license switch

People will ask questions about why I *actually* did this, whether there is some back story other than what I just wrote above, if there is some agreement involved, or a big amount of money; something odd or unclear. But sometimes things are very boring: 1. I contacted the company, not the reverse. 2. I’m not getting crazy money to re-enter, it’s not about exploiting some situation — normal salary (but, disclaimer: yes, I have Redis stock options like I had before, no less, no more). 3. I don’t have huge issues with Redis changing its license; Specifically I don’t think the fracture with the community is *really* about this. But since people will ask me about that very important matter, it is better to tell you all the truth immediately.

# The licensing dilemma

I wrote open source software for almost my whole life. Yet, as I’m an atheist and still I’m happy when I see other people believing in God, if this helps them to survive life’s hardships, I also don’t believe that open source is the only way to write software. When I started to develop Redis in the context of a company where I was one of the two founders and where we kept the software code closed (Redis was opened as it was considered not part of the core product). We didn't want our services to be copied by others, as simple as that. So I’m not an extremist in this regard – I’m an extremist only about software design.

Moreover, I don’t believe that openness and licensing are only what the OSI tells us they are. I see licensing as a spectrum of things you can and can’t do. At the same time, I’m truly concerned that big cloud providers have changed the incentives in the system software arena. Redis was not the only project to change license, it was actually the last one… of a big pile. And I have the feeling that in recent years many projects didn’t even start because of a lack of a clear potential business model. So, the Redis license switch was not my decision and perhaps I would have chosen a different license? I’m not sure, it’s too easy to relitigate right now, far from the scene for many years and without business pressures. But in general, I can understand the choice.

Moreover, if you read the new Redis license, sure, it’s not BSD, but basically as long as you don’t sell Redis as a service, you can use it in very similar ways and with similar freedoms as before (what I mean is that you can still modify Redis, redistribute it, use Redis commercially, in your for-profit company, for free, and so forth). You can *even* still sell Redis as a service if you want, as long as you release all the orchestration systems under the same license (something that nobody would likely do, but this shows the copyleft approach of the license). The license language is almost the same as the AGPL, with changes regarding the SAAS stuff. So, not OSI approved? Yes, but I have issues calling the SSPL a closed license.

You will say (I can hear you): the real problem is that there are companies controlling OSS projects’ direction! So eventually the interests get more aligned with companies and less with the user base. I’m grateful there are many projects out there with zero direct companies involvement (if not external sponsorship), but well, you know what? Involvement of companies, in many large projects, actually slows down this process of skewing the right path. This surely happened in the case of Redis.

# The Robin Hood of software

Let's jump back into the past, to the first days of Redis.

When Redis started to become popular, I wanted to find a way to continue working on it. This was before VMware offered me to sponsor my work. I started to play with the idea of a business model, and guess what? It was in the form of closed source products that would kinda help people running Redis, in some way or the other. (Amazingly, one of the repositories associated with this idea is still online, showing commits of *15* years ago: <a rel="nofollow" href="https://github.com/antirez/redis-tools">https://github.com/antirez/redis-tools</a>)

I was about to try some kind of open core approach; I also remember I was thinking about delaying the BSD license for new code for six months, in order to create some kind of advantage for paying users. Now I don’t believe I would be a jerk and do strange games with my users, but I would not be what I was able to be thanks to VMware and, later, more extensively thanks to Redis Labs later: a freaking Robin Hood of open source software, where I was well compensated by a company and no, not to do the interests of the company itself, but only to make the best interests of the Redis community. This is a better setup than having your own company, I’m sure about that.

VMWare, and later Redis Labs, didn’t pay just for me. If you give a quick look at the repository contributions history, you’ll see the second all time contributor to be Oran Agra (Redis) then there is Pieter Noordhuis (VMWare) and so forth.

So basically I think that 12 years of BSD code written just focusing on the user base is a good deal, and it’s something to be happy about. And right now for me the most important part is that the fracture with the community is not about licensing, or at least it’s not mainly about licensing. Actually the new license can solve some part of it: now there is no longer an incentive to just leave the core in maintenance mode and put the new developments into modules. With the new license, cloud providers can’t just cut and paste the Redis code base and sell it without any revenue sharing (was this really asking for too much? This could have prevented all the license switches you saw lately, not just Redis). With the new license, the spotlight can be back on the Redis core, with new, exciting features in the hands of the developers around the world. With tens of people well compensated for their work pushing useful, well documented changes in the GitHub repository. This is also one of the things I would like to help the company with, and I’ll try hard. We need to make the license switch having good effects on the user base and features: that’s my idea.

# About AI, LLMs and vector indexing

But there is more: Redis is getting interested in developing vector capabilities, and in general to support the kind of programming you can do with AI. Now, every day, I read Hacker News, and I see a huge amount of technical people who dislike AI and the new developments. I also see a lot of people who don't even care to really try the latest models available in depth (hint: Claude AI is in its own league) and still dismiss them as kinda useless. For me, it’s different. I always loved neural networks. I wrote my first NN library in 2003 and was totally shocked by how powerful and cool the whole concept was. And now, at the end of 2024, I’m finally seeing incredible results in the field, things that looked like sci-fi a few years ago are now possible: Claude AI is my reasoning / editor / coding partner lately. I’m able to accomplish a lot more than I was able to do in the past. I often do *more work* because of AI, but I do better work. Recently I wrote a sci-fi short story for an Italian publisher, and thanks to Claude criticizing parts of it I rewrote the ending and produced a much better work (I didn’t let Claude write a single line of the story or the plot: great use of AI is not making machines do what you can do better).

Yesterday I needed to evaluate how much faster dot product could be computed with 8 bit quantization of my vectors; I told Claude I needed a benchmark designed in a specific way, and two minutes later I could test it, modify it, and understand whether it was worthwhile or not. Basically, AI didn’t replace me, AI accelerated me or improved me with feedback about my work. And I believe that (regardless of the popularity of RAG, which is not necessarily the main application, nor the most future proof or useful, as models contexts are becoming larger and larger, and soon popular models attention may have linear complexity), sorry for the digression, I was saying that I believe that learned embeddings are here to stay, and vector search is something that belongs to Redis for several reasons: first because vector indexes are data structures, particularly slow data structures, and such data structures can work very well in memory. Also, because I think I found the perfect API to expose them.

During my work in designing Redis, I always showed some contradictory tendencies. I was always ready to say “no” to certain things that looked like perfect fits for the project (named Lua scripts, hash fields expires, that are both part of Redis now, btw) but at the same time I added Lua scripting capabilities — when it looked like nuts, an interpreter inside Redis?! —, the Pub/Sub capability, that seemed out of context, then streams, and even synthetic data structures that don’t exist in computer science books, like sorted sets. Because, for me, the fitness of new features into Redis was about two things: use cases and internal design fit. Redis, for me, is lego for programmers, not a “product”.

# Vector sets

So recently I started to think that sorted sets can inspire a new data type, where the score is actually a vector. And while I was in talks with Rowan, I started to write a design document, then I started to implement a proof of concept of the new data structure, reimplementing HNSWs from scratch (instead of using one of the available libraries, since I wanted to tune every little bit), the Redis way, and well, I’m not sure how this will end, I’m still in the early stages of coding, but perhaps I may end up contributing code again, if this proposal gets accepted. The module I implemented (that would be later merged into the core – for now it’s a module just for the sake of simplicity) implements new commands that manipulate embeddings directly. I’ll show you just that as a hint:


VSIM top_1000_movies_imdb ELE "The Matrix"  WITHSCORES
 1) "The Matrix"
 2) "0.9999999403953552"
 3) "Ex Machina"
 4) "0.8680362105369568"
 5) "Akira"
 6) "0.8635441958904266"
 7) "District 9"
 8) "0.8631418347358704"
 9) "The Martian"
10) "0.8608670234680176"
11) "The Bourne Ultimatum"
12) "0.8599717319011688"
13) "The Bourne Supremacy"
14) "0.8591427505016327"
15) "Blade Runner"
16) "0.8585404753684998"
17) "Metropolis"
18) "0.8572960793972015"
19) "Inception"
20) "0.8521313071250916"

So you have VSIM, VADD, VCARD, all the obvious stuff. It’s exactly the idea of sorted sets, but with multi-dimensional scores (embeddings!) and K-NN matches. What do you think? And, of course, on top of that there are many implementation tricks to make stuff more efficient. But for now it’s proof of concept code, let me work a bit more on it. I’m implementing threading, dimensionality reduction, quantization, and many more things. Quite fun, to be honest.

As you can see, there is no mention of hybrid search, the recent buzzword about vector stores. Again, this is the Redis way: to let the developer have a role and decide on their tradeoffs: they know what they are modeling, after all. You have a vector index per key, and like what programmers were able to do with sorted sets, they will invent interesting splitting strategies, new schemas, Lua scripts, patterns and all that is required in order to model their use cases.

Still, while normally the associated item will likely be a small string or a document ID, nothing prevents it from being something more complex, with metadata that can be filtered later (but I’ll resist). I just have the feeling that many use cases don’t really need complex server-side filtering, and can be modeled by pre-partitioning data.

What I see with great interest is the addition of a potential STORE option, to store the result into a sorted set instead of returning it to the user, where the score is the similarity, of course. All this also has complex and interesting effects on efficiency, scalability, ability to use scripting, and so forth: I hope I’ll have the opportunity to talk more about it in the next weeks and months.

Ok, ok: back to the point of this blog post. But perhaps the above is the *real* point, having new ideas that can be exciting.

# So, I’m back 🙂

All this to say that, I’m back. I think it’s the right moment for a big thank you to all the Redis community, for what it has done over the years. See you around, I hope there is something more to add to this journey.

P.S. I’m active on BlueSky, if you want to follow the developments of all this. <a rel="nofollow" href="https://bsky.app/profile/antirez.bsky.social">https://bsky.app/profile/antirez.bsky.social</a></pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Google Willow Thing (697 pts)]]></title>
            <link>https://scottaaronson.blog/?p=8525</link>
            <guid>42378407</guid>
            <pubDate>Tue, 10 Dec 2024 16:34:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottaaronson.blog/?p=8525">https://scottaaronson.blog/?p=8525</a>, See on <a href="https://news.ycombinator.com/item?id=42378407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-8525">
				
<p>Yesterday I arrived in Santa Clara for the <a href="https://q2b.qcware.com/2024-conferences/silicon-valley/">Q2B (Quantum 2 Business) conference</a>, which starts this morning, and where I’ll be speaking Thursday on “Quantum Algorithms in 2024: How Should We Feel?” and also closing the conference via an Ask-Us-Anything session with John Preskill.  (If you’re at Q2B, reader, come and say hi!)</p>



<p>And to coincide with Q2B, yesterday Google’s Quantum group <a href="https://blog.google/technology/research/google-willow-quantum-chip/">officially announced “Willow,”</a> its new 105-qubit superconducting chip with which it’s demonstrated an error-corrected surface code qubit as well as a new, bigger quantum supremacy experiment based on Random Circuit Sampling. I was lucky to be able to attend Google’s announcement ceremony yesterday afternoon at the Computer History Museum in Mountain View, where <a href="https://scottaaronson.blog/?p=88">friend-of-the-blog-for-decades Dave Bacon</a> and other Google quantum people explained exactly what was done and took questions (the technical level was surprisingly high for this sort of event). I was also lucky to get a personal briefing last week from Google’s Sergio Boixo on what happened.</p>



<p>Meanwhile, yesterday Sundar Pichai <a href="https://twitter.com/sundarpichai/status/1866167429367468422">tweeted about Willow</a>, and <a href="https://twitter.com/elonmusk/status/1866170803051499874">Elon Musk replied “Wow.”</a>  It cannot be denied that those are both things that happened.</p>



<p>Anyway, all yesterday, I then read comments on Twitter, <a href="https://news.ycombinator.com/item?id=42367649">Hacker News</a>, etc. complaining that, since there wasn’t yet a post on <em>Shtetl-Optimized</em>, how could anyone possibly know what to think of this?? For 20 years I’ve been trying to teach the world how to fish in <a href="https://en.wikipedia.org/wiki/Hilbert_space">Hilbert space</a>, but (sigh) I suppose I’ll just hand out some more fish. So, here are my comments:</p>



<ol>
<li>Yes, this is great. Yes, it’s a real milestone for the field. To be clear: for anyone who’s been following experimental quantum computing these past five years (say, since Google’s <a href="https://www.nytimes.com/2019/10/30/opinion/google-quantum-computer-sycamore.html">original quantum supremacy milestone</a> in 2019), there’s no particular shock here. Since 2019, Google has roughly doubled the number of qubits on its chip and, more importantly, increased the qubits’ coherence time by a factor of 5. Meanwhile, their 2-qubit gate fidelity is now roughly 99.7% (for controlled-Z gates) or 99.85% (for “iswap” gates), compared to ~99.5% in 2019. They then did the more impressive demonstrations that predictably become possible with more and better qubits. And yet, even if the progress is broadly in line with what most of us expected, it’s still of course immensely gratifying to see everything actually work! Huge congratulations to everyone on the Google team for a well-deserved success.<br></li>



<li>I <a href="https://scottaaronson.blog/?p=8310">already blogged about this!!!</a> Specifically, I blogged about Google’s fault-tolerance milestone when its <a href="https://arxiv.org/abs/2408.13687">preprint appeared on the arXiv</a> back in August. To clarify, what we’re all talking about now is the same basic technical advance that Google already reported in August, except now with the PR blitz from Sundar Pichai on down, a <a href="https://www.nature.com/articles/s41586-024-08449-y"><em>Nature</em> paper</a>, an official name for the chip (“Willow”), and a bunch of additional details about it.<br></li>



<li>Scientifically, the headline result is that, as they increase the size of their surface code, from 3×3 to 5×5 to 7×7, Google finds that their encoded logical qubit stays alive for <em>longer</em> rather than shorter.  So, this is a very important threshold that’s now been crossed.  As Dave Bacon put it to me, “eddies are now forming”—or, to switch metaphors, after 30 years we’re now finally tickling the tail of the dragon of quantum fault-tolerance, the dragon that (once fully awoken) will let logical qubits be preserved and acted on for basically arbitrary amounts of time, allowing scalable quantum computation.<br></li>



<li>Having said that, Sergio Boixo tells me that Google will only consider itself to have created a “true” fault-tolerant qubit, once it can do fault-tolerant two-qubit gates with an error of ~10<sup>-6</sup> (and thus, on the order of a million fault-tolerant operations before suffering a single error).  We’re still some ways from <em>that</em> milestone: after all, in this experiment Google created only a <em>single</em> encoded qubit, and didn’t even try to do encoded operations on it, let alone on multiple encoded qubits.  But all in good time.  Please don’t ask me to predict how long, though empirically, the time from one major experimental QC milestone to the next now seems to be measured in years, which are longer than weeks but shorter than decades.<br></li>



<li>Google has also announced a new quantum supremacy experiment on its 105-qubit chip, based on <a href="http://Random Circuit Sampling">Random Circuit Sampling</a> with 40 layers of gates.  Notably, they say that, if you use the best currently-known simulation algorithms (based on Johnnie Gray’s optimized tensor network contraction), as well as an exascale supercomputer, their new experiment would take ~300 million years to simulate classically if memory is not an issue, or ~10<sup>25</sup> years if memory <em>is</em> an issue (note that a mere ~10<sup>10</sup> years have elapsed since the Big Bang).  Probably some people have come here expecting me to debunk those numbers, but as far as I know they’re entirely correct, with the caveats stated.  Naturally it’s possible that better classical simulation methods will be discovered, but meanwhile the experiments themselves will also rapidly improve.<br></li>



<li>Having said that, the <em>biggest</em> caveat to the “10<sup>25</sup> years” result is one to which I fear Google drew insufficient attention. Namely, for the exact same reason why (as far as anyone knows) this quantum computation would take ~10<sup>25</sup> years for a classical computer to simulate, <strong>it would also take ~10<sup>25</sup> years for a classical computer to directly verify the quantum computer’s results!!</strong> (For example, by computing the “Linear Cross-Entropy” score of the quantum computer’s outputs.) For this reason, all validation of Google’s new supremacy experiment is indirect, based on extrapolations from smaller circuits, ones for which a classical computer <em>can</em> feasibly check the results. To be clear, I <em>personally</em> see no reason to doubt those extrapolations. But for anyone who wonders why I’ve been <a href="https://www.youtube.com/watch?v=A6YPAQlGejo">obsessing for years</a> about the need to design <em>efficiently</em> <em>verifiable</em> near-term quantum supremacy experiments: well, this is why! We’re now deeply into the unverifiable regime that I warned about.<br></li>



<li>In his remarks yesterday, Google Quantum AI leader Hartmut Neven talked about David Deutsch’s argument, way back in the 1990s, that quantum computers should force us to accept the reality of the Everettian multiverse, since “where else could the computation have happened, if it wasn’t being farmed out to parallel universes?” And naturally there was lots of debate about that on Hacker News and so forth. Let me confine myself here to saying that, in my view, the new experiment doesn’t add anything <em>new</em> to this old debate. It’s yet another confirmation of the predictions of quantum mechanics. What those predictions <em>mean</em> for our understanding of reality can continue to argued as it’s been since the 1920s.<br></li>



<li>Cade Metz did a <a href="https://www.nytimes.com/2024/12/09/technology/google-quantum-computing.html">piece about Google’s announcement</a> for the <em>New York Times</em>.  Alas, when Cade reached out to me for comment, I decided that it would be too awkward, after what Cade <a href="https://scottaaronson.blog/?p=5310">did to my friend Scott Alexander</a> almost four years ago.  I talked to several other journalists, such as <a href="https://www.science.org/content/article/google-passes-milestone-road-error-free-quantum-computer">Adrian Cho for <em>Science</em></a>.<br></li>



<li>No doubt people will ask me what this means for superconducting qubits versus trapped-ion or neutral-atom or photonic qubits, or for Google versus its many competitors in experimental QC. And, I mean, it’s not <em>bad</em> for Google or for superconducting QC! These past couple years I’d sometimes commented that, since Google’s 2019 announcement of quantum supremacy via superconducting qubits, the trapped-ion and neutral-atom approaches had seemed to be pulling ahead, with spectacular results from Quantinuum (trapped-ion) and QuEra (neutral atoms) among others. One could think of Willow as Google’s reply, putting the ball in competitors’ courts likewise to demonstrate better logical qubit lifetime with increasing code size (or, better yet, full operations on logical qubits exceeding that threshold, without resorting to postselection).  The great advantage of trapped-ion qubits continues to be that you can move the qubits around (and also, the two-qubit gate fidelities seem somewhat ahead of superconducting).  But to compensate, superconducting qubits have the advantage that the gates are a thousand times faster, which makes feasible to do experiments that require collecting millions of samples.<br></li>



<li>Of course the <em>big</em> question, the one on everyone’s lips, was always how quantum computing skeptic Gil Kalai was going to respond.  But we need not wonder!  On his blog, <a href="https://gilkalai.wordpress.com/2024/12/09/the-case-against-googles-claims-of-quantum-supremacy-a-very-short-introduction/">Gil writes</a>: “We did not study yet these particular claims by Google Quantum AI but my general conclusion apply to them ‘Google Quantum AI’s claims (including published ones) should be approached with caution, particularly those of an extraordinary nature. These claims may stem from significant methodological errors and, as such, may reflect the researchers’ expectations more than objective scientific reality.’ ”&nbsp; Most of Gil’s post is devoted to re-analyzing data from Google’s 2019 quantum supremacy experiment, which Gil continues to believe can’t possibly have done what was claimed.  Gil’s problem is that the 2019 experiment was long ago superseded anyway: besides the new and more inarguable Google result, IBM, Quantinuum, QuEra, and USTC have now all <em>also</em> reported Random Circuit Sampling experiments with good results.  I predict that Gil, and others who take it as axiomatic that scalable quantum computing is impossible, will continue to have their work cut out for them in this new world.</li>
</ol>



<p><strong><mark>Update:</mark></strong> <a href="https://x.com/skdh/status/1866352680899104960">Here’s Sabine Hossenfelder’s take.</a>  I don’t think she and I disagree about any of the actual facts; she just decided to frame things much more negatively.  Ironically, I guess 20 years of covering hyped, dishonestly-presented non-milestones in quantum computing has inclined me to be pretty positive when a group puts in this much work, demonstrates a <em>real</em> milestone, and talks about it without obvious falsehoods.</p>

		
				
				<p>
					<small>
						This entry was posted
												on Tuesday, December 10th, 2024 at 10:10 am						and is filed under <a href="https://scottaaronson.blog/?cat=4" rel="category">Quantum</a>.
						You can follow any responses to this entry through the <a href="https://scottaaronson.blog/?feed=rss2&amp;p=8525">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://scottaaronson.blog/wp-trackback.php?p=8525" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div><p>You can use rich HTML in comments!  You can also use basic TeX, by enclosing it within <span>$$ $$</span> for displayed equations or <span>\( \)</span> for inline equations.</p><p>
	After two decades of mostly-open comments, in July 2024 <i>Shtetl-Optimized</i> transitioned to the following policy:
	
</p><p>All comments are treated, by default, as personal missives to me, Scott Aaronson---with no expectation either that they'll appear on the blog or that I'll reply to them.

</p><p>At my leisure and discretion, and in consultation with the <a href="https://scottaaronson.blog/?p=6576"><i>Shtetl-Optimized</i> Committee of Guardians</a>, I'll put on the blog a curated selection of comments that I judge to be particularly interesting or to move the topic forward, and I'll do my best to answer those.  But it will be more like Letters to the Editor.  Anyone who feels unjustly censored is welcome to the rest of the Internet.

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Training LLMs to Reason in a Continuous Latent Space (262 pts)]]></title>
            <link>https://arxiv.org/abs/2412.06769</link>
            <guid>42378335</guid>
            <pubDate>Tue, 10 Dec 2024 16:26:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.06769">https://arxiv.org/abs/2412.06769</a>, See on <a href="https://news.ycombinator.com/item?id=42378335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.06769">View PDF</a>
    <a href="https://arxiv.org/html/2412.06769v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) are restricted to reason in the "language space", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may not always be optimal for reasoning. For example, most word tokens are primarily for textual coherence and not essential for reasoning, while some critical tokens require complex planning and pose huge challenges to LLMs. To explore the potential of LLM reasoning in an unrestricted latent space instead of using natural language, we introduce a new paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden state of the LLM as a representation of the reasoning state (termed "continuous thought"). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that Coconut can effectively augment the LLM on several reasoning tasks. This novel latent reasoning paradigm leads to emergent advanced reasoning patterns: the continuous thought can encode multiple alternative next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. Coconut outperforms CoT in certain logical reasoning tasks that require substantial backtracking during planning, with fewer thinking tokens during inference. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Shibo Hao [<a href="https://arxiv.org/show-email/cd5994a7/2412.06769" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 9 Dec 2024 18:55:56 UTC (11,057 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From Unemployment to Lisp: Running GPT-2 on a Teen's Deep Learning Compiler (109 pts)]]></title>
            <link>https://github.com/hikettei/Caten</link>
            <guid>42378194</guid>
            <pubDate>Tue, 10 Dec 2024 16:12:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hikettei/Caten">https://github.com/hikettei/Caten</a>, See on <a href="https://news.ycombinator.com/item?id=42378194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Caten</h2><a id="user-content-caten" aria-label="Permalink: Caten" href="#caten"></a></p>
<blockquote>
<p dir="auto"><strong>This repository is still in the early stages of development. Additionally, it includes many experimental approaches. Please consider this as a place to experiment with my ideas. Do not use it in a product under any circumstances.</strong></p>
</blockquote>
<p dir="auto"><a href="https://github.com/hikettei/Caten/actions/workflows/tests_on_push.yml"><img src="https://github.com/hikettei/Caten/actions/workflows/tests_on_push.yml/badge.svg" alt="CI"></a> <a href="https://github.com/hikettei/Caten/actions/workflows/benchmark.yml"><img src="https://github.com/hikettei/Caten/actions/workflows/benchmark.yml/badge.svg" alt="Benchmarks"></a> <a href="https://github.com/hikettei/Caten/actions/workflows/pages/pages-build-deployment"><img src="https://github.com/hikettei/Caten/actions/workflows/pages/pages-build-deployment/badge.svg" alt="pages-build-deployment"></a> <a href="https://discord.gg/tNawU7TN3s" rel="nofollow"><img src="https://camo.githubusercontent.com/b2fda4ac545746e659c6225cc1fe127973f784a782e4f5346bb548de8622a5e7/68747470733a2f2f646362616467652e6c696d65732e70696e6b2f6170692f7365727665722f744e61775537544e33733f7374796c653d666c6174" alt="" data-canonical-src="https://dcbadge.limes.pink/api/server/tNawU7TN3s?style=flat"></a></p>
<p dir="auto"><code>Caten = Compile+AbstracTENsor</code></p>
<p dir="auto">Caten is an experimental deep learning compiler. Our goal is to implement a compiler that is as simple as tinygrad, and as flexible as TVM.</p>
<p dir="auto"><strong>We're looking for collaborators! Please join our Discord and let me know if you'd like to contribute!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Showcases</h2><a id="user-content-showcases" aria-label="Permalink: Showcases" href="#showcases"></a></p>
<p dir="auto">Caten is still under development, but it aims to support a wide range of models in the future—from image processing to text generation, and vision language models! Some models are already up and running.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running LLMs</h3><a id="user-content-running-llms" aria-label="Permalink: Running LLMs" href="#running-llms"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ JIT=1 PARALLEL=8 ./roswell/caten.ros llm-example --model &quot;gpt2&quot; --prompt &quot;Hello&quot; --max-length 100"><pre>$ JIT=1 PARALLEL=8 ./roswell/caten.ros llm-example --model <span><span>"</span>gpt2<span>"</span></span> --prompt <span><span>"</span>Hello<span>"</span></span> --max-length 100</pre></div>
<p dir="auto">Give the GPT2 demo a try! You can pass compilation settings through environment variables.</p>
<p dir="auto">For example, setting <code>JIT=1</code> enables JIT compilation, while <code>JIT_DEBUG &gt;= 2</code> allows you to view the schedule and the generated kernels. Setting <code>PARALLEL=8</code> divides the ScheduleGraph and compiles it in parallel.</p>
<p dir="auto">You may still find the token/ms rate slow, but we're not yet at the stage of implementing an AutoScheduler to accelerate kernel performance (as well as GPU support). Once our IR matures enough to handle a wide range of deep learning models, we plan to focus on speeding things up!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<ol dir="auto">
<li>Install <a href="https://github.com/roswell/roswell">Roswell</a> and suitable IDE. (If unsure, Emacs or <a href="https://github.com/lem-project/lem">Lem</a> is recommended)</li>
<li>Install <a href="https://github.com/Meinersbur/isl">ISL (Integer Set Library)</a> for the fast kernel generation.</li>
<li>Install <a href="https://github.com/fukamachi/qlot">Qlot</a></li>
<li>Check out <a href="https://github.com/hikettei/Caten/blob/main/docs/getting-started.lisp">getting-started.lisp</a></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:hikettei/Caten.git
$ cd Caten
$ qlot install
$ qlot exec ros run
> (ql:quickload :caten)
> (in-package :caten-user)
> (proceed (!randn `(3 3)))"><pre>$ git clone git@github.com:hikettei/Caten.git
$ <span>cd</span> Caten
$ qlot install
$ qlot <span>exec</span> ros run
<span>&gt;</span> (ql:quickload :caten)
<span>&gt;</span> (in-package :caten-user)
<span>&gt;</span> (proceed (<span>!</span>randn <span><span>`</span>(3 3)))</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Involved</h2><a id="user-content-get-involved" aria-label="Permalink: Get Involved" href="#get-involved"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Join our <a href="https://discord.gg/tNawU7TN3s" rel="nofollow">Discord Server</a>.</p>
</li>
<li>
<p dir="auto">Check out our <a href="https://github.com/users/hikettei/projects/2">roadmap</a>.</p>
</li>
<li>
<p dir="auto">Create a PR</p>
</li>
</ol>
<p dir="auto">Caten is a project that started only a few months ago. We are currently in the stage of building a solid foundational library. Here’s what we’re looking for:</p>
<ul dir="auto">
<li>
<p dir="auto">Feature additions with tests (e.g., new activations, unimplemented matrix operations)</p>
</li>
<li>
<p dir="auto">Bug reports and additional tests.</p>
</li>
<li>
<p dir="auto">Refactoring of the core compiler components</p>
</li>
<li>
<p dir="auto">Improving the documentation</p>
</li>
</ul>
<p dir="auto">etc...</p>
<p dir="auto">Before contributing, please note that there is no linter here. Make an effort to adhere to <a href="https://google.github.io/styleguide/lispguide.xml" rel="nofollow">Google Common Lisp Style Guide</a>. Changes that do not follow this should be rejected by the review.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Supported Models</h3><a id="user-content-supported-models" aria-label="Permalink: Supported Models" href="#supported-models"></a></p>
<ul dir="auto">
<li><strong>Transformer</strong>
<ul>
<li> GPT2</li>
<li> Llama3 8B</li>
<li> TinyLLAMA</li>
</ul>
</li>
<li><strong>Classification</strong>
<ul>
<li> MobileNetV2</li>
<li> MobileNetV3</li>
<li> ResNet18/ResNet34/ResNet50</li>
<li> VIT_B_16</li>
</ul>
</li>
<li><strong>Segmentation</strong>
<ul>
<li> CenterNet</li>
</ul>
</li>
<li><strong>Detection</strong>
<ul>
<li> YoLOv3</li>
<li> YoLOv7</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Supported Formats</h3><a id="user-content-supported-formats" aria-label="Permalink: Supported Formats" href="#supported-formats"></a></p>
<ul>
<li> Common Lisp Frontend (caten/apis)</li>
<li> ONNX (caten/onnx)</li>
<li> GGUF (caten/gguf)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quantization</h3><a id="user-content-quantization" aria-label="Permalink: Quantization" href="#quantization"></a></p>
<ul>
<li> Support Dequantization from GGUF</li>
<li> Support QOPs</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Training</h3><a id="user-content-training" aria-label="Permalink: Training" href="#training"></a></p>
<ul>
<li> Autodiff</li>
<li> Fast Autodiff</li>
<li> Support Training</li>
<li> Distributed Training</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Accelerators</h3><a id="user-content-accelerators" aria-label="Permalink: Accelerators" href="#accelerators"></a></p>
<ul>
<li> LISP VM</li>
<li> CLANG JIT</li>
<li> CLANG with Auto Scheduler</li>
<li> METAL</li>
<li> CUDA</li>
<li> Vulkan</li>
<li> Auto Scheduler</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running tests</h2><a id="user-content-running-tests" aria-label="Permalink: Running tests" href="#running-tests"></a></p>
<p dir="auto">You should install python, numpy, pytorch before running the test-suite by using <code>make install_extra</code>. If not specified, install the latest one.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ make install_extra # extra dependencies for running tests
$ make test"><pre>$ make install_extra <span><span>#</span> extra dependencies for running tests</span>
$ make <span>test</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neuroplasticity in F16 fighter jet pilots (117 pts)]]></title>
            <link>https://pmc.ncbi.nlm.nih.gov/articles/PMC9974643/</link>
            <guid>42378138</guid>
            <pubDate>Tue, 10 Dec 2024 16:07:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9974643/">https://pmc.ncbi.nlm.nih.gov/articles/PMC9974643/</a>, See on <a href="https://news.ycombinator.com/item?id=42378138">Hacker News</a></p>
Couldn't get https://pmc.ncbi.nlm.nih.gov/articles/PMC9974643/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Depths of Wikipedians (174 pts)]]></title>
            <link>https://asteriskmag.com/issues/08/the-depths-of-wikipedians</link>
            <guid>42377770</guid>
            <pubDate>Tue, 10 Dec 2024 15:32:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/08/the-depths-of-wikipedians">https://asteriskmag.com/issues/08/the-depths-of-wikipedians</a>, See on <a href="https://news.ycombinator.com/item?id=42377770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Annie Rauwerda</span>
							</h2>
			</section>
	
			<section id="rangyscope">
					<p>A conversation about yogurt wars, German hymns, tropical cyclones, and the people who make Wikipedia function.</p>
				<div>
											<div><p><strong>Asterisk: </strong><em>You're famous for the Depths of Wikipedia account, where you share factoids from some of the most arcane, interesting, and surprising pages on Wikipedia. But you're also now a part of the broader Wikipedia community. How did you first get interested in the site, and how has your involvement changed over time?&nbsp;</em></p><p><strong>Annie Rauwerda: </strong>I started back in high school editing typos and adding things that I noticed were missing — like items to lists. But I had never done anything more than that because I was afraid of it because there are so many rules. Like, I'd seen the talk pages. And many of Wikipedia’s policies and guidelines and essays are very wordy.</p><p>Then I started the account — even though I felt a little like a phony. But I remember the first time I felt really excited about the Wikipedia community was when I got on a call with the president of Wikimedia, New York City, back in 2020. And she had told me about a guy named Jim who retired from working at the phone company. He worked in that big AT&amp;T building that doesn't have windows. I don't know exactly what he did in there — but cables and stuff. Anyway, he's retired now, and he spends all day biking around New York City and taking photos of infrastructure for Wikipedia, because Google Maps photos — and so many other photos — aren't freely licensed. And I was like, that's amazing.</p><p>So I kept hearing about more and more individual people and their shticks. There are a lot of generalists who edit Wikipedia, but there's something so endearing about the people who have just one thing. That's the first time I got excited. That was when I was brave enough to start making bolder changes and writing my own articles.&nbsp;</p><p><strong>A: </strong><em>Wikipedia's tagline is the </em>“<em>free encyclopedia, created and edited by volunteers around the world,</em>”<em> which makes it sound like a cohesive, happy little family. But as you alluded to, there's a lot of rules. It’s intimidating to write articles. Is it actually the case that there is a Wikipedia community, or is it more accurate to talk about communities within Wikipedia?</em></p><p><strong>AR: </strong>The answer is both, of course, but when people talk about Wikipedia as a decision making entity, usually they're talking about 300 people — the people that weigh in to the very serious and (in my opinion) rather arcane, boring, arduous discussions. There's not that many of them.&nbsp;</p><p>There are also a lot of islands. There is one woman who mostly edits about hamsters, and always on her phone. She has never interacted with anyone else. Who is she? She's not part of any community that we can tell.</p><p>But then there are hundreds of thousands of editors on English Wikipedia. And within that there are very specific communities that are really interesting. There's the military history WikiProject. Maybe this makes sense because of the whole military thing, but they are very hierarchical. They have a lot of rules. They're very efficient in reviewing articles. Also Wikipedia has a pretty outdated rating system for articles — one of which just got deprecated when “Featured Articles” and “Good Articles” became a thing — except for in military history, because that community was like, well, we need to have every level.&nbsp;</p><p>The same thing is true of the tropical cyclones community. They also do a lot of reviewing, and they also tend to skew very young. It's a lot of teenage boys in tropical cyclones. There's also a very strong anti-vandal community, who similarly skew very young.&nbsp;</p><p><strong>A: </strong><em>Before I had Wikipedia friends, I did not really understand how many different silos there were.</em></p><p><strong>AR: </strong>So many. There are acronyms that I hear that I do not know. The anti-vandal people especially are really off in their own world. One of the most effective, consistent, long serving anti-vandalism patrollers is not a teenager. He's a PhD-level material scientist who used to write very high quality articles about chemicals. And then he just got too upset about vandalism and decided “I have to devote hours of my life — even though I have a family and a really demanding job — to this.”</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-depths-of-wikipedians/81a1e8b3e1-1728068850/4-wiki_1.png" alt="">
  </p>
  </figure>
</div>
											<div><p><strong>A: </strong><em>What is your sense of the people who do get drawn in and commit so much time. We hear about these people who've edited over three million Wikipedia articles. What's driving them?</em></p><p><strong>AR: </strong>Well — two things. The three million articles guy, that's <a href="https://en.wikipedia.org/wiki/Steven_Pruitt">Stephen Pruitt</a>. He's wonderful. He kind of became the face of super editors. And it's because the edit count on Wikipedia is an imperfect proxy. Stephen uses bot-assisted editing — which might be something like doing categorization — and so he can do a lot of edits at one time.&nbsp; And so like, yeah, he's made an edit to a bunch of articles, but it's not the same as writing three million articles. But then again, he also writes a lot of articles.</p><p>As to what makes people get sucked in? I think that one shared quality of every single person I've met who has stuck around Wikipedia for a long time is that they have very little hesitation to work hard, and they put a low value on their own time. Maybe they are even willing to waste time. Like, people are very willing to raise concerns and discuss and accept critiques. I also think people tend to care a lot about precise language and about being correct. Some of that comes from the culture of Wikipedia, but I think it's also what predisposes them to edit it in the first place.&nbsp;</p><p><strong>A: </strong><em>Editing can seem incredibly inefficient sometimes, given that Wikipedia is so democratic and anyone can enter into any discussion. Take the page for </em><a href="https://en.wikipedia.org/wiki/Yogurt"><em>yogurt.</em></a><em> The debate over whether to call it “yogurt” or “yoghurt” lasted </em><a href="https://en.wikipedia.org/wiki/Talk:Yogurt/yogurtspellinghistory"><em>seven years</em></a><em> and totaled over 140,000 </em><a href="https://en.wikipedia.org/wiki/Talk:Yogurt/Archive_2%23Requested_move_revisited"><em>words</em></a><em>. What happened there specifically, and what makes the process so inefficient in general?</em>&nbsp;</p><p><strong>AR: </strong>I have not read all 140,000 words. That's multiple Shakespeare plays — which I would rather read.&nbsp;</p><p>My impression is that for the debates that last for so many years, people will tap in for a couple of months, and then things will kind of settle, and then they'll tap out and let other people argue. I don't really know what's going on there. I wonder if maybe it's just because people feel so invested because they've already sunk so much time and energy in and think they need to “win.”</p><p>But also — to the yogurt example specifically — when it comes to British versus American English, or Australian or Nigerian or Indian English, basically, the policy is kind of a free-for-all, and that's how it's been for a long time. It usually comes down to whether the topic has to deal with Nigeria or India. If it's about George Bush, then, like, please write it in American English. If not, the rule is to stick with whatever the original writer used. And so that's not always very satisfying. And then there's yogurt. That's not tied to any one country.</p><p><strong>A: </strong><em>You had a </em><a href="https://www.tiktok.com/@depthsofwikipedia/video/7373142677350829358?lang=en"><em>TikTok</em></a><em> about another internal Wikipedia debate. Until 2018, there were no freely licensed photos of Kim Jong Un. No one wanted to violate Korean copyright law (though there was a debate about that). And no media outlets freely licensed any photos. And this never got resolved, and so we had hand-drawn images of Kim Jong Un instead.&nbsp;</em></p><p><em>All of which leads to my larger question, which is — is the writing and editing process working?</em> &nbsp;</p><p><strong>AR: </strong>I mean, the answer is no. There are people who just kind of wait for their opponent to get carpal tunnel — and that's not productive for anyone. I would call those sorts of debates tendentious. You're not trying to find consensus. &nbsp;</p><p>I think when it comes to Wikipedia rules and interpreting the rules, it's impossible. You can't follow every single rule. And I'm using the word “rule,” but, on Wikipedia there are “policies,” which are like the Bible. But they change all the time because people work on them. And if you're going to change a policy, then it has to be discussed. And that happens all the time.</p><p>But then there are essays which are just written by a person. And they look a lot like policies! They just have a little thing on the top that says: “This is an essay.” And then there are guidelines! They basically look like rules, and people kind of treat them like rules. And so you can't really follow all of them because there's stuff that contradicts other stuff. It's a Catch-22.</p><p>Back in the day, there were <a href="https://en.wikipedia.org/wiki/Wikipedia:Five_pillars">five</a> — call them guidelines, decrees, commandments — sent down from on high from the less good co-founder, Larry Sanger. And the last one was: “Ignore all rules.” And ha! That's still there.&nbsp;</p><p>But within that, there’s a guideline: “Be bold.” And people still talk about both of those all the time. But there are rules where, if you don't follow them, and you don't have good standing or a good reputation, you're gonna get immediately blocked. And so “Ignore all the rules” and “Be bold” aren't actually true.&nbsp;</p><p>And that's the unfortunate thing about growing and becoming a massive encyclopedia that's more respected than it was in 2004. It's a lot harder to truly be this free-for-all, libertarian utopia that the founders thought it might be.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-depths-of-wikipedians/aa1861d2ce-1728068868/4-wiki_3.png" alt="">
  </p>
  </figure>
</div>
											<div><p><strong>A: </strong><em>You said there's, like, 300 people who are really making a lot of the decisions about Wikipedia editing. Who are they?&nbsp;</em></p><p><strong>AR: </strong>I threw 300 out there because — if there's a big, big vote — it's generally about 300 people who show up. About two years ago, they changed the Wikipedia skin, and so the table of contents appeared differently, and there was more white space, which people care a lot about. More than 300 people showed up for those votes — and that's about what you can expect for big votes. Usually those people are either administrators, of which, on English Wikipedia, there are fewer than a thousand active. And sometimes they're just people who care a lot about policies.&nbsp;</p><p>Who are they? I think that I can generalize because I go to a lot of meetups. There's a bimodal age distribution. There's a lot of students, very bright college students, grad students, and sometimes a precocious high schooler. (They're the best — I love them.) And then, there's a bunch of retirees. I think common professions are software and computer engineering.&nbsp;</p><p>A lot of people work blue-collar jobs. Wikipedia is like their intellectual outlet. And there are some people who are severely disabled in some way, so they don't leave the house for a traditional job — and that gives them more time to edit Wikipedia. It's more male than female.&nbsp;</p><p><strong>A: </strong><em>You’ve said that the Jimmy Wales, aughts-era goal of “building the sum of all human knowledge” was perhaps not the right goal. Why?</em></p><p><strong>AR: </strong>There are seven million articles on the English Wikipedia — which is, I think, the biggest Wikipedia. So many of them are getting dusty. They are outdated. They are suffering from, uh, a not very ethical PR person going in there. Basically, it's a lot to maintain. Do you remember Aaron Swartz?</p><p><strong>A: </strong><em>Sure.</em></p><p><strong>AR: </strong>Okay. So he was a Wikipedian. Back in 2006 he put out a <a href="http://www.aaronsw.com/weblog/whowriteswikipedia">blog post</a> that made a splash because it wasn't what people expected. The thinking back then was — okay, we have these few thousand people that are quite active on Wikipedia — they’re the ones doing all the work, right? And he was like, no. The bulk of Wikipedia's work is very much the people in the background that just see when something's wrong and fix it. Like what I did when I was 18.&nbsp;</p><p>So if the article is cottage cheese, and someone comes in and replaces it with “poop,” those will get fixed right away because first of all, there's anti-vandalism people watching, but also, even if they miss it, people are looking up cottage cheese a lot.&nbsp;</p><p>But if you're vandalizing or if you're doing something sketchy in an article about some&nbsp; really obscure person that doesn't totally meet notability standards and who isn't getting any page views, it's just impossible to maintain that stuff.&nbsp;</p><p><strong>A: </strong><em>What's the process for something getting deleted?</em></p><p><strong>AR: </strong>There's this place. We all solemnly march down to it. Anyone who wants to show up can, and then we just vote. It's called <a href="https://en.wikipedia.org/wiki/Category:Articles_for_deletion">articles for deletion</a>. Let's see what's up right now. The most recent thing I deleted was a page that had barely been changed from the 1911 encyclopedia, which was totally plundered back in the day when they were just trying to fill Wikipedia.</p><p><strong>A: </strong><em>Because it was public domain.</em></p><p><strong>AR: </strong>Right. And it was a term for a mountain that hadn't been in use since the ‘30s. It was what colonists called it. So it was a duplicate article, essentially.&nbsp;</p><p>Anyway, you nominate something for deletion, and people vote. Your vote really doesn't count very much if you don't add a reason. But then, once there's been a little bit of discussion, like, I don't know, usually if five people weigh in, that's sufficient. If it's a weird name of an old mountain, people don't really care. But if it's a big deletion, they get really huge.&nbsp;</p><p>I think more than half of the things that get nominated end up getting deleted but I need to double check that. And then, if people don't participate very much for some reason, which usually happens when it's a really boring topic that no one cares about, or it's boring and it's not clear whether or not it should be deleted — then it gets re-listed.</p><p>The standards change sometimes. Once in a blue moon, you'll have a huge deletion event, like — I don't know — we're deleting all the Olympians that don't have sources apart from this one register. So goodbye curlers from 1930! We actually do not know who you are.</p><p><strong>A: </strong><em>Speaking of sources, we are both editors. We've had the debate, sometimes, over whether or not we should cite Wikipedia. Can you answer this for us?</em>&nbsp;</p><p><strong>AR: </strong>If you're putting anything out into the world, please do not cite Wikipedia! Do not do that. I don't trust it. Ever. That's why you check all the sources. Ideally, every single thing, every single piece of information besides, like, “the sky is blue”-type stuff should be tied to a source. I would say, just cite those because people interpret things weirdly sometimes, and you never know.</p><p><strong>A: </strong><em>I'm actually surprised to hear you say that though maybe I shouldn’t be. I've definitely had conversations with people that assume that there's been so much work put into Wikipedia at this point — especially on really well sourced articles — that it's trustworthy enough.</em>&nbsp;</p><p><strong>AR: </strong>If it's a featured article, I trust it a little bit more. But I still wouldn't ever do MLA formatting with Wikipedia. But I love to trust Wikipedia when I'm just doing cursory reading about things I am interested in.</p><p><strong>A: </strong><em>This gets to areas where Wikipedia is strong. The Napoleon page, for instance, has over 500 sources. And you've touched on Wikipedia article grades. Where is Wikipedia strong and where does it need work?</em>&nbsp;</p><p><strong>AR: </strong>Okay, strong suits. Military ships of history. So strong. Tropical storms, strong. US military history, British military history. I would say, generally, it's pretty good on US politics — even local politics. There are articles about pretty much all the recent elections in random counties for the past, like, 75 years.</p><p><strong>A: </strong><em>This fits with my theory that these are the same people who are going to city council meetings.</em></p></div>
											<div><p><strong>AR </strong>Yeah. Things that are bad? I don't really talk about this as much as I should, but as an editor, I am very passionate about the articles that have a lot of page views but get very little attention from editors. Those often are things that are low-brow pop culture topics that are not naturally interesting to the median Wikipedia editor. For me, the one that I always notice is influencers. Influencers often have horrendous articles. You can tell that somebody that didn't really get the norms of Wikipedia went in there and added —&nbsp; I don't know —&nbsp; six paragraphs about the most minor scandal, all of which cited tabloids.&nbsp;</p><p>Also business articles. Or pages on CEOs. Sometimes those articles are really unbalanced, poorly written, weird, or outdated. That's not good. If they're a powerful person, we should know more about them.</p><p>And then of course people talk about the gender gap. There's been this huge push to write articles about women, and that's been pretty successful. One thing that doesn't really get at, though, is articles about hobbies or topics that are traditionally more popular among females.</p><p><strong>A: </strong><em>I have some friends who are very into this, and they're going back and fixing the textile history articles.</em></p><p><strong>AR: </strong>Yes, textiles! It's really amazing how much hasn't changed since 2003, when one Australian woman basically did it all. And then there haven't been a lot of contributions since, which is a huge bummer.&nbsp;</p><p><strong>A: </strong><em>Are there any internal mechanisms in Wikipedia for the allocation of attention beyond just the natural interests of the editors? A clearinghouse for saying: “This thing needs help. Go fix that”?</em>&nbsp;</p><p><strong>AR: </strong>There's the Signpost newspaper, which is Wikipedia's internal newspaper. That always has an “article for improvement” or whatever. There's daily tips that you can sign up for. And then there are big campaigns that come from on high from The Foundation. And those are almost always something like “photograph a monument” because people love to do that and it's a good gateway activity. Or “write a biography about a woman,” which is good. Sometimes there are photograph campaigns for culture or heritage. But you can only nominate so many topics, and they'll only get attention for a week.</p><p><strong>A: </strong><em>It sounds like Wikipedia needs to bring in newer, different demographics of writers and editors — but you've also alluded to the fact it's very intimidating to start up. Is there a process for acculturating new writers?&nbsp;</em></p><p><strong>AR: </strong>Yeah, definitely. I care a lot about holding newbies’ hands. A lot of the old timers that came up in 2004 — when there were people who actually believed the “Ignore all rules” thing — they never had to deal with all of the norms that exist now. Even if you're a Nobel Prize winner, just getting all the norms takes a minute. You have to learn it. There are some people who are truly so welcoming and kind that it makes me feel very, very excited and hopeful about the future. And then there are others that are total assholes. And that's how it goes, I guess.&nbsp;</p><p>This happens in a lot of organizations. It's not just Wikipedia. There are people who are very good at what they do, but they're also unpleasant and gruff. They get called “unblockable” because they don't violate the rules enough. But — and I don't know if this is really a trend — from my vantage point it seems like people are less tolerant of the old school, laddish internet type trolling. And that is exciting too.</p><p><strong>A: </strong><em>Wikipedia is unique in that it still feels very web 1.0 in its design and aesthetics. But it has attracted, like you said, lots of younger editors. You are Gen Z and you are both internet native and also Wikipedia native. How intergenerational is it?</em></p><p><strong>AR: </strong>The stats on Wikipedia editors are so bad that they're almost useless because people tend to be quite private. And if it's a survey that's coming from the Foundation, there's a whole mistrust of the authority thing. People don't really like to fill those out. But that's the best, objective guess at how multi-generational it is. And that is showing that people are aging. The median, and probably average, Wikipedia editor appears to be older now than ten years ago.&nbsp;</p><p><strong>A: </strong><em>Okay, you've alluded to the Foundation a couple times, and the tone of it has made it sound like the Capitol in the Hunger Games.</em></p><p><strong>AR: </strong>It's not that. So there's a lot of overlap. If you love Wikipedia, working at the Foundation is probably your dream job. It's amazing. But people butt heads with the Foundation a lot. It's fun to complain about The Man. That's definitely part of it.&nbsp;</p><p>A major factor is that, maybe four years ago, there was a big flare-up called Forum Gate, which people haven't quite recovered from. Wikipedia has this arbitration committee, and the executives at the Foundation permanently banned a guy who — while he is in the category of gruff, not friendly, not the most empathetic — was a very effective editor on the site. And tons of people either stepped back for a while or resigned in protest.</p><p>Also the Foundation is big now. And I think that some people, even if they don't admit it, hold some jealousy and resentment that there's this fancy office in San Francisco. For a nonprofit job, it's a good one. Whereas the people who actually make the product? They don't make any money. It doesn't always feel like we're trusted by the Foundation.&nbsp;</p><p>But I like the Foundation. There's a natural animosity that comes up sometimes — but overall, we work together. And more than half of the Foundation staff works on the tech — servers, MediaWiki — because you can't get enough volunteers to do that.&nbsp;</p></div>
											
											<div><p><strong>A:</strong> <em>How much authority does the Foundation have over the site?</em>&nbsp;</p><p><strong>AR: </strong>The Foundation doesn't really know what it's there to do. That's kind of what people have been saying for, like, 20 years. Some roles are very clear.&nbsp; If someone is threatening violence, give them to the trust and safety division. If there's a major tech problem, that's the Foundation. The volunteers just don't have the bandwidth for all that. But the patrolling, the determining of the rules, the participating in discussions — the Foundation is very hands off for all of that.</p><p><strong>A: </strong><em>The Did You Know section on Wikipedia features a trove of random facts every day, and that's run by a bureaucracy of volunteers. But it's not neutrally curated. It's an area for editors to show off their special interests, which has resulted in some topics being, I think, restricted. And some of those are ones you would expect, like Taylor Swift. But apparently, also, such topics as Gibraltar and German hymns?</em>&nbsp;</p><p><strong>AR: </strong>So it's not like German hymns is “banned,” and neither is Taylor Swift, or even Gibraltar — although that one was a bit more firm. It's mostly just like — hey, can we cool it? Can we cool it with the German hymns?&nbsp;</p><p>The idea behind the Did You Know section is to be interesting for readers, sort of. But really it's there because people want to show off their brand new articles, and we want to let people feel the pride of showing off their new articles. It's also a way to get a mini-review process — to make sure everything in there is cited — and it will get copy-edited for you. It's a good way to get people used to getting edited and reviewed.</p><p>But it's mostly the same squad that does the reviewing. So there are some people who never submit to the Did You Know section, and there are a lot of people that submit everything. So if you pay attention to it consistently you'll be, like, oh, another New Zealand coin. (There's a girl who's been doing lots of those, and she rocks.) Or another article about a time zone! It makes me feel a little tender. It's kind of cute.</p><p><strong>A: </strong><em>People are going to ChatGPT now as their first place to learn about a topic, compared to Wikipedia. I'm curious as to your thoughts on how LLMs are going to shift what Wikipedia feels like, and what you see as the future there.</em></p><p><strong>AR: </strong>The traffic to Wikipedia has not taken a dramatic hit.<strong> </strong>Maybe that will change in the future. The Foundation talks about coming opportunities, or the threat of LLMs. With my friends that edit a lot, it hasn't really come up a ton because I don't think they care. It doesn't affect us. We're doing the same thing. Like if all the large language models eat up the stuff we wrote and make it easier for people to get information — great. We made it easier for people to get information.</p><p>And if LLMs end up training on blogs made by AI slop and having as their basis this ouroboros of generated text, then it's possible that a Wikipedia-type thing — written and curated by a human — could become even more valuable.&nbsp;</p></div>
										 
				</div>
		
	</section>
	 	
	 	<section>            
		<p>
			Published November 2024		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	
	<!--end published content, not coming soon-->

	<!--tags-->
	 
	
	  
	<p>Subscribe</p>
	<div id="signup-article-popup">
			
<p><img src="https://asteriskmag.com/assets/img/asterisk_x.png">
		</p></div>
</div></div>]]></description>
        </item>
    </channel>
</rss>