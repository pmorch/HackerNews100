<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 06 Aug 2025 11:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Anthropic rejects the main developer of the library they use (342 pts)]]></title>
            <link>https://grell.dev/blog/ai_rejection</link>
            <guid>44808794</guid>
            <pubDate>Wed, 06 Aug 2025 07:25:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grell.dev/blog/ai_rejection">https://grell.dev/blog/ai_rejection</a>, See on <a href="https://news.ycombinator.com/item?id=44808794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
                <article>
                    <figure>
                        <picture>
                            <!-- AVIF first -->
                            <source type="image/avif" srcset="https://grell.dev/assets/img/ai_rejection/320.avif  320w,
                                https://grell.dev/assets/img/ai_rejection/640.avif  640w,
                                https://grell.dev/assets/img/ai_rejection/1280.avif 1280w,
                                https://grell.dev/assets/img/ai_rejection/1920.avif 1920w,
                                https://grell.dev/assets/img/ai_rejection/4096.avif 4096w" sizes="(max-width: 640px) 100vw,
                                (max-width:1280px) 1280px, 1920px">
                            <!-- then WebP -->
                            <source type="image/webp" srcset="https://grell.dev/assets/img/ai_rejection/320.webp  320w,
                                https://grell.dev/assets/img/ai_rejection/640.webp  640w,
                                https://grell.dev/assets/img/ai_rejection/1280.webp 1280w,
                                https://grell.dev/assets/img/ai_rejection/1920.webp 1920w,
                                https://grell.dev/assets/img/ai_rejection/4096.webp 4096w" sizes="(max-width: 640px) 100vw,
                                (max-width:1280px) 1280px, 1920px">
                            <!-- finally JPEG fallback -->
                            <img src="https://grell.dev/assets/img/ai_rejection/1280.jpg" srcset="
                                https://grell.dev/assets/img/ai_rejection/320.jpg  320w,
                                https://grell.dev/assets/img/ai_rejection/640.jpg  640w,
                                https://grell.dev/assets/img/ai_rejection/1280.jpg 1280w,
                                https://grell.dev/assets/img/ai_rejection/1920.jpg 1920w,
                                https://grell.dev/assets/img/ai_rejection/4096.jpg 4096w" sizes="(max-width: 640px) 100vw,
                                (max-width:1280px) 1280px, 1920px" alt="An AI generated image in a cyberpunk style of an AI using it's hands to reject me. The AI looks humanoid and is sitting in front of a computer." fetchpriority="high">
                        </picture>
                        <figcaption>An AI generated image of an AI using its hands to reject me.
                            Very meta, I know
                        </figcaption>
                    </figure>

                    
                    <p><time datetime="2025-07-03">2025-07-03</time></p>
                    <p>In October 2024, Anthropic released <a href="https://www.youtube.com/watch?v=ODaHJzOyVCQ">"Claude
                            Computer Use"</a>. It allows an AI to control a computer and for example copy data from a
                        browser to a spreadsheet. It's a really cool feature and since I am the maintainer of a library
                        that allows controlling a computer, I was curious to find out how they do it and learn from
                        them. I didn't have time to look into it until this spring. Anthropic is one of the leaders in
                        AI and was <a href="https://www.anthropic.com/news/anthropic-raises-series-e-at-usd61-5b-post-money-valuation">valued
                            at a cool 60+ billion dollars</a> in March 2025, so I was surprised to learn that
                        Anthropic is actually using my library <a href="https://crates.io/crates/enigo">enigo</a> for
                        it.</p>

                    <figure>
                        <picture>
                            <img src="https://grell.dev/assets/img/blinking.webp" alt="My reaction to the finding represented by the 'white guy blinking' meme." fetchpriority="high">
                        </picture>
                        <figcaption>My reaction to the finding
                        </figcaption>
                    </figure>

                    <p>You can confirm that enigo is used in Claude Desktop for macOS by running the following two
                        commands:</p>

                    <pre><code><span>$ 7z x Claude.dmg</span>
<span>$ perl -nle 'print $&amp; while /.{0,67}enigo.{0,30}/g' Claude/Claude.app/Contents/Resources/app.asar.unpacked/node_modules/claude-native/claude-native-binding.node</span>
<span>/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/enigo-0.2.1/src/macos/macos_impl.rs</span>
<span>/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/enigo-0.2.1/src/macos/macos_impl.rs</span></code></pre>

                    <p>It is also used in Claude Desktop for Windows. You can confirm it by running:</p>

                    <pre><code><span>$ 7z x Claude-Setup-x64.exe</span>
<span>$ 7z x AnthropicClaude-0.11.6-full.nupkg</span>
<span>$ perl -nle 'print $&amp; while /.{0,75}enigo.{0,26}/g' Claude-Setup-x64/AnthropicClaude-0.11.6-full/lib/net45/resources/app.asar.unpacked/node_modules/claude-native/claude-native-binding.node</span>
<span>C:\Users\runneradmin\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\enigo-0.2.1\src\win\win_impl.rs</span></code></pre>


                    <p>In the output, you can see that on both platforms <a href="https://crates.io/crates/enigo/0.2.1">enigo version
                            0.2.1</a> is used (you might have to scroll right to see it).</p>

                    <p>I am very proud that enigo matured enough for a company with a seemingly infinite development
                        budget to choose it for their commercial project. Input simulation is surprisingly difficult due
                        to little documentation
                        and a lot of OS-specific quirks and warrants its own blog post. In my (admittedly not
                        completely
                        objective) opinion enigo is a great
                        choice for the job. As far as I know, it is the only library that works on Windows, macOS,
                        *BSD and Linux (Wayland, X11 and libei) without root. It is written in Rust and thus is mostly
                        memory safe
                        while being very fast. It is the most popular choice on crates.io
                        with almost 300,000 downloads and 1,200+ stars on Github. And yet it makes me a little nervous
                        knowing that my hobby project is used by Claude Desktop and deployed to thousands of devices.
                    </p>


                    <p>If you're not familiar with open-source software, you might wonder how much money I made from
                        them — and how many Ferraris I’m going to buy. If you <em>are</em>
                        familiar with
                        open-source software, it will come as no surprise to you that I am not earning any money from
                        it.
                        enigo is published under the <a href="https://en.wikipedia.org/wiki/MIT_License">MIT
                            license</a>. That means everyone can use it free of charge. The only thing I
                        get in return is more stars on GitHub and higher download counts on crates.io (the nerd
                        equivalent of street creds).</p>

                    <p>Interestingly, although Claude Desktop is an Electron app, it's only available on
                        macOS and Windows. The benefit of Electron applications is that they work on all platforms.
                        Other people found ways to run Claude Desktop on Linux as well (<a href="https://github.com/k3d3/claude-desktop-linux-flake">1</a>, <a href="https://github.com/aaddrick/claude-desktop-debian">2</a>, <a href="https://aur.archlinux.org/packages/claude-desktop-bin">3</a>). They had to replace the
                        code that uses enigo with stubs. This is very curious, because enigo is also cross-platform.</p>

                    <p>Through a friend of a friend, I found out that Anthropic had an open position in the team
                        implementing the secret, unreleased feature of Claude Desktop using enigo. I wrote a cover
                        letter and sent out my application. An automatic reply informed me that they might take some
                        time to respond and that they only notify applicants if they made it to the next round. After a
                        few weeks without an answer, I had assumed they chose other applicants. I already forgot about
                        the
                        application when I received an e-mail from Anthropic. I excitedly opened it. Unfortunately they
                        thanked me for my application but said the team doesn't have the capacity to review additional
                        applications.</p>

                    <p>I would have loved working at Anthropic, implementing a feature similar to Computer Use and
                        bringing Claude Desktop to Linux. I thought I had a pretty good shot to get the position,
                        considering some of my code is already
                        part of their software. Through the years I accumulated a lot of knowledge in the niche that is
                        input simulation that I would have brought to the table. Working full-time on enigo for a few
                        months could lift the project to a whole different level of polish and professionalism and would
                        have helped Anthropic to be able to focus on their AI models and not input quirks.
                    </p>

                    <p>Overall I am overjoyed enigo is used in Claude Desktop and I tell everyone who listens to me
                        about it :P.
                        It's so cool to think that I metaphorically created the arms and legs for Claude AI, but I can't
                        help but wonder if the rejection letter was written by a human or Claude AI. Did the very AI I
                        helped equip with new capabilities just reject my application? On the bright side, I should now
                        be
                        safe
                        from <a href="https://wikipedia.org/wiki/Roko's_basilisk">Roko's Basilisk</a>.
                    </p>





                </article>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Kitten TTS – 25MB CPU-Only, Open-Source TTS Model (400 pts)]]></title>
            <link>https://github.com/KittenML/KittenTTS</link>
            <guid>44807868</guid>
            <pubDate>Wed, 06 Aug 2025 05:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/KittenML/KittenTTS">https://github.com/KittenML/KittenTTS</a>, See on <a href="https://news.ycombinator.com/item?id=44807868">Hacker News</a></p>
<div id="readability-page-1" class="page"><p dir="auto">Kitten TTS is an open-source realistic text-to-speech model with just 15 million parameters, designed for lightweight deployment and high-quality voice synthesis.</p><div data-snippet-clipboard-copy-content="pip install https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl"><pre><code>pip install https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl
</code></pre></div><div data-snippet-clipboard-copy-content="from kittentts import KittenTTS
m = KittenTTS(&quot;KittenML/kitten-tts-nano-0.1&quot;)

audio = m.generate(&quot;This high quality TTS model works without a GPU&quot;, voice='expr-voice-2-f' )

# available_voices : [  'expr-voice-2-m', 'expr-voice-2-f', 'expr-voice-3-m', 'expr-voice-3-f',  'expr-voice-4-m', 'expr-voice-4-f', 'expr-voice-5-m', 'expr-voice-5-f' ]

# Save the audio
import soundfile as sf
sf.write('output.wav', audio, 24000)
"><pre><code>from kittentts import KittenTTS
m = KittenTTS("KittenML/kitten-tts-nano-0.1")

audio = m.generate("This high quality TTS model works without a GPU", voice='expr-voice-2-f' )

# available_voices : [  'expr-voice-2-m', 'expr-voice-2-f', 'expr-voice-3-m', 'expr-voice-3-f',  'expr-voice-4-m', 'expr-voice-4-f', 'expr-voice-5-m', 'expr-voice-5-f' ]

# Save the audio
import soundfile as sf
sf.write('output.wav', audio, 24000)

</code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm Archiving Picocrypt (144 pts)]]></title>
            <link>https://github.com/Picocrypt/Picocrypt/issues/134</link>
            <guid>44807210</guid>
            <pubDate>Wed, 06 Aug 2025 03:14:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Picocrypt/Picocrypt/issues/134">https://github.com/Picocrypt/Picocrypt/issues/134</a>, See on <a href="https://news.ycombinator.com/item?id=44807210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      



    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p>

<react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  
  
</react-partial>




      

          

              



<header role="banner" data-is-top="true" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_product_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
          <p>
            GitHub Spark
              <span>
                New
              </span>
          </p><p>
        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    
                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:Picocrypt/Picocrypt" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="zyatvmHNj3emlsIXnzoJ09nqT9TR8a2AFFbGZON_3xjjSH77KDy4FV9Wpk0MGCW_KoblJLPzyN1PSqVFE0KRJw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="Picocrypt/Picocrypt" data-current-org="Picocrypt" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&amp;source=header-repo&amp;source_repo=Picocrypt%2FPicocrypt" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/Picocrypt/Picocrypt/issues/134&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3d2412517e62b603d6c586f0521540dece7960044eb554d72b1a56d5b18c73a6" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/voltron/issues_fragments/issue_layout;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-2cb88353-0221-4dff-aa1f-879b578f4862" for="icon-button-0a5de433-30ac-4001-8ada-0a2aae97d72d" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.76259b61ecc822265749.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div>
</header>

      
    </div>

  








    


    






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
      
    

    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
    



    
      
    


      





  



<react-app app-name="issues-react" initial-path="/Picocrypt/Picocrypt/issues/134" data-attempted-ssr="true" data-ssr="true" data-lazy="false" data-alternate="false" data-data-router-enabled="false" data-react-profiling="false">
  
  
  <div data-testid="issue-viewer-container" data-target="react-app.reactRoot"><div data-testid="issue-viewer-issue-container"><p><a href="https://github.com/HACKERALERT" data-hovercard-url="/users/HACKERALERT/hovercard" aria-label="@HACKERALERT's profile"><img data-component="Avatar" alt="@HACKERALERT" width="40" height="40" src="https://avatars.githubusercontent.com/u/48808396?u=77677d8507d0a44c6632def2a3f1262752359e11&amp;v=4&amp;size=80" data-testid="github-avatar"></a></p><div data-testid="issue-body" data-hpc="true"><h2>Description</h2><div><div><p><a href="https://github.com/HACKERALERT" data-hovercard-url="/users/HACKERALERT/hovercard" aria-label="@HACKERALERT's profile"><img data-component="Avatar" alt="@HACKERALERT" width="24" height="24" src="https://avatars.githubusercontent.com/u/48808396?u=77677d8507d0a44c6632def2a3f1262752359e11&amp;v=4&amp;size=48" data-testid="github-avatar"></a></p></div><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">Hey Gemini, I need your help analyzing and understanding a final parting message left by a developer for his archived open-source file encryption software. Can you me with that?</p></div></div></div></div><div data-testid="issue-viewer-metadata-container"><h2>Metadata</h2><h2>Metadata</h2><!--$--><!--/$--><!--$--><div data-testid="sidebar-section"><p><h3>Development</h3></p><p><span>No branches or pull requests</span></p></div><!--/$--><h2>Issue actions</h2><ul data-dividers="false" data-variant="full"></ul></div></div>
</react-app>



  



  </div>

</turbo-frame>

    </main>
  </div>

          



    <ghcc-consent id="ghcc" data-locale="en" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>



  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marines now have an official drone-fighting handbook (109 pts)]]></title>
            <link>https://www.marinecorpstimes.com/news/your-marine-corps/2025/08/04/the-marines-now-have-an-official-drone-fighting-handbook/</link>
            <guid>44807154</guid>
            <pubDate>Wed, 06 Aug 2025 03:05:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marinecorpstimes.com/news/your-marine-corps/2025/08/04/the-marines-now-have-an-official-drone-fighting-handbook/">https://www.marinecorpstimes.com/news/your-marine-corps/2025/08/04/the-marines-now-have-an-official-drone-fighting-handbook/</a>, See on <a href="https://news.ycombinator.com/item?id=44807154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-chain-name="c0fUbP76WXURanD" data-gtm-name="Article Body" id="c0fUbP76WXURanD"><article><p>On the heels of fielding the military’s first attack drone team, the U.S. Marine Corps added another weapon to their drone-fighting arsenal: a 90-page handbook all about employing small, unmanned aerial systems against the enemy and integrating them into formations.</p><p>The 1st Marine Division Schools’ Small UAS/Counter-small UAS Integration Handbook was published in June and approved for public release. It’s intended to support the 10-day sUAS/C-sUAS Integration Course recently launched at Camp Pendleton, which expects to see a throughput of about 400 students by the end of the year, according to a report from <a href="https://news.usni.org/2025/06/25/attack-of-the-drones" rel="">USNI News</a>.</p><p>A foreword to the handbook is signed by Lt. Col. Nick Freeman, director of 1st Marine Division Schools, and co-signed by two first lieutenants leading the drone integration and signature management courses. It emphasizes that the handbook will be updated and rewritten often to keep up with evolving capabilities and practices.</p><p>The book “is not a general reference on broader aspects of sUAS-related equipping, organization, and training. Instead, it synthesizes lessons learned and best practices from across 1st Marine Division and elsewhere to provide basic considerations and ‘how to’ instructions that are missing or underdeveloped in other references,” the officers write. </p><p>“In doing so, this guide also develops and seeks to standardize common sUAS procedures for the infantry, fires, reconnaissance, and aviation units that will operate together with this capability.”</p><p>The manual’s publication comes amid a clear shift in defense priorities to favor drone warfare and emphasize, in particular, proficiency with “first-person view” or “one-way attack” small drones designed to pack a lethal punch. </p><p>In addition to the fielding of the <a href="https://www.militarytimes.com/news/your-military/2025/04/30/marine-training-chief-wants-to-let-ncos-loose-with-more-drone-access/#:~:text=The%20current%20outfit%2C%20Cuomo%20said,26%20hours%20of%20simulator%20training." rel="">Marine Corps’ Attack Drone Team</a>, a small group of troops who will develop ways to employ these kinds of drones and integrate them into formations, the Pentagon in <a href="https://www.defensenews.com/pentagon/2025/07/10/hegseth-calls-for-extensive-reforms-to-pentagon-drone-buying-practices/" rel="">July announced a slate of changes to drone acquisition</a> designed to “establish UAS dominance” by 2027.</p><div><h6>RELATED</h6><article itemscope="" itemtype="http://schema.org/Article" data-story-url="/news/your-military/2025/04/30/marine-training-chief-wants-to-let-ncos-loose-with-more-drone-access/" data-story-id="72G6QKME7ZAZBFJAWULPLKE5GE" data-feature-id="false" data-story-index="1" data-promo-type="image"><div><figure type="story"><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.armytimes.com/resizer/v2/KJR7CJVNEFFBTLG7O53WDXCTRE.jpg?auth=84949f1555a57c62cc1c12d36ae09d827477fd9c4cb0baa9e547e46447a91732&amp;width=8192&amp;height=5462" srcset="https://www.armytimes.com/resizer/v2/KJR7CJVNEFFBTLG7O53WDXCTRE.jpg?auth=84949f1555a57c62cc1c12d36ae09d827477fd9c4cb0baa9e547e46447a91732&amp;width=800&amp;height=533 800w, https://www.armytimes.com/resizer/v2/KJR7CJVNEFFBTLG7O53WDXCTRE.jpg?auth=84949f1555a57c62cc1c12d36ae09d827477fd9c4cb0baa9e547e46447a91732&amp;width=1024&amp;height=682 1024w" width="8192" height="5462"></picture></figure></div></article></div><p>It’s a marked pivot from previous years, in which the services largely emphasized surveillance and logistics as the role of friendly, small drones in warfare and lacked a definitive approach to defending against hostile attack drones. </p><p>In 2020, a <a href="https://www.military.com/daily-news/2020/07/29/these-marines-just-published-how-guide-hiding-enemy-drones.html" rel="">small group of infantry Marines crowdsourced</a> an unofficial standard operating procedure for camouflaging small units from drone surveillance, underscoring the ad-hoc nature of efforts to account for this threat.</p><p>By contrast, the new 1st Marine Division handbook standardizes employment of various drones down to a common vocabulary. </p><p>Drone holding areas “are named after women and [battle positions] are named after animals (beginning with snakes), [loitering areas] are given the names of cigarettes and [task positions] are named after insects,” the manual states.</p><p>In addition, “hot walls” and “pizza slices” describe drone operating areas for hasty airspace deconfliction. </p><p>Charts and schematics show sample drone strikes in various personnel and equipment configurations. Tables break down specifications of the Corps’ most widely fielded small UAS. A sample strike brief provides a precise template for communications around drone operations. And a multi-page section on camouflage and evasion provides formal guidance on everything from hiding heat signatures to using vegetation to blend visually with the environment.</p><p>Drone employment as a team effort is emphasized throughout the book.</p><p>“In all cases, the operator of any one aerial system is unlikely to accomplish the unit’s mission by him/herself; instead, the operator performs tasks as part of a sUAS-equipped team whose other members may variously perform roles related to communications, targeting, mobility, protection, fires, maneuver/exploitation, and others,” the guide reads. </p><p>“For this reason, this handbook refers to sUAS teams as the basic unit of employment for these systems, even when the unit operating them (for example, a rifle squad or an artillery battery headquarters) may not have sUAS employment as its primary purpose.”</p><p>The handbook concludes with a list of chapters and sections the book is still missing, including weaponeering considerations for employing drones carrying munitions and a full chapter on tactics, techniques and procedures for one-way attack drones.</p><p>“Make no mistake, we are in a very tight race with our adversaries to master the possibilities of small aerial drones,” the authors write. “Consider this handbook a baton—now take it, and run with it!”</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.marinecorpstimes.com/resizer/v2/J5ON7Y2ROFB7DMYM5UTINDJOSU.jpg?auth=cd9b602d7f718768f26b0d82fe0c9ff854115b8ca8ea13e4ae4e81d259b03703&amp;width=7210&amp;height=4809" srcset="https://www.marinecorpstimes.com/resizer/v2/J5ON7Y2ROFB7DMYM5UTINDJOSU.jpg?auth=cd9b602d7f718768f26b0d82fe0c9ff854115b8ca8ea13e4ae4e81d259b03703&amp;width=800&amp;height=533 800w, https://www.marinecorpstimes.com/resizer/v2/J5ON7Y2ROFB7DMYM5UTINDJOSU.jpg?auth=cd9b602d7f718768f26b0d82fe0c9ff854115b8ca8ea13e4ae4e81d259b03703&amp;width=1024&amp;height=682 1024w" width="7210" height="4809"></picture></figure><figcaption>Marines with Advanced Infantry Training Battalion, School of Infantry – East load a Mjolnir munitions system on a SkyRaider. (Cpl. Zachariah Ferraro/Marine Corps)</figcaption></figure><p>While 1st Marine Division did not make anyone available to talk about the handbook by press time, Samuel Bendett, an adviser focusing on Russian military technology and capabilities including drones, called the book’s publication evidence of a “psychological shift” about the realities of the drone threat and the need to employ small UAS skillfully.</p><p>The handbook itself acknowledges lessons in drone use absorbed from the ongoing Russia-Ukraine war, where both sides have employed UAS to great effect. </p><p>While Bendett acknowledged that the next U.S. fight might not resemble the conflict in Ukraine, he maintained that the echoes of that war “will be heard in every conflict going forward,” adding that China was paying close attention and already training its military in drone warfare.</p><p>“It’s not just an abstract notion that there are adversary drones somewhere and we have to defend against them,” Bendett said. “It’s the fact that it’s right there, just around the bend, just just beyond the next building, just beyond the next tree. It’s there just two or three klicks away, and it’s observing and flying at you, and you won’t be able to react in time if you’re not prepared for it.”</p><p>Another helpful shift evidenced in the document, he said, was in viewing UAS not as small aircraft, but as weapons.</p><p>“These are not aircraft,” he said. “These are cheaper, attritable tactical systems that should be available to every military formation, based on what they’re doing and based on how they’re fighting.”</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Software Rot (126 pts)]]></title>
            <link>https://permacomputing.net/software_rot/</link>
            <guid>44807002</guid>
            <pubDate>Wed, 06 Aug 2025 02:35:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://permacomputing.net/software_rot/">https://permacomputing.net/software_rot/</a>, See on <a href="https://news.ycombinator.com/item?id=44807002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pagebody" role="main" class="page">
<p><strong>Software rot</strong> is generally thought of as degradation of <a href="https://permacomputing.net/software/">software</a> due to a changing environment. For example, a program written a decade ago may no longer work with new versions of the libraries it depends on because some of them have changed without retaining backwards compatibility. This kind of thinking encourages a culture where software becomes <a href="https://permacomputing.net/obsolescence/">obsolete</a> unless it is constantly maintained.</p>

<p>A better approach might be to talk about the reliability of the environment the software depends on. Would you build a house on a bog?</p>

<p>It is often necessary to build on "bogs" (i.e. "actively developed" platforms), but it might be a good idea to also be compatible with a <a href="https://permacomputing.net/bedrock_platform/">bedrock platform</a> whose specifications are static and solid.</p>

<p>Software rot is a big issue for cultures that constantly produce new programs (such as <a href="https://permacomputing.net/games/">games</a> or <a href="https://permacomputing.net/demoscene/">demos</a>) that are not supposed to be constantly maintained after release. Programs written for classical platforms (such as <a href="https://permacomputing.net/DOS/">DOS</a> or <span><a href="https://permacomputing.net/ikiwiki.cgi?do=create&amp;from=software_rot&amp;page=NES" rel="nofollow">?</a>NES</span>) usually need no post-release maintentance at all, while those written for e.g. <span><a href="https://permacomputing.net/ikiwiki.cgi?do=create&amp;from=software_rot&amp;page=Linux" rel="nofollow">?</a>Linux</span> will likely cease working in a decade or two. Sometimes, serious <span><a href="https://permacomputing.net/ikiwiki.cgi?do=create&amp;from=software_rot&amp;page=media_archeology" rel="nofollow">?</a>media archeology</span> work (such as finding specific versions of old libraries) is needed to get a program to run again.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kitten TTS: 25MB CPU-Only, Open-Source Voice Model (190 pts)]]></title>
            <link>https://algogist.com/kitten-tts-the-25mb-ai-voice-model-thats-about-to-change-everything-runs-on-a-potato/</link>
            <guid>44806543</guid>
            <pubDate>Wed, 06 Aug 2025 01:13:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://algogist.com/kitten-tts-the-25mb-ai-voice-model-thats-about-to-change-everything-runs-on-a-potato/">https://algogist.com/kitten-tts-the-25mb-ai-voice-model-thats-about-to-change-everything-runs-on-a-potato/</a>, See on <a href="https://news.ycombinator.com/item?id=44806543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        



        

        <main>



<article>
    

    <section id="post-body"><p>Alright, let's have a real talk. For years, the AI world has been obsessed with BIG. Big models, big data, big GPUs, and even bigger cloud bills. Most text-to-speech (TTS) models today are heavyweight champs of burning cash. We're talking about multi-billion parameter, GPU-guzzling monsters that need more silicon than your phone, your laptop, and maybe your entire neighborhood combined. They give you great voices, sure... but only if you're willing to sign away your firstborn to AWS.</p><p>Forget that. The era of bloated AI is OVER.</p><p>What if I told you the real revolution isn't coming from a massive, air-conditioned data center? It's coming from a model so small, it's almost a joke. A model that fits on a thumb drive with room to spare.</p><h2 id="say-hello-to-kitten-tts-%F0%9F%98%BB">Say hello to <strong>Kitten TTS</strong>. 😻</h2><figure><blockquote><div lang="en" dir="ltr"><p>Introducing Kitten TTS, a SOTA tiny text-to-speech model</p><p>- Just 15M parameters <br>- Runs without a GPU<br>- Model size less than 25 MB<br>- Multiple high-quality voices<br>- Ultra-fast - even runs on low-end edge devices</p><p>Github and HF links below <a href="https://t.co/9T3u1M0WGo">pic.twitter.com/9T3u1M0WGo</a></p></div>— Divam Gupta (@divamgupta) <a href="https://twitter.com/divamgupta/status/1952762876504187065?ref_src=twsrc%5Etfw">August 5, 2025</a></blockquote>
</figure><p>This isn't just another model dropped on Hugging Face; it's a statement. It's the David to the Goliath of big tech AI. Developed by the wizards at KittenML, this thing is here to prove that size ISN'T everything.</p><p>And listen, this isn't happening in a vacuum. The whole industry is waking up and smelling the coffee smaller, smarter, more efficient models are the future. We are witnessing a massive shift towards lean, on-device AI that actually respects your privacy and your wallet. This is about putting power back into the hands of the builders, the creators, the hobbyists the people who don't have a venture capitalist on speed dial. This move away from centralized, big-tech-controlled AI toward a distributed, community-driven ecosystem is the most exciting thing happening in tech right now. And Kitten TTS isn't just following the trend; it's leading the charge.</p><h2 id="the-specs-that-will-blow-your-mind-%F0%9F%A4%AF"><strong>The Specs That Will BLOW YOUR MIND 🤯</strong></h2><p>Okay, let's get into the nitty-gritty. What makes this little beast tick? These aren't just bullet points on a GitHub README; these are the specs that will fundamentally redefine what you thought was possible with local AI.</p><h3 id="15m-parameters-25mb-size-no-thats-not-a-typo"><strong>15M Parameters &amp; &lt;25MB Size. NO, THAT'S NOT A TYPO.</strong></h3><p>Most so-called "lightweight" models are still chunky boys, coming in at hundreds of megabytes. Kitten TTS? It clocks in at <strong>under 25MB</strong> with just <strong>15 million parameters</strong>. Let that sink in. That's smaller than most of the photos you take on your phone. It's about one-fifth the size of the previous "small" champion, Kokoro-82M, a model that was already celebrated for its efficiency. This ridiculously small footprint means it downloads in seconds and can be deployed on literally anything.</p><h3 id="runs-without-a-gpu-your-wallet-can-thank-us"><strong>Runs WITHOUT A GPU. Your Wallet Can Thank Us.</strong></h3><p>This is the big one. This is for all my "GPU-poor" folks out there who have been watching the AI revolution from the sidelines.<strong><sup> </sup></strong>YOU DO NOT NEED AN EXPENSIVE GRAPHICS CARD. Kitten TTS is aggressively CPU-optimized to run on your everyday laptop, a cheap Raspberry Pi, your Android phone... and probably even a smart toaster if you're feeling adventurous. I'm not kidding people have tested this on a free Google Colab CPU instance, and it was generating audio in SECONDS. The barrier to entry just got obliterated.</p><h3 id="multiple-expressive-voices-the-whole-fam"><strong>Multiple Expressive Voices (The Whole Fam!)</strong></h3><p>For a model this tiny, you'd expect a single, robotic, "Stephen Hawking circa 1988" voice, right? WRONG. Kitten TTS ships with <strong>eight different expressive voices</strong> four female and four male right out of the box. For a model of this size, the level of expressivity is honestly shocking and a massive advantage for anyone looking to build applications with character. We'll meet them all in a bit.</p><h3 id="ultra-fast-inference-for-real-time-apps"><strong>Ultra-Fast Inference for Real-Time Apps</strong></h3><p>This thing is BUILT FOR SPEED. It’s optimized for real-time speech synthesis, which means no more awkward, laggy delays in your applications. This is absolutely critical for building responsive chatbots, voice assistants that don't make you wait, and on-the-fly narration for accessibility tools. Anecdotal reports from community demos show it generating audio faster than real-time even on consumer hardware.</p><h3 id="open-source-baby-apache-20-license"><strong>OPEN SOURCE, BABY! (Apache 2.0 License)</strong></h3><p>And here's the cherry on top. The best part. It's completely open source under the permissive Apache 2.0 license. This means you can use it for free. For your personal projects. For your commercial products. For whatever you want. No strings attached. Go build something amazing and make some money! The code is on GitHub, the model is on Hugging Face... the playground is yours.</p><p>What's truly remarkable here is the cascade of innovation. It all starts with the core architectural breakthrough: achieving impressive quality with a tiny number of parameters. This single achievement directly causes the sub-25MB model size. That small size, in turn, is what allows it to run so efficiently on CPU-only systems. And that CPU efficiency is what unlocks its potential on low-power edge devices like the Raspberry Pi. It's a beautiful domino effect where one smart design choice solves for size, cost, and speed all at once the holy trinity for edge AI.</p><h2 id="enough-talk-lets-get-this-running-now-the-5-minute-guide"><strong>Enough Talk! Let's Get This Running NOW (The 5-Minute Guide)</strong></h2><p>Theory is great, but code is king. Let's get this running on your machine. No more excuses, this is copy-paste-ready. Let's GO! 🚀</p><h3 id="step-1-the-magical-one-line-install"><strong>Step 1: The Magical One-Line Install</strong></h3><p>Open your terminal. Do the right thing and create a virtual environment (<code>python -m venv.venv &amp;&amp; source.venv/bin/activate</code>). Now, paste this in. That's it. You're done.</p><pre><code># It's this easy, seriously.
pip install https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl</code></pre><h3 id="step-2-your-first-hello-world-basic-generation"><strong>Step 2: Your First "Hello World" (Basic Generation)</strong></h3><p>Create a Python file, call it <code>test_kitten.py</code>, and drop this code in. This will automatically grab the model from Hugging Face the first time you run it and generate your very first audio file.</p><pre><code># test_kitten.py
from kittentts import KittenTTS
import soundfile as sf

print("Loading KittenTTS model... Meow! 🐱")
# This downloads the model from Hugging Face the first time
m = KittenTTS("KittenML/kitten-tts-nano-0.1")

text = "This high quality TTS model works without a GPU, which is pretty awesome!"

print(f"Generating audio for: '{text}'")
# Generate the audio waveform
audio = m.generate(text)

# Save the audio to a file at 24kHz sample rate
output_file = 'hello_kitten.wav'
sf.write(output_file, audio, 24000)

print(f"✅ Audio saved to {output_file}! Go listen to it!")</code></pre><p>Run it with <code>python test_kitten.py</code> and go check out <code>hello_kitten.wav</code>. Welcome to the future.</p><h3 id="step-3-meet-the-whole-crew-looping-through-all-voices"><strong>Step 3: Meet the Whole Crew (Looping Through All Voices)</strong></h3><p>Okay, that was cool, but you just used the default voice. <strong>PRO TIP:</strong> The default voice (<code>expr-voice-5-m</code>) is... let's just say it has <em>character</em>. Some of the other voices are WAY better for general use. Let's generate a sample for every single voice so you can pick your favorite for your next project.</p><p>Create a new file, <code>all_voices.py</code>:</p><pre><code># all_voices.py
from kittentts import KittenTTS
import soundfile as sf

m = KittenTTS("KittenML/kitten-tts-nano-0.1")

TEXT = "Kitten TTS is an open-source series of tiny and expressive Text-to-Speech models for on-device applications."

# Get the list of all available voices
available_voices = m.available_voices
print(f"Available voices: {available_voices}")

for voice in available_voices:
    output_file = f"output_{voice}.wav"
    print(f"▶️ Generating for voice '{voice}' -&gt; {output_file}")
    
    # The magic is here: specify the voice!
    m.generate_to_file(TEXT, output_file, voice=voice)
    
print("✅ All voice samples generated!")</code></pre><p>Run this script, and you'll get a <code>.wav</code> file for each voice. To make it even easier, here's the official roster.</p>
<!--kg-card-begin: html-->
<table><colgroup><col><col><col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p>Voice ID</p></td><td colspan="1" rowspan="1"><p>Gender</p></td><td colspan="1" rowspan="1"><p>Vibe Check (Our Description)</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-2-f</code></p></td><td colspan="1" rowspan="1"><p>Female</p></td><td colspan="1" rowspan="1"><p>Clear, professional, great for narration.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-2-m</code></p></td><td colspan="1" rowspan="1"><p>Male</p></td><td colspan="1" rowspan="1"><p>Solid, standard male voice. The reliable choice.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-3-f</code></p></td><td colspan="1" rowspan="1"><p>Female</p></td><td colspan="1" rowspan="1"><p>A bit more expressive, good for character work.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-3-m</code></p></td><td colspan="1" rowspan="1"><p>Male</p></td><td colspan="1" rowspan="1"><p>Deep, thoughtful. Perfect for storytelling.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-4-f</code></p></td><td colspan="1" rowspan="1"><p>Female</p></td><td colspan="1" rowspan="1"><p>Upbeat and friendly. Your go-to for assistants.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-4-m</code></p></td><td colspan="1" rowspan="1"><p>Male</p></td><td colspan="1" rowspan="1"><p>Energetic and clear. Gets the point across.</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-5-m</code></p></td><td colspan="1" rowspan="1"><p>Male</p></td><td colspan="1" rowspan="1"><p>The default. A bit... unique. Use with caution! 😉</p></td></tr><tr><td colspan="1" rowspan="1"><p><code spellcheck="false">expr-voice-5-f</code></p></td><td colspan="1" rowspan="1"><p>Female</p></td><td colspan="1" rowspan="1"><p>Note: Sources are conflicting. Some list 7 voices, some list 8. The official GitHub lists 7, ending with 5-m. We'll update as the project evolves!</p></td></tr></tbody></table>
<!--kg-card-end: html-->
<h2 id="under-the-hood-how-does-this-magic-work-a-technical-deep-dive"><strong>Under the Hood: How Does This Magic Work? (A Technical Deep Dive)</strong></h2><p>So, how in the world did KittenML pull this off? How do you squeeze a decent-quality voice out of a model that's smaller than a cat video? While the team hasn't released a full research paper just yet, the open-source community has put on its detective hat, and the consensus is pretty clear.</p><p>The smart money, especially among the folks at r/LocalLLaMA, is that Kitten TTS is built on an architecture that's very similar to <strong>VITS</strong> (Variational Inference with Adversarial Learning for End-to-End Text-to-Speech) or possibly <strong>StyleTTS2</strong>.</p><p>Don't let the alphabet soup of an acronym scare you. VITS is a brilliantly clever end-to-end system that mashes up several powerful AI concepts into one elegant package:</p><ol><li><strong>Variational Autoencoder (VAE):</strong> At its core, a VAE is great at learning a compressed, meaningful representation of data. In this case, it learns the essential "essence" of speech.</li><li><strong>Normalizing Flows:</strong> This is a fancy mathematical trick that helps the model produce more diverse and natural-sounding variations in the speech, avoiding a monotonous, robotic tone.</li><li><strong>Generative Adversarial Network (GAN):</strong> This is the secret sauce that pushes the quality over the top. A GAN consists of two models locked in a battle to the death.<ul><li>The <strong>Generator</strong> creates the audio from text.</li><li>The <strong>Discriminator</strong> acts like a critic, trying to tell if the audio it hears is from a real human or a fake from the Generator.</li><li>They are trained together. The Generator's only goal is to fool the Discriminator, and the Discriminator's only goal is to not be fooled. Through this adversarial process, the Generator gets incredibly good at producing highly realistic speech.</li></ul></li></ol><p>This architecture is perfect for a model named "Kitten" because it's known for being incredibly efficient. It's a non-autoregressive model, which means it generates audio chunks in parallel instead of one sample at a time. This makes it blazing fast compared to older, step-by-step models like Tacotron 2. This combination of a VAE, GAN, and a parallel transformer backbone is what allows models like VITS and likely Kitten to be small, fast, and high-quality all at once.</p><p>The success here isn't necessarily about inventing a single, brand-new algorithm from thin air. It's about masterful engineering. It's the art of taking several powerful, proven concepts and synthesizing them into a highly optimized and refined implementation. This is a testament to the fact that in modern AI, execution and clever combination are just as important as pure research.</p><h2 id="kitten-tts-vs-the-world-a-local-tts-showdown"><strong>Kitten TTS vs. The World: A Local TTS Showdown</strong></h2><p>Okay, Kitten TTS is cool on its own. But how does it stack up against the other legends of local TTS? Let's throw it in the ring and see what happens. Ding ding! 🥊</p><h3 id="kitten-tts-vs-piper-tts"><strong>Kitten TTS vs. Piper TTS</strong></h3><p>This is the ultimate battle for the soul of your Raspberry Pi. For a long time, Piper TTS has been the undisputed king of fast, offline, on-device speech synthesis. It's known for being incredibly fast, running on minimal hardware, and having solid voice quality.</p><p><strong>The Verdict:</strong> Kitten is the new challenger, and it's coming in with a significant weight advantage. It is even <em>smaller</em> than most of Piper's voice models and targets the same CPU-only performance profile. For pure, bare-metal efficiency and the absolute smallest possible footprint, Kitten has a real edge. However, Piper has a more mature ecosystem, a wider variety of community-trained voices, and better language support at the moment. It's a close fight.</p><p>Your Choice: If you need the absolute tiniest model for an English-language project, try Kitten first. If you need broader language support or want to tap into a larger library of voices, Piper is still a fantastic choice.</p><h3 id="kitten-tts-vs-kokoro-tts"><strong>Kitten TTS vs. Kokoro TTS</strong></h3><p>Kokoro was the model that first made the community truly believe that small, high-quality TTS was possible. At 82M parameters, it was a huge step down from the billion-parameter giants and delivered impressive "Siri-like" quality on standard CPUs.</p><p><strong>The Verdict:</strong> This is a generational leap. Kitten TTS is <strong>~15M parameters</strong>. Kokoro walked so that Kitten could run a marathon. While Kokoro proved the concept, Kitten has refined it to an extreme degree, offering comparable or better expressiveness at a fraction of the size.</p><p>Your Choice: For any new project where efficiency is a concern, Kitten TTS is the clear winner in the size-to-quality trade-off.</p><h3 id="kitten-tts-vs-coqui-xtts"><strong>Kitten TTS vs. Coqui XTTS</strong></h3><p>This isn't a direct fight; it's about picking the right tool for the job. Coqui's XTTS is a heavyweight champion in its own right, but for a different reason: its incredible <strong>zero-shot voice cloning</strong>. You can feed it a mere 6-second audio clip of a voice, and it can start speaking in that voice. It's magic, but it's a different kind of magic.</p><p><strong>The Verdict:</strong> If your project requires cloning a specific voice, XTTS is the model you want. No question. But this power comes at a cost it's a much larger model and really wants a GPU to run smoothly. Kitten TTS is built for a different purpose: providing a set of high-quality, pre-built voices in the most lightweight and efficient package possible.</p><p>Your Choice: Use Kitten for speed, efficiency, and on-device deployment. Use XTTS for voice cloning and advanced style transfer features.</p><p>To make it even clearer, here's a handy comparison table:</p>
<!--kg-card-begin: html-->
<table><colgroup><col><col><col><col><col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p>Feature</p></td><td colspan="1" rowspan="1"><p>Kitten TTS (Nano)</p></td><td colspan="1" rowspan="1"><p>Piper TTS</p></td><td colspan="1" rowspan="1"><p>Kokoro TTS</p></td><td colspan="1" rowspan="1"><p>Coqui XTTS-v2</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>Model Size</strong></p></td><td colspan="1" rowspan="1"><p><strong>&lt;25 MB (15M params)</strong></p></td><td colspan="1" rowspan="1"><p>~50-100 MB per voice</p></td><td colspan="1" rowspan="1"><p>~165 MB (82M params)</p></td><td colspan="1" rowspan="1"><p>~1.5 GB+</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>Resource Needs</strong></p></td><td colspan="1" rowspan="1"><p><strong>CPU-only, low RAM</strong></p></td><td colspan="1" rowspan="1"><p>CPU-only, low RAM (RPi)</p></td><td colspan="1" rowspan="1"><p>CPU-only, moderate RAM</p></td><td colspan="1" rowspan="1"><p>GPU Recommended</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>Key Feature</strong></p></td><td colspan="1" rowspan="1"><p><strong>Extreme Size &amp; Efficiency</strong></p></td><td colspan="1" rowspan="1"><p>Speed &amp; Language Support</p></td><td colspan="1" rowspan="1"><p>Good quality for its size</p></td><td colspan="1" rowspan="1"><p>Zero-Shot Voice Cloning</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>Use Case</strong></p></td><td colspan="1" rowspan="1"><p>Edge AI, IoT, Accessibility</p></td><td colspan="1" rowspan="1"><p>Offline Assistants, RPi</p></td><td colspan="1" rowspan="1"><p>General CPU-based TTS</p></td><td colspan="1" rowspan="1"><p>Custom Voice Applications</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>License</strong></p></td><td colspan="1" rowspan="1"><p><strong>Apache 2.0 (Commercial OK)</strong></p></td><td colspan="1" rowspan="1"><p>Apache 2.0 (Commercial OK)</p></td><td colspan="1" rowspan="1"><p>Apache 2.0 (Commercial OK)</p></td><td colspan="1" rowspan="1"><p>Coqui Public License (Non-Commercial)</p></td></tr></tbody></table>
<!--kg-card-end: html-->
<h2 id="the-game-changing-applications-this-is-why-were-all-here"><strong>The Game-Changing Applications (This Is Why We're All Here)</strong></h2><p>Specs and code are fun, but what can you <em>actually build</em> with this? This is where it gets really exciting. Kitten TTS isn't just a cool tech demo; it's an enabler for a whole new generation of applications that were previously impossible, impractical, or just too damn expensive.</p><h3 id="application-1-true-edge-ai-private-iot"><strong>Application 1: True Edge AI &amp; Private IoT</strong></h3><p>Because Kitten runs entirely locally, it is the perfect engine for <strong>Edge AI</strong>. Think about it: smart home devices that can talk to you without sending your conversations to a server in another country.<strong><sup> </sup></strong>This means three huge things:</p><ol><li><strong>Lower Latency:</strong> Responses are instant because there's no round-trip to the cloud.</li><li><strong>Better Privacy:</strong> Your data never leaves your device. This is a massive deal.</li><li><strong>Offline Functionality:</strong> It works even when your internet is down.</li></ol><p>This unlocks applications like voice-enabled industrial sensors, talking toys for kids that don't spy on them, and smart home assistants that actually respect your privacy.<strong><sup> </sup></strong>The move to on-device processing is a direct response to growing public concern over data privacy, and Kitten is perfectly positioned to power this new wave of secure-by-design products. By eliminating the need to transmit sensitive voice data, it not only protects users but also simplifies compliance with data sovereignty laws.</p><h3 id="application-2-revolutionizing-accessibility-tools"><strong>Application 2: Revolutionizing Accessibility Tools</strong></h3><p>This one is HUGE, and it's something the community is genuinely excited about. People with visual impairments or learning disabilities like dyslexia rely on screen readers to access the digital world. But let's be honest, many of the default voices are still robotic and fatiguing to listen to. A user on Reddit specifically brought up this pain point, wishing for a better voice for the <strong>NVDA screen reader</strong> that wouldn't hog system resources.</p><p>Kitten TTS is the answer. It is small and fast enough to be integrated directly into accessibility tools like NVDA, providing a much more natural, human-sounding voice without slowing down the user's computer. This isn't just a cool feature; it's technology that can genuinely improve people's daily lives and make the digital world more inclusive.</p><h3 id="application-3-the-indie-dev-hobbyists-dream"><strong>Application 3: The Indie Dev &amp; Hobbyist's Dream</strong></h3><p>Want to build a voice for your custom robot? Need to give dialogue to characters in your indie game? Want to create a custom Jarvis-like assistant for your workshop? Before Kitten, you'd need to wrestle with a pricey API or set up a dedicated server. Now, you can do it all on a <strong>Raspberry Pi</strong>. Kitten TTS democratizes high-quality voice synthesis, putting it directly into the hands of every creator, student, and hobbyist, regardless of their budget.</p><h2 id="the-final-verdict-the-future-of-kitten"><strong>The Final Verdict &amp; The Future of Kitten</strong></h2><p>So, is Kitten TTS the perfect, flawless model that will end all others? Let's be real: <strong>not yet</strong>. It's still in <strong>developer preview</strong>. Some users have noted a bit of "soft distortion" in the audio or that the quality isn't quite at the level of the massive, expensive cloud APIs. There's a reason it's called a "preview," after all.</p><p>BUT, that's completely missing the point. The magic of Kitten TTS isn't that it's better than a model 1000x its size. The magic is that it's <strong>so damn good <em>for</em> its size</strong>. The performance-to-parameter ratio is absolutely off the charts. It represents a quantum leap in efficiency and accessibility.</p><p>And the story isn't over. The KittenML team has already announced they're working on a larger, <strong>~80M parameter model</strong> that will use the same eight expressive voices. This "big brother" version will likely smooth out the minor quality issues of the 'nano' model while still being small and efficient enough to run on a CPU. The future is incredibly bright.</p><p>Kitten TTS is a game-changer. It's a testament to the power of open-source innovation and the unstoppable trend toward smarter, smaller, more accessible AI.</p><p>Don't just read about it. <strong>Go build something!</strong></p><ul><li><strong>GitHub Repo: </strong><a href="https://github.com/KittenML/KittenTTS" rel="noreferrer">https://github.com/KittenML/KittenTTS</a></li><li><strong>Hugging Face Model:</strong> <a href="https://huggingface.co/KittenML/kitten-tts-nano-0.1" rel="noopener">https://huggingface.co/KittenML/kitten-tts-nano-0.1</a></li><li><strong>Live Web Demo (Community Built!):</strong> <a href="https://clowerweb.github.io/kitten-tts-web-demo/" rel="noopener">https://clowerweb.github.io/kitten-tts-web-demo/</a></li><li><strong>Join the Discord:</strong> <a href="https://discord.gg/upcyF5s6" rel="noopener">https://discord.gg/upcyF5s6</a></li></ul><h2 id="faq-disambiguation"><strong>FAQ &amp; Disambiguation</strong></h2><h3 id="wait-isnt-kitten-a-character-from-warhammer-40k"><strong>Wait, Isn't Kitten a Character from Warhammer 40k?</strong></h3><p>LOL, you got us. If you searched for "Kitten TTS" and were expecting the glorious Captain-General of the Adeptus Custodes, you're in the wrong place... but welcome! That legendary "Kitten" is from the amazing YouTube series <em>If the Emperor had a Text-to-Speech Device</em>. THIS Kitten TTS is an AI model. Both are pretty awesome, though.</p><h3 id="is-there-a-research-paper"><strong>Is there a research paper?</strong></h3><p>Not yet! The team has mentioned they plan to release more details about their training techniques and architecture soon, likely after the full release. The community is eagerly waiting!</p><h3 id="what-about-benchmarks-like-rtf-or-mos"><strong>What about benchmarks like RTF or MOS?</strong></h3><p>No official, formal benchmarks have been published by the creators yet. However, we can get a clue from the community. In a web demo, one user on an M1 Mac clocked a generation time of about 19 seconds for a 26-second audio clip. This gives us a rough</p><p><strong>Real-Time Factor (RTF)</strong> of about 0.73. RTF is simply the time it takes to generate the audio divided by the duration of the audio itself, so anything under 1.0 is faster than real-time. For a CPU-only model running in a browser, that's very promising!</p><h3 id="what-languages-does-it-support"><strong>What languages does it support?</strong></h3><p>Currently, the <code>nano-0.1</code> preview model only supports <strong>English</strong>. However, the team has stated that multilingual support is on the roadmap for future releases.</p><h3 id="what-is-kitten-tts-and-why-is-it-a-big-deal"><strong>What is Kitten TTS and why is it a big deal?</strong></h3><p>It’s a ~15M-parameter, <strong>&lt;25 MB</strong> text-to-speech model that runs well on plain CPUs and is Apache-2.0 licensed so you can ship it in products without GPU or API costs.</p><h3 id="does-kitten-tts-need-a-gpu"><strong>Does Kitten TTS need a GPU?</strong></h3><p>No. That’s the point it’s optimized for CPU and even runs fully in the browser in a community demo.</p><h3 id="how-big-is-the-download-exactly"><strong>How big is the download, exactly?</strong></h3><p>Under ~25 MB for the nano 0.1 preview (about 15M params). It pulls down fast and works out of the box.</p><h3 id="how-many-voices-does-it-have"><strong>How many voices does it have?</strong></h3><p>Multiple expressive presets (commonly cited as ~8: 4F/4M). Use <code>available_voices</code> in the API to list and pick.</p><h3 id="is-it-multilingual-yet"><strong>Is it multilingual yet?</strong></h3><p>The nano-0.1 preview is <strong>English-only</strong>. Multilingual support is on the roadmap.</p><h3 id="can-it-run-in-the-browser"><strong>Can it run in the browser?</strong></h3><p>Yes, there’s a community web demo using <code>transformers.js</code> that runs fully client-side on CPU. Great for quick tests.</p><h3 id="does-kitten-tts-support-ssml"><strong>Does Kitten TTS support SSML?</strong></h3><p>Not officially in the preview docs. Community threads have asked about it; for now, I control prosody with punctuation and chunking.</p><h3 id="does-it-do-zero-shot-voice-cloning"><strong>Does it do zero-shot voice cloning?</strong></h3><p>No that’s where <strong>Coqui XTTS-v2</strong> shines, but XTTS is heavier and GPU-friendly rather than tiny CPU-only. Use Kitten for preset voices and speed; XTTS for cloning.</p><h3 id="kitten-tts-vs-piper-what-should-i-pick"><strong>Kitten TTS vs Piper what should I pick?</strong></h3><p>If you want the <strong>smallest</strong> footprint for English on CPU, start with Kitten. If you need broader language coverage and a mature ecosystem, Piper is still excellent. I use both depending on target.</p><h3 id="kitten-tts-vs-kokoro-who-wins-on-cpus"><strong>Kitten TTS vs Kokoro who wins on CPUs?</strong></h3><p>Kokoro (≈82M) proved small can sound good; Kitten pushes size/latency further at ~15M. For super-lean builds, Kitten has the edge; Kokoro has more established usage and voices.</p><h3 id="is-the-license-ok-for-commercial-use"><strong>Is the license OK for commercial use?</strong></h3><p>Yes. <strong>Apache-2.0</strong> permissive and business-friendly. Ship it.</p><h3 id="how-do-i-install-it-quickly"><strong>How do I install it quickly?</strong></h3><p>Create a venv and <code>pip install</code> the wheel from the latest GitHub release, then load <code>"KittenML/kitten-tts-nano-0.1"</code> in your code. Simple, reproducible, and offline-friendly.</p><h3 id="is-it-fast-enough-for-real-time"><strong>Is it fast enough for real-time?</strong></h3><p>Early community reports and the browser demo are promising on CPU. For snappy UX, stream shorter chunks and cache frequent phrases.</p><h3 id="any-gotchas-i-should-know"><strong>Any gotchas I should know?</strong></h3><p>It’s a <strong>developer preview</strong> some users note mild artifacts on certain voices. I pick the cleaner presets (e.g., “2-f/2-m/4-f”) for narration.</p><h3 id="what-are-good-use-cases-right-now"><strong>What are good use cases right now?</strong></h3><p>On-device assistants, offline accessibility tools, indie games/NPCs, and privacy-sensitive apps that can’t rely on cloud TTS. (That’s exactly where I’d ship it first.)</p></section>




</article>


    




</main>

        

        

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HHS Winds Down mRNA Vaccine Development Under BARDA (122 pts)]]></title>
            <link>https://www.hhs.gov/press-room/hhs-winds-down-mrna-development-under-barda.html</link>
            <guid>44805261</guid>
            <pubDate>Tue, 05 Aug 2025 22:29:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hhs.gov/press-room/hhs-winds-down-mrna-development-under-barda.html">https://www.hhs.gov/press-room/hhs-winds-down-mrna-development-under-barda.html</a>, See on <a href="https://news.ycombinator.com/item?id=44805261">Hacker News</a></p>
Couldn't get https://www.hhs.gov/press-room/hhs-winds-down-mrna-development-under-barda.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Create personal illustrated storybooks in the Gemini app (168 pts)]]></title>
            <link>https://blog.google/products/gemini/storybooks/</link>
            <guid>44804411</guid>
            <pubDate>Tue, 05 Aug 2025 21:14:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gemini/storybooks/">https://blog.google/products/gemini/storybooks/</a>, See on <a href="https://news.ycombinator.com/item?id=44804411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div slot="uni-short-post-description-slot"><p data-block-key="kyyrc">Today we’re announcing a new way to bring your ideas to life in the Gemini app: personalized, illustrated storybooks complete with read-aloud narration.</p><p data-block-key="7m5p9">Simply describe any story you can imagine, and Gemini generates a unique 10-page book with custom art and audio. For a truly personal touch, you can ask Gemini to draw inspiration from your own photos and files. Bring your vision to life in any style imaginable: from pixel art and comics to claymation, crochet, and even coloring books, in more than 45 languages.</p><ul><li data-block-key="2gt88"><b>Help your child understand a complex topic:</b> Create a story that explains the solar system to my 5 year old.</li><li data-block-key="e908b"><b>Teach a lesson through storytelling:</b> Teach a 7-year-old boy about the importance of being kind to his little brother. My son loves elephants so let’s make the main character an elephant.</li><li data-block-key="68oot"><b>Bring personal artwork to life</b>: Upload an image of a kid's drawing and modify this example prompt for your use case: "This is my kid’s drawing. He’s 7 years old. Write a creative storybook that brings his drawing to life.”</li><li data-block-key="5v3mr"><b>Turn memories into magical stories:</b> Upload photos from your family trip to Paris and create a personalized adventure.</li></ul><p data-block-key="26fhm"><a href="http://gemini.google.com/gem/storybook">Try it today in the Gemini app</a>. Available globally on desktop and mobile, in all languages Gemini is available.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new database on police use of force and misconduct in California (131 pts)]]></title>
            <link>https://journalism.berkeley.edu/police-records-access/</link>
            <guid>44803196</guid>
            <pubDate>Tue, 05 Aug 2025 19:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journalism.berkeley.edu/police-records-access/">https://journalism.berkeley.edu/police-records-access/</a>, See on <a href="https://news.ycombinator.com/item?id=44803196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-node="jhblr3yv2e8m">
	<h4><img loading="lazy" decoding="async" src="https://journalism.berkeley.edu/wp-content/uploads/2025/07/Logo.Police-Records-Access.bw_-600x96.png" alt="" width="555" height="89" srcset="https://journalism.berkeley.edu/wp-content/uploads/2025/07/Logo.Police-Records-Access.bw_-600x96.png 600w, https://journalism.berkeley.edu/wp-content/uploads/2025/07/Logo.Police-Records-Access.bw_-1140x182.png 1140w, https://journalism.berkeley.edu/wp-content/uploads/2025/07/Logo.Police-Records-Access.bw_-768x123.png 768w, https://journalism.berkeley.edu/wp-content/uploads/2025/07/Logo.Police-Records-Access.bw_.png 1159w" sizes="auto, (max-width: 555px) 100vw, 555px"></h4>
<p><strong>For Immediate Release</strong><br>
<strong>August 4, 2025<br>
Contact: Journalism@berkeley.edu</strong></p>
<h2><b>A new database on police use of force and misconduct in California makes public 1.5 million pages of once-secret police records</b></h2>

<p><span>Public records about use of force and misconduct by California law enforcement officers — some 1.5 million pages obtained from nearly 500 law enforcement agencies — will now be searchable by the public for the first time thanks to a new database built by UC Berkeley and Stanford University and published today by the <a href="https://www.latimes.com/california/story/2025-08-04/clean-database-launch">Los Angeles Times</a>, <a href="https://www.sfchronicle.com/bayarea/article/california-police-records-20797063.php">San Francisco Chronicle</a>, <a href="https://www.kqed.org/news/12050816/thousands-of-california-police-records-now-publicly-available">KQED</a> and <a href="https://calmatters.org/justice/2025/08/police-misconduct-records-database/">CalMatters</a>.</span></p>
<p><span>The database — the first of its kind in the nation — will vastly expand public access to internal affairs records that disclose how law enforcement agencies throughout the state h</span><span>andle misconduct allegations as well as uses of police force that result in death or serious injury. The database, funded by the State of California, currently has records from nearly 12,000 cases, including thousands involving police shootings. Every record in the database was released by a law enforcement agency after being redacted in compliance with California’s public records laws. As a result, journalists and members of the public will now be able to </span><span>search statewide for particular types of misconduct and use-of-force. Police chiefs will be able to use the data to aid in hiring decisions. Researchers will be able to identify trends and patterns.&nbsp;</span></p>
<p><span><img fetchpriority="high" decoding="async" src="https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero-600x381.png" alt="A stack of paper on a red stool." width="422" height="267" srcset="https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero-600x381.png 600w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero-1140x723.png 1140w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero-768x487.png 768w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero-1536x975.png 1536w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/Public-Records-Access-Project-hero.png 1967w" sizes="(max-width: 422px) 100vw, 422px">The database, called the Police Records Access Project, is the product of years of work by a multidisciplinary team of journalists, data scientists, lawyers and civil liberties advocates, led by UC Berkeley Journalism’s </span><a href="https://journalism.berkeley.edu/programs/mj/investigative-reporting/"><span>Investigative Reporting Program </span></a><span>(IRP)</span><span>, </span><span>the </span><a href="https://bids.berkeley.edu/"><span>Berkeley Institute for Data Science</span></a><span> (BIDS), and Stanford University’s </span><a href="http://cjlab.stanford.edu/projects/big-local-news/"><span>Big Local News</span></a><span>. Other key contributors include the </span><a href="https://www.aclusocal.org/"><span>ACLU Foundation of Southern California</span></a><span>, California innocence organizations, the </span><a href="https://www.nacdl.org/"><span>National Association of Criminal Defense Lawyers</span></a><span>, UC Irvine law school’s </span><a href="https://www.law.uci.edu/academics/real-life-learning/clinics/press-freedom-project.html"><span>Press Freedom Project</span></a><span> and UC Berkeley law school’s </span><a href="https://www.law.berkeley.edu/research/criminal-law-and-justice-center/"><span>Criminal Law &amp; Justice Center</span></a><span>.&nbsp;</span></p>
<p><span>The team systematically collected, organized and vetted millions of public records, used emerging technologies such as generative AI to build the database, and created from scratch a searchable user-interface.&nbsp;</span></p>
<p><span>“The creation of a public facing database is critical for all of the stakeholders in the criminal legal system: whether public defenders, innocence organizations, prosecutors, police departments or academics,” said Barry Scheck, co-founder and special counsel to the Innocence Project. “This information can be used to understand the system and reform it.”</span></p>
<p><span>Aditya Parameswaran, an associate professor at </span><span>UC Berkeley’s Department of Electrical Engineering and Computer Sciences, </span><span>led work on the database at BIDS. “Here we have an amazing example of how generative AI </span><span>— with humans in the loop — </span><span>can be used for good, at a scale that’s unprecedented, for a task that’s never been done before and for societal impact,” he said.</span></p>
<p><span>Creation of the database was made possible by a series of landmark laws adopted recently by the state of California to improve transparency around law enforcement. Through </span><a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1421"><span>S.B. 1421</span></a><span>, approved in 2018, and </span><a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220SB16"><span>S.B. 16</span></a><span>, approved in 2021, California made records related to uses of force and misconduct accessible to the public for the first time. However, requesting these documents through the Public Records Act required going agency by agency, a laborious process that has made it impossible until now to identify trends and patterns across the state.</span></p>
<p><span>“For 40 years California hid police misconduct,’’ said former state Sen. Nancy Skinner, who helped lead the legislative push for the new transparency laws and played a key role in securing state funding to create the database. “We were able to open those records to the public when the legislature passed S.B. 1421 in 2019. Now with this new database, Californians will have even better access, making it easier to find out which law enforcement officers have a history of bad behavior and which of our police departments do the right thing to hold their officers accountable.’’&nbsp;</span></p>
<p><span>Tiffany Bailey, senior staff attorney at the ACLU Foundation of Southern California, which will contribute an additional 200,000 records to the database from its own efforts to obtain police records under S.B. 1421, said the Police Records Access Project will be a “vital tool’’ in holding law enforcement agencies accountable. “Critically, families who have lost loved ones in California will now have direct access to the information they need to seek meaningful accountability that has too often been denied,” Bailey said.</span></p>
<p><span>The database released today can now be accessed online via KQED, The San Francisco Chronicle, Los Angeles Times and CalMatters. The database does not include audio recordings or videos, and additional steps were taken to redact or remove graphic imagery along with personal information about sexual assault or domestic violence victims. </span></p>
<p><span><img loading="lazy" decoding="async" src="https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1-600x400.jpg" alt="A screen with the words Police Records Access Project that looks like a page of the datagase, surrounded by a green three-dimensional border." width="411" height="274" srcset="https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1-600x400.jpg 600w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1-1140x760.jpg 1140w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1-768x512.jpg 768w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1-1536x1024.jpg 1536w, https://journalism.berkeley.edu/wp-content/uploads/2025/08/policedatabase0804_ph1-1.jpg 2048w" sizes="auto, (max-width: 411px) 100vw, 411px">Work on the database began in 2018, when journalists in some 40 newsrooms formed the <a href="https://projects.scpr.org/california-reporting-project/">California Reporting Project</a> and began sharing documents obtained through records requests. Early funding to support this work was provided by the Sony Foundation and Roc Nation. In all, reporters sent more than 3,500 public records requests to nearly 700 police departments, district attorney offices, </span><span>sheriff’s offices, oversight agencies, probation, corrections</span><span> and coroners all across the state. “The idea was to collaborate among organizations to build up this system, to make it easy to access these public records,’’ said Cheryl Phillips, founder of Stanford’s Big Local News, which specializes in helping local newsrooms incorporate data into their reporting.</span></p>
<p><span>The California Reporting Project has produced more than 100 stories to date from these records. Leading contributors to the California Reporting Project include the </span><a href="https://www.mercurynews.com/"><span>Bay Area News Group</span></a><span>/</span><a href="https://www.ocregister.com/"><span>Southern California News Group</span></a><span>, </span><a href="https://www.capradio.org/"><span>CapRadio</span></a><span>, KPCC/</span><a href="https://laist.com/"><span>LAist</span></a><span> and the newsrooms publishing the database today. Additional newsrooms are expected to publish the database as part of a broader rollout effort, and new features and tools will be added to the database as they are developed by the Police Records Access Project.</span></p>
<p><span>“Making police misconduct records more transparent, searchable, and accessible to the public is a monumental leap for accountability,” said Lisa Wayne, executive director of the National Association of Criminal Defense Lawyers.</span></p>
<p><span>###</span></p>
<p><span>_________________________________________________________________________________________________________</span></p>
<p><strong>For more information about the Police Records Access Project, please contact David Barstow, Investigative Reporting Program chair, through Andrea Lampros, UC Berkeley Journalism’s communications director: 510.847.4469, alampros@berkeley.edu or journalism@berkeley.edu.</strong></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is propping up the US economy (260 pts)]]></title>
            <link>https://www.bloodinthemachine.com/p/the-ai-bubble-is-so-big-its-propping</link>
            <guid>44802916</guid>
            <pubDate>Tue, 05 Aug 2025 19:19:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloodinthemachine.com/p/the-ai-bubble-is-so-big-its-propping">https://www.bloodinthemachine.com/p/the-ai-bubble-is-so-big-its-propping</a>, See on <a href="https://news.ycombinator.com/item?id=44802916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Greetings all — </p><p><span>Busy week in BITM land. Got home from some travel only to take off to SF to speak on a panel about AI and work for </span><a href="https://www.youtube.com/watch?v=9E_q277l7KM&amp;list=PL7ZZjNmMAwA3Liz0XuJ5isKBLIkCfYLwt&amp;index=1" rel="">a CalMatters conference</a><span> with state lawmakers and labor leaders, and made it back to LA in time for </span><a href="https://www.404media.co/behind-the-blog-party-vibes-and-spilling-tea/" rel="">the 404 live event night</a><span>, where I had the pleasure of bumping into a bunch of BITM readers. I met ambitious students examining the history of tech and labor in the entertainment industry, veteran tech policy campaigners, and some young critical journos. You all are the best. It ALSO makes me think I should throw a BITM event or meetup of some kind one of these days—readers have suggested this before, and I like the idea, I’ve just been so slammed. I digress.</span></p><p><span>For those interested, I did an interview </span><a href="https://time.com/charter/7307090/how-ai-adoption-is-sitting-with-workers/" rel="">with TIME Magazine’s Charter project</a><span>. It was not my most eloquent spot—exhaustion!—but I think some good points came through. Also chatted with indy media/freelancer advocacy outlet </span><a href="https://thestudyhallpodcast.podbean.com/e/inside-the-ai-jobs-crisis-ft-brian-merchant/" rel="">Study Hall about AI in journalism</a><span>.</span></p><p><span>It was </span><em>also</em><span> a busy week in the AI world, though that’s hardly surprising, for reasons pertinent to the news we’re about to discuss. Without further ado, in this issue, we’ll dive into</span></p><p><span>-Microsoft’s AI-fueled $4 trillion valuation</span><br><span>-AI is driving so much investment it’s like a “private sector stimulus program” papering over losses to tariffs </span></p><p><span>And this week’s CRITICAL AI REPORT, with </span><br><span>-How America’s professors are organizing to fight the push of AI into higher ed</span><br><span>-The fury over an AI model appearing in Vogue</span><br><span>-Inside the collapse of Builder.AI, the AI company that wasn’t</span><br><span>-Good bloody news: Courts uphold ruling that Google’s Play store and billing system are illegal monopolies</span></p><p>For the full report, and to support my 100% grade A independent journalism, please consider becoming a paid subscriber so, well, I can do more of it. I’m very grateful to every subscriber who shells out their hard-earned bucks—equivalent to a cheap-ish beer on draft or a decent latte a month—to make this all possible. Hammers up. </p><p>Last week, Microsoft became the second company, after Nvidia, to reach a $4 trillion valuation. </p><p><span>CNN </span><a href="https://www.cnn.com/2025/07/31/tech/microsoft-4-trillion-valuation" rel="">reports</a><span>: </span></p><blockquote><p><span>Microsoft’s shares ﻿(</span><strong><a href="https://www.cnn.com/markets/stocks/MSFT" rel="">MSFT</a></strong><span>) jumped nearly 4.5% after the market opened on Thursday, pushing its intraday valuation to $4.01 trillion. The company’s shares have risen roughly 28% since the start of this year.</span></p><p><span>The milestone comes just a year and a half after Microsoft reached a </span><strong><a href="https://www.cnn.com/2024/01/24/investing/microsoft-three-trillion-market-value" rel="">$3 trillion valuation</a></strong><span>. The company first cracked the </span><strong><a href="https://www.cnn.com/2019/07/11/investing/amazon-microsoft-trillion-dollar-market-value" rel="">$1 trillion mark </a></strong><span>in April 2019. It follows Nvidia into the $4 trillion valuation club, which hit the mark earlier this month.</span></p></blockquote><p>There are so many wild and noteworthy things about this milestone that it’s hard to know when to start. </p><p><span>First, let’s take a second to note the sheer insanity of these numbers. The first company to hit a $1 trillion valuation in the modern era was Apple, in 2018. Now, just seven years later, there are </span><em>nine</em><span> $1 trillion+ tech companies, and Google, Amazon, and Meta are soaring past $2 trillion, and now Apple is well past $3 trillion. Much of this expansion of value has occurred in just the last two years, on the back of the AI boom. Nvidia tripled its valuation, becoming the first-ever $4 trillion company in the process, in less than </span><em>one year</em><span>. </span></p><p><span>Second, note the </span><em>source</em><span> of Microsoft’s new investor enthusiasm: Like Nvidia, MS seems to be primarily benefitting from the AI boom by selling shovels during the gold rush. While Nvidia cornered the market on chips needed to run AI’s resource-intensive computation, Microsoft is winning by selling cloud compute in bulk. (Notably its biggest client is OpenAI, which is part of a byzantine deal between the two companies, but more on that in a second.) Microsoft’s largest revenue source is now Azure, its cloud compute business. Azure used to be a distant second, behind industry leader Amazon Web Services, but better-than-expected sales there last quarter have driven Microsoft to its new peak. </span></p><p><span>Third, Microsoft and Nvidia are benefitting from bona fide historic levels of investment. Chris Mims sites the analysis of investor and programmer </span><a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/" rel="">Paul Kedrosky</a><span> in his most recent column in </span><a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431?st=oLCAcg&amp;reflink=desktopwebshare_permalink" rel="">the Wall Street Journal</a><span>:</span></p><blockquote><p><span>spending on AI infrastructure has already exceeded spending on telecom and internet infrastructure from the dot-com boom—and it’s still growing… one explanation for the U.S. economy’s ongoing strength, despite tariffs, is that spending on IT infrastructure is so big that it’s acting as a sort of </span><a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/" rel="">private-sector stimulus program</a><span>.</span></p><p><span>Capex spending for AI </span><a href="https://x.com/RenMacLLC/status/1950544075989377196" rel="">contributed more to growth</a><span> in the U.S. economy in the past two quarters than </span><em>all of consumer spending</em><span>, says Neil Dutta, head of economic research at Renaissance Macro Research, citing data from the Bureau of Economic Analysis.</span></p></blockquote><p><span>I’ll just repeat that. Over the last six months, capital expenditures on AI—counting just information processing equipment and software, by the way—added more to the growth of the US economy than all consumer spending combined. You can just pull any of those quotes out—spending on IT for AI is so big it might be making up for economic losses from the tariffs, serving as a </span><em>private sector stimulus program</em><span>.</span></p><p><span>To me, this is just screaming bubble. I’m sure I’m not alone. In fact I </span><em>know</em><span> I’m not alone. I’m thinking especially of </span><a href="https://www.wheresyoured.at/the-haters-gui/" rel="">Ed Zitron’s impassioned and</a><em><a href="https://www.wheresyoured.at/the-haters-gui/" rel=""> </a></em><a href="https://www.wheresyoured.at/the-haters-gui/" rel="">thorough guide to the AI bubble</a><span>; a rundown of how much money is being poured into and spent on AI vs how much money these products are making, and surprise, the situation as it stands is not sustainable. Worrying signs abound, and not least that so far, the companies benefitting most from AI are those selling the tools to simply build </span><em>more</em><span> of it (Nvidia, Microsoft), or who have monopolies through which they can force AI tools onto users en masse with limited repercussions (Google, Meta). Consumers routinely evince negative</span><em> </em><span>sentiment towards AI and AI products in polls, outweighing enthusiasm. And meanwhile, what I’d say is the only truly runaway, organically popular AI product category, chatbots, largely remain big money losers due to the resources they take to run. </span></p><p>As such, these massive valuations feel fishy. I asked Ed for his thoughts on Microsoft’s $4 trillion earnings report. He said: </p><blockquote><p>Microsoft broke out Azure revenue for the first time in history, yet has not updated their annualized revenue for AI since January 29 2025. If things were going so well with AI, why are they not providing these numbers? It's because things aren't going well at all, and they're trying to play funny games with numbers to confuse and excite investors. </p><p>Also, $10bn+ of that Azure revenue is OpenAI's compute costs, paid at-cost, meaning no profit (and maybe even loss!) for Microsoft.</p></blockquote><p>Look, I’m no prophet, clearly. I’ve predicted that we were probably witnessing the peak of the AI boom *nearly a year ago*, and while I think I was right with regard to genuine consumer and pop cultural interest, obviously the investment and expansion has kept right on flowing. It’s to the point that we’re well past dot com boom levels of investment, and, as Kedrosky points out, approaching railroad-levels of investment, last seen in the days of the robber barons. </p><p>I have no idea what’s going to happen next. But if AI investment is so massive that it’s quite actually helping to prop up the US economy in a time of growing stress, what happens if the AI stool does get kicked out from under it all? </p><p><span>There could be a crash that exceeds the dot com bust, at a time when the political situation through which such a crash would be navigated would be nightmarish. There could be a smaller bust, which weeds out the less monopolistic and unprofitable AI companies, or drives them to survive with the help of the tech giants or </span><a href="https://www.bloodinthemachine.com/p/trumps-ai-action-plan-is-a-blueprint" rel="">the ever more AI-friendly US state</a><span>. Who knows. It does, however, seem increasingly unlikely that there will be </span><em>no </em><span>correction at all. (I also should say that I find it implausible any crash will simply wipe out AI as a product category, either; as a surveillance and automation tool, AI is simply too alluring to business, and as a chatbot product, it’s already addicted millions of users. There are fresh challenges here.)</span></p><div data-component-name="DigestPostEmbed"><a href="https://www.bloodinthemachine.com/p/trumps-ai-action-plan-is-a-blueprint" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oWg2!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e968424-422c-4108-94e9-58884a2c62a5_1599x900.webp"><img src="https://substackcdn.com/image/fetch/$s_!oWg2!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e968424-422c-4108-94e9-58884a2c62a5_1599x900.webp" sizes="100vw" alt="Trump's AI Action Plan is a blueprint for dystopia" width="140" height="140"></picture></div></a></div><p>Recognizing from history the possibilities of where this all might lead, the prospect of any serious economic downturn being met with a widespread push of mass automation—paired with a regime overwhelmingly friendly to the tech and business class, and executing a campaign of oppression and prosecution of precarious manual and skilled laborers—well, it should make us all sit up and pay attention. </p><p>But take heart! There are people organizing against the wanton encroachment of AI into every pore of society. To wit: There are few sectors that have been as inundated with AI as education. From a deluge of AI-generated student papers to the AI companies hard push to sell administration on new edtech tools, education, and especially higher ed, is one of the front lines of AI. </p><p>Frustrated by their lack of a voice in how AI was being deployed in classrooms and beyond, with administrations too willing to greenlight AI deals without their consent, professors and academic workers are officially pushing organizing to push back. </p><p><span>In July, the American Association of University Professors (AAUP), the union that represents faculty and academic workers at colleges across the nation, issued a report, </span><em><a href="https://www.aaup.org/reports-publications/aaup-policies-reports/topical-reports/artificial-intelligence-and-academic" rel="">Artificial Intelligence and Academic Professions</a></em><span>. The report distill the results a survey of its membership and “calls for the establishment of policies in colleges and universities that prioritize economic security, faculty working conditions, and student learning conditions as advancements in artificial intelligence (AI) technologies accelerate.”</span></p><p><span>I spoke to </span><a href="https://www.britt-paris.net/about.html" rel="">Britt Paris</a><span>, the head of the AAUP's ad hoc Committee on Artificial Intelligence and Academic Professions, about the report and what it means. </span></p><p><strong>BLOOD IN THE MACHINE: What are the report’s key findings?</strong></p><p><strong>Britt Paris:</strong><span> This report… found that overall while faculty are often mandated to use specific technologies, 71% say they have no means to have a say or make decisions around whether or how technology is procured, deployed and used at their institutions. </span></p><p>People want to have meaningful power around tech decisions at their institutions. They also want the ability to opt out of technology without risk of punishment. They want better working conditions and are concerned about technology driving down wages, being used for surveillance, and to destroy academic freedom. They are also concerned about their intellectual property being used to amass profit for massive technology companies. </p><p>We want to be paid meaningfully for our labor and accommodated appropriately, as we educate young people to become active and knowledgeable participants in democracy, with the ability to form thoughtful relationships with one another and with the environment, and live full happy lives. We have done interviews and other engagements since the survey, and have overwhelmingly found that instead of improving working and learning conditions, administrators are too easily wooed by tech industry hype, and they are quick to deploy technology solutions which are cheaper and far less effective in bringing about positive change in higher education.</p><p><strong>Why did you deem it crucial to address the spread of AI in higher education? Do you consider there to be a crisis of AI in higher ed?</strong></p><p><span>We started this work last year, and even then higher education was severely evaluated and under attack, though in a different way than it has been since January 2025. We have needed better policy around technology in higher education for years, at least for 15, when the software-as-a-service model came to be the norm for bringing higher education online. Higher education has always had a problem with handing out massive amounts of money for technical solutions that could have been, and </span><em>were </em><span>until 15 years ago, developed and governed in-house, so to speak. </span></p><p><span>Educational technology, such as learning management systems (LMS) like Canvas, has always allowed these corporate firms to do anything they want with user data— tracking their clicks and activities both within and outside of the LMS, as well as retains the data that comprises course materials posted within these LMS, like syllabi and videos produced by instructors, and students completed assignments. In 2021, Concordia University notably got in hot water because they were </span><a href="https://slate.com/technology/2021/01/dead-professor-teaching-online-class.html" rel="">repurposing videos in an online class</a><span> from an instructor who was deceased. And even now, we have heard from members that administrators are floating the idea of creating AI avatars to "teach" in online courses to repurpose course material from people who they lay off.</span></p><p>As AI has been incorporated into educational technology, often without users knowing it, with no announcement from the university, and as universities had, before this year been trading enormous sums of money for AI partnerships, it makes the need to address technology issues in higher ed even more urgent. Arizona State began their partnership with OpenAI and other tech firms in 2024, which has now started sweeping higher education from the University of Michigan, which houses the largest, oldest, and most well curated datasets in higher education to the massive California State University system that is comprised of over 500,000 students.</p><p><strong>What are the risks to students?</strong></p><p><span>Students </span><a href="https://www.nytimes.com/2025/05/14/technology/chatgpt-college-professors.html" rel="">don't like </a><span>when their instructors use AI for grading or for developing course materials. They find that it "enshittifies" their education, in the words of one survey respondent. Students do want to be challenged, to learn, to develop different perspectives on the world and to hope for a future than is better than what we have at present. They understand that education provides them at least some of the knowledge, skills, and outlook necessary to live a good life. Another survey respondent noted that for students, they were not so concerned with the "academic honesty" discourse around using generative AI for assignments than the "failure to learn", thus the solutions we develop should not be punitive towards students, but rather engage them in solidarity, because it is their learning conditions that are at stake as much as our faculty working conditions are.</span></p><p><strong>What are the solutions and ideas for countermeasures you propose? How are you approaching organizing around AI?</strong></p><p>In our report, we focus on developing shared governance collectives comprised of workers—instructors, staff, and students, elected by those workers—to make decisions around technology procurement, deployment, and training. We have a collective bargaining guide for faculty across the country lucky enough to have union contracts, that includes wishlists and sample language that has been effective. We include other types of documents that faculty across the country with no union contract have used in faculty governing bodies like academic senate resolutions, memoranda of understanding and the like. </p><p>We suggest that these shared governance collectives would be better suited to decide on the many issues in higher education than the trustees who currently set the policy in institutions, and have, as a result, deeply devalued higher education in favor of the market driven bottom line, and lining their own pockets. We also suggest that there is a vast need to develop people's tech advocacy units to provide counter narratives to tech industry and adjacent consulting firms for state level policymakers, so that policymakers have the knowledge and ability to develop and vote on policy in favor of the people.</p><p><span>Across industries and communities, no one except the very rich who are profiting off of the gutting of what's left of the public good, no one is happy with AI's takeover. AI applications are </span><a href="https://www.cnet.com/personal-finance/retirement/social-security-has-a-maddening-new-ai-phone-bot-heres-how-to-deal-with-it/" rel="">taking over</a><span> government services and agencies like the Social Security Administration, and even to </span><a href="https://www.wired.com/story/doge-college-student-ai-rewrite-regulations-deregulation/" rel="">write regulation</a><span>. </span><a href="https://www.404media.co/ice-taps-into-nationwide-ai-enabled-camera-network-data-shows/" rel="">ICE is using it</a><span> to incarcerate people. Social media is unusable, </span><a href="https://www.theguardian.com/technology/2025/jul/24/ai-summaries-causing-devastating-drop-in-online-news-audiences-study-finds" rel="">most traffic on the internet goes to AI summaries</a><span>, and not to actual pages. Big tech advocate for AI taking over </span><a href="https://www.zdnet.com/article/this-new-ai-video-editor-is-an-all-in-one-production-service-for-filmmakers-how-to-try-it/" rel="">creative</a><span>, </span><a href="https://www.ndtv.com/feature/wikipedia-set-to-embrace-ai-what-does-it-mean-for-human-editors-8313745" rel="">knowledge</a><span>, and</span><a href="https://www.bloodinthemachine.com/p/inside-the-escalating-struggle-over" rel=""> journalism</a><span> sectors, which results in more muddying the waters around current and past events, as well as obliterating the personal fulfillment that comes from the act of creation itself, as well as the act of enjoying cultural content. </span></p><p>People are largely unhappy with the way that big tech has rolled out AI. But that dissatisfaction does not change things. AI here, as a tech industry product being rammed down our throats is part of the drive towards immiseration of the masses we have been seeing ramp up since the pandemic – in the minds of the oligarchs, there's no longer a future, so they are making what cash grabs they can so they can build their bunkers to save them while the world they have immiserated burns. Making common cause with people across areas of concern and pushing towards change across multiple avenues is the only way out, we cannot have a technical infrastructure that serves humanity when the roots of it are so rotten. </p><p><span>So we must refuse and cut off what doesn't serve us, and strive to let people be in charge of technology—not oligarchs and not authoritarian governments. We must develop counter narratives to the dominant view of technology, and especially AI, as a unquestionable good. We must provide examples of fighting back, as we have done in the contract language, and will continue to develop and communicate. We must connect the multiple attacks we see at present to corporate ownership of technology and capture of the electoral process. And we have to do this</span><em> while</em><span> bringing people in to the big tent to organize at the local level, from the bottom up.</span></p><p><span>(I have a </span><a href="https://www.ucpress.edu/books/radical-infrastructure/paper" rel="">book coming out in January 2026</a><span> about this very topic—not connected to A—but based in Internet infrastructure.)</span></p><p><strong>How does Trump's AI action plan complicate matters here, if at all?</strong></p><p>Our work on the AI committee both with the AAUP and in our own activities counters the dominant narrative by providing examples where to push back and how that will hopefully be compelling to ordinary people, and easier to pick up, organize around, and move forward with. </p><p><span>One of the first Executive Orders coming from the second Trump administration—on its second day—established Executive Order (EO) 14179, “Removing Barriers to American Leadership in Artificial Intelligence” that “revokes certain existing AI policies and directives that act as barriers to American AI innovation” and requires that AI expands “free from ideological bias or engineered social agendas” of course, the ideological bias referenced here is taken up and made more explicit in this AI Action Plan unveiled by the Trump administration July 23, as it states it's against "</span><a href="https://www.whitehouse.gov/fact-sheets/2025/07/fact-sheet-president-donald-j-trump-prevents-woke-ai-in-the-federal-government/" rel="">woke AI</a><span>" and threatens what little Biden area regulation around AI exists. It promises no regulation around AI at the federal level and opens the door for massive data center construction and regulating energy consumption related to data center use. Data centers are crucial for AI function as AI requires a glut of data and processing power to function. This is all great news to the tech oligarchs like Mark Zuckerberg and Sam Altmann who were in the front row of Trump's inauguration speech.</span></p><p><span>Less attention has been given Department of Education head Linda McMahon's statement around </span><a href="https://www.ed.gov/about/news/press-release/us-department-of-education-issues-guidance-artificial-intelligence-use-schools-proposes-additional-supplemental-priority" rel="">AI in education</a><span> released on July 23 in conjunction with the Trump AI Action Plan that uses standard language around AI as a necessary good, and that training and responsible AI use is necessary—without detailing what that means—while it ostensibly seeks to extend the same battles against "woke AI". </span></p><p><span>This and the AI action plan does not necessarily complicate matters for organizing around AI in higher ed, but it could. There is a dearth of framing around anything that would run counter to this standard line around AI as an unquestionable good, with policymakers and boards of trustees, and administrators of universities. The AAUP has signed on to the </span><a href="https://peoplesaiaction.com/" rel="">People's AI Action Plan</a><span> to provide and begin organizing around a narrative that people, not oligarchs should control technology. We will continue organizing for this end.</span></p><p>I have to say, it’s nice and affirming to see that, even two plus years into the AI boom, there’s still a strong reaction to efforts to replace human work and art with AI. This week’s exhibit A: </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TIL that You can spot base64 encoded JSON, certificates, and private keys (296 pts)]]></title>
            <link>https://ergaster.org/til/base64-encoded-json/</link>
            <guid>44802886</guid>
            <pubDate>Tue, 05 Aug 2025 19:17:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ergaster.org/til/base64-encoded-json/">https://ergaster.org/til/base64-encoded-json/</a>, See on <a href="https://news.ycombinator.com/item?id=44802886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-37fxchfa="" id="main-content" data-astro-cid-fur5yujb=""><nav><ol></ol></nav><p>I was working on my homelab and examined a file that was supposed to contain encrypted content that I could safely commit on a Github repository. The file looked like this</p>
<div><figure><pre data-language="json"><code><div><p><span>{</span></p></div><div><p><span>  </span><span>"serial"</span><span>: </span><span>13</span><span>,</span></p></div><div><p><span>  </span><span>"lineage"</span><span>: </span><span>"24d431ee-3da9-4407-b649-b0d2c0ca2d67"</span><span>,</span></p></div><div><p><span>  </span><span>"meta"</span><span>: {</span></p></div><div><p><span>    </span><span>"key_provider.pbkdf2.password_key"</span><span>: </span><span>"eyJzYWx0IjoianpHUlpMVkFOZUZKcEpSeGo4UlhnNDhGZk9vQisrR0YvSG9ubTZzSUY5WT0iLCJpdGVyYXRpb25zIjo2MDAwMDAsImhhc2hfZnVuY3Rpb24iOiJzaGE1MTIiLCJrZXlfbGVuZ3RoIjozMn0="</span></p></div><div><p><span><span>  </span></span><span>},</span></p></div><div><p><span>  </span><span>"encrypted_data"</span><span>: </span><span>"ONXZsJhz37eJA[...]"</span><span>,</span></p></div><div><p><span>  </span><span>"encryption_version"</span><span>: </span><span>"v0"</span></p></div><div><p><span>}</span></p></div></code></pre></figure></div>
<p>Hm, key provider? Password key? In an encrypted file? That doesn’t sound right. The problem is that this file is generated by taking a password, deriving a key from it, and encrypting the content with that key. I don’t know what the derived key could look like, but it could be that long indecipherable string.</p>
<p>I asked a colleague to have a look and he said “Oh that? It looks like a base64 encoded JSON. Give it a go to see what’s inside.”</p>
<p>I was incredulous but gave it a go, and it worked!!</p>
<div><figure><pre data-language="console"><code><div><p><span>$ echo </span><span>"eyJzYW[...]"</span><span> </span><span>|</span><span> </span><span>base64</span><span> </span><span>-d</span></p></div><div><p><span>{"salt":"jzGRZLVANeFJpJRxj8RXg48FfOoB++GF/Honm6sIF9Y=","iterations":600000,"hash_function":"sha512","key_length":32}</span></p></div></code></pre></figure></div>
<p>I couldn’t believe my colleague had decoded the base64 string on the fly, so I asked. “What gave it away? Was it the trailing equal signs at the end for padding? But how did you know it was base64 encoded <em>JSON</em> and not just a base64 string?”</p>
<p>He replied,</p>
<blockquote>
<p>Whenever you see&nbsp;<code>ey</code>, that’s&nbsp;<code>{"</code>&nbsp;and then if it’s followed by a letter, you’ll get&nbsp;<code>J</code>&nbsp;followed by a letter.</p>
</blockquote>
<p>I did a few tests in my terminal, and he was right! You can spot base64 json with your naked eye, and you don’t need to decode it on the fly!</p>
<div><figure><pre data-language="console"><code><div><p><span>$ echo </span><span>"{"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>ewo=</span></p></div><div><p><span>$ echo </span><span>"{</span><span>\"</span><span>"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>eyIK</span></p></div><div><p><span>$ echo </span><span>"{</span><span>\"</span><span>s"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>eyJzCg==</span></p></div><div><p><span>$ echo </span><span>"{</span><span>\"</span><span>a"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>eyJhCg==</span></p></div><div><p><span>$ echo </span><span>"{</span><span>\"</span><span>word</span><span>\"</span><span>"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>eyJ3b3JkIgo=</span></p></div></code></pre></figure></div>
<p>But there’s even better! As <a href="https://toot.now/@tyzbit">tyzbit</a> reported on the fediverse, you can even spot base64 encoded certificates and private keys! They all start with <code>LS</code>, which reminds of the LS in “TLS certificate.”</p>
<div><figure><pre data-language="console"><code><div><p><span>$ echo -en </span><span>"-----BEGIN CERTIFICATE-----"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0t</span></p></div></code></pre></figure></div>
<blockquote><div><p>As pointed out by <a href="https://news.ycombinator.com/item?id=44803260">gnabgib</a> and <a href="https://news.ycombinator.com/item?id=44803259">athorax</a> on Hacker News, this actually detects the leading dashes of the PEM format, commonly used for certificates, and a YAML file that starts with <code>---</code> will yield the same result</p><div><figure><pre data-language="console"><code><div><p><span>$ echo </span><span>"---\n"</span><span> </span><span>|</span><span> </span><span>base64</span></p></div><div><p><span>LS0tXG4K</span></p></div></code></pre></figure></div><p>This is not a silver bullet!</p></div></blockquote>
<p><em>Thanks Davide and Denis for showing me this simple but pretty useful trick, and thanks tyzbit for completing it with certs and private keys!</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ollama Turbo (369 pts)]]></title>
            <link>https://ollama.com/turbo</link>
            <guid>44802414</guid>
            <pubDate>Tue, 05 Aug 2025 18:46:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ollama.com/turbo">https://ollama.com/turbo</a>, See on <a href="https://news.ycombinator.com/item?id=44802414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<main>
  <section>
    <h2>
      Turbo<sup>Preview</sup>
    </h2>
    <img src="https://ollama.com/public/turbo.png" alt="Turbo">
    <h2>
      Supercharge models with faster hardware
    </h2>
    <h3>
      $20<span>/mo</span>
    </h3>
    <a href="https://ollama.com/upgrade">Upgrade to Turbo</a>
  </section>
  <section>
    <h2>
      Turbo lets you
    </h2>
    <ul>
      <li>
        <img src="https://ollama.com/public/supercharge.png" alt="Turbo speed">
        <div>
          <h3>Speed up model inference</h3>
          <p>
            Run models using datacenter-grade hardware, returning responses much
            faster.
          </p>
        </div>
      </li>
      <li>
        <img src="https://ollama.com/public/bigger-models.png" alt="Turbo speed">
        <div>
          <h3>Run larger models</h3>
          <p>
            Upgrade to the newest hardware, making it possible to run larger
            models.
          </p>
        </div>
      </li>
      <li>
        <img src="https://ollama.com/public/privacy-first.png" alt="Privacy first">
        <div>
          <h3>Privacy first</h3>
          <p>
            Ollama does not retain your data to ensure privacy and security.
          </p>
        </div>
      </li>
      <li>
        <img src="https://ollama.com/public/battery-life.png" alt="Turbo speed">
        <div>
          <h3>Save battery life</h3>
          <p>
            Take the load of running models off your Mac, Windows or Linux
            computer, giving you performance back for your other apps.
          </p>
        </div>
      </li>
    </ul>
  </section>
  <section>
    <h2>
      Frequently asked questions
    </h2>
    <ul>
      <li>
        <h3>What is Turbo?</h3>
        <p>
          Turbo is a new way to run open models using datacenter-grade hardware.
          Many new models are too large to fit on widely available GPUs, or run
          very slowly. Ollama Turbo provides a way to run these models fast
          while using Ollama's App, CLI, and API.
        </p>
      </li>
      <li>
        <h3>
          Which models are available in Turbo?
        </h3>
        <p>
          While in preview, the <code>gpt-oss-20b</code> and
          <code>gpt-oss-120b</code> models are available.
        </p>
      </li>
      <li>
        <h3>
          Does Turbo work with Ollama's CLI?
        </h3>
        <p>
          Yes, Ollama's CLI works with Turbo mode. See the
          <a href="http://github.com/ollama/ollama/blob/main/docs/turbo.md">docs</a>
          for more information.
        </p>
      </li>
      <li>
        <h3>
          Does Turbo work with Ollama's API and JavaScript/Python libraries?
        </h3>
        <p>
          Yes, Ollama's API and JavaScript/Python libraries work with Turbo
          mode. See the
          <a href="http://github.com/ollama/ollama/blob/main/docs/turbo.md">docs</a>
          for more information.
        </p>
      </li>
      <li>
        <h3>
          What data do you retain in Turbo mode?
        </h3>
        <p>Ollama does not log or retain any queries made via Turbo mode.</p>
      </li>
      <li>
        <h3>
          Where is the hardware that power Turbo located?
        </h3>
        <p>All hardware is located in the United States.</p>
      </li>
      <li>
        <h3>
          What are the usage limits for Turbo?
        </h3>
        <p>
          Turbo includes hourly and daily limits to avoid capacity issues.
          Usage-based pricing will soon be available to consume models in a
          metered fashion.
        </p>
      </li>
    </ul>
  </section>
</main>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US reportedly forcing TSMC to buy 49% stake in Intel to secure tariff relief (413 pts)]]></title>
            <link>https://www.notebookcheck.net/Desperate-measures-to-save-Intel-US-reportedly-forcing-TSMC-to-buy-49-stake-in-Intel-to-secure-tariff-relief-for-Taiwan.1079424.0.html</link>
            <guid>44801486</guid>
            <pubDate>Tue, 05 Aug 2025 17:44:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notebookcheck.net/Desperate-measures-to-save-Intel-US-reportedly-forcing-TSMC-to-buy-49-stake-in-Intel-to-secure-tariff-relief-for-Taiwan.1079424.0.html">https://www.notebookcheck.net/Desperate-measures-to-save-Intel-US-reportedly-forcing-TSMC-to-buy-49-stake-in-Intel-to-secure-tariff-relief-for-Taiwan.1079424.0.html</a>, See on <a href="https://news.ycombinator.com/item?id=44801486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="c14039108">
		<header><figure><a href="https://www.notebookcheck.net/fileadmin/_processed_/2/9/csm_US-is-forcing-TSMC-to-invest-in-intel_211a9abb3f.jpg" data-caption="Intel plans to have a new chip plant in Ohio in 2030. (Image source: Brecht Corbeel on Unsplash)"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc5/US-is-forcing-TSMC-to-invest-in-intel-q82-w240-h.webp 1x, https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc5/US-is-forcing-TSMC-to-invest-in-intel-q82-w480-h.webp 2x" type="image/webp"><img src="https://www.notebookcheck.net/fileadmin/_processed_/2/9/csm_US-is-forcing-TSMC-to-invest-in-intel_f52eb0a048.jpg" loading="lazy" width="240" height="180" alt="Intel plans to have a new chip plant in Ohio in 2030. (Image source: Brecht Corbeel on Unsplash)"></picture></a><figcaption>Intel plans to have a new chip plant in Ohio in 2030. (Image source: Brecht Corbeel on Unsplash)</figcaption></figure><div><p>A new report out of Taiwan has revealed that the current US administration is tying the reduction on trade of trade tariffs on Taiwan to significant TSMC investment in the US. This investment includes a 49% stake in Intel.</p></div></header>
	</div><div id="c14039107">
	<p>The current US administration, led by President Donald Trump, has employed trade tariffs as the primary way to reduce the US's trade deficit with partner countries. However, the US tariff policy has been erratic and unpredictable. These tariffs have also affected Taiwan, one of the US’s biggest trading partners.</p><p>Currently standing at 20%, the US trade tariff on Taiwan is more than that of countries like Japan, which pays a baseline tariff of 15%. Unsurprisingly, a 20% levy on Taiwanese exports to the US will hurt Taiwanese businesses quite a bit, which is why the country needs to negotiate further with the US to bring the tariffs down or downright eliminate then. However, according to a new report out of Taiwan, US President Trump has presented Taiwan with two conditions for tariff relief, both of which are quite stringent.</p><p><a href="https://www.mnews.tw/story/mm-20250804fin003" target="_blank">Per the Taiwanese outlet mnews.tw</a>, an industry source told the publication that President Donald Trump has mandated TSMC fulfill two conditions if Taiwan is to see any tariff reduction:</p><div><ol><li>Buy a 49% stake in Intel</li><li>Invest a further $400 billion in the US</li></ol></div><p>While ignoring the industrial ramifications of TSMC owning 49% of Intel, these are humongous financial commitments. <a href="https://www.notebookcheck.net/TSMC-s-second-Kumamoto-fab-reportedly-slips-to-2029-as-attention-shifts-to-U-S-expansion.1069608.0.html" target="_self">TSMC is already investing a ton of money in the US</a>, with one of the company’s fabs achieving volume production in 2024. The Taiwanese giant is on its way to building two more fabs at its Arizona facility, alongside an R&amp;D Center and a packaging facility. Overall, TSMC has planned to invest a total of $165 billion in the US.</p><p>So, President Trump’s alleged condition of investing a further $400 billion in the US alongside buying a stake in Intel seems improbable from a purely financial standpoint.</p><p><h2>The US is trying to save Intel from collapse</h2></p><p><a href="https://www.notebookcheck.net/AMD-is-absolutely-hammering-Intel-in-CPU-sales-as-even-old-AM4-chips-outsold-latest-Arrow-Lake-CPUs-last-week.1063493.0.html" target="_self">Intel is on the decline</a>. From the <a href="https://www.notebookcheck.net/Intel-now-reportedly-focusing-on-14A-production-as-18A-proves-to-be-a-billion-dollar-failure.1049302.0.html" target="_self">company’s fab operations</a> to consumer products, virtually every Intel department is taking a hit. This has shown in the company’s reported annual revenue figure, which has come down from a high of $79 billion in 2021 to $53 billion in 2024, is a massive 33% reduction.</p><p>Intel is a vital part of the US’s plans regarding domestic semiconductor manufacturing. As such, <a href="https://techcrunch.com/2025/01/30/intel-has-already-received-2-2b-in-federal-grants-for-chip-production/" target="_blank">the company has already received billions in federal grants</a>. However, this funding has not solved Intel’s troubles, as the company has delayed its Ohio fab from an initial target of 2025 to 2030/31. A primary reason for this delay seems to be Intel’s efforts to preserve capital resources amidst a lack of significant help from the US CHIPS Act and outside partners.</p><div><p>In short, the US administration seems to be pressuring TSMC to acquire a considerable stake in Intel to inject some much-needed capital into the company and keep the US government's plans of a domestic chip supply chain afloat. However, TSMC is unlikely to agree to this proposal.
</p>
<p>It'd be interesting to see what happens to Intel the coming months. Intel has a few exciting products in the works with <a href="https://www.notebookcheck.net/Intel-s-Panther-Lake-could-take-handheld-gaming-to-the-next-level.1072173.0.html" target="_self">Panther Lake</a> and <a href="https://www.notebookcheck.net/Intel-s-Nova-Lake-based-Ryzen-X3D-equivalent-to-launch-with-28-CPU-cores.1066983.0.html" target="_self">Nova Lake CPUs</a>. So, things could improve for Team Blue if these products deliver.</p></div></div><div itemscope="" itemtype="http://schema.org/Person" rel="author"><div><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=316"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/6/1/csm_IMG_1224_1_162133c8b0.jpg 1x, https://www.notebookcheck.net/fileadmin/_processed_/6/1/csm_IMG_1224_1_c8771969bf.jpg 2x"><img src="https://www.notebookcheck.net/fileadmin/_processed_/6/1/csm_IMG_1224_1_162133c8b0.jpg" loading="lazy" width="120" height="120" alt="Fawad Murtaza"></picture></a></div><p><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=316">Fawad Murtaza</a> - Senior Tech Writer <span title="1302&nbsp;"> - 1302 articles published on Notebookcheck</span> since 2021</p><p>I am Fawad, a fellow tech nerd. As a tech junkie, my relationship with technology goes back to my childhood years. Getting my first Intel Pentium 4 PC was the start of journey that would eventually bring me to Notebookcheck. Finally, I have been writing for tech media since 2018. From small no-name projects to industry leaders, I have worked with a number of tech publications.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Whittle – A shrinking word game (111 pts)]]></title>
            <link>https://playwhittle.com/</link>
            <guid>44801399</guid>
            <pubDate>Tue, 05 Aug 2025 17:39:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://playwhittle.com/">https://playwhittle.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44801399">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Consider using Zstandard and/or LZ4 instead of Deflate (172 pts)]]></title>
            <link>https://github.com/w3c/png/issues/39</link>
            <guid>44801027</guid>
            <pubDate>Tue, 05 Aug 2025 17:18:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/w3c/png/issues/39">https://github.com/w3c/png/issues/39</a>, See on <a href="https://news.ycombinator.com/item?id=44801027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">One of the issues we have with .PNG is slow read/write times. There are now new lossless open source codecs without patent concerns, such as Zstandard (maintained by Facebook) or LZ4:</p>
<p dir="auto"><a href="https://facebook.github.io/zstd/" rel="nofollow">https://facebook.github.io/zstd/</a><br>
<a href="https://github.com/lz4/lz4">https://github.com/lz4/lz4</a></p>
<p dir="auto">Zstandard is used by the new Khronos KTX2 GPU texture format specification. I propose that it be added as an option to a future version of .PNG. The possible speedups are quite significant, and for users that read and write a lot of .PNG's as part of their data processing pipelines the speedups will be high value improvements.</p>
<p dir="auto">There are also other far simpler but even faster codecs being developed, such as .QOI's, but using this would likely require changing or not filtering the image before compression:<br>
<a href="https://news.ycombinator.com/item?id=29328750" rel="nofollow">https://news.ycombinator.com/item?id=29328750</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Open Models (1855 pts)]]></title>
            <link>https://openai.com/open-models/</link>
            <guid>44800746</guid>
            <pubDate>Tue, 05 Aug 2025 17:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/open-models/">https://openai.com/open-models/</a>, See on <a href="https://news.ycombinator.com/item?id=44800746">Hacker News</a></p>
Couldn't get https://openai.com/open-models/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing gpt-oss (171 pts)]]></title>
            <link>https://openai.com/index/introducing-gpt-oss/</link>
            <guid>44800730</guid>
            <pubDate>Tue, 05 Aug 2025 17:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-gpt-oss/">https://openai.com/index/introducing-gpt-oss/</a>, See on <a href="https://news.ycombinator.com/item?id=44800730">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-gpt-oss/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Opus 4.1 (781 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-opus-4-1</link>
            <guid>44800185</guid>
            <pubDate>Tue, 05 Aug 2025 16:28:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-opus-4-1">https://www.anthropic.com/news/claude-opus-4-1</a>, See on <a href="https://news.ycombinator.com/item?id=44800185">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Today we're releasing Claude Opus 4.1, an upgrade to Claude Opus 4 on agentic tasks, real-world coding, and reasoning. We plan to release substantially larger improvements to our models in the coming weeks.</p><p>Opus 4.1 is now available to paid Claude users and in Claude Code. It's also on our API, Amazon Bedrock, and Google Cloud's Vertex AI. Pricing is the same as Opus 4.</p><h2 id="claude-opus-41">Claude Opus 4.1</h2><p>Opus 4.1 advances our state-of-the-art coding performance to 74.5% on <a href="https://www.swebench.com/">SWE-bench Verified</a>. It also improves Claude’s in-depth research and data analysis skills, especially around detail tracking and agentic search.</p><div><figure><img alt="Chart showing Claude's progress on a popular coding evaluation" loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fdced1e451a52da3bcb3807d7a9510b1b5426ace6-3840x2160.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fdced1e451a52da3bcb3807d7a9510b1b5426ace6-3840x2160.png&amp;w=3840&amp;q=75"></figure></div><p><strong>GitHub</strong> notes that Claude Opus 4.1 improves across most capabilities relative to Opus 4, with particularly notable performance gains in multi-file code refactoring. <strong>Rakuten Group</strong> finds that Opus 4.1 excels at pinpointing exact corrections within large codebases without making unnecessary adjustments or introducing bugs, with their team preferring this precision for everyday debugging tasks. <strong>Windsurf</strong> reports Opus 4.1 delivers a one standard deviation improvement over Opus 4 on their junior developer benchmark, showing roughly the same performance leap as the jump from Sonnet 3.7 to Sonnet 4.</p><div><figure><img alt="A benchmark table comparing Claude Opus 4.1 to prior Claude models and other public models" loading="lazy" width="2600" height="2084" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbde326699c667506c87f74b09a6355961d29eb26-2600x2084.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbde326699c667506c87f74b09a6355961d29eb26-2600x2084.png&amp;w=3840&amp;q=75"></figure></div><h2 id="getting-started">Getting started</h2><p>We recommend upgrading from Opus 4 to Opus 4.1 for all uses. If you’re a developer, simply use <code>claude-opus-4-1-20250805</code> via the API. You can also explore our <a href="https://www.anthropic.com/claude-opus-4-1-system-card">system card</a>, <a href="https://www.anthropic.com/claude/opus">model page</a>, <a href="https://www.anthropic.com/pricing#api">pricing page</a>, and <a href="https://docs.anthropic.com/en/docs/about-claude/models/overview">docs</a> to learn more.</p><p>As always, your <a href="mailto: feedback@anthropic.com">feedback</a> helps us improve, especially as we continue to release new and more capable models.</p></div></article><div><h4>Appendix</h4><p><strong>Data sources</strong></p><ul><li>OpenAI: <a href="https://openai.com/index/introducing-o3-and-o4-mini/">o3 launch post</a>, <a href="https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf">o3 system card</a></li><li>Gemini: <a href="https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro.pdf">2.5 Pro model card</a></li><li>Claude: <a href="https://www.anthropic.com/news/claude-3-7-sonnet">Sonnet 3.7 launch post</a>, <a href="https://www.anthropic.com/news/claude-4">Claude 4 launch post</a></li></ul><p><strong>Benchmark reporting</strong></p><p>Claude models are hybrid reasoning models. The benchmarks reported in this blog post show the highest scores achieved with or without extended thinking. We’ve noted below for each result whether extended thinking was used:</p><ul><li>No extended thinking: SWE-bench Verified, Terminal-Bench</li><li>The following benchmarks were reported with extended thinking (up to 64K tokens): TAU-bench, GPQA Diamond, MMMLU, MMMU, AIME</li></ul><p><strong>TAU-bench methodology</strong></p><p>Scores were achieved with a prompt addendum to both the Airline and Retail Agent Policy instructing Claude to better leverage its reasoning abilities while using extended thinking with tool use. The model is encouraged to write down its thoughts as it solves the problem distinct from our usual thinking mode, during the multi-turn trajectories to best leverage its reasoning abilities. To accommodate the additional steps Claude incurs by utilizing more thinking, the maximum number of steps (counted by model completions) was increased from 30 to 100 (most trajectories completed under 30 steps with only one trajectory reaching above 50 steps).</p><p><strong>SWE-bench methodology</strong></p><p>For the Claude 4 family of models, we continue to use the same simple scaffold that equips the model with solely the two tools described in our prior releases <a href="https://www.anthropic.com/engineering/swe-bench-sonnet">here</a>—a bash tool, and a file editing tool that operates via string replacements. We no longer include the <a href="https://www.anthropic.com/engineering/claude-think-tool">third ‘planning tool’</a> used by Claude 3.7 Sonnet. On all Claude 4 models, we report scores out of the full 500 problems. Scores for OpenAI models are reported out of a <a href="https://openai.com/index/gpt-4-1/">477 problem subset</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Harmony (367 pts)]]></title>
            <link>https://github.com/openai/harmony</link>
            <guid>44799869</guid>
            <pubDate>Tue, 05 Aug 2025 16:07:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openai/harmony">https://github.com/openai/harmony</a>, See on <a href="https://news.ycombinator.com/item?id=44799869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/harmony/blob/main/docs/header.png"><img alt="harmony" src="https://github.com/openai/harmony/raw/main/docs/header.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">OpenAI Harmony</h2><a id="user-content-openai-harmony" aria-label="Permalink: OpenAI Harmony" href="#openai-harmony"></a></p>
<p dir="auto">OpenAI's response format for its open-weight model series <a href="https://openai.com/open-models" rel="nofollow">gpt-oss</a>
<br>
<a href="https://gpt-oss.com/" rel="nofollow">Try gpt-oss</a> | <a href="https://cookbook.openai.com/topic/gpt-oss" rel="nofollow">Learn more</a> | <a href="https://openai.com/index/gpt-oss-model-card/" rel="nofollow">Model card</a>
</p>


<p dir="auto">The <a href="https://openai.com/open-models" rel="nofollow">gpt-oss models</a> were trained on the <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">harmony response format</a> for defining conversation structures, generating reasoning output and structuring function calls. If you are not using gpt-oss directly but through an API or a provider like HuggingFace, Ollama, or vLLM, you will not have to be concerned about this as your inference solution will handle the formatting. If you are building your own inference solution, this guide will walk you through the prompt format. The format is designed to mimic the OpenAI Responses API, so if you have used that API before, this format should hopefully feel familiar to you. gpt-oss should not be used without using the harmony format as it will not work correctly.</p>
<p dir="auto">The format enables the model to output to multiple different channels for chain of thought, and tool calling premables along with regular responses. It also enables specifying various tool namespaces, and structured outputs along with a clear instruction hierarchy. <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">Check out the guide</a> to learn more about the format itself.</p>
<div data-snippet-clipboard-copy-content="<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-06-28

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions

Always respond in riddles

# Tools

## functions

namespace functions {

// Gets the location of the user.
type get_location = () => any;

// Gets the current weather in the provided location.
type get_current_weather = (_: {
// The city and state, e.g. San Francisco, CA
location: string,
format?: &quot;celsius&quot; | &quot;fahrenheit&quot;, // default: celsius
}) => any;

} // namespace functions<|end|><|start|>user<|message|>What is the weather like in SF?<|end|><|start|>assistant"><pre><code>&lt;|start|&gt;system&lt;|message|&gt;You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-06-28

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.&lt;|end|&gt;&lt;|start|&gt;developer&lt;|message|&gt;# Instructions

Always respond in riddles

# Tools

## functions

namespace functions {

// Gets the location of the user.
type get_location = () =&gt; any;

// Gets the current weather in the provided location.
type get_current_weather = (_: {
// The city and state, e.g. San Francisco, CA
location: string,
format?: "celsius" | "fahrenheit", // default: celsius
}) =&gt; any;

} // namespace functions&lt;|end|&gt;&lt;|start|&gt;user&lt;|message|&gt;What is the weather like in SF?&lt;|end|&gt;&lt;|start|&gt;assistant
</code></pre></div>
<p dir="auto">We recommend using this library when working with models that use the <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">harmony response format</a></p>
<ul dir="auto">
<li><strong>Consistent formatting</strong> – shared implementation for rendering <em>and</em> parsing keeps token-sequences loss-free.</li>
<li><strong>Blazing fast</strong> – heavy lifting happens in Rust.</li>
<li><strong>First-class Python support</strong> – install with <code>pip</code>, typed stubs included, 100 % test parity with the Rust suite.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Harmony</h2><a id="user-content-using-harmony" aria-label="Permalink: Using Harmony" href="#using-harmony"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<p dir="auto"><a href="https://github.com/openai/harmony/blob/main/docs/python.md">Check out the full documentation</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install the package from PyPI by running</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install openai-harmony
# or if you are using uv
uv pip install openai-harmony"><pre>pip install openai-harmony
<span><span>#</span> or if you are using uv</span>
uv pip install openai-harmony</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai_harmony import (
    load_harmony_encoding,
    HarmonyEncodingName,
    Role,
    Message,
    Conversation,
    DeveloperContent,
    SystemContent,
)
enc = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)
convo = Conversation.from_messages([
    Message.from_role_and_content(
        Role.SYSTEM,
        SystemContent.new(),
    ),
    Message.from_role_and_content(
        Role.DEVELOPER,
        DeveloperContent.new().with_instructions(&quot;Talk like a pirate!&quot;)
    ),
    Message.from_role_and_content(Role.USER, &quot;Arrr, how be you?&quot;),
])
tokens = enc.render_conversation_for_completion(convo, Role.ASSISTANT)
print(tokens)
# Later, after the model responded …
parsed = enc.parse_messages_from_completion_tokens(tokens, role=Role.ASSISTANT)
print(parsed)"><pre><span>from</span> <span>openai_harmony</span> <span>import</span> (
    <span>load_harmony_encoding</span>,
    <span>HarmonyEncodingName</span>,
    <span>Role</span>,
    <span>Message</span>,
    <span>Conversation</span>,
    <span>DeveloperContent</span>,
    <span>SystemContent</span>,
)
<span>enc</span> <span>=</span> <span>load_harmony_encoding</span>(<span>HarmonyEncodingName</span>.<span>HARMONY_GPT_OSS</span>)
<span>convo</span> <span>=</span> <span>Conversation</span>.<span>from_messages</span>([
    <span>Message</span>.<span>from_role_and_content</span>(
        <span>Role</span>.<span>SYSTEM</span>,
        <span>SystemContent</span>.<span>new</span>(),
    ),
    <span>Message</span>.<span>from_role_and_content</span>(
        <span>Role</span>.<span>DEVELOPER</span>,
        <span>DeveloperContent</span>.<span>new</span>().<span>with_instructions</span>(<span>"Talk like a pirate!"</span>)
    ),
    <span>Message</span>.<span>from_role_and_content</span>(<span>Role</span>.<span>USER</span>, <span>"Arrr, how be you?"</span>),
])
<span>tokens</span> <span>=</span> <span>enc</span>.<span>render_conversation_for_completion</span>(<span>convo</span>, <span>Role</span>.<span>ASSISTANT</span>)
<span>print</span>(<span>tokens</span>)
<span># Later, after the model responded …</span>
<span>parsed</span> <span>=</span> <span>enc</span>.<span>parse_messages_from_completion_tokens</span>(<span>tokens</span>, <span>role</span><span>=</span><span>Role</span>.<span>ASSISTANT</span>)
<span>print</span>(<span>parsed</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust</h3><a id="user-content-rust" aria-label="Permalink: Rust" href="#rust"></a></p>
<p dir="auto"><a href="https://github.com/openai/harmony/blob/main/docs/rust.md">Check out the full documentation</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto">Add the dependency to your <code>Cargo.toml</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
openai-harmony = { git = &quot;https://github.com/openai/harmony&quot; }"><pre>[<span>dependencies</span>]
<span>openai-harmony</span> = { <span>git</span> = <span><span>"</span>https://github.com/openai/harmony<span>"</span></span> }</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example-1" aria-label="Permalink: Example" href="#example-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="use openai_harmony::chat::{Message, Role, Conversation};
use openai_harmony::{HarmonyEncodingName, load_harmony_encoding};
fn main() -> anyhow::Result<()> {
    let enc = load_harmony_encoding(HarmonyEncodingName::HarmonyGptOss)?;
    let convo = Conversation::from_messages([
        Message::from_role_and_content(Role::User, &quot;Hello there!&quot;),
    ]);
    let tokens = enc.render_conversation_for_completion(&amp;convo, Role::Assistant)?;
    println!(&quot;{:?}&quot;, tokens);
    Ok(())
}"><pre><span>use</span> openai_harmony<span>::</span>chat<span>::</span><span>{</span><span>Message</span><span>,</span> <span>Role</span><span>,</span> <span>Conversation</span><span>}</span><span>;</span>
<span>use</span> openai_harmony<span>::</span><span>{</span><span>HarmonyEncodingName</span><span>,</span> load_harmony_encoding<span>}</span><span>;</span>
<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; anyhow<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>let</span> enc = <span>load_harmony_encoding</span><span>(</span><span>HarmonyEncodingName</span><span>::</span><span>HarmonyGptOss</span><span>)</span>?<span>;</span>
    <span>let</span> convo = <span>Conversation</span><span>::</span><span>from_messages</span><span>(</span><span>[</span>
        <span>Message</span><span>::</span><span>from_role_and_content</span><span>(</span><span>Role</span><span>::</span><span>User</span><span>,</span> <span>"Hello there!"</span><span>)</span><span>,</span>
    <span>]</span><span>)</span><span>;</span>
    <span>let</span> tokens = enc<span>.</span><span>render_conversation_for_completion</span><span>(</span><span>&amp;</span>convo<span>,</span> <span>Role</span><span>::</span><span>Assistant</span><span>)</span>?<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span><span>,</span> tokens<span>)</span><span>;</span>
    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">The majority of the rendering and parsing is built in Rust for performance and exposed to Python
through thin <a href="https://pyo3.rs/" rel="nofollow"><code>pyo3</code></a> bindings.</p>
<div data-snippet-clipboard-copy-content="┌──────────────────┐      ┌───────────────────────────┐
│  Python code     │      │  Rust core (this repo)    │
│  (dataclasses,   │────► │  • chat / encoding logic  │
│   convenience)   │      │  • tokeniser (tiktoken)   │
└──────────────────┘  FFI └───────────────────────────┘"><pre><code>┌──────────────────┐      ┌───────────────────────────┐
│  Python code     │      │  Rust core (this repo)    │
│  (dataclasses,   │────► │  • chat / encoding logic  │
│   convenience)   │      │  • tokeniser (tiktoken)   │
└──────────────────┘  FFI └───────────────────────────┘
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Repository layout</h3><a id="user-content-repository-layout" aria-label="Permalink: Repository layout" href="#repository-layout"></a></p>
<div data-snippet-clipboard-copy-content=".
├── src/                  # Rust crate
│   ├── chat.rs           # High-level data-structures (Role, Message, …)
│   ├── encoding.rs       # Rendering &amp; parsing implementation
│   ├── registry.rs       # Built-in encodings
│   ├── tests.rs          # Canonical Rust test-suite
│   └── py_module.rs      # PyO3 bindings ⇒ compiled as openai_harmony.*.so
│
├── harmony/              # Pure-Python wrapper around the binding
│   └── __init__.py       # Dataclasses + helper API mirroring chat.rs
│
├── tests/                # Python test-suite (1-to-1 port of tests.rs)
├── Cargo.toml            # Rust package manifest
├── pyproject.toml        # Python build configuration for maturin
└── README.md             # You are here 🖖"><pre><code>.
├── src/                  # Rust crate
│   ├── chat.rs           # High-level data-structures (Role, Message, …)
│   ├── encoding.rs       # Rendering &amp; parsing implementation
│   ├── registry.rs       # Built-in encodings
│   ├── tests.rs          # Canonical Rust test-suite
│   └── py_module.rs      # PyO3 bindings ⇒ compiled as openai_harmony.*.so
│
├── harmony/              # Pure-Python wrapper around the binding
│   └── __init__.py       # Dataclasses + helper API mirroring chat.rs
│
├── tests/                # Python test-suite (1-to-1 port of tests.rs)
├── Cargo.toml            # Rust package manifest
├── pyproject.toml        # Python build configuration for maturin
└── README.md             # You are here 🖖
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Developing locally</h3><a id="user-content-developing-locally" aria-label="Permalink: Developing locally" href="#developing-locally"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Rust tool-chain (stable) – <a href="https://rustup.rs/" rel="nofollow">https://rustup.rs</a></li>
<li>Python ≥ 3.8 + virtualenv/venv</li>
<li><a href="https://github.com/PyO3/maturin"><code>maturin</code></a> – build tool for PyO3 projects</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">1. Clone &amp; bootstrap</h4><a id="user-content-1-clone--bootstrap" aria-label="Permalink: 1. Clone &amp; bootstrap" href="#1-clone--bootstrap"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/openai/harmony.git
cd harmony
# Create &amp; activate a virtualenv
python -m venv .venv
source .venv/bin/activate
# Install maturin and test dependencies
pip install maturin pytest mypy ruff  # tailor to your workflow
# Compile the Rust crate *and* install the Python package in editable mode
maturin develop -F python-binding --release"><pre>git clone https://github.com/openai/harmony.git
<span>cd</span> harmony
<span><span>#</span> Create &amp; activate a virtualenv</span>
python -m venv .venv
<span>source</span> .venv/bin/activate
<span><span>#</span> Install maturin and test dependencies</span>
pip install maturin pytest mypy ruff  <span><span>#</span> tailor to your workflow</span>
<span><span>#</span> Compile the Rust crate *and* install the Python package in editable mode</span>
maturin develop -F python-binding --release</pre></div>
<p dir="auto"><code>maturin develop -F python-binding</code> builds <em>harmony</em> with Cargo, produces a native extension
(<code>openai_harmony.&lt;abi&gt;.so</code>) and places it in your virtualenv next to the pure-
Python wrapper – similar to <code>pip install -e .</code> for pure Python projects.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">2. Running the test-suites</h4><a id="user-content-2-running-the-test-suites" aria-label="Permalink: 2. Running the test-suites" href="#2-running-the-test-suites"></a></p>
<p dir="auto">Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo test          # runs src/tests.rs"><pre>cargo <span>test</span>          <span><span>#</span> runs src/tests.rs</span></pre></div>
<p dir="auto">Python:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pytest              # executes tests/ (mirrors the Rust suite)"><pre>pytest              <span><span>#</span> executes tests/ (mirrors the Rust suite)</span></pre></div>
<p dir="auto">Run both in one go to ensure parity:</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">3. Type-checking &amp; formatting (optional)</h4><a id="user-content-3-type-checking--formatting-optional" aria-label="Permalink: 3. Type-checking &amp; formatting (optional)" href="#3-type-checking--formatting-optional"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="mypy harmony        # static type analysis
ruff check .        # linting
cargo fmt --all     # Rust formatter"><pre>mypy harmony        <span><span>#</span> static type analysis</span>
ruff check <span>.</span>        <span><span>#</span> linting</span>
cargo fmt --all     <span><span>#</span> Rust formatter</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is GitHub UI getting slower? (194 pts)]]></title>
            <link>https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/</link>
            <guid>44799861</guid>
            <pubDate>Tue, 05 Aug 2025 16:07:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/">https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/</a>, See on <a href="https://news.ycombinator.com/item?id=44799861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I couldn't help but notice - GitHub UI has been getting slower and slower recently. Some things that were snappy before are
hellishly slow nowadays. GitHub is doing something weird and I just can't wrap my head around what's going on there.</p>
<p><strong>You guys developing at GitHub, you're using GitHub to develop it, right? Do you not see this? What's going on?</strong></p>
<p>Whenever I bump into slow website which drives me nuts, I open the devtools and profile it. Who knows, maybe I
find something to report and the problem will get fixed.</p>
<p>To give one representative example, here's a profile for switching from "Conversation" tab to
"Files changed" tab on a PR.</p>
<p>Before we look into the profile, notice that this takes over 5s. How is anything like that acceptable in 2025 is beyond me.</p>
<p><img src="https://yoyo-code.com/file-view-route-change.webp" alt="file-view-route-change.png"></p>
<p>Now, if you dive deep into this, you'll see that GitHub uses <a rel="noopener" target="_blank" href="https://turbo.hotwired.dev/">Turbo</a> to preload next page and swap out the
content without page reload. This is usually done as a performance optimization, but here, we see something completely
absurd.</p>
<p>If you try this out at home and play around with it, you'll find out that <strong>opening the "Files changed" link in a new tab is
actually 2x faster:</strong></p>
<p><img src="https://yoyo-code.com/fresh-file-view.webp" alt="img.png"></p>
<p>And not only that - the client side post-processing in the first profile actually takes longer than loading the html
from the server. This whole thing just doesn't make any sense.</p>
<p>The cherry on top is the new loading bar that just drives me absolutely nuts, because it reminds me how slow
the whole transition is:</p>
<p><img src="https://yoyo-code.com/github-progress-bar.webp" alt="github-progress-bar.png"></p>
<p>Guys... can you just make the transition fast such that you don't need a new loading bar?
Like, what's the point of doing client side routing, when you just recreate the full page reload experience, but slower?
<strong>The whole point of doing SPAs was to avoid this. Client side routing should be instant.</strong></p>
<p>This is just one of many performance problems on GitHub. It didn't use to be that way. Trying to go through multiple PRs and 
issues is just suffering now. Imagine you have 20 PRs to find out which one introduced a regression, and every click takes more than 5 seconds to show something.</p>
<p>Don't even get me started on the diff view itself - yes, the one that periodically freezes for 2 seconds while browsing through
large PR's - maybe it has something to do with the fact that it renders thousands of invisible plus buttons with the
same inlined svg icon:</p>
<p><img src="https://yoyo-code.com/invisible-plus-icon.webp" alt="invisible-plus-icon.webp"></p>
<p><img src="https://yoyo-code.com/invisible-plus-icon-html.webp" alt="invisible-plus-icon-html.png"></p>
<p>Or, you know, maybe not trying to render <a rel="noopener" target="_blank" href="https://github.com/orgs/community/discussions/111001">100 000 DOM nodes</a> in general would
also help.</p>
<p>The whole window freezes for 3 seconds when you resize the dev tools window because you want to profile
this thing.</p>
<h2 id="does-this-ever-improve">Does this ever improve?<span>
<a href="#does-this-ever-improve" aria-label="Anchor link for: does-this-ever-improve">🔗</a>
</span>
</h2>
<p>So, maybe, when <a rel="noopener" target="_blank" href="https://github.com/orgs/community/discussions/33663">some of the popular issues</a> are related to performance, and GitHub has this seemingly related <a rel="noopener" target="_blank" href="https://github.com/orgs/github/projects/4247/views/1?filterQuery=is%3Aopen+product-focus-area%3A%22%E2%9B%B0+Platform+for+collaboration+at+scale%22">"Platform collaboration at scale"</a> focus area in the roadmap, maybe this will change?</p>
<p>Let's look at the roadmap and see if we can find
<a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap%20slow&amp;type=code">anything</a> <a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap+slow+ui&amp;type=issues">related</a> to <a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap+web+performance&amp;type=code">performance</a>. Did you find something?</p>
<hr>

<ul>
<li><a href="https://yoyo-code.com/javascript-style-for-optimal-size/">JavaScript style for optimal size</a></li>
<li><a href="https://yoyo-code.com/two-basic-rules-of-performance-aware-javascript-in-the-browser/">Basic rules of JavaScript performance in the browser</a></li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC abandons efforts to make U.S. broadband fast and affordable (250 pts)]]></title>
            <link>https://www.techdirt.com/2025/08/05/trump-fcc-abandons-efforts-to-make-u-s-broadband-fast-and-affordable/</link>
            <guid>44799756</guid>
            <pubDate>Tue, 05 Aug 2025 15:59:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2025/08/05/trump-fcc-abandons-efforts-to-make-u-s-broadband-fast-and-affordable/">https://www.techdirt.com/2025/08/05/trump-fcc-abandons-efforts-to-make-u-s-broadband-fast-and-affordable/</a>, See on <a href="https://news.ycombinator.com/item?id=44799756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-510135">

				


				


				<h3>from the <i>this-is-why-we-can't-have-nice-things</i> dept</h3>
				


				<p>Section 706 of the Telecom Act&nbsp;<a href="https://www.law.cornell.edu/uscode/text/47/1302">requires</a>&nbsp;the FCC to determine whether broadband is being deployed “on a reasonable and timely basis” to everyone. If the answer is no, the law says the FCC must “take immediate action to accelerate deployment of such capability by removing barriers to infrastructure investment and by promoting competition in the telecommunications market.”</p>
<p>For decades, the FCC has tap-danced around this mandate. Corruption and regulatory capture has resulted in a U.S. telecom sector that’s barely competitive, highly consolidated, and dominated by a handful of regional telecom monopolies. Those monopolies don’t have to try very hard to expand access, lower prices, or improve speeds. The FCC has been historically feckless about doing anything about it. </p>
<p>Every so often the FCC tries to do the absolute bare minimum to improve on this dynamic. Like during the Biden administration, when the Biden FCC <a href="https://www.techdirt.com/2024/03/20/fcc-finally-updates-americas-pathetic-definition-of-broadband-to-100-mbps/#:~:text=According%20to%20FCC%20boss%20Jessica,our%20colleagues%20at%20other%20agencies.">last year boosted the definition of broadband</a> to a still pathetic 100 Mbps downstream, 10 Mbps upstream, pledged to hold gigabit access as a future goal, and made a thin pledge to <strong>maybe</strong> take a closer look at why U.S. broadband is so expensive. </p>
<p>Not surprisingly, <a href="https://arstechnica.com/tech-policy/2025/07/fcc-to-eliminate-gigabit-speed-goal-and-scrap-analysis-of-broadband-prices/">the Trump administration is killing all of that</a>. </p>
<p>In a flimsy explanation, Trump FCC boss Brendan Carr claims that having meaningful standards and ensuring that broadband is affordable are “extraneous”&nbsp;matters. To further prop up his agency’s apathy, he points to the recent Loper Bright Supreme Court ruling that curtail the FCC’s authority to do anything that might upset a big U.S. corporation:</p>
<blockquote>
<p><em>“The Carr FCC’s proposal points to a&nbsp;<a href="https://arstechnica.com/tech-policy/2024/06/scotus-kills-chevron-deference-giving-courts-more-power-to-block-federal-rules/">Supreme Court ruling</a>&nbsp;that limited the ability of federal agencies to interpret ambiguous laws. Given that ruling, “we believe it is most prudent to strictly adhere to the statutory text,” the proposal said.”</em></p>
</blockquote>
<p>We’ve noted repeatedly how this is the <a href="https://www.techdirt.com/2025/05/01/brendan-carrs-fcc-abuses-run-face-first-into-trump-court-efforts-to-destroy-regulatory-power/">legal and logical incoherence</a> at the heart of Trump and Brendan Carr’s FCC. Carr wants to wield FCC authority like a tyrant, leveraging often <a href="https://www.techdirt.com/2023/04/25/fcc-commissioner-brendan-carr-continues-to-enjoy-oodles-of-free-press-for-fear-mongering-about-tiktok/">completely nonexistent agency power to force TikTok to sell itself to Trump’s buddies</a>, <a href="https://www.techdirt.com/2025/03/04/fcc-boss-brendan-carr-investigating-verizon-for-not-being-racist-enough/">bully telecom companies into being more racist</a>, or cajole media companies into softening their journalism of our idiot king.</p>
<p>The problem is, only one side can “win” this standoff, and it’s corporate power. Carr can saber rattle and threaten all he likes, but the primary agenda of Trump 2.0 (outside of the racism) is delivering the final killing blow to federal consumer protection, regulatory autonomy, and corporate oversight.</p>
<p>If you’re an amoral billionaire or corporation with zero interest in a habitable planet, any sort of equality, or functioning democracy, the project is going very well. If you’re an actual resident of the United States, interested in things like labor rights, clean drinking water, or evenly available and affordable broadband access, you are in <em>very, very serious trouble</em>. </p>
<p>Companies like Comcast, AT&amp;T, and Verizon want a federal government that just mindlessly rubber stamps their harmful mergers, then turns a blind eye to all of the harms of consolidation and market failure. And while U.S. regulators were already terrible at taking meaningful action to stop this, Trump 2.0 is making all of our regulatory capture and corruption problems<em> immeasurably worse</em>.</p>
<p>Our broken, consolidated corporate press doesn’t much want to talk about it, but <a href="https://www.techdirt.com/2025/04/07/federal-consumer-protection-is-dead-the-fate-of-net-neutrality-warned-you-it-was-coming/">U.S. federal consumer protection and corporate oversight is effectively dead</a>, the impact will reverberate for decades, and a significant portion of the damage of the second Trump Presidency will be permanent. </p>
<p>Even under an ideal situation where Trump authoritarianism is conquered and some sort of sensible alternative takes office, restoring oversight of companies like Comcast and AT&amp;T — both bone-grafted to our domestic surveillance networks — is never going to be a priority in a Congress that’s now too corrupt to function, under a broken court system that treats corporate power as an unimpeachable deity.</p>
<p>If the FCC was a serious agency, there’s plenty it could do to improve broadband access. It could take aim at monopoly power. It could encourage municipal broadband and local cooperatives. It could impose real penalties for service quality and privacy violations. It could implement and enforce consistent standards demanding better of our regional monopoly giants. </p>
<p>With only the occasional short-lived exceptions, at every opportunity the U.S. does the exact opposite, in blind service to telecom monopoly power.</p>

				
<p>

	Filed Under: <a href="https://www.techdirt.com/tag/affordable/" rel="tag">affordable</a>, <a href="https://www.techdirt.com/tag/brendan-carr/" rel="tag">brendan carr</a>, <a href="https://www.techdirt.com/tag/broadband/" rel="tag">broadband</a>, <a href="https://www.techdirt.com/tag/fcc/" rel="tag">fcc</a>, <a href="https://www.techdirt.com/tag/fiber/" rel="tag">fiber</a>, <a href="https://www.techdirt.com/tag/telecom/" rel="tag">telecom</a>
	<br>

	
</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub pull requests were down (121 pts)]]></title>
            <link>https://www.githubstatus.com/incidents/6swp0zf7lk8h</link>
            <guid>44799494</guid>
            <pubDate>Tue, 05 Aug 2025 15:44:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com/incidents/6swp0zf7lk8h">https://www.githubstatus.com/incidents/6swp0zf7lk8h</a>, See on <a href="https://news.ycombinator.com/item?id=44799494">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Resolved
          </h2>
          <div>
            <p><span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410479000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:14</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410465000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:14</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410454000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:14</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Issues is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410448000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:14</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410441000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:14</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410434000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:13</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We have fully mitigated this issue and all services are operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410426000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:13</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410133000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:08</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754410014000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:06</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We have identified a change that was made in the Pull Request area for GitHub. Users may be unable to use certain pull request and issues features and may see some webhooks impacted. We have identified the issue, taken mitigation and are starting to see recovery but will continue to monitor and post updates as we have them.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409949000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">16:05</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409395000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:56</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409311000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:55</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409248000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:54</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409114000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:51</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754409093000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:51</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are investigating reports of degraded performance for Issues and Webhooks</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1754408531000"></span>Aug <var data-var="date">05</var>, <var data-var="year">2025</var> - <var data-var="time">15:42</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: Git Operations, Webhooks, Issues, Pull Requests, and Actions.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eleven Music (184 pts)]]></title>
            <link>https://elevenlabs.io/blog/eleven-music-is-here</link>
            <guid>44799479</guid>
            <pubDate>Tue, 05 Aug 2025 15:42:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elevenlabs.io/blog/eleven-music-is-here">https://elevenlabs.io/blog/eleven-music-is-here</a>, See on <a href="https://news.ycombinator.com/item?id=44799479">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today, we launched <a href="http://elevenlabs.io/music"><span>Eleven Music</span></a> – the next step on our mission to build the most comprehensive AI audio platform in the world. With Eleven Music, businesses, creators, artists, and every single one of our users can generate studio-grade music from natural language prompts, with:</p><p>- Complete control over genre, style, and structure</p><p>- Vocals or just instrumental</p><p>- Multi-lingual, including English, Spanish, German, Japanese and more</p><p>- Edit the sound and lyrics of individual sections or the whole song</p><h3 id="0-a-few-of-our-favorite-samples">A few of our favorite samples</h3><p>Check out a few of our favorite songs generated by the ElevenLabs team thus far:&nbsp;</p><p><strong>Echoes of Midnight</strong></p><p>Prompt: “Dreamy, psychedelic, slow Indie Rock, reverb-soaked vocals, retro keys, catchy chorus, analog, phased guitars, liminal, nostalgic feeling, anthem.”</p></div><div><p><strong>Saddles and Shadows</strong></p><p>Prompt: “An epic track for a cowboy show, wild west, cinematic sound design, guitar twanging with awesome orchestral elements crescendoing to a powerful finale, soundtrack.”</p></div><div><p><strong>Don’t Let Me Go</strong></p><p>Prompt: “A very retro track from the 1950s with an old crooner male vocalist, charming, vintage, classic, nostalgic, golden oldies, vinyl crackle, catchy vocal hooks.”</p></div><div><p><strong>Obsidian</strong></p><p>Prompt: “Extremely dark, tense and powerful, cinematic sound design, electronic hybrid, trailer music, evil, braam, braam horns, impacts, boom, rising tension, completely instrumental.”</p></div><div><p><strong>Wanderer of the Moor</strong></p><p>Prompt: “A young english girl singing an old english folk song, stunning, lonely, thoughtful and almost haunting, fiddle and english folk instrumentation, reverb, short song.”</p></div><div><p><strong>Yellow Bus Jam</strong></p><p>Jam band song about driving through new york city in a big yellow school bus with 2 long guitar solos and lots of harmonizing</p></div><div><p>We can’t wait to see what you create.</p><h3 id="12-commercial-use">Commercial use&nbsp;</h3><p>Created in collaboration with labels, publishers, and artists, Eleven Music is cleared for nearly all commercial uses, from film and television to podcasts and social media videos, and from advertisements to gaming. For more information on supported usage across our different plans, <a href="https://elevenlabs.io/music-terms"><span>head here</span></a>.</p><p>Eleven Music is available today on our website, with public API access and integration into our Conversational AI platform coming soon. Check out our <a href="https://elevenlabs.io/docs/best-practices/prompting/eleven-music"><span>prompt engineering guide</span></a> to help you master the full range of the model’s capabilities. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Pull Requests Are Down (202 pts)]]></title>
            <link>https://github.com/github/site-policy/pull/582</link>
            <guid>44799435</guid>
            <pubDate>Tue, 05 Aug 2025 15:39:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/github/site-policy/pull/582">https://github.com/github/site-policy/pull/582</a>, See on <a href="https://news.ycombinator.com/item?id=44799435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="" data-turbo-frame="" id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
      
  <div id="partial-discussion-header" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3NjkiLCJ0IjoxNzU0NDExNDAyfQ==--2568efa0628aad1cc39d62ebec1a21f18c2c4f476a36e161c0236c877f489498" data-url="/github/site-policy/pull/582/partials/title?sticky=true" data-channel-event-name="title_updated" data-pull-is-open="false" data-gid="PR_kwDOBZWBkc48h7Vx">
          


             

<details>
  <summary id="button-abb164dc99c87f82">
    
    New issue
  </summary>
  <details-dialog aria-label="Sign up for GitHub">
            <div>
  <p>
    <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  

  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/github/site-policy/pull/582&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="4d9326608e8c097ec3e9566ae86f2f0d139f7b2568fb73904505561b2ae09c72" href="https://github.com/login?return_to=%2Fgithub%2Fsite-policy%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div>
  </details-dialog>
</details>
            
        </div>



        




    <div data-view-component="true" id="discussion_bucket" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3Njk6dGltZWxpbmUiLCJ0IjoxNzU0NDExNDAyfQ==--6e40b0786485dfecaa79dcfd5be724a909879d74d82e55ccb30ec50875eae584">            <h2>Conversation</h2>
  <div data-quote-markdown=".js-comment-body" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-team-hovercards-enabled="" data-hpc="">
    <template>
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <span>
      This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a class="Link--inTextBlock" href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template>
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
</span></template>

    <div>

      <div data-gid="PR_kwDOBZWBkc48h7Vx" data-url="/github/site-policy/pull/582/partials/body" data-channel-event-name="body_updated" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3NjkiLCJ0IjoxNzU0NDExNDAyfQ==--2568efa0628aad1cc39d62ebec1a21f18c2c4f476a36e161c0236c877f489498">

<p><a href="https://github.com/ghost" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/ghost/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/10137?s=60&amp;v=4" alt="ghost" size="40" height="40" width="40" data-view-component="true"></a>
  
  
</p><div id="issue-1326318719">
          

          <div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers.  <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period.<br>
<a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a><br>
We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification:<br>
DNT and self-help browser extensions<br>
Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that:<br>
• Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies.<br>
• Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons.<br>
• Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT.<br>
• Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies.<br>
• Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies.<br>
• Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub).<br>
Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options.<br>
Enterprise user experience<br>
Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most.<br>
Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page.<br>
Stylistic change<br>
Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
    </div>
  </task-lists>
  
</div>

          <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-cae512ba-9b0f-4a9e-80ee-9ff2c9bc4a40" for="reactions--reaction_button_component-bce9fe" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacamera, kpennell, Marcisbee, SwatDoge, whiztech, ElianCodes, nikolaymatrosov, agussyahrilmubarok, AmariHana, wopian, and 77 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e5f1a33b-f4ad-4a92-8ffe-bc591a814438" for="reactions--reaction_button_component-246031" popover="manual" data-direction="n" data-type="description" data-view-component="true">krystian3w, ivaluexrays, Hsn723, reilly3000, itzzexcel, diksown, fhlemes, futursolo, FlorianWendelborn, shoenig, and 1702 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-54f1ce29-00d3-4846-a190-16e66c0c4cf0" for="reactions--reaction_button_component-def9d5" popover="manual" data-direction="n" data-type="description" data-view-component="true">SwatDoge, flymedllva, keenwon, jessedoka, NLTD2010, LyeZinho, luism3861, surya-kasturi-lb, ZelphirKaltstahl, zongruxie4, and 11 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-b3edff4f-d3d1-4401-b138-197644bee341" for="reactions--reaction_button_component-f25c47" popover="manual" data-direction="n" data-type="description" data-view-component="true">shankarlol, jessedoka, fsvehla, itpropro, Varun270, ericbarrionuevo, ims2012035, naserykarim922, ma99R, JanaAhurtsova, and ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-0dcc38d8-3ee1-4acf-903b-ee6c7c6d1590" for="reactions--reaction_button_component-d62eb1" popover="manual" data-direction="n" data-type="description" data-view-component="true">leoheck, JJTech0130, william-herring, tylerjw, TheMaverickProgrammer, sigaloid, afkvido, MarcusGoldschmidt, BlazeIsClone, RoyTinker, and 179 more reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-8458cea6-6642-4b6a-b66d-b5ea467501fe" for="reactions--reaction_button_component-2e99fc" popover="manual" data-direction="n" data-type="description" data-view-component="true">renancaraujo, josemoises2007, bodeboushi12, euclidesdry, 8xu, ims2012035, naserykarim922, ma99R, guero0109, and JanaAhurtsova reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-a65a3160-420c-4cbd-a462-8c4c57e4a6dc" for="reactions--reaction_button_component-250fbe" popover="manual" data-direction="n" data-type="description" data-view-component="true">Ivanov-Anton, jessedoka, xFluffyke, itpropro, ims2012035, Natee9969, naserykarim922, ma99R, JanaAhurtsova, and ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-c1c957b7-0385-4948-8c1d-a0b348235859" for="reactions--reaction_button_component-71e65a" popover="manual" data-direction="n" data-type="description" data-view-component="true">pabloazurduy, kinow, jrmsjorgesilva, afkvido, arderyp, cpeterso, tulios, mau-seifert, genkoph, NNBnh, and 46 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>
</div>

      

       
            


      <div data-view-component="true" data-gid="C_kwDOBZWBkdoAKGRlNDUyMGRkYTRjZmEzZjM0NTA3OWI2Mjk5NWJmNTFmMzkyYjRiYzM">
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/olholder/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/olholder">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/47122450?s=40&amp;v=4" width="20" height="20" alt="@olholder">
</a>  </p>
</div>
    <div>
      <pre>Updates to privacy statement</pre>
    </div>
</div>

      <div data-team-hovercards-enabled="" id="event-7112771716" data-gid="RTE_lADOBZWBkc5PDgR_zwAAAAGn9EiE">

      


          <p><img src="https://avatars.githubusercontent.com/u/10137?s=32&amp;v=4" alt="@ghost" height="20" width="20">
  <strong>ghost</strong>


        changed the title
<del>Update github-privacy-statement.md</del>

<ins>Privacy Statement Updates September 2022</ins></p><a href="#event-7112771716"><relative-time datetime="2022-08-02T19:37:12Z">Aug 2, 2022</relative-time></a>

    </div>

      <div id="pullrequestreview-1059501308" data-gid="PRR_kwDOBZWBkc4_JrT8" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTAxMzA4IiwidCI6MTc1NDQxMTQwM30=--3978f98e3c7095f392252ef440aac4317db9bf54764706da6c204e2a0ca35b21" data-url="/github/site-policy/pull/582/partials/reviews/1059501308">
      <div data-view-component="true">
  <p><a href="https://github.com/rick" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/rick/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/6259?s=60&amp;v=4" alt="rick" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-598997423" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr data-position="0">
            <td data-line-number="..."></td>
            <td data-line-number="..."></td>
            <td colspan="2">@@ -33,13 +34,13 @@ To see our Privacy Notice to residents of California, please go to [GitHub's Not</td>
          </tr>
          <tr>

              <td data-line-number="33"></td>

              <td data-line-number="34"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="34"></td>

              <td data-line-number="35"></td>

            <td>
              <span><span>|</span> Section <span>|</span> What can you find there? <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="35"></td>

              <td data-line-number="36"></td>

            <td>
              <span><span>|</span>---<span>|</span>---<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="36"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your Personal Data in connection with the Website or Service. <span>|</span></span>

            </td>
          </tr>
    </tbody></table>

</div>


<div data-quote-markdown=".js-comment-body">
        <div id="discussion_r936082589">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Is the change from "Personal Data" to "personal data" a stylistic change?</p>
<p dir="auto">I note that the paragraph above is still intact:</p>
<blockquote>
<p dir="auto">All capitalized terms have their definition in <a href="https://github.com/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.</p>
</blockquote>
<p dir="auto">Presuming this capitalization change is unintentional, it has the unfortunate effect of decoupling "Personal Data" from the definition provided in the GitHub Terms of Service, which means that "personal data" is no longer as delineated there, but could well be anything.</p>
<p dir="auto">If this is an intentional change, it would seem better made as a visible change to the Terms of Service. If the intent is not to change the Terms of Service but to arbitrarily expand "personal data" without drawing attention, well, that seems evil.</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-ad23abe6-b8fe-4220-bc0c-719192021b4e" for="reactions--reaction_button_component-29373f" popover="manual" data-direction="n" data-type="description" data-view-component="true">TotallyInformation, bashrc2, TheLastProject, RokeJulianLockhart, Eireen, akshaim, S1GGEN, ims2012035, UNINOIZE, ikhtearalamshawonmollah54321, and ma99R reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-66512b5a-c560-40a1-9ac6-a698d63da9b1" for="reactions--reaction_button_component-00a730" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 and ma99R reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-3f557311-ba40-416d-9ac0-9f1f976447e7" for="reactions--reaction_button_component-054833" popover="manual" data-direction="n" data-type="description" data-view-component="true">Zaczero, TheDeveloper101, DimitarBogdanov, Rancunefr, adrian-enspired, chakravala, ycMia, Cking351, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-fb8b8546-ce4d-4fab-b04f-62096649d24a" for="reactions--reaction_button_component-9d78f0" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 and ma99R reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-345e3120-d607-420a-a9cc-41bfd8ba9f87" for="reactions--reaction_button_component-c65ae3" popover="manual" data-direction="n" data-type="description" data-view-component="true">CyberFlameGO, kiwiroy, thexkey, TheMaverickProgrammer, queer, cedarkeith, jrmsjorgesilva, byronic, thomasingalls, cheshire137, and 81 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936087501">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Looking into this further -- it looks like "Personal Data" is defined these days in the <a href="https://docs.github.com/en/site-policy/privacy-policies/github-data-protection-agreement">GitHub Data Protection Agreement</a>. Perhaps this was being decapitalized since it is not directly defined (afaict) in the GitHub Terms of Service?</p>
  </task-lists>
  

</div>

    <div id="discussion_r940888560">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Oh bet</p>
  </task-lists>
  

</div>

    <div id="discussion_r944061298">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">The collection of information and sale of it I think is something that has been going on for a long time. I think what matters is knowing what information we provide. But it's always good to know</p>
  </task-lists>
  

</div>

    <div id="discussion_r946820017">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">salve cade os BR</p>
  </task-lists>
  

</div>



    <div id="discussion_r949338919">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">in a court of law, doesn't "Personal Data" mean "personal data" ?</p>
<p dir="auto">lol</p>
    </div>
  </task-lists>
  

</div>

    <div id="discussion_r1532912063">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Soy mario sl papa si tubieron q ver en esta acciion demla boluntad arreglenlo o se veran en lios no agan mad difisil las cosas y agan l9 correcto</p>
  </task-lists>
  

</div>


    </div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

      <div data-view-component="true" id="pullrequestreview-1059517964" data-gid="PRR_kwDOBZWBkc4_JvYM" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTE3OTY0IiwidCI6MTc1NDQxMTQwNH0=--8c6ddaf987dfc32c556e3c02fcce267ae439c8deba49a292ce2507373f9e11d3" data-url="/github/site-policy/pull/582/partials/reviews/1059517964">
  <p><a href="https://github.com/krystian3w" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/krystian3w/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/35370833?s=60&amp;v=4" alt="krystian3w" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div id="pullrequestreview-1059535140" data-gid="PRR_kwDOBZWBkc4_Jzkk" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTM1MTQwIiwidCI6MTc1NDQxMTQwNH0=--c6c97cc8124869c29d940b628bc0fd7722c9f8d1b238fe0cbe793b56c2b7fcb4" data-url="/github/site-policy/pull/582/partials/reviews/1059535140">
      <div data-view-component="true">
  <p><a href="https://github.com/Consolatis" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Consolatis/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/35009135?s=60&amp;v=4" alt="Consolatis" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-599013576" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr>

              <td data-line-number="217"></td>

              <td data-line-number="222"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="218"></td>

              <td data-line-number="223"></td>

            <td>
              <span>Our emails to users may contain a pixel tag, which is a small, clear image that can tell us whether or not you have opened an email and what your IP address is. We use this pixel tag to make our email communications more effective and to make sure we are not sending you unwanted email.</span>

            </td>
          </tr>
          <tr>

              <td data-line-number="219"></td>

              <td data-line-number="224"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="220"></td>

              <td data-line-number="225"></td>

            <td>
              <span><span>### <span>DNT</span></span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="221"></td>

              <td data-line-number="226"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="222"></td>

              <td></td>

            <td>
              <span>"<span>[</span>Do Not Track<span>]</span><span>(</span><span>https://www.eff.org/issues/do-not-track</span><span>)</span>" (DNT) is a privacy preference you can set in your browser if you do not want online services to collect and share certain kinds of information about your online activity from third party tracking services. <span>GitHub responds </span>to browser DNT signals and <span>follows</span> the <span>[</span>W3C standard for responding to DNT signals<span>]</span><span>(</span><span>https://www.w3.org/TR/tracking-dnt/</span><span>)</span>. If you would like to set your browser to signal that you would not like to be tracked, please check your browser's documentation for how to enable that signal. There are also good applications that block online tracking, such as <span>[</span>Privacy Badger<span>]</span><span>(</span><span>https://privacybadger.org/</span><span>)</span>.</span>

            </td>
          </tr>
          <tr>

              <td></td>

              <td data-line-number="227"></td>

            <td>
              <span>"<span>[</span>Do Not Track<span>]</span><span>(</span><span>https://www.eff.org/issues/do-not-track</span><span>)</span>" (DNT) is a privacy preference you can set in your browser if you do not want online services to collect and share certain kinds of information about your online activity from third party tracking services. <span>Some services may respond </span>to browser DNT signals and <span>follow</span> the <span>[</span>W3C standard for responding to DNT signals<span>]</span><span>(</span><span>https://www.w3.org/TR/tracking-dnt/</span><span>)</span>. If you would like to set your browser to signal that you would not like to be tracked, please check your browser's documentation for how to enable that signal. There are also good applications that block online tracking, such as <span>[</span>Privacy Badger<span>]</span><span>(</span><span>https://privacybadger.org<span>/</span></span><span>)</span><span> or </span><span>[</span><span>uBlock Origin</span><span>]</span><span>(</span><span><span>https://github.com/gorhill/uBlock</span>/</span><span>)</span>.</span>

            </td>
          </tr>
    </tbody></table>

</div>


<div data-quote-markdown=".js-comment-body">
        <div id="discussion_r936108986">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Let me prefix this by stating that I am a complete layman.</p>
<p dir="auto">Previously: *GitHub* responds to browser DNT signals and follows the W3C spec.<br>
Now: Some random services, somewhere in the world, hosted by GitHub or somebody else *may* respond to browser DNT signals and follow the W3C spec.</p>
<p dir="auto">Doesn't this change invalidate the whole paragraph and turns it into a generic wiki article?</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-4c24a62b-b1e7-4795-9923-13d6240d857a" for="reactions--reaction_button_component-0794cc" popover="manual" data-direction="n" data-type="description" data-view-component="true">MrBartusek, TheMaverickProgrammer, getaaron, jrockway, DoodlesEpic, tiansh, SkyLeite, afkvido, beaugunderson, ajacques, and 195 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-91310069-57e3-42ab-b776-d1be8fe66aba" for="reactions--reaction_button_component-26add5" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-e5603720-7091-48ac-b626-a2d24729961a" for="reactions--reaction_button_component-d06f63" popover="manual" data-direction="n" data-type="description" data-view-component="true">L3P3, bjornrud, kamulos, real-yfprojects, blizzz, vishaltomars, DimitarBogdanov, wschwab, bsedin, adrian-enspired, and 4 more reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-11a6d538-e473-4b0f-be8e-61770b8dd299" for="reactions--reaction_button_component-12fb2f" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-3b8e27dd-0aad-4305-8bef-2c3cce10a943" for="reactions--reaction_button_component-f7f650" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, DamianFekete, adrian-enspired, jacobrose, gresm, euclidesdry, and mdjunaeidislam reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936122042">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Dunno, they will stop respecting DNT but leave this paragraph and make it seem as if they do. This is just confusing.</p>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-2973e65d-bf5e-4948-af95-8bf2455773c7" for="reactions--reaction_button_component-261632" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, guarilha, bdougherty, amomchilov, jmillerv, swadeley, gaael, SVendittelli, pravinxor, ZelphirKaltstahl, and 12 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-18c498cc-9fdb-4ed7-a3d7-aded3bfcc28b" for="reactions--reaction_button_component-4d0961" popover="manual" data-direction="n" data-type="description" data-view-component="true">hen-x, kkirsche, vishaltomars, SkrudjReal, TarikViehmann, and ims2012035 reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-3843c8c4-b33a-4fa0-b471-7017c31418e7" for="reactions--reaction_button_component-05e917" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars and ims2012035 reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-1bef7ab0-ca76-4b9b-ac69-8e8948f5f0eb" for="reactions--reaction_button_component-4236e4" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, ims2012035, and ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-b0451b1c-9849-4491-9081-86e905e1b931" for="reactions--reaction_button_component-c9f4a9" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, oscarhermoso, amomchilov, and ims2012035 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-080e21f3-e717-4f9d-82ea-76d9e4e9af49" for="reactions--reaction_button_component-4b0c70" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, wschwab, rettichschnidi, and ims2012035 reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-10933e06-2cff-4aba-ad45-a9384cc59dc6" for="reactions--reaction_button_component-96f6c5" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-71b3b497-5d3d-4575-8a3f-ce3cd56bc987" for="reactions--reaction_button_component-6cffcc" popover="manual" data-direction="n" data-type="description" data-view-component="true">mdjunaeidislam reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936152327">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">"Confusing" is one way to put it.</p>
<p dir="auto">Edit:<br>
<a data-hovercard-type="user" data-hovercard-url="/users/zzo38/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zzo38">@zzo38</a> articulated my personal opinion better than I could so I'll quote part of their <a href="https://github.com/github/site-policy/pull/582#issuecomment-1203508593" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment</a> here:</p>
<blockquote>
<p dir="auto">I also think that they should avoid using confusing privacy policies; the mention of DNT should either be kept as is if GitHub uses the DNT header to reduce tracking, or deleted entirely if GitHub does not use the DNT header. If it does so only in some cases, <b>it should mention what cases these are</b>. The privacy policy made sense before the change in the section about DNT, although the change mentioned above makes it confusing (as other comments already mention).</p>
<p dir="auto">[..]</p>
<p dir="auto">I have no problem with adding these non-essential cookies to the enterprise marketing pages, as long as the rest of GitHub can be used without it <b>and it is documented which pages these are</b> (and if the cookie domain is the same, also which cookies). Moving the enterprise marketing pages to a separate domain seems to me to be a good idea though, in order to be clearly distinguished (although a subdomain is probably good enough, in my opinion; <b>as long as it is documented clearly which subdomains these are</b>).</p>
</blockquote>
<p dir="auto">Emphasis are mine.<br>
In my opinion, <code>documented</code> should mean being very specific and being part of a legally binding document like the privacy policy.</p>
<p dir="auto">An example for not being specific is this part of the changes:</p>
<blockquote>
<p dir="auto">As described below, we may use non-essential cookies on <b>certain pages</b> of our website</p>
</blockquote>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-ae17e92a-6cf9-4bc8-95ed-5a70f5921c31" for="reactions--reaction_button_component-69b8a4" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, BezBIS, gatlinnewhouse, Elman295, goyalyashpal, UNINOIZE, and henry701 reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-6e7f7eda-30f1-4f20-91f6-1090500b07f2" for="reactions--reaction_button_component-57a03a" popover="manual" data-direction="n" data-type="description" data-view-component="true">MrBartusek, SkyLeite, antn, karolba, gldraphael, not-matthias, RomainTHD, jwshields, kkirsche, ulfox, and 22 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-9e5378bf-71b3-4093-82eb-128412df4079" for="reactions--reaction_button_component-821bb3" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose and stancalau reacted with heart emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r939618543">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">:))</p>
  </task-lists>
  

</div>

    <div id="discussion_r942363229">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">So; let's get this straight:</p>
<ol dir="auto">
<li>According to GDPR article 22 data subjects may exercise their right to object to processing using technical specifications.</li>
<li>GitHub acknowledges the DNT signal as a valid technical standard, i.e. technical specification.</li>
<li>Moreover; GitHub honors - or at least used to honor - that signal, illustrating that they have the capacity to respond to it appropriately.</li>
</ol>
<p dir="auto">Yeah... uhm..<br>
How is attempting to weasel yourself out from under that not morally blackest evil?</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-912a780c-5546-4fb9-b5c1-7514b54657dd" for="reactions--reaction_button_component-0af45e" popover="manual" data-direction="n" data-type="description" data-view-component="true">lodo1995, CADawg, jacobrose, reinerh, stancalau, yogthos, gaael, AaronHebert, gatlinnewhouse, bryan-hoang, and 15 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-f6831a82-9fc5-42fa-8b7b-6d02eae29abb" for="reactions--reaction_button_component-f63463" popover="manual" data-direction="n" data-type="description" data-view-component="true">Rwarcards762, CADawg, ericksoa, and euclidesdry reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-6b1ad3fa-205d-4c04-a52a-8a942afb2422" for="reactions--reaction_button_component-65f8be" popover="manual" data-direction="n" data-type="description" data-view-component="true">CADawg and Gerardojc reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>



    <div id="discussion_r1830653959">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">can someone please explain the policy's <a data-hovercard-type="organization" data-hovercard-url="/orgs/github/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/github">@github</a> and what happened to <a data-hovercard-type="user" data-hovercard-url="/users/dontsellmydata/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/dontsellmydata">@dontsellmydata</a>?<br>
asking for a friend</p>
  </task-lists>
  

</div>

    <div id="discussion_r2249062805">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">privacy-statement-update-sep-2022</p>
  </task-lists>
  

</div>


    </div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

      <div data-gid="IC_kwDOBZWBkc5HuV3O" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuV3O/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jdgregson/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jdgregson"><img src="https://avatars.githubusercontent.com/u/3778841?s=80&amp;u=22355dea7c49323adb8b54ea6072935d2ee0703a&amp;v=4" width="40" height="40" alt="@jdgregson"></a>

</p>


  
<div data-body-version="b55ba0cce6be6f0d8f1b3768340000e3a94313b34054ccde7d7a31308cad3968" id="issuecomment-1203330510">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">You lost me at <code>ads for enterprise users</code>.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e1745cb8-7683-432b-9734-0410c8b93cb5" for="reactions--reaction_button_component-9340c8" popover="manual" data-direction="n" data-type="description" data-view-component="true">iam-py-test, stamminator, rizkyhaksono, FaircoreHD, askeer25, Madi-Ji, michaeldelago, LambdAurora, Asjas, bdougherty, and 62 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-d3d20cd6-8ce9-417c-b79b-e491ad3d30bb" for="reactions--reaction_button_component-500a5c" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-e158a52a-7078-46c7-b757-821c376b5655" for="reactions--reaction_button_component-950b95" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035, ma99R, FlorianWendelborn, and henry701 reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-53c21ae0-34e2-437c-b809-61fea0c3702f" for="reactions--reaction_button_component-90d6f4" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-5aeea9e7-bc6e-4743-b238-22aced1d99af" for="reactions--reaction_button_component-d5b04c" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-9dd94a8b-4d57-4b28-bd2d-4fa13bdfd488" for="reactions--reaction_button_component-04f54d" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-c4d6c54b-8d75-4efd-98a6-dd3e9c4cc3e8" for="reactions--reaction_button_component-678542" popover="manual" data-direction="n" data-type="description" data-view-component="true">leoheck, Cyb3r-Jak3, c3r0, Sunnnner, yanghanlin, jtraglia, TheMaverickProgrammer, trevorstenson, ZeroCool2u, pabloazurduy, and 139 more reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-cf030c09-c8dd-4b5c-9373-54669141b8ee" for="reactions--reaction_button_component-56f010" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuXeX" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuXeX/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/leoheck/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/leoheck"><img src="https://avatars.githubusercontent.com/u/1277920?s=80&amp;v=4" width="40" height="40" alt="@leoheck"></a>

</p>


  
<div data-body-version="3a75bde190114c20f35bfdf768a07f335b9e864ad4f20c4aca3d884c0ed8d56a" id="issuecomment-1203337111">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Github is being undermined by Microsoft.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-f14876c1-70cf-45b5-9bec-7e9462d043c9" for="reactions--reaction_button_component-c44d52" popover="manual" data-direction="n" data-type="description" data-view-component="true">ardrigh, darkbanjo, afkvido, mskelton, MarcusGoldschmidt, xCss, patstha, ariedro, karolba, povilaspetkevicius, and 173 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-0cf823b4-0196-4f08-9b0c-e14605590abc" for="reactions--reaction_button_component-bdee2d" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, cinnamondev, TreeBranches, mbifulco, itpropro, RokeJulianLockhart, ims2012035, zeina1991, and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-f7a91aa8-76b1-4b1d-a9d5-d9aa682bcca5" for="reactions--reaction_button_component-99cbee" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-45164a4c-5aa4-496e-a847-35bd761f0937" for="reactions--reaction_button_component-dbc875" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, ims2012035, and ma99R reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuafN" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuafN/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/TechSolomon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TechSolomon"><img src="https://avatars.githubusercontent.com/u/7608183?s=80&amp;u=d50a3f18756548563d2d83d8a712cc6ef025f4b9&amp;v=4" width="40" height="40" alt="@TechSolomon"></a>

</p>


  
<div data-body-version="2bdae0352f7d6a759aae50ef08ef17471e9f511665b705b55584648b86d30283" id="issuecomment-1203349453">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-ff5b3616-b6b2-4f61-aada-e8a222feb5c4" for="reactions--reaction_button_component-9ab90d" popover="manual" data-direction="n" data-type="description" data-view-component="true">yanghanlin, doamatto, william-herring, jtraglia, xplato, ocdtrekkie, byrnes, stepbrobd, andyferris, henriquebremenkanp, and 292 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-21117f32-9dfb-43bb-bbee-331f4b200122" for="reactions--reaction_button_component-3a9e5e" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, ims2012035, ma99R, and abosayedmusic reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-a298ec59-9ae2-4642-a8e0-73f0eeca275b" for="reactions--reaction_button_component-b0cc28" popover="manual" data-direction="n" data-type="description" data-view-component="true">kubo6472, S1GGEN, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-2d35f837-2636-4ba4-b988-56150dea9b89" for="reactions--reaction_button_component-a62076" popover="manual" data-direction="n" data-type="description" data-view-component="true">html5cat, cpl, kkirsche, arsam-sedighi, rodamaral, Rikj000, speller26, LumitoLuma, NeuronButter, wschwab, and 4 more reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-71b3661e-9493-46db-964c-7562dacadc4b" for="reactions--reaction_button_component-bce69d" popover="manual" data-direction="n" data-type="description" data-view-component="true">flbn, MarcusGoldschmidt, shivajivarma, ZeroAurora, crankyadmin, DarkOnion0, just-max, krall12, arsam-sedighi, rodamaral, and 19 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huigr" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huigr/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/TheMaverickProgrammer/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TheMaverickProgrammer"><img src="https://avatars.githubusercontent.com/u/91709?s=80&amp;u=8ae1459deffcd91d0c3d84d36fb41a6666dabc32&amp;v=4" width="40" height="40" alt="@TheMaverickProgrammer"></a>

</p>


  
<div data-body-version="2994297af41a6c30fd743ed2e31ec97fc5abc19a544ce2039943b3c429d5eb5a" id="issuecomment-1203382315">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">so what github alternative is everyone using these days? asking for a friend.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-22aa830a-ba6f-40eb-bad1-4ffc85686422" for="reactions--reaction_button_component-4c7e79" popover="manual" data-direction="n" data-type="description" data-view-component="true">ardrigh, afkvido, leoheck, dominikwilkowski, timvisee, wout, demonshreder, xcfrg, osmankorogluu, alimkoca, and 103 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-bf9fd3c0-b9e4-4989-8d9f-e42e70c56bd2" for="reactions--reaction_button_component-cada5e" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, whiztech, TreeBranches, nowaythisworks, and NeuronButter reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-25e4cfc2-595e-4079-ae6b-bdc7148952fd" for="reactions--reaction_button_component-6ae80c" popover="manual" data-direction="n" data-type="description" data-view-component="true">uglow, leoheck, wout, Benj2005, powderedfish, IgorVolochay, maSchoeller, Jonikulov, Feridinha, onkoe, and 28 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-c548b372-4c91-49d2-8fea-2ca7e370a3bf" for="reactions--reaction_button_component-0ca7cd" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, wout, nothub, Feridinha, Rikj000, Risyandi, LumitoLuma, theRealProHacker, gin0115, devtooligan, and 14 more reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-f27d57d9-2064-4d73-a22a-4a16d2a79f55" for="reactions--reaction_button_component-c61ac9" popover="manual" data-direction="n" data-type="description" data-view-component="true">Rwarcards762 and afkvido reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huko-" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huko-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ocdtrekkie/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ocdtrekkie"><img src="https://avatars.githubusercontent.com/u/4399499?s=80&amp;u=ceab721d97868ffa78feb5e97ff1bb547dfd6356&amp;v=4" width="40" height="40" alt="@ocdtrekkie"></a>

</p>


  
<div data-body-version="d4ad471236222a6d776ac85103f2d5cec6b9c2f98bbc54c71a93214513a01141" id="issuecomment-1203391038">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">"We are also committing that going forward, we will only use cookies that are required for us to serve GitHub.com."</p>
<p dir="auto">Apparently in corporate terms, a "commitment" is now less than two calendar years of obligation. Good to know. Though, I guess I don't visit the marketing pages and hence, don't really care that much? Corporations being untrustworthy isn't new territory.</p>
<p dir="auto">Literally just "business advice": Your marketing teams should be weighing the value of the data here against the cost of "yet another breach of user trust and commitment", user trust, of course, being something extremely hard to earn back.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-774a2706-ea57-4394-9ca1-7ec2d72e6947" for="reactions--reaction_button_component-735dc1" popover="manual" data-direction="n" data-type="description" data-view-component="true">damien, consultutah, andyferris, jtraglia, queer, DoodlesEpic, sandro-fugro, flbn, icecreammatt, ardrigh, and 161 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-0c24b900-25c2-4e9c-8274-ed43f9d305be" for="reactions--reaction_button_component-c8a486" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart and ma99R reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HumM9" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HumM9/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/karlshea/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/karlshea"><img src="https://avatars.githubusercontent.com/u/40136?s=80&amp;u=83a9cdcd1f24cb9d4ec1a99e4ef398a389a4da36&amp;v=4" width="40" height="40" alt="@karlshea"></a>

</p>


  
<div data-body-version="2fec3d0f81d7f90dff34e5701f7c2e434cb3eba117da99165e6d390ab12b7e91" id="issuecomment-1203397437">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Marketing people don't care about user trust or commitments. They'll just burn things to the ground and move on to the next corp job, each time making the world a slightly worse place.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-bdac5443-41e5-42dc-8462-8705e03d2e96" for="reactions--reaction_button_component-bc548b" popover="manual" data-direction="n" data-type="description" data-view-component="true">nclark, sandro-fugro, icecreammatt, ardrigh, slater, mskelton, patstha, RoyTinker, uglow, ariedro, and 117 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-4ee0024a-bbec-4b30-8316-0553b09e748f" for="reactions--reaction_button_component-13db14" popover="manual" data-direction="n" data-type="description" data-view-component="true">gavinhenderson, RokeJulianLockhart, and michaelkuznetsov reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-0360eaba-9a1f-467b-a694-5aa3ba6f854e" for="reactions--reaction_button_component-60e098" popover="manual" data-direction="n" data-type="description" data-view-component="true">EwenQuim reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-2cf3d011-9355-4a72-bdc3-fc85e8bfa276" for="reactions--reaction_button_component-eb2918" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-3caadcd8-e8bc-499a-b8c7-4b5e3ca6ca52" for="reactions--reaction_button_component-d4a665" popover="manual" data-direction="n" data-type="description" data-view-component="true">UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HupcL" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HupcL/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="8b75cb42e99586e3c67be7363b4d40340484cc29cfe23742949772b47141fb93" id="issuecomment-1203410699">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This clearly shows that GitHub cares more about revenue than the user base behind it.</p>
</blockquote>
<p dir="auto">Microsoft fucking sucks, GitHub wasn't evil until Microsoft really started to abuse GitHub.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-11ea3271-c9bb-4281-a20f-183c84ebbbeb" for="reactions--reaction_button_component-ea36df" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, MarcusGoldschmidt, patstha, ariedro, karolba, dseevr, dominikwilkowski, timvisee, wout, talgat-ruby, and 82 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-d4ba0777-51ff-48c0-b2b5-baf18723bad2" for="reactions--reaction_button_component-d68b3a" popover="manual" data-direction="n" data-type="description" data-view-component="true">CAFxX, evieluvsrainbows, whiztech, liamengland1, TreeBranches, nowaythisworks, crazychatting, Blaumaus, dszymon, wojpawlik, and 4 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-8fd0372b-69ce-457d-b0ca-80e270ed607c" for="reactions--reaction_button_component-3b7206" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, JanJastrow, and ims2012035 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-4402c8ca-576d-44c8-b2fa-8ad35b9dc315" for="reactions--reaction_button_component-432d5f" popover="manual" data-direction="n" data-type="description" data-view-component="true">UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HupnV" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HupnV/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="e2c91e5973a4063323826528013bf4e0abd0a7c69ab27c13ebd6983412e49c54" id="issuecomment-1203411413">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-eb17e9ee-1043-431d-b134-09a9a935b333" for="reactions--reaction_button_component-0ef17c" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, leoheck, shivamydv, just-max, xcfrg, DanielVenturini, otavio-silva, onkoe, crazychatting, sz55net, and 20 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-2ff13314-7b4e-41e0-811f-c1be84084956" for="reactions--reaction_button_component-16647b" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, nothub, krall12, SincerelyFaust, ryuukk, coderinblack08, sanamhub, nowaythisworks, null2264, Vendicated, and 16 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-83a228b7-6d18-4f2d-8a63-b79060acf5ce" for="reactions--reaction_button_component-8e38e8" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, just-max, DanielVenturini, Caiofcas, otavio-silva, afkvido, Rwarcards762, rettichschnidi, fuomag9, MariojGG, and 2 more reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div id="pullrequestreview-1059625419" data-gid="PRR_kwDOBZWBkc4_KJnL" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NjI1NDE5IiwidCI6MTc1NDQxMTQwNH0=--56fda6c1cde88f791bececa8846f8a5d2201d6a460d98f5e5c45579fe8949f44" data-url="/github/site-policy/pull/582/partials/reviews/1059625419">
      <div data-view-component="true">
  <p><a href="https://github.com/afkvido" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/69060894?s=60&amp;v=4" alt="afkvido" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-1059625419" data-view-component="true">
                      
                  <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Requesting a change: Don't add this.</p>
  </task-lists>
  
</div>


                    <!-- '"` --><!-- </textarea></xmp> -->
                      <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-8ee6618e-5cae-46ae-9875-8ea749965023" for="reactions--reaction_button_component-88cf91" popover="manual" data-direction="n" data-type="description" data-view-component="true">mskelton, thomasingalls, VitorLuizC, jtraglia, byronic, patstha, afkvido, mattburdumy, francisschmaltz, arderyp, and 224 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-19c10583-5097-4463-afdd-0f6f11f2b6be" for="reactions--reaction_button_component-bdea34" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-45511ff1-f4d9-4f56-b6d8-ce1f28672bfe" for="reactions--reaction_button_component-4b93ab" popover="manual" data-direction="n" data-type="description" data-view-component="true">wout, Jack2104, fleroviux, DarkOnion0, gruselhaus, DanielVenturini, Rikj000, speller26, afkvido, LambdAurora, and 10 more reacted with heart emoji</tool-tip>
      
    </div>
</form></div>

</div>
        </div>

      <div data-gid="IC_kwDOBZWBkc5HuthO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuthO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/RoyTinker/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RoyTinker"><img src="https://avatars.githubusercontent.com/u/984080?s=80&amp;u=30d9e5bb3663a62a5c759a4bb6f09ed3a79c8126&amp;v=4" width="40" height="40" alt="@RoyTinker"></a>

</p>


  
<div data-body-version="41a408e6fbc267577580379401216d3157e5d38d6649104bcb40b40396a0c44b" id="issuecomment-1203427406">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I understand that cookies are helpful for analytics and gathering sales funnel data. It's always sad when companies don't keep prior promises, though 😟</p>
<p dir="auto">If you must break the promise, here's my suggestion, for what it's worth: move enterprise marketing pages (maybe even all marketing pages besides the front page?) off of <code>github.com</code> onto a separate domain. Maybe <code>github.info</code>?</p>
<p dir="auto">Then point marketing links from the front page to that domain.</p>
<p dir="auto">This will allow folks to deal with that domain separately from <code>github.com</code>.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-a4fb3b95-fef8-4ef6-a21c-86889a058139" for="reactions--reaction_button_component-d71fbd" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, cheshire137, sarangj, leoheck, yanghanlin, dominikwilkowski, pgear-wd, timvisee, wout, borisceranic, and 68 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-c89d4e37-1e16-4a9e-9e4d-75eead6fd02b" for="reactions--reaction_button_component-ace2aa" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-59e32d1e-669a-4441-af15-983dfcf9daf1" for="reactions--reaction_button_component-f475f8" popover="manual" data-direction="n" data-type="description" data-view-component="true">sz55net reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-9a8180c2-8fcb-454b-9cf3-ed87b6a64dd3" for="reactions--reaction_button_component-6f3de0" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, leoheck, 1to5pc, freearhey, Rikj000, and adrian-enspired reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huthk" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huthk/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/tylt6688/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/tylt6688"><img src="https://avatars.githubusercontent.com/u/45555547?s=80&amp;u=d52d51990831a98f478abc7bae9e1f042da2380b&amp;v=4" width="40" height="40" alt="@tylt6688"></a>

</p>


  
<div data-body-version="d5064eb55e1c6f83cedf6d00b81b2f1ed9d5617e5dcce228083f87a09e734b7d" id="issuecomment-1203427428">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I personally feel that the enterprise version can be made independently.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-45b052b9-6651-4454-9a64-23aec61440a6" for="reactions--reaction_button_component-01f298" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, kaenova, wout, borisceranic, StanleyMasinde, RomainTHD, saulshanabrook, TheMaverickProgrammer, Risyandi, jeffersongandra, and 18 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-b262209e-f17f-4180-acb9-b0b9c50a02fe" for="reactions--reaction_button_component-a1fbdf" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, TarikViehmann, and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-a4a2b480-f05a-4099-9030-3457c1c2823f" for="reactions--reaction_button_component-c8dbcf" popover="manual" data-direction="n" data-type="description" data-view-component="true">tylt6688, wfnian, and ma99R reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuvZ9" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuvZ9/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jacamera/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jacamera"><img src="https://avatars.githubusercontent.com/u/18013188?s=80&amp;u=c51a6a2fec30a7a26b998c757e289366a93f02cc&amp;v=4" width="40" height="40" alt="@jacamera"></a>

</p>


  
<div data-body-version="16a004dd6fd917fb7c0ec0f161d833772db0bf4dc759bbb2c18a72343cda88b2" id="issuecomment-1203435133">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">As a happy GitHub user I just hope all this recreational outrage doesn't result in GitHub allocating more time or resources than would otherwise be required to complete this change. Full speed ahead!</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-0f5ef109-8aeb-4acd-a061-26ef5c36e2fa" for="reactions--reaction_button_component-e1c4fd" popover="manual" data-direction="n" data-type="description" data-view-component="true">natario1, dszymon, binarydad, RokeJulianLockhart, and landsman reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-721f6e0f-8bcb-44d3-8d23-22d901b9b114" for="reactions--reaction_button_component-677584" popover="manual" data-direction="n" data-type="description" data-view-component="true">Thanaen, lopis, nothub, pankajthekush, Kl4rry, terrarier2111, TheMaverickProgrammer, SalomonSmeke, yannikbloscheck, bobaikato, and 79 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-ecaee89c-83f2-4e4e-a6ea-9134566a3221" for="reactions--reaction_button_component-3a1afa" popover="manual" data-direction="n" data-type="description" data-view-component="true">TeMPOraL, Serups, hckr, and UNINOIZE reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-7d6df16a-4382-45e6-bd00-22a89f4a3ffa" for="reactions--reaction_button_component-978364" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, TeMPOraL, and ItsIgnacioPortal reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuyQK" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuyQK/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="040ee3680903ca32b5f40831434f72fd5ee4c60053e67f61783e2e3013e8ceb6" id="issuecomment-1203446794">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">As a happy GitHub user I just hope all this recreational outrage doesn't result in GitHub allocating more time or resources than would otherwise be required to complete this change. Full speed ahead!</p>
</blockquote>
<p dir="auto">I'd want GitHub to remove Microsoft, then continue full speed ahead</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-b7c5cb26-abed-4293-99f8-4400f0ff8586" for="reactions--reaction_button_component-bdde6c" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, StanleyMasinde, asieverding, DanielVenturini, jonm58, Rikj000, sz55net, nonperforming, speller26, and 42 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-54bc1937-c9ca-48c9-a8bd-f93c1ae11d4d" for="reactions--reaction_button_component-26fa25" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, whiztech, TreeBranches, nowaythisworks, Hunam6, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-876fb72b-94e9-4ba3-b448-c91181c3732a" for="reactions--reaction_button_component-44ca6f" popover="manual" data-direction="n" data-type="description" data-view-component="true">amytimed, afkvido, hukl, danielabrozzoni, rettichschnidi, chakravala, and UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuzZe" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuzZe/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="081e2e31f5acd909e128adbaaf237292aa30344dd330cc3a631792b86ad4c935" id="issuecomment-1203451486">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This change is only on subdomains where GitHub markets products and services to enterprise customers, and all other GitHub subdomains will continue to operate as-is.</p>
</blockquote>
<p dir="auto">Why are people getting so riled up when this change <em>only</em> impacts the Enterprise marketing subdomains? Makes no sense to me how this of all things is getting negative attention. Majority of people don't use GitHub Enterprise, as its only for businesses, And they're just cookies. Use uBlock Origin as it says if you really can't stand a few cookies on subdomains you'll probably never end up going to.</p>
<p dir="auto">Also, people love pointing the finger at Microsoft, as if this change was demanded by them. It more than likely wasn't. There are always going to be changes that people don't like, but not all changes are influenced by the parent company. If Microsoft was puttng their hands all over GitHub, they probably would've moved GitHub to the Microsoft Policy Statement a long time ago.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-61e2f369-045e-446c-834a-280b5bff188c" for="reactions--reaction_button_component-026737" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacamera, theolivenbaum, whiztech, lumaxis, PatheticMustan, lunaisnotaboy, 5HT2, SaifAqqad, cesarfigueroa, aphedges, and 27 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-af8681ce-2426-47b7-885f-5790cd5a41db" for="reactions--reaction_button_component-4696b7" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, doamatto, c0b41, nothub, talesaraujo, yannikbloscheck, rodrigoruan-osf, pankajthekush, Brawl345, nonperforming, and 56 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-26ab5c7b-eaa4-448e-bb48-4fb2a48d4470" for="reactions--reaction_button_component-b06b31" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido and maroehsushe37 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-4f78ec32-302f-4918-9591-2f096d92340f" for="reactions--reaction_button_component-793a06" popover="manual" data-direction="n" data-type="description" data-view-component="true">NochEinKamel, Rfc2026, and maroehsushe37 reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-d0637240-5ae7-4f07-869d-8b708839abbf" for="reactions--reaction_button_component-491057" popover="manual" data-direction="n" data-type="description" data-view-component="true">NochEinKamel, shaikshafiulla, and maroehsushe37 reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huzy6" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huzy6/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="8b188db1c74deee351b03a2500817c59d1a4706a1998fd68e56bbf228ab401c0" id="issuecomment-1203453114">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Cuz GitHub said they wouldnt use cookies<br>
daym its a borken promise</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e9d2b685-c9ef-4a45-ae54-3ed762a4ffbb" for="reactions--reaction_button_component-1e90ad" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, localcached, talesaraujo, naufik, rodrigoruan-osf, null2264, Rikj000, sz55net, jmeggitt, and 45 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e59fecfb-9ac1-436a-84b0-6d751580c11f" for="reactions--reaction_button_component-e9c350" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, TheMaverickProgrammer, nowaythisworks, lunaisnotaboy, NochEinKamel, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1JO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1JO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="8f4aa6b45a390aec52bb03dab5bf7df8e7d623e129df411e49d67f449d94b0ee" id="issuecomment-1203458638">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">"We are also committing that going forward, we will only use cookies that are required for us to serve GitHub.com."</p>
<p dir="auto">Apparently in corporate terms, a "commitment" is now less than two calendar years of obligation. Good to know. Though, I guess I don't visit the marketing pages and hence, don't really care that much? Corporations being untrustworthy isn't new territory.</p>
<p dir="auto">Literally just "business advice": Your marketing teams should be weighing the value of the data here against the cost of "yet another breach of user trust and commitment", user trust, of course, being something extremely hard to earn back.</p>
</blockquote>
<p dir="auto">How exactly does this in any way impact user trust? It doesn't impact the main site, like the dashboard, the landing page, or <em>any</em> other part of GitHub like profiles, repositories, or organizations. It literally <em>only</em> impacts the enterprise marketing pages, and its for sales data tracking &amp; analytics. GitHub Enterprise is a very business-oriented product, so the only visitors to those pages will be by business leaders potentially interested in GitHub Enterprise, or users who land on that page by mistake.</p>
<p dir="auto">And I believe that is what GitHub meant when they said "to serve GitHub.com" - the main site (dashboard, repos, profiles, etc), not including stuff related to their Enterprise product, so I genuinely don't believe they broke their commitment. People are overreacting, as usual, to insignificant changes that don't really impact them.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-612714b1-9596-49bd-becf-0eeacb730cf0" for="reactions--reaction_button_component-b4e532" popover="manual" data-direction="n" data-type="description" data-view-component="true">Marcisbee, PatheticMustan, 5HT2, SayakMukhopadhyay, wopian, nowaythisworks, SheepTester, gavinhenderson, mbmjertan, NeuronButter, and 8 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-aaa0bcf1-0212-4030-97d5-5d1bd154c668" for="reactions--reaction_button_component-64ceed" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, timvisee, unfunco, nothub, dallincrane, TheMaverickProgrammer, talesaraujo, yannikbloscheck, rodrigoruan-osf, jonm58, and 35 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-45b7c3a2-185e-4c74-9cc7-b5cf15187213" for="reactions--reaction_button_component-942684" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1WO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1WO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="39b59fddd31362dfea8ea9d9036eacac1e5b3d5f5e768b6b6111e1d601d49e5f" id="issuecomment-1203459470">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Thats fine but fuck microsoft for existing</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e2d6fbc5-34a7-4f76-9c38-8660b2694461" for="reactions--reaction_button_component-e82bcc" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, nothub, xv, musaubrian, ryuukk, CauaLW, Rikj000, SkyyWasTaken, tavofh98, and 7 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-caae534a-2b73-4f05-a1d1-0dab5d661117" for="reactions--reaction_button_component-d678a5" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, jtraglia, Consolatis, whiztech, PatheticMustan, jcorkhill, 5HT2, TreeBranches, samuel-hunter, nowaythisworks, and 24 more reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1pg" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1pg/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="6c1ea137d378e0d58654792c8900207b5f8320ab4864980e760802f2a4f88ce4" id="issuecomment-1203460704">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">There's a reason this PR has 128+ negative reactions 👎</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-3589bf48-d760-4bfa-b17c-224b684b915b" for="reactions--reaction_button_component-dbb0c0" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, nothub, localcached, TheMaverickProgrammer, ryuukk, talesaraujo, CauaLW, Rikj000, speller26, and 16 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-816f39eb-f5fd-4e73-b801-a62f3239470a" for="reactions--reaction_button_component-a0bb30" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, 5HT2, nowaythisworks, Colerar, Asjas, dszymon, RokeJulianLockhart, thyeggman, itpropro, and 0kku reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1tH" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1tH/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="4996e815d00df5c22650da1d36016945492eec709d27440760fbd1b1dd71328a" id="issuecomment-1203460935">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Also, they have, take a look at this PR.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu4R0" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu4R0/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="4f53117b43efeb5099688f955777cfe53678525830ad6f0b5e2ccfb85ca91ec8" id="issuecomment-1203471476">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido">@afkvido</a>: Also, they have, take a look at this PR.</p>
</blockquote>
<p dir="auto">This was more than likely not Microsoft's doing. Not everything a subsidiary of Microsoft does is because of Microsoft itself. You have the vast majority of comments on this PR (at 8 comments), and your opinion isn't be all end all. Most of the negative reactions are additionally probably from people who don't understand the scope of what GitHub said back when they committed to not use cookies not necessary to serve GitHub itself - they probably didn't extend it to the Enterprise marketing pages to begin with and always meant the main site that serves repositories and profiles and such.</p>
<p dir="auto">There are things worse than cookies by the way, like actual trackers embedded in web pages. Cookies are relatively harmless if used sparingly and for very specific purposes like tracking sales analytics or for keeping a user logged into their web browsers, or in a specific GitHub use case, tracking the current site theme. There is nothing wrong with stuff like this.</p>
<p dir="auto">You seem awfully mad at Microsoft for some reason, as if they stole your pet dog or something. This isn't 2000s &amp; early 2010s-era Microsoft, Microsoft is nowhere near as bad as they were when Steve Ballmer was the CEO of Microsoft. Ever since Satya became CEO, I have noticed a significant improvement in Microsoft's business culture and strategy. MS was way, way, <em>way</em> worse back when Ballmer was CEO.</p>
<p dir="auto">(also, slight question, why upvote your own comments?)</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-2d23be74-6be4-40f4-beed-91cb3f3c43ff" for="reactions--reaction_button_component-78b172" popover="manual" data-direction="n" data-type="description" data-view-component="true">theolivenbaum, gldraphael, GoldenretriverYT, StuSerious, PatheticMustan, lunaisnotaboy, SayakMukhopadhyay, wopian, nowaythisworks, itslychee, and 11 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-ae1803a1-c51a-4319-ab31-867b909cf300" for="reactions--reaction_button_component-52bebe" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, Zethson, nothub, rkujawa, ulfox, TheMaverickProgrammer, talesaraujo, yannikbloscheck, rootwork, parkuristt, and 25 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-345238c6-f986-4c66-bc13-464ce73dcb7e" for="reactions--reaction_button_component-995e97" popover="manual" data-direction="n" data-type="description" data-view-component="true">gresm reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu8cj" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu8cj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="ab6a4a255e35a4e0197cfaad46947f29e28a21cf30fefe01d9aedda42be31003" id="issuecomment-1203488547">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This was more than likely not Microsoft's doing. Not everything a subsidiary of Microsoft does is because of Microsoft itself.</p>
</blockquote>
<p dir="auto">I don't know why anyone at GitHub would do this change, and Microsoft is the only other entity with the authority to make such a change.</p>
<br>
<blockquote>
<p dir="auto">You have the vast majority of comments on this PR (at 8 comments), and your opinion isn't be all end all.</p>
</blockquote>
<p dir="auto">I just poke in whenever this comes up on my GitHub notifications.</p>
<br>
<blockquote>
<p dir="auto">Most of the negative reactions are additionally probably from people who don't understand the scope of what GitHub said back when they committed to not use cookies not necessary to serve GitHub itself - they probably didn't extend it to the Enterprise marketing pages to begin with and always meant the main site that serves repositories and profiles and such.</p>
</blockquote>
<p dir="auto">That is a good point, however, that doesn't change the fact that GitHub is no longer the white and fluffy angel that it was.</p>
<br>
<blockquote>
<p dir="auto">There are things worse than cookies by the way, like actual trackers embedded in web pages. Cookies are relatively harmless if used sparingly and for very specific purposes like tracking sales analytics or for keeping a user logged into their web browsers, or in a specific GitHub use case, tracking the current site theme. There is nothing wrong with stuff like this.</p>
</blockquote>
<p dir="auto">While you seem quite intelligent, I don't think that you understand that cookies could actually be used as slight trackers, and if used to their fullest potential, complete on-site tracking for AI/ML based targeted recommendations for profit.</p>
<br>
<blockquote>
<p dir="auto">You seem awfully mad at Microsoft for some reason, as if they stole your pet dog or something. This isn't 2000s &amp; early 2010s-era Microsoft, Microsoft is nowhere near as bad as they were when Steve Ballmer was the CEO of Microsoft. Ever since Satya became CEO, I have noticed a significant improvement in Microsoft's business culture and strategy. MS was way, way, way worse back when Ballmer was CEO.</p>
</blockquote>
<p dir="auto">Microsoft is still a mega-corp. They're still 'evil', just like Google or Apple. I also don't see much of a difference with the two CEOs. One was making more money, one was discussing ethics more often, but in the end, Microsoft is still somewhat invasive. To add on, Microsoft decided to absolutely <strong>RUIN</strong> Minecraft, a game that I don't really play these days, but my friends play a lot.</p>
<br>
<blockquote>
<p dir="auto">(also, slight question, why upvote your own comments?)</p>
</blockquote>
<p dir="auto">(also, slight question, why downvote my comments?)</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-cdd6bcda-f2aa-4283-8354-cda69dd96cf4" for="reactions--reaction_button_component-297b63" popover="manual" data-direction="n" data-type="description" data-view-component="true">talesaraujo, leoheck, afkvido, mitchellzehr, duck-nukem, zendynar, cryptoAlgorithm, oneEyedCharlie, Eireen, and UNINOIZE reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e44d10ba-c72c-41ec-bd93-b299b3aae9e9" for="reactions--reaction_button_component-b24f54" popover="manual" data-direction="n" data-type="description" data-view-component="true">nowaythisworks, Rexogamer, Mijyuoon, lunaisnotaboy, thatlittleboy, encode42, dszymon, qfr68414, TeknikalDomain, seve, and 6 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-c56fbfe5-07f6-4d0d-90f3-ee8d60900816" for="reactions--reaction_button_component-c7eba3" popover="manual" data-direction="n" data-type="description" data-view-component="true">EnduringBeta, samuel-hunter, and robahub reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvBVx" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvBVx/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zzo38/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zzo38"><img src="https://avatars.githubusercontent.com/u/108554049?s=80&amp;v=4" width="40" height="40" alt="@zzo38"></a>

</p>


  
<div data-body-version="9afa00a3fa928b251a312f70321003fa6f7776977cbecf46671e14e4985640f9" id="issuecomment-1203508593">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I think that the cookies ought to be documented, so that you know which cookie means what.</p>
<p dir="auto">I also think that they should avoid using confusing privacy policies; the mention of DNT should either be kept as is if GitHub uses the DNT header to reduce tracking, or deleted entirely if GitHub does not use the DNT header. If it does so only in some cases, it should mention what cases these are. The privacy policy made sense before the change in the section about DNT, although the change mentioned above makes it confusing (as other comments already mention).</p>
<p dir="auto">Mentioning other programs such as Privacy Badger and uBlock Origin are OK, although it might be worth to add a disclaimer if GitHub is not affiliated with such programs, even if they are hosted on GitHub. (Since GitHub is used for many FOSS projects, it is likely that some of them will be.)</p>
<p dir="auto">I have no problem with adding these non-essential cookies to the enterprise marketing pages, as long as the rest of GitHub can be used without it and it is documented which pages these are (and if the cookie domain is the same, also which cookies). Moving the enterprise marketing pages to a separate domain seems to me to be a good idea though, in order to be clearly distinguished (although a subdomain is probably good enough, in my opinion; as long as it is documented clearly which subdomains these are).</p>
<p dir="auto">About alternatives to GitHub, I would not recommend GitLab because it will not display the files if JavaScripts are not enabled. However, it is acceptable to use GitLab if there are mirrors on multiple services. GitHub, Codeberg, and NotABug, and some others, also use JavaScripts, although the files can be displayed even if JavaScripts are disabled (even though there is a note that says enable JavaScripts, it is not required to simply view files), so it is acceptable. Another alternative is Sourcehut, which also doesn't need JavaScripts (and says that all features work without JavaScripts, although it still has some).</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-1bcd9d13-c195-49af-95f5-ee59a035d645" for="reactions--reaction_button_component-ffa32b" popover="manual" data-direction="n" data-type="description" data-view-component="true">Consolatis, evieluvsrainbows, terrarier2111, bdemirel, Mijyuoon, boomboompower, real-yfprojects, amytimed, bdougherty, techyCoder81, and 16 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvGRU" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvGRU/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="a935c1249808b2a1d2d0956f021d70cf59988fd96299e777f417421f89a254cd" id="issuecomment-1203528788">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I don't mind GitLab, except that I have to pause for 15 minutes to finish laughing every time i see "Merge Requests"</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-62b80856-9ecb-4e0e-98b6-78cf564c99bf" for="reactions--reaction_button_component-b7e712" popover="manual" data-direction="n" data-type="description" data-view-component="true">oatovar, nowaythisworks, Colerar, amytimed, lunaisnotaboy, bsedin, wheresalice, googleson78, ifarbod, leftshift, and 8 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-30f4dfa9-3d1d-412b-b0c4-576f15624564" for="reactions--reaction_button_component-3fe408" popover="manual" data-direction="n" data-type="description" data-view-component="true">real-yfprojects, afkvido, mytja, Rwarcards762, fuomag9, and renancaraujo reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-a7f882c9-29dd-42a1-8e1e-41ec74f82ea1" for="reactions--reaction_button_component-599a78" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvIwp" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvIwp/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/sammcj/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/sammcj"><img src="https://avatars.githubusercontent.com/u/862951?s=80&amp;u=cfd1c4a95ff2d92c1201a95c68b52dd353b8cc10&amp;v=4" width="40" height="40" alt="@sammcj"></a>

</p>


  
<div data-body-version="d7f77e883304ee58f38e8eb0ca258e6f5155ad828d64a2d36d9acf3f383ce8eb" id="issuecomment-1203538985">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-b4f8e713-c1c2-46e0-9e29-2335fb6cd824" for="reactions--reaction_button_component-68ab9a" popover="manual" data-direction="n" data-type="description" data-view-component="true">talgat-ruby, nothub, freearhey, talesaraujo, null2264, Rikj000, speller26, amytimed, theRealProHacker, guarilha, and 35 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-6da40911-94e2-4bf5-8dbc-50a7fd735ac3" for="reactions--reaction_button_component-891f58" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows and itpropro reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>



  

        <div id="pullrequestreview-2519558596" data-gid="PRR_kwDOBZWBkc6WLWnE" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTE5NTU4NTk2IiwidCI6MTc1NDQxMTQwNH0=--d65355594272c2033f588aa9c77698a61fdfbd1215431ab2c0f55ad49c24e83c" data-url="/github/site-policy/pull/582/partials/reviews/2519558596">
      <div data-view-component="true">
  <p><a href="https://github.com/bulosandaina05" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/bulosandaina05/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/192487906?s=60&amp;v=4" alt="bulosandaina05" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2519558596" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">1</p>
  </task-lists>
  
</div>
        </div>

        <div id="pullrequestreview-2527188942" data-gid="PRR_kwDOBZWBkc6WodfO" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTI3MTg4OTQyIiwidCI6MTc1NDQxMTQwNH0=--9128f11650a436a1c426933aacea5fb23e7cf0f04f3e10218738a9da11751224" data-url="/github/site-policy/pull/582/partials/reviews/2527188942">
      <div data-view-component="true">
  <p><a href="https://github.com/Jwhite6381" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Jwhite6381/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/188800562?s=60&amp;v=4" alt="Jwhite6381" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2527188942" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Johnny</p>
  </task-lists>
  
</div>
        </div>

        <div id="pullrequestreview-2562557654" data-gid="PRR_kwDOBZWBkc6YvYbW" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTYyNTU3NjU0IiwidCI6MTc1NDQxMTQwNH0=--e122c3063e4ec1da3617aee9b90660a22f6fe9f4acf9c6ef44258c9d761d087d" data-url="/github/site-policy/pull/582/partials/reviews/2562557654">
      <div data-view-component="true">
  <p><a href="https://github.com/Cryptopuy" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/157313185?s=60&amp;v=4" alt="Cryptopuy" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2562557654" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">635491</p>
  </task-lists>
  
</div>
        </div>

        <div data-gid="IC_kwDOBZWBkc6bIG4_" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bIG4_/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Cryptopuy"><img src="https://avatars.githubusercontent.com/u/157313185?s=80&amp;u=a831afd4c50dbfd5dca88d86bc4f8c9472f2cf67&amp;v=4" width="40" height="40" alt="@Cryptopuy"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bIHiE" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bIHiE/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Cryptopuy"><img src="https://avatars.githubusercontent.com/u/157313185?s=80&amp;u=a831afd4c50dbfd5dca88d86bc4f8c9472f2cf67&amp;v=4" width="40" height="40" alt="@Cryptopuy"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bd7cn" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd7cn/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bd77Z" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd77Z/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  
<div data-body-version="20b8551b2790cc4e124f16ca90b6fbcf6741d076b42c8a0248ca1bab9de8794f" id="issuecomment-2608316121">

        
<task-lists disabled="" sortable="">
<div>
          <ul dir="auto">
<li>[ ]</li>
</ul>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6bd8BE" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd8BE/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bqIJ7" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bqIJ7/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/SoeAung95/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SoeAung95"><img src="https://avatars.githubusercontent.com/u/158731633?s=80&amp;u=0d29c18b7762beb62a362c0583e4ef6326ddeb8f&amp;v=4" width="40" height="40" alt="@SoeAung95"></a>

</p>


  
<div data-body-version="e0bccf05ca8f173055686a399d89595bb10e4679332e237a88135c0ac78cc151" id="issuecomment-2611511931">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">git checkout main  # main branch<br>
git pull origin main  # latest changes update</p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6eg5Xj" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6eg5Xj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/OpgKwa/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/OpgKwa"><img src="https://avatars.githubusercontent.com/u/199000369?s=80&amp;v=4" width="40" height="40" alt="@OpgKwa"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6fwnqC" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6fwnqC/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Poeta1986/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Poeta1986"><img src="https://avatars.githubusercontent.com/u/120993535?s=80&amp;v=4" width="40" height="40" alt="@Poeta1986"></a>

</p>


  
<div data-body-version="8899189a9376967a9d151b266ebf6bddd1263f42d0617434eaca1cd421a7ffb5" id="issuecomment-2680322690">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers.  <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period.<br>
<a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a><br>
We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification:<br>
DNT and self-help browser extensions<br>
Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that:<br>
• Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies.<br>
• Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons.<br>
• Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT.<br>
• Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies.<br>
• Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies.<br>
• Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub).<br>
Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options.<br>
Enterprise user experience<br>
Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most.<br>
Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page.<br>
Stylistic change<br>
Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
</blockquote>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6gf7oi" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6gf7oi/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Elnandya396/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Elnandya396"><img src="https://avatars.githubusercontent.com/u/194666275?s=80&amp;v=4" width="40" height="40" alt="@Elnandya396"></a>

</p>


  
<div data-body-version="5b2aeb0f5afd83253c3ac15078d07a761ae25ce1f2b94b3dd035533eeb255656" id="issuecomment-2692725282">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers. <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period. <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a> We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification: DNT and self-help browser extensions Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that: • Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies. • Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons. • Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT. • Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies. • Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies. • Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub). Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options. Enterprise user experience Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most. Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page. Stylistic change Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
</blockquote>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6jsR35" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6jsR35/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jawid66/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jawid66"><img src="https://avatars.githubusercontent.com/u/204546664?s=80&amp;v=4" width="40" height="40" alt="@jawid66"></a>

</p>


  


</div>


        <div data-view-component="true" id="pullrequestreview-2738227083" data-gid="PRR_kwDOBZWBkc6jNgeL" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNzM4MjI3MDgzIiwidCI6MTc1NDQxMTQwNH0=--122c9a5a5d75a36800d241d7e173d7dac95418b7c7f4283fd1e1322fc34fe75a" data-url="/github/site-policy/pull/582/partials/reviews/2738227083">
  <p><a href="https://github.com/sheikhaftab005" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/sheikhaftab005/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/193155404?s=60&amp;v=4" alt="sheikhaftab005" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

        

        <div data-gid="IC_kwDOBZWBkc6lxxzT" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6lxxzT/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/venpisey/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/venpisey"><img src="https://avatars.githubusercontent.com/u/193808321?s=80&amp;v=4" width="40" height="40" alt="@venpisey"></a>

</p>


  


</div>


        <div id="pullrequestreview-2748846235" data-gid="PRR_kwDOBZWBkc6j2BCb" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNzQ4ODQ2MjM1IiwidCI6MTc1NDQxMTQwNH0=--5e213ef66a6b4f3099652cc923702635394430c063fc1e8756e38fe51a900fa5" data-url="/github/site-policy/pull/582/partials/reviews/2748846235">
      <div data-view-component="true">
  <p><a href="https://github.com/rizinator007" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/rizinator007/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/204532432?s=60&amp;v=4" alt="rizinator007" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2748846235" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Bentley</p>
  </task-lists>
  
</div>
        </div>

        <div data-gid="IC_kwDOBZWBkc6nhm2p" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6nhm2p/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/kizooj/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/kizooj"><img src="https://avatars.githubusercontent.com/u/192160475?s=80&amp;v=4" width="40" height="40" alt="@kizooj"></a>

</p>


  


</div>


        

        <div data-gid="IC_kwDOBZWBkc6rjyk-" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6rjyk-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ULTRAPAOTHAiLAND31110/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ULTRAPAOTHAiLAND31110"><img src="https://avatars.githubusercontent.com/u/203488967?s=80&amp;u=de668eb4d0bba0b0ea28cfd6718ef7f487f8ae66&amp;v=4" width="40" height="40" alt="@ULTRAPAOTHAiLAND31110"></a>

</p>


  


</div>


        

        <div data-gid="IC_kwDOBZWBkc6wwwKc" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6wwwKc/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/commanderrobot14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/commanderrobot14"><img src="https://avatars.githubusercontent.com/u/213124953?s=80&amp;v=4" width="40" height="40" alt="@commanderrobot14"></a>

</p>


  


</div>


        

        <div id="pullrequestreview-2977039092" data-gid="PRR_kwDOBZWBkc6xcgL0" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyOTc3MDM5MDkyIiwidCI6MTc1NDQxMTQwNH0=--0ed25141472de2d285170172cfe8865dfd303d2bedfa8a4ee3c77daf64527856" data-url="/github/site-policy/pull/582/partials/reviews/2977039092">
      <div data-view-component="true">
  <p><a href="https://github.com/mommommo19" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/mommommo19/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/154574240?s=60&amp;v=4" alt="mommommo19" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-1400955267" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div id="discussion_r2178585524" data-quote-markdown=".js-comment-body" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    
  </task-lists>
  

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

        

        <div id="pullrequestreview-2989683176" data-gid="PRR_kwDOBZWBkc6yMvHo" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyOTg5NjgzMTc2IiwidCI6MTc1NDQxMTQwNH0=--5f8269c569eab5a8f01b4fb3730a11f41dc4240dbb433a69b3e9bb745cf407d1" data-url="/github/site-policy/pull/582/partials/reviews/2989683176">
      <div data-view-component="true">
  <p><a href="https://github.com/Escarcega1989" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Escarcega1989/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/216053993?s=60&amp;v=4" alt="Escarcega1989" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-1406652583" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr data-position="0">
            <td data-line-number="..."></td>
            <td data-line-number="..."></td>
            <td colspan="2">@@ -33,13 +34,13 @@ To see our Privacy Notice to residents of California, please go to [GitHub's Not</td>
          </tr>
          <tr>

              <td data-line-number="33"></td>

              <td data-line-number="34"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="34"></td>

              <td data-line-number="35"></td>

            <td>
              <span><span>|</span> Section <span>|</span> What can you find there? <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="35"></td>

              <td data-line-number="36"></td>

            <td>
              <span><span>|</span>---<span>|</span>---<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="36"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your Personal Data in connection with the Website or Service. <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="37"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>What information GitHub collects<span>]</span><span>(</span><span>#what-information-github-collects</span><span>)</span> <span>|</span> GitHub collects information directly from you for your registration, payment, transactions, and user profile. We also automatically collect from you your usage information, cookies, and device information, subject, where necessary, to your consent. GitHub may also collect Personal Data from third parties. We only collect the minimum amount of Personal Data necessary from you, unless you choose to provide more.<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td></td>

              <td data-line-number="37"></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your personal data in connection with the Website or Service if you are in North America. For individuals outside North America the data controller is GitHub B.V. <span>|</span></span>

            </td>
          </tr>
    </tbody></table>

</div>


<div id="discussion_r2187007903" data-quote-markdown=".js-comment-body">
            <details data-body-version="95b1e6e4340d1d6aa818fc10e2f95a7bdc362c0269ac541bbffb2e8d6c875ea3">
    <summary>
      <div>
        <h3>
              This comment was marked as outdated.

        </h3>
          
      </div>
    </summary>

    
  </details>


</div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

        <div data-gid="IC_kwDOBZWBkc66Q-WW" data-url="/github/site-policy/comments/IC_kwDOBZWBkc66Q-WW/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/flcon12/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/flcon12"><img src="https://avatars.githubusercontent.com/u/223188888?s=80&amp;v=4" width="40" height="40" alt="@flcon12"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc67e414" data-url="/github/site-policy/comments/IC_kwDOBZWBkc67e414/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LuckyD14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LuckyD14"><img src="https://avatars.githubusercontent.com/u/174380515?s=80&amp;v=4" width="40" height="40" alt="@LuckyD14"></a>

</p>


  
<div data-body-version="4d43e786f4b74b8c8987ce030d5dc22bb3ab485242d825682ca2553ac0e25a58" id="issuecomment-3145436536">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/174380515/473573366-56a6da97-c49c-4ac6-a8b0-dcbb6daa01c9.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ0MTE3MDMsIm5iZiI6MTc1NDQxMTQwMywicGF0aCI6Ii8xNzQzODA1MTUvNDczNTczMzY2LTU2YTZkYTk3LWM0OWMtNGFjNi1hOGIwLWRjYmI2ZGFhMDFjOS5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwNVQxNjMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yNDMwZjUyZWVhNTFlMzA4MWExNzA0NDYwNDM0ZDcxOWE1NjkxMTUzNGFlMTMyNTc0MjA2OWFiYmRjY2RkMGRlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ONoSbTHupW89f6PanB8L8utrQPt6NZcrUMGDr49xGKs"><img src="https://private-user-images.githubusercontent.com/174380515/473573366-56a6da97-c49c-4ac6-a8b0-dcbb6daa01c9.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ0MTE3MDMsIm5iZiI6MTc1NDQxMTQwMywicGF0aCI6Ii8xNzQzODA1MTUvNDczNTczMzY2LTU2YTZkYTk3LWM0OWMtNGFjNi1hOGIwLWRjYmI2ZGFhMDFjOS5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwNVQxNjMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yNDMwZjUyZWVhNTFlMzA4MWExNzA0NDYwNDM0ZDcxOWE1NjkxMTUzNGFlMTMyNTc0MjA2OWFiYmRjY2RkMGRlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ONoSbTHupW89f6PanB8L8utrQPt6NZcrUMGDr49xGKs" alt="OKX_1754011583554"></a></p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc67hezP" data-url="/github/site-policy/comments/IC_kwDOBZWBkc67hezP/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LuckyD14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LuckyD14"><img src="https://avatars.githubusercontent.com/u/174380515?s=80&amp;v=4" width="40" height="40" alt="@LuckyD14"></a>

</p>


  


</div>




  <!-- Rendered timeline since 2025-08-01 18:55:09 -->
  



      

    </div>

    
  </div>

</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EPA Moves to Cancel $7B in Grants for Solar Energy (109 pts)]]></title>
            <link>https://www.nytimes.com/2025/08/05/climate/epa-cancels-solar-energy-grants.html</link>
            <guid>44799290</guid>
            <pubDate>Tue, 05 Aug 2025 15:29:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/08/05/climate/epa-cancels-solar-energy-grants.html">https://www.nytimes.com/2025/08/05/climate/epa-cancels-solar-energy-grants.html</a>, See on <a href="https://news.ycombinator.com/item?id=44799290">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/08/05/climate/epa-cancels-solar-energy-grants.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[US Coast Guard Report on Titan Submersible (166 pts)]]></title>
            <link>https://www.news.uscg.mil/Press-Releases/Article/4265651/coast-guard-marine-board-of-investigation-releases-report-on-titan-submersible/</link>
            <guid>44798705</guid>
            <pubDate>Tue, 05 Aug 2025 14:47:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.news.uscg.mil/Press-Releases/Article/4265651/coast-guard-marine-board-of-investigation-releases-report-on-titan-submersible/">https://www.news.uscg.mil/Press-Releases/Article/4265651/coast-guard-marine-board-of-investigation-releases-report-on-titan-submersible/</a>, See on <a href="https://news.ycombinator.com/item?id=44798705">Hacker News</a></p>
Couldn't get https://www.news.uscg.mil/Press-Releases/Article/4265651/coast-guard-marine-board-of-investigation-releases-report-on-titan-submersible/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Los Alamos is capturing real-time images of explosions at 7mths of a second (110 pts)]]></title>
            <link>https://www.lanl.gov/media/publications/1663/dynamics-of-dynamic-imaging</link>
            <guid>44798695</guid>
            <pubDate>Tue, 05 Aug 2025 14:47:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lanl.gov/media/publications/1663/dynamics-of-dynamic-imaging">https://www.lanl.gov/media/publications/1663/dynamics-of-dynamic-imaging</a>, See on <a href="https://news.ycombinator.com/item?id=44798695">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Ozempic Shows Anti-Aging Effects in Trial, Reversing Biological Age by 3.1 Years (163 pts)]]></title>
            <link>https://trial.medpath.com/news/5c43f09ebb6d0f8e/ozempic-shows-anti-aging-effects-in-first-clinical-trial-reversing-biological-age-by-3-1-years</link>
            <guid>44798410</guid>
            <pubDate>Tue, 05 Aug 2025 14:28:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trial.medpath.com/news/5c43f09ebb6d0f8e/ozempic-shows-anti-aging-effects-in-first-clinical-trial-reversing-biological-age-by-3-1-years">https://trial.medpath.com/news/5c43f09ebb6d0f8e/ozempic-shows-anti-aging-effects-in-first-clinical-trial-reversing-biological-age-by-3-1-years</a>, See on <a href="https://news.ycombinator.com/item?id=44798410">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="detailed-analysis"><div><p><span>The diabetes drug Ozempic has demonstrated remarkable anti-aging effects in the first clinical trial to directly measure its impact on biological aging, with participants becoming an average of 3.1 years biologically younger after 32 weeks of treatment. The findings provide the strongest evidence yet that GLP-1 drugs like semaglutide may offer benefits far beyond their established roles in diabetes management and weight loss.</span></p>
<h2>First Direct Clinical Evidence of Anti-Aging Effects</h2>
<p><span>Varun Dwaraka from diagnostics company TruDiagnostic in Lexington, Kentucky, led a randomized controlled trial involving 108 people with HIV-associated lipohypertrophy, a condition characterized by excess fat accumulation and accelerated cellular aging. Half the participants received weekly Ozempic injections for 32 weeks, while the other half received a placebo.</span></p>
<p><span>The researchers used epigenetic clocks to assess biological aging - sophisticated tools that identify patterns of DNA methylation, chemical tags that affect gene activity and shift predictably with age. These patterns can be accelerated or slowed by lifestyle factors, meaning biological age can differ significantly from chronological age.</span></p>
<p><span>"Those on semaglutide became, on average, 3.1 years biologically younger by the end of the study," Dwaraka reported. The placebo group showed no significant change in biological age over the same period.</span></p>
<h2>Organ-Specific Anti-Aging Benefits</h2>
<p><span>The anti-aging effects weren't uniform across all body systems. The research team found that semaglutide slowed biological aging in several organs and systems, with the most dramatic improvements occurring in the inflammatory system and brain, where the drug appeared to delay biological aging by almost 5 years. Significant benefits were also observed in the heart and kidneys.</span></p>
<p><span>"Semaglutide may not only slow the rate of ageing, but in some individuals partially reverse it," Dwaraka noted, highlighting the potential for the drug to actually turn back the biological clock rather than simply slowing its progression.</span></p>
<h2>Mechanisms Behind the Anti-Aging Effects</h2>
<p><span>The researchers believe semaglutide's anti-aging properties stem from its effects on fat distribution and metabolic health. Excess fat around organs triggers the release of pro-aging molecules that alter DNA methylation in key aging-related genes. By reducing this harmful fat accumulation and preventing low-grade inflammation - both major drivers of epigenetic aging - semaglutide appears to create a more youthful biological environment.</span></p>
<p><span>Randy Seeley from the University of Michigan Medical School expressed little surprise at the findings, explaining that the drugs "reduce the metabolic burden on a wide range of cells and lower inflammation. Both are major drivers of ageing in many different types of cells." However, he believes much of the benefit stems not from semaglutide's direct cellular effects, but from broader improvements to overall health.</span></p>
<h2>Broader Implications and Future Directions</h2>
<p><span>While the study focused specifically on people with HIV-associated lipohypertrophy, the biological pathways affected by semaglutide aren't unique to this condition. "Therefore, it is plausible that similar effects on epigenetic ageing could be observed in other populations," Dwaraka explained, suggesting the anti-aging benefits could extend to the general population.</span></p>
<p><span>Despite the promising results, Dwaraka cautioned against rushing to prescribe semaglutide broadly as an anti-aging therapy. "Prescribing it more broadly as an anti-ageing therapy is premature," he stated. However, he noted that the study adds momentum to ongoing efforts to repurpose existing drugs for age-related problems, which could speed approval processes and reduce the risk of unexpected side effects.</span></p>
<p><span>The research represents a significant milestone in understanding the full therapeutic potential of GLP-1 drugs, which have already gained prominence for treating type 2 diabetes and obesity, and are being explored for cardiovascular disease, addiction, and dementia. "Semaglutide may well emerge as one of the most promising candidates in this space," Dwaraka concluded.</span></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Enough is enough–I dumped Google's worsening search for Kagi (281 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/</link>
            <guid>44798215</guid>
            <pubDate>Tue, 05 Aug 2025 14:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/">https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/</a>, See on <a href="https://news.ycombinator.com/item?id=44798215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2104999">
  
  <header>
  <div>
    

    <h2>
      Enough is enough—I dumped Google’s worsening search for Kagi
    </h2>

    <p>
      I like how the search engine is the product instead of <em>me</em>.
    </p>

    

    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1441" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-2048x1153.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-980x552.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1440x811.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg" target="_blank">
              <img width="2560" height="1441" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg" alt="Artist's depiction of the article author heaving a large multicolored &quot;G&quot; into the fires of Mount Doom" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-2048x1153.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-980x552.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1440x811.jpg 1440w" sizes="(max-width: 2560px) 100vw, 2560px">
            </a></p><div id="caption-2108066">
    
    <p>
      "Won't be needing this anymore!"

              <span>
          Credit:

          
          Aurich "The King" Lawson

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p>
      "Won't be needing this anymore!"

              <span>
          Credit:

          
          Aurich "The King" Lawson

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Mandatory AI summaries have come to Google, and they <a href="https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/">gleefully showcase hallucinations while confidently insisting on their truth</a>. I feel about them the same way I felt about mandatory G+ logins when all I wanted to do was access my damn YouTube account: I hate them. Intensely.</p>
<p>But <em>unlike</em> those mandatory G+ logins—on which Google <a href="https://arstechnica.com/gadgets/2015/07/google-officially-ends-forced-google-integration-first-up-youtube/">eventually relented</a> before <a href="https://arstechnica.com/gadgets/2019/01/google-shuts-down-april-2-all-data-will-be-deleted/">shutting down the G+ service</a>—our reading of the tea leaves suggests that, this time, the search giant <em>is extremely pleased</em> with how things are going.</p>
<p>Fabricated AI dreck polluting your search? It's the new normal. Miss your little results page with its 10 little blue links? Too bad. They're gone now, and you can't get them back, no matter what <a href="https://gizmodo.com/add-fcking-to-your-google-searches-to-neutralize-ai-summaries-2000557710">ephemeral workarounds</a> or <a href="https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/?comments=1&amp;post=43861979">temporarily functional flags</a> or <a href="https://udm14.com/">undocumented, could-fail-at-any-time URL tricks</a> you use.</p>
<p>And the galling thing is that Google expects you to be a good consumer and just <em>take it</em>. The subtext of the company's (probably AI-generated) robo-MBA-speak non-responses to <a href="https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/">criticism</a> and <a href="https://arstechnica.com/tech-policy/2025/02/education-tech-firm-sues-google-over-ai-search-summaries/">complaining</a> is clear: "LOL, what are you going to do, use a different search engine? Now, <a href="https://arstechnica.com/google/2025/05/the-gmail-app-will-now-create-ai-summaries-whether-you-want-them-or-not/">shut up and have some more AI</a>!"</p>
<p>But like <a href="https://www.youtube.com/watch?v=h97kbv4mbsc">the old sailor used to say</a>: "That's all I can stands, and I can't stands no more." So I <em>did</em> start using a different search engine—one that doesn't constantly shower me with half-baked, anti-consumer AI offerings.</p>
<p>Out with Google, in with <a href="https://kagi.com/">Kagi</a>.</p>
<h2>What the hell is a Kagi?</h2>
<p>Kagi was founded in 2018, but its search product has only been publicly available since <a href="https://blog.kagi.com/kagi-orion-public-beta">June 2022</a>. It purports to be an <a href="https://help.kagi.com/kagi/company/">independent search engine</a> that pulls results from around the web (<a href="https://help.kagi.com/kagi/search-details/search-sources.html">including from its own index</a>) and is aimed at returning search to a user-friendly, user-focused experience. The company's stated purpose is to deliver useful search results, full stop. The goal is <em>not</em> to blast you with AI garbage or bury you in "Knowledge Graph" summaries hacked together from posts in a 12-year-old Reddit thread between two guys named /u/WeedBoner420 and /u/14HitlerWasRight88.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>Kagi's offerings (it has <a href="https://kagi.com/orion/">a web browser, too</a>, though I've not used it) are based on a simple idea. There's an (oversimplified) axiom that if a good or service (like Google search, for example, or good ol' Facebook) is free for you to use, it's because you're the product, not the customer. With Google, you pay with your attention, your behavioral metrics, and the intimate personal details of your wants and hopes and dreams (and the contents of your emails and other electronic communications—Google's got most of that, too).</p>
<p>With Kagi, you pay for the product using <em>money</em>. That's it! You give them some money, and you get some service—great service, really, which I'm overall quite happy with and which I'll get to shortly. You don't have to look at any ads. You don't have to look at AI droppings. You don't have to give perpetual ownership of your mind-palace to a pile of optioned-out tech bros in sleeveless Patagonia vests while you are endlessly subjected to amateur AI Rorschach tests every time you search for "pierogis near me."</p>

<h2>How much money are we talking?</h2>
<p>I dunno, about <a href="https://kagi.com/pricing">a hundred bucks a year</a>? That's what I'm spending as an individual for unlimited searches. I'm using Kagi's "Professional" plan, but there are others, including a free offering so that you can poke around and see if the service is worth your time.</p>
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1611" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-640x403.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-768x483.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1536x967.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-2048x1289.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-980x617.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1440x906.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing.png" target="_blank">
              <img width="1024" height="644" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png" alt="image of kagi billing panel" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-640x403.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-768x483.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1536x967.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-2048x1289.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-980x617.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1440x906.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107941"><p>
              This is my account's billing page, showing what I've paid for Kagi in the past year. (By the time this article runs, I'll have renewed my subscription!)
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      This is my account's billing page, showing what I've paid for Kagi in the past year. (By the time this article runs, I'll have renewed my subscription!)

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>I'd previously bounced off two trial runs with Kagi in 2023 and 2024 because the idea of <em>paying for search</em> just felt so alien. But that was before Google's AI enshittification rolled out in full force. Now, sitting in the middle of 2025 with the world burning down around me, a hundred bucks to kick Google to the curb <em>and</em> get better search results feels totally worth it. Your mileage may vary, of course.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          


<p>The other thing that made me nervous about paying for search was the idea that my money was going to enrich some scumbag VC fund, but fortunately, there's good news on that front. According to <a href="https://help.kagi.com/kagi/company/">the company's "About" page</a>, Kagi has not taken any money from venture capitalist firms. Instead, it has been funded by a combination of self-investment by the founder, selling equity to some Kagi users in two rounds, and subscription revenue:</p>
<blockquote><p>Kagi was bootstrapped from 2018 to 2023 with ~$3M initial funding from the founder. In 2023, <a href="https://blog.kagi.com/safe-round">Kagi raised $670K</a> from Kagi users in its first external fundraise, followed by <a href="https://blog.kagi.com/what-is-next-for-kagi#3">$1.88M raised in 2024</a>, again from our users, bringing the number of users-investors to 93... In early 2024, Kagi became a <a href="https://blog.kagi.com/what-is-next-for-kagi#4">Public Benefit Corporation (PBC)</a>.</p></blockquote>
<h2>What about DuckDuckGo? Or Bing? Or Brave?</h2>
<p>Sure, those can be perfectly cromulent alternatives to Google, but honestly, I don't think they go far enough. DuckDuckGo is fine, but it largely utilizes <a href="https://duckduckgo.com/duckduckgo-help-pages/results/sources">Bing's index</a>; and while DuckDuckGo exercises considerable control over its search results, the company is tied to the vicissitudes of Microsoft by that index. It's a bit like sitting in a boat tied to a submarine. Sure, everything's fine now, but at some point, that sub will do what subs do—and your boat is gonna follow it down.</p>
<p>And as for Bing itself, perhaps I'm nitpicky [Ed. note: He is!], but using Bing feels like interacting with 2000-era MSN's slightly perkier grandkid. It's younger and fresher, yes, but it still radiates that same old stanky feeling of <a href="https://www.youtube.com/watch?v=EUXnJraKM3k">taste-free, designed-by-committee artlessness</a>. I'd rather just use Google—which is saying something. At least Google's search home page remains uncluttered.</p>
<p><a href="https://search.brave.com/">Brave Search</a> is another fascinating option I haven't spent a tremendous amount of time with, largely because Brave's <a href="https://brave.com/wallet/">cryptocurrency ties</a> still feel <a href="https://brave.com/brave-rewards/">incredibly low-rent and skeevy</a>. I'm slowly warming up to the Brave Browser as a replacement for Chrome (see the screenshots in this article!), but I'm just not comfortable with Brave yet—and likely won't be unless the company divorces itself from cryptocurrencies entirely.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<h2>More anonymity, if you want it</h2>
<p>The feature that convinced me to start paying for Kagi was its <a href="https://help.kagi.com/kagi/privacy/privacy-pass.html">Privacy Pass</a> option. Based on a clean-sheet Rust implementation of the Privacy Pass standard (IETF RFCs <a href="https://www.rfc-editor.org/rfc/rfc9576.html">9576</a>, <a href="https://www.rfc-editor.org/rfc/rfc9577.html">9577</a>, and <a href="https://www.rfc-editor.org/rfc/rfc9578.html">9578</a>) by <a href="https://github.com/raphaelrobert/privacypass">Raphael Robert</a>, this is a technology that uses cryptographic token-based auth to send an "I'm a paying user, please give me results" signal to Kagi, without Kagi knowing which user made the request. (There's a much longer <a href="https://blog.kagi.com/kagi-privacy-pass">Kagi blog post</a> with actual technical details for the curious.)</p>
<p>To search using the tool, you install the Privacy Pass extension (linked in the docs above) in your browser, log in to Kagi, and enable the extension. This causes the plugin to request a bundle of tokens from the search service. After that, you can log out and/or use private windows, and those tokens are utilized whenever you do a Kagi search.</p>
<figure>
    <div>
            <p><a data-pswp-width="2730" data-pswp-height="1978" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi.png 2730w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-640x464.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-768x556.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1536x1113.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-2048x1484.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-980x710.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1440x1043.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi.png" target="_blank">
              <img width="1024" height="742" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png" alt="image of a kagi search with privacy pass enabled" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-640x464.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-768x556.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1536x1113.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-2048x1484.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-980x710.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1440x1043.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107908"><p>
              Privacy pass is enabled, allowing me to explore the delicious mystery of pierogis with some semblance of privacy.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Privacy pass is enabled, allowing me to explore the delicious mystery of pierogis with some semblance of privacy.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>The obvious flaw here is that Kagi still records source IP addresses along with Privacy Pass searches, potentially de-anonymizing them, but there's a path around that: Privacy Pass functions with <a href="https://help.kagi.com/kagi/privacy/tor.html">Tor</a>, and Kagi maintains <a href="http://kagi2pv5bdcxxqla5itjzje2cgdccuwept5ub6patvmvn3qgmgjd6vid.onion/">a Tor onion address</a> for searches.</p>
<p>So why do I keep using Privacy Pass without Tor, in spite of the opsec flaw? Maybe it's the placebo effect in action, but I feel better about putting at least a tiny bit of friction in the way of someone with root attempting to casually browse my search history. Like, I want there to be at least a SQL <code>JOIN</code> or two between my IP address and my searches for "<a href="https://arstechnica.com/gaming/2017/03/the-correct-alien-sex-choices-in-the-mass-effect-trilogy/">best <em>Mass Effect</em> alien sex choices</a>" or "<a href="https://arstechnica.com/gaming/2014/04/hands-on-with-biowares-garrus-vakarian-body-pillow-very-very-hands-on/">cleaning tips for Garrus body pillow</a>." I mean, you know, assuming I were ever to search for such things.</p>
<h2>What’s it like to use?</h2>
<p>Moving on with embarrassed rapidity, let's look at Kagi a bit and see how using it feels.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          


<p>My anecdotal observation is that Kagi doesn't favor Reddit-based results nearly as much as Google does, but sometimes it still has them near or at the top. And here is where Kagi curb-stomps Google with quality-of-life features: Kagi lets you prioritize or de-prioritize a website's prominence in your search results. You can even pin that site to the top of the screen or block it completely.</p>
<p>This is a feature I've wanted Google to get for about <em>25 damn years</em> but that the company has consistently refused to properly implement (likely because allowing users to exclude sites from search results notionally reduces <a href="https://en.wikipedia.org/wiki/Engagement_marketing">engagement</a> and therefore reduces the potential revenue that Google can extract from search). Well, screw you, Google, because Kagi lets me prioritize or exclude sites from my results, and it works <em>great</em>—I'm extraordinarily pleased to never again have to worry about Quora or Pinterest links showing up in my search results.</p>
<p>Further, Kagi lets me adjust these settings both for the current set of search results (if you don't want Reddit results for <em>this</em> search but you don't want to drop Reddit altogether) and also globally (for all future searches):</p>


<figure>
    <div>
            <p><a data-pswp-width="2706" data-pswp-height="1423" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized.png 2706w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-640x337.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-768x404.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1536x808.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-2048x1077.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-980x515.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1440x757.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized.png" target="_blank">
              <img width="1024" height="538" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png" alt="image of kagi search personalization options" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-640x337.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-768x404.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1536x808.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-2048x1077.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-980x515.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1440x757.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107938"><p>
              Goodbye forever, useless crap sites.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Goodbye forever, useless crap sites.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>Another tremendous quality-of-life improvement comes via Kagi's image search, which does a bunch of stuff that Google should and/or used to do—like giving you direct right-click access to save images without having to fight the search engine with workarounds, plugins, or <a href="https://www.tampermonkey.net/">Tampermonkey</a>-esque userscripts.</p>



<p>The Kagi experience is also vastly more customizable than Google's (or at least, how Google's has become). The widgets that appear in your results can be turned off, and the "lenses" through which Kagi sees the web can be adjusted to influence what kinds of things do and do not appear in your results.</p>


<p>If that doesn't do it for you, how about the ability to <a href="https://help.kagi.com/kagi/features/custom-css.html">inject custom CSS</a> into your search and landing pages? Or to <a href="https://help.kagi.com/kagi/features/redirects.html">automatically rewrite search result URLs</a> to taste, doing things like redirecting <code>reddit.com</code> to <code>old.reddit.com</code>? Or breaking free of AMP pages and always viewing originals instead?</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="2118" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-640x530.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-768x635.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1536x1271.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-2048x1694.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-980x811.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1440x1191.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css.png" target="_blank">
              <img width="1024" height="847" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png" alt="Image of kagi custom css field" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-640x530.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-768x635.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1536x1271.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-2048x1694.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-980x811.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1440x1191.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107900"><p>
              Imagine all the things Ars readers will put here.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Imagine all the things Ars readers will put here.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<h2>Is that all there is?</h2>
<p>Those are really all the features <em>I</em> care about, but there are loads of other Kagi bits to discover—like a Kagi Maps tool (it's pretty good, though I'm not ready to take it up full time yet) and a Kagi video search tool. There are also tons of classic old-Google-style inline search customizations, including <a href="https://help.kagi.com/kagi/features/verbatim.html">verbatim mode</a>, where instead of trying to infer context about your search terms, Kagi searches for <em>exactly</em> what you put in the box. You can also add custom search operators that do whatever you program them to do, and you get API-based access for doing programmatic things with search.</p>
<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>A quick run-through of a few additional options pages. This is the general customization page.</span>
                    <span>
                      Lee Hutchinson
                  </span>
          </p>
  </div>

<p>I haven't spent any time with <a href="https://kagi.com/orion/">Kagi's Orion browser</a>, but it's there as an option for folks who want a WebKit-based browser with baked-in support for Privacy Pass and other Kagi functionality. For now, Firefox continues to serve me well, with Brave as a fallback for working with Google Docs and other tools I can't avoid and that treat non-Chromium browsers like second-class citizens. However, Orion is probably on the horizon for me if things in Mozilla-land <a href="https://arstechnica.com/tech-policy/2025/02/firefox-deletes-promise-to-never-sell-personal-data-asks-users-not-to-panic/">continue to sour</a>.</p>

<h2>Cool, but is it any good?</h2>
<p>Rather than fill space with a ton of comparative screenshots between Kagi and Google or Kagi and Bing, I want to talk about my subjective experience using the product. (You can do all the comparison searches you want—<a href="https://kagi.com/">just go and start searching</a>—and your comparisons will be a lot more relevant to your personal use cases than any examples I can dream up!)</p>
<p>My time with Kagi so far has included about seven months of casual opportunistic use, where I'd occasionally throw a query at it to see how it did, and about five months of committed daily use. In the five months of daily usage, I can count on one hand the times I've done a supplementary Google search because Kagi didn't have what I was looking for on the first page of results. I've done searches for all the kinds of things I usually look for in a given day—article fact-checking queries, searches for details about the parts of speech, hunts for duck facts (we have some feral Muscovy ducks nesting in our front yard), obscure technical details about Project Apollo, who the hell played Dupont in <em>Equilibrium</em> (Angus Macfadyen, who also played Robert the Bruce in <em>Braveheart</em>), and many, many other queries.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="3686" data-pswp-height="1822" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history.png 3686w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-640x316.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1536x759.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-2048x1012.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-980x484.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1440x712.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history.png" target="_blank">
              <img width="1024" height="506" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png" alt="Image of Firefox history window showing kagi searches for july 22" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-640x316.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1536x759.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-2048x1012.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-980x484.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1440x712.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2108307"><p>
              A typical afternoon of Kagi searches, from my Firefox history window.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      A typical afternoon of Kagi searches, from my Firefox history window.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>For all of these things, Kagi has responded quickly and correctly. The time to service a query feels more or less like Google's service times; according to the timer at the top of the page, my Kagi searches complete in between 0.2 and 0.8 seconds. Kagi handles misspellings in search terms with the grace expected of a modern search engine and has had no problem figuring out my typos.</p>
<p>Holistically, taking search customizations into account on top of the actual search performance, my subjective assessment is that Kagi gets me accurate, high-quality results on more or less any given query, and it does so without festooning the results pages with features I find detractive and irrelevant.</p>
<p>I know that's not a data-driven assessment, and it doesn't fall back on charts or graphs or figures, but it's how I feel after using the product every single day for most of 2025 so far. For me, Kagi's search performance is firmly in the "good enough" category, and that's what I need.</p>
<h2>Kagi and AI</h2>
<p>Unfortunately, the thing that's stopping me from being completely effusive in my praise is that Kagi is exhibiting a disappointing amount of "keeping-up-with-the-Joneses" by rolling out a big 'ol pile of (optional, so far) AI-enabled search features.</p>
<p>A <a href="https://blog.kagi.com/kagi-ai-search">blog post from founder Vladimir Prelovac</a> talks about the company's use of AI, and it says all the right things, but at this point, I trust written statements from tech company founders about as far as I can throw their corporate office buildings. (And, dear reader, that ain't very far).</p>
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1461" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-640x365.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-768x438.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1536x877.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-2048x1169.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-980x559.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1440x822.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai.png" target="_blank">
              <img width="1024" height="584" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png" alt="image of kagi ai features" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-640x365.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-768x438.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1536x877.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-2048x1169.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-980x559.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1440x822.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107939"><p>
              No thanks. But I would like to exclude AI images from my search results, please.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      No thanks. But I would like to exclude AI images from my search results, please.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>The short version is that, like Google, Kagi has some AI features: There's an AI search results summarizer, an AI page summarizer, and an "ask questions about your results" chatbot-style function where you can interactively interrogate an LLM about your search topic and results. So far, all of these things can be disabled or ignored. I don't know how good any of the features are because I have disabled or ignored them.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>If the existence of AI in a product is a bright red line you won't cross, you'll have to turn back now and find another search engine alternative that doesn't use AI and also doesn't suck. When/if you do, let me know, because the pickings are slim.</p>
<h2>Is Kagi for you?</h2>
<p>Kagi <em>might</em> be for you—especially if you've recently typed a simple question into Google and gotten back a pile of fabricated gibberish in place of those 10 blue links that used to serve so well. Are you annoyed that Google's search sucks vastly more now than it did 10 years ago? Are you unhappy with how difficult it is to get Google search to do what you want? Are you fed up? Are you <em>pissed off</em>?</p>
<p>If your answer to those questions is the same full-throated "Hell yes, I am!" that mine was, then perhaps it's time to try an alternative. And Kagi's a pretty decent one—if you're not averse to paying for it.</p>
<p>It's a fantastic feeling to type in a search query and once again get useful, relevant, non-AI results (that I can customize!). It's a bit of sanity returning to my Internet experience, and I'm grateful. Until Kagi is bought by a value-destroying vampire VC fund or implodes into its own AI-driven enshittification cycle, I'll probably keep paying for it.</p>
<p>After that, who knows? Maybe I'll throw away my computers and live in a cave. At least until the cave's robot exclusion protocol fails and <a href="https://www.ftrain.com/robot_exclusion_protocol">the Googlebot comes for me</a>.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/lee-hutchinson/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/l.hutchinson-1394.jpg" alt="Photo of Lee Hutchinson"></a></p>
  </div>

  <div>
    

    <p>
      Lee is the Senior Technology Editor, and oversees story development for the gadget, culture, IT, and video sections of Ars Technica. A long-time member of the Ars OpenForum with an extensive background in enterprise storage and security, he lives in Houston.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/#comments" title="184 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    184 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2025/08/is-the-dream-chaser-space-plane-ever-going-to-launch-into-orbit/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/Dream-Chaser-Full-Profile-Landscape-2-768x432.jpg" alt="Listing image for first story in Most Read: Is the Dream Chaser space plane ever going to launch into orbit?" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is not Making Engineers 10x as Productive (682 pts)]]></title>
            <link>https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/</link>
            <guid>44798189</guid>
            <pubDate>Tue, 05 Aug 2025 14:10:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/">https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/</a>, See on <a href="https://news.ycombinator.com/item?id=44798189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
			<heading-anchors>
				



<p>Curing Your AI 10x Engineer Imposter Syndrome</p>

<ul>
	<li><time datetime="2025-08-05">05 August 2025</time></li>
	<li><a href="https://colton.dev/tags/ai/">AI</a></li>
</ul>

<p>A few months ago I went through a bit of a mental slump. I've always been confident of my abilities as an engineer, but I couldn't help but feel like my skills were falling hopelessly behind as I scrolled places like LinkedIn and Twitter. If these sources were to be believed, engineering had moved on from the medieval practice of typing code into an editor. <em>Real</em> engineers were now 10-100x more productive than I was. I'm writing this hoping to help others who are feeling similar anxieties.</p>
<p>I'm a skeptical person so I don't usually fall over myself immediately when I hear a claim like that. I usually roll my eyes in the same way I do when someone tells me a simple herbal remedy cures all disease. But the sheer volume these 10x engineer claims are reaching right now started to hit a nerve. What if I'm <em>wrong</em>? Will I miss the bus and become unemployable if I don't learn to use AI right now? After all, there are a lot of fancy words going around that distance the "AI" these people are talking about with the "AI" I was familiar with.</p>
<p>These people were using <em>✨agentic✨</em> AI. They were using <em>✨thinking✨</em> models that surfed the internet, ran tests, and corrected their own mistakes. Sure I popped into a chat window here and there and asked it to write some code, then promptly discarded most of the output once I got the idea that I needed. But these engineers were letting Claude fully take the wheel and had agents ripping 5 PRs for them while they made morning coffee. Was I becoming a dinosaur, an old man yelling at cloud?</p>
<p>Part of what made me feel so anxious was that it was entirely possible AI changed without me knowing it because I didn't use AI very much. Because I didn't <em>like</em> using AI that much. Reviewing code is vastly less enjoyable process than writing it. Had my stubborn desire to <em>enjoy coding</em> set me up to be left behind?</p>
<h2 id="diving-in">Diving In</h2>
<p>Eventually I hit a breaking point and decided I simply had to dive in head first to AI coding. I tried Claude Code, Cursor, Roo Code, and Zed for their agentic coding promises. I started asking AI to write all sorts of code in all sorts of projects. I tried the different models and compared them. I even vibe coded a few things, not editing the code manually once.</p>
<p>And it was... Fine. Despite claims that AI today is improving at a fever pitch, it felt largely the same as before. It's good at writing boilerplate, especially in Javascript, and particularly in React. It's not good at keeping up with the standards and utilities of your codebase. It tends to struggle with languages like Terraform. It still hallucinates libraries leading to significant <a href="https://en.wikipedia.org/wiki/Slopsquatting">security vulnerabilities</a>.</p>
<p>AIs still struggle to absorb the context of a larger codebase, even with a great prompt and <code>CLAUDE.md</code> file. If you use a library that isn't StackOverflow's favorite it will butcher it even after an agentic lookup of the documentation. Agents occasionally do something neat like fix the tests they broke. Often they just waste time and tokens, going back and forth with themselves not seeming to gain any deeper knowledge each time they fail. Thus, AI's best use case for me remains writing one-off scripts. Especially when I have no interest in learning deeper fundamentals for a single script, like when writing a custom ESLint rule.</p>
<p>Dark warnings that if I didn't start using AI now I'd be hopelessly behind proved unfounded. Using AI to code is not hard to learn. Obviously? Well, the AI coding community seems split on whether AI makes coding so easy a caveman can do it and that it requires an advanced, dedicated prompt engineer skillset. There are a few things you need to learn but they come quickly. You learn how to split up tasks into smaller pieces so the AI doesn't lose its mind late in the context window. Tools like Claude Code can do a bit of this themselves, even, though not always reliably. And you learn to identify when the AI is too far off and it's time to take the wheel.</p>
<p>A competent engineer will figure this stuff out in less than a week of moderate AI usage. Further, if AI is about to get 2x, 10x, or 100x better at any minute (as everyone keeps saying it will), then any lessons about how to use it now are moot for the future.</p>
<p>Every time I encountered AI working "just okay", it strangely made me more anxious, not less. It meant I couldn't find the spicy secret sauce that made everyone else so productive. I just didn't have what it takes: dinosaur, meet asteroid, thy name is AI. Eventually, a few things shook me out of this slump. One of those was <a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/">this article</a> from Ludicity, directly countering the claims of the AI pumpers. I write this article to share more things that helped me get out of the AI 10x engineer imposter syndrome.</p>
<h2 id="the-math">The Math</h2>
<p>Let's start by looking at the simple math of 10-100x productivity. 10x productivity means ten times the outcomes, not ten times the lines of code. This means what you used to ship in a quarter you now ship in a week and a half. These numbers should make even the truest AI believer pause. The amount of product ideation, story point negotiation, bugfixing, code review, waiting for deployments, testing, and QA in that go into what was traditionally 3 months of work is now getting done in 7 work days? For that to happen each and every one of these bottlenecks has to also seen have 10x productivity gains.</p>
<p>Any software engineer who has worked on actual code in an actual company knows this isn't possible. You can't compress the back and forth of 3 months of code review into 1.5 weeks. When you code review you:</p>
<ol>
<li>Tag your reviewer</li>
<li>Hope they will get to it sooner rather than later (which will be tough because they are apparently code reviewing 10x as much code as before)</li>
<li>Context switch to something else while you wait</li>
<li>See a notification (perhaps immediately, perhaps 2 hours after your reviewer went offline for the day)</li>
<li>Context switch back to the review</li>
<li>Read their comments</li>
<li>Respond accordingly</li>
<li>Rinse and repeat.</li>
</ol>
<p>This process can be made fairly efficient at a competent company with good standards and communication practices. But you're telling me you made this process <strong>10 times</strong> as efficient to handle 10x the work? This simply can not be done.</p>
<p>The human processes involved in actual corporate software engineering have not changed significantly. Product managers might use ChatGPT to do "research" but they aren't suddenly pumping out ten times as many well vetted, well justified, well estimated stories as they did before. They can not do 10 user interviews all at once. The same goes for Designers and QA testers. Hiring 10x the number of PMs to keep up isn't feasible. Each hire has diminishing returns as network effects and bureaucracy take hold.</p>
<p>Even if we assume people mean only the actual code writing process is now 10-100x faster, we should still be skeptical of how this maths out. When you write code, how much of your time do you truly spend pushing buttons on the keyboard? It's probably less than you think. Much of your prime coding time is actually reading and thinking, often while waiting for compiling, a page refresh, or for tests to run. LLMs do not make <code>rustc</code> go faster.</p>
<p>What LLMs produce is often broken, hallucinated, or below codebase standards. The frequency of these errors go up with the size of the codebase. When that happens you have to re-prompt, which could instantly fix the problem or could be a huge waste of time. Or you can go in and fix the code yourself. But then you're back to measly 1x engineer status, perhaps worse if you've gotten so used to vibe coding you <a href="https://nmn.gl/blog/ai-and-learning">forgot how to code</a>. If you're "embracing the vibes" and not even looking at the code produced, you're simply going to hit a productivity wall once the codebase gets large enough. And once you do you'll have to reckon with the complete lack of standards and proper abstractions.</p>
<p>I think sometimes people lose the scale of just how big a 10x improvement is. 10x is the difference between your mini-van and a record setting <a href="https://en.wikipedia.org/wiki/ThrustSSC">supersonic land jet</a>. Imagine trying to drive your 10 minute commute down your city streets in a car that goes 600mph. Will you get to the other side of town in one tenth the time? No, because even a single 60 second stoplight will eat up your entire time budget. F1 cars slow down to mini-van speeds in basic turns. It turns out that most of any activity is not spent going at top speed.</p>
<p>100x productivity means you now do what used to be one year of work in two days. I shouldn't even need to touch the ludicrousness of numbers at that scale.</p>
<h2 id="do-10x-engineers-exist">Do 10x Engineers Exist?</h2>
<p>This debate isn't something I want to weigh in on but I might have to. My answer is sometimes, kinda. When I have had engineers who were 10x as valuable as others it was primarily due to their ability to <em>prevent unnecessary work</em>. Talking a PM down from a task that was never feasible. Getting another engineer to not build that unnecessary microservice. Making developer experience investments that save everyone just a bit of time on every task. Documenting your work so that every future engineer can jump in faster. These things can add up over time to one engineer saving 10x the time company wide than what they took to build it.</p>
<p>Work of this nature is not always available, so great engineers will only find themselves being 10x as productive in certain situations. At a certain point every engineer just needs to build features, which a great engineer might do twice as fast as a junior engineer, but they'll still hit the same bottlenecks as before. Flawed as story points are, I've never seen an engineer actually complete ten times as many as an average engineer consistently.</p>
<p>Notably, AI coding assistants do very little to prevent unnecessary work. On the contrary, AI often seems to encourage hastiness and over-building. When I ask architectural questions, it often recommends something that I realize is not necessary after a good night's sleep or a talk with a great engineer. All other things held the same, is a faster coder a better engineer? Yes, but it's not the 10x difference maker and it's hard to hold everything else constant. The more you focus on pumping out tasks as fast as possible the easier is to miss the important time savers that reduce total work.</p>
<h2 id="so-are-the-ai-posters-lying-or-what">So are the AI-posters lying or what?</h2>
<p>I think the AI-posters are a mix of the following, in order of least to most malevolent:</p>
<ul>
<li>Good-natured folks who are mismeasuring themselves and others</li>
<li>People heavily invested, personally or financially, in the success of AI (AI startup founders, investors, etc.)</li>
<li>Bosses outright trying to make their engineers feel precarious so they don't quit, look for other jobs, or ask for raises</li>
</ul>
<h3 id="the-good-natured-engineer-with-bad-math-skills">The good-natured engineer with bad math skills</h3>
<p>In my experience, AI delivers rare, short bursts of 10-100x productivity. When I have AI write me a custom ESLint rule in a few minutes, which would have taken hours of documentation surfing and tutorials otherwise, that's a genuine order of magnitude time and effort improvement. Moments like this do happen with AI. Many career non-coders have felt the magic in the first few days after spinning an app up with Lovable.</p>
<p>The problem is that productivity does not scale. I don't write more than one ESLint rule per year. This burst of productivity was enabled solely by the fact that I didn't care about this code and wasn't going to work to make it readable for the next engineer. If constantly writing ESLint rules became a core job requirement I'd sink the one-time cost to learn how ESLint internals work. After that, there simply wouldn't be a big difference in the time it takes to vibe code a rule vs. write it myself, especially when you add in the extra time to make my code human readable for when I come back to this file in 6 months.</p>
<p>Eventually every vibe coder reaches the point where the returns start heavily diminishing. Their <a href="https://pivot-to-ai.com/2025/03/18/guys-im-under-attack-ai-vibe-coding-in-the-wild/">site gets hacked</a> and they need to actually sink the time to learn how security works. The app gets too big for context windows and things start looking and functioning inconsistently. Real frontend engineers who know what they are doing are hired to implement a consistent design system and UX.</p>
<p>There's also a lot of simple biases and blind spots that can cause a productivity illusion. If you leave the depths of big corporate for a startup you will genuinely be shocked at how much more productive each engineer is. It's easy to credit this to AI. Some people really enjoy the technological novelty of AI coding and when you are working in something new you often feel like you're doing more than you ever did. I know the first time I used Python I felt like I was "sipping rocket fuel", but, as with all other technologies, it always comes back down to earth.</p>
<p>I think a lot of the more genuine 10x AI hype is coming from people who are simply in the honeymoon phase or haven't sat down to actually consider what 10x improvement means mathematically. I wouldn't be surprised to learn AI helps many engineers do certain tasks 20-50% faster, but the nature of software bottlenecks mean this doesn't translate to a 20% productivity increase and certainly not a 10x increase.</p>
<h3 id="incentives-matter">Incentives matter</h3>
<p>Look, I'm not an AI startup hater. If you want to plug OpenAI's API into your healthcare startup I might raise an eyebrow of concern over the risks, but I'd do the same for any startup desiring to move fast and break things in the medical field. My goal here isn't to say AI startup founders or investors are evil or even dishonest. My point is to say in the droll voice of your high school Econ 101 professor, "Incentives Matter".</p>
<p>If you are running an AI startup and every other AI startup is telling investors they are seeing 10x more productivity thanks to AI, the incentives are plain and simple: you should say the same publicly and privately. If your company is built on the back of AI, you are incentivized to sell AI as a miracle solution in every part of life. If you are an engineer at an AI startup and your boss asks you:</p>
<blockquote>
<p>Hey, you're getting 10x the productivity thanks to AI, just like all the other engineers, right?</p>
</blockquote>
<p>You are strongly incentivized to say yes. And when every other engineer also says yes for the same reason, that CEO <a href="https://www.youtube.com/watch?v=vn_PSJsl0LQ">isn't lying</a>, they are just relaying what they heard.</p>
<p>What I'd like to stress to those feeling anxiety like me is that this is nothing new. CEOs are not unbiased sources. Executives have been claiming that everything from Agile to Meyers-Briggs have unlocked limitless productivity. There will always be a new synergistic buzzword on LinkedIn, don't let it get you down. In fact, stop scrolling LinkedIn at all. It's a silly place.</p>
<h3 id="outright-malice">Outright Malice</h3>
<p>When something is said that makes people feel anxious, at least some of the time you should conclude it's because that's what the speaker wanted to happen. Bosses trying to make their engineers feel like their position is precarious is also nothing new. We all remember the narrative that a 3 month coding bootcamp could churn out 4-year-degree quality engineers, so you'd best not get too uppity or you'll be replaced with a bachelor of arts doing a career pivot. Then a few years went by and people realized that bootcamp grads were usually <a href="https://www.sandofsky.com/lambda-school/">woefully underprepared</a> for actual software engineering since they were not given the proper foundation.</p>
<p>Bootcamps and AI are just examples in a long series of poorly born out threats to commoditize the highly expensive, highly professionalized field of software engineering. They are rhetorical devices designed to imply precarity. Your boss can't actually fire you and replace you with AI, but he can make you <em>feel</em> like he <em>could</em>, and maybe not ask for that raise.</p>
<p>Some amount of the 10x AI engineer story is likely being told by people who simply want you to feel bad for this purpose. How much of it, I don't know. Despite how highly distrustful we've become of each other in these times, I still believe most people are fundamentally decent, so I'm not inclined to believe it's a high percentage.</p>
<h2 id="degrees-of-separation">Degrees of separation</h2>
<p>One thing I've noticed about all these characters in AI coding hype pieces is there is almost always a degree of separation from the writer to the actual productivity benefits. The poster is a founder, or a manager, or an investor, making grandiose claims about someone else's productivity. There's nothing wrong with secondary sources but if you can't find a primary source, you might start questioning the reliability of the information.</p>
<p>Presentations from actual engineers demonstrating how they achieve more productivity with AI are much more varied and much more muted in their praise. These demos show largely AI as the same technology you and I were familiar with before we got so anxious: a neat text generator that sometimes does magic but often requires you to take the wheel.</p>
<p>AI usage on open source projects, where the productive process can be publicly witnessed, has famously been a <a href="https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/">hilarious failure</a>. I have learned things about how to use AI better from a few youtube videos. <a href="https://www.youtube.com/watch?v=sQYXZCUvpIc">Here's</a> a good one referenced in that Ludicity article above. I'll spoil it for you though, this engineer has not found the fountain of coding productivity.</p>
<h2 id="its-okay-to-be-less-productive">It's okay to be less productive</h2>
<p>Even after I got over the idea that there was a secret clade of engineer who was now ten times as productive and strong and tall and sexy as I was, I still felt some anxiety over the fact that I still didn't enjoy using AI very much. Vibe coding is a complete bore once the magic wears off. Reading LLM generated code sucks. Asking it politely to use a not hallucinated library is painful. But what if I was, despite all that, 20% more productive vibe coding than regular coding? Would it be wrong for me to do "normal" coding if a higher output path is available?</p>
<p>No. It's okay to sacrifice some productivity to make work enjoyable. More than okay, it's <em>essential</em> in our field. If you force yourself to work in a way you hate, you're just going to burn out. Only so much of coding is writing code, the rest is solving problems, doing system design, reasoning about abstractions, and interfacing with other humans. You are better at all those things when you feel good. It's okay to feel pride in your work and appreciate the craft. Over the long term your codebase will benefit from it.</p>
<p>It doesn't matter if digital music sounds objectively better than vinyl. It doesn't matter if flipping the record is less "productive" than letting the streaming service automatically roll over to the next song in 100x less time. If listening to a 70 year old disk makes you happier, just do it. You'll listen to more music if you do that than you would by forcing yourself to use the more "productive" streaming service. You will spend more time writing code and you'll write better code if you do it the way you like to.</p>
<p>Oh, and this exact argument works in reverse. If you feel good doing AI coding, just do it. If you feel so excited that you code more than ever before, that's awesome. I want everyone to feel that way, regardless of how they get there.</p>
<h2 id="how-to-be-a-good-ai-leader">How to be a good AI leader</h2>
<p>Making all your engineers feel constantly anxious about their performance is <em>bad for your company</em>. It will make your engineers not want to work for you. This is a recipe for short term thinking that will encourage engineers to max out bad metrics, like lines of code. Code review will get neglected, tech debt will compound, and in the long term the whole company will be footing the bill of those errors.</p>
<p>Unrealistic 10x expectations will result in rushed and thus subpar work without fail. Engineers need to have room to breathe. Room to take a little bit more time to do the thing right. Good codebases and good companies are built on a healthy balance of thinking for today and tomorrow. I'm thankful to work at one of these companies right now, but many aren't so fortunate.</p>
<p>Do not scold engineers for not using enough tokens. Your engineers are highly educated professionals in an extremely competitive field. Software engineers are already infamous for an over-eager cycle of embracing and abandoning new languages and tools. If you are paying these people this much, you should have the trust in them that if a super amazing productivity boost becomes available, they'll <em>come to you</em> asking for the pro plan. If you're worried about missing out on all the AI coding gains everyone else seems to be getting, sign up for a LLM team plan, host a training session, and see what comes out of it. That's all you need to do.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is no secret herbal medicine that prevents all disease sitting out in the open if you just follow the right Facebook groups. There is no AI coding revolution available if you just start vibing. You are not missing anything. Trust yourself. You are enough.</p>
<p>Oh, and don't scroll LinkedIn. Or Twitter. Ever.</p>

<ul><li>← Previous<br> <a href="https://colton.dev/blog/tailwind-is-the-worst-of-all-worlds/">Tailwind is the Worst of All Worlds</a></li>
</ul>

			</heading-anchors>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genie 3: A new frontier for world models (969 pts)]]></title>
            <link>https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/</link>
            <guid>44798166</guid>
            <pubDate>Tue, 05 Aug 2025 14:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/">https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/</a>, See on <a href="https://news.ycombinator.com/item?id=44798166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="capabilities">
              
                
                
                  
                  <div>
  <h2 data-block-key="wbu8i">Genie 3’s capabilities include:</h2><p data-block-key="7oibn">The following are recordings of real time interactions from Genie 3.</p><h3 data-block-key="4b33n">Modelling physical properties of the world</h3><p data-block-key="5alru">Experience natural phenomena like water and lighting, and complex environmental interactions.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-2c894174-1e81-45ce-9d7e-f6eed0466be8">
  
  <div>
<div aria-label="Item 2" id="block-4d2e1943-df2a-474d-916b-748e4b2e48b3">
  <figure aria-labelledby="caption-4d2e1943-df2a-474d-916b-748e4b2e48b3">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_1_MNInndd.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> The video shows a first person perspective of someone navigating difficult terrain in the middle of a volcanic area. This is a real world video shot from the perspective of a wheeled robot that needs to traverse across a terrain. The vehicle has chunky offroad tires that crunch under the blackened rock. The camera is an egocentric camera mounted to the vehicle, and you can see the front tires just on the bottom of the camera along with the body of the robot. In the distance you can see smoke and lava flowing from the volcano. There are no other visible signs of life. There are lava pools that the agent is trying to avoid and random rock formations. The sky is a vivid blue.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-29587f73-7711-41b8-a95d-ceb42d5f598a">
  <figure aria-labelledby="caption-29587f73-7711-41b8-a95d-ceb42d5f598a">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_2_Qvyu3BP.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Jetski during the festival of lights</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-6fc97f07-124d-46bb-a8fb-39d74c3eaf92">
  <figure aria-labelledby="caption-6fc97f07-124d-46bb-a8fb-39d74c3eaf92">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_3_I8KO3kl.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking on a pavement in Florida next to a two-lane road from one side and the sea on the other, during an approaching hurricane, with strong wind and waves splashing over the road. There is a railing on the left of the agent, separating them from the sea. The road goes along the coast, with a short bridge visible in front of the agent. Waves are splashing over the railing and onto the road one after another. Palm trees are bending in the wind. There is heavy rain, and the agent is wearing a rain coat. Real world, first-person.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-245112c4-0e91-4311-844a-f341a4be5398">
  <figure aria-labelledby="caption-245112c4-0e91-4311-844a-f341a4be5398">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_4_6dT1rge.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Fast tracking real world video following a jellyfish swimming at high speed through the darkness of the deep sea between canyons covered in densely packed vent mussels with tiny white crabs crawling on them. Blurry hydrothermal vents in the distance spew thick, billowing plumes of vibrant blue, mineral-rich smoke from glowing rocky structures. Very dark, dim deep sea lighting, particles float in the cloudy ocean.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-030795d7-6f37-4866-beb3-9784132bf143">
  <figure aria-labelledby="caption-030795d7-6f37-4866-beb3-9784132bf143">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_5_1sm8u8o.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A helicopter pilot carefully maneuvering over a coastal cliff with a small waterfall.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Simulating the natural world</h3><p data-block-key="dr8gd">Generate vibrant ecosystems, from animal behaviors to intricate plant life.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-bc05a02a-a545-41b3-8795-62d152b86618">
  
  <div>
<div aria-label="Item 5" id="block-7ce58041-66f0-4125-ae19-3f529874688a">
  <figure aria-labelledby="caption-7ce58041-66f0-4125-ae19-3f529874688a">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_1_KkDJNGE.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Running by the shores of a glacial lake, exploring branching paths through the forest, crossing flowing mountain streams. Set amidst beautiful snow capped mountains and pine forest. Plentiful wildlife makes the journey a delight.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-5ed99f1c-ffb5-4e78-ace4-b51c8edefe5f">
  <figure aria-labelledby="caption-5ed99f1c-ffb5-4e78-ace4-b51c8edefe5f">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_2_BJ3YgL8.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Real world tracking shot swimming through deep dimly lit ocean between deep ocean canyons, densely packed vast school of jellyfish swimming, bioluminescent lighting.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-0ac1f2a3-6136-49e7-93df-a38677c5b5dc">
  <figure aria-labelledby="caption-0ac1f2a3-6136-49e7-93df-a38677c5b5dc">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_3_gwzGBLr.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> This is a natural, real-world landscape designed as a Japanese zen garden. The scene is set in the early morning under a clear sky. Soft, warm sunlight illuminates the garden, casting long, gentle shadows. The ground is covered in fine, white sand that is raked into meticulous swirling patterns. A small, still pond is present, with pink water lilies floating on its surface. Smooth, grey rocks of various sizes are placed throughout the garden, some with green moss on their surfaces. Key structures include a stacked stone cairn and a traditional Japanese stone lantern. The entire area is enclosed by a tall bamboo fence in the background. The visual style is photorealistic, with high detail in the textures of the sand, stone, and lush green vegetation.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-5e81a48a-68a4-4cc6-8b5c-88a4fe9e1189">
  <figure aria-labelledby="caption-5e81a48a-68a4-4cc6-8b5c-88a4fe9e1189">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_4_KmMnEoZ.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> The environment is a natural, real-world landscape, specifically a dense arrangement of lush, vibrant foliage. The leaves are broad and deeply textured, displaying an array of green hues from emerald to lime, interspersed with hints of yellow and red, suggesting a rich, healthy ecosystem. Abstract dappled light filters down from above, creating shifting patterns of illumination and shadow across the leaves, highlighting their intricate veins and varied surfaces. The atmosphere is serene and deeply immersive, evoking a sense of being within a vibrant, living natural world. Small water droplets are visible on some leaf surfaces, reflecting the ambient light. The background is a soft blur of similar foliage, emphasizing the foreground elements. The air appears humid and still.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Modelling animation and fiction</h3><p data-block-key="dcth0">Tap into imagination, creating fantastical scenarios and expressive animated characters.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-0b6f1d8c-1b87-4c40-86fe-d5faf67c0988">
  
  <div>
<div aria-label="Item 8" id="block-64b19250-9187-4eb7-b5b1-24ddc6f45064">
  <figure aria-labelledby="caption-64b19250-9187-4eb7-b5b1-24ddc6f45064">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_1_cTvKl3P.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A vibrant 3D style, an adorable, fluffy creature bounding across a vibrant rainbow bridge in a fantastical landscape. The creature is small and compact, with fur that mimics the warm hues of a sunrise – oranges, yellows, and pinks blending seamlessly together. Its most striking feature is a pair of large, perked ears, shaped like those of a German Shepherd, adding a touch of playful contrast to its otherwise rounded form. As it runs on four short legs across the rainbow, its fur appears to ripple and flow, adding to its sense of dynamism and energy. The rainbow bridge arches gracefully through a whimsical landscape, perhaps filled with floating islands, glowing flora, and swirling clouds. The lighting is bright and cheerful, casting a warm glow on the creature and its surroundings. The overall impression is one of joy, wonder, and boundless energy, capturing the creature's playful spirit and the magical nature of the world it inhabits. This image evokes a sense of childlike whimsy and invites the viewer to imagine the adventures that await this charming creature in its fantastical realm.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-334ea4df-0e0f-4d4d-8446-4cb390db797d">
  <figure aria-labelledby="caption-334ea4df-0e0f-4d4d-8446-4cb390db797d">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_2_RNg1ibH.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Being a lizard, origami style</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-03e8584c-a8a4-41bf-aceb-2e29096871cc">
  <figure aria-labelledby="caption-03e8584c-a8a4-41bf-aceb-2e29096871cc">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_3_ZXctgpq.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A fantastical, wide-angle shot captures a lush, enchanted forest bathed in the soft glow of twilight. The player controls a large firefly flying through towering trees with vibrant foliage creating a dense canopy overhead, filtering the sunlight and casting dappled shadows on the forest floor. Nestled among the branches are a handful of charming tree houses, each glowing with a warm, inviting light. The tree houses vary in size and design, some resembling whimsical castles, others cozy cabins. Tiny details, like glowing windows and miniature balconies, add to their charm. A winding path, barely visible beneath the undergrowth, leads the viewer's eye deeper into the enchanted forest. The overall scene evokes a sense of wonder, tranquility, and the magic of childhood dreams.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-99192087-b0e2-4be4-9596-a81f5b1f5777">
  <figure aria-labelledby="caption-99192087-b0e2-4be4-9596-a81f5b1f5777">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_4_DuLFEfx.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A serene Irish landscape, with rolling emerald-green hills, misty lakes, and rugged mountains, suddenly trembles violently—as if the earth itself is being torn apart. In a moment of surreal chaos, entire sections of land rip free, rising into the sky in jagged, brutalist formations, their rocky undersides exposed like raw, fractured earth. The lakes are wrenched upward, now suspended in the sky, their waters spilling downward in colossal waterfalls, creating an apocalyptic storm of mist and rain over the land below. The camera pulls back, revealing a new impossible geography—mountains floating, cliffs inverted, rivers twisting mid-air—as gravity itself bends, turning the once-peaceful countryside into a brutalist, surreal monument to nature’s violent transformation.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Exploring locations and historical settings</h3><p data-block-key="bkrrk">Transcend geographical and temporal boundaries to explore places and past eras.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-4cab3e39-d22b-47fb-92a9-846bb4186784">
  
  <div>
<div aria-label="Item 11" id="block-9b140acb-78a9-447f-8d4c-20ab136ef61c">
  <figure aria-labelledby="caption-9b140acb-78a9-447f-8d4c-20ab136ef61c">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_1_OUxxXpK.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A real world mountainous environment in the Alps. The landscape features steep, rocky cliffs and narrow gorges filled with loose scree and debris. The rock is predominantly grey and white, with patches of green vegetation clinging to the cliff faces. The top of the gorge opens up to a vista of dense evergreen forests and meadows. The overall theme is one of rugged, natural beauty and extreme terrain.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-b4bb6eb9-eed1-4ee2-96aa-3633951d10ee">
  <figure aria-labelledby="caption-b4bb6eb9-eed1-4ee2-96aa-3633951d10ee">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_2_ryC3jcr.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Venice by Vaporetto. The canals of Venice are recreated with painstaking detail. The water has realistic reflections and wakes. The buildings show crumbling plaster and centuries of weathering. The scene is populated with other gondolas, water taxis, and barges.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-a7c32395-2772-4d7c-8689-42572cda3ff0">
  <figure aria-labelledby="caption-a7c32395-2772-4d7c-8689-42572cda3ff0">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_3_dlHXqb9.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Exploring the palace of Knossos on Crete as it would have stood in its glorious heyday.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-9f40e5ba-079f-45b6-a26a-1442c28d7693">
  <figure aria-labelledby="caption-9f40e5ba-079f-45b6-a26a-1442c28d7693">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_4_oZjNQYu.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking around on a beautiful day out in Hinsdale, Illinois. Real world. There are cars parked. The person filming is standing on the sidewalk, there are flocks of birds flying overhead.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-070f8fe9-52f4-4f85-85ba-4c7b549e32cd">
  <figure aria-labelledby="caption-070f8fe9-52f4-4f85-85ba-4c7b549e32cd">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_5_LKqlgO0.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A biking enthusiast driving on a narrow road on an edge of a cliff in India, the Killar-Kishtwar Road. Real-world, first-person, only hands on handles visible.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Pushing the frontier of real-time capabilities</h3><p data-block-key="1001j">Achieving a high degree of controllability and real-time interactivity in Genie 3 required significant technical breakthroughs. During the auto-regressive generation of each frame, the model has to take into account the previously generated trajectory that grows with time. For example, if the user is revisiting a location after a minute, the model has to refer back to the relevant information from a minute ago. To achieve real-time interactivity, this computation must happen multiple times per second in response to new user inputs as they arrive.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="apn2o">Environmental consistency over a long horizon</h3><p data-block-key="a0tgg">In order for AI generated worlds to be immersive, they have to stay physically consistent over long horizons. However, generating an environment auto-regressively is generally a harder technical problem than generating an entire video, since inaccuracies tend to accumulate over time. Despite the challenge, Genie 3 environments remain largely consistent for several minutes, with visual memory extending as far back as one minute ago.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-2338c9da-d003-40eb-9541-65621a0a7bb1">
  
  <div>
<div aria-label="Item 15" id="block-6e097311-816e-4176-8695-9117c3496c0b">
  <figure aria-labelledby="caption-6e097311-816e-4176-8695-9117c3496c0b">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_1_iNVUBuv.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> POV action camera of a tan house being painted by a first person agent with a paint roller</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-ce662459-2030-4c14-a575-df35b8a57f56">
  <figure aria-labelledby="caption-ce662459-2030-4c14-a575-df35b8a57f56">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_2_zS0EAgg.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A Victorian street with a grey house. The grey house has a portal ringed by magical sparks. The portal leads to a vast desert filled with dunes, and that desert is visible from the outside. The agent can walk into the portal and is teleported to the desert.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-3dbaa10d-fbfe-4bb9-9aa7-d85048fb3732">
  <figure aria-labelledby="caption-3dbaa10d-fbfe-4bb9-9aa7-d85048fb3732">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_3_ccj4cHU.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A classroom where on the blackboard at the front of the room it says GENIE-3 MEMORY TEST and underneath is a beautiful chalk picture of an apple, a mug of coffee, and a tree. The classroom is empty except for this. Outside the window are trees and a few cars driving past.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-5555c342-6995-4d49-ae78-2dc7971a53e8">
  <figure aria-labelledby="caption-5555c342-6995-4d49-ae78-2dc7971a53e8">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_4_gIb3IbS.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> This is a fantastical, whimsical forest environment. The lighting is bright and cheerful, suggesting a sunny day with dappled light filtering through a dense canopy of lush, oversized leaves. The air is clear and still. The ground is a soft, verdant carpet of moss and unusually large, brightly coloured mushrooms in shades of red and blue, their caps dotted with white. Winding dirt paths, well-trodden and narrow, weave between towering, ancient trees with smooth, grey bark. Interspersed throughout the forest are charming, mushroom-shaped houses, with intricate wooden doors and tiny, circular windows, each one unique in its design and colour palette, ranging from vibrant reds to gentle blues and greens. Various small, friendly forest creatures, such as colourful butterflies and tiny singing birds, flit amongst the foliage, adding to the lively atmosphere. There is an abundance of peculiar, oversized flowers blooming in an array of pastel and bright hues, releasing a gentle glow.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-4fa74576-2ab3-4a55-a4d2-c969a31984bb">
  <figure aria-labelledby="caption-4fa74576-2ab3-4a55-a4d2-c969a31984bb">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_5_OCdIbx8.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> An extremely enormous, realistic gorilla, draped in a flamboyant, emerald red vest with ornate brass buttons and an elaborate, feathered bicorne hat, brandishing only a vintage silk parasol, navigates a series of outrageously extravagant, moss-laden McMansions where grand marble structures are subtly embraced by sprawling, ancient rose bushes and creeping ivy.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-34d3776a-7837-4d86-9192-64684008bd3b">
  <figure aria-labelledby="caption-34d3776a-7837-4d86-9192-64684008bd3b">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_6_96KPmd3.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking around ancient Athens, Greek architecture, marble</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-a1bfba40-e2ee-436c-b3d3-7272a93d8666">
  

  <figcaption>
      <p data-block-key="w07ur"><i>The trees to the left of the building remain consistent throughout the interaction, even as they go in and out of view.</i></p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <p data-block-key="wbu8i">Genie 3’s consistency is an emergent capability. Other methods such as NeRFs and Gaussian Splatting also allow consistent navigable 3D environments, but depend on the provision of an explicit 3D representation. By contrast, worlds generated by Genie 3 are far more dynamic and rich because they’re created frame by frame based on the world description and actions by the user.</p>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-ddec9ea1-cb6f-4e51-967b-dffdcad93111">
  

  <figcaption>
      <gdm-caption>
    <p data-block-key="3r9m9"><strong>Prompt:</strong> First-person view drone video. High speed flight into and along a narrow canyon in Iceland with a river at the bottom and moss on the rocks, golden hour, realworld</p>
    
    
  </gdm-caption>
    </figcaption>
</figure>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Promptable world events</h3><p data-block-key="40ru4">In addition to navigational inputs, Genie 3 also enables a more expressive form of text-based interaction, which we refer to as <i>promptable world events</i>.</p><p data-block-key="7abeu">Promptable world events make it possible to change the generated world, like altering weather conditions or introducing new objects and characters, enhancing the experience from navigation controls.</p><p data-block-key="cirvr">This ability also increases the breadth of counterfactual, or “what if” scenarios, that can be used by agents learning from experience to handle unexpected situations.</p>
</div>
                
              
                
                
                  
                  <p data-block-key="du66g"><strong>Choose a world setting. Then, pick an event, and see Genie 3 create it.</strong></p>
                
              
                
                
                  
                  
                
              
                
                
                  
                  <hr>
                
              
            </div><div id="embodied-agent-research">
              
                
                
                  
                  <div>
  <h3 data-block-key="apn2o">Fueling embodied agent research</h3><p data-block-key="d857">To test the compatibility of Genie 3 created worlds for future agent training, we generated worlds for a recent version of our <a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/" rel="noopener" target="_blank">SIMA agent</a>, our generalist agent for 3D virtual settings. In each world we instructed the agent to pursue a set of distinct goals, which it aims to achieve by sending navigation actions to Genie 3. Like any other environment, Genie 3 is not aware of the agent’s goal, instead it simulates the future based on the agent's actions.</p>
</div>
                
              
                
                
                  
                  <p data-block-key="du66g"><strong>Choose a world setting. Then, pick a goal you'd like an agent to achieve and watch how it accomplishes it.</strong></p>
                
              
                
                
                  
                  
                
              
                
                
                  
                  <p data-block-key="wbu8i">Since Genie 3 is able to maintain consistency, it is now possible to execute a longer sequence of actions, achieving more complex goals. We expect this technology to play a critical role as we push toward AGI, and agents play a greater role in the world.</p>
                
              
                
                
                  
                  


<gdm-carousel id="block-e703a0c8-b4b3-4935-bf81-e0806049082b">
  
  
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
            </div><div id="limitations">
  <h2 data-block-key="wbu8i">Limitations</h2><p data-block-key="ggqs">While Genie 3 pushes the boundaries of what world models can accomplish, it's important to acknowledge its current limitations:</p><ul><li data-block-key="61sd2"><strong>Limited action space</strong>. Although promptable world events allow for a wide range of environmental interventions, they are not necessarily performed by the agent itself. The range of actions agents can perform directly is currently constrained.</li><li data-block-key="bfsot"><strong>Interaction and simulation of other agents</strong>. Accurately modeling complex interactions between multiple independent agents in shared environments is still an ongoing research challenge.</li><li data-block-key="55slt"><strong>Accurate representation of real-world locations</strong>. Genie 3 is currently unable to simulate real-world locations with perfect geographic accuracy.</li><li data-block-key="4irvj"><strong>Text rendering.</strong> Clear and legible text is often only generated when provided in the input world description.</li><li data-block-key="1nt0m"><strong>Limited interaction duration.</strong> The model can currently support a few minutes of continuous interaction, rather than extended hours.</li></ul>
</div><div id="responsibility">
  <h2 data-block-key="swoy7">Responsibility</h2><p data-block-key="fit92">We believe foundational technologies require a deep commitment to responsibility from the very beginning. The technical innovations in Genie 3, particularly its open-ended and real-time capabilities, introduce new challenges for safety and responsibility. To address these unique risks while aiming to maximize the benefits, we have worked closely with our Responsible Development &amp; Innovation Team.</p><p data-block-key="29qra">At Google DeepMind, we're dedicated to developing our best-in-class models in a way that amplifies human creativity, while limiting unintended impacts. As we continue to explore the potential applications for Genie, we are announcing Genie 3 as a limited research preview, providing early access to a small cohort of academics and creators. This approach allows us to gather crucial feedback and interdisciplinary perspectives as we explore this new frontier and continue to build our understanding of risks and their appropriate mitigations. We look forward to working further with the community to develop this technology in a responsible way.</p>
</div><div id="next-steps">
              
                
                
                  
                  <div>
  <h2 data-block-key="swoy7">Next steps</h2><p data-block-key="5i4jt">We believe Genie 3 is a significant moment for world models, where they will begin to have an impact on many areas of both AI research and generative media. To that end, we're exploring how we can make Genie 3 available to additional testers in the future.</p><p data-block-key="2us9t">Genie 3 could create new opportunities for education and training, helping students learn and experts gain experience. Not only can it provide a vast space to train agents like robots and autonomous systems, Genie 3 can also make it possible to evaluate agents’ performance, and explore their weaknesses.</p><p data-block-key="b7jov">At every step, we’re exploring the implications of our work and developing it for the benefit of humanity, safely and responsibly.</p>
</div>
                
              
                
                
                  
                  

<section>
  
    <h2>Please cite using the following BibTex</h2>
  

  <ul>
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/genie-3/genie3worldmodel2025.bib" rel="noopener" target="_blank">
      <span>Download BibTeX</span>
      
    </a>
            </gemini-button>
        </li>
        
    
  </ul>
</section>
                
              
                
                
                  
                  <div>
      <h2 data-block-key="vmhlu">Acknowledgments</h2><p data-block-key="dpcrj">Genie 3 was made possible due to key research and engineering contributions from Phil Ball, Jakob Bauer, Frank Belletti, Bethanie Brownfield, Ariel Ephrat, Shlomi Fruchter, Agrim Gupta, Kristian Holsheimer, Aleks Holynski, Jiri Hron, Christos Kaplanis, Marjorie Limont, Matt McGill, Yanko Oliveira, Jack Parker-Holder, Frank Perbet, Guy Scully, Jeremy Shar, Stephen Spencer, Omer Tov, Ruben Villegas, Emma Wang and Jessica Yung.</p><p data-block-key="1qkkl">We thank Andrew Audibert, Cip Baetu, Jordi Berbel, David Bridson, Jake Bruce, Gavin Buttimore, Sarah Chakera, Bilva Chandra, Paul Collins, Alex Cullum, Bogdan Damoc, Vibha Dasagi, Maxime Gazeau, Charles Gbadamosi, Woohyun Han, Ed Hirst, Ashyana Kachra, Lucie Kerley, Kristian Kjems, Eva Knoepfel, Vika Koriakin, Jessica Lo, Cong Lu, Zeb Mehring, Alex Moufarek, Henna Nandwani, Valeria Oliveira, Fabio Pardo, Jane Park, Andrew Pierson, Ben Poole, Helen Ran, Nilesh Ray, Tim Salimans, Manuel Sanchez, Igor Saprykin, Amy Shen, Sailesh Sidhwani, Duncan Smith, Joe Stanton, Hamish Tomlinson, Dimple Vijaykumar, Luyu Wang, Piers Wingfield, Nat Wong, Keyang Xu, Christopher Yew, Nick Young and Vadim Zubov for their invaluable partnership in developing and refining key components of this project.</p><p data-block-key="rr7r">Thanks to Tim Rocktäschel, Satinder Singh, Adrian Bolton, Inbar Mosseri, Aäron van den Oord, Douglas Eck, Dumitru Erhan, Raia Hadsell, Zoubin Gharamani, Koray Kavukcuoglu and Demis Hassabis for their insightful guidance and support throughout the research process.</p><p data-block-key="uevg">Feature video was produced by Suz Chambers, Matthew Carey, Alex Chen, Andrew Rhee, JR Schmidt, Scotch Johnson, Heysu Oh, Kaloyan Kolev, Arden Schager, Sam Lawton, Hana Tanimura, Zach Velasco, Ben Wiley, and Dev Valladares. Including samples generated by Signe Norly, Eleni Shaw, Andeep Toor, Gregory Shaw, and Irina Blok.</p><p data-block-key="7r9de">Finally, we extend our gratitude to Mohammad Babaeizadeh, Gabe Barth-Maron, Parker Beak, Jenny Brennan, Tim Brooks, Max Cant, Harris Chan, Jeff Clune, Kaspar Daugaard, Dumitru Erhan, Ashley Feden, Simon Green, Nik Hemmings, Michael Huber, Jony Hudson, Dirichi Ike-Njoku, Bonnie Li, Simon Osindero, Georg Ostrovski, Ryan Poplin, Alex Rizkowsky, Giles Ruscoe, Ana Salazar, Guy Simmons, Jeff Stanway, Metin Toksoz-Exley, Petko Yotov, Mingda Zhang and Martin Zlocha for their insights and support.</p>
    </div>
                
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proxmox Virtual Environment 9.0 with Debian 13 released (150 pts)]]></title>
            <link>https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0</link>
            <guid>44798035</guid>
            <pubDate>Tue, 05 Aug 2025 13:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0">https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0</a>, See on <a href="https://news.ycombinator.com/item?id=44798035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><strong>VIENNA, Austria – August 05, 2025 –</strong> Leading open-source server solutions provider Proxmox Server Solutions GmbH (henceforth "Proxmox"), celebrating its 20th year of innovation, today announced the release of Proxmox Virtual Environment (VE) 9.0. Main highlight of this update is a modernized core built upon Debian 13 “Trixie”, ensuring a robust foundation for the platform.</p>
<p>Proxmox VE 9.0 further introduces significant advancements in both storage and networking capabilities, addressing critical enterprise demands. A highlight is the long-awaited support for snapshots on thick-provisioned LVM shared storage, improving storage management capabilities especially for enterprise users with Fibre Channel (FC) or iSCSI SAN environments. With newly added “fabric” support for Software-Defined Networking (SDN), administrators can construct highly complex and scalable network architectures.</p>
<h2>Highlights in Proxmox Virtual Environment 9.0</h2>
<p>Debian 13 “Trixie” at the core</p>
<p>This core update is based on Debian 13 “Trixie”, bringing the latest Debian release as foundation for Proxmox VE including newer packages, improved hardware support, and enhanced security. Proxmox VE is using a newer Linux kernel 6.14.8-2 as stable default enhancing hardware compatibility and performance.&nbsp;</p>
<p>Also, updates to the latest versions of leading open-source technologies for virtual environments like QEMU 10.0.2, LXC 6.0.4, Ceph Squid 19.2.3, and ZFS 2.3.3 are included. ZFS now supports adding new devices to existing RAIDZ pools with minimal downtime. For existing users of Proxmox VE 8.4 or older versions, an extensively tested and detailed upgrade path is available to enable a smooth upgrade.</p>
<p>Snapshots for thick-provisioned LVM shared storage</p>
<p>Virtual Machines (VMs) utilizing thick-provisioned LVM shared storages, such as those backed by iSCSI or FC-based SANs, now benefit from snapshot functionality out of the box. This is achieved by implementing snapshots as volume chains, where a volume based on a snapshot only records differences to its parent snapshot volume. Directory, NFS, and CIFS storages also gain additional support for snapshots as volume chains.</p>
<p>This new feature provides a powerful and highly requested capability for customers with traditional SAN infrastructure who have historically relied on clustered file systems. While direct integrations from many storage vendors continue to grow, this new feature closes the gap by providing a storage-independent solution for snapshots. This gives customers the independence to seamlessly manage their snapshots regardless of their hardware, without compromising on convenience.</p>
<p>New Fabrics feature for the SDN stack</p>
<p>This release enhances the SDN capabilities with the introduction of an SDN Fabrics feature, designed to simplify the configuration and management of complex routed networks. Engineered for reliability, SDN Fabrics facilitates multiple paths between nodes and automatic failover across Network Interface Cards (NICs), enabling the configuration of robust two-layer spine-leaf architectures for improved network redundancy and performance.</p>
<p>This new feature simplifies the management of dynamically routed networks which can for example be used as Ethernet VPN (EVPN) underlay or full-mesh networks for Ceph. The SDN stack in Proxmox VE gains support for two different routing protocols, OpenFabric and OSPF, and provides intuitive tools for the simplified configuration and precise management of those dynamic routing protocols.</p>
<p>Affinity rules in High Availability (HA) clusters</p>
<p>The Proxmox team introduces HA resource affinity rules to enable fine-grained control and flexibility over resource placement in HA clusters, ensuring optimal performance, enhanced resiliency, and minimized latency for critical workloads. To better control complex, interconnected applications, the new HA Resource Affinity Rules allow administrators to precisely define how virtual machines and other HA resources are distributed across a cluster.</p>
<p>Interdependent HA resources, such as for example an application server and its associated database, can be kept together on the same physical node to minimize network latency. For services requiring maximum redundancy, like multiple VMs running the same mission-critical application, the rules can ensure these instances are kept on different nodes. This increases fault tolerance and ensures resiliency even during HA failovers.</p>
<p>Enhanced mobile interface</p>
<p>The Proxmox VE mobile interface has been thoroughly reworked, using the new Proxmox widget toolkit powered by the Rust-based Yew framework. The redesigned interface provides quick access to service overviews and includes essential management functions, including starting and stopping virtual guests and basic configuration. It is now easier than ever for users to access fundamental functionalities of Proxmox VE directly from their mobile browsers.</p>
<h3>Availability</h3>
<p>Proxmox VE 9.0 is available for download.&nbsp;The ISO contains the complete feature-set and can be installed on bare-metal. The virtualization platform from Proxmox comes stocked with all the essential management tools, as well as an easy-to-use, web-based user interface. This allows for simple, out-of-the-box management of the host, either through the command line or a standard web browser.</p>
<p>Seamless upgrade instructions from Proxmox VE 8 to 9 are available. It’s also possible to install Proxmox VE 9.0 on top of Debian.</p>
<p>License: Proxmox Virtual Environment is free and open-source software, published under the GNU Affero General Public License, v3.<br>Support Subscriptions: For enterprise users, Proxmox Server Solutions GmbH offers a subscription-based support model, which provides access to the extensively tested Enterprise Repository, with regular updates via the web interface, as well as technical support on a subscription basis. Prices start at EUR 115 per year and CPU.</p>
<p>Resources:</p>
<ul>
<li>ISO Image Download: <a href="https://www.proxmox.com/downloads">https://www.proxmox.com/downloads</a></li>
<li>Roadmap:&nbsp;For published and upcoming features, see the <a href="https://pve.proxmox.com/wiki/Roadmap#Roadmap">Release Notes &amp; Roadmap</a></li>
<li>Video: <a href="https://www.proxmox.com/en/services/training-courses/videos/proxmox-virtual-environment/whats-new-in-proxmox-ve-9-0">What's new in Proxmox VE 9.0</a></li>
</ul>
<p><a href="https://www.proxmox.com/"></a>###</p>
<p><strong>Facts</strong><br>The open-source project Proxmox VE has a huge worldwide user base with more than 1.6 million hosts. The virtualization platform has been translated into over 31 languages. More than 225,000 community members in the support forum engage with and help each other. By using Proxmox VE as an alternative to proprietary virtualization management solutions, enterprises are able to centralize and modernize their IT infrastructure, and turn it into a cost-effective and flexible software-defined data center, based on the latest open-source technologies. Tens of thousands of customers rely on enterprise support subscriptions from Proxmox Server Solutions GmbH.</p>
<p><strong>About Proxmox Server Solutions</strong><br>Proxmox provides powerful and user-friendly open-source server software. For 20 years, enterprises of all sizes and industries use the Proxmox solutions to deploy efficient and simplified IT infrastructures, minimize total cost of ownership, and avoid vendor lock-in. Proxmox also offers commercial support, training services, and an extensive partner ecosystem to ensure business continuity for its customers. Proxmox Server Solutions GmbH was established in 2005 and is headquartered in Vienna, Austria.</p>
<p>Contact:&nbsp;Daniela Häsler, Proxmox Server Solutions GmbH, marketing@proxmox.com</p>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lack of intent is what makes reading LLM-generated text exhausting (143 pts)]]></title>
            <link>https://lambdaland.org/posts/2025-08-04_artifical_inanity/</link>
            <guid>44797917</guid>
            <pubDate>Tue, 05 Aug 2025 13:46:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lambdaland.org/posts/2025-08-04_artifical_inanity/">https://lambdaland.org/posts/2025-08-04_artifical_inanity/</a>, See on <a href="https://news.ycombinator.com/item?id=44797917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      
      
<article>
  
  
  <h5>4 Aug 2025</h5>



  

  
  
  



<p>There’s something icky about LLM-generated text when you think it’s written by a human. I think I finally put my finger on one reason why I feel this way.</p>
<p>Note on the title: “Artificial Inanity” comes from Neal Stephenson’s novel <em>Anathem</em>.</p>
<p>At work I was sent a long design document and asked for my thoughts on it. As I read, I had a really hard time following it. Eventually I guessed correctly (confirmed via a follow-up conversation I had with the “author”<label for="sn1"></label>

<span>
I have “author” in quotes because, if a machine wrote it, you don’t merit being called the <em>author</em> of the work.
</span>
) that an LLM had generated the majority of the document. Parts of it <em>sounded</em> like a decent design document, but there was just way too much fluff that served only to confuse me.</p>
<p>When I read technical documents, I read to understand the content. In this mode of reading, I operate under the assumption that the author had a reason for choosing the words they did, and that every sentence is there to convey something that the author wishes me to understand.</p>
<p>This mode fails when an LLM or the like has generated the text. When I read something I know came out of a computer’s probabilistic sampling of a token-space, I have read knowing that every statement might be some hallucinated slop or incidental filler. I <em>cannot</em> trust that the human operator’s intent is expressed by the machine. In fact, I am confident that it is often <em>not</em>, but I have to waste tremendous effort trying to find that gap. Reading slop text when I think I’m reading real text is exhausting: since I am not on the alert for hallucinations or irrelevancies, every turn of phrase that seems out of place causes me to wonder <em>why that phrase it there</em> and <em>what am I missing</em> when in reality, such questions are ill formed: that was just a phrase composed by accident that <em>sounds</em> good but actually is devoid of much intent at all.</p>
<p><em>Intent</em> is the core thing: the <em>lack</em> of intent is what makes reading AI-slop so revolting. There needs to be a human intent—human will and human care—behind everything that is demanded of our care and attention. Even if you agree with Rolland Barthes’<label for="sn2"></label>

<span>
The author of <em>The Death of the Author</em>, an essay where Barthes argues that focusing on the author’s intent is fruitless—the meaning of a text is the effect it has on the audience.
</span>
views on literary criticism, the fact that there <em>is</em> an author who put care and intent into a work imbues that work with infinitely more meaning than if it were spat out by a machine.</p>
<p>Counterfeits to human connection will—unfortunately—always be in demand. The multi-billion dollar industry churning out pornography is proof enough. People will probably always, from here on out, be using LLMs to cheat their way through classes and themselves out of learning. Some might turn to them for some faux-companionship. Others will be prompting themselves to death by offloading more and more of their reasoning to machines, convinced that the computer—like a slot machine—somehow will let them win bigger in life.</p>
<p>I am <strong>not</strong> saying that LLMs are worthless—they are marvels of engineering and can solve some particularly thorny problems that have confounded us for decades. But it’s important to remember that, no matter how capable these machines get, they are not humans. And no human is so worthless as to be replaceable with a machine.</p></article>
 
      

      

      
  
  
  
 

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC says employees tried to steal trade secrets on iPhone 18 chip process (223 pts)]]></title>
            <link>https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/</link>
            <guid>44797408</guid>
            <pubDate>Tue, 05 Aug 2025 12:53:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/">https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/</a>, See on <a href="https://news.ycombinator.com/item?id=44797408">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?quality=82&amp;strip=all&amp;w=1600" alt="TSMC says employees tried to steal trade secrets on iPhone 18 chip process | Photo shows the inside of a hard drive" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p><a href="https://9to5mac.com/guides/aapl/" target="_blank" rel="noreferrer noopener">Apple</a> chipmaker <a href="https://9to5mac.com/guides/tsmc/" target="_blank" rel="noreferrer noopener">TSMC</a> has said that several then-employees tried to steal trade secrets relating to the company’s most advanced chip process. TSMC fired the individuals concerned and is now taking legal action against them. The former employees may also face criminal prosecution.</p>



<p>The report relates to the company’s 2-nanometer chip process, which is expected to be used for the A20 chips across next year’s <a href="https://9to5mac.com/guides/iphone-18/" target="_blank" rel="noreferrer noopener">iPhone 18</a> lineup …</p>



<h2 id="h-tsmc-2nm-process-expected-to-debut-in-iphone-18">TSMC 2nm process expected to debut in iPhone 18</h2>



<p>TSMC leads the world in the most advanced chip processes, and is next year expected to use its 2nm technology <a href="https://9to5mac.com/2025/06/03/apples-a20-chip-packaging-breakthrough/" target="_blank" rel="noreferrer noopener">for the A20 chips</a> used in the iPhone 18 range. Apple typically gets access to TSMC’s most advanced chip processes ahead of the company’s other customers.</p>



<p>Apple analyst Ming-Chi Kuo has suggested that the new chip will be <a href="https://9to5mac.com/2025/03/22/apple-iphone-18-2nm-a20-chip-kuo/" target="_blank" rel="noreferrer noopener">used for all iPhone 18 models</a>, not just the two Pro ones.</p>



<h2 id="h-tsmc-says-employees-tried-to-steal-trade-secrets">TSMC says employees tried to steal trade secrets</h2>



<p><em><a href="https://asia.nikkei.com/business/technology/tsmc-fires-workers-for-breaching-data-rules-on-cutting-edge-chip-tech" target="_blank" rel="noreferrer noopener">Nikkei Asia</a></em> reports that TSMC accused several former employees of attempting to obtain secret information about its 2nm chip development and production process.</p>



<blockquote>
<p>Several former employees of TSMC are suspected of attempting to obtain critical proprietary information on 2-nanometer chip development and production while working at the company, according to multiple sources familiar with the matter.</p>



<p>In response to Nikkei Asia’s questions, TSMC said that it recently “detected unauthorized activities during routine monitoring, leading to the discovery of potential trade secret leaks.”</p>



<p>The world’s top chipmaker said on Monday it took “strict disciplinary actions against the personnel involved and has initiated legal proceedings.”</p>
</blockquote>



<p>The attempt was detected by spotting “unusual access patterns” on the part of one of the employees.</p>



<p>The report says there could even be national security implications, as the Taiwanese government takes extremely seriously the protection of advanced technology developed within the country. Prosecutors have confirmed that they are investigating, and TSMC says that it will seek prosecution to the fullest extent of the law.</p>



<p>No details have been shared on the nature of the information obtained. It is likely that it relates to the 2nm process in general rather than anything specific to Apple’s A20 chip.</p>



<h4 id="h-highlighted-accessories">Highlighted accessories</h4>



<ul>
<li><a href="https://amzn.to/3UaJjDn" target="_blank" rel="noreferrer noopener">Official Apple Store on Amazon</a></li>



<li><a href="https://www.amazon.com/Anker-Charger-Compact-Technology-Included/dp/B0CP7NWH6L?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Anker 511 Nano Pro ultra-compact iPhone charger</a></li>



<li><a href="https://www.amazon.com/Spigen-Compatible-Accessories-Anti-Yellowing-Military-Grade/dp/B0DKGBTVHW?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Spigen MagFit case for iPhone 16e – adds MagSafe support</a></li>



<li><a href="https://www.amazon.com/Apple-MagSafe-Charger-Capability-Compatible/dp/B0DGJ4QQ5W?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Apple MagSafe Charger with 25w power for iPhone 16 models</a></li>



<li><a href="https://www.amazon.com/Apple-30W-USB-C-Power-Adapter/dp/B0CX23PHFD?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Apple 30W charger for above</a></li>



<li><a href="https://www.amazon.co.uk/dp/B0C4FDJ8F7?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Anker 240W braided USB-C to USB-C cable</a></li>
</ul>



<p><em>Photo by&nbsp;<a href="https://unsplash.com/@heapdump?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Patrick Lindenberg</a>&nbsp;on&nbsp;<a href="https://unsplash.com/photos/photo-of-optical-disc-drive-1iVKwElWrPA?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Your Own Lisp (189 pts)]]></title>
            <link>https://www.buildyourownlisp.com/</link>
            <guid>44796953</guid>
            <pubDate>Tue, 05 Aug 2025 11:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.buildyourownlisp.com/">https://www.buildyourownlisp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44796953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<h2>
  Build Your Own Lisp<br>
  <small>Learn C and build your own programming language in 1000 lines of code!</small>
</h2>

<p><img src="https://www.buildyourownlisp.com/static/img/lovelace.png" alt="lovelace" width="275px" height="395px">
</p>

<hr>

<p>If you're looking to learn C, or you've ever wondered how to build your own programming language, this is the book for you.</p>

<p>In just a few lines of code, I'll teach you how to use C, and together, we'll start building your very own language.</p>

<p>Along the way we'll learn about the weird and wonderful nature of Lisps, how to develop a real-world project, concisely solve problems, and write beautiful code!</p>

<p>This book is free to read online, so you can get started right away! But for those who want to show their support, or who want the best reading experience, this book is also available for purchase in print format, or for cheap in all major e-book formats.</p>






<!--
<p>If you want to show support, I also accept donations in the following formats...</p>

<table cellpadding='10'>
  <tr><td><em>Bitcoin</em></td>    <td><code><small>17WQM2WYt28j6pNYZvUcRsozG87wCwPhmp</small></code></td></tr>
  <tr><td><em>Dogecoin</em></td>   <td><code><small>D5Tozp7epcLZCfN3zU9x51cM7uZD72PbwU</small></code></td></tr>
  <tr><td><em>Real Money &trade;</em></td>
    <td style='text-align:center;'>
      <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
      <input type="hidden" name="cmd" value="_s-xclick">
      <input type="hidden" name="hosted_button_id" value="AJYFXLPVF8S72">
      <button type="submit" name="submit" class="btn btn-large btn-primary" >Donate</button>
      </form>
    </td>
  </tr>
</table>
-->

<table>

  <tbody><tr>
    <td><em>"I finally feel complete as a C programmer, having implemented my own Lisp."</em></td>
    <td><em>"Every programmer should do something like this, at least once."</em></td>
    <td><em>"One of the greatest things I've ever found on the internet..."</em></td>
  </tr>
  
  <tr>
    <td><a href="https://twitter.com/hirojin">@hirojin</a></td>
    <td><a href="https://twitter.com/mattcaldwell">@mattcaldwell</a></td>
    <td><a href="https://twitter.com/euryadam">@euryadam</a></td>
  </tr>
  
</tbody></table>




         </div></div>]]></description>
        </item>
    </channel>
</rss>