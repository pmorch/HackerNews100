<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 04 Feb 2025 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Payments Crisis of 2025: Doge Have "Read-Write" Access to Federal Payment System (205 pts)]]></title>
            <link>https://www.crisesnotes.com/day-five-of-the-trump-musk-treasury-payments-crisis-of-2025-not-read-only-access-anymore/</link>
            <guid>42933219</guid>
            <pubDate>Tue, 04 Feb 2025 15:05:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crisesnotes.com/day-five-of-the-trump-musk-treasury-payments-crisis-of-2025-not-read-only-access-anymore/">https://www.crisesnotes.com/day-five-of-the-trump-musk-treasury-payments-crisis-of-2025-not-read-only-access-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=42933219">Hacker News</a></p>
Couldn't get https://www.crisesnotes.com/day-five-of-the-trump-musk-treasury-payments-crisis-of-2025-not-read-only-access-anymore/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Popular Linux orgs Freedesktop and Alpine Linux are scrambling for new webhost (182 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/02/popular-linux-orgs-freedesktop-and-alpine-linux-are-scrambling-for-new-web-hosting/</link>
            <guid>42930974</guid>
            <pubDate>Tue, 04 Feb 2025 11:19:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/02/popular-linux-orgs-freedesktop-and-alpine-linux-are-scrambling-for-new-web-hosting/">https://arstechnica.com/gadgets/2025/02/popular-linux-orgs-freedesktop-and-alpine-linux-are-scrambling-for-new-web-hosting/</a>, See on <a href="https://news.ycombinator.com/item?id=42930974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Having worked "around the clock" to move from Google Cloud Platform after its open source credits there ran out, and now rushing to move off Equinix, Tissoires suggests a new plan: "[H]ave [freedesktop.org] pay for its own servers, and then have sponsors chip in."</p>
<h2>“Popular without most users knowing it”</h2>
<p>Alpine Linux, a small, security-minded distribution used in many containers and embedded devices, also needs a new home quickly. As <a href="https://alpinelinux.org/posts/Seeking-Support-After-Equinix-Metal-Sunsets.html">detailed in its blog</a>, Alpine Linux uses about 800TB of bandwidth each month and also needs continuous integration runners (or separate job agents), as well as a development box. Alpine states it is seeking co-location space and bare-metal servers near the Netherlands, though it will consider virtual machines if bare metal is not feasible.</p>
<p>Like X.org/Freedesktop, Alpine is using this moment as a wake-up call. Responding to Ars, Carlo Landmeter, who serves on Alpine's council, noted that Alpine Linux is a kind of open source project "that became popular without most users knowing it." Users are starting to donate, and companies are reaching out to help, but it's still "early days," Landmeter wrote.</p>
<p>Every so often, those working at the foundations of open source software experience something that highlights <a href="https://arstechnica.com/information-technology/2014/04/tech-giants-chastened-by-heartbleed-finally-agree-to-fund-openssl/">the mismatch between a project's importance and its support and funding</a>. Perhaps some people or some organizations will do the harder work of finding a sustaining future for these projects.</p>
<p>Ars has reached out to Equinix and X/Freedesktop and will update this post with responses.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia open-source nanite: continuous level of detail (LOD) mesh library (131 pts)]]></title>
            <link>https://github.com/nvpro-samples/nv_cluster_lod_builder</link>
            <guid>42930890</guid>
            <pubDate>Tue, 04 Feb 2025 11:05:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nvpro-samples/nv_cluster_lod_builder">https://github.com/nvpro-samples/nv_cluster_lod_builder</a>, See on <a href="https://news.ycombinator.com/item?id=42930890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">nv_cluster_lod_builder </h2><a id="user-content-nv_cluster_lod_builder-" aria-label="Permalink: nv_cluster_lod_builder " href="#nv_cluster_lod_builder-"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/lod_stitch.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/lod_stitch.svg" alt=""></a></p>
<p dir="auto"><strong>nv_cluster_lod_builder</strong> is a <em>continuous</em> level of detail (LOD) mesh library.
Continuous LOD allows for fine-grained control over geometric detail within a
mesh, compared to traditional discrete LOD. Clusters of triangles are carefully
precomputed by decimating the original mesh in a way that they can be seamlessly
combined across different LOD levels. At rendering time, a subset of these
clusters is selected to adaptively provide the required amount of detail as the
camera navigates the scene.</p>
<p dir="auto">Key features of continuous LOD systems include:</p>
<ul dir="auto">
<li><strong>Fast rendering with more detail:</strong> Triangles are allocated where they are
most needed.</li>
<li><strong>Reduced memory usage with geometry streaming:</strong> Particularly beneficial for
ray tracing applications.</li>
</ul>
<p dir="auto">This library serves as a quick placeholder or learning tool, demonstrating the
basics of creating continuous LOD data. For a reference implementation of the
rendering system, see
<a href="https://github.com/nvpro-samples/vk_lod_clusters">https://github.com/nvpro-samples/vk_lod_clusters</a>.</p>
<p dir="auto"><strong>Input:</strong> a triangle mesh with millions of triangles</p>
<p dir="auto"><strong>Output:</strong></p>
<ol dir="auto">
<li><a href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/include/nvclusterlod/nvclusterlod_mesh.h">nvclusterlod/nvclusterlod_mesh.h</a> - decimated clusters of the
original mesh, with groupings and relations to other groups</li>
<li><a href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/include/nvclusterlod/nvclusterlod_hierarchy.h">nvclusterlod/nvclusterlod_hierarchy.h</a> - a spatial
hierarchy of <em>cluster groups</em> to improve performance of runtime cluster
selection for rendering</li>
</ol>
<p dir="auto">To render, select <em>cluster groups</em> where:</p>
<ul dir="auto">
<li>Detail or decimation error of the group is small enough, relative to the camera</li>
<li>Detail or decimation error of the group's decimated geometry is not small enough</li>
</ul>
<p dir="auto">This is the gist, but the library also does some massaging of the values that
feed into these checks to make sure multiple LODs do not render over the top of
each other. See below.</p>
<p dir="auto">Geometry can be streamed in when needed to save memory.</p>
<p dir="auto"><strong>Table of Contents</strong></p>
<ul dir="auto">
<li><a href="#how-it-works">How it works</a>
<ul dir="auto">
<li><a href="#building-lods">Building LODs</a></li>
<li><a href="#selecting-clusters">Selecting Clusters</a></li>
<li><a href="#spatial-hierarchy">Spatial Hierarchy</a></li>
<li><a href="#streaming">Streaming</a></li>
<li><a href="#references">References</a></li>
</ul>
</li>
<li><a href="#usage-example">Usage Example</a></li>
<li><a href="#build-integration">Build Integration</a>
<ul dir="auto">
<li><a href="#dependencies">Dependencies</a></li>
</ul>
</li>
<li><a href="#license">License</a></li>
<li><a href="#limitations">Limitations</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">The key to continuous LOD is a decimation strategy that allows regular
watertight LOD transitions across a mesh. Such transitions require borders that
match on both sides, and are obtained by keeping the border of the triangle
edges fixed during decimation. Since these edges do not change, successive
iterations of decimation must choose different borders and fix new edges to let
the old ones decimate.</p>
<p dir="auto">To explain why, consider forming groups of triangles and decimating triangles
within. Then grouping the decimated groups and decimating again <em>recursively</em>
until there is just one root group. In this case, some of the vertices would
remain fixed across the entire hierarchy, and would be decimated only when the
last two groups are grouped and decimated to form the coarsest LOD. To avoid
this, new groups must instead be allowed to cross any border, and in fact
encouraged to.</p>
<p dir="auto">This library makes groups of geometry and decimates within <em>groups</em>. Decimated
geometry is then re-grouped, encouraging crossing the old group's borders when
forming new groups. Groups are made from clusters of triangle rather than just
triangles for performance reasons. A group is a cluster of clusters of
triangles. Whole triangle clusters are swapped in and out at runtime for detail
transitions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building LODs</h3><a id="user-content-building-lods" aria-label="Permalink: Building LODs" href="#building-lods"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/lod_generate.jpg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/lod_generate.jpg" width="600"></a></p>
<p dir="auto">The image above shows the process that is repeated to create LODs until there is
just a single cluster representing the whole mesh:</p>
<ol dir="auto">
<li>
<p dir="auto">Make clusters [, within old borders]</p>
<p dir="auto">This library uses
<a href="https://github.com/nvpro-samples/nv_cluster_builder">nv_cluster_builder</a>'
segmented API to make clusters of a fixed size from triangles within groups
of the previous iteration, or globally for the first iteration.</p>
</li>
<li>
<p dir="auto">Group clusters [, crossing old borders]</p>
<p dir="auto">This is just making clusters of clusters, but with a catch. Border edges
cannot decimate so it is important to encourage grouping clusters in a way to
keep old borders internal to the group. Then the previously locked edges are
free to decimate. This is done by adding a connection and weight between
clusters sharing many vertices (locked in particular) and optimizing for a
<em>minimum cut</em> when making cluster groups with
<a href="https://github.com/nvpro-samples/nv_cluster_builder">nv_cluster_builder</a>.</p>
<p dir="auto">If there is only one cluster in one group, the operation is complete.</p>
</li>
<li>
<p dir="auto">Decimate within groups, keep border</p>
<p dir="auto">Vertices shared between groups are computed and locked before using
<a href="https://github.com/zeux/meshoptimizer">meshoptimizer</a>'s <code>simplify</code> to
decimate each cluster group. The aim is to halve the number of triangles.
These become the input to the next iteration.</p>
</li>
</ol>
<p dir="auto">The code is documented and intended to be read too. These steps can be found in
<code>nvclusterlodMeshCreate()</code> at the bottom of
<a href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/src/nvclusterlod_mesh.cpp"><code>nvclusterlod_mesh.cpp</code></a>.</p>
<p dir="auto">When decimating, the generating group is tracked. This is the geometry each
cluster was decimated from. A cluster's group is one of many groups generated by
decimating its generating group. Similarly a group has many generating groups.
Clusters will be selected in intersections of groups and generating groups -
perhaps something to optimize the decision making with. The term <em>parent</em> is
avoided due to possible confusion between the originating geometry and the
direction to the root node.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/lod_dag.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/lod_dag.svg" alt=""></a></p>
<p dir="auto">The image above shows an example 2D illustration with colored groups, their
clusterings and relationships. Notably, two groups of clusters may produce
decimated clusters that are both part of a new group. This allows group borders
to be decimated after each iteration. The relationships form a directed acyclic
graph (DAG), i.e. not a tree, with the constraint that relationships don't skip
levels - but maybe that could help with uneven detail? LOD transitions may only
happen across group borders, which places a limit on the rate of LOD change.</p>
<p dir="auto">The output data are:</p>
<ul dir="auto">
<li>Clusters of triangles, referencing vertices in the original mesh</li>
<li>Groupings of clusters and their relationships:
<ul dir="auto">
<li>Generating geometry, input to decimation</li>
<li>Generated geometry, decimation output</li>
</ul>
</li>
<li>Group bounding spheres</li>
<li>Group decimation quadric error</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Selecting Clusters</h3><a id="user-content-selecting-clusters" aria-label="Permalink: Selecting Clusters" href="#selecting-clusters"></a></p>
<p dir="auto">The first step is to pick the goal. A couple of examples are:</p>
<ol dir="auto">
<li>Pixel-sized triangles?</li>
<li>Sub-pixel-sized geometric error?</li>
</ol>
<p dir="auto">The latter may be more efficient if for example large triangles give the same
visual result. This may be more challenging to quantify particularly if
decimation introduces error not captured by the metric. For the moment this
library uses <a href="https://www.cs.cmu.edu/~./garland/Papers/quadrics.pdf" rel="nofollow"><em>quadric
error</em></a>, an approximate
measure of the object-space distance between the decimated mesh and the original
high-resolution mesh. Inaccuracies from decimating vertex attributes such as
normals and UVs are currently ignored.</p>
<p dir="auto">A conservative maximum vertex position error is maintained for all cluster
groups. This is the farthest any vertex may be from representing the original
surface. When rendering we ask, "what is the largest possible angular error from
the camera?" for a particular group. We then want to render geometry when its
error is just less than a threshold, but not any overlapping geometry.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/arcsin_angular_error.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/arcsin_angular_error.svg" alt=""></a></p>
<p dir="auto">The farthest a decimated vertex may be incorrectly representing geometry is the
quadric error. This will be bigger in screen space nearer the camera so the
nearest point on the group's bounding sphere is chosen. The largest possible
angular error from the camera is then the angular size of a sphere with quadric
error radius at that point. Convenient and simple: the arcsine of the error
divided by the distance to the closest point on the bounding sphere. A target
threshold can be chosen based on a single pixel's FOV at the center of the
projection - to keep any geometric error less than the size of a pixel. This
avoids varying the threshold across the image, which would further complicate a
problem yet to solve.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/graph_cut.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/graph_cut.svg" alt=""></a></p>
<p dir="auto">We have a target goal and a way to compute it, but how can we guarantee a single
unique continuous surface? I.e. no holes and no overlaps. An ideal solution
would be to pick clusters that satisfy the angular error threshold but constrain
the rest to only making a single LOD transition per group. That would require
traversing the graph with its adjacency information, visualized above. The term
is a making graph cut and it would be challenging to do quickly and in parallel
on a GPU.</p>
<p dir="auto">We ideally want to test whether to render a cluster independently. We could
render geometry where its error is the first below the threshold, i.e. its
decimated error is greater. Just that would actually guarantee no holes, but
there would still be overlaps. E.g. two clusters that represent the same surface
being drawn at once. This can happen when the bounding sphere of a decimated
group is so far from the camera that its conservative angular error is smaller
than a group's angular error that it was decimated from.</p>
<p dir="auto">The solution implemented by this library is to artificially increase the size of
the bounding spheres such that the nearest point to the camera is always nearer
than that on a bounding sphere of its generating geometry. In short, make
bounding spheres bound generating geometry too. Once done, a single watertight
mesh can be stitched together from independent parallel decisions. In general,
the angular error, or whatever metric is compared to a threshold, must never
decrease with each level of decimation. The failure above was a decrease due to
the size distortion of a perspective projection.</p>
<p dir="auto">One derivation glossed over so far is why store bounding spheres and errors per
group. The simple answer is that for LOD transitions to work, the entire group
must change LOD at the same time, so all clusters in a group must share the same
values.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Spatial Hierarchy</h3><a id="user-content-spatial-hierarchy" aria-label="Permalink: Spatial Hierarchy" href="#spatial-hierarchy"></a></p>
<p dir="auto">This library provides a spatial hierarchy of bounding spheres to search for
cluster groups of the right LOD in the right spatial region relative to the
camera.</p>
<p dir="auto">One way to think of this is there are many high-detailed clusters and few low
detail. If an object is far away, only the low-detailed clusters should be
checked. That is, the search can exit early if it is known that all remaining
clusters are too detailed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/spatial_selection.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/spatial_selection.svg" alt=""></a></p>
<p dir="auto">Another way of thinking about this is at a certain distance range from the
camera, as shown in the image above, only clusters with certain bounding sphere
radii and quadric error ranges should be rendered. Thus, the search space can be
reduced by conservatively searching only that region. An r-tree could work well
here too.</p>
<p dir="auto">The hierarchy is actually a set of hierarchies - one for each LOD level. For
convenience, per-level roots are merged since the application would need to
search all levels anyway, or at least their roots.</p>
<p dir="auto">Leaf nodes point to cluster groups and are initialized with the group's
decimated cluster maximum quadric error (i.e. from the next level*) and the
group's bounding sphere. The hierarchy is built by recursively spatially
clustering nodes - not fast, but it works and it isn't a bottleneck yet.
Internal nodes are given the maximum quadric error and bounding sphere of their
children.</p>
<p dir="auto">*The group quadric error is the error of the generated group's clusters, i.e.
after decimation, not the error in the group's clusters. This avoids
unnecessarily storing a per-cluster error.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nvpro-samples/nv_cluster_lod_builder/blob/main/doc/hierarchy_selection.svg"><img src="https://github.com/nvpro-samples/nv_cluster_lod_builder/raw/main/doc/hierarchy_selection.svg" alt=""></a></p>
<p dir="auto">The tree can be traversed using the same angular error check as for cluster
groups, exiting when the node's error is less than the threshold. The trees for
LODs with too fine detail will exit early. The blue crosses in the above image
show an example - those nodes are already below the threshold. Since traversed
leaf nodes have already been checked to be above the threshold, and they are
initialized with cluster's generated group's error, their clusters only need to
check that they are below the threshold in order to select them for rendering.
Note that the entire group may not necessarily be drawn. For example, two of the
yellow clusters were not below the threshold (red cross). This same check is
made by the blue group's leaf node and blue clusters are drawn instead.</p>
<p dir="auto">While it is possible to exit early from a tree with too coarse detail, it may
interfere with streaming, depending on how dependencies are implemented.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Streaming</h3><a id="user-content-streaming" aria-label="Permalink: Streaming" href="#streaming"></a></p>
<p dir="auto">This is not a definitive how-to, but outlines some ideas for getting started
with streaming continuous LOD.</p>
<p dir="auto">The first feature needed for streaming is indirection - e.g. pointers to cluster
groups that are initially null and can be populated over time (outside of
cluster selection and rendering). Then, cluster groups in leaf nodes encountered
during hierarchy traversal must be marked and streamed in. Finally, minor
changes are needed for selecting clusters:</p>
<ul dir="auto">
<li>Obviously, don't traverse leaf nodes whose groups have not been loaded yet</li>
<li>Consider clusters to be below the threshold if their generating group has not been loaded</li>
</ul>
<p dir="auto">Choosing to keep lower detail geometry loaded greatly simplifies things. That
is, making sure decimated geometry is loaded first. This happens naturally due
to traversal order, but tracking dependencies host side may be needed if
streaming less than everything-at-once from traversal.</p>
<p dir="auto">Initially, streaming at the granularity of cluster groups and using the
generated group indices directly as dependencies is straight forward. Cluster
groups could also be combined for coarser streaming granularity, with a new set
of dependencies.</p>
<p dir="auto"><strong>Simple Streaming</strong></p>
<p dir="auto">Compute per-group needed flags during traversal. Emit load/unload events on
rising/falling edges. Fulfil those events in whole and set or unset the pointers
to the new data between traversal+rendering. Some filtering such as per-group
frame age may be useful to avoid frequently unloading and reloading groups.</p>
<p dir="auto"><strong>Continuous Streaming</strong></p>
<p dir="auto">The simple streaming above has less control over the amount streamed per batch.
This can be improved by adding batch size limits and queues. Note that by
partially streaming will require manually resolving dependency orders. Some
ideas are:</p>
<ol dir="auto">
<li>Limit the number of load/unload events emitted per frame</li>
<li>Add a global event queue
<ul dir="auto">
<li>Delay unloads and ignore pulses by comparing events at the front of the
queue with the most recent events inserted into the back of the queue.</li>
<li>Prioritise events by a detail metric so geometry loads evenly on screen</li>
</ul>
</li>
<li>Set a fixed memory limit (memory pool even) and/or fixed cluster/group count
<ul dir="auto">
<li>Prioritise loading until memory exhausted</li>
<li>Then only unload until memory reclaimed</li>
</ul>
</li>
<li>To maintain dependency loading in topological order, expand events after the global queue
<ul dir="auto">
<li>Recursively load generated groups first</li>
<li>Unload groups only if it is not a dependency of another group</li>
<li>The order of dependency resolution must not be changed after this step in the pipeline, but batches can still be formed</li>
</ul>
</li>
<li>Form batches during dependency loading
<ul dir="auto">
<li>The memory limit may be hit during dependency expansion</li>
<li>Must not include load/unload for same item in batch, assuming batches are
executed in parallel</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">References</h3><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<ul dir="auto">
<li><a href="https://ieeexplore.ieee.org/document/19053" rel="nofollow">(1989) A pyramidal data structure for triangle-based surface description</a></li>
<li><a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=3fa8c74a44f02aaaa18fe2d3cfdedfc9b8dbc50a" rel="nofollow">(1995) On Levels of Detail in Terrains</a></li>
<li><a href="https://dl.acm.org/doi/10.5555/288216.288222" rel="nofollow">(1998) Efficient Implementation of Multi-Triangulations</a></li>
<li><a href="https://ieeexplore.ieee.org/document/964533" rel="nofollow">(2001) Visualization of Large Terrains Made Easy</a></li>
<li><a href="https://ieeexplore.ieee.org/document/1532797" rel="nofollow">(2005) Batched Multi Triangulation</a></li>
<li><a href="https://advances.realtimerendering.com/s2021/Karis_Nanite_SIGGRAPH_Advances_2021_final.pdf" rel="nofollow">(2021) A Deep Dive into Unreal Engine's 5 Nanite</a> (<a href="https://www.youtube.com/watch?v=eviSykqSUUw" rel="nofollow">video</a>)</li>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/real-time-ray-tracing-of-micro-poly-geometry.html" rel="nofollow">(2023) Real-Time Ray Tracing of Micro-Poly Geometry with Hierarchical Level of Detail</a> (<a href="https://www.youtube.com/watch?v=Tx32yi_0ETY" rel="nofollow">video</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage Example</h2><a id="user-content-usage-example" aria-label="Permalink: Usage Example" href="#usage-example"></a></p>
<p dir="auto">For a complete usage example, see <a href="https://github.com/nvpro-samples/vk_lod_clusters">https://github.com/nvpro-samples/vk_lod_clusters</a>.</p>
<p dir="auto">To create LOD data with this library:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <nvclusterlod/nvclusterlod_hierarchy.h>
#include <nvclusterlod/nvclusterlod_hierarchy_storage.hpp>
#include <nvclusterlod/nvclusterlod_mesh.h>
#include <nvclusterlod/nvclusterlod_mesh_storage.hpp>

...

// Create contexts for running operations
nvcluster::Context context;
nvcluser::ContextCreateInfo contextCreateInfo{};
nvclusterCreateContext(&amp;contextCreateInfo, &amp;context);

nvclusterlod::Context lodContext;
nvclusterlod::ContextCreateInfo lodContextCreateInfo{.clusterContext = context};
nvclusterlodCreateContext(&amp;lodContextCreateInfo, &amp;lodContext);

// Input mesh
std::vector<uint32_t> indices   = ...;
std::vector<vec3>     positions = ...;

// Create decimated clusters
const nvclusterlod::MeshInput meshInput{
    // Mesh data
    .indices      = indices.data(),
    .indexCount   = static_cast<uint32_t>(indices.size()),
    .vertices     = reinterpret_cast<const float*>(positions.data()),
    .vertexOffset = 0,
    .vertexCount  = static_cast<uint32_t>(positions.size()),
    .vertexStride = sizeof(vec3),
    // Use default configurations and decimation factor:
    .clusterConfig = {},
    .clusterGroupConfig = {},
    .decimationFactor = 0.5,
};

nvclusterlod::LocalizedLodMesh mesh;
nvclusterlod::generateLocalizedLodMesh(lodContext, meshInput, mesh);

// Build a spatial hierarchy for faster selection
const nvclusterlod::HierarchyInput hierarchyInput {
    .clusterGeneratingGroups = mesh.lodMesh.clusterGeneratingGroups.data(),
    .groupQuadricErrors      = mesh.lodMesh.groupQuadricErrors.data(),
    .groupClusterRanges      = mesh.lodMesh.groupClusterRanges.data(),
    .groupCount              = static_cast<uint32_t>(mesh.lodMesh.groupClusterRanges.size()),
    .clusterBoundingSpheres  = mesh.lodMesh.clusterBoundingSpheres.data(),
    .clusterCount            = static_cast<uint32_t>(mesh.lodMesh.clusterBoundingSpheres.size()),
    .lodLevelGroupRanges     = mesh.lodMesh.lodLevelGroupRanges.data(),
    .lodLevelCount           = static_cast<uint32_t>(mesh.lodMesh.lodLevelGroupRanges.size())
};

nvclusterlod::LodHierarchy hierarchy;
nvclusterlod::generateLodHierarchy(lodContext, hierarchyInput, hierarchy);

// Upload mesh and hierarchy to the GPU. These are both simple structures of arrays.
..."><pre>#<span>include</span> <span><span>&lt;</span>nvclusterlod/nvclusterlod_hierarchy.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>nvclusterlod/nvclusterlod_hierarchy_storage.hpp<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>nvclusterlod/nvclusterlod_mesh.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>nvclusterlod/nvclusterlod_mesh_storage.hpp<span>&gt;</span></span>

...

<span><span>//</span> Create contexts for running operations</span>
nvcluster::Context context;
nvcluser::ContextCreateInfo contextCreateInfo{};
<span>nvclusterCreateContext</span>(&amp;contextCreateInfo, &amp;context);

nvclusterlod::Context lodContext;
nvclusterlod::ContextCreateInfo lodContextCreateInfo{.<span>clusterContext</span> = context};
<span>nvclusterlodCreateContext</span>(&amp;lodContextCreateInfo, &amp;lodContext);

<span><span>//</span> Input mesh</span>
std::vector&lt;<span>uint32_t</span>&gt; indices   = ...;
std::vector&lt;vec3&gt;     positions = ...;

<span><span>//</span> Create decimated clusters</span>
<span>const</span> nvclusterlod::MeshInput meshInput{
    <span><span>//</span> Mesh data</span>
    .<span>indices</span>      = indices.<span>data</span>(),
    .<span>indexCount</span>   = <span>static_cast</span>&lt;<span>uint32_t</span>&gt;(indices.<span>size</span>()),
    .<span>vertices</span>     = <span>reinterpret_cast</span>&lt;<span>const</span> <span>float</span>*&gt;(positions.<span>data</span>()),
    .<span>vertexOffset</span> = <span>0</span>,
    .<span>vertexCount</span>  = <span>static_cast</span>&lt;<span>uint32_t</span>&gt;(positions.<span>size</span>()),
    .<span>vertexStride</span> = <span>sizeof</span>(vec3),
    <span><span>//</span> Use default configurations and decimation factor:</span>
    .<span>clusterConfig</span> = {},
    .<span>clusterGroupConfig</span> = {},
    .<span>decimationFactor</span> = <span>0.5</span>,
};

nvclusterlod::LocalizedLodMesh mesh;
<span>nvclusterlod::generateLocalizedLodMesh</span>(lodContext, meshInput, mesh);

<span><span>//</span> Build a spatial hierarchy for faster selection</span>
<span>const</span> nvclusterlod::HierarchyInput hierarchyInput {
    .<span>clusterGeneratingGroups</span> = mesh.<span>lodMesh</span>.<span>clusterGeneratingGroups</span>.<span>data</span>(),
    .<span>groupQuadricErrors</span>      = mesh.<span>lodMesh</span>.<span>groupQuadricErrors</span>.<span>data</span>(),
    .<span>groupClusterRanges</span>      = mesh.<span>lodMesh</span>.<span>groupClusterRanges</span>.<span>data</span>(),
    .<span>groupCount</span>              = <span>static_cast</span>&lt;<span>uint32_t</span>&gt;(mesh.<span>lodMesh</span>.<span>groupClusterRanges</span>.<span>size</span>()),
    .<span>clusterBoundingSpheres</span>  = mesh.<span>lodMesh</span>.<span>clusterBoundingSpheres</span>.<span>data</span>(),
    .<span>clusterCount</span>            = <span>static_cast</span>&lt;<span>uint32_t</span>&gt;(mesh.<span>lodMesh</span>.<span>clusterBoundingSpheres</span>.<span>size</span>()),
    .<span>lodLevelGroupRanges</span>     = mesh.<span>lodMesh</span>.<span>lodLevelGroupRanges</span>.<span>data</span>(),
    .<span>lodLevelCount</span>           = <span>static_cast</span>&lt;<span>uint32_t</span>&gt;(mesh.<span>lodMesh</span>.<span>lodLevelGroupRanges</span>.<span>size</span>())
};

nvclusterlod::LodHierarchy hierarchy;
<span>nvclusterlod::generateLodHierarchy</span>(lodContext, hierarchyInput, hierarchy);

<span><span>//</span> Upload mesh and hierarchy to the GPU. These are both simple structures of arrays.</span>
...</pre></div>
<p dir="auto"><strong>Rendering whole levels of detail</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// For each LOD level (highest detail first)
for(size_t lod = 0; lod < mesh.lodMesh.lodLevelGroupRanges.size(); lod++)
{
    const nvcluster::Range&amp; lodLevelGroupRange = mesh.lodMesh.lodLevelGroupRanges[lod];
    glBegin(GL_TRIANGLES);  // Naive OpenGL immediate mode just for illustration

    // For each group
    for(uint32_t groupIndex = lodLevelGroupRange.offset; groupIndex < lodLevelGroupRange.offset + lodLevelGroupRange.count; groupIndex++)
    {
        const nvcluster::Range&amp; groupClusterRange = mesh.lodMesh.groupClusterRanges[groupIndex];

        // For each cluster
        for(uint32_t clusterIndex = groupClusterRange.offset; clusterIndex < groupClusterRange.offset + groupClusterRange.count; clusterIndex++)
        {
            const nvcluster::Range&amp; clusterTriangleRange = mesh.lodMesh.clusterTriangleRanges[clusterIndex];
            const nvcluster::Range&amp; clusterVertexRange   = mesh.clusterVertexRanges[clusterIndex];

            // Can use this to pre-compute a per-cluster vertex array
            const uint32_t* clusterVertexGlobalIndices = &amp;mesh.vertexGlobalIndices[clusterVertexRange.offset];

            // For each triangle
            for(uint32_t triangleIndex = clusterTriangleRange.offset; triangleIndex < clusterTriangleRange.offset + clusterTriangleRange.count; triangleIndex++)
            {
                // For each triangle vertex
                for (uint32_t vertex = 0; vertex < 3; ++vertex)
                {
                    uint32_t localVertexIndex  = mesh.lodMesh.triangleVertices[3 * triangleIndex + vertex];
                    uint32_t globalVertexIndex = clusterVertexGlobalIndices[localVertexIndex];
                    glVertex3fv(glm::value_ptr(positions[globalVertexIndex]));
                }
            }
        }
    }
    glEnd();
}"><pre><span><span>//</span> For each LOD level (highest detail first)</span>
<span>for</span>(<span>size_t</span> lod = <span>0</span>; lod &lt; mesh.lodMesh.lodLevelGroupRanges.size(); lod++)
{
    <span>const</span> nvcluster::Range&amp; lodLevelGroupRange = mesh.<span>lodMesh</span>.<span>lodLevelGroupRanges</span>[lod];
    <span>glBegin</span>(GL_TRIANGLES);  <span><span>//</span> Naive OpenGL immediate mode just for illustration</span>

    <span><span>//</span> For each group</span>
    <span>for</span>(<span>uint32_t</span> groupIndex = lodLevelGroupRange.<span>offset</span>; groupIndex &lt; lodLevelGroupRange.<span>offset</span> + lodLevelGroupRange.<span>count</span>; groupIndex++)
    {
        <span>const</span> nvcluster::Range&amp; groupClusterRange = mesh.<span>lodMesh</span>.<span>groupClusterRanges</span>[groupIndex];

        <span><span>//</span> For each cluster</span>
        <span>for</span>(<span>uint32_t</span> clusterIndex = groupClusterRange.<span>offset</span>; clusterIndex &lt; groupClusterRange.<span>offset</span> + groupClusterRange.<span>count</span>; clusterIndex++)
        {
            <span>const</span> nvcluster::Range&amp; clusterTriangleRange = mesh.<span>lodMesh</span>.<span>clusterTriangleRanges</span>[clusterIndex];
            <span>const</span> nvcluster::Range&amp; clusterVertexRange   = mesh.<span>clusterVertexRanges</span>[clusterIndex];

            <span><span>//</span> Can use this to pre-compute a per-cluster vertex array</span>
            <span>const</span> <span>uint32_t</span>* clusterVertexGlobalIndices = &amp;mesh.<span>vertexGlobalIndices</span>[clusterVertexRange.<span>offset</span>];

            <span><span>//</span> For each triangle</span>
            <span>for</span>(<span>uint32_t</span> triangleIndex = clusterTriangleRange.<span>offset</span>; triangleIndex &lt; clusterTriangleRange.<span>offset</span> + clusterTriangleRange.<span>count</span>; triangleIndex++)
            {
                <span><span>//</span> For each triangle vertex</span>
                <span>for</span> (<span>uint32_t</span> vertex = <span>0</span>; vertex &lt; <span>3</span>; ++vertex)
                {
                    <span>uint32_t</span> localVertexIndex  = mesh.<span>lodMesh</span>.<span>triangleVertices</span>[<span>3</span> * triangleIndex + vertex];
                    <span>uint32_t</span> globalVertexIndex = clusterVertexGlobalIndices[localVertexIndex];
                    <span>glVertex3fv</span>(<span>glm::value_ptr</span>(positions[globalVertexIndex]));
                }
            }
        }
    }
    <span>glEnd</span>();
}</pre></div>
<p dir="auto"><strong>Selecting clusters</strong></p>
<p dir="auto">It is intended clusters are rendered based on their quadric error, a measure of
geometric accuracy. A threshold in error over distance [to the camera] is chosen</p>
<ul dir="auto">
<li>the arcsine of which would be the angular error. This could be converted to a
screen space pixel size, but for ray tracing where there are shadows and
reflections behind the camera, a pure distance metric is a good start.</li>
</ul>
<p dir="auto">To form a single unique surface with clusters of the right LOD, render clusters
where:</p>
<div dir="auto" data-snippet-clipboard-copy-content="errorOverDistance(
        objectToEyeTransform,
        hierarchy.groupCumulativeBoundingSpheres[clusterGroup],
        hierarchy.groupCumulativeQuadricError[clusterGroup]
    ) >= threshold
&amp;&amp;
errorOverDistance(
        objectToEyeTransform,
        hierarchy.groupCumulativeBoundingSpheres[clusterGeneratingGroup],
        hierarchy.groupCumulativeQuadricError[clusterGeneratingGroup]
    ) < threshold"><pre><span>errorOverDistance</span>(
        objectToEyeTransform,
        hierarchy.groupCumulativeBoundingSpheres[clusterGroup],
        hierarchy.groupCumulativeQuadricError[clusterGroup]
    ) &gt;= threshold
&amp;&amp;
errorOverDistance(
        objectToEyeTransform,
        hierarchy.groupCumulativeBoundingSpheres[clusterGeneratingGroup],
        hierarchy.groupCumulativeQuadricError[clusterGeneratingGroup]
    ) &lt; threshold</pre></div>
<p dir="auto">The <code>clusterGeneratingGroup</code> is the group from which a cluster was generated by
decimation. E.g. decimating the "generating" group of clusters <em>generates</em>
another a new smaller set of clusters.</p>
<p dir="auto">The <code>groupCumulativeQuadricError</code> is actually the error after its geometry is
decimated, not the error of the group itself's clusters. This value doesn't
exist at the group level, which is the reason for the surprise. The above
conditions gives a band in which cluster are chosen. Their group's decimated
geometry (first check) is closest to but not exceeding the threshold. Their
geometry (second check) does exceed the threshold so they are first past the
threshold. This holds true given some massaging of the bounding spheres to
guarantee the decimated geometry will always pass the threshold before the
geometry itself.</p>
<p dir="auto">The <code>groupCumulativeBoundingSpheres</code> conservatively include their generating
group's bounding spheres. This guarantees that clusters from multiple levels
cannot be rendered at once.</p>
<p dir="auto"><strong>Spatial hierarchy</strong></p>
<p dir="auto">Performing a test per cluster would be expensive. Even only testing every unique
group--generating-group pair. This library creates a spatial hierarchy of
bounding spheres to reduce the search space.</p>
<p dir="auto"><code>hierarchy.nodes</code> contains a tree of all clusters. The first node is the root
node. Simply descend while the following condition holds and check all cluster
range nodes when found. It's actually a combination of hierarchies for each LOD
level. The way it works is described below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="errorOverDistance(
        objectToEyeTransform,
        node.boundingSphere,
        node.maxClusterQuadricError
    ) >= threshold"><pre><span>errorOverDistance</span>(
        objectToEyeTransform,
        node.boundingSphere,
        node.maxClusterQuadricError
    ) &gt;= threshold</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build Integration</h2><a id="user-content-build-integration" aria-label="Permalink: Build Integration" href="#build-integration"></a></p>
<p dir="auto">This library uses CMake and requires C++20. It is currently a static
library, designed with C compatibility in mind with data passed as a structure
of arrays and output allocated by the user. Integration has been verified by
directly including it with <code>add_subdirectory</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="add_subdirectory(nv_cluster_lod_builder)
...
target_link_libraries(my_target PUBLIC nv_cluster_lod_builder)"><pre><span>add_subdirectory</span>(nv_cluster_lod_builder)
...
<span>target_link_libraries</span>(my_target <span>PUBLIC</span> nv_cluster_lod_builder)</pre></div>
<p dir="auto">If there is interest, please reach out for CMake config files (for
<code>find_package()</code>) or any other features. GitHub issues are welcome.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dependencies</h3><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<p dir="auto">nv_cluster_lod_builder depends upon
<a href="https://github.com/nvpro-samples/nv_cluster_builder">nv_cluster_builder</a> and
<a href="https://github.com/zeux/meshoptimizer">meshoptimizer</a>, which are submodules. To
download them, run</p>
<div data-snippet-clipboard-copy-content="git submodule update --init --recursive"><pre><code>git submodule update --init --recursive
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This library and
<a href="https://github.com/nvpro-samples/nv_cluster_builder">nv_cluster_builder</a> are
licensed under the <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">Apache License
2.0</a>.</p>
<p dir="auto">This library uses third-party dependencies, which have their own:</p>
<ul dir="auto">
<li><a href="https://github.com/zeux/meshoptimizer">meshoptimizer</a>, licensed under the
<a href="https://github.com/zeux/meshoptimizer/blob/47aafa533b439a78b53cd2854c177db61be7e666/LICENSE.md">MIT License</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<p dir="auto">This library is intended to enable a quick start to continuous LOD. It
demonstrates the basics for use as a learning tool or a placeholder.</p>
<p dir="auto">Cluster and cluster group quality includes the limitations outlined in
<a href="https://github.com/nvpro-samples/nv_cluster_builder">nv_cluster_builder</a>.</p>
<p dir="auto">The number of triangles per cluster is configurable, but the vertex count is
unconstrained. There are plans to address this, but for now it is possible that
the 256 vertex limit of <code>VK_NV_cluster_acceleration_structure</code> may be exceeded.</p>
<p dir="auto">The decimation step uses <a href="https://github.com/zeux/meshoptimizer">meshoptimizer</a>
for its lightweight convenience. This step is internal and not configurable.
Texture seams are not preserved and in general vertex attributes are yet to be
plumbed through.</p>
<p dir="auto">Performance is limited by the clustering and decimation algorithms that run on
the CPU, although there is some parallelization.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OWASP Non-Human Identities Top 10 (141 pts)]]></title>
            <link>https://owasp.org/www-project-non-human-identities-top-10/2025/</link>
            <guid>42928645</guid>
            <pubDate>Tue, 04 Feb 2025 06:07:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://owasp.org/www-project-non-human-identities-top-10/2025/">https://owasp.org/www-project-non-human-identities-top-10/2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42928645">Hacker News</a></p>
Couldn't get https://owasp.org/www-project-non-human-identities-top-10/2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Alibaba/T-HEAD's Xuantie C910 (212 pts)]]></title>
            <link>https://chipsandcheese.com/p/alibabat-heads-xuantie-c910</link>
            <guid>42928482</guid>
            <pubDate>Tue, 04 Feb 2025 05:40:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/alibabat-heads-xuantie-c910">https://chipsandcheese.com/p/alibabat-heads-xuantie-c910</a>, See on <a href="https://news.ycombinator.com/item?id=42928482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>T-HEAD is a wholly owned subsidiary of Alibaba, one of China's largest tech companies. Over the past few years, T-HEAD has created a line of RISC-V cores. Alibaba seems to have two motivations for pushing RISC-V. On one hand, the company stands to benefit from creating cost effective chips optimized for areas it cares about, like IoT endpoints and edge computing. On the other, Alibaba almost certainly wants to reduce its dependence on foreign imports. RISC-V is an open instruction set, and isn't controlled by US or British corporations like x86-64 or ARM. T-HEAD's RISC-V push can thus be seen more broadly as a part of China's push to create viable domestic microchips.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png" width="1456" height="815" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:815,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d7bf8f2-eda4-43cf-b2c2-fb01be36bb36_1492x835.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Xuantie C910 slots into the "high performance" category within T-HEAD's lineup. Besides joining a small number of out-of-order RISC-V cores that have made it into hardware, C910 is an early adopter for RISC-V's vector extension. It supports RVV 0.7.1, which features masking and variable vector length support. T-HEAD has since released the C920 core, which brings RVV support up to version 1.0, but otherwise leaves C910 unchanged.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png" width="1162" height="693" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:693,&quot;width&quot;:1162,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:902869,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818561ec-96b1-4080-9be0-388224f7b72e_1162x693.png 1456w" sizes="100vw"></picture></div></a><figcaption>From Alibaba's paper, with descriptions added in red by Clam. PIU and PLIC appear in the dual core diagram below.</figcaption></figure></div><p><span>C910 targets "AI, Edge servers, Industrial control, [and] ADAS" as possible applications. It's also T-HEAD's first generation out-of-order design, so taking on all those applications is ambitious. C910 is implemented in clusters of up to four cores, each with a shared L2 cache. T-HEAD targets 2 to 2.5 GHz on TSMC's 12nm FinFET process, where a C910 core occupies 0.8 mm</span><sup>2</sup><span>. Core voltage is 0.8V at 2 GHz, and 1.0V at 2.5 GHz. On TSMC's 7nm process, T-HEAD managed to push core frequency to 2.8 GHz. T-HEAD's paper further claims dynamic power is around 100 microwatts/MHz, which works out to 0.2W at 2 GHz. Of course, this figure doesn't include static power or power draw outside the core. Yet all of these characteristics together make clear C910 is a low power, low area design.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png" width="631" height="489" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:489,&quot;width&quot;:631,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:521240,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e13f891-3cca-494d-83e0-ae2c6d151968_631x489.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>This article will examine C910 in the T-HEAD TH1520, using the LicheePi single board computer. TH1520 is fabricated on TSMC’s 12nm FinFET process, and has a quad-core C910 cluster with 1 MB of L2 running at 1.85 GHz. It’s connected to 8 GB of LPDDR4X-3733. C910 has been </span><a href="https://github.com/XUANTIE-RV/openc910" rel="">open-sourced</a><span>, so I’ll be attempting to dig deeper into core details by reading some of the source code – but with some disclaimers. I’m a software engineer, not a hardware engineer. Also, some of the code is likely auto-generated from another undisclosed source, so reading that code has been a time consuming and painful experience. Expect some mistakes along the way.</span></p><p>The Xuantie C910 is a 3-wide, out-of-order core with a 12 stage pipeline.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png" width="554" height="534" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:534,&quot;width&quot;:554,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:119429,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd200284d-a30a-4892-a4d8-d098f9c6eb8c_554x534.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Like Arm’s Cortex A73, C910 can release out-of-order resources early. For microbenchmarking, I used both a dependent branch and incomplete load to block retire, just as I did on A73.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png" width="871" height="831" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:831,&quot;width&quot;:871,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:289428,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53c49f62-f8f8-4c55-a8f2-38419c377b8a_871x831.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>C910’s frontend is tailored to handle both 16-bit and 32-bit RISC-V instructions, along with the requirements of RISC-V’s vector extension. The core has a 64 KB, 2-way set associative instruction cache with a FIFO replacement policy. Besides caching instruction data, C910 stores four bits of predecode data for each possible 16-bit instruction slot. Two bits tentatively indicate whether an instruction starts at that position, while the other two provide branch info. In total, C910 uses 83.7 KB of raw bit storage for instruction caching.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png" width="560" height="608" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4484e263-a65c-42f9-86da-3b66d614a545_560x608.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:608,&quot;width&quot;:560,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109919,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4484e263-a65c-42f9-86da-3b66d614a545_560x608.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>An L1i access reads instruction bytes, predecode data, and tags from both ways. Thus, the instruction fetch (IF) stage brings 256 bits of instruction bytes into temporary registers alongside 64 bits of predecode data. Tags for both ways are checked to determine which way has a L1i hit, if any. Simultaneously, the IF stage checks a 16 entry, fully associative L0 BTB, which lets the core handle a small number of taken branches with effectively single cycle latency.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png" width="1320" height="834" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:834,&quot;width&quot;:1320,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:241802,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88caa9ec-fceb-4c38-86aa-db2c89e6a4a5_1320x834.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Rough, simplified sketch of C910’s frontend</figcaption></figure></div><p><span>Instruction bytes and predecode data from both ways are passed to the next Instruction Pack (IP) stage. All of that is fed into a pair of 8-wide early decode blocks, called IP decoders in </span><a href="https://github.com/XUANTIE-RV/openc910/blob/main/C910_RTL_FACTORY/gen_rtl/ifu/rtl/ct_ifu_ipdecode.v" rel="">the source code</a><span>. Each of the 16 early decode slots handles a possible instruction start position at a 16-bit boundary, across both ways. These early decoders do simple checks to categorize instructions. For vector instructions, the IP decoders also figure out VLEN (vector length), VSEW (selected element width), and VLMAX (number of elements).</span></p><p>Although the IP stage consumes 256 bits of instruction data and 64 bits of predecode data, and process all of that with 16 early decode slots, half of that is always discarded because the L1i can only hit in one way. Output from the 8-wide decode block that processed the correct way is passed to the next stage, while output from the other 8-wide decoder is discarded.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png" width="461" height="484" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:484,&quot;width&quot;:461,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:88646,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10582ce7-1c83-4f8b-9d57-18e9d7c20e22_461x484.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>C910’s main branch predictor mechanisms also sit at the IP stage. Conditional branches are handled with a </span><a href="https://people.eecs.berkeley.edu/~kubitron/courses/cs152-S04/handouts/papers/p4-lee.pdf" rel="">bi-mode predictor</a><span>, with a 1024 entry selection table, two 16384 entry history tables containing 2-bit counters, and a 22-bit global history register. The selection table is indexed by hashing the low bits of the branch address and global history register, while the history tables are indexed by hashing the high hits of the history register. Output from the selection table is used to pick between the two history tables, labeled “taken” and “ntaken”. Returns are handled using a 12 entry return stack, while a 256 entry indirect target array handles indirect branches. In all, the branch predictor uses approximately 17.3 KB of storage. It’s therefore a small branch predictor by today’s standards, well suited to C910’s low power and low area design goals. For perspective, a high performance core like Qualcomm’s Oryon uses 80 KB for its conditional (direction) predictor alone, and another 40 KB for the indirect predictor.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png" width="1434" height="717" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:717,&quot;width&quot;:1434,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:347631,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F638c7314-8c3e-4fae-941a-d076d168ee05_1434x717.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Testing with random patterns of various lengths shows C910 can deal with moderately long patterns. It’s in line with what I’ve seen this test do with other low power cores. Both C910 and A73 struggle when there are a lot of branches in play, though they can maintain reasonably good accuracy for a few branches without excessively long history.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png" width="1217" height="604" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:604,&quot;width&quot;:1217,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:255087,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35651277-2b6a-4946-ae02-6d7f4331de58_1217x604.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>C910’s main BTB has 1024 entries and is 4-way set associative. Redirecting the pipeline from the IP stage creates a single pipeline bubble, or effectively 2 cycle taken branch latency. Branches that spill out of the 1024 entry BTB have 4 cycle latency, as long as code stays within the instruction cache.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png" width="1158" height="579" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:579,&quot;width&quot;:1158,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:104282,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e513772-cc3c-4bf5-9b31-363197df8642_1158x579.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The Instruction Pack stage feeds up to eight 16-bit instructions along with decoder output into the next Instruction Buffer (IB) stage. This stage’s job is to smooth out instruction delivery, covering any hiccups in frontend bandwidth as best as it can. To do this, the IB stage has a 32 entry instruction queue and a separate 16 entry loop buffer. Both have 16-bit entries, so 32-bit instructions will take two slots. C910’s loop buffer serves the same purpose as Pentium 4’s trace cache, seeking to fill in lost frontend slots after a taken branch. Of course, a 16 entry loop buffer can only do this for the smallest of loops.</p><p>To feed the subsequent decode stage, the IB stage can pick instructions from the loop buffer, instruction queue, or a bypass path to reduce latency if queuing isn’t needed. Each instruction and its associated early decode metadata are packed into a 73-bit format, and sent to the decode stage.</p><p>The Instruction Decode (ID) stage contains C910’s primary decoders. Three 73-bit inputs from the IP stage are fed into these decoders, which parse out register info and splits instructions into multiple micro-ops if necessary.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png" width="932" height="549" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:549,&quot;width&quot;:932,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:123565,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f38a092-19e1-400a-8534-6a0fbbfdb100_932x549.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Only the first decode slot can handle instructions that decode into four or more micro-ops. All decode slots can emit 1-2 micro-ops for simpler instructions, though the decode stage in total can’t emit more than four micro-ops per cycle. Output micro-ops are packed into a 178-bit format, and passed directly to the rename stage. C910 does not have a micro-op queue between the decoders and renamers like many other cores. Rename width and decoder output width therefore have to match, explaining why the renamer is 4-wide and why the decoders are restricted to 4 micro-ops per cycle. Any instruction that decoders into four or more micro-ops will block parallel decode.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp" width="915" height="2048" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2048,&quot;width&quot;:915,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:113796,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e48188e-a77c-4005-b666-c0e9840059d9_915x2048.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Notes on micro-op format</figcaption></figure></div><p>C910’s instruction rename (IR) stage then checks for matches between architectural registers to find inter-instruction dependencies. It then assigns free registers out of the respective pool (integer or FP registers), or by picking newly deallocated registers coming off the retire stage. The IR stage does further decoding too. Instructions are further labeled with whether they’re a multi-cycle ALU operation, which ports they can go to, and so on. After renaming, micro-ops are 271 bits.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png" width="1417" height="666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:666,&quot;width&quot;:1417,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:119397,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61bac17-e4ce-4a25-a3e5-d3403fa3c9e8_1417x666.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>From software, C910’s frontend can sustain 3 instructions per cycle as long as code fits within the 64 KB instruction cache. L2 code bandwidth is low at under 1 IPC. SiFive’s P550 offers more consistent frontend bandwidth for larger code footprints, and can maintain 1 IPC even when running code from L3.</p><p><span>C910’s backend uses a physical register file (PRF) based out-of-order execution scheme, where both pending and known-good instruction results are stored in register files separate from the ROB. </span><a href="https://github.com/XUANTIE-RV/openc910/blob/main/C910_RTL_FACTORY/gen_rtl/rtu/rtl/ct_rtu_rob.v" rel="">C910’s source code (</a><code>ct_rtu_rob.v</code><a href="https://github.com/XUANTIE-RV/openc910/blob/main/C910_RTL_FACTORY/gen_rtl/rtu/rtl/ct_rtu_rob.v" rel="">)</a><span> defines 64 ROB entries, but T-HEAD’s paper says the ROB can hold up to 192 instructions. Microbenchmarking generally agrees.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png" width="563" height="334" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:334,&quot;width&quot;:563,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:46890,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96f26b67-038b-48ff-b4ee-afceb504ae5d_563x334.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Therefore, C910 has reorder buffer capacity on par with Intel’s Haswell from 2013, theoretically letting it keep more instructions in flight than P550 or Goldmont Plus. However, other structures are not appropriately sized to make good use of that ROB capacity.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png" width="943" height="478" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:478,&quot;width&quot;:943,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:66006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b02680-bf6a-4a2e-8c5e-cac02b780314_943x478.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>RISC-V has 32 integer and 32 floating point registers, so 32 entries in each register file generally have to be reserved for holding known-good results. That leaves only 64 integer and 32 floating point registers to hold results for in-flight instructions. Intel’s Haswell supports its 192 entry ROB with much larger register files on both the integer and floating point side.</p><p>C910 has eight execution ports. Two ports on the scalar integer side handle the most common ALU operations, while a third is dedicated to branches. C910’s integer register file has 10 read ports to feed five execution pipes, which includes three pipes for handling memory operations. A distributed scheduler setup feeds C910’s execution ports. Besides the opcode and register match info, each scheduler entry has a 7-bit age vector to enable age-based prioritization.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png" width="588" height="262" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:262,&quot;width&quot;:588,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53837,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5ef93ba-7e33-43ca-9d3d-f4bc2eefd31d_588x262.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Scheduler capacity is low compared to Goldmont Plus and P550, with just 16 entries available for the most common ALU operations. P550 has 40 scheduler entries available across its three ALU ports, while Goldmont Plus has 30 entries.</p><p>C910’s FPU has a simple dual pipe design. Both ports can handle the most common floating point operations like adds, multiplies, and fused multiply. Both pipes can handle 128-bit vector operations too. Feeding each port requires up to four inputs from the FP/vector register file. A fused multiply instruction (a*b+c) requires three inputs. A fourth input provides a mask register. Unlike AVX-512 and SVE, RISC-V doesn’t define separate mask registers, so all inputs have to come from the FP/vector register file. Therefore, C910’s FP register file has almost as many read ports as the integer one, despite feeding fewer ports.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png" width="357" height="238" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:238,&quot;width&quot;:357,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31756,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda4eb4-e6dd-44fa-bd55-27729b87210f_357x238.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Floating point execution latency is acceptable, and ranges from 3 to 5 cycles for the most common operations. Some recent cores like Arm’s Cortex X2, Intel’s Golden Cove, and AMD’s Zen 5 can do FP addition with 2 cycle latency. I don’t expect that from a low power core though.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png" width="867" height="220" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:220,&quot;width&quot;:867,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23084,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d94075-0d6c-4262-8e2b-b3da99d22c62_867x220.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Two address generation units (AGUs) on C910 calculate effective addresses for memory accesses. One AGU handles loads, while the other handles stores. C910’s load/store unit is generally split into two pipelines, and aims to handle up to one load and one store per cycle. Like many other cores, store instructions are broken into a store address and a store data micro-op.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png" width="526" height="507" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:507,&quot;width&quot;:526,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:111848,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eaf51b5-7221-469f-8c1e-4eabe737a772_526x507.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>From Alibaba’s paper</figcaption></figure></div><p>39-bit virtual addresses are then generated into 40-bit physical addresses. C910’s L1 DTLB has 17 entries and is fully associative. A 1024 entry, 4-way L2 TLB handles L1 TLB misses for both data and instruction accesses, and adds 4 cycles latency over a L1 hit. Physically, the L2 TLB has two banks, both 256×84 SRAM instances. The tag array is a 256×196 bit SRAM instance, and a 196-bit access includes tags for all four ways along with four “FIFO” bits, possibly used to implement a FIFO replacement policy. Besides necessary info like the virtual page number and a valid bit, each tag includes an address space ID and a global bit. These can exempt an entry from certain TLB flushes, reducing TLB thrashing on context switches. In total, the L2 TLB’s tags and data require 8.96 KB of bit storage.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png" width="522" height="166" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:166,&quot;width&quot;:522,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7ef3812-c2ae-438b-af84-1ae0c1011204_522x166.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Physical addresses are written into the load and store queues, depending on whether the address is a load or store. I’m not sure how big the load queue is. C910’s source code suggests there are 12 entries, and microbenchmarking results are confusing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png" width="817" height="443" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:443,&quot;width&quot;:817,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:71886,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75acae07-5e1b-4b9b-ae68-30c8ddb1089d_817x443.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the source code, each load queue entry stores 36 bits of the load’s physical address along with 16 bits to indicate which bits are valid, and a 7-bit instruction id to ensure proper ordering. A store queue entry stores the 40-bit physical address, pending store data, 16 byte valid bits, a 7-bit instruction id, and a ton of other fields. To give some examples:</p><ul><li><p>wakeup_queue: 12 bits, possibly indicates which dependent loads should be woken up when data is ready</p></li><li><p>sdid: 4 bits, probably store data id</p></li><li><p>age_vec, age_vec_1: 12 bit age vectors, likely for tracking store order</p></li></ul><p>To check for memory dependencies, the load/store unit compares bits 11:4 of the memory address. From software testing, C910 can do store forwarding for any load completely contained within the store, regardless of alignment within the store. However, forwarding fails if a load crosses a 16B aligned boundary, or a store crosses a 8B aligned boundary. Failed store forwarding results in a 20+ cycle penalty.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp" width="1456" height="717" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:717,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1697102,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb73fedc-d6e8-4202-a6db-732719fe0ffa_2560x1261.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>C910 handles unaligned accesses well, unlike P550. If a load doesn’t cross a 16B boundary or a store doesn’t cross a 8B boundary, it’s basically free. If you do cross those alignment boundaries, you don’t face a performance penalty beyond making an extra L1D access under the hood. Overall, C910’s load/store unit and forwarding behavior is a bit short of the most recent cores from Intel and AMD. But it’s at about the same level as AMD’s Piledriver, a very advanced and high performance core in its own right. That’s a good place to be.</p><p>The 64 KB, 2-way data cache has 3 cycle latency, and is divided into 4 byte wide banks. It can handle up to one load and one store per cycle, though 128-bit stores take two cycles. L1D tags are split into two separate arrays, one for loads and one for stores.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png" width="464" height="564" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/19c31aba-3418-453e-9677-21ebe7a66821_464x564.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:564,&quot;width&quot;:464,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:82376,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c31aba-3418-453e-9677-21ebe7a66821_464x564.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Data cache misses are tracked by one of eight line-fill buffer entries, which store the miss address. Refill data is held in two 512-bit wide fill buffer registers. Like the instruction cache, the data cache uses a simple FIFO replacement policy.</p><p>Each C910 core interfaces with the outside world via a “PIU”, or processor interface unit. At the other end, a C910 cluster has a Consistency Interface Unit (CIU) that accepts requests from up to four PIUs and maintains cache coherency. The CIU is split into two “snb” instances, each of which has a 24 entry request queue. SNB arbitrates between requests based on age, and has a 512-bit interface to the L2 cache.</p><p>C910’s L2 cache acts as both the first stop for L1 misses and as a cluster-wide shared last level cache. On the TH1520, it has 1 MB of capacity and is 16-way set associative with a FIFO replacement policy. To service multiple accesses per cycle, the L2 is built from two banks, selected by bit 6 of the physical address. The L2 is inclusive of upper level caches, and uses ECC protection to ensure data integrity.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png" width="641" height="613" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:613,&quot;width&quot;:641,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:100495,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50a044a6-61a0-42b6-95f7-eb40de640b9a_641x613.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>L2 latency is 60 cycles which is problematic for a core with limited reordering capacity and no mid-level cache. Even P550’s 4 MB L3 cache has better latency than C910’s L2, from both a cycle count and true latency standpoint. Intel’s Goldmont Plus also uses a shared L2 as a last level cache, and has about 28 cycles of L2 latency (counting a uTLB miss).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png" width="1307" height="641" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:641,&quot;width&quot;:1307,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109234,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e718d24-c0d6-435a-aca3-353f06664951_1307x641.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>C910’s L2 bandwidth also fails to impress. A single core gets just above 10 GB/s, or 5.5 bytes per cycle. All four cores together can read from L2 at 12.6 GB/s, or just 1.7 bytes per cycle per core. Write bandwidth is better at 23.81 GB/s from all four cores, but that’s still less than 16 bytes per cycle in total, and writes are usually less common than reads.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp" width="1280" height="624" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:624,&quot;width&quot;:1280,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:11756,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb825ce6c-96a8-4337-8708-75343eaf3ef0_1280x624.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Again, C910’s L2 is outperformed by both P550’s L3 and Goldmont Plus’s L2. I suspect multi-threaded applications will easily push C910’s L2 bandwidth limits.</p><p>Off-cluster requests go through a 128-bit AXI4 bus. In the Lichee Pi 4A, the TH1520 has just under 30 GB/s of theoretical DRAM bandwidth from its 64-bit LPDDR4X-3733 interface. Achieved read bandwidth is much lower. Multithreaded applications might find 4.2 GB/s a bit tight, especially when there’s only 1 MB of last level cache shared across four cores.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png" width="838" height="311" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:311,&quot;width&quot;:838,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:42586,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16fa44b3-a8ea-4473-9aa2-ce48c6b64119_838x311.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>DRAM latency is at least under control at 133.9 ns, tested using 2 MB pages and 1 GB array. It’s not on the level of a desktop CPU, but it’s better than Eswin and Intel’s low power implementations.</p><p>Sometimes, the memory subsystem has to carry out a core to core transfer to maintain cache coherency. Sites like Anandtech have used a core to core latency test to probe this behavior, and I’ve written my own version. Results should be broadly comparable with those from Anandtech.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp" width="199" height="120" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:120,&quot;width&quot;:199,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2812,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89c31cab-7cb2-4ee3-9261-28e22f82886e_199x120.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>T-HEAD’s CIU can pass data between cores with reasonable speed. It’s much better than P550, which saw over 300 ns of latency within a quad core cluster.</p><p>C910 is T-HEAD’s first out-of-order core. Right out of the gate, C910 is more polished than P550 in some respects. Core to core latency is better, unaligned accesses are properly handled, and there’s vector support. Like P550, C910 aims to scale across a broad range of low power applications. L2 capacity can be configured up to 8 MB, and multi-cluster setups allow scaling to high core counts. I feel like there’s ambition behind C910, since Alibaba wants to use in-house RISC-V cores instead of depending on external factors.</p><blockquote><p>Alibaba has been promoting Xuantie core IP series to facilitate external customers for edge computing applications, such as AI, edge servers, industrial control and advanced driver assistance systems (ADAS)…by the end of 2022, a total volume of 15 million units is expected</p><p>Xuantie-910: A Commercial Multi-Core 12-Stage Pipeline Out-of-Order 64-bit High Performance RISC-V Processor with Vector Extension – T-Head Division, Alibaba Cloud</p></blockquote><p>Yet I also feel the things C910 does well are overshadowed by executing poorly on the basics. The core’s out-of-order engine is poorly balanced, with inadequate capacity in critical structures like the schedulers and register files in relation to its ROB capacity. CPU performance is often limited by memory access performance, and C910’s cache subsystem is exceptionally weak. The cluster’s shared L2 is both slow and small, and the C910 cores have no mid-level cache to insulate L1 misses from that L2. DRAM bandwidth is also lackluster.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg" width="688" height="632" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:632,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F883412d3-684c-49d9-86f5-62d17c21b8af_688x632.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A TH1520 chip, seen at Hot Chips 2024 (not the one tested)</figcaption></figure></div><p>C910 is therefore caught in a position where it needs to keep a lot of instructions in flight to smooth out spikes in demand for memory bandwidth and mitigate high L2 latency, but can rarely do so in practice because its ROB capacity isn’t supported by other structures. C910’s unaligned access handling, vector support, and decent core-to-core latency are all nice to have. But tackling those edge cases is less important than building a well balanced core supported by a solid memory subsystem. Missing the subset of applications that use unaligned accesses or take advantage of vectorization is one thing. But messing up performance for everything else is another. And C910’s poor L2 and DRAM performance may even limit the usefulness of its vector capabilities, because vectorized applications tend to pull more memory bandwidth.</p><p>Hopefully T-HEAD will use experience gained from C910 to build better cores going forward. With Alibaba behind it, T-HEAD should have massive financial backing. I also hope to see more open source out-of-order cores going forward. Looking through C910 source code was very insightful. I appreciated being able to see how micro-op formats changed between pipeline stages, and how instruction decode is split across several stages that aren’t necessarily labeled “decode”.</p><p><span>If you like the content then consider heading over to the </span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span> or </span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span> if you want to toss a few bucks to Chips and Cheese. Also consider joining the </span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's Going on at the FBI? (148 pts)]]></title>
            <link>https://www.lawfaremedia.org/article/the-situation--what-s-going-on-at-the-fbi</link>
            <guid>42928087</guid>
            <pubDate>Tue, 04 Feb 2025 04:46:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lawfaremedia.org/article/the-situation--what-s-going-on-at-the-fbi">https://www.lawfaremedia.org/article/the-situation--what-s-going-on-at-the-fbi</a>, See on <a href="https://news.ycombinator.com/item?id=42928087">Hacker News</a></p>
Couldn't get https://www.lawfaremedia.org/article/the-situation--what-s-going-on-at-the-fbi: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[I bought a container full of Chinese electric excavators. Here's what showed up (179 pts)]]></title>
            <link>https://electrek.co/2025/02/03/i-bought-a-container-full-of-chinese-electric-excavators-heres-what-showed-up/</link>
            <guid>42927391</guid>
            <pubDate>Tue, 04 Feb 2025 03:19:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/02/03/i-bought-a-container-full-of-chinese-electric-excavators-heres-what-showed-up/">https://electrek.co/2025/02/03/i-bought-a-container-full-of-chinese-electric-excavators-heres-what-showed-up/</a>, See on <a href="https://news.ycombinator.com/item?id=42927391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/electric-excavator-nx2500-nesher-head-micah-toll.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/02/electric-excavator-nx2500-nesher-head-micah-toll.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/02/electric-excavator-nx2500-nesher-head-micah-toll.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/02/electric-excavator-nx2500-nesher-head-micah-toll.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/02/electric-excavator-nx2500-nesher-head-micah-toll.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>This isn’t exactly my first time dropping a container full of Chinese electric vehicles in the yard and cracking it open with childlike glee. But it is likely one of the most unique experiences I’ve had so far doing this, revealing inside a fleet of battery-powered Chinese electric mini-excavators and assorted accessories.</p>



<p>If you’ve followed my escapades in my articles and videos for any amount of time, you’ll know this is pretty much par for the course for me. I’m the guy who <a href="https://electrek.co/2022/07/25/electric-mini-truck-how-its-holding-up/">imported that viral $2,000 Chinese electric mini-truck</a> that netted tens of millions of views around the internet. I followed that up with <a href="https://electrek.co/2022/11/21/i-bought-this-electric-boat-alibaba/">electric boats</a> and <a href="https://electrek.co/2023/11/30/i-bought-container-full-of-electric-tractors-and-construction-equipment/">electric tractors</a> and all sorts of <a href="https://electrek.co/2023/05/18/minghong-electric-microcar-unboxing-testing/">other fun EVs</a> from the world’s largest and most controversial electric vehicle market.</p>



<p>This time though, things are getting serious as I get to work. Or, at least work-related vehicles, as my latest import is a pile of electric mini-excavators. So buckle up and join me for the journey! And if you want to see the process in full moving pictures, check out my fun <a href="https://youtu.be/ifQRS5fZCzM">container unboxing video here</a> to get this experience first hand.</p>



<figure><img decoding="async" width="1340" height="893" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg 1340w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=150,100 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=300,200 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=768,512 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=1024,682 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=350,233 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-6.jpg?resize=140,93 140w" sizes="(max-width: 1340px) 100vw, 1340px"></figure>



<p>In case you’re wondering how I got here, it all started with a need for an electric wheel loader – a type of articulating tractor that is useful for a wide range of land managing tasks like digging, loading, hauling, trenching, towing, and more. </p>	
	



<p>My parents live on a bit of land in Florida and needed a few machines to help keep up with chores around the property. They don’t need a massive tractor, but some modest machines would be a big help.</p>



<p>As it turns out, there actually are a few smaller articulated wheel loaders available for these types of homesteaders and landowners – folks who don’t really need a $50,000 diesel Bobcat like you’d see on a contractor’s job site.</p>



<p>However, the family didn’t really want a diesel machine. With the advent of electric alternatives, the advantages of lower operating costs, safer working environment, reduced maintenance, and quieter/more peaceful operation were too hard to pass up. Our family has an electric mini-truck and an electric UTV, both of which are major work vehicles for us, and the experience has driven home just how much nicer it is to own and operate electric alternatives of common work vehicles.</p>



<p>The problem is that when it comes to electric tractor loaders and electric excavators, there just aren’t many options. Nearly everything out there is diesel. Without finding any options for such machines in the US, I went to the world’s largest electric vehicle maker: China. There I found several options that were a good step in the right direction, but weren’t quite ready for prime time in their existing form. With a good starting point, I worked with a factory that I liked to improve the machines for North American operators. </p>



<figure><img loading="lazy" decoding="async" width="1303" height="790" src="https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg 1303w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=150,91 150w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=300,182 300w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=768,466 768w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=1024,621 1024w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=350,212 350w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=130,78 130w, https://electrek.co/wp-content/uploads/sites/3/2023/12/nesher-loaders.jpg?resize=140,85 140w" sizes="auto, (max-width: 1303px) 100vw, 1303px"></figure>



<p>After making a number of safety, quality, and ergonomic improvements to the equipment, the machines became the first <a href="http://nesherequipment.com/">NESHER electric loaders </a>in a growing lineup. Developing into a small business run by my father and me, we’ve now been able to hire a couple of staff and have since shipped electric machines all over the US.</p>



<p>The next logical step in growing was to expand into dedicated mini-excavators, which could dig deeper and do more than just the excavator attachment available on the NESHER L880 and NESHER L1400 loaders. So I repeated the process but for excavators this time, working with a suitable factory to improve their machines to my ideal design intended to better serve North American users.</p>



<p>Having now gone through this container importing process many times over the last 18 months or so, this time I thought I’d bring you guys along on the process of cracking one of these open.</p>



<figure><img loading="lazy" decoding="async" width="1505" height="850" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg 1505w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=150,85 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=300,169 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=768,434 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=1024,578 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=350,198 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-4.jpg?resize=140,79 140w" sizes="auto, (max-width: 1505px) 100vw, 1505px"></figure>



<figure>
<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065db478&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1500" height="809" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400157" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg 1500w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=150,81 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=300,162 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=768,414 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=1024,552 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=350,189 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-5.jpg?resize=140,76 140w" sizes="auto, (max-width: 1500px) 100vw, 1500px"></figure>



<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065dbbe8&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1506" height="845" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400156" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg 1506w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=150,84 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=300,168 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=768,431 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=1024,575 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=350,196 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-6.jpg?resize=140,79 140w" sizes="auto, (max-width: 1506px) 100vw, 1506px"></figure>
</figure>



<p>First of all, any one of these containers takes months to set up. It starts with working with the factory designers and engineers, then negotiating pricing, fronting the production, dealing with inevitable production delays, quality inspections before shipping, booking sea freight, working through customs and handling tariffs, setting up incoming freight, and finally landing the container at your doorstep.</p>



<p>It’s a long and arduous process with each step full of headaches, but having done this with a dozen or so containers at this point, it’s starting to become easier and smoother.</p>



<p>When the container finally arrives after those many months of work, the real fun starts. I cracked this one open and got to work unloading the crates of mini-excavator attachments, such as grapples, augers, ripper teeth, various buckets sizes, rock hammers, etc.</p>



<p>Next came the machines themselves. I always make sure my factories package my machines extra well. It’s not as much the long ocean journey I’m worried about, which is relatively gentle. Rather, the first and last few hundred miles on the back of a truck chassis can bounce things around more. We use a spiderweb of strapping and a small army of ratchets to ensure every machine and attachment is safe and secure for the journey.</p>



<p>They are each unloaded down the ramps and go through an initial quick inspection looking for any obvious issues, like problems with the hydraulics or tracks, then driven off to staging. Once all of the machines are out and the container is cleared out, the more intensive inspections begin. Each machine is put through a few hours of work to suss out any potential issues that were missed at the factory. Occasionally this turns up something small, but thorough quality inspections at the factory mean that any real issues get caught before they arrive stateside.</p>



<figure><img loading="lazy" decoding="async" width="1920" height="1080" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg 1920w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=150,84 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=300,169 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=768,432 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=1024,576 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=1536,864 1536w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=350,197 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=140,79 140w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-8.jpg?resize=1600,900 1600w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>



<figure>
<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065dc2d8&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1340" height="1010" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400151" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg 1340w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=150,113 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=300,226 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=768,579 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=1024,772 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=350,264 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=140,106 140w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-1.jpeg?resize=1327,1000 1327w" sizes="auto, (max-width: 1340px) 100vw, 1340px"></figure>



<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065dc694&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1241" height="712" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400153" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg 1241w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=150,86 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=300,172 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=768,441 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=1024,588 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=350,201 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-9.jpg?resize=140,80 140w" sizes="auto, (max-width: 1241px) 100vw, 1241px"></figure>
</figure>



<p>I’d be lying if I said the inspection process isn’t fun, because it basically means we get to play around with all of the functions. And there’s something about digging holes with small-format heavy equipment that just brings out the inner child in you.</p>



<p>These are fairly small machines – the NESHER NX2500 model name hints at the 2,500 lb (1.1 metric ton) weight of the mini-excavator. With a 5.5-foot (167 cm) digging depth, they are great for tasks such as landscaping jobs like tree planting, utility work like trench digging, material handling like loading and unloading gravel, logs, etc., and even light demolition work. They are especially useful for indoor demolition and renovation jobs, since their zero-emission operation means that operators don’t have to run a long exhaust hose to pipe out the poisonous diesel exhaust or risk the health of anyone in the building.</p>



<p>However, the small size of the machines means that they aren’t really meant for major jobs. You could dig a pond, but it’d take a pretty darn long time.</p>



<p>To give you an example, a few days ago I dug a couple of holes for some palm trees we’ll be adding to the property, and the charge on the machine dropped by 2%. That doesn’t necessarily mean it will be a linear drop and that you can dig 100 holes on a charge, but it’s a rough approximation. </p>



<p>With a 48V 200Ah Li-ion battery, the 9.6 kWh battery is sufficiently large for up to 5-6 hours of light-duty operation, though digging through dense material like clay or rocky terrain will reduce the run time. Recharging takes around 7 hours via a 120V wall outlet with the included charger. </p>



<p>Again, this isn’t meant for an 8-hour shift on a job site. These are machines largely intended for landowners and homesteaders who often have digging tasks but don’t want to repeatedly rent a machine – not that you could find an electric mini-excavator to rent, anyway. Seriously, give it a try. If you want to buy or rent an electric mini-excavator in the US, there simply aren’t any options. They don’t exist. Or at least, they didn’t.</p>



<p>There are a few major companies that have begun producing them in very limited numbers, such as JCB, Bobcat, etc. But they are largely unobtanium, only available to contractors, and carry pricetags approaching and exceeding six figures.</p>



<figure><img loading="lazy" decoding="async" width="1378" height="740" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg 1378w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=150,81 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=300,161 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=768,412 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=1024,550 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=350,188 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-1.jpg?resize=140,75 140w" sizes="auto, (max-width: 1378px) 100vw, 1378px"></figure>



<h2 id="h-common-questions-about-the-electric-mini-excavators">Common questions about the electric mini-excavators</h2>



<p>The most common questions I get on these are run time and cost. With the 6-hour answer out of the way, that leaves pricing. To frame this answer, it’s important to understand what prices look like in this industry. There are VERY few sources for electric mini-excavators anywhere in the Western World. The <a href="https://www.jcb.com/en-us/products/compact-excavators/19c-1e">JCB 19C-1E</a> is one of the few options out there. Traditional heavy equipment companies don’t publicly share prices. You have to jump through hoops of JCB sales reps before they finally tell you that is a nearly US $100,000 machine.</p>



<p>But that machine also weighs around 1,500 lb more than the NESHER NX2500. A closer comparison would be the <a href="https://www.bobcat.com/na/en/equipment/excavators/compact-excavators/e10e">Bobcat E10e</a>, which is roughly the same size and spec as the NESHER NX2500. Again, it takes a lot of digging (no pun intended), but ultimately you’ll find that it is priced at around US $60,000.</p>



<p>By comparison, the NESHER NX2500 is priced at <a href="http://www.nesherequipment.com/">US $19,600</a>. </p>



<p>This isn’t to say that these machines are directly comparable, but they do have similar specs and perform similar tasks. Bobcat and JCB are certainly larger companies, but they cater to commercial users. The NX2500, on the other hand, finally brings the capability of electric mini-excavators to more average Joes and small businesses that can’t afford a $60k or $100k piece of equipment.</p>



<figure>
<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065dcdff&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1480" height="817" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400159" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg 1480w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=150,83 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=300,166 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=768,424 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=1024,565 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=350,193 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-3.jpg?resize=140,77 140w" sizes="auto, (max-width: 1480px) 100vw, 1480px"></figure>



<figure data-wp-context="{&quot;imageId&quot;:&quot;67a1b065dd24b&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1340" height="893" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" data-id="400145" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg 1340w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=150,100 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=300,200 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=768,512 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=1024,682 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=350,233 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-7.jpg?resize=140,93 140w" sizes="auto, (max-width: 1340px) 100vw, 1340px"></figure>
</figure>



<p>Another common question I get when people hear I import a lot of these types of things is “do you get to keep the container?”</p>



<p>Sometimes, yes. But it’s not as much that I <em>get</em> to keep and more that I had to buy it in advance. This is what is known as one-tripper. That means it is a new shipping container, and this is its first trip across the ocean. </p>



<p>In this case, I bought the container so I could keep it and use it as storage – basically a super sturdy and locking shed. You might have seen my article about turning a shipping container into <a href="https://electrek.co/2024/08/26/i-run-my-electric-tractor-completely-off-grid-heres-my-secret/">a solar-powered charging shed </a>complete with air conditioning. That’s one of the nice things about choosing to buy a one-tripper container, you can get very creative with them. </p>



<p>However, most of my imports are done using the shipping line containers. These are essentially borrowed from the container lines. Maersk or MSC or the other big names lend you a shipping container as part of the price of shipping with them, you fill it in China, empty it in the US, and then it goes back to the port for many more journeys in its future. That’s the most common and economical way to do it, but getting a few shipping containers of your own isn’t a bad thing either, if you have the space.</p>



<figure><img loading="lazy" decoding="async" width="1355" height="713" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg 1355w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=150,79 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=300,158 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=768,404 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=1024,539 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=350,184 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Micah-toll-in-nesher-nx2500.jpg?resize=140,74 140w" sizes="auto, (max-width: 1355px) 100vw, 1355px"></figure>



<p>The last question that I often hear is simply, “Why electric?”</p>



<p>I get it, many old-school operators are of the “diesel or die” variety. The problem is, sometimes you get both. That diesel exhaust is a carcinogen. And unlike larger excavators with enclosed cabs and better exhaust manifold designs, most diesel-powered open-cab mini-excavators result in the operator’s face being located a mere 2-3 feet from a diesel exhaust pipe. That’s not how I want to spend my digging hours and I wouldn’t wish it upon anyone else.</p>



<p>Then you have to add on top of that the sound of an unisolated engine running inches beneath your thighs, the vibrations of that engine, the extended upkeep and maintenance of an engine with hundreds of moving parts, and the hassle of winterizing or other extra steps that required to keep such machines in good working order.</p>



<p>There’s a reason a power drill has a battery and an electric motor instead of a small gasoline engine, even though such engines are widely available for model building. Electric tools are simply nicer and more convenient to own and operate. Sure, 30 years ago we didn’t have the kind of motor and battery technology to make electric construction equipment a viable alternative. But now we do, and these machines are proof of it.</p>




	<p>Are they more expensive than a no-name diesel-powered Chinese mini-excavator bought at auction for $5,200? Sure. But they are also cheaper to operate, longer lasting, safer, and more comfortable, and come backed by a US distributor with service and support, including a local inventory of spare parts. Electric might not be for everyone, but it is for me, and now I’ve seen how it is for many others as well.</p>



<figure><img loading="lazy" decoding="async" width="1340" height="1005" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg 1340w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=150,113 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=300,225 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=768,576 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=1024,768 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=350,263 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=140,105 140w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-excavator-5.jpeg?resize=1333,1000 1333w" sizes="auto, (max-width: 1340px) 100vw, 1340px"></figure>



<figure><img loading="lazy" decoding="async" width="1415" height="765" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg 1415w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=150,81 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=300,162 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=768,415 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=1024,554 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=350,189 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/Dad-and-I-on-excavators.jpg?resize=140,76 140w" sizes="auto, (max-width: 1415px) 100vw, 1415px"></figure>



<p>This is unlikely to be the last time I import something fun and interesting from China, though it certainly is the last one without new tariffs that were recently imposed. Like all businesses, we’ll be analyzing the impact of the new tariffs on our own operating costs, and unfortunately, we may have to raise prices on these machines as our costs rise.</p>



<p>But since a lot of what I bring in is for personal use (and I’ve got more fun EVs already in the works!), that’s largely a problem for me to deal with.</p>



<p>I’m looking forward to sharing the next fun EVs I get my hands on. Until then, I’ll have those hands busy digging!</p>



<figure><img loading="lazy" decoding="async" width="1047" height="568" src="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg 1047w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=150,81 150w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=300,163 300w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=768,417 768w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=1024,556 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=350,190 350w, https://electrek.co/wp-content/uploads/sites/3/2025/02/nesher-nx2500-electric-miniexcavator-2.jpg?resize=140,76 140w" sizes="auto, (max-width: 1047px) 100vw, 1047px"></figure>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Escaping surprise bills and over-engineered messes: Why I left AWS (119 pts)]]></title>
            <link>https://travisbumgarner.dev/blog/leaving-aws</link>
            <guid>42927172</guid>
            <pubDate>Tue, 04 Feb 2025 02:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://travisbumgarner.dev/blog/leaving-aws">https://travisbumgarner.dev/blog/leaving-aws</a>, See on <a href="https://news.ycombinator.com/item?id=42927172">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><p><time>Posted <!-- -->Thu Jan 30 2025</time></p><p>I love building side projects. They've been a way to push myself and explore new ideas and technologies. Each site has needed hosting. I started my hosting journey with WordPress. I moved on to raw Linux servers and finally ended up on AWS. Hosting on AWS felt like a badge of honor, but it also felt like a ticking time bomb of complexity and cost.</p>
<h3>Surprise Bills</h3>
<p>I've heard horror stories of accidental bills. They ranged from a few hundred to several hundred thousand dollars. Sometimes they're refunded, like when the story hits the front page of Hacker News and Reddit, but most times not.</p>
<p>I searched for ways to control my financial exposure on AWS. I expected a simple monthly max spend option. I found none. There were mentions of setting up alerts. What if I got DDoSed at 3 a.m.? Some suggested setting up intricate systems to shut everything down. What if they were setup incorrectly?</p>
<h3>Over-Engineered Messes</h3>
<p>I have noticed that we as engineers have a tendency over-engineer systems. We tend to mimic the practices of companies like Facebook or Netflix. We over-engineer solutions, choosing technologies that are often overkill for our actual needs. For me, AWS was far more than I needed.</p>
<h3>NearlyFreeSpeech to the Rescue</h3>
<p>After some research and conversations with other engineers, I discovered <a href="https://www.nearlyfreespeech.net/">NearlyFreeSpeech</a> (NFS). Their approach to hosting was exactly what I was looking for. One blog post stood out to me:</p>
<blockquote>
<p>“[…] since our service is paid in advance, you always have complete control over your maximum financial liability simply by controlling the balance of your account. If you feel your site is attack-prone and you are primarily concerned about costs, we encourage you to maintain a low account balance to limit your exposure.” - <a href="https://faq.nearlyfreespeech.net/q/attack">Blog Post</a></p>
</blockquote>
<p>This model was perfect. By prepaying, I could ensure complete control over my financial liability.</p>
<p>It's possible with NFS to setup several billing accounts with prepaid balances. I have a primary account that I add a few dollars to each month. This is hosting for my portfolio websites and some stable side projects. I have a secondary account for experimental projects. I can add some more money and tinker without the worry of spending too much.</p>
<p>The NFS dashboard is simple and straightforward. Everything is a button click or two away - the bills, what's enabled, what's not, what's working, what's not and why.</p>
<p>Linux boxes leave it up to you to do everything. AWS offers way too many ways to do things in way too complicated of manners. NFS offers some boilerplate and opinions for each server that gets the best of both of these worlds.</p>
<h3>Moving Apps</h3>
<p>In total, I migrated eight of nine apps to NFS.</p>
<p>One app gave me trouble - a Python Flask app. It had several complicated dependencies including OpenCV, Numpy, and Matplotlib. My belief is that this had more to do with the complex nature of the libraries and less to do with NFS.</p>
<p>For implementation notes and pull requests, scroll down to the Migration section.</p>
<h3>Conclusion</h3>
<p>I still think AWS holds a place and I'll most likely use it as a tool in the future. But for now, I'm going to keep things simple simple.</p>
<p>My bill has increased from about $1 to $7 a month. I'm content to pay a few dollars more a month for peace of mind and to support a smaller business.</p>
<h2>Migration Guide</h2>
<h3>Pull Requests</h3>
<p>Preface - I bit off more than I could chew. I migrated 8 sites at once. There were several follow up PRs to correct some things that slipped through the cracks.</p>
<p>Listed below are the eight websites I migrated. The website, pull requests, technologies used, and some notes are included.</p>
<p><strong>Engineering Portfolio</strong> [<a href="http://travisbumgarner.dev/">Website</a>]</p>
<ul>
<li>Technologies - Next.JS</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/Engineering-Portfolio-and-Blog/pull/61">Part 1</a>, <a href="https://github.com/TravisBumgarner/Engineering-Portfolio-and-Blog/pull/63">Part 2</a>, <a href="https://github.com/TravisBumgarner/Engineering-Portfolio-and-Blog/pull/64">Part 3</a></li>
<li>Notes - The majority of the files was me misunderstanding NextJS static hosting and had nothing to do with NFS.</li>
</ul>
<p><strong>Photography Portfolio [<a href="https://travisbumgarner.photography/">Website</a>]</strong></p>
<ul>
<li>Technologies - React</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/Photography-Portfolio/pull/87/files">Part 1</a></li>
</ul>
<p>Bananarama [<a href="https://voting.sillysideprojects.com/">Website</a>]</p>
<ul>
<li>Technologies - React, Express, GraphQL, WebSockets</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/Bananarama-Voting-Bananza/pull/5">Part 1</a></li>
<li>Notes - Traffic for WebSockets and HTTP need to be served by different ports.</li>
</ul>
<p>Manifest Playlists [<a href="https://playlists.sillysideprojects.com/">Website</a>]</p>
<ul>
<li>Technologies - React, Express, GraphQL, WebSockets</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/playlist-generator/pull/8/files">Part 1</a></li>
</ul>
<p>3x Landing Pages [<a href="https://todo.sillysideprojects.com/">Website 1</a>, <a href="https://ideas.sillysideprojects.com/">Website 2</a>]</p>
<ul>
<li>Technologies - React</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/Todo-Today-Website/pull/12">Part 1,</a> <a href="https://github.com/TravisBumgarner/Todo-Today-Website/pull/13">Part 2</a></li>
<li>Notes - An <code>.htaccess</code> file is required to ensure that all routes direct the user to the React app. Otherwise you'll get 404 errors.</li>
</ul>
<p>Contact Form (for the sites above)</p>
<ul>
<li>Technologies - Express, Pushover</li>
<li>Pull Requests - <a href="https://github.com/TravisBumgarner/Contact-Form/tree/main">Part 1</a></li>
<li>Notes - NFS doesn't offer services like Lambdas. My contact form was previously hosted by a Lambda. It now lives as an Express server.</li>
</ul>
<h3>Migration (or Creation) Process</h3>
<p>Reference the pull requests and code in the previous section for examples.</p>
<ol>
<li><strong>Build your Website</strong></li>
<li><strong>Write a <code>run.sh</code> Script</strong>
<ul>
<li>This script will be responsible for bringing up your app.</li>
<li>For multiple apps (e.g., frontend and backend), create separate scripts for each.</li>
</ul>
</li>
<li><strong>Configure site on NFS</strong>
<ul>
<li><strong>Choose Server Type:</strong>
<ul>
<li>Use <code>Apache 2.4 Static Content</code> for frontend apps (like React without a server).</li>
<li>Use <code>Custom</code> for backend apps (e.g., Express, Next.js, Python).</li>
</ul>
</li>
<li><strong>Set Up Daemon(s):</strong>
<ul>
<li>Daemons manage the <code>run.sh</code> scripts and keep your app running.</li>
</ul>
</li>
<li><strong>Set Up Proxy(s):</strong>
<ul>
<li>Expose the necessary ports to the outside world.</li>
</ul>
</li>
<li><strong>Set Up SSH:</strong>
<ul>
<li>Attach your <code>deploy.sh</code> script to the unique login for each site.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Launch Your App</strong>
<ul>
<li><strong>Write and Run <code>deploy.sh</code></strong>:<!-- -->
<ul>
<li>The <code>deploy.sh</code> script sets everything up on the server.</li>
</ul>
</li>
<li><strong>Start Daemons</strong>:<!-- -->
<ul>
<li>Use the NFS dashboard to start each daemon for your apps.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Debug Any Issues</strong>
<ul>
<li>Check logs in <code>/home/logs/[daemon_name]</code> for errors.</li>
</ul>
</li>
<li><strong>Set Up DNS</strong>
<ul>
<li>Update your DNS records to point to your NFS site (IP addresses are available in the NFS dashboard).</li>
</ul>
</li>
<li><strong>Delete AWS Resources</strong>
<ul>
<li>Once your migration is complete and tested, decommission your AWS resources.</li>
</ul>
</li>
</ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Video Game History Foundation Library Opens in Early Access (304 pts)]]></title>
            <link>https://gamehistory.org/vghf-library-launch/</link>
            <guid>42926076</guid>
            <pubDate>Tue, 04 Feb 2025 01:15:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gamehistory.org/vghf-library-launch/">https://gamehistory.org/vghf-library-launch/</a>, See on <a href="https://news.ycombinator.com/item?id=42926076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content">

	
<article id="post-27399">
	
	<!-- .cover-header -->

	<div id="post-inner">

		
<p>Today, the Video Game History Foundation launches early access to its digital archive of video game history research materials, available now at <a href="https://library.gamehistory.org/">library.gamehistory.org</a>.</p>



<p>Ever since we started in 2017, the Video Game History Foundation has been building a digital library to help the study of video game history. We’ve been collecting development documents, behind-the-scenes content, rare video game publications and catalogs, magazines, memorabilia, ephemera, and more.</p>



<p>After years of cataloging, processing, and digitizing our collections, we’re ready to open our (virtual) doors to the public for the first time.</p>



<figure><p>
<iframe title="library.gamehistory.org —  Now in early access" width="800" height="450" src="https://www.youtube.com/embed/6Tysm_Wf60Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<h2>Our collections</h2>



<p>Our digital library platform launches with access to a curated selection of materials from our library, including:</p>



<ul>
<li>Never-before-seen game development materials.</li>



<li>Artwork, press kits, and promotional materials from iconic video games.</li>



<li>Over 1500 full-text searchable <a href="https://archive.gamehistory.org/folder/205c628c-5d0a-4de8-a5a5-782f31706ac0" target="_blank" rel="noreferrer noopener">out-of-print video game magazines</a>—including game industry trade magazines rarely available to the public.</li>
</ul>



<figure><img fetchpriority="high" decoding="async" width="1024" height="273" src="https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-1024x273.jpg" alt="A flyer for Castlevania III: Dracula's Curse and Super C; marketing art for Maximum Carnage; and reference art for Bart Simpson." srcset="https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-1024x273.jpg 1024w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-300x80.jpg 300w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-740x197.jpg 740w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-768x205.jpg 768w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-50x13.jpg 50w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight-1200x320.jpg 1200w, https://gamehistory.org/wp-content/uploads/2025/01/flitman-highlight.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>Learn how games were made</h3>



<p>VGHF works with the game development community to preserve design documents, artwork, video footage, correspondence, and other unique items from behind the scenes of game production.</p>



<p>Now we’re opening these resources for you, and you can discover for yourself how games were made and sold.</p>



<p>The highlight of our launch collection is <a href="https://library.gamehistory.org/repositories/2/resources/84" target="_blank" rel="noreferrer noopener">the Mark Flitman papers</a>. Mark is a retired game producer who worked at companies like Konami, Acclaim, Midway, and Mindscape in the 90s and 2000s. <a href="https://www.newyorker.com/tech/annals-of-technology/the-collectors-who-save-video-game-history-from-oblivion" target="_blank" rel="noreferrer noopener">He and his family graciously invited the Video Game History Foundation to his home</a> and allowed us to digitize and share the mountains of paperwork and digital file backups he’s kept in his basement for over two decades.</p>



<p>Even if you don’t know the games he worked on—and you probably know a few!—his papers are an incredible record of the business of video game production and marketing.</p>



<figure><img decoding="async" width="1024" height="273" src="https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-1024x273.jpg" alt="Rand and Robyn Miller at a computer; Rand Miller as Atrus on a chroma key set during the making of Riven; and a video concept for Uru: Ages Beyond Myst." srcset="https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-1024x273.jpg 1024w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-300x80.jpg 300w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-740x197.jpg 740w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-768x205.jpg 768w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-50x13.jpg 50w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight-1200x320.jpg 1200w, https://gamehistory.org/wp-content/uploads/2025/01/cyan-highlight.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Our library also premieres with <a href="https://archive.gamehistory.org/folder/22cf9aa2-812b-4f39-b42e-e87a3c153b8c" target="_blank" rel="noreferrer noopener">over 100 hours of footage from the production of the <em>Myst</em> series</a> by developer Cyan, including the original FMV filming footage for <em>Myst</em> and <em>Riven: The Sequel to Myst</em> and hours of never-before-seen interviews with the Cyan team. We digitized these in support of the upcoming film <em><a href="https://themystdocumentary.com/" target="_blank" rel="noreferrer noopener">The Myst Documentary</a></em>; Cyan has been unbelievably supportive of our mission and has given us unprecedented access to their internal archives to share these videos with you.</p>



<h3>Collaborating with the community</h3>



<p>Fans around the world have been collecting, preserving, documenting game history. We’re helping build their work into something even more impactful.</p>



<p>Many items in our digital library were donated or digitized by members of the gaming community. Hundreds of magazine scans were provided by groups like <a href="https://www.retromags.com/" target="_blank" rel="noreferrer noopener">Retromags</a> and <a href="https://www.outofprintarchive.com/" target="_blank" rel="noreferrer noopener">Out-of-Print Archive</a>. Other exciting items, like <a href="https://archive.gamehistory.org/item/9a06fb86-5ed9-4ddd-8f7f-f57dd3b94c1d" target="_blank" rel="noreferrer noopener">a rare educational game catalog</a> and <a href="https://archive.gamehistory.org/folder/719e9f8b-eb62-41aa-81e9-85336daf1d65" target="_blank" rel="noreferrer noopener">an early electronic game commercial</a>, were loaned to us by private collectors who wanted to make them available for everyone.</p>



<p>The VGHF Library is a force multiplier for citizen archivists who have been preserving the history of games. We’re excited to formally recognize and institutionalize their work.</p>



<h3>And that’s not all!</h3>



<p>The launch of the VGHF Library also includes:</p>



<ul>
<li>The first 100 CDs from <a href="https://archive.gamehistory.org/folder/a5823d80-320b-41c9-9e3c-4dc28f79f2a2" target="_blank" rel="noreferrer noopener">the art and press release archives of <em>GamePro</em> magazine</a>, reformatted to view in your browser.</li>



<li><a href="https://archive.gamehistory.org/folder/1c21011a-6e22-4c3e-9298-c2f71470e1de" target="_blank" rel="noreferrer noopener">Guidebooks and ephemera from video game events</a>, including searchable directories and maps from the first 12 years of the Electronic Entertainment Expo.</li>



<li>An extensive international collection of <a href="https://archive.gamehistory.org/folder/4d999ce2-81f1-45fe-b103-f50a00e8283f" target="_blank" rel="noreferrer noopener">FromSoftware promotional materials</a>, collected by citizen archivist Kris Urquhart, with a blessing from FromSoftware to donate them to our library!</li>



<li>And much more!</li>
</ul>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="384" src="https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-1024x384.jpg" alt="In clockwise from the upper-left: Aerith standing in front of the Highwind from Final Fantasy VII; the key art from Dark Souls Remastered; a flyer for Donkey Kong; a letter from the TV show Video Power; a catalog listing for the Sega CD; the cover of a guidebook for the Electronic Entertainment Expo; and a promotional brochure for Xbox Live." srcset="https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-1024x384.jpg 1024w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-300x113.jpg 300w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-740x278.jpg 740w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-768x288.jpg 768w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-50x19.jpg 50w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights-1200x450.jpg 1200w, https://gamehistory.org/wp-content/uploads/2025/01/more-collection-highlights.jpg 1333w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>


<h2>Meet our library system</h2>



<p>Our digital library system makes it easier than ever to explore video game history. We’ve spent years creating rich, extensive metadata for our collections and figuring out how to share our library materials with you. What we’ve built is more than just a bunch of files: This is a powerful tool for video game research with best-in-class discovery features.</p>



<p>Our library is powered by ArchivesSpace and Preservica, two archival management platforms that we use to catalog, preserve, and share our materials. Using the power of these professional-grade archive tools, you can search and filter our collections in deep detail and view digital items directly in-browser.</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="576" src="https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-1024x576.png" alt="A screenshot from the Video Game History Foundation's digital archive system. A search for Baldur's Gate has returned 775 items, and each result shows where the phrase &quot;Baldur's Gate&quot; appears in the text of the item." srcset="https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-1024x576.png 1024w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-300x169.png 300w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-740x416.png 740w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-768x432.png 768w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-50x28.png 50w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-1600x900.png 1600w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-1536x864.png 1536w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search-1200x675.png 1200w, https://gamehistory.org/wp-content/uploads/2025/01/digitalarchive_search.png 1920w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>


<p>We’ve also built our own tools to make the library experience even better. We developed a state-of-the-art text recognition toolset that makes even the wildest, weirdest video game magazines and promotional materials fully text-searchable. And we’ve created <a href="https://archive.gamehistory.org/" target="_blank" rel="noreferrer noopener">our own digital archive portal</a> with the powerful search and navigation features that video game historians have asked us for.</p>



<p>There has never been a better way to research video game history. By putting our rich collections in conversation with each other in a curated, text-searchable archive, we’ve turned them into a powerful, one-of-a-kind resource.</p>



<p>Our library is for anyone who wants to study video game history—whether you’re a scholar who wants to supplement your academic resources, or a YouTuber making a video about the story of your favorite game. We think this is the start of something that will change how people study the history of video games.</p>



<p>(In fact, we’ve already been using the library internally for our own research for months!)</p>



<figure><img loading="lazy" decoding="async" width="1024" height="556" src="https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-1024x556.jpg" alt="A drawing from a design document, showing a dragon boss that shoots fireballs." srcset="https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-1024x556.jpg 1024w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-300x163.jpg 300w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-740x401.jpg 740w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-768x417.jpg 768w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-50x27.jpg 50w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-1536x833.jpg 1536w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon-1200x651.jpg 1200w, https://gamehistory.org/wp-content/uploads/2025/01/tinytoon_dragon.jpg 1552w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption><em>From the Mark Flitman papers –&nbsp;<a href="https://archive.gamehistory.org/folder/31bb1446-8567-472c-9124-1680e6b3e045" target="_blank" rel="noreferrer noopener">Tiny Toon Adventures planning document, 1990</a></em></figcaption></figure>



<h2>What’s next?</h2>



<p>Our library is the future home for all our collections. We’re in this for the long-haul, and over the coming years, we’ll be adding even more materials to our archive and adding new features to our library system. If you want to learn more about what we have in our library, <a href="https://library.gamehistory.org/">our catalog</a> has additional information about items that aren’t available digitally yet, and even <a href="https://library.gamehistory.org/accessions">materials we haven’t processed</a>.</p>



<p>Stay tuned to <a href="https://gamehistory.org/blog/">our blog</a> and <a href="http://youtube.com/gamehistoryorg">YouTube channel</a> for highlights of our collections and announcements about new acquisitions!</p>



<p>And if you’re a game developer who wants to contribute your materials to our growing collections, please reach out at <a href="mailto:info@gamehistory.org">info@gamehistory.org</a>.</p>



<h2>Testimonials for the VGHF Library</h2>



<div>
<blockquote>
<p>The Video Game History Foundation Library is a tremendous resource for my research. Being able to look at magazines, press releases, developer documents, and advertisements all in one place and fully searchable is a huge time saver. And by studying a video game through this rich variety of sources, I’m able, as a historian, to see the history of that game in a new way. I’m excited to see the Video Game History Foundation Library grow and I can’t wait to see what else is added in the future.</p>
</blockquote>



<p>―Norm Caruso, video essayist, <a href="https://www.youtube.com/@GamingHistorian" target="_blank" rel="noreferrer noopener"><em>Gaming Historian</em></a></p>



<blockquote>
<p>At Digital Eclipse, we start every one of our interactive documentary games with a huge deep dive into the research, and to have this all at our fingertips—design documents, and press releases, and internal stuff, and magazines—it’s incredible.</p>
</blockquote>



<p>―Chris Kohler, Editorial Director, <a href="https://www.digitaleclipse.com/">Digital Eclipse</a></p>



<blockquote>
<p>If I’m trying to find the earliest use of a word or the earliest news related to a game, it’s a relief when I sort by date in the Foundation’s library, I can trust that all the dates are actually correct. In other databases, the details are frequently entered incorrectly, if any date was entered at all.</p>
</blockquote>



<p>―Kate Willaert, gaming historian, <em><a href="https://www.acriticalhit.com/" target="_blank" rel="noreferrer noopener">A Critical Hit!</a></em></p>



<blockquote>
<p>As someone who thinks about creating content around, “Hey, what were people thinking and feeling at the time?” […] this is gonna very quickly become an invaluable resource. It feels primed to change how people create videos and books going forward. It’s going to be a very important tool, and I’m so glad it exists.</p>
</blockquote>



<p>―Jeff Grubb, News Editor, <a href="http://giantbomb.com/">Giant Bomb</a></p>



<blockquote>
<p>What the VGHF is doing now isn’t just going help researchers presently, but it’s going to be a hugely important resource for researchers and historians in the future.</p>
</blockquote>



<p>―<a href="https://bsky.app/profile/hollynielsen.bsky.social">Holly Nielsen</a>, play historian, game writer</p>



<blockquote>
<p>This is the coolest thing ever.</p>
</blockquote>



<p>―hbomberguy, <a href="https://www.youtube.com/@hbomberguy">video essayist</a></p>
</div>



<h2>Frequently asked questions</h2>



<h3>Is this everything you have?</h3>



<p>Our archive portal only includes items that have been processed and have a digital copy available to the public. We are actively working to catalog and digitize as much of our collection as possible, and more materials will be coming to the library on an ongoing basis. For a more complete list of VGHF’s holdings, visit the <a href="https://library.gamehistory.org/" target="_blank" rel="noreferrer noopener">Library Catalog</a> and the “<a href="https://library.gamehistory.org/accessions">Unprocessed Materials</a>” section.</p>



<h3>Do you really have everything here?</h3>



<p>Yes! Every item listed in the library is held by the Video Game History Foundation, or if we do not own a physical copy, VGHF has received permission from a donor to share a digital copy of their material.</p>



<h3>Are you allowed to do this?</h3>



<p>Yes. The VGHF Library follows <a href="https://copyrightalliance.org/faqs/what-is-fair-use/">the guidelines for fair use in U.S. copyright law</a>, which allows us to use copyrighted material for transformative, educational purposes that do not impact the commercial market. Our non-profit archive uses out-of-print and freely available materials, which we have turned into a powerful research tool.</p>



<h3>Who can access the library?</h3>



<p>The VGHF Library is free for anyone to access digitally, anywhere in the world. You don’t need special credentials to use the library. Anyone studying video game history is a researcher, and we do not charge to view publicly accessible materials.</p>



<p>As a paid service, we may be able to provide researchers with access to original or unprocessed materials, at the discretion of VGHF staff. Researchers can <a href="https://archive.gamehistory.org/contact">contact the library team</a> with requests, although we may be unable to respond during the initial launch of the library due to high demand.</p>



<h3>Can people use your items in their books, blog posts, videos, etc.?</h3>



<p>For some special collections and developer materials, we may have permission from the donor to let people reproduce materials for research purposes. We have included notes in each collection that describe what people can and can’t do with our materials.</p>



<p>Unless stated otherwise, the library does not own the intellectual property of materials in the library and cannot give express permission to reproduce them. However, researchers <a href="https://cmsimpact.org/report-list/codes/" target="_blank" rel="noreferrer noopener">may still be able use these materials as fair use</a>.</p>



<h3>Can you play games in this archive?</h3>



<p>No, for now. With limited exceptions, the Video Game History Foundation does not collect retail video games and does not have plans to provide them to researchers.</p>



<p>Additionally, <a target="_blank" href="https://gamehistory.org/dmca-2024-statement/" rel="noreferrer noopener">restrictions in United States copyright law</a> currently prevent VGHF from sharing digital access to out-of-print video games with researchers. We are fighting to change this law in coordination with the <a target="_blank" href="https://www.softwarepreservationnetwork.org/" rel="noreferrer noopener">software preservation community</a>.</p>



<h3>I would like to contribute my materials to the archive.</h3>



<p>Prospective donors can contact the Video Game History Foundation team at <a href="mailto:info@gamehistory.org">info@gamehistory.org</a>.</p>



<h2>Meet the library team</h2>



<div>
<div>
<figure><img loading="lazy" decoding="async" width="978" height="978" src="https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023.jpg" alt="" srcset="https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023.jpg 978w, https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023-300x300.jpg 300w, https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023-740x740.jpg 740w, https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023-768x768.jpg 768w, https://gamehistory.org/wp-content/uploads/2024/09/Phil-Salvador-headshot-2023-50x50.jpg 50w" sizes="auto, (max-width: 978px) 100vw, 978px"></figure>
</div>



<p><strong>Phil Salvador</strong> is the Library Director at the Video Game History Foundation. Previously, he was the author of the Survey of the Video Game Reissue Market in the United States, a groundbreaking study on the state of commercial video game preservation. His research on video game history and preservation has been featured on NPR, The Verge, and Game Developer.</p>
</div>



<div>
<div>
<figure><img loading="lazy" decoding="async" width="1000" height="1000" src="https://gamehistory.org/wp-content/uploads/2020/10/travis-headshot.jpg" alt="" srcset="https://gamehistory.org/wp-content/uploads/2020/10/travis-headshot.jpg 1000w, https://gamehistory.org/wp-content/uploads/2020/10/travis-headshot-300x300.jpg 300w, https://gamehistory.org/wp-content/uploads/2020/10/travis-headshot-740x740.jpg 740w, https://gamehistory.org/wp-content/uploads/2020/10/travis-headshot-768x768.jpg 768w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></figure>
</div>



<p><strong>Travis Brown</strong> is the Director of Technology at the Video Game History Foundation. He is responsible for developing and managing the VGHF Library’s tech infrastructure, including its next-generation text-recognition tools. When he’s not working on his day job as Director of Developer Relations at Live Aware Labs, he’s working on restoring arcade cabinets and vintage motorcycles.</p>
</div>



<div>
<div>
<figure><img loading="lazy" decoding="async" width="981" height="981" src="https://gamehistory.org/wp-content/uploads/2020/09/amandacifaldi.jpg" alt="" srcset="https://gamehistory.org/wp-content/uploads/2020/09/amandacifaldi.jpg 981w, https://gamehistory.org/wp-content/uploads/2020/09/amandacifaldi-300x300.jpg 300w, https://gamehistory.org/wp-content/uploads/2020/09/amandacifaldi-740x740.jpg 740w, https://gamehistory.org/wp-content/uploads/2020/09/amandacifaldi-768x768.jpg 768w" sizes="auto, (max-width: 981px) 100vw, 981px"></figure>
</div>



<p><strong>Amanda Cifaldi</strong> is an artist and engineer with a passion for creating joyful experiences, who regularly volunteers at the Video Game History Foundation. Drawing on a background in consumer and enterprise software, she brings both creative and technical expertise to many of the Foundation’s public-facing projects. Outside of volunteering and work, she enjoys looking at plants and reading horror comics.</p>
</div>



<div>
<h3>We need your support to keep going.</h3>


<div>
<figure><img loading="lazy" decoding="async" width="800" height="800" src="https://gamehistory.org/wp-content/uploads/2024/11/getinvolved.png" alt="" srcset="https://gamehistory.org/wp-content/uploads/2024/11/getinvolved.png 800w, https://gamehistory.org/wp-content/uploads/2024/11/getinvolved-300x300.png 300w, https://gamehistory.org/wp-content/uploads/2024/11/getinvolved-740x740.png 740w, https://gamehistory.org/wp-content/uploads/2024/11/getinvolved-768x768.png 768w, https://gamehistory.org/wp-content/uploads/2024/11/getinvolved-50x50.png 50w" sizes="auto, (max-width: 800px) 100vw, 800px"></figure></div>


<p>Help keep our library free! The VGHF is funded thanks to generous individuals just like you. If you’re able, please consider&nbsp;<a href="http://gamehistory.org/donate">supporting us today</a>.</p>
</div>

		</div><!-- .post-inner -->

	
</article><!-- .post -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Coup Is in Progress in America (300 pts)]]></title>
            <link>https://www.techdirt.com/2025/02/03/a-coup-is-in-progress-in-america/</link>
            <guid>42925782</guid>
            <pubDate>Tue, 04 Feb 2025 00:48:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2025/02/03/a-coup-is-in-progress-in-america/">https://www.techdirt.com/2025/02/03/a-coup-is-in-progress-in-america/</a>, See on <a href="https://news.ycombinator.com/item?id=42925782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-463262">

				


				


				<h3>from the <i>wake-up</i> dept</h3>
				


				<p>A coup is underway in the United States, and we must stop pretending otherwise. The signs are&nbsp;<strong>unmistakable and accelerating</strong>: in just the past 48 hours, Elon Musk’s DOGE commission has seized control of Treasury payment systems and gained unauthorized access to classified USAID materials, while security officials who followed protocols were removed. Career civil servants across agencies are being systematically purged for having followed legal requirements during previous administrations. The president openly declares he won’t enforce laws he dislikes, while Congress watches in complicit silence. This isn’t happening through tanks in the streets or soldiers at government buildings—it’s occurring through the systematic dismantling of constitutional governance and its replacement with a system of personal loyalty to private interests. Those who resist are being removed, while those who enable this transformation are being rewarded with unprecedented control over government functions. The time for euphemisms and careful hedging has passed. We are watching, in real time, the conversion of constitutional democracy into something darker and more dangerous. To pretend otherwise isn’t prudence—it’s complicity.</p>
<p>I understand why many Americans are hesitant to accept what’s happening—acknowledging the reality of a coup in progress is frightening. But we must confront the facts before us with clear eyes: Donald Trump and Elon Musk are systematically seizing control of the federal government’s machinery through plainly illegal means. They are violating civil service protections established by law, shuttering congressionally mandated agencies without authority, and subjecting career public servants to ideological purges.</p>
<p>When security officials are removed for following classification protocols, when private citizens gain unauthorized access to Treasury payment systems, when civil servants are punished for having participated in legally required training—these aren’t isolated incidents or normal policy changes. They represent the coordinated dismantling of constitutional governance and its replacement with a system of personal loyalty.</p>
<p>The machinery of government—the actual systems and institutions through which public authority flows—is being captured by private interests operating outside constitutional constraints. This is precisely what the Civil Service Reform Act was designed to prevent. These aren’t abstract concerns about democratic norms—these are concrete violations of specific laws designed to prevent exactly this kind of authoritarian capture of government functions.</p>
<p>This is an emergency, and it demands emergency response from every American with power or influence. The window for effective resistance narrows with each passing day. History will judge harshly those who had the capacity to resist but chose instead to wait and see how things develop. The time to act is now, before the mechanisms that would allow effective resistance are completely dismantled.</p>
<p>The American Constitution represents more than just a system of government—it embodies humanity’s greatest experiment in self-governance through reason and law rather than force and will. When the Founders established our constitutional republic, they created something unprecedented: a government bound by law rather than personal authority, where power flows through democratic institutions rather than individual whim. This inheritance, paid for with the blood of patriots from Lexington to Normandy, gave birth to the very idea of modern liberal democracy.</p>
<p>Now we watch as this precious inheritance is being systematically subjugated to the personal authority of Donald Trump and Elon Musk. The constitutional firebreaks designed to prevent the concentration of power—checks and balances, civil service protections, congressional oversight—are being dismantled not through revolution but through a calculated strategy of institutional capture. When private citizens gain control of Treasury systems, when security officials are removed for following classification protocols, when Congress abandons its constitutional duties, we’re witnessing the subordination of constitutional governance to personal power.</p>
<p>This isn’t just another political crisis—it’s an existential threat to the constitutional order that has secured human liberty for over two centuries. Every American who understands the value of this inheritance has a duty to resist its destruction. The Constitution doesn’t defend itself—it requires citizens willing to stand for the principles of democratic governance against those who would replace the rule of law with the rule of men.</p>
<p>There is a fundamental difference between partisan policy debates and what we’re witnessing now. When Republicans pass legislation on immigration, when they reform tax policy, when they push back against progressive cultural initiatives—this is the normal, healthy function of democratic governance. Elections have consequences, and the party in power has every right to advance its policy agenda through legal channels.</p>
<p>But what’s happening now exists in a different category entirely. When private citizens gain unauthorized access to Treasury payment systems, when security officials are removed for following classification protocols, when congressionally established agencies are illegally shuttered—these aren’t policy changes. They represent the systematic dismantling of the constitutional framework that makes policy debates possible in the first place.</p>
<p>Consider the profound difference: Opposing Democratic policies on taxation or immigration is legitimate political disagreement. Refusing to execute laws passed by Congress, removing civil servants for following legal requirements, and allowing private citizens to seize control of government functions represents an attack on constitutional governance itself. The former is about what policies we should have; the latter is about whether we’ll maintain a system where policy debates matter at all.</p>
<p>To conservatives who value our constitutional inheritance: This isn’t about advancing Republican policies or opposing Democratic ones. It’s about whether we’ll preserve the constitutional system that allows these debates to occur through democratic processes rather than personal decree. When we replace professional civil service with personal loyalty systems, when we ignore congressional mandates, when we allow private interests to seize control of government functions—we’re not winning political battles, we’re destroying the arena where those battles are meant to occur.</p>
<p>The voices of history echo through our present crisis with devastating clarity. Each American who gave their life to preserve constitutional democracy—from the blood-soaked fields of Gettysburg to the beaches of Normandy—did so with the faith that future generations would guard the precious gift of self-governance. They died not just to defeat specific enemies, but to ensure that government of the people, by the people, for the people would not perish from the earth.</p>
<p>Now, as we watch the systematic dismantling of constitutional governance—as private citizens seize control of government functions, as career civil servants are purged for following the law, as Congress abandons its duties—these sacrifices demand action from every American who understands what’s at stake. The transformation happening before our eyes—from a government bound by law to one bound by personal loyalty—is precisely what generations of Americans gave their lives to prevent.</p>
<p>This isn’t about partisan politics or policy preferences. This is about preserving the constitutional inheritance that makes American democracy possible at all. When we see security officials removed for protecting classified information, when we watch congressionally established agencies illegally shuttered, when we witness the machinery of government being captured by private interests—we’re seeing the unraveling of everything our fallen heroes died to protect.</p>
<p>The dead speak to us now with urgent clarity: The time for comfortable illusions has passed. Every American who values constitutional democracy must act to preserve it. Not tomorrow, not after the next election, but now—while the mechanisms for democratic resistance still exist. Our ancestors paid for our freedom with their blood. We dishonor their sacrifice if we surrender it through inaction.</p>
<p><em>Mike Brock is a former tech exec who was on the leadership team at Block. Originally published at his <a href="https://www.notesfromthecircus.com/p/a-coup-is-in-progress-in-america">Notes From the Circus</a>. Republished here with permission.</em></p>

				
<p>

	Filed Under: <a href="https://www.techdirt.com/tag/congress/" rel="tag">congress</a>, <a href="https://www.techdirt.com/tag/constitutional-crisis/" rel="tag">constitutional crisis</a>, <a href="https://www.techdirt.com/tag/coup/" rel="tag">coup</a>, <a href="https://www.techdirt.com/tag/democracy/" rel="tag">democracy</a>, <a href="https://www.techdirt.com/tag/donald-trump/" rel="tag">donald trump</a>, <a href="https://www.techdirt.com/tag/elon-musk/" rel="tag">elon musk</a>, <a href="https://www.techdirt.com/tag/politics/" rel="tag">politics</a>
	<br>

	
</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Order Declassifying JFK and MLK Assassination Records [pdf] (253 pts)]]></title>
            <link>https://www.govinfo.gov/content/pkg/FR-2025-01-31/pdf/2025-02116.pdf</link>
            <guid>42925712</guid>
            <pubDate>Tue, 04 Feb 2025 00:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.govinfo.gov/content/pkg/FR-2025-01-31/pdf/2025-02116.pdf">https://www.govinfo.gov/content/pkg/FR-2025-01-31/pdf/2025-02116.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42925712">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[El Salvador Abandons Bitcoin as Legal Tender After Failed Experiment (863 pts)]]></title>
            <link>https://ticotimes.net/2025/02/02/el-salvador-abandons-bitcoin-as-legal-tender-after-failed-experiment</link>
            <guid>42925210</guid>
            <pubDate>Tue, 04 Feb 2025 00:00:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ticotimes.net/2025/02/02/el-salvador-abandons-bitcoin-as-legal-tender-after-failed-experiment">https://ticotimes.net/2025/02/02/el-salvador-abandons-bitcoin-as-legal-tender-after-failed-experiment</a>, See on <a href="https://news.ycombinator.com/item?id=42925210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-td-block-uid="tdi_70">
<p>Bitcoin was never used by most Salvadorans, its modern city was never built, and now it will cease to be legal tender in El Salvador, the first country in the world to adopt it in 2021: a complete failed economic bet by President Nayib Bukele. Congress, dominated by the ruling party, approved last Wednesday a confusing reform to the Bitcoin Law at the request of Bukele’s government, which had no other option to receive the $1.4 billion credit agreed in December with the International Monetary Fund (<a href="https://www.imf.org/en/home" target="_blank" rel="noreferrer noopener">IMF</a>).</p>



<p>The reform eliminated the word “currency” when referring to bitcoin, but says it is “<a href="https://ticotimes.net/2021/09/07/in-world-first-bitcoin-becomes-legal-tender-in-el-salvador" target="_blank" rel="noreferrer noopener">legal tender</a>.” Despite the lack of clarity, it lifts, as required by the IMF, the obligation to accept it in transactions or debt payments, a key condition for it to be “legal tender,” according to economic analysts. With the change, “if someone owes you money and wants to pay you in bitcoin, you can refuse to be paid in bitcoin, but you cannot refuse if it’s legal tender,” economist Carlos Acevedo explained.</p>



<p>The use of bitcoin in El Salvador’s dollarized economy, according to the new rule, will be optional and will be at the discretion of the private sector to accept cryptocurrency payments for goods and services. Businesses are no longer required to convert dollar prices into this cryptocurrency. “Bitcoin no longer has that force of legal tender. That’s how it should have always remained, but the government wanted to force it and it didn’t work,” economist Rafael Lemus said.</p>



<h2 id="h-very-complicated-and-risky"><strong>Very Complicated and Risky</strong></h2>



<p>The Bitcoin Law reform will take effect 90 days after it’s published in the Official Gazette, which could happen in the coming days. For Acevedo, former president of the former Central Bank, “it makes no sense” to have left in the reformed law that it is “legal tender.” “It’s a monstrosity that’s not understood and that should be corrected and made clear that bitcoin is no longer legal tender,” the economist argues.</p>



<p>But even being so, Salvadorans, with the exception of a few, never embraced Bukele’s initiative, who enjoys enormous popularity for his war against gangs, which dropped homicides to historic lows in El Salvador. A recent survey by the Central American University (UCA) revealed that 92% of Salvadorans did not use bitcoin in their transactions in 2024.</p>



<p>“I used it and didn’t like it… Very complicated and risky. This is not for an employee who barely gets by on their salary,” Juana Henríquez, a 55-year-old nurse, said, saying she had tried to make some profit and instead lost money. Bukele also failed to achieve his project, which he announced with fireworks, to create Bitcoin City, a high-tech city that would be the capital of bitcoiners in the country and would take energy for mining from a volcano in Conchagua, about 200 km from Salvador.</p>



<p>Berlin, a city 110 km east of San Salvador, and <a href="https://ticotimes.net/2025/01/31/trump-effect-drives-bitcoin-growth-in-small-el-salvador-town">El Zont</a><a href="https://ticotimes.net/2025/01/31/trump-effect-drives-bitcoin-growth-in-small-el-salvador-town" target="_blank" rel="noreferrer noopener">e beach</a> (southwest) are two areas that concentrate bitcoiners, but many are foreign residents or tourists.</p>



<h2 id="h-government-reserves"><strong>Government Reserves</strong></h2>



<p>Bitcoin’s biggest promoter in the country, Bukele, has not yet referred to the legal reform. But officials ensure that the government will continue betting on this cryptocurrency, whose price currently exceeds $100,000. El Salvador’s ambassador to the United States, Milena Mayorga, told journalists Thursday, during a bitcoin event in San Salvador, that the law reforms should be seen as an adaptation “to the circumstances.”</p>



<p>The government, she assured, will continue buying bitcoin and having reserves in this cryptocurrency. According to the National Bitcoin Office, El Salvador has 6,050 bitcoins worth $634.8 million. “President Bukele continues buying bitcoin, we have a Bitcoin Office, we have the Bitcoin Law, bitcoin can be used in El Salvador. It hasn’t been an easy road,” Mayorga summarized.</p>



<p>For Lemus, because “the government has its bitcoin reserve and will buy more” it is necessary “to have transparency, for citizens to know how public funds are being invested.” Bukele recently said he is convinced that with Donald Trump – whom he supports – in the White House there will be “an exponential revaluation” of the cryptocurrency. He frequently posts price increases on his social networks. For now, he remains silent.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Bill Proposes Jail Time for People Who Download DeepSeek (469 pts)]]></title>
            <link>https://www.404media.co/senator-hawley-proposes-jail-time-for-people-who-download-deepseek/</link>
            <guid>42925001</guid>
            <pubDate>Mon, 03 Feb 2025 23:41:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/senator-hawley-proposes-jail-time-for-people-who-download-deepseek/">https://www.404media.co/senator-hawley-proposes-jail-time-for-people-who-download-deepseek/</a>, See on <a href="https://news.ycombinator.com/item?id=42925001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The Republican Senator from Missouri Josh Hawley has introduced a new bill that would make it illegal to import or export artificial intelligence products to and from China, meaning someone who knowingly downloads a Chinese developed AI model like the now immensely popular DeepSeek could face up to 20 years in jail, a million dollar fine, or both, should such a law pass.</p><p>Kevin Bankston, a senior advisor on AI governance at the Center for Democracy &amp; Technology, told 404 Media it is “a broad attack on the very idea of scientific dialogue and technology exchange with China around AI, with potentially ruinous penalties for AI researchers and users alike and deeply troubling implications for the future of online speech and freedom of scientific inquiry.”</p><p>Hawley <a href="https://www.hawley.senate.gov/hawley-introduces-legislation-to-decouple-american-ai-development-from-communist-china/?ref=404media.co"><u>introduced the legislation</u></a>, titled the Decoupling America’s Artificial Intelligence Capabilities from China Act, on Wednesday of last year.&nbsp;</p><p>“Every dollar and gig of data that flows into Chinese AI are dollars and data that will ultimately be used against the United States,” Senator Hawley said in a statement. “America cannot afford to empower our greatest adversary at the expense of our own strength. Ensuring American economic superiority means cutting China off from American ingenuity and halting the subsidization of CCP innovation.”</p><p>Hawley’s statement explicitly says that he introduced the legislation because of the release of DeepSeek, an advanced AI model that’s competitive with its American counterparts, and which its developers claimed was made for a fraction of the cost and without access to as many and as advanced of chips, though these claims are unverified. Hawley’s statement called DeepSeek “a data-harvesting, low-cost AI model that <a href="https://outreach.senate.gov/iqextranet/iqClickTrk.aspx?cid=SenHawley&amp;crop=14331QQQ9477525QQQ8249110QQQ8019990&amp;report_id=&amp;redirect=https%3A%2F%2Fwww.foxnews.com%2Fpolitics%2Fdeepseek-fallout-gop-sen-josh-hawley-seeks-cut-off-all-us-china-collaboration-ai-development%3Fintcmp%3Dtw_fnc&amp;redir_log=286219651778979&amp;ref=404media.co"><u>sparked</u></a> international concern and sent American technology stocks plummeting.”&nbsp;</p><p>Hawley’s statement says the goal of the bill is to “prohibit the import from or export to China of artificial intelligence technology, “prohibit American companies from conducting AI research in China or in cooperation with Chinese companies,” and “Prohibit U.S. companies from investing money in Chinese AI development.”</p><p>Hawley’s bill and its aims were covered credulously on <a href="https://www.foxnews.com/politics/deepseek-fallout-gop-sen-josh-hawley-seeks-cut-off-all-us-china-collaboration-ai-development?ref=404media.co"><u>Fox News</u></a>, but even if you think the bill’s goals are worth pursuing the actual <a href="https://www.hawley.senate.gov/wp-content/uploads/2025/01/Hawley-Decoupling-Americas-Artificial-Intelligence-Capabilities-from-China-Act.pdf?ref=404media.co"><u>language of the bill</u></a> is broad and dystopian. Unlike legislators who fearmongered about TikTok and wanted to ban it, Hawley’s bill would criminalize the activity of average users, millions of whom downloaded DeepSeek recently, making it one of the most popular apps on the Apple App store.&nbsp;</p><p>Specifically, the bill prohibits “the importation into the United States of artificial intelligence or generative artificial intelligence technology or intellectual proprietary developed or produced in the People’s Republic of China.” Those who violate this&nbsp; “Shall be subject to the criminal penalties set forth in subsection (b) of section 1760 of the Export Control Reform Act of 2018 (50 U. S.C, 4819).”&nbsp;</p><p><a href="https://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title50-section4819&amp;num=0&amp;edition=prelim&amp;ref=404media.co"><u>That law states that</u></a> “A person who willfully commits, willfully attempts to commit, or willfully conspires to commit, or aids and abets in the commission of, an unlawful act described in subsection (a) (1) shall be fined not more than $1,000,000; and (2) in the case of the individual, shall be imprisoned for not more than 20 years, or both.”</p><p>the Center for Democracy &amp; Technology’s Bankston told me that he’s skeptical that there would be strong criminal cases against someone who unintentionally downloaded an app like DeepSeek because the legislation specifies a person’s conduct must be “willful” for the imposition of criminal penalties, the bill is still “worrisomely broad.”&nbsp;</p><p>“It appears that it *could* apply to someone who downloaded DeepSeek knowing that it was from China, and yes, the criminal penalty for that under this proposal would be up to one million dollars or 20 years in prison (and also potentially civil penalties as well, which may require less proof of state of mind and may potentially even reach a mere accidental ‘importer’ of a Chinese model),” Bankston said.</p><p>The bill, which also prohibits the “transfer of research,” could create an unworkable environment for computer scientists who make their research public, and regularly read AI papers published by Chinese researchers.&nbsp;</p><p>“Beyond just impacting people downloading models from China, the bill's penalties for the import to or export from China of AI technology and intellectual property could also potentially extend to anyone who publishes AI models or research papers on the open internet knowing they will be downloaded by people in China,” Bankston said. “Researchers are also threatened by the second half of the bill, which would directly outlaw American collaboration with researchers at basically any Chinese university or company—with a fine of up to 100 million dollars for any company that violates the prohibition, amongst other penalties.”</p><p>"The bill threatens the development and publishing of AI advancements in the United States, and we're particularly worried about the impact on open and collaborative development of these technologies outside the proprietary systems of the Big Tech incumbents," Kit Walsh, the Electronic Frontier Foundation's Director of AI and Access-to-Knowledge Legal Projects, told me. "In the past, the government has argued that merely publishing information on the internet counts as an export, and interpreting this law in such a way would further solidify the dominance of proprietary AI over open or academic research. The law would also interfere with efforts at AI accountability, such as transparency requirements that states and members of Congress have sought to create in order to make sure that AI isn't harming people in the United States when used for decisions about such wide-ranging things as housing, health care, and hiring."</p><p>On its face, the bill seems mostly like hawkish posturing from Hawley, and the language of the bill seems unworkable given the current state of computer science, the AI industry, and the culture of researchers sharing their work. However, there is bipartisan support for legislation that targets China wherever it appears able to topple American dominance. Banning TikTok also seemed like a ludicrous notion at first given its popularity among Americans, and while the app is still live, a bill banning it did pass both the house and the Senate and was signed by the president.&nbsp;</p><p>Hawley’s office did not respond to a request for comment.</p><p><em>Update: This article has been updates with comment from the EFF.</em></p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

                    <div>
    <div>
      <p>About the author</p>
      <p>Emanuel Maiberg is interested in little known communities and processes that shape technology, troublemakers, and petty beefs. Email him at emanuel@404media.co
</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/headshot-1.jpg" alt="Emanuel Maiberg" src="https://www.404media.co/content/images/2023/08/headshot-1.jpg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No-Panic Rust: A Nice Technique for Systems Programming (177 pts)]]></title>
            <link>https://blog.reverberate.org/2025/02/03/no-panic-rust.html</link>
            <guid>42924448</guid>
            <pubDate>Mon, 03 Feb 2025 22:48:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.reverberate.org/2025/02/03/no-panic-rust.html">https://blog.reverberate.org/2025/02/03/no-panic-rust.html</a>, See on <a href="https://news.ycombinator.com/item?id=42924448">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Can Rust replace C? This is a question that has been on my mind for many years,
as I created and now am tech lead for
<a href="https://github.com/protocolbuffers/protobuf/tree/main/upb">upb</a>, a C library
for Protocol Buffers.  There is an understandable push to bring memory safety
  to all
parts of the software stack, and this would suggest a port of upb to Rust.</p>

<p>While I love the premise of Rust, I have long been skeptical that a port of upb
to Rust could preserve the performance and code size characteristics that I and
others have fought so hard to optimize.  In fact, this blog entry was
originally going to be an argument for why Rust cannot match C for upb’s use
case.</p>

<p>But I recently discovered a technique that shifted my thinking a lot.  I call
it “No-Panic Rust”, and while the technique is clearly not new<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">1</a></sup>, I was not
able to find any in-depth discussion of how it works or what problems it
solves.  This article is my attempt to fill that gap.</p>

<p>I believe that No-Panic Rust is the key to making Rust a compelling option for
low-level systems programming.  I now am optimistic about the possibility of
porting upb to Rust.</p>

<h2 id="what-are-panics">What are Panics?</h2>

<p>Panics are Rust’s mechanism for <em>unrecoverable errors</em>.  Anytime our program
encounters an error, we have three basic options for how to handle it:</p>

<ol>
  <li>Handle the error immediately (eg. retry the operation or fall back to plan B).</li>
  <li>Propagate the error to the caller, who can decide how to handle it.</li>
  <li>Immediately abort execution.</li>
</ol>

<p>In Rust, we use <code>Result</code> for (2) and <code>panic!()</code> for (3).  When we use <code>Result</code>,
it is considered a “recoverable error”, because the caller can test for the
error and decide how to respond.</p>

<p>With recoverable errors, the potential for error is reflected in the function
signature; a function that returns <code>Result</code> is fallible from the perspective of
the caller.  Panics on the other hand present the illusion of infallibility
from an API perspective, but then proceed to handle errors by simply aborting.</p>

<p>There is a lot of standard guidance for when to use <code>panic!()</code> vs <code>Result</code> (for
example,
<a href="https://doc.rust-lang.org/book/ch09-03-to-panic-or-not-to-panic.html">here</a>
and
<a href="https://doc.rust-lang.org/std/macro.panic.html#when-to-use-panic-vs-result">here</a>),
which largely boils down to the idea that panics should only be used for bugs
in the code.  I especially like the framing given in <a href="https://www.reddit.com/r/rust/comments/9x17hn/comment/e9p5c9t/">this Reddit post</a>:</p>

<blockquote>
  <p>[If] your <strong>library</strong> is the source of a panic, then one of the following
should be true:</p>

  <ul>
    <li>
      <p>Your library has a bug.</p>
    </li>
    <li>
      <p>Your library documents a precondition of a public API item that, when not
met, causes a panic. Therefore, the user of your library has misused your
library, and their code has a bug.</p>
    </li>
  </ul>

  <p>If your Rust <strong>application</strong> panics in response to any user input, then the
following should be true: your application has a bug, whether it be in a
library or in the primary application code.</p>
</blockquote>

<p>In this article we are focused on the library case.</p>

<h2 id="why-are-panics-bad-for-systems-libraries">Why Are Panics Bad For Systems Libraries?</h2>

<p>If we are trying to port a C library to Rust, we really do not want to
introduce panics in the code, even for unusual error conditions.  They cause
many practical problems:</p>

<ol>
  <li><strong>Code Size:</strong> The runtime to handle a panic pulls in about 300Kb of code.<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" rel="footnote">2</a></sup>
We pay this cost if even a single <code>panic!()</code> is reachable in the code.
From a code size perspective, this is a severe overhead, given that the upb
core is only 30Kb.</li>
  <li><strong>Unrecoverable exit:</strong> If a panic is triggered, it takes down the
entire process.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">3</a></sup>  In many applications, this is a severe failure mode
that libraries should never invoke.  Instead, we should return all errors
to the caller using status codes.</li>
  <li><strong>Runtime overhead:</strong> A potential panic implies some kind of runtime check.
In many cases, the cost of this check will be minimal, but for very small
and frequently invoked operations, the cost of this check could be
significant.</li>
</ol>

<p>In the case of upb, I was concerned about all three of these factors.  Ideally
we could port upb to Rust without users even noticing.  To do that, we want to
maintain the same performance, code size footprint, and error reporting
behavior that the C code has now.  Panics get in the way of this ideal.</p>

<p>At some point I realized that it might be possible to ban panics from the
library entirely, which would solve all of these problems at once.  That is
when I started getting much more optimistic about porting upb to Rust.</p>

<h2 id="what-is-no-panic-rust">What is No-Panic Rust?</h2>

<p>No-Panic Rust is a subset of Rust for which <code>panic!()</code> is unreachable.
Programs written in no-panic Rust are guaranteed never to panic under any
circumstances.</p>

<p>For a library, this means we should be able to build a <code>cdylib</code> that does
not have a panic handler linked into it at all.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">4</a></sup></p>

<p>We can experiment on <a href="https://godbolt.org/">godbolt.org</a>
to see if we have succeeded or not.  Using my tool <a href="https://github.com/google/bloaty">Bloaty</a>,
we can see if the <code>cdylib</code> binary is &gt;300Kb (suggesting that the panic
handler has been linked in) or &lt;10Ki (suggesting it has not).<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup></p>

<p>Let’s explore this subset a bit.  Is “Hello, World” no-panic?</p>

<div><pre><code><span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, World!"</span><span>)</span>    <span>// Can panic</span>
<span>}</span>
</code></pre></div>

<p>No, per <a href="https://doc.rust-lang.org/std/macro.println.html#panics">the documentation for <code>println!()</code></a>:</p>

<blockquote>
  <p>Panics if writing to <code>io::stdout</code> fails.</p>
</blockquote>

<p>And indeed, if we try this on Godbolt, we see a big binary:</p>



<p>So <code>println!()</code> is out.  If we want to print to stdout, we’ll need to use an API
that does not advertise that panic is possible.</p>

<p>The <a href="https://doc.rust-lang.org/beta/std/io/fn.stdout.html"><code>stdout</code></a> API looks
promising, because it has a <code>write_all()</code> API that returns a <code>Result</code>, which
should allow us to handle errors explicitly:</p>

<div><pre><code><span>use</span> <span>std</span><span>::</span><span>io</span><span>::{</span><span>self</span><span>,</span> <span>Write</span><span>};</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>()</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
    <span>let</span> <span>result</span> <span>=</span> <span>io</span><span>::</span><span>stdout</span><span>()</span><span>.write_all</span><span>(</span><span>b"Hello, World!</span><span>\n</span><span>"</span><span>);</span>
    <span>match</span> <span>result</span> <span>{</span>
        <span>Ok</span><span>(</span><span>_</span><span>)</span> <span>=&gt;</span> <span>true</span><span>,</span>
        <span>Err</span><span>(</span><span>_</span><span>)</span> <span>=&gt;</span> <span>false</span><span>,</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>This seems like it should be no-panic.  We are only calling two APIs,
<a href="https://doc.rust-lang.org/beta/std/io/fn.stdout.html"><code>stdout()</code></a> and
<a href="https://doc.rust-lang.org/beta/std/io/struct.Stdout.html#method.write_all-1"><code>write_all()</code></a>,
neither of which documents a potential panic.</p>

<p>But if we try it, we’ll see that panic is indeed reachable in this program
somehow.</p>



<p>From this we have learned that we unfortunately cannot rely on panic
annotations in API documentation to determine <em>a priori</em> whether some Rust code
is no-panic or not.  We have to actually try it and observe the results.</p>

<p>How can we diagnose what went wrong?  On macOS, the linker has a very handy
option called <code>-why_live</code>, which will print the chain of symbol references
that prevented a symbol from being dead-stripped.  We can’t access it on Godbolt
unfortunately, but on macOS we can run this command:</p>

<div><pre><code>$ RUSTC_LOG=rustc_codegen_ssa::back::link=info \
  RUSTFLAGS="-C link-arg=-Wl,-why_live,_rust_panic" \
  cargo build --release 2&gt;&amp;1 | rustfilt
</code></pre></div>

<p>This results in the following output, with extraneous details removed:</p>

<div><pre><code>_core::panicking::panic from [...]
  _core::ops::function::FnOnce::call_once from [...]
    l_anon.56b0c16dbe4596c74313e318a3dfaa78.520 from [...]
      _std::sync::once_lock::OnceLock&lt;T&gt;::initialize from [...]
        _std::io::stdio::stdout from [...]
          _hello_world from [...]
</code></pre></div>

<p>The panic reference apparently comes from
<code>_core::ops::function::FnOnce::call_once</code>, which is called
from <code>_std::io::stdio::stdout</code>.</p>

<p>This seems to suggest that Rust’s standard library does not meet the criteria
given <a href="#what-are-panics">above</a>, because it is capable of panicing even in APIs
like <code>std::io::stdout()</code> that do not document a panic-worthy precondition.</p>

<p>This also implies that we need tests that check for the no-panic property.
It’s not enough to check once that the code is no-panic, we need to make sure
it <em>stays</em> no-panic over time, even as our project and our dependendencies
evolve.</p>

<p>To get a fully no-panic version of “Hello, World”, we have to reach for the C
library <code>libc</code>.  This makes sense, since the C library is generally written to
return all errors as status codes or <code>errno</code>.  Unfortunately this means turning
to <code>unsafe</code>:</p>

<div><pre><code><span>extern</span> <span>crate</span> <span>libc</span><span>;</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>()</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
    <span>const</span> <span>MSG</span><span>:</span> <span>&amp;</span><span>'static</span> <span>str</span> <span>=</span> <span>"Hello, World!</span><span>\n\0</span><span>"</span><span>;</span>
    <span>let</span> <span>result</span> <span>=</span> <span>unsafe</span> <span>{</span>
        <span>libc</span><span>::</span><span>printf</span><span>(</span><span>MSG</span><span>.as_ptr</span><span>()</span> <span>as</span> <span>*</span><span>const</span> <span>_</span><span>)</span>
    <span>};</span>
    <span>result</span> <span>&gt;=</span> <span>0</span>
<span>}</span>
</code></pre></div>

<p>And checking on Godbolt, we see the small binary that confirms that this
library is indeed no-panic:</p>



<h2 id="opt-no-panic">Opt No-Panic</h2>

<p>What about adding two numbers?  Is this no-panic?</p>

<div><pre><code><span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>(</span><span>a</span><span>:</span> <span>i32</span><span>,</span> <span>b</span><span>:</span> <span>i32</span><span>)</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
    <span>a</span> <span>+</span> <span>b</span>
<span>}</span>
</code></pre></div>

<p>This is a trick question: this is no-panic in opt mode only.  For numeric
operations like addition, Rust introduces overflow checks (which panic on
failure) in debug mode, but leaves them out of opt builds.</p>

<p>We can observe this on Godbolt if we add separate panes for opt and non-opt
builds:<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">6</a></sup></p>



<p>This essentially creates a new class of code, which is “no-panic in opt, but
can panic in dbg”.</p>

<p>For the case of upb, this seems like a great option, because it gives us extra
consistency checks in debug mode without suffering the problems of panic in
release builds.  It is essentially the Rust equivalent of <code>assert()</code> in C.
Overflow by itself does not represent a safety issue, so we are not giving up
safety by leaving the panics out of opt builds.</p>

<h2 id="rusts-standard-library">Rust’s Standard Library</h2>

<p>What about using standard containers like <code>Vec</code>?</p>

<div><pre><code><span>use</span> <span>std</span><span>::</span><span>hint</span><span>::</span><span>black_box</span><span>;</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>()</span> <span>{</span>
    <span>let</span> <span>vec</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u32</span><span>&gt;</span> <span>=</span> <span>Vec</span><span>::</span><span>new</span><span>();</span>
    <span>black_box</span><span>(</span><span>vec</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>It turns out this is also “opt no-panic” code (perhaps <code>Vec</code> is internally
performing some arithmetic which can overflow):</p>



<p>But once we try to actually push elements into the <code>Vec</code>, we’re squarely out
of no-panic Rust:</p>



<p><code>Vec</code> does have a few APIs that will surface allocation errors instead of panicking.
Theoretically, this code should be no-panic:</p>

<div><pre><code><span>#![feature(vec_push_within_capacity)]</span>

<span>use</span> <span>std</span><span>::</span><span>hint</span><span>::</span><span>black_box</span><span>;</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>()</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>vec</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u32</span><span>&gt;</span> <span>=</span> <span>Vec</span><span>::</span><span>new</span><span>();</span>
    <span>if</span> <span>!</span><span>vec</span><span>.try_reserve</span><span>(</span><span>1</span><span>)</span><span>.is_ok</span><span>()</span> <span>{</span>
        <span>return</span> <span>false</span><span>;</span>
    <span>}</span>
    <span>if</span> <span>!</span><span>vec</span><span>.push_within_capacity</span><span>(</span><span>1</span><span>)</span><span>.is_ok</span><span>()</span> <span>{</span>
        <span>return</span> <span>false</span><span>;</span>
    <span>}</span>
    <span>black_box</span><span>(</span><span>vec</span><span>);</span>
    <span>true</span>
<span>}</span>
</code></pre></div>

<p>This requires the nightly compiler, but I was able to make this work as no-panic
on macOS.  For some reason, it did not work with the nightly compiler on Godbolt,
which appears to always include the panic runtime no matter what I do, even for a
trivial library.  I was not able to figure out why.</p>

<p>The Rust standard library was not really designed to be no-panic.  For example,
memory allocation failure will panic in most cases.  If we want to be no-panic,
we will probably have to avoid most of the standard library.  Realisticaly we
will probably want to go fully <code>#![no_std]</code>.</p>

<h2 id="a-dance-with-the-optimizer">A Dance With The Optimizer</h2>

<p>Here is another trick question: is this no-panic Rust?</p>

<div><pre><code><span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>if</span> <span>data</span><span>.len</span><span>()</span> <span>&lt;</span> <span>1</span> <span>{</span>
        <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>data</span><span>[</span><span>0</span><span>]</span>
<span>}</span>
</code></pre></div>

<p>On one hand, the slice index operation <a href="https://doc.rust-lang.org/std/ops/trait.Index.html#tymethod.index">clearly
documents</a>
that it may panic.  On the other hand, the docs say that this panic will only
be triggered if the index is out of bounds, and we have inserted a guard to
ensure that it never is.  So is the panic reachable?</p>

<p>If we use our minds to reason about the code, we would conclude that panic is
unreachable.  The compiler is capable of reaching the same conclusion, but only
if we run the optimizer, which can prove through a series of optimizations that
the bounds check will never fail.</p>

<p>So this example ends up being “opt no-panic”, just like our arithmetic
operation, but for an entirely different reason!</p>



<p>This is quite an interesting result that totally changed my thinking about
Rust’s bounds checks.</p>

<p>My previous perspective was that Rust will insert all of these unnecessary
bounds checks, bloating the code and slowing it down for no reason.  But our
pre-existing C code is not throwing caution to the wind and hoping for the
best.  Every place that we perform an index operation in C, it’s because we
believe we have a proof that the index is in bounds.  To avoid the bounds
checks in Rust, we just need to express this proof in a way that the Rust
optimizer can understand.  This is what I call the “dance with the optimizer.”</p>

<h2 id="a-slightly-more-dangerous-dance">A Slightly More Dangerous Dance</h2>

<p>In the example above, the bounds check is eliminated using only safe code,
but there are other cases where we might need to use unsafe code to help
the optimizer know about program invariants that cannot be easily derived
from the program flow.</p>

<p>For example, consider this (admittedly contrived) program:</p>

<div><pre><code><span>pub</span> <span>struct</span> <span>S</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
    <span>data</span><span>:</span> <span>&amp;</span><span>'a</span><span>[</span><span>u8</span><span>],</span>
    <span>ofs</span><span>:</span> <span>usize</span><span>,</span>   <span>// Invariant: ofs &lt; data.len()</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>S</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>S</span><span>&gt;</span> <span>{</span>
        <span>match</span> <span>data</span><span>.len</span><span>()</span> <span>{</span>
            <span>0</span> <span>=&gt;</span> <span>None</span><span>,</span>
            <span>n</span> <span>=&gt;</span> <span>Some</span><span>(</span><span>S</span><span>{</span><span>data</span><span>:</span> <span>data</span><span>,</span> <span>ofs</span><span>:</span> <span>n</span> <span>-</span> <span>1</span><span>}),</span>
        <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
        <span>self</span><span>.data</span><span>[</span><span>self</span><span>.ofs</span><span>]</span>
    <span>}</span>
<span>}</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>(</span><span>s</span><span>:</span> <span>&amp;</span><span>S</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>s</span><span>.get</span><span>()</span>
<span>}</span>
</code></pre></div>

<p>In this program, our struct <code>S</code> has an invariant that the offset <code>S::ofs</code> will
always be in bounds.  This invariant effectively guarantees that the bounds
check in <code>S::get()</code> will never fail.  And we can strongly guarantee that the
invariant holds, because it is enforced by our <code>new()</code> function which is the
only code that sets these struct members.</p>

<p>But the optimizer isn’t capable of reasoning at this level, so it thinks that
the panic is reachable, and keeps the bounds check in the program, even in opt
mode:</p>



<p>To make this no-panic, we need to help the compiler out by reminding it that
this struct invariant holds in the critical path:</p>

<div><pre><code><span>use</span> <span>std</span><span>::</span><span>hint</span><span>::</span><span>assert_unchecked</span><span>;</span>

<span>pub</span> <span>struct</span> <span>S</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
    <span>data</span><span>:</span> <span>&amp;</span><span>'a</span><span>[</span><span>u8</span><span>],</span>
    <span>ofs</span><span>:</span> <span>usize</span><span>,</span>   <span>// Invariant: ofs &lt; data.len()</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>S</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>check_invariant</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>unsafe</span> <span>{</span> <span>assert_unchecked</span><span>(</span><span>self</span><span>.ofs</span> <span>&lt;</span> <span>self</span><span>.data</span><span>.len</span><span>())</span> <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>S</span><span>&gt;</span> <span>{</span>
        <span>match</span> <span>data</span><span>.len</span><span>()</span> <span>{</span>
            <span>0</span> <span>=&gt;</span> <span>None</span><span>,</span>
            <span>n</span> <span>=&gt;</span> <span>{</span>
                <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>{</span><span>data</span><span>:</span> <span>data</span><span>,</span> <span>ofs</span><span>:</span> <span>n</span> <span>-</span> <span>1</span><span>};</span>
                <span>s</span><span>.check_invariant</span><span>();</span>
                <span>Some</span><span>(</span><span>s</span><span>)</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
        <span>self</span><span>.check_invariant</span><span>();</span>
        <span>self</span><span>.data</span><span>[</span><span>self</span><span>.ofs</span><span>]</span>
    <span>}</span>
<span>}</span>

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>hello_world</span><span>(</span><span>s</span><span>:</span> <span>&amp;</span><span>S</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>s</span><span>.get</span><span>()</span>
<span>}</span>
</code></pre></div>

<p>This makes use of
<a href="https://doc.rust-lang.org/std/hint/fn.assert_unchecked.html"><code>std::hint::assert_unchecked</code></a>,
a very sharp tool for making soundness promises to the compiler.  Here we use
it to inform the compiler of our struct invariant.  This has the desired effect
of making this “opt no-panic”:</p>



<p>This definitely requires care; we have to be very sure that the predicate we
pass to <code>assert_unchecked</code> is true.  Luckily we can fuzz against this assertion
to increase our confidence (in debug mode, <code>assert_unchecked</code> will panic if the
condition is not true).  Used judiciously, it can be a powerful tool for
explicitly expressing to Rust the invariants we were relying on to make index
operations safe in C.</p>

<h2 id="conclusion">Conclusion</h2>

<p>No-Panic Rust is not for the faint of heart.  It requires a lot of careful,
detailed work, and forces you to give up some niceties of Rust, like the
standard library.  But if we are diligent, it can give us the performance, code
size, and error reporting behavior of a C library with the extra safety that
comes from Rust.</p>

<p>This extra safety comes from the fact that Rust will automatically insert
bounds checks anywhere it cannot prove that an access is safe.  This puts
the burden on us to justify to the compiler in every case why the bounds
check is safe to elide.  In some cases this will mean detecting a bounds
violation explictly and reporting the error to the caller (especially in
parsers, where we do not know whether the input is valid or not).  In other
cases, we may know through a program invariant that the index will always
be in-bounds, and we will need to communicate this invariant to Rust.</p>

<p>I should be clear that I have not yet attempted this technique at scale, so
I cannot report on how well it works in practice.  For now it is an exciting
future direction for upb, and one that I hope will pay off.</p>

<p>To make this technique practical, we need a tool that can diagnose where a
panic handler was reachable from.  The main technique we used in this article
(looking at binary size) does not give us any information about where a panic
came from.  On macOS, the <code>-why_live</code> linker option is perfect for this.  I
hope other linkers like LLD will add support for this option also.  If not, a
standalone tool could be written that analyzes a binary after it’s linked to
find the chain of references that lead to a panic handler.</p>

<p>It would be nice if Rust made it easier to stay within the no-panic subset.
It’s clear that writing no-panic code is not a core use case that the language
focuses on, but there are many situations (embedded, Linux Kernel, etc) where
we want to avoid panics.  It would be nice if functions or even crates could
advertise themselves as no-panic and have the compiler enforce this
transitively.  Changing a function from no-panic to panicking would then be an
API-breaking change.</p>


  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A computer can never be held accountable (304 pts)]]></title>
            <link>https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/</link>
            <guid>42923870</guid>
            <pubDate>Mon, 03 Feb 2025 22:01:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/">https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/</a>, See on <a href="https://news.ycombinator.com/item?id=42923870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://twitter.com/bumblebike/status/832394003492564993">A computer can never be held accountable</a></strong>. This legendary page from an internal IBM training in 1979 could not be more appropriate for our new age of AI.</p>
<p><img alt="A COMPUTER CAN NEVER BE HELD ACCOUNTABLE. THEREFORE A COMPUTER MUST NEVER MAKE A MANAGEMENT DECISION" src="https://static.simonwillison.net/static/2025/a-computer-can-never-be-held-accountable.jpg"></p>
<blockquote>
<p><strong>A computer can never be held accountable</strong></p>
<p><strong>Therefore a computer must never make a management decision</strong></p>
</blockquote>
<p>Back in June 2024 I <a href="https://twitter.com/simonw/status/1798168995373498524">asked on Twitter</a> if anyone had more information on the original source.</p>
<p>Jonty Wareing <a href="https://twitter.com/jonty/status/1798170111058264280">replied</a>:</p>
<blockquote>
<p>It was found by someone going through their father's work documents, and subsequently destroyed in a flood.</p>
<p>I spent some time corresponding with the IBM archives but they can't locate it. Apparently it was common for branch offices to produce things that were not archived.</p>
</blockquote>
<p>Here's <a href="https://twitter.com/jonty/status/1727344374370222264">the reply</a> Jonty got back from IBM:</p>
<p><img alt="Dear Jonty Wareing, This is Max Campbell from the IBM Corporate Archives responding to your request. Unfortunately, I've searched the collection several times for this presentation and I am unable to find it. I will take another look today and see if I can find it, but since there is so little information to go on, l'm not sure I will be successful. Sincerely, Max Campbell, Reference Desk, IBM Corporate Archives, 2455 South Rd, Bldg 04-02 Room CSC12, Poughkeepsie, NY 12601" src="https://static.simonwillison.net/static/2025/jonty-reply.jpeg"></p>
<p>I believe the image was first shared online in <a href="https://twitter.com/bumblebike/status/832394003492564993">this tweet</a> by @bumblebike in February 2017. Here's where they confirm <a href="https://twitter.com/bumblebike/status/1385690727330451457">it was from 1979 internal training</a>.</p>
<p>Here's <a href="https://twitter.com/bumblebike/status/1468346709994582020">another tweet from @bumblebike</a> from December 2021 about the flood:</p>
<blockquote>
<p>Unfortunately destroyed by flood in 2019 with most of my things.  Inquired at the retirees club zoom last week, but there’s almost no one the right age left. Not sure where else to ask.</p>
</blockquote>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Euro LLM: Open LLMs for Transparent AI in Europe (297 pts)]]></title>
            <link>https://openeurollm.eu/launch-press-release</link>
            <guid>42922989</guid>
            <pubDate>Mon, 03 Feb 2025 20:56:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openeurollm.eu/launch-press-release">https://openeurollm.eu/launch-press-release</a>, See on <a href="https://news.ycombinator.com/item?id=42922989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>Press release (Feb. 3, 2025)</span></p></div><section><p>Europe's leading AI companies and research institutions combine their forces and expertise to develop next-generation open-source language models in an unprecedented collaboration to advance European AI capabilities, the<!-- --> <a target="_blank" href="https://openeurollm.eu/">OpenEuroLLM project</a>.</p><p>A consortium of<!-- --> <strong>20 leading European research institutions</strong>, companies and EuroHPC centres coordinated by Jan Hajič (<a href="https://ufal.mff.cuni.cz/">Charles University</a>, Czechia) and co-led by Peter Sarlin (<a href="https://www.silo.ai/">AMD Silo AI</a>, Finland) will build a family of performant, multilingual, large language foundation models for commercial, industrial and public services.</p><p>The <strong>transparent and compliant open-source models</strong> <!-- -->will democratize access to high-quality AI technologies and strengthen the ability of European companies to compete on a global market and public organizations to produce impactful public services.</p><p>The OpenEuroLLM project is aligned with the imperative to improve Europe’s competitiveness and digital sovereignty. The project is a prime example of the type of technology infrastructure needed to lower thresholds for European AI product development and refinement, demonstrating the strength of transparency, openness and community involvement, values largely recognized across the European tech ecosystem.</p><p>The models will be developed within Europe's robust regulatory framework, ensuring alignment with European values while maintaining technological excellence. Cooperating with open-source and open science communities like<!-- --> <a href="https://laion.ai/">LAION</a>, open-sci and<!-- --> <a href="https://openml.org/">OpenML</a>, and additional experts in the field assembled in the project’s Open Strategic Partnership Board, OpenEuroLLM will ensure that the models, software, data and evaluation will be fully open and can be fine-tuned and instruction-tuned for specific industry and public sector needs. These performant multilingual models preserve both linguistic and cultural diversity, enabling European companies to develop high-quality products and services in the era of AI.</p><p> <!-- -->The project, which has been awarded the STEP (Strategic Technologies for Europe Platform) seal, leverages support from previous European projects and the experience of the partners and their results, including large repositories of high-quality data and pilot LLMs developed previously. The consortium commences its work on February 1st, 2025, with funding from the European Commission under the Digital Europe Programme.</p></section><section><h2>Full list of partners</h2><h3>Universities and Research Organizations:</h3><ul><li><a target="_blank" href="https://ufal.mff.cuni.cz/">Charles University, Institute of Formal and Applied Linguistics</a>, Czechia (coordinator)<!-- --> </li><li><a target="_blank" href="https://alt-edic.eu/about-us/">Alliance for Language Technologies EDIC</a>, (ALT-EDIC), France</li><li><a target="_blank" href="https://www.tue.nl/en/">Eindhoven University of Technology</a>, the Netherlands</li><li><a target="_blank" href="https://institute-tue.ellis.eu/">ELLIS Institute Tübingen</a>, Germany</li><li><a target="_blank" href="https://www.iais.fraunhofer.de/en.html">Fraunhofer IAIS</a>, Germany</li><li><a target="_blank" href="https://www.fz-juelich.de/en">Research Center Juelich</a>, Germany</li><li><a target="_blank" href="https://www.ai.se/en">Lindholmen Science Park</a>, (AI Sweden), Sweden</li><li><a target="_blank" href="https://www.helsinki.fi/en">University of Helsinki</a>, Finland</li><li><a target="_blank" href="https://www.uio.no/english/">University of Oslo</a>, Norway</li><li><a target="_blank" href="https://www.utu.fi/en">University of Turku</a>, Finland</li><li><a target="_blank" href="https://tuebingen.ai/">University of Tübingen,</a> <a target="_blank" href="https://uni-tuebingen.de/en/">(Tübingen AI Center)</a>, Germany</li></ul><h3>Companies:</h3><ul><li><a target="_blank" href="https://www.silo.ai/">Silo GenAI</a>, (AMD Silo AI), Finland (co-lead)</li><li><a target="_blank" href="https://aleph-alpha.com/">Aleph Alpha Research</a>, Germany</li><li><a target="_blank" href="https://ellamind.com/">ellamind</a>, Germany</li><li><a target="_blank" href="https://www.lighton.ai/">LightOn</a>, France</li><li><a target="_blank" href="https://www.prompsit.com/">Prompsit Language Engineering</a>, Spain</li></ul><h3>EuroHPC centres:</h3><ul><li><a target="_blank" href="https://www.bsc.es/">Barcelona Supercomputing Center</a>, Spain</li><li><a target="_blank" href="https://www.cineca.it/en">Cineca Interuniversity Consortium</a>, Italy</li><li><a target="_blank" href="https://csc.fi/en/">CSC - IT Center for Science</a>, Finland</li><li><a target="_blank" href="https://www.surf.nl/en">SURF</a>, the Netherlands</li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IRS Direct File team disbanded (112 pts)]]></title>
            <link>https://twitter.com/elonmusk/status/1886498750052327520</link>
            <guid>42922543</guid>
            <pubDate>Mon, 03 Feb 2025 20:25:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/elonmusk/status/1886498750052327520">https://twitter.com/elonmusk/status/1886498750052327520</a>, See on <a href="https://news.ycombinator.com/item?id=42922543">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Cantonese Scrolls – A Cantonese language learning mental RPG (114 pts)]]></title>
            <link>https://cantoscrolls.com/</link>
            <guid>42922052</guid>
            <pubDate>Mon, 03 Feb 2025 19:48:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cantoscrolls.com/">https://cantoscrolls.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42922052">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <h3>Jonathan Vasquez (范俊樂)</h3>
    <h3>2025 年 01 月 27 日 20 點 00 分</h3>

    <hr>

    <h2>Dedication</h2>

    <div><p>
        This game is dedicated to my beautiful wife, <b><i>Fallon</i></b>, and my dear late Chinchilla daughter,
        <b><i>Leslie</i></b>,
        who have both forever changed my life.</p><p><b><i>Juntos para siempre</i></b>.
    </p></div>

    <hr>

    <h2>Main Menu</h2>
    <div><p>
        Welcome to <b>The Cantonese Scrolls (粵卷)</b> - <b>A Cantonese Language Learning Mental RPG</b>.</p><p>

        This game can be played in two modes:
    </p></div>

    <div>
        <table>
            <tbody><tr>
                <td><b>Single Player</b></td>
                <td>This mode is for people who prefer studying independently ;).</td>
            </tr>
            <tr>
                <td><b>Multiplayer (Couch Co-Op)</b></td>
                <td>This mode is identical to the above, but you'll have someone else
                    with you to go along for the ride :).
                </td>
            </tr>
        </tbody></table>
    </div>

    <br>
    <h2><a href="https://cantoscrolls.com/town.html">Start Game</a></h2>
    <br>
    <hr>

    <h2>Game Standards</h2>

    

    <h2>A Living Document</h2>

    <p>
        This game is <b><i>a living document</i></b>, and will continuously be updated with more content,
        extensions, and language corrections.
    </p>

    <h2>License</h2>

    <p>
        This game is released under the <b><a href="https://cantoscrolls.com/extra/license.html">Mozilla Public License 2.0</a></b>.
    </p>

    <h2>About</h2>

    <p>
        Since <b><i>Cantonese has no formal standardization for its phonetic and writing systems</i></b>,
        it is extremely difficult for a new learner to find resources for it, and pick up the language.
        My goal for this game is to document the Cantonese language as I currently understand it, and
        create a fun and simple large body of work, that can be <b><i>freely</i></b> used by anyone to
        learn the language.
    </p>

    <h2><a href="https://cantoscrolls.com/The_Cantonese_Scrolls.zip">Download Offline Backup</a></h2>

    <p>
        <b><i>This game is available for download, free of charge, with no
                internet connection required.</i></b> If you found this game
        useful and would like to either thank me and/or support me in
        its on-going development, please consider donating. Every bit
        counts. Thank you!
    </p>

    <a href="https://liberapay.com/fearedbliss/donate"><img alt="Donate using Liberapay" src="https://liberapay.com/assets/widgets/donate.svg"></a>

    <h2><a href="https://cantoscrolls.com/additional.html">Additional Resources</a></h2>

    <h5>Copyright © 2023-2025 Jonathan Vasquez &lt;jon@xyinn.org&gt;</h5>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Remote Code Execution in Marvel Rivals Game (182 pts)]]></title>
            <link>https://shalzuth.com/Blog/IFoundAGameExploit</link>
            <guid>42920962</guid>
            <pubDate>Mon, 03 Feb 2025 18:02:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shalzuth.com/Blog/IFoundAGameExploit">https://shalzuth.com/Blog/IFoundAGameExploit</a>, See on <a href="https://news.ycombinator.com/item?id=42920962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="intro">Intro</h2><p>Security vulnerabilities in online games aren't just theoretical - they happen more often than you'd think. Recently, I discovered a <strong>Remote Code Execution (RCE) exploit</strong> in Marvel Rivals that could allow an attacker on the same network to run arbitrary code on another player's device.</p><h2 id="the-elephant">The Elephant</h2><p>The issue is the game uses remote code execution for their hotfix patching system - but <strong>the game doesn't verify that it's connected to the real game server</strong>, and the cherry on top is that <strong>the game runs with admin privileges for the sake of anti-cheat.</strong></p><p>This type of exploit, known as Remote Code Execution (RCE), is one of the most dangerous vulnerabilities a game can have. It means an attacker could potentially run harmful commands on your PC without your knowledge - just by being connected to the same Wi-Fi.</p><h2 id="video">Video</h2><p>Watch my breakdown of the exploit and why game security matters</p><iframe width="50%" src="https://youtube.com/embed/sSXoH1xYIcE"></iframe><h2 id="ps5-implications">PS5 Implications</h2><p>This also opens the door up to an entrypoint on PS5. You can see the POC here - <a href="https://youtu.be/IDxUaIvVxmY">https://youtu.be/IDxUaIvVxmY</a></p><h2 id="other-rant">Other Rant</h2><p>Game developers continue to amaze me at their lack of security awareness.</p><p>In the past year, I've found at least 5 critical bugs in VERY POPULAR games that can have a negative impact on the entire player base. 3 of them still exist, because either the game dev isn't reachable, or the game dev just straight up doesn't care. Cool, right?</p><p>It's very hard for security researchers to report bugs to most game dev companies. On top of that, most do not have bug bounty programs. It is a huge shame, and it encourages people looking into video game security to not report vulnerabilities and only create hacks and bots, because that's where the money is. Thank you to those game devs that do have successful bug bounty programs!</p><h2 id="contributions">Contributions</h2><p>AeonLucid, LukeFZ, nitro, and sanktanglia all helped with the network crypto and helped out.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD: Microcode Signature Verification Vulnerability (263 pts)]]></title>
            <link>https://github.com/google/security-research/security/advisories/GHSA-4xq7-4mgh-gp6w</link>
            <guid>42920921</guid>
            <pubDate>Mon, 03 Feb 2025 17:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google/security-research/security/advisories/GHSA-4xq7-4mgh-gp6w">https://github.com/google/security-research/security/advisories/GHSA-4xq7-4mgh-gp6w</a>, See on <a href="https://news.ycombinator.com/item?id=42920921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h3 dir="auto">Summary</h3>
<p dir="auto">Google Security Team has identified a security vulnerability in some AMD Zen-based CPUs. This vulnerability allows an adversary with local administrator privileges (ring 0 from outside a VM) to load malicious microcode patches. We have demonstrated the ability to craft arbitrary malicious microcode patches on Zen 1 through Zen 4 CPUs. The vulnerability is that the CPU uses an insecure hash function in the signature validation for microcode updates.  This vulnerability could be used by an adversary to compromise confidential computing workloads protected by the newest version of AMD Secure Encrypted Virtualization, SEV-SNP or to compromise Dynamic Root of Trust Measurement.</p>
<p dir="auto">AMD SEV-SNP users can verify the fix by confirming TCB values for SNP in their attestation reports (can be observed from a VM, consult <a href="https://www.amd.com/en/resources/product-security/bulletin/amd-sb-3019.html" rel="nofollow">AMD's security bulletin</a> for further details).</p>
<h3 dir="auto">Severity</h3>
<p dir="auto">HIGH - Improper signature verification in&nbsp;AMD CPU ROM microcode patch loader may allow an attacker with local administrator privilege to load malicious CPU microcode resulting in loss of confidentiality and integrity of a confidential guest running under AMD SEV-SNP.</p>
<h3 dir="auto">Proof of Concept</h3>
<p dir="auto">A test payload for Milan and Genoa CPUs that makes the RDRAND instruction return 4 can be downloaded <a href="https://github.com/google/security-research/tree/master/pocs/cpus/entrysign">here</a> (applying it requires the user to be root from outside of a VM).</p>
<h3 dir="auto">Timeline</h3>
<p dir="auto"><strong>Date reported</strong>:  September 25, 2024<br>
<strong>Date fixed</strong>:  December 17, 2024<br>
<strong>Date disclosed</strong>:  February 3, 2025</p>
<p dir="auto">Google notified AMD of this vulnerability on September 25, 2024. AMD subsequently provided an embargoed fix to its customers on December 17, 2024. To coordinate with AMD, we made a one-off exception to our standard <a href="https://about.google/appsecurity" rel="nofollow">vulnerability disclosure policy</a> and delayed public disclosure until today, February 3, 2025. This joint disclosure occurs 46 days after AMD shared the fix with its customers and 131 days after Google's initial report. Due to the deep supply chain, sequence and coordination required to fix this issue, we will not be sharing full details at this time in order to give users time to re-establish trust on their confidential-compute workloads. We will share additional details and tools on March 5, 2025.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Developer Philosophy (252 pts)]]></title>
            <link>https://qntm.org/devphilo</link>
            <guid>42920285</guid>
            <pubDate>Mon, 03 Feb 2025 17:00:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qntm.org/devphilo">https://qntm.org/devphilo</a>, See on <a href="https://news.ycombinator.com/item?id=42920285">Hacker News</a></p>
Couldn't get https://qntm.org/devphilo: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>