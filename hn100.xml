<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Sep 2024 19:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Pirate library must pay publishers $30M, but no one knows who runs it (101 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/09/pirate-library-must-pay-publishers-30m-but-no-one-knows-who-runs-it/</link>
            <guid>41688242</guid>
            <pubDate>Sun, 29 Sep 2024 16:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/09/pirate-library-must-pay-publishers-30m-but-no-one-knows-who-runs-it/">https://arstechnica.com/tech-policy/2024/09/pirate-library-must-pay-publishers-30m-but-no-one-knows-who-runs-it/</a>, See on <a href="https://news.ycombinator.com/item?id=41688242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      "This site can't be reached"    —
</h4>
            
            <h2 itemprop="description">Some Libgen links can’t be reached after broad takedown order.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-1128391448-800x534.jpg" alt="Pirate library must pay publishers $30M, but no one knows who runs it">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 1:single/related:af6ba39c1aa8a5e7fd46c6bdaab9cde8 --><!-- empty -->
<p>On Thursday, some links to the notorious shadow library Library Genesis (Libgen) couldn't be reached after a US district court judge, Colleen McMahon, <a href="https://cdn.arstechnica.net/wp-content/uploads/2024/09/Cengage-v-LibGen-Default-Judgment-9-24-24.pdf">ordered</a> what TorrentFreak <a href="https://torrentfreak.com/u-s-court-orders-libgen-to-pay-30m-to-publishers-issues-broad-injunction-240925/">called</a> "one of the broadest anti-piracy injunctions" ever issued by a US court.</p>
<p>In her order, McMahon sided with textbook publishers who <a href="https://arstechnica.com/tech-policy/2023/09/most-notorious-illegal-shadow-library-sued-by-textbook-publishers/">accused Libgen of willful copyright infringement</a> after Libgen completely ignored their complaint.</p>
<p>To compensate rightsholders, McMahon ordered Libgen to pay $30 million, but because nobody knows who runs the shadow library, it seems unlikely that publishers will be paid any time soon, if ever.</p>
<p>Because Libgen's admins remain anonymous and elusive—and previously avoided paying <a href="https://arstechnica.com/tech-policy/2017/06/scientific-research-piracy-site-hit-with-15-million-fine/">a different set of publishers $15 million</a> in 2017—McMahon granted publishers' request for an uncommonly broad injunction that may empower publishers to go further than ever to destroy the shadow library.</p>
<p>Under the injunction, not only is Libgen banned from sharing copyrighted content, but so are "all those in active concert or participation with" anyone connected to Libgen. The order forbids anyone from hosting Libgen, registering Libgen domains, or providing cloud storage, file-sharing, or advertising services, among other restrictions. Even using tools to display links or enabling browser extensions linking to Libgen is forbidden under the order.</p>
<p>But even under such a broad injunction, the question remains whether publishers can succeed in taking down Libgen—which <a href="https://www.roundonce.com/the-folks-behind-libgen/">openly informs users</a> that using its platform violates copyright laws and encourages them to pirate books anyway.</p>
<p>"It is illegal to download ('make copies of') material that is protected by copyright," Libgen's 2023 video said. "However, all that is illegal is not criminal… for the average person, generally there won't be any criminal consequences under copyright law from having pirated items on your computer."</p>
<p>Publishers are potentially already succeeding in taking down some of Libgen's links that enable vast infringement. Yesterday, TorrentFreak reported that none of the Libgen sites targeted in publishers' complaint were down, but as of Thursday, some links couldn't be reached, timed out while loading, or generated a 403 error denying access. The majority of links, including the primary domain, remain online, though.</p>                                                                        
                                                                                
<p>As TorrentFreak noted, it's possible that most of the Libgen links remain online because the order is just two days old. In the order, McMahon gave registrars of LinkedIn domains 21 business days to either transfer domains to publishers' control or "otherwise implement technical measures, such as holding, suspending, or canceling the domain name to ensure the domain names cannot be used" for further copyright infringement.</p>
<p>TorrentFreak suggested that "completely eliminating" Libgen has been "extremely difficult" for years, though, "partly because the identities of those running it remains unknown." The site, known for closely monitoring file-sharing online, only considered publishers' most recent victory "a win on paper."</p>
<p>Notably, the broad injunction that McMahon ordered does not require Internet service providers to block Libgen, although other countries have tried that, too. Instead, publishers seem to be hoping that controlling domains will get rid of the pirate library, with the court ordering any newly registered domains to be turned over to publishers, too.</p>
<p>Targeting future domains could stop Libgen from endlessly pointing users to new links to avoid takedowns, as it has historically. But there's a chance that third parties may resist complying with the order, TorrentFreak noted.</p>
<h2>Ad ban may be key to Libgen’s destruction</h2>
<p>So far at least, Libgen remains online through it all, attracting 16 million monthly visits to its primary domain, which Ars confirmed is still online as of this writing. And it's still exceedingly popular in the US, McMahon's order noted.</p>
<p>In 2023, the shadow library <a href="https://www.roundonce.com/the-folks-behind-libgen/">told</a> users that it remains indestructible by relying on "thousands of volunteers worldwide who upload files and share the torrents to protect the shadow library from being taken down."</p>
<p>Perhaps the most significant aspect of the order isn't the focus on domain registration, though, but a ban on providing advertising services.</p>
<p>Last year, Libgen also <a href="https://www.roundonce.com/questions-and-answers-about-ebooks/">told</a> users that it's primarily funded through Google advertising. In the video, Libgen was warning users that while admins are difficult to unmask, "Google gets informed of every download, and if a user has ever registered with Google, then Google knows exactly who they are, what they've downloaded, and when they downloaded it."</p>
<p>If Google cuts off Libgen's advertising, the site could potentially struggle to afford to continue operating.</p>
<p>Ars attempted to reach Libgen for comment, but Libgen's inbox was full. Ars will update this story if Google provides any new insights.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC Report Confirms: Commercial Surveillance Is Out of Control (121 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/09/ftc-report-confirms-commercial-surveillance-out-control</link>
            <guid>41688080</guid>
            <pubDate>Sun, 29 Sep 2024 15:38:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/09/ftc-report-confirms-commercial-surveillance-out-control">https://www.eff.org/deeplinks/2024/09/ftc-report-confirms-commercial-surveillance-out-control</a>, See on <a href="https://news.ycombinator.com/item?id=41688080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>A </span><a href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-staff-report-finds-large-social-media-video-streaming-companies-have-engaged-vast-surveillance"><span>new Federal Trade Commission (FTC) report</span></a><span> confirms what EFF has been warning about for years: tech giants are widely harvesting and sharing your personal information to fuel their online behavioral advertising businesses. This four-year investigation into the data practices of nine social media and video platforms, including Facebook, YouTube, and X (formally Twitter), demonstrates how commercial surveillance leaves consumers with little control over their privacy. While not every investigated company committed the same privacy violations, the conclusion is clear: companies prioritized profits over privacy.&nbsp;</span></p>
<p><span>While EFF has long warned about these practices, the FTC’s investigation offers detailed evidence of how widespread and invasive commercial surveillance has become. Here are key takeaways from the report:</span></p>
<h3>Companies Collected Personal Data Well Beyond Consumer Expectations</h3>
<p><span>The FTC report confirms that companies collect data in ways that far exceed user expectations. They’re not just tracking activity on their platforms, but also monitoring activity on other websites and apps, gathering data on non-users, and buying personal information from third-party data brokers. Some companies could not, or would not, disclose exactly where their user data came from.&nbsp;</span></p>
<p><span>The FTC found companies gathering detailed personal information, such as the websites you visit, your location data, your demographic information, and your interests, including sensitive interests like “divorce support” and “beer and spirits.” Some companies could only report high-level descriptions of the user attributes they tracked, while others produced spreadsheets with thousands of attributes.&nbsp;</span></p>
<h3>There’s Unfettered Data Sharing With Third Parties</h3>
<p><span>Once companies collect your personal information, they don’t always keep it to themselves. Most companies reported sharing your personal information with third parties. Some companies shared so widely that they claimed it was impossible to provide a list of all third-party entities they had shared personal information with. For the companies that could identify recipients, the lists included law enforcement and other companies, both inside and outside the United States.&nbsp;</span></p>
<p><span>Alarmingly, most companies had no vetting process for third parties before sharing your data, and none conducted ongoing checks to ensure compliance with data use restrictions. For example, when companies say they’re just sharing your personal information for something that seems unintrusive, like analytics, there's no guarantee your data is only used for the stated purpose. The lack of safeguards around data sharing exposes consumers to </span><a href="https://slate.com/technology/2021/07/catholic-priest-grindr-data-privacy.html"><span>significant</span></a> <a href="https://www.wyden.senate.gov/news/press-releases/wyden-reveals-phone-data-used-to-target-abortion-misinformation-at-visitors-to-hundreds-of-reproductive-health-clinics"><span>privacy</span></a> <a href="https://thehill.com/policy/technology/3619515-ftc-alleges-data-broker-exposes-users-to-violent-threats-by-selling-location-data/"><span>risks</span></a><span>.</span></p>
<h3>Consumers Are Left in the Dark</h3>
<p><span>The FTC report reveals a disturbing lack of transparency surrounding how personal data is collected, shared, and used by these companies. If companies can’t tell the FTC who they share data with, how can you expect them to be honest with you?</span></p>
<p><span>Data tracking and sharing happens behind the scenes, leaving users largely unaware of how much privacy they’re giving up on different platforms. These companies don't just collect data from their own platforms—they gather information about non-users and from users' activity across the web. This makes it nearly impossible for individuals to avoid having their personal data swept up into these vast digital surveillance networks. Even when companies offer privacy controls, the controls are often opaque or ineffective. The FTC also found that some companies were not actually deleting user data in response to deletion requests.</span></p>
<p><span>The scale and secrecy of commercial surveillance described by the FTC demonstrates why the burden of protecting privacy can’t fall solely on individual consumers.</span></p>
<h3>Surveillance Advertising Business Models Are the Root Cause</h3>
<p><span>The FTC report underscores a fundamental issue: these privacy violations are not just occasional missteps—they’re inherent to the business model of online behavioral advertising. Companies collect vast amounts of data to create detailed user profiles, primarily for targeted advertising. The profits generated from targeting ads based on personal information drive companies to develop increasingly invasive methods of data collection. The FTC found that the business models of most of the companies incentivized privacy violations.</span></p>
<h3>FTC Report Underscores Urgent Need for Legislative Action</h3>
<p><span>Without federal privacy legislation, companies have been able to collect and share billions of users’ personal data with few safeguards. The FTC report confirms that self-regulation has failed: companies’ internal data privacy policies are inconsistent and inadequate, allowing them to prioritize profits over privacy. In the FTC’s own words, “The report leaves no doubt that without significant action, the commercial surveillance ecosystem will only get worse.”</span></p>
<p><span>To address this, the EFF advocates for federal privacy legislation. It should have many components, but these are key:</span></p>
<ol>
<li><a href="https://www.eff.org/files/2023/11/21/privacy_first_a_better_way_to_address_online_harms.pdf"><span>Data minimization and user rights</span></a><span>: Companies should be prohibited from processing a person’s data beyond what’s necessary to provide them what they asked for. Users should have the right to access their data, port it, correct it, and delete it.</span></li>
<li><a href="https://www.eff.org/deeplinks/2022/03/ban-online-behavioral-advertising"><span>Ban on Online Behavioral Advertising</span></a><span>: We should tackle the root cause of commercial surveillance by banning behavioral advertising. Otherwise, businesses will always find ways to skirt around privacy laws to keep profiting from intrusive data collection.</span></li>
<li><a href="https://www.eff.org/deeplinks/2019/01/you-should-have-right-sue-companies-violate-your-privacy"><span>Strong Enforcement with Private Right of Action</span></a><span>: To give privacy legislation bite, people should have a private right of action to sue companies that violate their privacy. Otherwise, we’ll continue to see widespread violation of privacy laws due to limited government enforcement resources.&nbsp;</span></li>
</ol>
<p><span>Using online services shouldn't mean surrendering your personal information to countless companies to use as they see fit.&nbsp; When you sign up for an account on a website, you shouldn’t need to worry about random third-parties getting your information or every click being monitored to serve you ads. For now, our </span><a href="https://privacybadger.org/"><span>Privacy Badger extension</span></a><span> can help you block some of the tracking technologies detailed in the FTC report. But the scale of commercial surveillance revealed in this investigation requires significant legislative action. Congress must act now and&nbsp;protect our data&nbsp;from corporate exploitation with a strong federal privacy law.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flexible RISC-V Processor: Could Cost Less Than a Dollar (146 pts)]]></title>
            <link>https://spectrum.ieee.org/flexible-risc-v</link>
            <guid>41687739</guid>
            <pubDate>Sun, 29 Sep 2024 14:42:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/flexible-risc-v">https://spectrum.ieee.org/flexible-risc-v</a>, See on <a href="https://news.ycombinator.com/item?id=41687739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="A Bendy RISC-V Processor"><p>For the first time, scientists have created a flexible programmable chip that is not made of silicon. The new ultralow-power 32-bit microprocessor from U.K.-based <a href="https://www.pragmaticsemi.com/" target="_blank">Pragmatic Semiconductor</a> and its colleagues can operate while bent, and can run <a href="https://spectrum.ieee.org/tag/machine-learning">machine learning</a> workloads. The microchip’s open-source RISC-V architecture suggests it might cost less than a dollar, putting it in a position to power wearable healthcare electronics,  smart package labels, and other inexpensive items, its inventors add.<br></p><p>For example, “we can develop an <a href="https://spectrum.ieee.org/skin-circuits" target="_self">ECG</a> patch that has flexible electrodes attached to the chest and a flexible microprocessor connected to flexible electrodes to classify <a href="https://en.wikipedia.org/wiki/Arrhythmia" target="_blank">arrhythmia</a> conditions by processing the ECG data from a patient,” says Emre Ozer, senior director of processor development at Pragmatic, a flexible chip manufacturer in Cambridge, England. Detecting normal heart rhythms versus an arrhythmia “is a machine learning task that can run in software in the flexible microprocessor,” he says.</p><p><a href="https://spectrum.ieee.org/stretchable-electronics" target="_self"><u>Flexible electronics</u></a> have the potential for any application requiring interactions with soft materials, such as devices worn on or implanted within the body. Those applications could include <a href="https://spectrum.ieee.org/skin-circuits" target="_self"><u>on-skin computers</u></a>, <a href="https://spectrum.ieee.org/soft-robotics" target="_self"><u>soft robotics</u></a>, and <a href="https://spectrum.ieee.org/a-braincomputing-interface-that-lasts-for-weeks" target="_self"><u>brain-machine interfaces</u></a>. But, conventional electronics are made of rigid materials such as silicon.<strong></strong></p><h2>Open-source, Flexible, and Fast Enough</h2><p>Pragmatic sought to create a flexible microchip that cost significantly less to make than a silicon processor. The new device, named Flex-RV, is a 32-bit microprocessor based on the metal-oxide semiconductor <a href="https://spectrum.ieee.org/transparent-transistorshttps://spectrum.ieee.org/thin-fast-and-flexible-semiconductors" target="_blank">indium gallium zinc oxide (IGZO</a>).</p><p>Attempts to create flexible devices from silicon require special packaging for the brittle microchips to protect them from the mechanical stresses of bending and stretching. In contrast, pliable thin-film transistors made from IGZO can be made directly at low temperatures onto flexible plastics, leading to lower costs.</p><p>The new microchip is based on the <a href="https://spectrum.ieee.org/risc-v-ai" target="_self">RISC-V</a> instruction set. (RISC stands for reduced instruction set computer.) First introduced in 2010, RISC-V aims to enable smaller, lower-power, better-performing processors by slimming down the core set of instructions they can execute.</p><p>“Our end goal is to democratize computing by developing a license-free microprocessor,” Ozer says.</p><p>RISC-V’s is both free and open-source, letting chip designer dodge the costly licensing fees associated with proprietary architectures such as x86 and Arm. In addition, proprietary architectures offer limited opportunities to customize them, as adding new instructions is generally restricted. In contrast, RISC-V encourages such changes.</p><p data-rm-resized-container="25%"><img alt="A computer monitor saying Hello World! hangs above gloved hands sitting next to a green board with a golden chip bent around a tube." data-rm-shortcode-id="4715a668b795e977db277c7650752dbf" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-computer-monitor-saying-hello-world-hangs-above-gloved-hands-sitting-next-to-a-green-board-with-a-golden-chip-bent-around-a-t.jpg?id=53684043&amp;width=980" height="1145" id="e0c08" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-computer-monitor-saying-hello-world-hangs-above-gloved-hands-sitting-next-to-a-green-board-with-a-golden-chip-bent-around-a-t.jpg?id=53684043&amp;width=980" width="643"><small placeholder="Add Photo Caption...">A bent Flex-RV microprocessor runs a program to print ‘Hello World’. </small><small placeholder="Add Photo Credit...">Pragmatic Semiconductor</small></p><p>“We chose the <a href="https://github.com/olofk/serv" target="_blank">Serv</a> designed by Olof Kindgren... as the open source 32-bit RISC-V CPU when we designed Flex-RV,” Ozer says. “Serv is the smallest RISC-V processor in the open-source community.”</p><p>Other processors have been built using flexible <a href="https://spectrum.ieee.org/topic/semiconductors/">semiconductors</a>, such as Pragmatic’s 32-bit <a href="https://www.nature.com/articles/s41586-021-03625" rel="noopener noreferrer" target="_blank">PlasticARM</a><u></u>and an <a href="https://spectrum.ieee.org/plastic-microprocessor" target="_blank">ultracheap microcontroller</a> designed by engineers in Illinois. Unlike these earlier devices, Flex-RV is programmable and can run compiled programs written in high-level languages such as C. In addition, the open-source nature of RISC-V also let the researchers equip Flex-RV with a programmable <a href="https://spectrum.ieee.org/risc-v-ai" target="_blank">machine learning hardware accelerator,</a> enabling <a href="https://spectrum.ieee.org/topic/artificial-intelligence/">artificial intelligence</a> applications.</p><p>Each Flex-RV microprocessor has a 17.5 square millimeter core and roughly 12,600 <a href="https://spectrum.ieee.org/optical-computing-picosecond-gates" target="_self">logic gates</a>. The research team found Flex-RV could run as fast as 60 kilohertz while consuming less than 6 milliwatts of power.</p><p>All previous flexible non-silicon microprocessors were tested solely on the wafers they were made on. In contrast, Flex-RV was tested on flexible printed circuit boards, which let the researchers see how well it operated when flexed. The Pragmatic team found that Flex-RV could still execute programs correctly when bent to a curve with a radius of 3 millimeters. Performance varied between a 4.3 percent slowdown to a 2.3 percent speedup depending on the way it was bent. “Further research is needed to understand how bending conditions such as direction, orientation and angle impact performance at macro and micro scales,” Ozer says.</p><p>Silicon microchips can run at gigahertz speeds, much faster than Flex-RV, but that shouldn’t be a problem, according to Ozer. “Many sensors—for example, temperature, pressure, odor, humidity, pH, and so on—<a href="https://spectrum.ieee.org/the-internet-of-disposable-things-will-be-made-of-paper-and-plastic-sensors" target="_blank">in the flexible electronics world</a> typically operate very slowly at hertz or kilohertz regimes,” he says. “These sensors are used in smart packaging, labels and wearable healthcare electronics, which are the emerging applications for which flexible microprocessors will be useful. Running the microprocessor at 60 kHz would be more than enough to meet the requirements of these applications.”</p><p>Ozer and his team suggest each Flex-RV might cost less than a dollar. Although Ozer did not want to say how much less than a dollar it might cost, he says they are confident such low costs are possible “thanks to low-cost flexible chip fabrication technology by Pragmatic and a license-free RISC-V technology.”</p><p>The scientists detailed <u><a href="https://www.nature.com/articles/s41586-024-07976-y" target="_blank">their findings</a></u> online 25 September in the journal <em>Nature</em>.</p><div><p>From Your Site Articles</p><ul><li><a href="https://spectrum.ieee.org/riscvs-opensource-architecture-shakes-up-chip-design" target="_blank" rel="noopener noreferrer">RISC-V's Open-Source Architecture Shakes Up Chip Design - IEEE ... ›</a></li><li><a href="https://spectrum.ieee.org/risc-v-raspberry-pi" target="_blank" rel="noopener noreferrer">RISC-V Guns for Raspberry Pi, Legacy Chips - IEEE Spectrum ›</a></li><li><a href="https://spectrum.ieee.org/risc-v-chip-delivers-quantum-resistant-encryption" target="_blank" rel="noopener noreferrer">RISC-V Chip Delivers Quantum-Resistant Encryption ›</a></li><li><a href="https://spectrum.ieee.org/risc-v-ai" target="_blank" rel="noopener noreferrer">RISC-V AI Chips Will Be Everywhere - IEEE Spectrum ›</a></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Some Go web dev notes (169 pts)]]></title>
            <link>https://jvns.ca/blog/2024/09/27/some-go-web-dev-notes/</link>
            <guid>41687707</guid>
            <pubDate>Sun, 29 Sep 2024 14:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2024/09/27/some-go-web-dev-notes/">https://jvns.ca/blog/2024/09/27/some-go-web-dev-notes/</a>, See on <a href="https://news.ycombinator.com/item?id=41687707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>I spent a lot of time in the past couple of weeks working on a website in Go
that may or may not ever see the light of day, but I learned a couple of things
along the way I wanted to write down. Here they are:</p>

<h3 id="go-1-22-now-has-better-routing">go 1.22 now has better routing</h3>

<p>I’ve never felt motivated to learn any of the Go routing libraries
(gorilla/mux, chi, etc), so I’ve been doing all my routing by hand, like this.</p>

<pre><code>	// DELETE /records:
	case r.Method == "DELETE" &amp;&amp; n == 1 &amp;&amp; p[0] == "records":
		if !requireLogin(username, r.URL.Path, r, w) {
			return
		}
		deleteAllRecords(ctx, username, rs, w, r)
	// POST /records/&lt;ID&gt;
	case r.Method == "POST" &amp;&amp; n == 2 &amp;&amp; p[0] == "records" &amp;&amp; len(p[1]) &gt; 0:
		if !requireLogin(username, r.URL.Path, r, w) {
			return
		}
		updateRecord(ctx, username, p[1], rs, w, r)

</code></pre>

<p>But apparently <a href="https://go.dev/blog/routing-enhancements">as of Go 1.22</a>, Go
now has better support for routing in the standard library, so that code can be
rewritten something like this:</p>

<pre><code>	mux.HandleFunc("DELETE /records/", app.deleteAllRecords)
	mux.HandleFunc("POST /records/{record_id}", app.updateRecord)
</code></pre>

<p>Though it would also need a login middleware, so maybe something more like
this, with a <code>requireLogin</code> middleware.</p>

<pre><code>	mux.Handle("DELETE /records/", requireLogin(http.HandlerFunc(app.deleteAllRecords)))
</code></pre>

<h3 id="a-gotcha-with-the-built-in-router-redirects-with-trailing-slashes">a gotcha with the built-in router: redirects with trailing slashes</h3>

<p>One annoying gotcha I ran into was: if I make a route for <code>/records/</code>, then a
request for <code>/records</code> <a href="https://pkg.go.dev/net/http#hdr-Trailing_slash_redirection-ServeMux">will be redirected</a> to <code>/records/</code>.</p>

<p>I ran into an issue with this where sending a POST request to <code>/records</code>
redirected to a GET request for <code>/records/</code>, which broke the POST request
because it removed the request body. Thankfully <a href="https://xeiaso.net/blog/go-servemux-slash-2021-11-04/">Xe Iaso wrote a blog post about the exact same issue</a> which made it
easier to debug.</p>

<p>I think the solution to this is just to use API endpoints like <code>POST /records</code>
instead of <code>POST /records/</code>, which seems like a more normal design anyway.</p>

<h3 id="sqlc-automatically-generates-code-for-my-db-queries">sqlc automatically generates code for my db queries</h3>

<p>I got a little bit tired of writing so much boilerplate for my SQL queries, but
I didn’t really feel like learning an ORM, because I know what SQL queries I
want to write, and I didn’t feel like learning the ORM’s conventions for
translating things into SQL queries.</p>

<p>But then I found <a href="https://sqlc.dev/">sqlc</a>, which will compile a query like this:</p>

<pre><code>
-- name: GetVariant :one
SELECT *
FROM variants
WHERE id = ?;

</code></pre>

<p>into Go code like this:</p>

<pre><code>const getVariant = `-- name: GetVariant :one
SELECT id, created_at, updated_at, disabled, product_name, variant_name
FROM variants
WHERE id = ?
`

func (q *Queries) GetVariant(ctx context.Context, id int64) (Variant, error) {
	row := q.db.QueryRowContext(ctx, getVariant, id)
	var i Variant
	err := row.Scan(
		&amp;i.ID,
		&amp;i.CreatedAt,
		&amp;i.UpdatedAt,
		&amp;i.Disabled,
		&amp;i.ProductName,
		&amp;i.VariantName,
	)
	return i, err
}
</code></pre>

<p>What I like about this is that if I’m ever unsure about what Go code to write
for a given SQL query, I can just write the query I want, read the generated
function and it’ll tell me exactly what to do to call it. It feels much easier
to me than trying to dig through the ORM’s documentation to figure out how to
construct the SQL query I want.</p>

<p>Reading <a href="https://brandur.org/fragments/sqlc-2024">Brandur’s sqlc notes from 2024</a> also gave me some confidence
that this is a workable path for my tiny programs. That post gives a really
helpful example of how to conditionally update fields in a table using CASE
statements (for example if you have a table with 20 columns and you only want
to update 3 of them).</p>

<h3 id="sqlite-tips">sqlite tips</h3>

<p>Someone on Mastodon linked me to this post called <a href="https://kerkour.com/sqlite-for-servers">Optimizing sqlite for servers</a>. My projects are small and I’m
not so concerned about performance, but my main takeaways were:</p>

<ul>
<li>have a dedicated object for <strong>writing</strong> to the database, and run
<code>db.SetMaxOpenConns(1)</code> on it. I learned the hard way that if I don’t do this
then I’ll get <code>SQLITE_BUSY</code> errors from two threads trying to write to the db
at the same time.</li>
<li>if I want to make reads faster, I could have 2 separate db objects, one for writing and one for reading</li>
</ul>

<p>There are a more tips in that post that seem useful (like “COUNT queries are
slow” and “Use STRICT tables”), but I haven’t done those yet.</p>

<p>Also sometimes if I have two tables where I know I’ll never need to do a <code>JOIN</code>
beteween them, I’ll just put them in separate databases so that I can connect
to them independently.</p>

<h3 id="go-1-19-introduced-a-way-to-set-a-gc-memory-limit">Go 1.19 introduced a way to set a GC memory limit</h3>

<p>I run all of my Go projects in VMs with relatively little memory, like 256MB or
512MB. I ran into an issue where my application kept getting OOM killed and it
was confusing – did I have a memory leak? What?</p>

<p>After some Googling, I realized that maybe I didn’t have a memory leak, maybe I
just needed to reconfigure the garbage collector! It turns out that by default (according to <a href="https://tip.golang.org/doc/gc-guide">A Guide to the Go Garbage Collector</a>), Go’s garbage collector will
let the application allocate memory up to <strong>2x</strong> the current heap size.</p>

<p><a href="https://messwithdns.net/">Mess With DNS</a>’s base heap size is around 170MB and
the amount of memory free on the VM is around 160MB right now, so if its memory
doubled, it’ll get OOM killed.</p>

<p>In Go 1.19, they added a way to tell Go “hey, if the application starts using
this much memory, run a GC”. So I set the GC memory limit to 250MB and it seems
to have resulted in the application getting OOM killed less often:</p>

<pre><code>export GOMEMLIMIT=250MiB
</code></pre>

<h3 id="some-reasons-i-like-making-websites-in-go">some reasons I like making websites in Go</h3>

<p>I’ve been making tiny websites (like the <a href="https://nginx-playground.wizardzines.com/">nginx playground</a>) in Go on and off for the last 4 years or so and it’s really been working for me. I think I like it because:</p>

<ul>
<li>there’s just 1 static binary, all I need to do to deploy it is copy the binary</li>
<li>there’s a built-in webserver that’s okay to use in production, so I don’t need to configure WSGI or whatever to get it to work</li>
<li>Go’s toolchain is very easy to install, I can just do <code>apt-get install golang-go</code> or whatever and then a <code>go build</code> will build my project</li>
<li>it feels like there’s very little to remember to start sending HTTP responses
– basically all there is are functions like <code>Serve(w http.ResponseWriter, r *http.Request)</code> which read the request and send a response. If I need to
remember some detail of how exactly that’s accomplished, I just have to read
the function!</li>
<li>also <code>net/http</code> is in the standard library, so you can start making websites
without installing any libraries at all. I really appreciate this one.</li>
<li>Go is a pretty systems-y language, so if I need to run an <code>ioctl</code> or
something that’s easy to do</li>
</ul>

<p>In general everything about it feels like it makes projects easy to work on for
5 days, abandon for 2 years, and then get back into writing code without a lot
of problems.</p>

<p>For contrast, I’ve tried to learn Rails a couple of times and I really <em>want</em>
to love Rails – I’ve made a couple of toy websites in Rails and it’s always
felt like a really magical experience. But ultimately when I come back to those
projects I can’t remember how anything works and I just end up giving up. It
feels easier to me to come back to my Go projects that are full of a lot of
repetitive boilerplate, because at least I can read the code and figure out how
it works.</p>

<h3 id="it-s-cool-to-see-the-new-features-go-has-been-adding">it’s cool to see the new features Go has been adding</h3>

<p>Both of the Go features I mentioned in this post (<code>GOMEMLIMIT</code> and the routing)
are new in the last couple of years and I didn’t notice when they came out. It
makes me think I should pay closer attention to the release notes for new Go
versions.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web components are okay (150 pts)]]></title>
            <link>https://nolanlawson.com/2024/09/28/web-components-are-okay/</link>
            <guid>41686722</guid>
            <pubDate>Sun, 29 Sep 2024 11:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2024/09/28/web-components-are-okay/">https://nolanlawson.com/2024/09/28/web-components-are-okay/</a>, See on <a href="https://news.ycombinator.com/item?id=41686722">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>Every so often, the web development community gets into a tizzy about something, usually web components. I find these fights tiresome, but I also see them as a good opportunity to reach across <a href="https://css-tricks.com/the-great-divide/">“the great divide”</a> and try to find common ground rather than another opportunity to dunk on each other.</p>
<p>Ryan Carniato started the latest round with <a href="https://dev.to/ryansolid/web-components-are-not-the-future-48bh">“Web Components Are Not the Future”</a>. Cory LaViska followed up with <a href="https://www.abeautifulsite.net/posts/web-components-are-not-the-future-they-re-the-present/">“Web Components Are Not the Future — They’re the Present”</a>. I’m not here to escalate, though – this is a peace mission.</p>
<p>I’ve been an avid follower of Ryan Carniato’s work for years. <a href="https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/">This post</a> and the steady climb of <a href="https://lwc.dev/">LWC</a> on the <a href="https://github.com/krausest/js-framework-benchmark"><code>js-framework-benchmark</code></a> demonstrate that I’ve been paying attention to what he has to say, especially about performance and framework design. The guy has single-handedly done more to move the web framework ecosystem forward in the past 5 years than anyone else I can think of.</p>
<p>That said, I also heavily work with web components, both on the framework side and as a <a href="https://github.com/nolanlawson/emoji-picker-element/">component author</a>. I’ve participated in the <a href="https://www.w3.org/community/webcomponents/">Web Components Community Group</a> and <a href="https://github.com/WICG/aom/">Accessibility Object Model group</a>, and I’ve written extensively on shadow DOM, custom elements, and web component accessibility in this blog.</p>
<p>So <em>obviously</em> I’m going to be interested when I see a post from Ryan Carniato on web components. And it’s a thought-provoking post! But I also think he misses the mark on a few things. So let’s dive in:</p>
<h2>Performance</h2>
<blockquote><p>
  [T]he fundamental problem with Web Components is that they are built on Custom Elements.</p>
<p>  […] [E]very interface needs to go through the DOM. And of course this has a performance overhead.
</p></blockquote>
<p>This is completely true. If your goal is to build the absolute fastest framework you can, then you want to minimize DOM nodes wherever possible. This means that web components are off the table.</p>
<p>I fully believe that Ryan knows how to build the fastest possible framework. Again, the <a href="https://krausest.github.io/js-framework-benchmark/">results</a> for Solid on the <code>js-framework-benchmark</code> are a testament to this.</p>
<p>That said – and I might alienate some of my friends in the web performance community by saying this – performance isn’t everything. There are other tradeoffs in software development, such as maintainability, security, usability, and accessibility. Sometimes these things come into conflict.</p>
<p>To make a silly example: I could make DOM rendering slightly faster by never rendering any <code>aria-*</code> attributes. But of course sometimes you <em>have</em> to render <code>aria-*</code> attributes to make your interface accessible, and nobody would argue that a couple milliseconds are worth excluding screen reader users.</p>
<p>To make an even sillier example: you can improve performance by using <code>for</code> loops instead of <code>.forEach()</code>. Or using <a href="https://www.reddit.com/r/sveltejs/comments/1fklm73/curious_about_the_use_of_var_in_the_svelte_5/"><code>var</code> instead of <code>const</code>/<code>let</code></a>. Typically, though, these kinds of micro-optimizations are just not worth it.</p>
<p>When I see this kind of stuff, I’m reminded of <a href="https://www.youtube.com/watch?v=7rIJNT7dCmE">speedrunners trying to shave milliseconds</a> off a 5-minute run of Super Mario Bros using precise inputs and obscure glitches. If that’s your goal, then by all means: <a href="https://ukikipedia.net/wiki/Backwards_Long_Jump">backwards long jump</a> across the entire stage instead of just having Mario run forward. I’ll continue to be impressed by what you’re doing, but it’s just not for me.</p>
<p>Minimizing the use of DOM nodes is a classic optimization – this is the main idea behind <a href="https://web.dev/articles/virtualize-long-lists-react-window">virtualization</a>. That said, sometimes you can get away with <a href="https://nolanlawson.com/2024/09/18/improving-rendering-performance-with-css-content-visibility/">simpler approaches</a>, even if it’s not the absolute fastest option. I’d put “components as elements” in the same bucket – yes it’s sub-optimal, but optimal is not always the goal.</p>
<p>Similarly, I’ve long argued that <a href="https://nolanlawson.com/2021/08/01/why-its-okay-for-web-components-to-use-frameworks/">it’s fine for custom elements to use different frameworks</a>. Sometimes you just need to gradually migrate from Framework A to Framework B. Or you have to compose some micro-frontends together. Nobody would argue that this is the fastest possible interface, but fine – sometimes tradeoffs have to be made.</p>
<p>Having worked for a long time in the web performance space, I find that the lowest-hanging fruit for performance is usually something dumb like <a href="https://web.dev/articles/avoid-large-complex-layouts-and-layout-thrashing">layout thrashing</a>, network waterfalls, unnecessary re-renders, etc. Framework authors like myself love to play <a href="https://en.wikipedia.org/wiki/Code_golf">performance golf</a> with things like the <code>js-framework-benchmark</code>, and it’s a great flex, but it just doesn’t usually matter in the real world.</p>
<p>That said, if it does matter to you – if you’re building for resource-constrained environments where every millisecond counts: great! Ditch web components! I will geek out and cheer for every speedrunning record you break.</p>
<h2>The cost of standards</h2>
<blockquote><p>
  More code to ship and more code to execute to check these edge cases. It’s a hidden tax that impacts everyone.
</p></blockquote>
<p>Here’s where I completely get off the train from Ryan’s argument. As a framework author, I just don’t find that it’s that much effort to support web components. Detecting props versus attributes is a simple <code>prop in element</code> check. <em>Outputting</em> web components is indeed painful, but hey – nobody said you have to do it. Vue 2 got by with a standalone <a href="https://github.com/vuejs/vue-web-component-wrapper">web component wrapper library</a>, and <a href="https://github.com/rstacruz/remount">Remount</a> exists without any input from the React team.</p>
<p>As a framework author, if you want to freeze your thinking in 2011 and code as if nothing new was added to the web platform since then, you absolutely can! And you can still write a great framework! This is the beauty of the web. jQuery v1 is still chugging away on plenty of websites, and in fact it gets faster and faster with every new browser release, since browser perf teams are often targeting whatever patterns web developers used ~5 year ago in an endless <a href="https://learn.microsoft.com/en-us/shows/webplatformsummit-microsoft-edge-web-summit-2017/es15">cat-and-mouse game</a>.</p>
<p>But assuming you don’t want to freeze your brain in amber, then yes: you do need to account for new stuff added to the web platform. But this is also true of things like <code>Symbol</code>s, <code>Proxy</code>s, Promises, etc. I just see it as part of the job, and I’m not particularly bothered, since I know that whatever I write will still work in 10 years, thanks to the web’s backwards compatibility guarantees.</p>
<p>Furthermore, I get the impression that a wide swath of the web development community does not care about web components, does not want to support them, and you probably couldn’t convince them to. And that’s okay! The web is a big tent, and you can build entire UIs based on web components, or with a sprinkling of <a href="https://adactio.com/journal/20618">HTML web components</a>, or with none at all. If you want to declare your framework a “no web components” zone, then you can do that and still get plenty of avid fans.</p>
<p>That said, Ryan is right that, by blessing something as “the standard,” it inherently becomes a mental default that needs to be grappled with. Component authors must decide whether <a href="https://dev.to/richharris/why-i-don-t-use-web-components-2cia">their <code>&lt;slot&gt;</code>s should work like native <code>&lt;slot&gt;</code>s</a>. That’s true, but again, you could say this about a lot of new browser APIs. You have to decide whether <code>IntersectionObserver</code> or <code>&lt;img loading="lazy"&gt;</code> is worth it, or whether you’d rather write your own abstraction. That’s fine! At least we have a common point of reference, a shared vocabulary to compare and contrast things.</p>
<p>And just because something is a web standard doesn’t mean you have to use it. For the longest time, <a href="https://www.reddit.com/r/ProgrammerHumor/comments/621qrt/javascript_the_good_parts/">the classic joke</a> about <em>JavaScript: The Good Parts</em> was how small it is compared to <em>JavaScript: The Definitive Guide</em>. The web is littered with deprecated (but still supported) APIs like <code>document.domain</code>, <code>with</code>, and <code>&lt;frame&gt;</code>s. Take it or leave it!</p>
<h2>Conclusion</h2>
<blockquote><p>
  [I]n a sense there are nothing wrong with Web Components as they are only able to be what they are. It’s the promise that they are something that they aren’t which is so dangerous.
</p></blockquote>
<p>Here I totally agree with Ryan. As <a href="https://nolanlawson.com/2023/08/23/use-web-components-for-what-theyre-good-at/">I’ve said before</a>, web components are bad at a lot of things – Server-Side Rendering, accessibility, even interop in some cases. They’re good at plenty of things, but replacing all JavaScript frameworks is not one of them. Maybe we can check back in 10 years, but for now, there are still cases where React, Solid, Svelte, and friends shine and web components flounder.</p>
<p>Ryan is making an eminently reasonable point here, as is the rest of the post, and on its own it’s a good contribution to the discourse. The title is a bit inflammatory, which leads people to wield it as a bludgeon against their perceived enemies on social media (likely without reading the piece), but <a href="https://nolanlawson.com/2022/02/02/five-years-of-quitting-twitter/">this is something I blame on social media</a>, not on Ryan.</p>
<p>Again, I find these debates a bit tiresome. I think the fundamental issue, as <a href="https://nolanlawson.com/2023/12/30/shadow-dom-and-the-problem-of-encapsulation/">I’ve previously said</a>, is that people are talking past each other because they’re building different things with different constraints. It’s as if a salsa dancer criticized ballet for not being enough like salsa. There is more than one way to dance!</p>
<p>From my own personal experience: at Salesforce, we build a client-rendered app, with its own <a href="https://appexchange.salesforce.com/">marketplace of components</a>, with <a href="https://developer.salesforce.com/blogs/2024/01/introducing-component-level-api-versioning-for-lwc">strict backwards-compatibility guarantees</a>, where the intended support is measured in years if not decades. Is this you? If not, then maybe you shouldn’t build your entire UI out of web components, with shadow DOM and the whole kit-n-kaboodle. (Or maybe you should! I can’t say!)</p>
<p>What I find exciting about the web is the sheer number of people doing so many wild and bizarre things with it. It has everything from games to art projects to enterprise SaaS apps, built with WebGL and Wasm and Service Workers and all sorts of zany things. Every new capability added to the web platform isn’t a limitation on your creativity – it’s an opportunity to express your creativity in ways that nobody imagined before.</p>
<p>Web components may not be the future for you – that’s great! I’m excited to see what you build, and I might steal some ideas for my own corner of the web.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a robust frontend using progressive enhancement (213 pts)]]></title>
            <link>https://www.gov.uk/service-manual/technology/using-progressive-enhancement</link>
            <guid>41686715</guid>
            <pubDate>Sun, 29 Sep 2024 11:54:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">https://www.gov.uk/service-manual/technology/using-progressive-enhancement</a>, See on <a href="https://news.ycombinator.com/item?id=41686715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-module="govspeak">
      <p>For users to experience a quality service it must be built in a robust way.</p>

<p>Progressive enhancement is a way of building websites and applications based on the idea that you should make your page work with HTML first.</p>

<p>Only after this can you add anything else like Cascading Style Sheets (CSS) and JavaScript.</p>

<p>All government services must follow progressive enhancement, even if part of the service or a parent service needs JavaScript</p>

<p>Building your service using progressive enhancement will:</p>

<ul>
  <li>
    <p>ensure your service is robust and of a high quality</p>
  </li>
  <li>
    <p>make it more likely your service will work <a href="https://www.gov.uk/service-manual/technology/designing-for-different-browsers-and-devices">regardless of which browser or device is being used</a></p>
  </li>
  <li>
    <p>mean your service’s most basic functionality will work and meet the core needs of the user</p>
  </li>
  <li>
    <p>improve accessibility by encouraging best practices like <a rel="external" href="https://html.com/semantic-markup/">writing semantic markup</a>
help users with device or connectivity limitations to use your service</p>
  </li>
</ul>

<p>If you are using a ‘commercial off the shelf’ (COTS) solution or asking an external supplier to build the service, you should consider including this in your requirements as part of your <a href="https://www.gov.uk/guidance/define-your-purchasing-strategy">purchasing strategy</a>.</p>

<h2 id="start-with-html">Start with HTML</h2>

<p>Government services should be functional using only HTML. This includes services such as:</p>

<ul>
  <li>
    <p>transactional services, for example forms that let the user provide information to government</p>
  </li>
  <li>
    <p><a rel="external" href="https://insidegovuk.blog.gov.uk/2016/10/27/making-it-easier-to-understand-smart-answer-logic/">smart answers</a>, for example the <a href="https://www.gov.uk/register-a-birth">Registering a birth abroad</a> service</p>
  </li>
  <li>
    <p>content-based websites, for example GOV.UK’s <a href="https://www.gov.uk/foreign-travel-advice">foreign travel advice</a> page</p>
  </li>
</ul>

<p>The HTML layer is fault-tolerant by design. The browser ignores markup that it does not understand and continues to parse it as best as it can.</p>

<p>This means that older browsers will be very likely to be able to load the HTML for your service, even if there are bugs in the HTML or you use features that only exist in more modern browsers.</p>



<h2 id="using-css">Using CSS</h2>

<p>You can style your service using CSS to make it look like GOV.UK.</p>

<p>The CSS layer is reasonably fault-tolerant. This means the browser will ignore individual declarations that it does not understand, for example if you use a property that only exists in newer browsers.</p>

<p>Be aware that the browser will ignore the entire ruleset if it encounters a selector that it does not understand.</p>

<p>There are also <a href="#css-fail">other reasons why the CSS may fail to load</a>.</p>

<p>Avoid techniques such as ‘CSS-in-JS’ to ensure that your site still looks correct even if the JavaScript fails to load.</p>

<h2 id="using-javascript">Using JavaScript</h2>

<p>JavaScript can be used to add interactive elements to your service.</p>

<p>The JavaScript layer is not fault-tolerant. If your JavaScript uses a syntax or calls an API that is not supported in the user’s browser, it will error and the rest of the JavaScript will not run.</p>

<p>There are <a href="#css-fail">other reasons why the JavaScript may fail to load or run</a>.</p>

<p>If your service is not designed with this in mind, users may be unable to use it.</p>

<p>You can increase the chances that your JavaScript will work correctly in all browsers by:</p>

<ul>
  <li>
    <p>using <a rel="external" href="https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Cross_browser_testing/Feature_detection">feature detection</a> for browser APIs</p>
  </li>
  <li>
    <p>including <a rel="external" href="https://developer.mozilla.org/en-US/docs/Glossary/Polyfill">polyfills</a> for newer browser features</p>
  </li>
  <li>
    <p>transpiling your JavaScript to a common syntax that your target browsers can understand</p>
  </li>
  <li>
    <p>using automated tests or linters</p>
  </li>
  <li>
    <p>doing regular manual testing, including testing with older or lower-powered devices</p>
  </li>
</ul>

<p>Transpilation and polyfills can significantly increase the size of your JavaScript. You should consider the trade offs involved and revisit these decisions regularly as browser usage changes.</p>

<p>Where possible the JavaScript should enhance HTML and CSS that provides the same core functionality. For example, an autocomplete could enhance a  element, or something similar. This still lets the user do what they need to do, even if the JavaScript fails.</p>

<h3 id="alternatives-to-javascript">Alternatives to JavaScript</h3>

<p>If you believe your service can only be built using JavaScript, you should think about using simpler solutions that are built using HTML and CSS and will meet user needs.</p>

<p>For example, if you want to use use JavaScript to provide interactive graphs, other options are to:</p>

<ul>
  <li>
    <p>display the data in a table</p>
  </li>
  <li>
    <p>allow the data to be exported so that it can analysed in another application</p>
  </li>
  <li>
    <p>pre-render the graphs as images</p>
  </li>
</ul>

<p>If the core functionality of your service cannot be provided without JavaScript, you’ll need to consider how users can access your service through other channels. This might be telephone calls or in-person visits to offices.</p>

<h3 id="using-client-side-javascript-frameworks">Using client-side JavaScript frameworks</h3>

<p>If your service is mostly built using components from the <a rel="external" href="https://design-system.service.gov.uk/">GOV.UK Design System</a> and doesn’t have a complex user interface, you do not need to use a client-side JavaScript framework.</p>

<p>The components in the <a rel="external" href="https://design-system.service.gov.uk/">GOV.UK Design System</a> include <a rel="external" href="https://frontend.design-system.service.gov.uk/import-javascript">how to import JavaScript</a> to your service without the need for a framework.</p>

<p>If you do choose to use client-side <a rel="external" href="https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Client-side_JavaScript_frameworks">JavaScript frameworks</a>, be aware that although they can be helpful when building a service with a complex user interface, they can introduce problems.</p>

<p>Using a client-side JavaScript framework can:</p>

<ul>
  <li>
    <p>increase the overall size of your code base and push processing to the client-side, causing performance issues for users with a slower network connection or lower powered device</p>
  </li>
  <li>
    <p>create a reliance on third-party code that your developers do not have control over, requiring you to make major changes to your service in order to stay up to date with changes in the framework</p>
  </li>
  <li>
    <p>make it difficult to find people with the skills required to maintain the code, if the framework’s loses popularity over time</p>
  </li>
</ul>

<p>If you use a JavaScript framework you should:</p>

<ul>
  <li>
    <p>be able to justify with evidence, how using JavaScript would benefit users</p>
  </li>
  <li>
    <p>be aware of any negative impacts and be able to mitigate them</p>
  </li>
  <li>
    <p>consider whether the benefits of using it outweigh the potential problems</p>
  </li>
  <li>
    <p>only use the framework for parts of the user interface that cannot be built using HTML and CSS alone</p>
  </li>
  <li>
    <p>design each part of the user interface as a separate component</p>
  </li>
</ul>

<p>Having separate components means that if the JavaScript fails to load, it will only be that single component that fails. The rest of the page will load as normal.</p>

<p>If you use JavaScript, it should only be used to enhance the HTML and CSS so users can still use the service if the JavaScript fails.</p>

<h3 id="css-fail">Reasons why CSS or JavaScript may fail to load or run</h3>

<p>CSS and JavaScript can fail to load or run because of, for example:</p>

<ul>
  <li>
    <p>temporary network errors</p>
  </li>
  <li>
    <p>third-party browser extensions like ad blockers</p>
  </li>
  <li>
    <p>third-party supplier downtime, such as when using a content delivery network
DNS lookup failures</p>
  </li>
  <li>
    <p>bugs introduced by browser updates</p>
  </li>
  <li>
    <p>bugs introduced in third party JavaScript intentionally running on the same page
corporate firewalls blocking, removing or changing content (large institutions like banks or government departments may use these)</p>
  </li>
  <li>
    <p>mobile network providers changing content to speed up load times and reduce bandwidth usage</p>
  </li>
  <li>
    <p>personal firewalls or antivirus software changing or blocking content</p>
  </li>
  <li>
    <p>the use of unsecure connections, where internet providers insert their own code into the page that accidentally conflicts with your own</p>
  </li>
</ul>

<p>Some users may deliberately turn off features in their browsers. You should respect their decision and make sure those users can still use your service.</p>

<h2 id="single-page-applications">Single page applications</h2>

<p>Do not build your service as a single-page application (SPA). This is where the loading of pages within your service is handled by JavaScript, rather than the browser.</p>

<p>Single page applications rarely bring benefits and can make the service inaccessible because:</p>

<ul>
  <li>
    <p>users of assistive technology would be unaware of changes in context, for example when moving to a new page</p>
  </li>
  <li>
    <p>it would fail to handle focus when moving between pages</p>
  </li>
  <li>
    <p>the user would be unable to navigate using the back or forward buttons in their browser</p>
  </li>
  <li>
    <p>users would be unable to recover from an error, for example if there is an interruption to their network connection</p>
  </li>
</ul>

<h2 id="testing-your-service">Testing your service</h2>

<p>If any components in your service rely heavily on JavaScript or JavaScript frameworks you will need to make sure they:</p>

<ul>
  <li>
    <p>work on a wide range of browsers and devices</p>
  </li>
  <li>
    <p>work with <a href="https://www.gov.uk/service-manual/technology/testing-with-assistive-technologies">assistive technologies</a></p>
  </li>
  <li>
    <p>are <a href="https://www.gov.uk/service-manual/technology/how-to-test-frontend-performance">tested to ensure good performance</a></p>
  </li>
</ul>





<ul>
  <li>
    <p><a rel="external" href="https://gdstechnology.blog.gov.uk/2016/09/19/why-we-use-progressive-enhancement-to-build-gov-uk/">Why we use progressive enhancement to build GOV.UK</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/technology/designing-for-different-browsers-and-devices">Designing for different devices</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/technology/how-to-test-frontend-performance">How to test for front end performance</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/understanding-wcag">Understanding WCAG 2.2</a></p>
  </li>
</ul>

</div><div data-module="gem-toggle">
        <div>
            
              <dl>
                <dt>Last update:</dt>
                <dd>
                  <time datetime="2024-09-27T10:04:16+01:00">
  27 September 2024
</time>
<p>
  Updated to include the use of JavaScript in progressive enhancement and the potential impact on user experience.
</p>

                </dd>
              </dl>
        </div>
          <p>
            <a href="#full-history" data-controls="full-history" data-toggled-text="- Hide all page updates (3)" data-expanded="false" data-module="ga4-event-tracker" data-ga4-event="{&quot;event_name&quot;:&quot;select_content&quot;,&quot;type&quot;:&quot;content history&quot;,&quot;section&quot;:&quot;Footer&quot;}" data-ga4-expandable="" role="button" aria-controls="full-history" aria-expanded="false">
                + Show all page updates (3)
            </a>
          </p>
          <ol id="full-history" aria-live="polite" role="region">
              <li>
                <time datetime="2019-12-16T12:34:57+00:00">
  16 December 2019
</time>
<p>
  Added browser update bugs to the list of reasons why JavaScript or CSS might fail to load
</p>

              </li>
              <li>
                <time datetime="2019-05-21T14:53:33+01:00">
  21 May 2019
</time>
<p>
  Updated to reflect progressive enhancement's effect on a service's resilience, plus clarified guidance on building more complex services that use JavaScript
</p>

              </li>
              <li>
                <time datetime="2016-05-23T17:53:11+01:00">
  23 May 2016
</time>
<p>
  Guidance first published
</p>

              </li>
          </ol>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floating megabomb heaves to near the English coast (189 pts)]]></title>
            <link>https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/</link>
            <guid>41685917</guid>
            <pubDate>Sun, 29 Sep 2024 08:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/">https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/</a>, See on <a href="https://news.ycombinator.com/item?id=41685917">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>The MV Ruby, a ship carrying a highly explosive Russian cargo, is damaged and looking for a port. Whether or not this is hybrid warfare, the threat is clear. </p><div>
					
<p>The Maltese-registered cargo ship, carrying 20,000 tons of explosive ammonium nitrate, triggered alarm bells in Western capitals when the vessel sustained damage and began to seek permission to unload its lethal cargo.</p>



<p>She is currently seaworthy but <a href="https://www.vesselfinder.com/vessels/details/9626390">unmoving</a> some miles off the coast of Kent, to the east of London, and just outside UK territorial waters.</p>



<p>Spurning the obvious solution of a return to Russia, where she loaded at <a href="https://theloadstar.com/baltic-ports-bar-damaged-ruby-now-in-the-channel-due-to-dangerous-cargo/">Kandalaksha</a> in late August, the damaged vessel embarked on an odyssey of attempted entry to European ports, beginning at the Norwegian anchorage of Tromsø, a naval base that she was <a href="https://www.thebarentsobserver.com/security/trouble-vessel-has-departed-tromso-but-future-uncertain/166105">ordered to leave</a> on September 4. <em>Ruby</em> then sought permission to dock at Klaipėda in Lithuania, a critical NATO reinforcement facility in time of crisis and war.</p>



<p><a href="https://www.lrt.lt/en/news-in-english/19/2358770/ship-with-russian-chemicals-will-not-be-allowed-into-klaipeda-port-pm">Lithuania refused</a> because of the dangerous nature of the cargo. If 20,000 tons of ammonium nitrate were to detonate, it would obliterate the center of any port city — the blast would be equal to <a href="https://x.com/TomSharpe134/status/1839706939292340394">a third</a> of the 1945 Hiroshima bomb. That would be a repeat of the <a href="https://interconnectedrisks.org/disasters/beirut-explosion">devastating explosion</a> of the same substance in Beirut in 2020, although <em>Ruby</em> is carrying seven times more ammonium nitrate.</p>



<p>While Lithuanian authorities announced there was no evidence of malicious intent against the country’s national security, they noted that when dealing with Russia, or other unfriendly international actors, states should always be cautious.</p>



<p>Alongside its war against Ukraine, the Kremlin has long pursued an aggressive hybrid strategy aimed at spreading chaos and destabilization through disinformation, interference in elections, and support for anti-Western political parties. But there has been a substantial uptick in recent months, including serious <a href="https://cepa.org/article/wake-up-nato-its-sabotage/">acts of sabotage</a>.</p>



<p>The shift in its strategy in the Baltic states from “classical” hybrid warfare to more “kinetic” approaches — not just propaganda and cyber-attacks, has now shifted to physical action on the ground.</p>



<p>The physical <a href="https://cepa.org/article/wake-up-nato-its-sabotage/">sabotage</a> includes acts such as a fire at an IKEA storage facility in Lithuania, which helped fuel false narratives about the safety and <a href="https://www.lrytas.lt/english/society/2024/05/20/news/suspicious-fires-in-neighbouring-countries-may-also-affect-lithuania-warn-of-exceptionally-high-risk-in-these-areas-31970773">reliability of foreign investments</a>, while cyber-attacks on power grids, water supply, and communication networks have also been used alongside <a href="https://breakingdefense.com/2024/01/as-baltics-see-spike-in-gps-jamming-nato-must-respond/">GPS jamming</a> to disrupt people’s everyday lives.</p>



<p>The Baltic states are NATO members, meaning an outright military attack would likely trigger collective defense under Article 5; hybrid threats are designed to <a href="https://www.rand.org/content/dam/rand/pubs/research_reports/RR1500/RR1577/RAND_RR1577.pdf">avoid direct confrontation</a> that would result in a military response.</p>



<p>Others have also been targeted. In August, German officials were reportedly <a href="https://www.yahoo.com/news/germany-issues-air-freight-security-124233351.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9kdWNrZHVja2dvLmNvbS8&amp;guce_referrer_sig=AQAAAI7U-SIzAuGpSS3nm-XDz6tBdh_TfpkrwPg0JyMZjxFrhnoE64vawL3OIEZ1IyHJMP5rFU-y7v4_bns8l9geTcSQB5LgDoc3Ssql0HTJbkNFOJIdiLgj2-cMjNgM_BsvTqILfMWdkciF5ttwDBYLbdiD5w_TjKjiqSXAhcw2ReO3">concerned</a> that Russia was responsible for incendiary devices on international air parcels. German trains have also been hit by sabotage attacks.</p>



<p>In this atmosphere of heightened tension, should a ship carrying ammonium nitrate be interpreted as a hybrid threat? Potentially, yes, but it is important to walk between the dual traps of either neglecting emerging problems or labeling all incidents as deliberate.</p>



<div id="" data-block="newsletter">
				<p>
			Get the Latest		</p>
		
				<p>
			Sign up to receive regular emails and stay informed about CEPA's work.		</p>
		
		
				
		
	</div>



<p>Ammonium nitrate is highly explosive, especially when exposed to fire or contamination, so strict safety protocols are followed, including controlled unloading in designated safe zones, continuous monitoring, and emergency response plans. The International Maritime Dangerous Goods (IMDG) Code contains strict guidelines for the substance, and compliance <a href="https://maritimecyprus.com/2024/02/13/maritime-risk-focus-fire-risk-transporting-ammonium-nitrate-on-ships-2/?fbclid=IwZXh0bgNhZW0CMTAAAR0gaAfxgb4cPqACkSeDUrPozngdelgXYMfyAJtpch0AdWnELvTxqak_0Ns_aem_Z3WV9axAHJsY-GEiw6htpg">helps prevent accidents</a> during transport and emergency repairs.</p>



<p>Allowing <em>Ruby</em> to dock in Klaipėda would have created a significant security risk as the cargo would be a direct physical threat to a critical infrastructure hub, making it <a href="https://interconnectedrisks.org/disasters/beirut-explosion?fbclid=IwZXh0bgNhZW0CMTAAAR0Vs01fWN1rgTraRB3k5Mu-LtIi9QLdcdEHcqyVdMokcBGKRM1VrGk909U_aem_0puSxWdOtt-mUJ-SFjezAw">a potential trigger for destabilization</a> if exploited by hostile actors.</p>



<p>Klaipėda is vitally important to Lithuania and NATO in several strategic areas — military logistics, energy security, and regional power stability.</p>



<p>It is a key hub for transporting military equipment and personnel and essential for NATO and the US’s reinforcement capabilities in the Baltic region. This would be particularly crucial in scenarios where <a href="https://www.washingtoninstitute.org/policy-analysis/lebanons-port-risks-need-action-against-substandard-ships?fbclid=IwZXh0bgNhZW0CMTAAAR1NyS4ertPZsq8Sh3acDs3eMzbTlfm3ms8hpFvctRbfgTWeCsa5AVTSuRY_aem_RAnwf4CrCLdHKiaU0kiUxQ">the Suwałki Corridor</a>, the narrow land strip connecting Poland and Lithuania, was under threat as the port would ensure NATO’s operational readiness in the region.</p>



<p>The port also hosts the only large-scale <a href="https://www.kn.lt/en/long-term-operation-of-klaipeda-lng-terminal/4841">LNG terminal</a> in the Baltic states, which enables the import of LNG as an alternative to Russian gas and is a cornerstone of Lithuania’s energy security strategy. A security incident could disrupt supplies for the whole region.</p>



<p>As if that wasn’t enough, Klaipėda plays a significant role in regional power connectivity through <a href="https://www.nsenergybusiness.com/analysis/featurecompletion-of-nordbalt-and-litpol-closes-the-baltic-ring-4847289/">the NordBalt power cable</a>, which links Lithuania with Sweden and is crucial for maintaining the stability of the Baltic power grid.</p>



<p>Given these strategic roles, any threat to Klaipėda, whether from mismanagement of a dangerous cargo or a deliberate act, has far-reaching implications for regional security and energy stability.</p>



<p>The <em>Ruby</em> episode underscores how hybrid threats can potentially evolve to include kinetic elements. The complexity of attribution, combined with Klaipėda’s strategic significance, makes it a potential flashpoint for regional security.</p>



<p>To prevent such situations, robust intelligence-sharing, surveillance and maritime security protocols must be robust. Authorities should also be vigilant about the origins and intentions of vessels requesting access.</p>



<p>Refusing or accepting such ships can have diplomatic repercussions, and denying entry might strain relations with the country of registration or cargo origin, especially if they are allies or significant trade partners. However, allowing such a vessel to dock could expose the host country to security and safety risks.</p>



<p>Effective communication and <a href="https://www.washingtoninstitute.org/policy-analysis/lebanons-port-risks-need-action-against-substandard-ships?fbclid=IwZXh0bgNhZW0CMTAAAR3avSbMFXY1Xk2Ih0c8mlk5PDRpb4zoiZgufrIgjDUnDTLl9Z3nkc5_Twg_aem_CKUZxLnjknsooj-9qgYI6A">adherence to international protocols</a> are essential to navigate these diplomatic challenges, highlighting the need for a balanced approach to security, diplomatic and legal considerations.</p>



<p><em>Eitvydas Bajarūnas is an ambassador in the Ministry of Foreign Affairs of the Republic of Lithuania, and currently a Center for Europe Policy Analysis (CEPA) Visiting Fellow. Assessments and views expressed in the article are those of the author and should not be treated as the official position of the MFA of the Republic of Lithuania.</em></p>



<p><span dir="ltr"><a aria-label="Link Europe’s Edge" title="https://cepa.org/insights-analysis/commentary/europes-edge/" rel="noreferrer noopener" href="https://cepa.org/insights-analysis/commentary/europes-edge/" target="_blank"><i>Europe’s Edge</i></a><i>&nbsp;is CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America. All opinions are those of the author and do not necessarily represent the position or views&nbsp;of the institutions they represent&nbsp;or the Center for European Policy Analysis.</i></span></p>



<div id="" data-block="featured-post">
				<a href="https://cepa.org/event/cepa-forum/cepa-forum-2024/2024-leadership-awards-dinner/" target="">
									<p><img decoding="async" src="https://cepa.org/wp-content/uploads/2023/05/092922-Embassy-of-the-Czech-Republic-053-1400x2100.jpg">
				</p>
							</a>
				
			</div>




<div id="" data-block="newsletter">
				<p>
			Europe's Edge		</p>
		
				<p>
			CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America.		</p>
		
					<p><a href="https://cepa.org/insights-analysis/commentary/europes-edge/" target="">
				Read More			</a>
		
		
	</p></div>

									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feldera Incremental Compute Engine (105 pts)]]></title>
            <link>https://github.com/feldera/feldera</link>
            <guid>41685689</guid>
            <pubDate>Sun, 29 Sep 2024 08:03:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/feldera/feldera">https://github.com/feldera/feldera</a>, See on <a href="https://news.ycombinator.com/item?id=41685689">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">
  <em><b><a href="https://feldera.com/" rel="nofollow">Feldera</a></b></em> is a fast query engine for <b>incremental computation</b>. Feldera has the <a href="#-theory">unique</a> ability to <b>evaluate arbitrary SQL programs incrementally</b>, making it more powerful, expressive and performant than existing alternatives like batch engines, warehouses, stream processors or streaming databases.
</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔥 Incremental Computation Engine</h2><a id="user-content--incremental-computation-engine" aria-label="Permalink: 🔥 Incremental Computation Engine" href="#-incremental-computation-engine"></a></p>
<p dir="auto">Our approach to incremental computation is simple. A Feldera <code>pipeline</code> is a set of SQL tables and views. Views can be
deeply nested.
Users start, stop or pause pipelines to manage and advance a computation.
Pipelines continuously process
<strong>changes</strong>, which are any number of inserts, updates or deletes to a set of tables. When the pipeline receives changes,
Feldera <strong>incrementally</strong> updates all the views by only looking at the changes and it completely avoids recomputing over
older data.
While a pipeline is running, users can inspect the results of the views at any time.</p>
<p dir="auto">Our approach to incremental computation makes Feldera incredibly fast (millions of events per second on a laptop).
It also enables <strong>unified offline and online compute</strong> over both live and historical data. Feldera users have built batch
and real-time
feature engineering pipelines, ETL pipelines, various forms of incremental and periodic analytical jobs over batch data,
and more.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Our defining Features</h2><a id="user-content--our-defining-features" aria-label="Permalink: 🎯 Our defining Features" href="#-our-defining-features"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Full SQL support and more.</strong>  Our engine is the only one in existence that can evaluate full SQL
syntax and semantics completely incrementally. This includes joins and aggregates, group by, correlated subqueries,
window functions, complex data types, time series operators, UDFs, and
recursive queries. Pipelines can process deeply nested hierarchies of views.</p>
</li>
<li>
<p dir="auto"><strong>Fast out-of-the-box performance.</strong>  Feldera users have reported getting complex use cases
implemented in 30 minutes or less, and hitting millions
of events per second in performance on a laptop without any tuning.</p>
</li>
<li>
<p dir="auto"><strong>Datasets larger than RAM.</strong> Feldera is designed to handle datasets
that exceed the available RAM by spilling efficiently to disk, taking advantage of recent advances in NVMe storage.</p>
</li>
<li>
<p dir="auto"><strong>Strong guarantees on consistency and freshness.</strong> Feldera is strongly consistent. It
also <a href="https://www.feldera.com/blog/synchronous-streaming/" rel="nofollow">guarantees</a> that the state of the views always corresponds
to what you'd get if you ran the queries in a batch system for the same input.</p>
</li>
<li>
<p dir="auto"><strong>Connectors for your favorite data sources and destinations.</strong> Feldera connects to myriad batch and streaming data
sources, like Kafka, HTTP, CDC streams, S3, Data Lakes, Warehouses and more.
If you need a connector that we don't yet support, <a href="https://github.com/feldera/feldera/issues">let us know</a>.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">💻 Architecture</h2><a id="user-content--architecture" aria-label="Permalink: 💻 Architecture" href="#-architecture"></a></p>
<p dir="auto">The following diagram shows Feldera's architecture</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/feldera/feldera/blob/main/architecture.svg"><img src="https://github.com/feldera/feldera/raw/main/architecture.svg" alt="Feldera Platform Architecture"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡️ Quick start with Docker</h2><a id="user-content-️-quick-start-with-docker" aria-label="Permalink: ⚡️ Quick start with Docker" href="#️-quick-start-with-docker"></a></p>
<p dir="auto">First, make sure you have <a href="https://docs.docker.com/compose/" rel="nofollow">Docker Compose</a> installed.</p>
<p dir="auto">Next, run the following command to download a Docker Compose file, and use it to bring up
a Feldera Platform deployment suitable for demos, development and testing:</p>
<div data-snippet-clipboard-copy-content="curl -L https://github.com/feldera/feldera/releases/latest/download/docker-compose.yml | \
docker compose -f - --profile demo up"><pre lang="text"><code>curl -L https://github.com/feldera/feldera/releases/latest/download/docker-compose.yml | \
docker compose -f - --profile demo up
</code></pre></div>
<p dir="auto">It can take some time for the container images to be downloaded. About ten seconds after that, the Feldera
web console will become available. Visit <a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a> on your browser
to bring it up. We suggest going through our <a href="https://docs.feldera.com/tutorials/basics/" rel="nofollow">tutorial</a> next.</p>
<p dir="auto">Our <a href="https://docs.feldera.com/get-started" rel="nofollow">Getting Started</a> guide has more detailed instructions on running the
demo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Running Feldera from sources</h2><a id="user-content-️-running-feldera-from-sources" aria-label="Permalink: ⚙️ Running Feldera from sources" href="#️-running-feldera-from-sources"></a></p>
<p dir="auto">To run Feldera from sources, first install all the required
<a href="https://github.com/feldera/feldera/blob/main/CONTRIBUTING.md">dependencies</a>. This includes the Rust toolchain (at least 1.75), Java (at
least JDK 19), Maven and Typescript.</p>
<p dir="auto">After that, the first step is to build the SQL compiler:</p>
<div data-snippet-clipboard-copy-content="cd sql-to-dbsp-compiler
./build.sh"><pre><code>cd sql-to-dbsp-compiler
./build.sh
</code></pre></div>
<p dir="auto">Next, from the repository root, run the pipeline-manager:</p>
<div data-snippet-clipboard-copy-content="cargo run --bin=pipeline-manager --features pg-embed"><pre><code>cargo run --bin=pipeline-manager --features pg-embed
</code></pre></div>
<p dir="auto">As with the Docker instructions above, you can now visit
<a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a> on your browser to see the
Feldera WebConsole.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📖 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📖 Documentation" href="#-documentation"></a></p>
<p dir="auto">To learn more about Feldera Platform, we recommend going through the
<a href="https://docs.feldera.com/" rel="nofollow">documentation</a>.</p>
<ul dir="auto">
<li><a href="https://docs.feldera.com/get-started" rel="nofollow">Getting started</a></li>
<li><a href="https://docs.feldera.com/tour" rel="nofollow">UI tour</a></li>
<li><a href="https://docs.feldera.com/tutorials" rel="nofollow">Tutorials</a></li>
<li><a href="https://docs.feldera.com/demo" rel="nofollow">Demo</a></li>
<li><a href="https://docs.feldera.com/sql/intro" rel="nofollow">SQL reference</a></li>
<li><a href="https://www.feldera.com/api" rel="nofollow">API reference</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤖 Benchmarks</h2><a id="user-content--benchmarks" aria-label="Permalink: 🤖 Benchmarks" href="#-benchmarks"></a></p>
<p dir="auto">Feldera is generally <a href="https://www.feldera.com/blog/nexmark-vs-flink" rel="nofollow">faster and uses less memory</a>
than systems like stream processors. Our Benchmarks are performed by our CI on every commit that goes in
<code>main</code>. If you want to see all the results, please visit <a href="https://benchmarks.feldera.io/" rel="nofollow">benchmarks.feldera.io</a>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f09ff8cba88f053fc8d1435b8035399badc709f0efd77c9ff52738b53cb0d8fb/68747470733a2f2f7777772e66656c646572612e636f6d2f5f6e6578742f696d6167653f75726c3d68747470733a2f2f63646e2e73616e6974792e696f2f696d616765732f6e6c7465383539692f70726f64756374696f6e2f633830613964353932666236663665346366326337613636356164643234646136353939383132332d31373430783439332e706e673f443735266669743d636c6970266175746f3d666f726d617426773d3139323026713d313030"><img src="https://camo.githubusercontent.com/f09ff8cba88f053fc8d1435b8035399badc709f0efd77c9ff52738b53cb0d8fb/68747470733a2f2f7777772e66656c646572612e636f6d2f5f6e6578742f696d6167653f75726c3d68747470733a2f2f63646e2e73616e6974792e696f2f696d616765732f6e6c7465383539692f70726f64756374696f6e2f633830613964353932666236663665346366326337613636356164643234646136353939383132332d31373430783439332e706e673f443735266669743d636c6970266175746f3d666f726d617426773d3139323026713d313030" width="100%" data-canonical-src="https://www.feldera.com/_next/image?url=https://cdn.sanity.io/images/nlte859i/production/c80a9d592fb6f6e4cf2c7a665add24da65998123-1740x493.png?D75&amp;fit=clip&amp;auto=format&amp;w=1920&amp;q=100"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">👍 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 👍 Contributing" href="#-contributing"></a></p>
<p dir="auto">The software in this repository is governed by an open-source license.
We welcome contributions. Here are some <a href="https://github.com/feldera/feldera/blob/main/CONTRIBUTING.md">guidelines</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎓 Theory</h2><a id="user-content--theory" aria-label="Permalink: 🎓 Theory" href="#-theory"></a></p>
<p dir="auto">Feldera Platform achieves its objectives by building on a solid mathematical
foundation. The formal model that underpins our system, called DBSP, is
described in the accompanying paper:</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://docs.feldera.com/vldb23.pdf" rel="nofollow">Budiu, Chajed, McSherry, Ryzhyk, Tannen. DBSP: Automatic
Incremental View Maintenance for Rich Query Languages, Conference on
Very Large Databases, August 2023, Vancouver,
Canada</a></p>
</li>
<li>
<p dir="auto">Here is <a href="https://www.youtube.com/watch?v=iT4k5DCnvPU" rel="nofollow">a presentation about DBSP</a> at the 2023
Apache Calcite Meetup.</p>
</li>
</ul>
<p dir="auto">The model provides two things:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Semantics.</strong> DBSP defines a formal language of streaming operators and
queries built out of these operators, and precisely specifies how these queries
must transform input streams to output streams.</p>
</li>
<li>
<p dir="auto"><strong>Algorithm.</strong> DBSP also gives an algorithm that takes an arbitrary query and
generates an incremental dataflow program that implements this query correctly (in accordance
with its formal semantics) and efficiently. Efficiency here means, in a
nutshell, that the cost of processing a set of input events is proportional to
the size of the input rather than the entire state of the database.</p>
</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Text2CAD Generating Sequential CAD Designs from Text Prompts (104 pts)]]></title>
            <link>https://sadilkhan.github.io/text2cad-project/</link>
            <guid>41685642</guid>
            <pubDate>Sun, 29 Sep 2024 07:52:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sadilkhan.github.io/text2cad-project/">https://sadilkhan.github.io/text2cad-project/</a>, See on <a href="https://news.ycombinator.com/item?id=41685642">Hacker News</a></p>
<div id="readability-page-1" class="page">

    

    

    <header>
                
        
        <img src="https://sadilkhan.github.io/text2cad-project/assets/img/logo_lab_light.png" alt="Results" id="Lab Logo">
        
        <h2><b>Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts </b>
        </h2>
        <h3>
                
                <span>·</span>
                
                <span>·</span>
                
                <br>
                
                <span>·</span>
                
                <span>·</span>
                
        </h3>
        <center> <i>  <sup>*</sup> equal contributions</i>  <span>·</span> <sup>†</sup> <i>corresponding author</i></center>
        <center>
            <sup>1</sup><a href="https://av.dfki.de/" target="_blank"><b> German Research Center for AI (DFKI GmbH)</b></a> <span>·</span>
            <sup>2</sup><a href="https://rptu.de/" target="_blank"><b> RPTU</b></a> <span>·</span>
            <sup>3</sup><a href="https://blog.mindgarage.de/" target="_blank"><b> MindGarage</b></a> <span>·</span>
            <sup>4</sup><a href="https://www.bits-pilani.ac.in/hyderabad/" target="_blank"><b> BITS Pilani, Hyderabad</b></a> 
        </center>
        
        <center>
            <h3>NeurIPS 2024 (Spotlight 🤩) </h3>  
        </center>


        <a href="https://arxiv.org/abs/2409.17106" target="_blank">
            <span>
                <i></i>
            </span>
            <span>Arxiv</span>
        </a>
        <a href="" target="_blank">
            <span>
                <i></i>
            </span>
            <span>Code (Soon)</span>
        </a>
        <a href="" target="_blank">
            <span>
                🤗
            </span>
            <span>Dataset (Soon)</span>
        </a>
        <a href="" target="_blank">
            <span>
                <i></i>
            </span>
            <span>Demo (Soon)</span>
        </a>
        
    </header>
   

    <section id="contribution">
        <p>
            <video controls="" autoplay="" loop="" muted="" id="teaser_video" poster="https://sadilkhan.github.io/text2cad-project/assets/img/teaser_light.jpg">
                <source src="https://sadilkhan.github.io/text2cad-project/assets/animation/teaser_animation.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </p>
        
        
        
            <p> <b>Text2CAD:</b> Designers can efficiently generate parametric CAD models from text
                prompts. The prompts can vary from abstract shape descriptions to detailed parametric instructions.
            </p>

        <div>
            <center>
                <h2>Contribution</h2>
            </center>
            <p>We propose <b>Text2CAD</b> as the first AI framework for generating parametric CAD designs using <b> multi-level textual descriptions </b>. Our main contributions are:
                </p><ol>
                    <li><a href="#annotation"><b>A Novel Data Annotation Pipeline </b></a> that leverages open-source LLMs and VLMs to annotate <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> dataset with text prompts <u>containing varying level of complexities and parametric details.</u> </li>
                    <li><a href="#architecture"><b>Text2CAD Transformer: </b></a>An end-to-end Transformer based autoregressive architecture for generating CAD design history from input text prompts.</li>
                </ol>
            
        </div>
</section>
    
<section id="annotation">
    <center>
        <h2> Data Annotation </h2>
    </center>
    <p>Our data annotation pipeline generates multi-level text prompts describing the construction workflow of a CAD model with varying complexities. We use a two-stage method - 
        </p><ol>
            <li> <b>Stage 1</b>: Shape description generation using VLM (<a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">LlaVA-NeXT</a>). </li>
            <li> <b>Stage 2</b>: Multi-Level textual annotation generation using LLM (<a href="https://mistral.ai/news/mixtral-of-experts/">Mixtral-50B</a>). </li>
        </ol>
        
    <img src="https://sadilkhan.github.io/text2cad-project/assets/img/data_annot_light.png" alt="Architecture" id="data_annot">

    </section>


    <section id="architecture">
        <center>
            <h2> Text2CAD Transformer </h2>
        </center>
        <p>We developed Text2CAD Transformer to transform natural
            language descriptions into 3D CAD models by deducing all its intermediate design steps autoregres-
            sively. Our model takes as input a text prompt \(T\) and a CAD subsequence \(\mathbf{C}_{1:t-1}\) of length \({t-1}\). The text embedding \(T_{adapt}\) is extracted from \(T\) using a pretrained BeRT Encoder followed by a trainable Adaptive layer. The resulting embedding \(T_{adapt}\) and the CAD sequence embedding \(F^0_{t-1}\) is passed through \(\mathbf{L}\) decoder blocks to generate the full CAD sequence in auto-regressive way.
        </p>
        <img src="https://sadilkhan.github.io/text2cad-project/assets/img/arch_light.png" alt="Architecture" id="arch_image">
    </section>

    <section id="results">
        <center>
            <h2>Visual Results</h2>
        </center>
        <div>
            <div>
                <!-- Clone of the last image -->
                <div>
                    <p>
                        Visual examples of 3D CAD model generation using varied prompts. 
                        (<span>1</span>) Three different prompts yielding the same ring-like model, some without explicitly mentioning ’<i>ring</i>’. 
                        (<span>2</span>) Three diverse prompts resulting in same <i>star-shaped model</i>, each emphasizing <i>different star characteristics</i>.
                    </p>
                <p><img src="https://sadilkhan.github.io/text2cad-project/assets/img/qual_3_light.svg" alt="Image 3" id="qual_3_image">
                </p></div>
                <!-- Original images -->
                 <div>
                    <p> Qualitative results of the reconstructed CAD models of <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD
                        on <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> dataset. From top to bottom - <b>Input Texts, Reconstructed CAD models using
                        <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD respectively and GPT-4V Evaluation.</b></p>
                <p><img src="https://sadilkhan.github.io/text2cad-project/assets/img/qual_1_light.png" alt="Image 1" id="qual_1_image">
                     
                     </p></div>
                <div>
                    <p> Qualitative results of the reconstructed CAD models of <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD
                        on <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> dataset. From top to bottom - <b>Input Texts, Reconstructed CAD models using
                        <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD respectively and GPT-4V Evaluation.</b></p>
                <p><img src="https://sadilkhan.github.io/text2cad-project/assets/img/qual_2_light.png" alt="Image 2" id="qual_2_image"> 
                
            </p></div>
                <div>
                    <p>
                        Visual examples of 3D CAD model generation using varied prompts. 
                        (<span>1</span>) Three different prompts yielding the same ring-like model, some without explicitly mentioning ’<i>ring</i>’. 
                        (<span>2</span>) Three diverse prompts resulting in same <i>star-shaped model</i>, each emphasizing <i>different star characteristics</i>.
                    </p>
                <p><img src="https://sadilkhan.github.io/text2cad-project/assets/img/qual_3_light.svg" alt="Image 3" id="qual_3_image"> 
                
                
            </p></div>
                <!-- Clone of the first image -->
                <div>
                    <p> Qualitative results of the reconstructed CAD models of <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD
                        on <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> dataset. From top to bottom - <b>Input Texts, Reconstructed CAD models using
                        <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> and Text2CAD respectively and GPT-4V Evaluation.</b></p>
                <p><img src="https://sadilkhan.github.io/text2cad-project/assets/img/qual_1_light.png" alt="Image 1" id="qual_1_image"> 
                
            </p></div>
            
        </div>
            <p><span id="prev-button">❮</span>
                <span id="next-button">❯</span>
            </p>

            
        </div>
    </section>

    <section id="quantitative-results">
        <!-- <center>
            <h1 class="h1_section">Qualitative Results</h1>
        </center>
        <div id="chart-container">
            <canvas id="comparisonChart"></canvas>
        </div> -->

        <center>
            <h2>Quantitative Results</h2>
        </center>
        <p> We evaluated the performance of Text2CAD using two strategies.
            </p><ol>
                <li> <b>CAD Sequence Evaluation:</b> We assess the parametric correspondence between the generated CAD sequences with the input texts. This is done using the following metrics:
                    <ul>
                        <li> <b>F1 Scores</b> of Line, Arc, Circle and Extrusion using the method proposed in <a href="http://skazizali.com/cadsignet.github.io/"> CAD-SIGNet</a>. </li>
                        <li> <b>Chamfer Distance (CD) </b> measures geometric alignment
                            between the ground truth and reconstructed CAD models of Text2CAD and <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a>. </li>
                           <li> <b>Invality Ratio (IR)</b> Measures the invalidity of the reconstructed CAD models. </li>
    
                    </ul>
                </li><li> <b>Visual Inspection:</b> We compare the performance of Text2CAD and <a href="https://arxiv.org/abs/2105.09492">DeepCAD</a> with GPT-4 and Human evaluation. </li>
            </ol>
            
        
        <center><i>Click on the tab to visualize the bar chart. You can also hover on the bars to see the metrics. </i>
            <br>
        </center>
     
        <!-- Main Tabs -->


<!-- Sequence Evaluation Content -->


<!-- Automatic Evaluation (GPT-4 and User) -->


        
        
    </section>
    
    
    <section id="video">
        <center>
            <h2> Video </h2>
            <!-- <div class="message-container">
                <span>Please click on the play button</span>
                <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/YouTube_icon_%282013-2017%29.png/800px-YouTube_icon_%282013-2017%29.png"
                    alt="Play Button" class="play-button">
                <span>to watch the video.</span>
            </div>

            <div style="width: 100%; min-width: 400px; max-width: 800px;">
                <div style="position: relative; width: 100%; overflow: hidden; padding-top: 56.25%;">
                    <p><iframe
                            style="position: absolute; top: 0; left: 0; right: 0; width: 100%; height: 100%; border: none;"
                            src="https://www.youtube.com/embed/ivg03_ckLIM" width="560" height="315"
                            allowfullscreen="allowfullscreen"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
                    </p>
                </div>
            </div> -->
             Coming Soon
        </center> 
        
    </section>

    <section id="acknowledgement">
        <center>
            <h2> Acknowledgement </h2>
        </center>
        <p>This work was in parts supported by the EU Horizon Europe Framework under grant agreement <code>101135724</code> (LUMINOUS).
        </p>
    </section>

    <section id="citation">
        <center>
            <h2> Citation </h2>
        </center>
        <p>If you like our work, please cite.</p>
        <p><code id="metadata">    
                <span>@misc</span>{<span>khan2024text2cadgeneratingsequentialcad</span>, <br>
                title={Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts}, <br>
                author={Mohammad Sadil Khan and Sankalp Sinha and Talha Uddin Sheikh and Didier Stricker and Sk Aziz Ali and Muhammad Zeshan Afzal}, <br>
                year={2024}, <br>
                eprint={2409.17106}, <br>
                archivePrefix={arXiv}, <br>
                primaryClass={cs.CV}, <br>
                url={https://arxiv.org/abs/2409.17106}, <br>
          }
        </code>
        
            <br>
                
        </p>
    </section>

    

    
    
    
      



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA is selling a brand-new Moon rover: Never used, one previous owner (110 pts)]]></title>
            <link>https://www.economist.com/science-and-technology/2024/09/25/nasa-is-selling-a-brand-new-moon-rover</link>
            <guid>41685326</guid>
            <pubDate>Sun, 29 Sep 2024 06:30:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/science-and-technology/2024/09/25/nasa-is-selling-a-brand-new-moon-rover">https://www.economist.com/science-and-technology/2024/09/25/nasa-is-selling-a-brand-new-moon-rover</a>, See on <a href="https://news.ycombinator.com/item?id=41685326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><h2>Never used, one previous owner</h2></section><section><figure><img alt="VIPER moon rover. " fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240928_STP002.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240928_STP002.jpg"><figcaption><span>Photograph: NASA</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">N</span><small>ASA HAS</small> big plans for the Moon. By the end of the decade, it wants to send humans back to the lunar surface. Before then, though, it intends to send probes to look for ice at its south pole. This ice carries enormous scientific value. It could shed light on how Earth acquired its liquid water; it is also ripe for conversion into rocket propellant.</p></section><p>This article appeared in the Science &amp; technology section of the print edition under the headline “Moon rover for sale”</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240928_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the September 28th 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-09-28" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Too much efficiency makes everything worse (2022) (709 pts)]]></title>
            <link>https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html</link>
            <guid>41684082</guid>
            <pubDate>Sun, 29 Sep 2024 01:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html">https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html</a>, See on <a href="https://news.ycombinator.com/item?id=41684082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <meta charset="utf-8">
<!-- Google tag (gtag.js) -->



<pre>Increased efficiency can sometimes, counterintuitively, lead to worse outcomes. 
This is true almost everywhere.  
We will name this phenomenon the strong version of [Goodhart's law](https://en.wikipedia.org/wiki/Goodhart%27s_law). 
As one example, more efficient centralized tracking of student progress by standardized testing 
seems like such a good idea that well-intentioned laws [mandate it](https://en.wikipedia.org/wiki/No_Child_Left_Behind_Act). 
However, testing also incentivizes schools to focus more on teaching students to test well, and less on teaching broadly useful skills.
As a result, it can cause overall educational outcomes to become worse. Similar examples abound, in politics, economics, health, science, and many other fields.

This same counterintuitive relationship between efficiency and outcome occurs in machine learning, where it is called overfitting.
Overfitting is heavily studied, somewhat theoretically understood, and has well known mitigations.
This connection between the strong version of Goodhart's law in general, and overfitting in machine learning, provides a new 
lens for understanding bad outcomes, and new ideas for fixing them.


Overfitting and Goodhart's law
==========================

In machine learning (ML), **overfitting** is a pervasive phenomenon. We want to train an ML model to achieve some goal. We can't directly fit the model to the goal, so we instead train the model using some proxy which is *similar* to the goal.

![](/assets/cartoon-conversation.png width="300px" border="1")

For instance,
as an occasional computer vision researcher,
my 
goal is sometimes to
prove that my new image classification model works well.
I accomplish this by measuring its accuracy, after asking 
it to label images (is this image a cat or a dog or a frog or a truck or a ...)
from a standardized 
[test dataset of images](https://paperswithcode.com/dataset/cifar-10).
I'm not allowed to train my model on the test dataset though (that would be cheating), 
so I instead train the model on a *proxy* dataset, called the training dataset.
I also can't directly target prediction accuracy during training[^accuracytarget], so I instead target a *proxy* objective which is only related to accuracy.
So rather than training my model on the goal I care about -- classification accuracy on a test dataset -- I instead train it using a *proxy objective* on a *proxy dataset*.

At first everything goes as we hope -- the proxy improves, and since the goal is similar to the proxy, it also improves.

![](/assets/cartoon-early.png width="444px" border="1")

As we continue optimizing the proxy though, we eventually exhaust the useable similarity between proxy and goal. The proxy keeps on getting better, but the goal stops improving. In machine learning we call this overfitting, but it is also an example of Goodhart's law.

![](/assets/cartoon-mid.png width="444px" border="1")

[Goodhart's law](https://en.wikipedia.org/wiki/Goodhart%27s_law) states that, *when a measure becomes a target, it ceases to be a good measure*[^strathern]. 
Goodhart proposed this in the context of monetary policy, but it applies far more broadly. In the context of overfitting in machine learning, it describes how the proxy objective we optimize ceases to be a good measure of the objective we care about.

The strong version of Goodhart's law: as we become too efficient, the thing we care about grows worse
==========================

If we keep on optimizing the proxy objective, even after our goal stops improving, something more worrying happens. The goal often starts getting *worse*, even as our proxy objective continues to improve. Not just a little bit worse either -- often the goal will diverge towards infinity.

This is an [extremely](https://www.cs.princeton.edu/courses/archive/spring16/cos495/slides/ML_basics_lecture6_overfitting.pdf) [general](https://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture02.pdf) [phenomenon](https://scholar.google.com/scholar?hl=en&amp;q=overfitting) in machine learning. It mostly doesn't matter what our goal and proxy are, or what model architecture we use[^overfittinggenerality]. If we are very efficient at optimizing a proxy, then we make the thing it is a proxy for grow worse.

![](/assets/cartoon-late.png width="444px" border="1")

Though this pheonomenon is often discussed, it doesn't seem to be named[^notoverfitting]. Let's call it **the strong version of Goodhart's law**[^strongunintended]. 
We can state it as:
&gt; *When a measure becomes a target,
&gt; if it is effectively optimized,
&gt; then the thing it is designed to measure will grow worse.*

Goodhart's law says that if you optimize a proxy, eventually the goal you care about will stop improving. 
The strong version of Goodhart's law differs 
in that it says that as you over-optimize, the goal you care about won't just stop improving,
but will instead grow much worse than if you had done nothing at all.

Goodhart's law applies well beyond economics, where it was originally proposed. Similarly, the strong version of Goodhart's law applies well beyond machine learning. I believe it can help us understand failures in economies, governments, and social systems.

Increasing efficiency and overfitting are happening everywhere
==========================

Increasing efficiency is permeating almost every aspect of our society. If the thing that is being made more efficient is beneficial, then the increased efficiency makes the world a better place (overall, the world [seems to be becoming a better place](https://ourworldindata.org/a-history-of-global-living-conditions-in-5-charts)). If the thing that is being made more efficient is socially harmful, then the consequences of greater efficiency are scary or depressing (think mass surveillance, or robotic weapons). What about the most common case though -- where the thing we are making more efficient is related, but not identical, to beneficial outcomes? What happens when we get better at something which is merely correlated with outcomes we care about?

In that case, we can overfit, the same as we do in machine learning. The outcomes we care about will improve for a while ... and then they will grow dramatically worse.

Below are a few, possibly facile, examples applying this analogy.

&gt; **Goal:** Educate children well  <br>
&gt; **Proxy:** [Measure student and school performance](https://en.wikipedia.org/wiki/No_Child_Left_Behind_Act) on standardized tests <br>
&gt; **Strong version of Goodhart's law leads to:** Schools narrowly focus on teaching students to answer questions like those on the test, at the expense of the underlying skills the test is intended to measure

&gt; **Goal:** Rapid progress in science  <br>
&gt; **Proxy:** Pay researchers a [cash bonus for every publication](https://www.science.org/content/article/cash-bonuses-peer-reviewed-papers-go-global) <br>
&gt; **Strong version of Goodhart's law leads to:** Publication of incorrect or incremental results, collusion between reviewers and authors, research paper mills

&gt; **Goal:** A well-lived life    <br>
&gt; **Proxy:** Maximize the reward pathway in the brain    <br>
&gt; **Strong version of Goodhart's law leads to:** Substance addiction, gambling addiction, days lost to doomscrolling Twitter

&gt; **Goal:** Healthy population  <br>
&gt; **Proxy:** Access to nutrient-rich food  <br>
&gt; **Strong version of Goodhart's law leads to:** Obesity epidemic

&gt; **Goal:** Leaders that act in the best interests of the population  <br>
&gt; **Proxy:** Leaders that have the most support in the population <br>
&gt; **Strong version of Goodhart's law leads to:** Leaders whose expertise and passions center narrowly around manipulating public opinion at the expense of social outcomes

&gt; **Goal:** An informed, thoughtful, and involved populace  <br>
&gt; **Proxy:** The ease with which people can share and find ideas  <br>
&gt; **Strong version of Goodhart's law leads to:** Filter bubbles, conspiracy theories, parasitic memes, escalated tribalism

&gt; **Goal:** Distribution of labor and resources based upon the needs of society  <br>
&gt; **Proxy:** Capitalism  <br>
&gt; **Strong version of Goodhart's law leads to:** Massive wealth disparities (with incomes ranging from hundreds of dollars per year to hundreds of dollars per second), with [more than a billion](https://hdr.undp.org/en/2020-MPI ) people living in poverty

&gt; **Goal:** The owners of Paperclips Unlimited, LLC, become wealthy  <br>
&gt; **Proxy:** Number of paperclips made by the AI-run manufacturing plant <br>
&gt; **Strong version of Goodhart's law leads to:** The entire solar system, including the company owners, being [converted to paperclips](https://www.lesswrong.com/tag/paperclip-maximizer)

As an exercise for the reader, you can think about how the strong version of Goodhart's law would apply to other efficiencies, like the ones in this list:
~~~ none
telepresence and virtual reality
personalized medicine
gene therapy
tailoring marketing messages to the individual consumers or voters who will find them most actionable
predicting the outcome of elections
writing code
artificial intelligence
reducing slack in supply chains
rapidly disseminating ideas
generating entertainment
identifying new products people will buy
raising livestock
trading securities
extracting fish from the ocean
constructing cars
~~~
[Listing [greater-efficiency]: Some additional diverse things we are getting more efficient at. For most of these, initial improvements were broadly beneficial, but getting too good at them could cause profound negative consequences.]


How do we mitigate the problems caused by overfitting and the strong version of Goodhart's law?
==========================
If overfitting is useful as an analogy, it will be because some of the approaches that improve it in machine learning also transfer to other domains. Below, I review some of the most effective techniques from machine learning, and share some thoughts about how they might transfer.

+ **<span>Mitigation</span>: Better align proxy goals with desired outcomes.** In machine learning this often means carefully collecting training examples which are as similar as possible to the situation at test time. Outside of machine learning, this means changing the proxies we have control over -- e.g. laws, incentives, and social norms -- so that they directly encourage behavior that better aligns with our goals. This is the standard approach used to (try to) engineer social systems.

+ **<span>Mitigation</span>: Add regularization penalties to the system.**  In machine learning, this is often performed by [penalizing the squared magnitude of parameters](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization), so that they stay small. Importantly, regularization doesn't need to directly target undesirable behavior. Almost anything that penalizes deviations of a model from typicality works well. Outside of machine learning, anything that penalizes complexity, or adds friction or extra cost to a system, can be viewed as regularization. Some example ideas:
  + Add a billing mechanism to SMTP, so there's a small cost for every email.
  + Use a progressive tax code, so that unusual success is linked to disproportionately greater cost
  + Charge a court fee proportional to the squared (exponentiated?) number of lawsuits initiated by an organization, so that unusual use of the court system leads to unusual expenses
  + Tax the number of bits of information stored about users

+ **<span>Mitigation</span>: Inject noise into the system.** In machine learning, this involves adding random jitter to the inputs, parameters, and internal state of a model. The unpredictability resulting from this noise makes overfitting far more difficult. Here are some ideas for how to improve outcomes by injecting noise outside of machine learning:
  + Stack rank all the candidates for a highly competitive school or job. Typically, offers would be made to the top-k candidates. Instead, make offers probabilistically, with probability proportional to $\left(\right.$[approx # top tier candidates] $+$ [candidate's stack rank]$\left.\right)^{-1}$. Benefits include: greater diversity of accepted candidates; less ridiculous resources spent by the candidates tuning their application, and by application reviewers reviewing the applications, since small changes in assessed rank only have a small effect on outcome probabilities; occasionally you will draw a longshot candidate that is more likely to fail, but also more likely to succeed in an unconventional and unusually valuable way.
  + Randomly time quizzes and tests in a class, rather than giving them on pre-announced dates, so that students study to understand the material more, and cram (i.e., overfit) for the test less.
  + Require securities exchanges to add random jitter to the times when they process trades, with a standard deviation of about a second. (An efficient market is great. Building a global financial system out of a chaotic nonstationary dynamical system with a characteristic timescale more than six orders of magnitude faster than human reaction time is just asking for trouble.)
  + Randomize details of the electoral system on voting day, in order to prevent candidates from overfitting to incidental details of the current electoral system (e.g. by taking unreasonable positions that appeal to a pivotal minority). For instance randomly select between ranked choice or first past the post ballots, or randomly rescale the importance of votes from different districts. (I'm not saying all of these are *good* ideas. Just ... ideas.)

+ **<span>Mitigation</span>: Early stopping.** In machine learning, it's common to monitor a third metric, besides training loss and test performance, which we call validation loss. When the validation loss starts to get worse, we stop training, even if the training loss is still improving. This is the single most effective tool we have to prevent catastrophic overfitting. Here are some ways early stopping could be applied outside of machine learning:
  + Sharply limit the time between a call for proposals and submission date, so that proposals better reflect pre-existing readiness, and to avoid an effect where increasing resources are poured into proposal generation, rather than being used to create something useful
  + Whenever stock volatility rises above a threshold, suspend all market activity
  + The use of antitrust law to split companies that are preventing competition in a market
  + Estimate the importance of a decision in $$. When the value of the time you have already spent analyzing the decision approaches that value, make a snap decision.
  + Freeze the information that agents are allowed to use to achieve their goals. Press blackouts in the 48 hours before an election might fall under this category.

One of the best understood *causes* of extreme overfitting is that the expressivity of the model being trained *too closely matches* the complexity of the proxy task. 
When the model is very weak, it can only make a little bit of progress on the task, and it doesn’t exhaust the similarity between the goal and the proxy. 
When the model is extremely strong and expressive, it can optimize the proxy objective in isolation, without inducing extreme behavior on other objectives. 
When the model's expressivity roughly matches the task complexity (e.g., the number of parameters is no more than a few orders of magnitude higher or lower than the number of training examples), then it can only do well on the proxy task by doing *extreme things everywhere else*. See Figure [capacity] for a demonstration of this idea on a simple task. 
This cause of overfitting motivates two final, diametrically opposed, methods for mitigating the strong version of Goodhart’s law.

+ **<span>Mitigation</span>: Restrict capabilities / capacity.** In machine learning, this is often achieved by making the model so small that it's incapable of overfitting. In the broader world, we could similarly limit the capacity of organizations or agents. Examples include:
  + Campaign finance limits
  + Set a maximum number of people that can work in companies of a given type. e.g. allow only 10 people to work in any lobbying group
  + Set the maximum number of parameters, or training compute, that any AI system can use.
 
+ **<span>Mitigation</span>: Increase capabilities / capacity.** In machine learning, if a model is made very big, it often has enough capacity to overfit to the training data without making performance on the test data worse. In the broader world, this would correspond to developing capabilities that are so great that there is no longer any tradeoff required between performance on the goal and the proxy. Examples include:
  + Obliterate all privacy, and make all the information about all people, governments, and other organizations available to everyone all the time, so that everyone can have perfect trust of everyone else. This could be achieved by legislating that every database be publicly accessible, and by putting cameras in every building. (to be clear -- from my value system, this would be a dystopian scenario)
  + Invest in basic research in clean energy
  + Develop as many complex, inscrutable, and diverse market trading instruments as possible, vesting on as many timescales as possible. (In nature, more complex ecosystems are more stable. Maybe there is a parallel for markets?)
  + Use the largest, most compute and data intensive, AI model possible in every scenario 😮[^gobig]

This last mitigation of just continuing to increase capabilities works surprisingly well in machine learning.
It is also a path of least resistance. 
Trying to fix our institutions by blindly making them better at pursuing misaligned goals is a terrible idea though.

Parting thoughts
==========================

The strong version of Goodhart's law underlies most of my personal fears around AI (expect a future blog post about my AI fears!). 
If there is one thing AI will enable, it is greater efficiency, on almost all tasks, over a very short time period. 
We are going to need to simultaneously deal with massive numbers of diverse unwanted side effects, 
just as our ability to collaborate on solutions is also disrupted.

There's a lot of opportunity to *research* solutions to this problem. 
If you are a scientist looking for research ideas which are pro-social, 
and have the potential to create a whole new field, you should consider
building formal (mathematical) bridges between results on overfitting
in machine learning, and problems in economics, political science, management science, operations research, and elsewhere[^researchideas].
This is a goldmine waiting to be tapped. (I might actually be suggesting here that we should invent the field of [psychohistory](https://en.wikipedia.org/wiki/Psychohistory), and that overfitting phenomena will have a big role in that field.)

The more our social systems break due to the strong version of Goodhart's law, 
the less we will be able to take the concerted rational action required to fix them.
Hopefully naming, and better understanding, the phenomenon will help push in the opposite direction. 

<br>

![Figure [capacity]: **Models often suffer from the strong version of Goodhart's law, and overfit catastrophically, when their complexity is well matched to the complexity of the proxy task.** If a model is instead much more or much less capable than required, it will overfit less. Here, models are trained to map from a one-dimensional input $x$ to a one-dimensional output $y$. All models are trained on the same 10 datapoints, in red. The model with 4 parameters is too weak to exactly fit the datapoints, but it smoothly approximates them. The model with 10,000 parameters is strong enough to easily fit all the datapoints, and also smoothly interpolate between them. The model with 10 parameters is exactly strong enough to fit the datapoints, but it can only contort itself to do so by behaving in extreme ways away from the training data. If asked to predict $y$ for a new value of $x$, the 10 parameter model would perform extremely poorly. For details of this toy experiment, which uses linear random feature models, see this [colab notebook](https://colab.research.google.com/drive/1mAqCsCE-6biiFxQu8swlc5MygmI9lMJA?usp=sharing).](/assets/size-mitigation.png width="290px" border="1")

<br>

[^accuracytarget]: Accuracy is not differentiable, which makes it impossible to target by naive gradient descent training. It is usually replaced during training by a proxy of softmax-cross-entropy loss, which is differentiable. There are blackbox training methods which can directly target accuracy, but they are inefficient and rarely used.

[^strathern]: This modern phrasing is due to Marilyn Strathern. 
Goodhart originally phrased the observation as the more clunky 
*any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes*. 

[^overfittinggenerality]: This glosses over a lot of variation. For instance, there is an entire subfield which studies the qualitative differences in overfitting in underparameterized, critically parameterized, and overparameterized models. Despite this variation, the core observation --  that when we train on a proxy our target gets better for a while, but then grows worse -- holds broadly. 

[^notoverfitting]: It's not simply overfitting. Overfitting refers to the proxy becoming better than the goal, not to the goal growing worse in an absolute sense. There are other related, but not identical, concepts -- for instance [perverse incentives](https://en.wikipedia.org/wiki/Perverse_incentive), [Campbell's law](https://en.wikipedia.org/wiki/Campbell%27s_law), the [Streisand effect](https://en.wikipedia.org/wiki/Streisand_effect), the [law of unintended consequences](https://en.wikipedia.org/wiki/Unintended_consequences), [Jevons paradox](https://en.m.wikipedia.org/wiki/Jevons_paradox), and the concept of [negative externalities](https://en.m.wikipedia.org/wiki/Externality#Negative). [Goodhart's curse](https://arbital.com/p/goodharts_curse/) is perhaps the closest. However, the definition of Goodhart's curse incorporates not only the phenomenon, but also a specific mechanism, and the mechanism is incorrect[^Goodhartcurse]. *Edit 2022/11/9: Andrew Hundt [suggests](https://twitter.com/athundt/status/1589591738792177664) that similar observations that optimization isn't always desirable have been made in the social sciences, and gives specific examples of "The New Jim Code" and "[Weapons of Math Destruction](https://en.m.wikipedia.org/wiki/Weapons_of_Math_Destruction)". Kiran Vodrahalli [points out](https://mathstodon.xyz/@kiranvodrahalli/109300676096306738) connections to robust optimization and the "[price of robustness](https://www.robustopt.com/references/Price%20of%20Robustness.pdf)." [Leo Gao](https://bmk.sh/) points me at a [recent paper](https://arxiv.org/abs/2210.10760) which uses the descriptive term "overoptimization" for this phenomenon, which I think is good.*

[^strongunintended]: I also considered calling it the strong law of unintended consequences -- it's not just that there are unexpected side effects, but that that the more effectively you accomplish your task, the more those side effects will act against your original goal.

[^gobig]: Note that for suficiently strong AI, limitations on its capabilities might be determined by the laws of physics, rather than by its compute scale or training dataset size. So if you're worried about misaligned AGI, this mitigation may offer no comfort.

[^researchideas]: For instance, take PAC Bayes bounds from statistical learning theory, and use them to predict the optimal amount of power unions should have, in order to maximize the wealth of workers in an industry. Or, estimate the spectrum of candidate-controllable and uncontrollable variables in political contests, to predict points of political breakdown. (I'm blithely suggesting these examples as if they would be easy, and are well formed in their description. Of course, neither is true -- actually doing this would require hard work and brilliance in some ratio.)

[^Goodhartcurse]: The [definition of Goodhart's curse](https://arbital.com/p/goodharts_curse/) includes [the optimizer's curse](https://www.semanticscholar.org/paper/The-Optimizer's-Curse%3A-Skepticism-and-Postdecision-Smith-Winkler/28cfed594544215673db802dce79b8c12d3ab5ab) as its causal mechanism. This is where the word 'curse' comes from in its name. 
If an objective $u$ is an imperfect proxy for a goal objective $v$, the optimizer's curse explains why optimizing $u$ finds an anomalously good $u$, and makes the *gap* between $u$ and $v$ grow large. It doesn't explain why optimizing $u$ makes $v$ grow worse in an absolute sense. That is, the optimizer's curse provides motivation for why Goodhart's law occurs. It does not provide motivation for why the strong version of Goodhart's law occurs. (As I briefly discuss elsewhere in the post, one common causal mechanism for $v$ growing worse is that it's expressivity is too closely matched to the complexity of the task it is performing. This is a very active research area though, and our understanding is both incomplete and actively changing.)
<p>

-----
<br>

Thank you to Asako Miyakawa and Katherine Lee for providing feedback on earlier drafts of this post.

</p></pre>

<!-- Markdeep: -->





  </div><p><small>
BibTeX entry for post:<br>
<tt>

@misc{sohldickstein20221106,<br>
   author = {Sohl-Dickstein, Jascha},<br>
   title = {{ Too much efficiency makes everything worse: overfitting and the strong version of Goodhart's law }},<br>
   howpublished = "\url{https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html}",<br>
   date    = {2022-11-06}<br>
}
</tt>
</small>

  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on the Crystal Language (150 pts)]]></title>
            <link>https://wiki.alopex.li/CrystalNotes</link>
            <guid>41683815</guid>
            <pubDate>Sun, 29 Sep 2024 00:16:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.alopex.li/CrystalNotes">https://wiki.alopex.li/CrystalNotes</a>, See on <a href="https://news.ycombinator.com/item?id=41683815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><div id="TOC">
<ul>
<li><a href="#first-impressions">First impressions</a></li>
<li><a href="#object-stuff">Object stuff</a></li>
<li><a href="#type-system-stuff">Type system stuff</a></li>
<li><a href="#stdlib-stuff">Stdlib stuff</a></li>
<li><a href="#other-random-bits">Other random bits</a></li>
<li><a href="#things-to-look-at-later">Things to look at later</a></li>
<li><a href="#conclusions">Conclusions</a></li>
</ul>
</div>

<p>A friend talked me into trying out the <a href="https://crystal-lang.org/">Crystal programming language</a>, and
then another friend talked me into starting a <a href="https://hg.sr.ht/~icefox/casual-benchmarks">little project</a>
that Crystal would be good for, so here’s the traditional rambling
thoughts on it. Written in September 2024, using Crystal 1.13. Also note
that I’ve used almost no statically-typed language besides Rust for like
8 years, so I am <em>very</em> Rust-brained these days.</p>
<h2 id="first-impressions">First impressions</h2>
<ul>
<li>Language started in 2014</li>
<li>Overarching idea: Strongly-typed Ruby (with lots of type
inference)</li>
<li>This means Everything Is An Object, which always feels wrong to me
these days, but like Ruby it’s a fairly good implementation of the idea.
You can have standalone functions and whatever and it works fine.</li>
<li>Programs are just compiled to native executables through LLVM.
Compilation isn’t instant, but it’s Fast Enough for me so far.</li>
<li>No repl that I’ve found, but also no <code>main()</code> function,
writing bare statements in a toplevel file executes them from start to
end. Sounds like a potential liability to me, with order of file imports
changing side effects, but it sure is convenient to learn with.</li>
<li>The tutorial also has editable and executable online code blocks,
which is an excellent way to play around</li>
<li>Has a good range of useful-but-less-common built-in types like sets,
symbols/atoms, tuples and closures, so the creator is no fool</li>
<li>Reasonably modern package/build manager: <code>shards</code>. Uses
yaml for the file format unfortunately, but oh well.</li>
<li>Decent project-blessed Debian packages and the usual (bad)
<code>curl ... | sudo sh</code> style install script, which I eyeballed
and is not at this time a rootkit. Its .deb is hosted on opensuse.org,
which feels weird; someday I should actually learn anything about SuSE
besides “RPM based, I tried it in 2005 and it didn’t work well on my PC
at the time”</li>
<li>Tutorial is really minimal, be prepared to just read through the
reference once you get through the bare essentials</li>
<li>The reference is pretty good though</li>
<li>Where the hell are for loops??? Oh they don’t exist, you use
<code>10.each do |x| ... end</code> like Ruby. Sure, why not.</li>
<li>Reasonable ecosystem of libs, seemingly mostly decentralized like Go
but <code>shards</code> has at least the framework for different package
sources, so if someone makes a centralized Crystal package lib and it
gets popular it can just be added as another option. Standard lib is
more of the maximalist style, has a bunch of handy script-y things in
it.</li>
<li>Compiles to static-ish binaries with LLVM. So it’s not a scripting
language per se, but… scripting-language-coded, I suppose.</li>
<li>Was sold to me as having very good FFI and macro metaprogramming,
which sounds useful.</li>
</ul>
<h2 id="object-stuff">Object stuff</h2>
<ul>
<li>It splits apart <code>new</code> to allocate memory and
<code>initialize</code> to initialize it like Objective C does, which is
always nice to see. Usually unnecessary, but nice to see.</li>
<li>Class variables are all private, everything is done through
accessors. There’s freely-available overloads for operators like
<code>=[]</code> for <code>x[y] = z</code>, and more shortcuts (which
turn out to be <a href="https://crystal-lang.org/api/1.13.2/Object.html#property%28%2Anames%2C%26block%29-macro">macros</a>)
for defining accessors.</li>
<li>Does the Ruby annotation thing where <code>foo</code> is local var,
<code>@foo</code> is instance var, <code>@@foo</code> is class var,
which feels weird but after using it for a while I actually kinda like
it.</li>
<li>Oooooh all constants start with capital letters… and all
types/classes start with capital letters… so all types are constants at
runtime. Classy. …No, not that kind of <code>class</code>-y. Dammit that
wasn’t supposed to be a pun! Go away!</li>
<li>Structs are value-typed classes, like in C#. IMO this is a worse
design than just having explicit references, but fine for 2014 when the
language was created.</li>
<li>There’s a feature called “splat assignment” which just seems like
weaksauce pattern matching. Looks useful, but why not just have pattern
matching? Splat assignment probably evolved out of Python’s
<code>*</code> function argument swizzling operators.</li>
<li>Has some nice shortcut syntax for designing your own collections
types, so <code>{1 =&gt; :foo, 2 =&gt; :bar}</code> makes the builtin
<code>Hash</code> type, but you can write
<code>MyType{1 =&gt; :foo, 2 =&gt; :bar}</code> and it will desugar to
<code>MyType.new(); MyType[1] = :foo; MyType[2] = :bar;</code> Feels a
bit like C# there, nice option to have.</li>
</ul>
<h2 id="type-system-stuff">Type system stuff</h2>
<ul>
<li>You (almost) never need to add type annotations to vars and function
args/returns to make the program typecheck, but you always have the
option to add them so it typechecks the way you want,, which is
good</li>
<li>It looks like it does some form of global type inference, which
sounds somewhat ad-hoc compared to OCaml-y HM but seems to work fine in
practice (so far).</li>
<li>The type inference allows unions of types like Typescript does, such
as <code>Int | String</code>.</li>
<li>Variables are declared by being assigned to, which to me feels a
little unnecessarily sloppy but usually works okay in practice. The
<code>@</code> sigils help a bit.</li>
<li>Variables can be reassigned with a value of a different type, which
is a little bold. So you can do <code>a = 3; a = "hi"</code> and it
works. Not sure yet how hazardous this is in practice. I assume it types
<code>a</code> as <code>Int32 | String</code> in that case? Yep; if you
declare the type of a variable <code>a : Int32 = 3; a = "hi"</code> then
it complains that the type of <code>a</code> is <code>Int32</code> but
you’re trying to use it as if it were <code>Int32 | String</code>.
Writing <code>a : Int32 | String = 3; a = "hi"</code> works just
fine.</li>
<li>This is also how uninitialized variables work. Uninitialized vars
have type <code>Nil</code>, which has only one value <code>nil</code>,
which then interacts with other types like normal. So an uninitialized
variable that is later set to a <code>String</code> has type
<code>Nil | String</code>.</li>
<li>So if you don’t want this to happen, you can always just give a
variable a type. And if you don’t do that, but screw something up, it
will get caught next time that variable is used with a function that has
typed args.</li>
<li>That feels <em>very</em> much like Typescript’s type system. Now, TS
is a little infamously unsound, which means you can write contradictions
in it; invalid programs can typecheck successfully. In practice this is
<em>seldom</em> too much of a problem in TS, afaik, but definitely can
fuck you up sometimes. I have no idea whether Crystal is unsound or not,
since its logic around types and objects and stuff seems different from
TS’s approach, which is shaped by needing to interoperate with the
abject sadness that is JS. Would be interesting to learn more about
it!</li>
<li>In general subtyping (such as OO inheritance) and union types (like
<code>Int | String</code>) are places where type systems get Hard, and
are areas of active research. So having Crystal wandering around this
design space is pretty neat from a language creator’s point of
view.</li>
<li>There are also real generics, haven’t touched them much yet but they
seem to do the job?</li>
<li>There’s the usual zoo of OO features like private/protected methods,
covariance and contravariance, virtual and abstract types, etc. I’m
happy to ignore them when possible.</li>
</ul>
<h2 id="stdlib-stuff">Stdlib stuff</h2>
<ul>
<li>Woohoo, batteries! Fun change from Rust. There’s hash functions in
there! JSON parser/writer! A smol HTTP server! Bignums! Tempfiles!</li>
<li>Oops, looks like its tempfile lib is written in library code in the
style of <code>mktemp(3)</code>, instead of calling the OS’s
<code>mkstemp(3)</code> or equivalent. So it just finds a filename that
doesn’t exist and then opens it separately, letting an attacker create a
new file which they can read at that location between those two steps.
Uh, have fun with your temporary files leading to exploitable race
conditions guys.</li>
<li>Digging through the Crystal issue tracker for this problem shows
multiple attempts to try to make this better done at different times by
different people, none of which seem to have been Good Enough. It’s a
pretty good example of the downsides of a batteries-included library,
tbh. Trying not to break shit is hard work.</li>
<li>The stdlib’s <code>OptionParser</code> is hella better than a C/bash
<code>argparse</code>-like API but it could be better still. I wish it
were more declarative and a little more opinionated, like Rust’s
<code>clap</code> or <code>argh</code>.</li>
<li>Oh I take it back, there’s no way I can find to just tell
<code>OptionParser</code> “this command line flag is necessary”. WTF?
It’s basically “wire your own state machine” like Python’s lame-ass
<code>argparse</code>. Maybe I should write a new command line parser
lib.</li>
<li>Oh, there’s already a bunch already written. A disadvantage of
Crystal’s Go-style package management where everything is in its own
repo, vs.&nbsp;Rust-style where there’s a blessed <code>crates.io</code> or
equivalent: it’s hard to know where to go to find packages. There
appears to be a decent (if commercial) curated list at <a href="https://crystal.libhunt.com/">https://crystal.libhunt.com/</a>. <a href="https://github.com/mrrooijen/commander">commander</a> and <a href="https://github.com/jwaldrip/admiral.cr">admiral</a> seem close to
what I want, though there’s plenty of others.</li>
<li>Annoying as this is, I <em>love</em> that there’s a good language
out there that makes decisions <em>different</em> from my habitual
Rust/Python/Elixir ecosystem. Tradeoffs are worth exploring.</li>
</ul>
<p>Okay I hate writing this ’cause I’ve been having fun up until now,
but the stdlib honestly needs some help. I had this code:</p>
<pre><code>testdir = Dir.new(testdir_path)
LANGUAGES.each do |name, lang|
  Dir.cd(testdir_path)
  # Iterate through subdirs
  testdir.each_child do |subdir|
    puts "Processing stuff in #{subdir}"
    do_stuff(testdir_path / subdir)
  end
end</code></pre>
<p>First off, <code>Dir#each_child()</code> returns a
<code>String</code>, not a <code>Path</code> or a <code>Dir</code> or
<code>File</code> object. Okay fine, paths are fucking cursed no matter
what. But it turns out that the <code>Dir</code> object <em>is</em> an
iterator, instead of what I expected, which was
<code>Dir#each_child</code> <em>creating</em> an iterator. So for the
first run of the outer loop it would iterate through the subdirectories
of <code>testdir_path</code>, and <code>do_stuff()</code> in each one.
Then for the <em>next</em> run of the outer loop it calls
<code>testdir.each_child()</code> again… which is already at the end of
the iterator, so it just bloody runs zero times. Want to iterate through
the directory again? Gotta call <code>testdir.rewind()</code> first. Is
this in the docs? Only if you look at the <code>rewind()</code> method
and understand that this is a possibility; otherwise you just gotta
figure it out the hard way like I did. Apparently this (like a lot of
the rest of the Crystal stdlib) is inherited from Ruby, but that doesn’t
mean it’s a good idea.</p>
<p>THIS is why you need an immutable-first language with move semantics
and borrowing, dammit! People ask me what Rust is good for if you are
happy to have a GC? Shit like this, that’s what.</p>
<p>Fine, Crystal isn’t that language, but still. But for as good as
Crystal itself is, it deserves to have the stdlib that doesn’t result in
me tripping across three separate footguns while writing what is, in the
end, a 300-line “I didn’t want to write a shell script” program. That’s
not great. Asking a good lang designer to also be a good stdlib designer
is a pretty tall order, but fortunately lib improvements are the sort of
work that can be done by a community more easily than core lang design.
Someone with intimate knowledge of the Rust stdlib and all the horrible
footguns its incredibly labyrinthine design tries to avoid, and the
intestinal fortitude to rewrite major parts of a stdlib, please help
Crystal out.</p>
<h2 id="other-random-bits">Other random bits</h2>
<ul>
<li>You can make functions with named args and call them like
<code>some_method 10, w: 1, y: 2, z: 3</code>. Heh, more Objective C
lineage – I don’t <em>think</em> Ruby does that? Oops it does; I think I
last touched Ruby in like 2012. Either way, classy. Feels like how
Elixir writes DSL’s out of functions, but in a good way. Probably not a
coincidence, since they’re both Ruby-ish syntax.</li>
<li>Yep, you can use the “splat operator” in function args and it’s
exactly like Python’s arg swizzle operators. Always a nice feature for a
dynamic-ish language, and one of the fun things that is just really
fucking annoying to do sensibly in a For Realsies Static language like
Rust. Even when it’s statically typed and compiled to native code, being
able to have the language say “yeah we just use lots of dynamic dispatch
and/or reflection here, it’s fine” is pretty convenient at times.</li>
<li>Oh shit, there’s no sum types! Heck, no <em>wonder</em> this feels
weird to write in. There’s enums, which is nice, but they are very
explicitly limited to integers and intended for flags and stuff. If you
really wanted Rust-style sum types you could fake them easily enough,
but that always Feels Bad. No real pattern matching either, so you it’s
more annoying to use the “tuple of symbol + value” style of sum types
that’s ubiquitous in Elixir or Erlang.</li>
<li>Modules are first-class values, huh. And have some relation to
classes. Again I am reminded of one of my more mind-bending moments
while learning Ruby, which was reading something along the lines of “the
<code>Module</code> class of <code>Module</code> is a subclass of the
<code>Class</code> class of <code>Class</code>.” Good times.</li>
<li>The <code>crystal</code> binary comes with some handy tools built
in, with the command <code>crystal tool</code>. There’s fairly mundane
things like a formatter and a macro-expander, and also slightly more
uncommon but interesting bits like something that prints out the full
class tree for a program, or shows the implementations possible for an
overloaded method call.</li>
<li>The <code>require</code> file import statement is mostly file-based,
vs Rust or Elixir’s more abstract module tree knowing where it
<em>expects</em> to find files. There’s still some default search paths
that result in a particular file layout in a multi-file project, but it
seems to be more of a suggestion than a rule. Files also all share the
same namespace by default, if you want nested namespaces you just make
the file <code>foo/bar.cr</code> contain your code inside
<code>module Foo::Bar ... end</code> . Feels a little oldschool compared
to more abstract systems, like the concept is “C includes done
properly”, but it seems to work fine. Meshes decently with the
scripting-language vibe, you can just kinda throw files together if you
want to.</li>
<li>There’s some auto-casting of numerical types, but it’s very
conservative compared to say C or Python 2. It only can occur in
function args or class initialization as well, which is an interesting
choice.</li>
<li>Error handling is fairly mundane exceptions, so far.</li>
<li>Crystal’s tools for dealing with <code>Nil</code> are kinda
interesting. The type <code>String?</code> is a shortcut for
<code>String | Nil</code>. <code>Nil</code> is falsey, but has a little
syntactic sugar to it: if you have a value <code>x</code> of type
<code>String?</code> you can write
<code>if x do_stuff_with(x) end</code> and the <code>x</code> inside the
if block is of type <code>String</code>. It’s smart enough to do the
opposite too; if you write
<code>if !x do_stuff(x) else do_other_stuff(x) end</code> then inside
the “if” part <code>x</code> is type <code>Nil</code>, and inside the
“else” part <code>x</code> is type <code>String</code>. So I guess it’s
a case/pattern match on the type, really, but a very handy one. Very
alien to my brain used to Rust’s <code>Option</code>’s; Crystal once
again does something that <em>feels</em> like how you’d write stuff in a
dynamic language, but makes it type safe.</li>
<li>The shortcuts for properties in class constructors are very
convenient. Rust could learn some things there, tbh.</li>
</ul>
<h2 id="things-to-look-at-later">Things to look at later</h2>
<ul>
<li>Reflection</li>
<li>FFI</li>
<li>Error handling</li>
<li>Macros</li>
<li>Generics (in more depth)</li>
<li>Can you magically return/break out of iterator functions like you
can in Ruby?</li>
<li>Threads/fibers?</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>I still think the world really needs a solid, immutable-first and
functional-first scripting/glue language, and Crystal isn’t that. But it
<em>is</em> a solid, well-considered OO language with a static type
system that feels as low-friction as a dynamic one. So give Crystal a go
next time you’re sick of writing your bajillion’th Python/Ruby/JS
script. It steals lots of stuff from Ruby, but the stuff it adds is very
solid so far.</p><div id="categoryList"><ul><li><a href="https://wiki.alopex.li/_category/writing">writing</a></li><li><a href="https://wiki.alopex.li/_category/programming">programming</a></li><li><a href="https://wiki.alopex.li/_category/languages">languages</a></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notion's mid-life crisis (202 pts)]]></title>
            <link>https://www.jjinux.com/2024/09/notions-mid-life-crisis.html</link>
            <guid>41683577</guid>
            <pubDate>Sat, 28 Sep 2024 23:14:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jjinux.com/2024/09/notions-mid-life-crisis.html">https://www.jjinux.com/2024/09/notions-mid-life-crisis.html</a>, See on <a href="https://news.ycombinator.com/item?id=41683577">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX launches mission for 2 NASA astronauts who are stuck on the ISS (340 pts)]]></title>
            <link>https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b</link>
            <guid>41683306</guid>
            <pubDate>Sat, 28 Sep 2024 22:11:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b">https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b</a>, See on <a href="https://news.ycombinator.com/item?id=41683306">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>CAPE CANAVERAL, Fla. (AP) — SpaceX <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/boeing-spacex-nasa-astronauts-starliner-e4e81e5a6c23dee2f8f72260ddea011c">launched a rescue mission</a></span> for the two stuck astronauts at the International Space Station on Saturday, sending up a downsized crew to bring them home but not until next year.</p><p>The capsule rocketed into orbit to fetch the test pilots whose <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/nasa-stuck-astronauts-boeing-starliner-92dca67a1fbecf05f5f0e6e2e79afc3b">Boeing spacecraft returned to Earth empty</a></span> earlier this month because of safety concerns. The switch in rides left it to NASA’s Nick Hague and Russia’s Alexander Gorbunov to retrieve <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/stuck-astronauts-boeing-starliner-nasa-1933b64f91ba06713e57446e2dbee1c4">Butch Wilmore and Suni Williams</a></span>. </p><p>Because NASA rotates space station crews approximately every six months, this newly launched flight with two empty seats reserved for Wilmore and Williams won’t return until late February. Officials said there wasn’t a way to bring them back earlier on SpaceX without interrupting other scheduled missions.</p><p>By the time they return, the pair will have logged more than eight months in space. They expected to be gone just a week when they signed up for Boeing’s first astronaut flight that launched in June.</p>
    

<p>NASA ultimately decided that Boeing’s Starliner was too risky after a cascade of thruster troubles and helium leaks marred its trip to the orbiting complex. The space agency cut two astronauts from this SpaceX launch to make room on the Dragon capsule’s return leg for Wilmore and Williams.</p>



<p>Wilmore and Williams watched the liftoff via a live link sent to the space station, prompting a cheer of “Go Dragon!” from Williams, NASA deputy program manager Dina Contella said.</p>
    
<p>Williams has been promoted to commander of the space station, which will soon be back to its normal population of seven. Once Hague and Gorbunov arrive on Sunday, four astronauts living there since March can leave in their own SpaceX capsule. Their homecoming was delayed a month by Starliner’s turmoil.</p><p>Hague noted before the flight that change is the one constant in human spaceflight.</p><p>“There’s always something that is changing. Maybe this time it’s been a little more visible to the public,” he said.</p>
    

<p>Hague was thrust into the commander’s job for the rescue mission based on his experience and handling of a launch emergency six years ago. The Russian rocket failed shortly after liftoff, and the capsule carrying him and a cosmonaut catapulted off the top to safety.</p><p>Rookie NASA astronaut Zena Cardman and veteran space flier Stephanie Wilson were pulled from this flight after NASA opted to go with SpaceX to bring the stuck astronauts home. Promised a future space mission, both were at NASA’s Kennedy Space Center, taking part in the launch livestream. Gorbunov remained on the flight under an exchange agreement between NASA and the Russian Space Agency.</p><p>“Every crewed launch that I have ever watched has really brought me a lot of emotion. This one today was especially unique,” a teary-eyed Cardman said following the early afternoon liftoff. “It was hard not to watch that rocket lift off without thinking, ‘That’s my rocket and that’s my crew.’ ”</p><p>Moments before liftoff, Hague paid tribute to his two colleagues left behind: “Unbreakable. We did it together.” Once in orbit, he called it a ”sweet ride” and thanked everyone who made it possible.</p>
    

<p>Earlier, Hague acknowledged the challenges of launching with half a crew and returning with two astronauts trained on another spacecraft. </p><p>“We’ve got a dynamic challenge ahead of us,” Hague said after arriving from Houston last weekend. “We know each other and we’re professionals and we step up and do what’s asked of us.”</p><p>SpaceX has long been the leader in NASA’s commercial crew program, established as the space shuttles were retiring more than a decade ago. SpaceX beat Boeing in delivering astronauts to the space station in 2020, and it is now up to 10 crew flights for NASA.</p><p>Boeing has struggled with a variety of issues over the years, repeating a Starliner test flight with no one on board after the first one veered off course. The Starliner that left Wilmore and Williams in space landed without any issues in the New Mexico desert on Sept. 6, and has since returned to Kennedy Space Center. A week ago, Boeing’s defense and space chief was replaced.</p>
    

<p>Delayed by Hurricane Helene pounding Florida, the latest SpaceX liftoff marked the first for astronauts from Launch Complex 40 at Cape Canaveral Space Force Station. SpaceX took over the old Titan rocket pad nearly two decades ago and used it for satellite and station cargo launches, while flying crews from Kennedy’s former Apollo and shuttle pad next door. The company wanted more flexibility as more Falcon rockets soared.</p><h2>___</h2><p>The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute’s Science and Educational Media Group. The AP is solely responsible for all content. </p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Discord stores trillions of messages (382 pts)]]></title>
            <link>https://discord.com/blog/how-discord-stores-trillions-of-messages</link>
            <guid>41683293</guid>
            <pubDate>Sat, 28 Sep 2024 22:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discord.com/blog/how-discord-stores-trillions-of-messages">https://discord.com/blog/how-discord-stores-trillions-of-messages</a>, See on <a href="https://news.ycombinator.com/item?id=41683293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="heading-1"><p>In 2017, we wrote a blog post on <a href="https://discord.com/blog/how-discord-stores-billions-of-messages">how we store billions of messages.</a> We shared our journey of how we started out using MongoDB but migrated our data to Cassandra because we were looking for a database that was scalable, fault-tolerant, and relatively low maintenance. We knew we’d be growing, and we did!</p><p>We wanted a database that grew alongside us, but hopefully, its maintenance needs wouldn’t grow alongside our storage needs. Unfortunately, we found that to not be the case — our Cassandra cluster exhibited serious performance issues that required increasing amounts of effort to just maintain, not improve.</p><p>Almost six years later, we’ve changed a lot, and how we store messages has changed as well.<br>‍</p></div><div id="heading-2"><h2>Our Cassandra Troubles</h2><p>We stored our messages in a database called cassandra-messages. As its name suggests, it ran Cassandra, and it stored messages. In 2017, we ran 12 Cassandra nodes, storing billions of messages.</p><p>At the beginning of 2022, it had 177 nodes with trillions of messages. To our chagrin, it was a high-toil system — our on-call team was frequently paged for issues with the database, latency was unpredictable, and we were having to cut down on maintenance operations that became too expensive to run.</p><p>What was causing these issues? First, let’s take a look at a message.</p><p>The CQL statement above is a minimal version of our message schema. Every ID we use is a <a href="https://blog.twitter.com/engineering/en_us/a/2010/announcing-snowflake">Snowflake</a>, making it chronologically sortable. We partition our messages by the channel they’re sent in, along with a bucket, which is a static time window. This partitioning means that, in Cassandra, all messages for a given channel and bucket will be stored together and replicated across three nodes (or whatever you’ve set the replication factor).</p><p>Within this partitioning lies a potential performance pitfall: a server with just a small group of friends tends to send orders of magnitude fewer messages than a server with hundreds of thousands of people.</p><p>In Cassandra, reads are more expensive than writes. Writes are appended to a commit log and written to an in memory structure called a memtable that is eventually flushed to disk. Reads, however, need to query the memtable and potentially multiple SSTables (on-disk files), a more expensive operation. Lots of concurrent reads as users interact with servers can hotspot a partition, which we refer to imaginatively as a “hot partition”. &nbsp;The size of our dataset when combined with these access patterns led to struggles for our cluster.</p><p>When we encountered a hot partition, it frequently affected latency across our entire database cluster. One channel and bucket pair received a large amount of traffic, and latency in the node would increase as the node tried harder and harder to serve traffic and fell further and further behind.</p><p>Other queries to this node were affected as the node couldn’t keep up. Since we perform reads and writes with quorum consistency level, all queries to the nodes that serve the hot partition suffer latency increases, resulting in broader end-user impact.</p><p>Cluster maintenance tasks also frequently caused trouble. We were prone to falling behind on compactions, where Cassandra would compact SSTables on disk for more performant reads. Not only were our reads then more expensive, but we’d also see cascading latency as a node tried to compact.</p><p>We frequently performed an operation we called the “gossip dance”, where we’d take a node out of rotation to let it compact without taking traffic, bring it back in to pick up hints from Cassandra’s hinted handoff, and then repeat until the compaction backlog was empty. We also spent a large amount of time tuning the JVM’s garbage collector and heap settings, because GC pauses would cause significant latency spikes.<br>‍</p></div><div id="heading-3"><h2>Changing Our Architecture</h2><p>Our messages cluster wasn’t our only Cassandra database. We had several other clusters, and each exhibited similar (though perhaps not as severe) faults.</p><p>In our <a href="https://discord.com/blog/how-discord-stores-billions-of-messages">previous iteration of this post</a>, we mentioned being intrigued by ScyllaDB, a Cassandra-compatible database written in C++. Its promise of better performance, faster repairs, stronger workload isolation via its shard-per-core architecture, and a garbage collection-free life sounded quite appealing.</p><p>Although ScyllaDB is most definitely not void of issues, it is void of a garbage collector, since it’s written in C++ rather than Java. Historically, our team has had many issues with the garbage collector on Cassandra, from GC pauses affecting latency, all the way to super long consecutive GC pauses that got so bad that an operator would have to manually reboot and babysit the node in question back to health. These issues were a huge source of on-call toil, and the root of many stability issues within our messages cluster.</p><p>After experimenting with ScyllaDB and observing improvements in testing, we made the decision to migrate all of our databases. While this decision could be a blog post in itself, the short version is that by 2020, we had migrated every database but one to ScyllaDB.</p><p>The last one? Our friend, cassandra-messages.</p><p>Why hadn’t we migrated it yet? To start with, it’s a big cluster. With trillions of messages and nearly 200 nodes, any migration was going to be an involved effort. Additionally, we wanted to make sure our new database could be the best it could be as we worked to tune its performance. We also wanted to gain more experience with ScyllaDB in production, using it in anger and learning its pitfalls.</p><p>We also worked to improve ScyllaDB performance for our use cases. In our testing, we discovered that the performance of reverse queries was insufficient for our needs. We execute a reverse query when we attempt a database scan in the opposite order of a table’s sorting, such as when we scan messages in ascending order. The ScyllaDB team prioritized improvements and implemented performant reverse queries, removing the last database blocker in our migration plan.</p><p>We were suspicious that slapping a new database on our system wasn’t going to make everything magically better. Hot partitions can still be a thing in ScyllaDB, and so we also wanted to invest in improving our systems upstream of the database to help shield and facilitate better database performance.<br>‍</p></div><div id="heading-4"><h2>Data Services Serving Data</h2><p>With Cassandra, we struggled with hot partitions. High traffic to a given partition resulted in unbounded concurrency, leading to cascading latency in which subsequent queries would continue to grow in latency. If we could control the amount of concurrent traffic to hot partitions, we could protect the database from being overwhelmed.</p><p>To accomplish this task, we wrote what we refer to as data services — intermediary services that sit between our API monolith and our database clusters. When writing our data services, we chose a language we’ve been using <a href="https://discord.com/blog/why-discord-is-switching-from-go-to-rust">more and more at Discord</a>: Rust! We’d used it for a few projects previously, and it lived up to the hype for us. It gave us fast C/C++ speeds without having to sacrifice safety.</p><p>Rust touts fearless concurrency as one of its main benefits — the language should make it easy to write safe, concurrent code. Its libraries also were a great match for what we were intending to accomplish. The <a href="https://tokio.rs/">Tokio ecosystem</a> is a tremendous foundation for building a system on asynchronous I/O, and the language has driver support for both Cassandra and ScyllaDB.</p><p>Additionally, we found it a joy to code in with the help the compiler gives you, the clarity of the error messages, the language constructs, and its emphasis on safety. We became quite fond of how once it compiled, it generally works. Most importantly, however, it lets us say we rewrote it in Rust (meme cred is very important).</p><p>Our data services sit between the API and our ScyllaDB clusters. They contain roughly one gRPC endpoint per database query and intentionally contain no business logic. The big feature our data services provide is request coalescing. If multiple users are requesting the same row at the same time, we’ll only query the database once. The first user that makes a request causes a worker task to spin up in the service. Subsequent requests will check for the existence of that task and subscribe to it. That worker task will query the database and return the row to all subscribers.</p><p>This is the power of Rust in action: it made it easy to write safe concurrent code.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/6406629e7ba3569d3c32c8ed_Example%201%402x.png" loading="lazy" alt=""></p></figure><p>Let’s imagine a big announcement on a large server that notifies @everyone: users are going to open the app and read the message, sending tons of traffic to the database. Previously, this might lead to a hot partition, and on-call would potentially need to be paged to help the system recover. With our data services, we’re able to significantly reduce traffic spikes against the database.</p><p>The second part of the magic here is upstream of our data services. We implemented consistent hash-based routing to our data services to enable more effective coalescing. For each request to our data service, we provide a routing key. For messages, this is a channel ID, so all requests for the same channel go to the same instance of the service. This routing further helps reduce the load on our database.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/640662a51e3e13599d292404_Example%202%402x.png" loading="lazy" alt=""></p></figure><p>These improvements help a lot, but they don’t solve all of our problems. We’re still seeing hot partitions and increased latency on our Cassandra cluster, just not quite as frequently. It buys us some time so that we can prepare our new optimal ScyllaDB cluster and execute the migration.<br>‍</p></div><div id="heading-5"><h2>A Very Big Migration</h2><p>Our requirements for our migration are quite straightforward: we need to migrate trillions of messages with no downtime, and we need to do it quickly because while the Cassandra situation has somewhat improved, we’re frequently firefighting.</p><p>Step one is easy: we provision a new ScyllaDB cluster using our <a href="https://discord.com/blog/how-discord-supercharges-network-disks-for-extreme-low-latency">super-disk storage topology</a>. By using Local SSDs for speed and leveraging RAID to mirror our data to a persistent disk, we get the speed of attached local disks with the durability of a persistent disk. With our cluster stood up, we can begin migrating data into it.</p><p>Our first draft of our migration plan was designed to get value quickly. We’d start using our shiny new ScyllaDB cluster for newer data using a cutover time, and then migrate historical data behind it. It adds more complexity, but what every large project needs is additional complexity, right?</p><p>We begin dual-writing new data to Cassandra and ScyllaDB and concurrently begin to provision ScyllaDB’s Spark migrator. It requires a lot of tuning, and once we get it set up, we have an estimated time to completion: three months.</p><p>That timeframe doesn’t make us feel warm and fuzzy inside, and we’d prefer to get value faster. We sit down as a team and brainstorm ways we can speed things up, until we remember that we’ve written a fast and performant database library that we could potentially extend. We elect to engage in some meme-driven engineering and rewrite the data migrator in Rust.</p><p>In an afternoon, we extended our data service library to perform large-scale data migrations. It reads token ranges from a database, checkpoints them locally via SQLite, and then firehoses them into ScyllaDB. We hook up our new and improved migrator and get a new estimate: nine days! If we can migrate data this quickly, then we can forget our complicated time-based approach and instead flip the switch for everything at once.</p><p>We turn it on and leave it running, migrating messages at speeds of up to 3.2 million per second. Several days later, we gather to watch it hit 100%, and we realize that it’s stuck at 99.9999% complete (no, really). Our migrator is timing out reading the last few token ranges of data because they contain gigantic ranges of tombstones that were never compacted away in Cassandra. We compact that token range, and seconds later, the migration is complete!</p><p>We performed automated data validation by sending a small percentage of reads to both databases and comparing results, and everything looked great. The cluster held up well with full production traffic, whereas Cassandra was suffering increasingly frequent latency issues. We gathered together at our team onsite, flipped the switch to make ScyllaDB the primary database, and ate celebratory cake!<br>‍</p></div><div id="heading-6"><h2>Several Months Later…</h2><p>We switched our messages database over in May 2022, but how’s it held up since then?</p><p>It’s been a quiet, well-behaved database (it’s okay to say this because I’m not on-call this week). We’re not having weekend-long firefights, nor are we juggling nodes in the cluster to attempt to preserve uptime. It’s a much more efficient database — we’re going from running 177 Cassandra nodes to just 72 ScyllaDB nodes. Each ScyllaDB node has 9 TB of disk space, up from the average of 4 TB per Cassandra node.</p><p>Our tail latencies have also improved drastically. For example, fetching historical messages had a p99 of between 40-125ms on Cassandra, with ScyllaDB having a nice and chill 15ms p99 latency, and message insert performance going from 5-70ms p99 on Cassandra, to a steady 5ms p99 on ScyllaDB. Thanks to the aforementioned performance improvements, we’ve unlocked new product use cases now that we have confidence in our messages database.</p><p>At the end of 2022, people all over the world tuned in to watch the World Cup. One thing we discovered very quickly was that goals scored showed up in our monitoring graphs. This was very cool because not only is it neat to see real-world events show up in your systems, but this gave our team an excuse to watch soccer during meetings. We weren’t “watching soccer during meetings”, we were “proactively monitoring our systems’ performance.”</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/6406587246a8ce1cfe8f105f_Screen%20Shot%202023-02-27%20at%205.44.56%20PM.png" loading="lazy" alt=""></p></figure><p>We can actually tell the story of the World Cup Final via our message send graph. The match was tremendous. Lionel Messi was trying to check off the last accomplishment in his career and cement his claim to being the greatest of all time and lead Argentina to the championship, but in his way stood the massively talented Kylian Mbappe and France.</p><p>Each of the nine spikes in this graph represents an event in the match.</p><ol role="list"><li>Messi hits a penalty, and Argentina goes up 1-0.</li><li>Argentina scores again and goes up 2-0.</li><li>It’s halftime. There’s a sustained fifteen-minute plateau as users chat about the match.</li><li>The big spike here is because Mbappe scores for France and scores again 90 seconds later to tie it up!</li><li>It’s the end of regulation, and this huge match is going to extra time.</li><li>Not much happens in the first half of extra time, but we reach halftime and users are chatting.</li><li>Messi scores again, and Argentina takes the lead!</li><li>Mbappe strikes back to tie it up!</li><li>It’s the end of extra time, we’re heading to penalty kicks!</li><li>Excitement and stress grow throughout the shootout until France misses and Argentina doesn’t! Argentina wins!</li></ol><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/64065884c4a34e2bcb7b470d_Screen%20Shot%202023-02-27%20at%205.52.07%20PM.png" loading="lazy" alt=""></p><figcaption>Coalesced messages per second</figcaption></figure><p>People all over the world are stressed watching this incredible match, but meanwhile, Discord and the messages database aren’t breaking a sweat. We’re way up on message sends and handling it perfectly. &nbsp;With our Rust-based data services and ScyllaDB, we’re able to shoulder this traffic and provide a platform for our users to communicate.</p><p>We’ve built a system that can handle trillions of messages, and if this work is something that excites you, <a href="https://discord.com/careers">check out our careers page</a>. We’re hiring!<br>‍</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: htmgo - build simple and scalable systems with golang + htmx (146 pts)]]></title>
            <link>https://htmgo.dev</link>
            <guid>41683144</guid>
            <pubDate>Sat, 28 Sep 2024 21:34:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htmgo.dev">https://htmgo.dev</a>, See on <a href="https://news.ycombinator.com/item?id=41683144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>introduction:</strong></p>
<p>htmgo is a lightweight pure go way to build interactive websites / web applications using go &amp; htmx.</p>
<p>By combining the speed &amp; simplicity of go + hypermedia attributes (<a href="https://htmx.org/">htmx</a>) to add interactivity to websites, all conveniently wrapped in pure go, you can build simple, fast, interactive websites without touching javascript. All compiled to a <strong>single deployable binary</strong>.</p>
<pre tabindex="0"><code><span><span><span>func</span> <span>IndexPage</span>(ctx <span>*</span>h.RequestContext) <span>*</span>h.Page {
</span></span><span><span>  now <span>:=</span> time.<span>Now</span>()
</span></span><span><span>  <span>return</span> h.<span>NewPage</span>(
</span></span><span><span>    h.<span>Div</span>(
</span></span><span><span>      h.<span>Class</span>(<span>"flex gap-2"</span>),
</span></span><span><span>      h.<span>TextF</span>(<span>"the current time is %s"</span>, now.<span>String</span>())
</span></span><span><span>    )
</span></span><span><span>  )
</span></span><span><span>}
</span></span></code></pre><p><strong>core features:</strong></p>
<ol>
<li>deployable single binary</li>
<li>live reload (rebuilds css, go, ent schema, and routes upon change)</li>
<li>automatic page and partial registration based on file path</li>
<li>built in tailwindcss support, no need to configure anything by default</li>
<li>plugin architecture to include optional plugins to streamline development, such as <a href="http://entgo.io/">http://entgo.io</a></li>
<li>custom <a href="https://github.com/maddalax/htmgo/tree/b610aefa36e648b98a13823a6f8d87566120cfcc/framework/assets/js/htmxextensions">htmx extensions</a> to reduce boilerplate with common tasks</li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Britain buys semiconductor factory for defence purposes (199 pts)]]></title>
            <link>https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/</link>
            <guid>41683098</guid>
            <pubDate>Sat, 28 Sep 2024 21:23:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/">https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/</a>, See on <a href="https://news.ycombinator.com/item?id=41683098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3>The UK government has acquired a semiconductor factory in Newton Aycliffe, County Durham, in a move to strengthen the defence supply chain and support the Armed Forces.</h3><p><strong>This facility is the only secure site in the UK capable of manufacturing gallium arsenide semiconductors, a vital component in military platforms such as fighter jets.</strong></p><p>Defence Secretary John Healey visited the site, which was previously owned by Coherent Inc. and will now be known as Octric Semiconductors UK. The acquisition is expected to secure up to 100 skilled jobs in the North East and safeguard a critical part of the UK’s defence infrastructure.</p><p><em>“Semiconductors are at the forefront of the technology we rely upon today, and will be crucial in securing our military’s capabilities for tomorrow.</em><br> <em>This acquisition is a clear signal that our government will back British defence production. We’ll protect and grow our UK Defence supply chain, supporting North East jobs, safeguarding crucial tech for our Armed Forces and boosting our national security.”</em></p><p>Semiconductors are an essential component of modern electronics, from phones and computers to military applications. The government has stated that this acquisition will enhance the UK’s defence capabilities and increase its industrial capacity, with plans to invest further in the facility over the coming years.</p><p>The acquisition comes ahead of an Investment Summit aimed at strengthening the UK’s trading relations and supporting high-quality jobs at home.</p><p>With global semiconductor demand rising, this move positions the UK to meet future technological needs, including advancements in artificial intelligence, quantum technologies, and 6G.</p><h3>Background</h3><p>In 2023, Coherent, the former owner of the Newton Aycliffe semiconductor facility, announced plans to cut over 100 jobs due to a drop in business demand, leaving the future of the site in doubt. With the facility’s long history of ownership changes since it first opened in 1991, there were growing concerns about whether it could continue producing the crucial semiconductor components needed for industries like defence and aerospace.</p><p>The recent government acquisition is a key move to secure the future of this vital facility. By stepping in, the government is protecting jobs and ensuring the production of important semiconductors used in military applications, such as boosting fighter jet capabilities. This not only stabilises the plant after last year’s uncertainty but also strengthens the UK’s ability to maintain control over critical technology in the defence sector.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Possible cluster of human bird-flu infections expands in Missouri (101 pts)]]></title>
            <link>https://www.nytimes.com/2024/09/27/health/bird-flu-cluster-missouri.html</link>
            <guid>41682828</guid>
            <pubDate>Sat, 28 Sep 2024 20:41:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/09/27/health/bird-flu-cluster-missouri.html">https://www.nytimes.com/2024/09/27/health/bird-flu-cluster-missouri.html</a>, See on <a href="https://news.ycombinator.com/item?id=41682828">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/09/27/health/bird-flu-cluster-missouri.html: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>