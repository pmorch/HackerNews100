<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 02 Oct 2025 10:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Immich v2.0.0 ‚Äì First stable release (152 pts)]]></title>
            <link>https://github.com/immich-app/immich/discussions/22546</link>
            <guid>45446834</guid>
            <pubDate>Thu, 02 Oct 2025 06:25:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/immich-app/immich/discussions/22546">https://github.com/immich-app/immich/discussions/22546</a>, See on <a href="https://news.ycombinator.com/item?id=45446834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="8971417" data-target-translation-type="discussion">
        <tr>
    <td>
        <h2 dir="auto">v2.0.0 - Stable Release of Immich</h2>
<p dir="auto"><a href="https://www.youtube.com/watch?v=xz8LfGXgFAI" rel="nofollow">Watch the video</a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=xz8LfGXgFAI" rel="nofollow"><img src="https://camo.githubusercontent.com/ed58cd08a441dd9a013bcc51e61ef4c4fe0f4bd852807fd5204d6d4ecdb0c82d/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f787a384c664758674641492f6d617872657364656661756c742e6a7067" alt="YouTube Video" data-canonical-src="https://img.youtube.com/vi/xz8LfGXgFAI/maxresdefault.jpg"></a></p>
<h2 dir="auto">Welcome</h2>
<p dir="auto">Hello everyone,</p>
<p dir="auto">After:</p>
<ul dir="auto">
<li><em>~1,337 days,</em></li>
<li><em>271 releases,</em></li>
<li><em>78,000 stars on GitHub,</em></li>
<li><em>1,558 contributors,</em></li>
<li><em>31,500 members on Discord,</em></li>
<li><em>36,000 members on Reddit,</em></li>
<li><em>68 languages on Weblate,</em></li>
<li><em>Surviving the controversial announcement about joining FUTO,</em></li>
<li><em>Having overwhelming success and support from the community with the product keys model,</em></li>
<li><em>Launching the Merch store,</em></li>
<li><em>Attending our first FOSDEM,</em></li>
<li><em>...and <strong>before</strong></em> <em>the release of GTA VI</em></li>
</ul>
<p dir="auto">We are thrilled to announce the <strong>stable release of Immich!</strong> üéâ</p>
<p dir="auto">This has been a journey long in the making. So much has changed since the first commit on the project, all the way back in February, 2022. The project and team continue to grow, and today we‚Äôre proud to announce <code>v2.0.0</code>, our stable release. Stable signifies that we have now resolved a significant amount of technical debt. It also means we will be prioritizing compatibility and less effort will be required to keep Immich up-to-date. Finally, it means that the warning banner on the website has been removed! Along with this, we‚Äôre happy to announce a new version of the <a href="https://immich.app/" rel="nofollow">https://immich.app/</a> website.</p>
<p dir="auto">For more specifics about the stable release, see our <a href="#user-content-faqs">FAQs</a> below.</p>
<h2 dir="auto">Merch and DVD</h2>
<p dir="auto">To celebrate this release, we want to capture this moment in a nostalgic form, reminiscent of how software was distributed in our childhood - on a CD (or DVD, in this ‚Äúcase‚Äù). Introducing Immich Stable in physical form! You can find the link to the disk <a href="https://immich.store/products/immich-retro" rel="nofollow">here</a></p>
<a href="https://immich.store/products/immich-retro" rel="nofollow">
<img width="1200" alt="image" src="https://private-user-images.githubusercontent.com/27055614/496353055-c3883849-ffeb-4022-9b7a-09cbdd7c714c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTkzOTc3MDIsIm5iZiI6MTc1OTM5NzQwMiwicGF0aCI6Ii8yNzA1NTYxNC80OTYzNTMwNTUtYzM4ODM4NDktZmZlYi00MDIyLTliN2EtMDljYmRkN2M3MTRjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEwMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMDAyVDA5MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRmMTZmZDA5MzlhNjA1OGYzYTc5NTNiMjI2YjZiYjQ1MThiOGZlYWVmYWExNjBmOGJiYjMwY2YyOWY0MTIyYWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uXCyqI3xWs9Iuv7G1W3exnxrWVKXO3wKSst9nTuIkpY" secured-asset-link="">
</a>
<p dir="auto">The disk comes with a fully bootable Immich instance, featuring a selection of curated photos chosen by the team. You can purchase the disk from our merch store, along with a client or server product key, to support and celebrate this milestone with us.</p>
<p dir="auto">The merch store is also updated with retro-styled Immich designs, check it out in <a href="https://immich.store/" rel="nofollow">https://immich.store</a></p>
<a href="https://immich.store/" rel="nofollow">
<img width="1200" alt="image" src="https://private-user-images.githubusercontent.com/27055614/496353135-d2dc89c2-61af-4f64-afae-10c98ffbb08f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTkzOTc3MDIsIm5iZiI6MTc1OTM5NzQwMiwicGF0aCI6Ii8yNzA1NTYxNC80OTYzNTMxMzUtZDJkYzg5YzItNjFhZi00ZjY0LWFmYWUtMTBjOThmZmJiMDhmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEwMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMDAyVDA5MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI2OWY5NmFmYzYwMjQ5MTNhNmQyNDRjYThiZWEzZjA2MzEwZTI4OTkyMmMwNmNkODJiMTllZjAwMWY3ZWU1ODgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.bZxwNO6jqlW6RrDTbKHvsfmOWEm85cbghrgC2nriPCA" secured-asset-link="">
</a>
<h2 dir="auto">Future plans</h2>
<p dir="auto">Now that Immich is stable, here are some of the things that we will be focusing on:</p>
<ul dir="auto">
<li><strong>Roadmap</strong> ‚Äî There are still a few items on our roadmap that we want to complete before the year ends such as auto-stacking, and achieving feature parity between the web and mobile app. We also have plans to start work on improved stack support, better sharing, group management, and ownership improvements, as well as many other enhancements.</li>
<li><strong>Usage data</strong> ‚Äî The team wants to understand how the software is used, so that we can make better, informed decisions as we design and build Immich. We want to collect that information in a non-invasive and transparent way. We plan to discuss it with the community and gather feedback from everyone to come up with the best solution.</li>
<li><strong>Backup services</strong> ‚Äî We aim to introduce additional paid services (<em>not paywalled features, as we will never implement paywalled features</em>), which will help support the project and that enhance self-hosting, making it easier and more reliable. First among the many services already planned is an end-to-end encrypted, off-site backup and restore feature, built directly into Immich. This will enable a buddy backup feature as well.</li>
</ul>
<h2 dir="auto">Thank you</h2>
<p dir="auto">We cannot thank you enough for the support over the past three years. Community participation, from the first comments on the <a href="https://www.reddit.com/r/selfhosted/comments/si5lp6/i_am_building_a_selfhosted_alternative_version_of/" rel="nofollow">original reddit post</a>, to the feedback when we joined FUTO, have contributed to the awesome product Immich is today. Thank you for joining us and believing in our mission to regain control over your most precious data. Here‚Äôs to many more years!</p>
<p dir="auto">We'll also be hosting a Q&amp;A livestream tomorrow, <strong>October 2nd, 2025 at 6 PM UTC</strong>. You can submit your questions <a href="https://www.live-ask.com/event/01K6GFKQGJSB1GQC086ZJW6F6R" rel="nofollow">here</a> and subscribe for notifications when the livestream starts <a href="https://www.youtube.com/live/qgQ4ci2hRMQ" rel="nofollow">here</a>.</p>
<p dir="auto">Cheers,</p>
<p dir="auto">The Immich Team</p>
<hr>
<h2 id="user-content-faqs" dir="auto">FAQs</h2>
<h2 dir="auto">Will there be a live stream?</h2>
<p dir="auto">Yes. We'll be hosting a Q&amp;A livestream tomorrow, <strong>October 2nd, 2025 at 6 PM UTC</strong>. You can submit your questions <a href="https://www.live-ask.com/event/01K6GFKQGJSB1GQC086ZJW6F6R" rel="nofollow">here</a> and subscribe for notifications when the livestream starts <a href="https://www.youtube.com/live/qgQ4ci2hRMQ" rel="nofollow">here</a>.</p>
<h2 dir="auto">Do I still need backups?</h2>
<p dir="auto">Yes! A 3-2-1 backup strategy is still crucial. The team has the responsibility to ensure that the application doesn‚Äôt cause loss of your precious memories; however, we cannot guarantee that hard drives will not fail, or an electrical event causes unexpected shutdown of your server/system, leading to data loss. Therefore, we still encourage users to follow best practices when safeguarding their data. Keep multiple copies of your most precious data: at least two local copies and one copy offsite in cold storage. Additionally, we are starting to work on a cloud backup service to make backups easier.</p>
<h2 dir="auto">When will <code>v2.0.0</code> be available?</h2>
<p dir="auto">The Docker images for <code>v2.0.0</code> will be pushed out a few hours after this post is released.</p>
<h2 dir="auto">How can I update to <code>v2.0.0</code>?</h2>
<p dir="auto">You can follow the upgrade documentation, <a href="https://docs.immich.app/install/upgrading" rel="nofollow">here</a>.</p>
<h2 dir="auto">What versioning strategy will Immich use?</h2>
<p dir="auto">Starting with <code>v2.0.0</code>, we will now follow <a href="https://semver.org/" rel="nofollow">semantic versioning</a>.</p>
<h2 dir="auto">What mobile app versions will work with <code>v2.0.0</code>?</h2>
<p dir="auto">Any <code>v2.x.x</code> version of the mobile app will work with any <code>2.x.x</code> version of the server. For example, a mobile app on version <code>v2.9.0</code> will continue to work with server versions: <code>v2.0.0</code>, <code>v2.1.0</code>, <code>v2.3.1</code>, etc.</p>
<h2 dir="auto">Will new features continue to be released?</h2>
<p dir="auto">Yes. Immich will continue to build, develop, and release new features.</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keyhive ‚Äì Local-first access control (108 pts)]]></title>
            <link>https://www.inkandswitch.com/keyhive/notebook/</link>
            <guid>45445114</guid>
            <pubDate>Thu, 02 Oct 2025 00:12:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inkandswitch.com/keyhive/notebook/">https://www.inkandswitch.com/keyhive/notebook/</a>, See on <a href="https://news.ycombinator.com/item?id=45445114">Hacker News</a></p>
<div id="readability-page-1" class="page">

  <header>
    
    <h2>Local-first access control</h2>

    

    <div>
<p>üêù</p>
<p>Keyhive is a project exploring local-first access control. It aims to provide a firm basis for secure collaboration, similar to the guarantees of private chat but for any local-first application.</p>
<p>In this lab notebook, we‚Äôll share snippets of our findings as we explore the problem space and prototype potential solutions.</p>
<p>The entries start from the beginning, but you can jump to the most recent post: <a href="https://www.inkandswitch.com/keyhive/notebook/05/">05 ¬∑ Syncing Keyhive</a></p>
    </div>
  </header>

<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/00/">00 ¬∑ Keyhive Background</a></h2>
  <p>2024 Aug 1</p>
<p>As the <a href="https://www.inkandswitch.com/local-first/">local-first</a> ecosystem matures, the contexts that local-first applications fill has also expanded. Local-first emphasizes collaboration, but the constraints on an application are different if you build an application for you and a handful of friends versus delivering a team-oriented product. Your data not being viewable or editable by everyone in the world is a basic requirement of applications ranging from planning a surprise party, corporate meeting notes, book drafts, and legal contracts.</p>
<p>Today‚Äôs most common access control patterns assume a central server. While cloud auth tools are forever developing, generally speaking existing tools for cloud auth are very mature. Doing access control without a cloud auth server requires rethinking the underlying mechanics of how auth works. Keyhive is an attempt to do secure and efficient local-first auth while retaining the user experience found in familiar applications like Google Docs, Dropbox, GitHub, and Discord. We believe that these are table stakes for the next generation of local-first applications.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/00/github-rbac.png" alt="GitHub Repo Membership Page">
<figcaption>
<p>A GitHub repository permissions page</p>
</figcaption>
</figure>
<p>We‚Äôve seen user-agency principals successfully applied to other contexts. <a href="https://signal.org/">Signal</a> popularized end-to-end encrypted chat while retaining much of the convenience of less-secure messaging applications. We find ourselves asking ‚Äúwhat would Signal for documents look like?‚Äù</p>
<h2>Least Surprise</h2>
<p>Unlike a cloud auth system which can depend on the network to keep data hidden behind a web API, local-first runs a complete copy of the application at each replica. What are the correct bounds on access control when everyone has direct access to all of the content? Ultimately access control is about collaboration. Collaboration and access control can be seen as two sides of the same topic: who do you want to collaborate with, in which ways, and for how long?</p>
<p>CRDTs try to merge data in the least surprising way possible. For example, concurrent text will merge to produce the same data on all replicas, but the resulting paragraphs may not make sense next to each other. Users then fix these semantic errors manually. We believe that this is a major improvement over the user experience of something like Git, which often gets stuck and demands user intervention.</p>
<p>The equivalent situation exists for concurrent access control, but the stakes are higher. Preventing your friend from learning that you‚Äôre planning a surprise party, or opposing legal councel from altering your case prep are both important, and it should be clear how they will behave despite any underlying concurrency. The behavior of an access control system should be as clear to the end user as possible. Since there is no single source of truth about who can do what at any given time, the rules themselves need to be straightforward.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/00/history.png" alt="Ranges of authorization over time">
<figcaption>
<p>Ranges of authorization (and revocation) over time. Here üôã‚Äç‚ôÄÔ∏è is added, removed, and re-added later. Some of üôã‚Äç‚ôÄÔ∏è‚Äôs updates are not materialized based on where they‚Äôre ordered in the document history.</p>
</figcaption>
</figure>
<h2>Out of Obscurity</h2>
<p>Often local-first applications today depend on <a href="https://en.wikipedia.org/wiki/Security_through_obscurity">‚Äúsecurity through obscurity‚Äù</a>. For example, by default you can write into any <a href="https://automerge.org/">Automerge</a> document that you know the document ID for. This style is sometimes called ‚Äú<a href="http://erights.org/talks/thesis/markm-thesis.pdf">Swiss number</a>‚Äù or ‚Äú<a href="https://en.wikipedia.org/wiki/Rumpelstiltskin">Rumpelstiltskin</a>‚Äù security. It works as long as the document ID is only ever shared with people that you want to collaborate with, your security is all-or-nothing, and you never want to later remove someone from a document. If the document ID leaks (e.g. someone posts it to Bluesky), then the document is world-writable.</p>
<p>In lieu of a widely-adopted<sup><a href="#fn1" id="fnref1">1</a></sup> purely local-first access control system, some teams have tried leveraging existing auth methods by routing updates through a cloud auth server (e.g. <a href="https://en.wikipedia.org/wiki/OAuth">OAuth</a> login and auth logic in a server). Others have opted to emphasize decentralized user agency by using a blockchain to store access control policies. Both of these approaches require a network connection in order to check if an update is valid, which is not local-first. Bringing access control features to a local-first context requires rethinking how authority flows between nodes.</p>
<p>What we want is a system that retains the best of the above: the self-certification of Rumpelstiltskin, the power of auth servers, and the user agency of decentralized solutions. Following the definition of local-first, applications should accept updates after arbitrarily long periods of disconnection. Extending that requirement to access control means the ability to revoke access or have finer grained control (e.g. read vs write) requires tracking who has authorization to do what, and at which point in the document‚Äôs history.</p>
<!-- Footnotes -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>While we believe that local-first access control is nascent, the Keyhive team is grateful to benefit from work done by other projects. Some of our inspirations include <a href="https://mattweidner.com/assets/pdf/acs-dissertation.pdf">Causal TreeKEM</a>, <a href="https://ieeexplore.ieee.org/document/4032481">Cryptree</a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3460120.3484542">DCGKA</a>, <a href="https://github.com/local-first-web/auth">Local-First Auth</a>, <a href="https://matrix.org/">Matrix</a>, <a href="https://www.serenity.page/">Serenity</a>, <a href="https://tahoe-lafs.org/trac/tahoe-lafs">Tahoe-LAFS</a>, <a href="https://github.com/ucan-wg">UCAN</a>, and <a href="https://github.com/wnfs-wg">Web Native File System</a>. <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/01/">01 ¬∑ Welcome to the Keyhive</a></h2>
  <p>2024 Sept 5</p>
<p>Today‚Äôs cloud services have very mature access control features. These systems depend on a key architectural detail: they are able to rely on encapsulation by taking advantage of the network boundary. Since data is not available to read or write directly by the client, a privileged guard process is able to apply arbitrary access control rules. This process retrieves and/or mutates data on behalf of clients.</p>
<p>This power unfortunately comes at a price: since auth is on the hot path of every request ‚Äî and generally depends on a central single-source-of-truth auth database ‚Äî authorization at scale often bottlenecks overall application performance. And yet, an attacker that is able to bypass the auth part of the request lifecycle has unmitigated access to arbitrarily read, change, or delete the application‚Äôs data. This is to say nothing of the complexity of building, deploying, and maintaining cloud architectures to get that network boundary in the first place!</p>
<p>For local-first software to be successful in many production contexts, it needs to provide similar features without relying on a central authorization server. The local-first setting does not have the luxury of a network boundary: access control must travel with the data itself and work without a central guard.</p>
<p>There are also some tricky edge cases due to causal consistency. What should happen to honest operations that causally depend on content that‚Äôs later discovered to be malicious? What is the best strategy to handle operations from an agent that was revoked concurrently, especially given that ‚Äúback-dating‚Äù operations is always possible. If a document has exactly two admins (and many non-admin users), what should happen if the admins concurrently revoke each other (for instance, one is malicious)?</p>

<p>To address the above challenges, we‚Äôve started work on Keyhive: a project focused on local-first access control. Our goal is to design and build a production ready instance of such a system which is general enough for most local-first applications.</p>
<h2 id="audience-and-application"><a href="#audience-and-application">Audience &amp; Application</a></h2>
<p>To date, the local-first ecosystem has primarily used a purely pull-based model where users manually decide which changes to accept. This approach is often sufficient for personal projects: each user can manually decide which peers to connect to and which changes should be applied. On the other hand, many production contexts have lower trust, require higher alignment, and are ideally low touch <em>enough</em> so that it‚Äôs not up to each person in a large organization to separately and manually infer who to trust. As a rough north star, we‚Äôre keeping the following use cases in mind:</p>
<ul>
<li>Publishing (publicly visible data with restricted edits, like a blog)</li>
<li>Planning a surprise party: small groups, low risk</li>
<li>Meeting notes: small-to-medium groups, low-to-medium risk</li>
<li>Corporate legal documents: medium-to-large groups, medium-to-high risk</li>
<li>Journalists &amp; activists: small-to-medium groups, high risk</li>
</ul>
<p>Cryptography has a reputation for being slow, especially if there‚Äôs crypto-heavy code running on low-powered devices. To have a performance margin that can cover a large range of practical use cases, Keyhive aims to run efficiently over at least ten-of-thousands of documents, millions of readers, thousands of writers, and hundreds of admins/superusers.</p>
<h3 id="antigoals"><a href="#antigoals">Antigoals</a></h3>
<p>Since authorization, authentication, and identity are often conflated, it is worth highlighting that Keyhive deliberately excludes user identity (i.e. the binding of a human identity to an application‚Äôs identifier like a public key). In our initial community consultations we found that there are many different identity mechanisms that developers downstream of Keyhive would like to use. As such, we‚Äôre designing the system to be <a href="https://en.wikipedia.org/wiki/Zooko's_triangle">decentralized and secure</a>, and leave name registration/discovery and user verification (e.g. email or social) to a future layer above Keyhive.</p>
<p>The following are left out of our design goals:</p>
<ul>
<li>Constraining downstream applications to use a small predefined set of policies or roles</li>
<li>Interactive protocols (since local-first must work under network partition)</li>
<li>Reliance on a central authority</li>
<li><a href="https://en.wikipedia.org/wiki/Cryptographic_agility">Cryptographic agility</a></li>
<li><a href="https://en.wikipedia.org/wiki/Federal_Information_Processing_Standards">FIPS</a> (or similar) compliance</li>
</ul>
<h2 id="layers"><a href="#layers">Layers</a></h2>
<p>Most client/server backends place data at the bottom, and compute over it. In that model, auth is just another kind of computation. Leaving access control to a central process is not possible in a local-first context. In our context, the auth layer must act as a foundation.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/stack-changes.png" alt="Comparing how authorization is layered in centralized and local-first applications">
</figure>
<p>Static authorization typically impacts the design of all other layers of a project. As an intuition, the storage layer will need to support data that is encrypted-at-rest, and so its design has a dependency on the auth layer. This means that since the design of an authorization mechanism may impose downstream constraints, its design should consider such potential impacts on the design of the rest of the stack. As much as possible, this project attempts to minimize imposing such constraints on other layers.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/block-diagram.png" alt="Dependency Stack">
</figure>
<p>Keyhive (as currently designed) carves out three layers to handle this:</p>
<ol>
<li><strong>Convergent Capabilities:</strong> A new <a href="https://en.wikipedia.org/wiki/Object-capability_model">capability</a> model appropriate for CRDTs, and sits between object- and certificate-capabilities</li>
<li><strong>A Group Management CRDT:</strong> Self-certifying, concurrent group management complete with coordination-free revocation</li>
<li><strong>E2EE with Causal Keys:</strong> With <a href="https://eprint.iacr.org/2016/221.pdf">post-compromise security (PCS)</a> and symmetric key management granting access to causal predessesors.</li>
</ol>
<p>These three have a strong dependency between each other. Capabilities enable use to manage groups, and groups let us share keys for E2EE. We will go into more detail on all three in future posts, but in the meantime here is a very high level treatment:</p>
<h3 id="convergent-capabilities"><a href="#convergent-capabilities">Convergent Capabilities</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/granovetter.png">
<figcaption>
<h4>Granovetter Diagram</h4>
<p>A diagram showing Alice delegating to Bob her existing access to Carol</p>
</figcaption>
</figure>
<p>Capabilities and delegation form the basic access control mechanism that are known to be <a href="https://srl.cs.jhu.edu/pubs/SRL2003-02.pdf">very expressive</a>. In short: all Automerge documents get identified by a public key, and delegate control over themselves to other public keys. This provides stateless self-certification with a cryptographic proof. Public keys in the system can represent anything: other documents, users, groups, or anything else. This is a very low-level mechanism that can be used to model high level concepts like <a href="http://wiki.erights.org/wiki/Walnut/Secure_Distributed_Computing#Powerbox_Capability_Manager">powerboxes</a>, <a href="https://en.wikipedia.org/wiki/Role-based_access_control">roles</a>, device groups, and more with very little code, all while remaining extensible to new patterns.</p>
<p><a href="https://en.wikipedia.org/wiki/Object-capability_model">Object-capabilities</a> (AKA ‚Äúocap‚Äù) are ‚Äú<a href="https://en.wikipedia.org/wiki/Fail-stop">fail-stop</a>‚Äù, meaning that they intentionally stop working if there‚Äôs a network partition to <a href="https://en.wikipedia.org/wiki/PACELC_theorem">preserve consistency over availability</a>. Since local-first operates under partition (e.g. offline), parts of the classic object-capability design are not suitable. Certificate capabilities such as <a href="https://www.rfc-editor.org/rfc/rfc2693">SPKI/SDSI</a>, <a href="https://w3c-ccg.github.io/zcap-spec/">zcap-ld</a> and <a href="https://github.com/ucan-wg">UCAN</a> are partition-tolerant, but depend on stateless certificate chains which is highly scalable but somewhat limits their flexibility. We propose a system between the two: convergent capabilities (‚Äúconcap‚Äù for short) which contain CRDT state to get the benefits of both while retaining suitability for local-first applications.</p>

<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/doc-group.png">
<figcaption>
<h4>An Automerge Document Agent</h4>
<p>A Keyhive document in isolation, with a simplified view of its stateful delegation graph.</p>
</figcaption>
</figure>
<p>Concurrent access control will always have some tricky situations. The big obvious ones are what to do if two admins concurrently revoke each other, or happened if operations depend on others that were revoked, and how to handle maliciously back-dated updates. There is quite a lot to discuss on this topic, so we‚Äôll leave it for a future post.</p>
<h3 id="transitive-groups"><a href="#transitive-groups">Transitive Groups</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/device-management.png">
<figcaption>
<h4>Device Management</h4>
<p>A Keyhive group showing how devices can be managed behind a proxy (‚ÄòAlice‚Äô). Documents in this scenario only need to know about Alice, not every device.</p>
</figcaption>
</figure>
<p>Groups are built on top of convergent capabilities. They‚Äôre ‚Äújust‚Äù a thin design pattern, but help model things like user devices, teams, and more. By following the delegations between groups, we can discover which public keys have what kind of access to a certain document. This provides a handy abstraction over teams and user devices. By following the links, it both lets a writer know who has read access (i.e. who to share keys for the latest E2EE chunk with), and lets the <a href="#trust-minimized-sync-servers">trust-minimized sync engine</a> know which documents the current device can request from the server.</p>
<h3 id="e2ee-with-causal-keys"><a href="#e2ee-with-causal-keys">E2EE with Causal Keys</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/causal-encryption.png">
<figcaption>
<h4>Causal Encryption</h4>
<p>Causal key management: a strategy for managing E2EE keys based on the causal structure of a document. Similar to a <a href="https://ieeexplore.ieee.org/document/4032481">Cryptree</a>, having the key to some encrypted chunk lets you iteratively discover the rest of the keys for that chunk‚Äôs causal history, but not its parents or siblings.</p>
</figcaption>
</figure>
<p>Data in Keyhive is encrypted-at-rest. Encrypting every Automerge operation separately would lead to very large documents that cannot be compressed. Instead we use the <a href="https://automerge.org/automerge-binary-format-spec/">Automerge Binary Format</a> to compress-then-encrypt ranges of changes. We expect these encryption boundaries to change over time as parts of the document become more stable, so we need a way to manage (and prune) a potentially large number of keys with changing envelope boundaries.</p>
<p>We achieve the above by including the keys to all of their causal predessesor chunks. This sacrifices forward secrecy (FS) ‚Äî leaking old message keys in the case of a later compromised key ‚Äî but retains secrecy of concurrent and future chunks. Of course ‚Äúleaking‚Äù <em>anything</em> sounds bad. However, unlike ephemeral messaging (e.g. <a href="https://signal.org/">Signal</a>) where not all users are nessesarily expected to have the entire chat history, CRDTs like Automerge require access to the entire causal history in order to render a view. This means that in all scenarios we need to pass around all historical keys, whether or not they‚Äôre in the same encryption envelope. We believe that this choice is appropriate for static control context on documents that require the entire history. As a nice side-effect of this choice, we also gain flexibility and simplicity.</p>
<p>In this design, keys behave a bit like pointers, so we can apply all of the standard data structure pointer indirection tricks to do smooth updates to encryption boundaries. This is fairly well-developed at this stage, so we will save a deeper exploration of this topic for a future post.</p>
<h2 id="pull-control"><a href="#pull-control">Pull Control</a></h2>
<p>E2EE raises a new issue: there is no such thing as perfect security. All encryption algorithms are deemed secure with respect to some explicitly-defined assumptions (such as the difficulty of factoring large primes or group operations). There may be mathematical breakthroughs, edge cases discovered, or new hardware that render your choice of encryption algorithm useless. Even more worse, keys can be accidentally leaked or devices stolen. While we can revoke future write access, if someone has the data and the symmetric key, then they have the ability to read that data. The best practice is to have defense in depth: don‚Äôt make ciphertexts retrievable by anyone, but only those with ‚Äúpull access‚Äù or higher. ‚ÄúPull‚Äù is weaker than the more familiar ‚Äúread‚Äù and ‚Äúwrite‚Äù access effects: it‚Äôs only the ability to retrieve bytes from the network but not decrypt or modify them. This is especially helpful for trust-minimizing sync servers, since by definition they cannot have the ability to see the plaintext if we want to claim E2EE.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/effects.png">
<figcaption>
<h4>Access Effects</h4>
<p>An example of delegation across the Keyhive access effect types</p>
</figcaption>
</figure>
<h2 id="trust-minimized-sync-servers"><a href="#trust-minimized-sync-servers">Trust Minimized Sync Servers</a></h2>
<p>If <a href="https://youtu.be/NMq0vncHJvU?si=_U53CwSnbpkyf5gB&amp;t=1016">we want to move towards an ecosystem of interchangeable relays</a>, minimizing trust on such relays is a must. Our approach (perhaps unsurprisingly) is to end-to-end encrypt the data, removing read access from sync servers altogether. Under this regime, sync engines are ‚Äúmerely‚Äù a way to move random-looking bytes between clients.</p>
<p>There is another ongoing project at the lab focused improving data synchronization for peer-to-peer and via sync servers. We‚Äôve realized that sync and secrecy strongly interact. Broadly speaking, sync protocols benefit from more metadata (to efficiently calculate deltas), but cryptographic protocols aim to minimize or eliminate metadata exposure. This tension extends across related systems, including merging E2EE <a href="https://automerge.org/automerge-binary-format-spec/">compressed chunks</a>, and determining if a peer has already received specific operations when a sync server cannot access them in plaintext.</p>
<p>Fortunately, combining these systems can sometimes result in more than the sum of their parts. For instance, convergent capabilities help facilitate the calculation of which documents are of interest to particular agent, helping the sync system know which documents to send deltas of. For these reasons, we‚Äôre treating synchronization and authorization as part of a larger, unified project, even though each will yield distinct artifacts.</p>
<h2 id="whats-next"><a href="#whats-next">What‚Äôs Next?</a></h2>
<p>Cryptographic code is notoriously difficult to debug, so we decided to start with design and move to code when we had some fairly good theories on how the basics of this system should work. Now that we‚Äôre at that point, we‚Äôve very recently begun to implement this design. We‚Äôll report on our progress in future posts, as well as dive deeper into some of the topics we touched on in the overview here.</p>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/02/">02 ¬∑ Group Key Agreement with BeeKEM</a></h2>
  <p>2025 Jan 21</p>
<p>As we‚Äôve seen in past lab notes, Keyhive provides access control for local-first applications. We support both server-based collaboration and peer-to-peer operation without a trusted server. And individuals might work offline for extended periods of time. In the context of Automerge, our goal is to control access to documents, collections of documents, and parts of documents.</p>
<p>Every document has a group of users with access to that document. That group might include other groups as members (in which case the members of those groups are also members of the document). Importantly, a document group‚Äôs membership is dynamic, with new members added and removed over time. We must be able to handle concurrent changes in a distributed context.</p>
<p>Of course, if we want to limit read access to just our group, we can‚Äôt safely share our document as plaintext via sync servers. We need a way to encrypt and decrypt our data that is accessible to only our document‚Äôs members. This means we need a way for our group to agree on the keys that will be used for encryption and decryption over time.</p>
<h2 id="continuous-group-key-agreement"><a href="#continuous-group-key-agreement">Continuous Group Key Agreement</a></h2>
<p>In the literature, this problem is known as <a href="https://eprint.iacr.org/2019/1189.pdf">Continuous Group Key Agreement (CGKA)</a>. A <strong>CGKA protocol</strong> enables a dynamic group to agree on a sequence of keys over time. CGKAs ordinarily guarantee two properties: forward secrecy (FS) and <a href="https://eprint.iacr.org/2016/221.pdf">post-compromise security (PCS)</a>. Imagine a successful attacker compromises a single key. In the simplest terms, forward secrecy means that this key will not enable access to past data. And post-compromise security means it will not enable access to future data. If you can guarantee both, then you can limit the damage from a key compromise.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/forward_secrecy_and_post-compromise_security.png" alt="Forward secrecy and post-compromise security">
</figure>
<p>One way to achieve <strong>forward secrecy</strong> is through ‚Äúratcheting‚Äù. With a ratchet, honest users employ a key derivation function (KDF) to deterministically transform a key in a way that is effectively impossible to reverse. A cryptographic hash function is one way to achieve this. Ratcheting with such a one-way function prevents an attacker from discovering past keys since there is no feasible way to reverse the function. But a one-way function on its own does not prevent an attacker from discovering future keys, since you can derive all future keys from a compromised key by repeatedly applying the hash function.</p>
<p>Of course, we don‚Äôt want a system that once compromised is always insecure. That‚Äôs where <strong>post-compromise security</strong> comes in. The intuitive idea is that a system with post-compromise security has some mechanism to deny access after an attack. Compromised information will no longer be enough to derive future keys. One way to achieve this is to periodically rotate information required for determining future keys in a way that is not accessible to a past attacker.</p>
<p>In practice, ratcheting protocols mix in fresh information with each ratchet so that knowledge of a key is not by itself sufficient to derive future keys. For example, Signal‚Äôs <a href="https://signal.org/docs/specifications/doubleratchet/">Double Ratchet protocol</a> includes sending a Diffie-Hellman public key with each message so that the receiver can derive a shared Diffie-Hellman secret to use as a side input to the key derivation function (KDF) that is used for ratcheting.</p>
<h3 id="treekem"><a href="#treekem">TreeKEM</a></h3>
<p>The current Message Layer Security (MLS) protocol for CGKA uses <a href="https://inria.hal.science/hal-02425247v1/file/treekem%20%281%29.pdf">TreeKEM</a>, a protocol for asynchronous, decentralized key agreement for dynamic groups<sup><a href="#fn1" id="fnref1">1</a></sup>. TreeKEM uses a binary tree with group members‚Äô public keys at the leaves and the current group secret encrypted at the root. All other inner nodes act like the root for their subtrees (and subtrees act like subgroups with their own shared, encrypted secrets). Members can be dynamically added and removed from the tree.</p>
<p>For post-compromise security, each member periodically rotates out its public keys on its leaf, which leads to cascading secret updates all the way to the root. Both updating and decrypting the root secret requires traversing the path from the member‚Äôs leaf to the root, performing <code>log(n)</code> operations (although there is a linear worst case under certain conditions).</p>
<p>Unfortunately, Keyhive‚Äôs requirements rule out TreeKEM as it stands. That‚Äôs because TreeKEM depends on a central server to create a total order of operations, and to pick winners among concurrent operations. Keyhive‚Äôs local-first model is peer-to-peer compatible and does not require such a central server. And for Keyhive, concurrent operations can be merged in long after they were actually performed (for example, if a member made changes while aboard a long-haul flight).</p>
<h3 id="decentralized-cgka-alternatives"><a href="#decentralized-cgka-alternatives">Decentralized CGKA alternatives</a></h3>
<p>An alternative that is more aligned with our requirements is the <a href="https://dl.acm.org/doi/pdf/10.1145/3460120.3484542">Decentralized Continuous Group Key Agreement (DCGKA) protocol</a> developed by <a href="https://mattweidner.com/">Matthew Weidner</a> and <a href="https://martin.kleppmann.com/">Martin Kleppmann</a>. This protocol assumes a decentralized network that does not depend on a trusted central server. However, unlike TreeKEM, it provides linear rather than logarithmic performance. As a result, they target groups on the order of 100 members as opposed to MLS‚Äôs target of 50k members. A design goal for Keyhive is to target at least thousands of members<sup><a href="#fn2" id="fnref2">2</a></sup>.</p>
<p>Matthew Weidner has also proposed an alternative to TreeKEM called <a href="https://mattweidner.com/assets/pdf/acs-dissertation.pdf">Causal TreeKEM</a>. Whereas TreeKEM requires a total order imposed by a central server, Causal TreeKEM only requires a causal order, which is much better suited to a decentralized network. Like TreeKEM, it has logarithmic performance (with a linear worst case) and is meant to ensure both forward secrecy and post-compromise security.</p>
<p>However, Causal TreeKEM depends on fancier crypto than we‚Äôd prefer in order to merge concurrent updates in any order. It requires a cryptographic operation to combine updates at a node that is both associative and commutative. One option here would be BLS, but this is far less common than the standard options and there is not currently a great library option for Rust (the language Keyhive is written in). And we have definitely ruled out rolling our own crypto (you probably should too).</p>
<p>For these reasons, we‚Äôve proposed our own alternative<sup><a href="#fn3" id="fnref3">3</a></sup> for Keyhive that we call ‚ÄúBeeKEM‚Äù. It is closely modelled on TreeKEM with insights from Causal TreeKEM. It requires no central server and only a causal order of operations. It provides logarithmic performance (with linear worst case). And like the other TreeKEM variants, it provides forward secrecy and post-compromise secrecy<sup><a href="#fn4" id="fnref4">4</a></sup>. Furthermore, it relies exclusively on standard crypto, such as <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie Hellman key exchange</a> and <a href="https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf">BLAKE3</a> hashing.</p>
<h2 id="beekem"><a href="#beekem">BeeKEM</a></h2>
<p>In this section, we‚Äôll see how BeeKEM works in more detail.</p>
<p>In BeeKEM (as in TreeKEM), the current group secret is stored encrypted at the root node of a binary tree. We‚Äôll call this the ‚Äúroot secret‚Äù. The root secret is used for encrypting and decrypting document chunks shared with our group over the network<sup><a href="#fn5" id="fnref5">5</a></sup>.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/basic_beekem_tree.png" alt="Basic BeeKEM tree">
</figure>
<p>Each leaf of the tree corresponds to a member of the group and contains its ID and latest Diffie Hellman (DH) public key. A member‚Äôs ID is persistent over time but each member will periodically rotate its DH public key. When a member rotates its DH public key, that will cause the root secret to change as well. Thus, member key rotations help provide post-compromise security. From the point of view of an adversary, they introduce fresh randomness.</p>
<p>Each leaf has an implicit secret known only to the corresponding member (i.e. not stored in the tree). All other ‚Äúinner‚Äù nodes in the tree contain a DH public key for that node and a corresponding secret key that is stored encrypted at the node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_inner_nodes.png" alt="BeeKEM inner nodes">
</figure>
<p>Each node in a binary tree has a single sibling node, as illustrated in the following diagram:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/siblings.png" alt="Node sibling">
</figure>
<p>When encrypting or decrypting a new secret at a parent node, a child node performs a <strong>Diffie Hellman key exchange</strong> with its sibling. That means it will use its sibling DH public key and its own secret key to derive what we‚Äôll call a ‚Äúshared DH secret‚Äù. The shared DH secret is used to encrypt and decrypt the new secret at the parent.</p>
<p>A brief (simplified) aside on how Diffie Hellman key exchange works. Imagine Alice and Bob each have their own DH public keys (alice_pk and bob_pk) and DH secrets (alice_sk and bob_sk). If Alice combines her DH public key with Bob‚Äôs secret key, she can derive a shared DH secret. If Bob combines his DH public key with Alice‚Äôs secret key, he can derive the same shared DH secret. In this way, they can agree on a shared secret just by exchanging their public keys in the open.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/diffie_hellman_basics.png" alt="Diffie Hellman basics">
</figure>
<p>We use this same principle to derive a shared DH secret for any sibling pair in our tree. For example, to decrypt Alice‚Äôs parent node, Alice can use its secret <code>alice_sk</code> and its sibling‚Äôs public key <code>bob_pk</code> to derive a shared DH secret. It can then use that shared secret to decrypt the secret at the parent node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_diffie_hellman_example.png" alt="BeeKEM Diffie Hellman example">
</figure>
<p>In pseudocode, this might look like:</p>
<div>
<pre><code>shared_dh_secret = DH(bob_pk, alice_sk)
parent_secret =
  encrypted_parent_secret.decrypt_with(shared_dh_secret)
</code></pre>
</div>
<p>That parent secret can in turn be used for a Diffie Hellman exchange with the parent‚Äôs sibling‚Äôs DH public key.</p>
<p>For a member to decrypt the root secret, it must start from its leaf and traverse the tree one parent at a time until it reaches the root. The sequence of nodes from leaf to root is called that leaf‚Äôs ‚Äúpath‚Äù. At each node in its path, it will derive a shared DH secret with its sibling to decrypt the secret at its parent. Once it‚Äôs decrypted the root secret, it‚Äôs done.</p>
<p>In the following diagram, the decrypting leaf‚Äôs path is marked in green. The siblings used as Diffie Hellman partners along the way are marked in purple:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_path.png" alt="BeeKEM path">
</figure>
<p>There are three mutating operations that can be performed on the tree: Update Key (i.e. key rotation), Remove Member, and Add Member. Let‚Äôs look at these in more detail.</p>
<h3 id="update-key"><a href="#update-key">Update Key</a></h3>
<p>Every member must periodically update the DH public key at its leaf in order to guarantee post-compromise security. When we update our leaf DH public key, we must then update the secrets for all the nodes on our path, eventually updating the root secret for the entire group.</p>
<p>Before traversing our path, we can derive a sequence of path secrets by applying BLAKE3‚Äôs key derivation function to an initial secret once for each node on the path. As we move up each parent on our path, we will encrypt the next derived secret and store it on that parent.</p>
<p>In order to encrypt the secret for a parent, we use Diffie Hellman key exchange as described above. We then derive a new Diffie Hellman public key from the secret for the parent, and store both that new DH public key and the corresponding encrypted secret at the parent.</p>
<p>In pseudocode:</p>
<div>
<pre><code>parent_secret = derived_secrets[next_idx]
shared_dh_secret = DH(child_sibling_pk, child_sk)
encrypted_parent_secret =
  parent_secret.encrypt_with(shared_dh_secret)
parent_pk = DH_pk_from(parent_secret)
parent_node.insert(parent_pk, encrypted_parent_secret)
</code></pre>
</div>
<p>Later on, when the sibling wants to decrypt that parent secret, it can do Diffie Hellman the other way, using the encrypter node‚Äôs DH public key with the sibling node‚Äôs secret to derive the same shared DH secret that was used to encrypt the parent.</p>
<div>
<pre><code>shared_dh_secret = DH(encrypter_pk, sibling_sk)
encrypted_parent_secret = parent_node.encrypted_secret
parent_secret =
  encrypted_parent_secret.decrypt_with(shared_dh_secret)
</code></pre>
</div>
<h3 id="membership-changes"><a href="#membership-changes">Membership Changes</a></h3>
<p>In order to explain membership changes, we must introduce the concept of ‚Äúblanking‚Äù a node. Blanking a node means that we remove all key and secret information from that node. If the root node is blank, then the tree does not currently hold a shared group key. Some nodes are blanked after membership change operations, and all leaves beyond the last member leaf on the right are blank.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/blank_nodes.png" alt="Blank nodes">
</figure>
<p>If a tree has a blank root, then at least one member must perform an Update Key operation to restore a root secret. An update will replace all blank nodes on its update path with key information.</p>
<p>When we perform a <strong>Remove Member</strong> operation, we first blank the leaf corresponding to that member. We then blank the entire path from that leaf up to the root node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/remove_member.png" alt="Remove member">
</figure>
<p>Notice that if a removed member performs an update concurrently with its removal, we need to ensure that the update does not survive (or else the member will continue to have access to the root secret). When merging concurrent removes with other operations, BeeKEM ensures that the remove paths are blanked after all other concurrent operations are merged.</p>
<p>When we perform an <strong>Add Member</strong> operation, we add the new member‚Äôs ID and public key to the next blank leaf on the right. We then blank the path from that leaf to the root.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/add_member.png" alt="Add member">
</figure>
<p>Notice that if two members add a member concurrently to the same tree, they will add them to the same leaf. BeeKEM resolves such conflicts on merge by sorting all concurrently added leaves and blanking their paths.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/merging_concurrent_adds.png" alt="Resolving add conflicts">
</figure>
<h3 id="handling-blank-nodes-on-update-and-decryption"><a href="#handling-blank-nodes-on-update-and-decryption">Handling Blank Nodes on Update and Decryption</a></h3>
<p>So far, we‚Äôve assumed that every node has a sibling with key information. That‚Äôs what allowed us to use Diffie Hellman to derive a shared DH secret. But what happens when a node‚Äôs sibling is blank?</p>
<p>In that case, we must find the blank node‚Äôs <strong>resolution</strong>. A node‚Äôs resolution is the set of its highest non-blank descendents. Here‚Äôs an example:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/node_resolution_examples.png" alt="Node resolution example">
</figure>
<p>If you have a blank sibling, you must do a separate encryption of the new parent secret for every member of your sibling‚Äôs resolution. For each of those members, you use its Diffie Hellman public key with your secret to derive a shared DH secret. You then encrypt the new parent secret using that shared secret and store it for that member.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/blank_sibling.png" alt="Blank sibling">
</figure>
<p>This means that if the resolution of a sibling node contains 5 members, you will need to store the parent secret 5 times, each one encrypted for a separate member.</p>
<p>The worse case scenario is if the entire inner tree is blank. Encrypting a new path will no longer be a logarithmic operation since every leaf will be contained in the resolution of some blank node on your path. Instead, the cost will be linear in the number of leaves: you will have to perform a separate encryption for every other leaf somewhere on your path.</p>
<p>When decrypting a leaf with blanks on its path, you simply skip those blanks. This works because the highest blank in your path will contain its last non-blank descendent in its resolution. So when you encounter a blank on your path, you hold onto the last secret you‚Äôve seen and start skipping. When you eventually get to a non-blank node, you‚Äôll use that secret you‚Äôre holding onto to derive the shared DH secret you need to decrypt the non-blank parent.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/skipping_blanks.png" alt="Skipping blanks">
</figure>
<h3 id="handling-concurrent-updates-with-conflict-keys"><a href="#handling-concurrent-updates-with-conflict-keys">Handling Concurrent Updates with ‚ÄúConflict Keys‚Äù</a></h3>
<p>Keyhive assumes that concurrent operations can be merged in any causal order. Concurrent updates will always have some overlapping nodes in their paths (at least the root is shared by all paths). How does BeeKEM resolve these conflicts?</p>
<p>We must first consider our potential vulnerabilities. Imagine that an adversary has compromised a group member and their leaf secrets. They can use a compromised leaf secret to decrypt the root secret at some point in time. Recall that knowing a leaf secret means you can decrypt all of the inner node secrets along your path.</p>
<p>If an adversary knows the secret for a leaf, it‚Äôs possible they will continue to be able to decrypt the group secret even if that leaf is rotated during a future concurrent update. This depends on how we handle merging concurrent updates.</p>
<p>If we just naively pick a winner for updates to a series of overlapping nodes, then the new information added by the loser‚Äôs key rotation will no longer be necessary to decrypt the root secret. We effectively forget that information.</p>
<p>Notice that the winner used the outdated keys from the loser for its update (since the winner‚Äôs and loser‚Äôs updates were concurrent). That means an adversary with the loser‚Äôs outdated leaf keys will still be able to decrypt the winner‚Äôs nodes. Subsequent updates by other leaves that only intersect with the winner‚Äôs path will also fail to exclude our adversary.</p>
<p>In BeeKEM, when merging concurrent updates, we ensure that all updates contribute information along their entire paths. We keep conflicting information around at each node until it is overwritten by a causally subsequent operation (or blanked by a membership change).</p>
<p>If two leaves update the same node concurrently, then they would have each written a distinct Diffie Hellman public key and encrypted secret to that node. In this scenario, we call these ‚Äúconflict keys‚Äù and store them both when merging conflicts.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/merging_concurrent_updates.png" alt="Merging conflict keys">
</figure>
<p>Imagine a member subsequently updates the tree. If a node on its leaf‚Äôs path has a sibling with conflict keys, this means there is an unresolved merge at that sibling. An adversary could have access to both sides of the corresponding fork. So it wouldn‚Äôt be secure to use those conflict keys for Diffie Hellman. Instead, we take the resolution of the node, just as we did with blank nodes. We then separately encrypt the secret for every DH public key in the resolution, again just as we did with blank nodes.</p>
<p>This means that for BeeKEM we update the definition of the ‚Äúresolution of a node‚Äù to mean either (1) the single DH public key at that node <strong>if there is exactly one</strong> or (2) the set of highest non-blank, <strong>non-conflict</strong> descendents of that node.</p>
<p>If we merged in both sides of a fork, then we know we‚Äôve updated both corresponding leaves with their latest rotated DH public key. Since taking the resolution skips all conflict nodes, it ensures that we integrate the latest information when encrypting a parent node. That‚Äôs because any non-conflict nodes have successfully integrated all causally prior information from their descendents.</p>
<p>This means an adversary needs to compromise one of the latest leaf secrets to be able to decrypt an entire path to the root. Even knowing outdated leaf secrets at multiple leaves will not be enough to accomplish this. An honest user, on the other hand, will always know the latest secret for its leaf.</p>
<p>During a future update (key rotation), if you find a conflict key node on the path you‚Äôre updating, you can remove all conflict keys at that node and replace them with a single new public key and encrypted secret (as with normal parent encryption). That‚Äôs because your update operation is the causal successor of all the operations that placed those conflict keys. This means your tree contains the necessary information from all of those past updates, which is integrated into your update.</p>
<p>BeeKEM‚Äôs approach comes with two downsides. First, before conflicts are resolved by subsequent updates or blanks, we must store extra information at each conflict node. Second, conflict keys add extra encryption and decryption overhead. In the worst case, where the tree is populated with the maximum number of possible conflict keys, the space cost would be <code>n log(n)</code> (as opposed to the best case of <code>2n</code>). The time cost in the worst case would be linear (as opposed to logarithmic), as when the tree is maximally blanked. Our current set of benchmarks reflect these time costs when we intentionally exercise our worst cases.</p>
<p>BeeKEM provides Keyhive with a Continuous Group Key Agreement protocol that is well-suited to distributed local-first applications that require end-to-end encryption for groups on the order of thousands of members. It exhibits logarithmic performance in the common case with linear worst case. And it provides both forward secrecy and post-compromise security.</p>
<p>In the future, we plan to write a paper explaining this protocol and its security and performance characteristics in more detail. But hopefully this has given you a sense for how it works.</p>
<!-- Footnotes -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>TreeKEM was inspired by earlier work on <a href="https://eprint.iacr.org/2017/666.pdf">Asynchronous Ratcheting Trees (ART)</a>. <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p>Weidner and Kleppmann argue that secure messaging for large groups does not have a plausible threat model since it would be too easy to infiltrate them. But Keyhive is designed for shared documents. In the context of private documents shared within a company with thousands of employees, for example, we would still expect access control. It‚Äôs also worth mentioning that in Keyhive, a single user might have multiple device-specific keys (each of which will count as a member from Keyhive‚Äôs perspective). <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3"><p>Other alternatives include <a href="https://eprint.iacr.org/2022/251">CoCoA</a> and <a href="https://eprint.iacr.org/2022/559.pdf">DeCAF</a>. <a href="#fnref3">‚Ü©Ô∏é</a></p>
</li>
<li id="fn4"><p>BeeKEM in isolation provides forward secrecy, but Keyhive as a whole does not. That‚Äôs because users require access to an entire document and Keyhive is used to encrypt that document in chunks. If you can decrypt a chunk, you will gain access to the key for decrypting the previous chunk (as described in an earlier lab note). <a href="#fnref4">‚Ü©Ô∏é</a></p>
</li>
<li id="fn5"><p>More precisely, we use the root secret as one input into deriving an ‚Äúapplication secret‚Äù. It is the application secret that is directly used for encrypting and decrypting document chunks. There can be multiple application secrets derived from one root secret, but each application secret is used to encrypt exactly one document chunk. Updating the root secret provides post-compromise security by ensuring no prior key can be used to derive application secrets associated with it. We are glossing over these details in this lab note since they strictly speaking happen outside BeeKEM, which is concerned with group agreement on the root secrets. <a href="#fnref5">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/03/">03 ¬∑ What's In a Name?</a></h2>
  <p>2025 Feb 27</p>
<p>The Beehive project is now officially renamed <em>‚ÄúKeyhive‚Äù!</em></p>
<p>Changing names can be a painful process, and doing so as early as possible in a project‚Äôs life is helpful. As <a href="https://www.karlton.org/2017/12/naming-things-hard/">Phil Karlton famously said</a>, there‚Äôs exactly two hard problems in computer science: caching, naming, and off-by-one errors. Naming is important for orienting readers, searching the web, and avoiding ambiguity. We wanted to make sure that the name was finalized prior to open sourcing the code.</p>
<p>There is a naming philosophy that says names should be descriptive, or at least present a direct ‚Äúmental hook‚Äù that implies what the signified thing does. Additional puns and whimsey help with memorability.</p>
<p>The previous project name ‚ÄúBeehive‚Äù was intended to present a sense of safety and collaboration: bees build complex-yet-sturdy structures together while working independently, and guard their hives to make a safe space on the inside. This metaphor was also inspired by earlier conversations with <a href="https://en.wikipedia.org/wiki/Christine_Lemmer-Webber">Christine Lemmer-Webber</a> about metaphors to help explain capability systems (like Keyhive) to folks not familiar with formal concepts from the <a href="https://en.wikipedia.org/wiki/Object-capability_model">object-capabilities</a> world like <a href="https://erights.org/elib/concurrency/vat.html">Vats</a>.</p>

<p>At the time that we decided on ‚ÄúBeehive‚Äù, the team was aware of namespace conflicts in the academic distributed systems literature<sup><a href="#fn1" id="fnref1">1</a></sup>. Over time it‚Äôs become clear that we also have this problem with packages in more than one language ecosystem. Since we don‚Äôt want to tie the project to <a href="https://automerge.org/">Automerge</a> exclusively, prefixing the core project with <code>automerge-*</code> was not appropriate.</p>
<p>We are retaining our apian naming for other parts of the project. <a href="https://www.inkandswitch.com/keyhive/notebook/#beekem">BeeKEM</a> maintains it‚Äôs pun on TreeKEM, and Beelay is the Keyhive-enabled relay.</p>
<p>Beehive is dead. Long live Keyhive!</p>
<!-- Footnotes -->
<!-- Internal Links -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>Some examples include <a href="https://www.cs.cornell.edu/people/egs/615/beehive.pdf">Beehive: Exploiting Power Law Query Distributions for O(1) Lookup Performance in Peer to Peer Overlays</a>, <a href="https://iqua.ece.toronto.edu/papers/junli-tpds17.pdf">Beehive: Erasure Codes for Fixing Multiple
Failures in Distributed Storage Systems</a>, and <a href="https://courses.cs.duke.edu/spring17/compsci590.7/Papers/Beehive16.pdf">Beehive: Simple Distributed Programming in Software-Defined Networks</a>. <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/04/">04 ¬∑ Opening the Pre-Alpha</a></h2>
  <p>2025 Mar 10</p>
<p>We‚Äôre excited to announce that we‚Äôre opening the <em>pre-alpha</em> code for the following libraries:</p>
<ul>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/beelay/beelay-core">beelay-core</a>: Auth-enabled sync over end-to-end encrypted data</li>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/keyhive_core">keyhive_core</a>: The core signing, encryption, and delegation system</li>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/keyhive_wasm">keyhive_wasm</a>: <a href="https://webassembly.org/">Wasm</a> wrapper around <code>keyhive_core</code>, plus TypeScript bindings</li>
</ul>
<p>‚ö†Ô∏è <strong>DO NOT use this release in production applications</strong> ‚ö†Ô∏è</p>
<p>We want to emphasize that this is an early preview release for those that are curious about the project. Expect there to be bugs, inconsistencies, and unstable APIs. This code has also not been through a security audit at time of writing.</p>
<p>If you have any questions, thoughts, or feedback, please contact the team at by filing a <a href="https://github.com/inkandswitch/keyhive/issues/new">GitHub Issue</a>, or in the <a href="https://discord.com/channels/1200006940210757672/1347253710048333884"><code>keyhive-beelay</code> channel in the Automerge Discord</a>.</p>
<!-- External Links -->
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/05/">05 ¬∑ Syncing Keyhive</a></h2>
  <p>2025 Mar 13</p>
<h2>Syncing Keyhive</h2>
<p>The last few lab notes have focused on the cryptographic components which support a local first access control system. Those being a capability based system for managing write access to documents, and a key agreement protocol for encrypting and decrypting writes (thus implementing read control). We now have to think about how to actually transfer this data between devices.</p>
<p>Alongside the Keyhive project we have also been working on a new sync protocol for Automerge. The existing sync protocol works well for a single document but it is common for Automerge applications to have thousands of documents. Furthermore, the sync protocol requires that both ends are able to read the document whilst one of the objectives of Keyhive is for the server to only have access to the encrypted data.</p>
<p>Solving all of these problems in one go is the job of Beelay (the name is inspired by the idea of Beehive being the relay for all the bees (peers) in the Keyhive).</p>
<h2 id="overview"><a href="#overview">Overview</a></h2>
<p>Beelay is an RPC protocol which is designed to be usable over any transport which can provide confidentiality (in practice, HTTPS, WebSockets, or raw TLS). The intended usage is to create a local Beelay instance and then connect it to other peers, Beelay will then authenticate with the other peers and synchronise everything which each side thinks the other has access to.</p>
<p>Each message is authenticated by signing it with the <a href="https://en.wikipedia.org/wiki/EdDSA#Ed25519">Ed25519</a> key that the local node controls. To synchronise we first synchronise the Keyhive membership graph which each end has, this allows each end to determine what documents the other end should have access to. Then we synchronise the collection of documents to figure out which documents are out of sync, before finally synchroising each individual document.</p>
<h2 id="authentication"><a href="#authentication">Authentication</a></h2>

<h3 id="what-are-we-authenticating"><a href="#what-are-we-authenticating">What are we authenticating?</a></h3>
<p>It will be useful here to review how we intend to represent devices, people, and documents in Keyhive. In Keyhive there are two important kinds of principal: ‚Äúgroups‚Äù and ‚Äúindividuals‚Äù. An individual is identified by a single Ed25519 public key - which is immutable - whilst a group is a collection of other principals (groups or individuals) and can be updated by it‚Äôs members. One way we intend to use this is to represent a person (or more specifically their authority) as a group, with each of the persons devices being an individual member of the group. Key rotation can then be handled by adding a new individual to the group and removing the old one.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/person-group.png" alt="A diagram of a group representing a person, with three nodes representing devices called 'phon', 'laptop', and 'table' all of which have arrows pointing to the person node">
</figure>
<p>Groups can contain other groups. This means that we can represent as groups, where each member of the organisation is another group representing a person (or for that matter another organisation, such as a department).</p>
<p>Another useful aspect of this structure is that documents can also be represented as groups. This allows documents to have members which can access the document. For example, a document representing this lab note might add the Ink &amp; Switch group so that all (transitive) members of the Ink &amp; Switch group can read and write to it. Documents can also add other documents which represents ‚Äúfolder‚Äù style relationships. The ‚Äúlab notes‚Äù folder document (which is also a group, because all documents are) might contain all the lab notes and have the Ink &amp; Switch as a member.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/person-doc-group.png" alt="Another diagram, this time with a node labelled 'Ink &amp; Switch' which represents an organisation with the original 'person' diagram being a member of that group">
</figure>
<p>What this all means for the sync protocol is that any given peer is represented by an ‚Äúindividual‚Äù. The task of authentication is to ensure that each end knows what Ed25519 public key the other end is using so that we can relate that individual key to the Keyhive membership graph.</p>
<h3 id="how-do-we-authenticate"><a href="#how-do-we-authenticate">How do we authenticate?</a></h3>
<p>One solution which might seem obvious here is to rely on an authenticated TLS session. While we use TLS for confidentiality, and the browser itself authenticates the server, our application <em>also</em> needs to know about the server‚Äôs public key. Unfortunately, the browser doesn‚Äôt expose this information to the application context; there is no way in the browser to obtain the connection‚Äôs TLS certificate. We don‚Äôt just need to know that a connection is secure, we need to know the public key of the other end in order to use it for access control decisions and so on.</p>
<p>Given that each peer is represented by a public key, the simplest possible authentication scheme would be to sign each message. I.e. a message might look like this:</p>
<div>
<pre><code>type Envelope = {
    message: Uint8Array,
    signature: Signature,
    sender: PublicKey,
}

type PublicKey = Uint8Array
type Signature = Uint8Array
</code></pre>
</div>
<p>To authenticate a message we check that the signature is valid over the message, then we know that the other end is the individual represented by the given public key. There are two problems with this, <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">person in the middle (PITM)</a> attacks, and <a href="https://en.wikipedia.org/wiki/Replay_attack">replay attacks</a>.</p>
<h3 id="person-in-the-middle-attacks"><a href="#person-in-the-middle-attacks">Person in the middle attacks</a></h3>
<p>A good example of PITM attack on this protocol would be a phishing based attack. Imagine an application which allows users to input the URL of a sync server to sync from. Let‚Äôs say an attacker creates a sync server at a familiar looking URL, such as <code>wss://sync.automege.org</code> (note the misspelling) and convinces the user to enter this URL into their application. The attacker can now intercept all messages intended for the real <code>sync.automerge.org</code> server and forward them on to the sync server. This means the attacker can read all the messages and even modify messages sent back to the client.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/pitm.png" alt="A diagram with three nodes connnected in a line, the right most is labelled 'browser', the middle is labelled 'sync.automerge.org (attacker)' and the rightmost is labelled 'sync.automerge.org'">
</figure>
<p>The fundamental problem here is that the message is bound to the sender but not to the receiver. We can solve this by adding an ‚Äúaudience‚Äù field to the message.</p>
<div>
<pre><code>type Envelope = {
    message: Message,
    signature: Signature,
    sender: PublicKey,
}

type Message = {
    payload: Uint8Array,
    audience: PublicKey,
}
</code></pre>
</div>
<p>This doesn‚Äôt quite solve the problem above though. At this stage we only have a URL, we don‚Äôt have a public key for the server. To solve this we allow the audience field to either be a public key, or the URL we are addresssing. In this case the audience would be <code>sync.automege.org</code>. This means that when the PITM forwards the message to <code>sync.automerge.org</code> the real server can check and see that the audience doesn‚Äôt match <code>sync.automerge.org</code> and reject the message.</p>

<p>This works because the connection is being made over TLS, which binds the network transport to the hostname, ensuring that whoever is at the other end, they definitely control <code>sync.automerge.org</code>. Beelay is designed to work over arbitrary transports though, in other network setups such as P2P transports you will need to obtain the public key of the receiver out of band.</p>
<h3 id="replay-attacks"><a href="#replay-attacks">Replay attacks</a></h3>
<p>In a replay attack an attacker is somehow able to intercept messages and store them, and then later replay them to the server. To mitigate this we add a timestamp to the message and then reject messages which are older than some validity window that accounts for latency plus a <a href="https://en.wikipedia.org/wiki/Clock_skew">clock skew</a> grace period ‚Äî e.g. 5 minutes.</p>
<p>The main issue with this scheme is that the clocks of two peers might be out of sync by arbitrary amounts of time. Soft locking the sync system due to clock sync issues is not acceptable. To solve this, when a peer rejects a message due to an old timestamp, the rejecting peer sends their current timestamp along with the rejection message. This allows the sending peer to determine the drift between their local clock and the remote clock and adjust the timestamps on the messages they send, and account for it during this session.</p>
<h3 id="summary"><a href="#summary">Summary</a></h3>
<p>Altogether then, our messages look a bit like this:</p>
<div>
<pre><code>type Envelope = {
    message: Message,
    signature: Signature,
    sender: PublicKey,
}

type Message = {
    payload: Uint8Array,
    audience: PublicKey | string,
    timestamp: number,
}
</code></pre>
</div>
<p>To authenticate a message we check that the signature is valid, that the audience is either our public key or the hash of our hostname (or some other string which is bound to the recipient in some way) and that the timestamp is new enough.</p>
<h2 id="syncing-the-membership-graph"><a href="#syncing-the-membership-graph">Syncing the membership graph</a></h2>
<p>Once we are authenticated, we need to determine what each side thinks the other should have access to. This means that we need to sync the Keyhive ‚Äúmembership graph‚Äù. This is the graph of groups and individuals which represent devices, people, organisations, and documents.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/what-are-we-syncing.png" alt="An image of three large boxes labelled group, document, and document. Each box has arrows pointing to the other and also contains within it a set of smaller boxes pointing to each other labelled op">
</figure>
<p>The membership graph is a directed graph of ‚Äúoperations‚Äù where each operation either creates a new node, delegates access to some other node, or revokes access. Unlike Automerge documents (which are also graphs) the membership operation graph is very shallow and wide, and the linked groups and documents can have cycles. There are many approaches to this problem, but it becomes much simpler if we frame it as <em>set reconciliation</em>, where each side has an unstructured set of operations and needs to figure out what operations the other side has that it needs (i.e. the delta between the two sets). We will encounter a very similar problem later, when we sync the collection of documents. In both cases we use a construction called <a href="https://arxiv.org/html/2402.02668v2">Rateless Invertible Bloom Lookup Tables</a> (RIBLT) to solve this problem.</p>
<h3 id="riblt-set-reconciliation"><a href="#riblt-set-reconciliation">RIBLT set reconciliation</a></h3>
<p>RIBLT is described in detail in <a href="https://arxiv.org/html/2402.02668v2">this paper</a>, what I will describe here are the important properties that the scheme gives us.</p>
<p>RIBLT is a set reconciliation protocol, which means there are two peers who have some possibly overlapping set of things which they want to have the same view of. I.e. after the protocol completes each side should have the union of the things each started with.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/set-reconciliation-1.png" alt="set reconciliation">
</figure>
<p>RIBLT solves this problem by having each side encode it‚Äôs set of things into a set of hashes and then generate a set of special ‚Äúsymbols‚Äù which one side sends to the other.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/riblt-things-to-hashes-to-symbols.png" alt="an image of a set of boxes labeled thing1, thing2, and thing3, with each box pointing to another box labelled hash(thing1), hash(thing2), hash(thing3). A larger box surrounds the entire set of boxese pointing to a sequence of boxes labelled symbol1, symbol2, symbol3">
</figure>
<p>These symbols are structured in such a way that once the receiver has received enough of them they will be able to decode the symbols into the set difference.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/riblt-symbols-decoded.png" alt="an image of three boxes labeled symbol1, symbol2, symbol3 with an arrow - labelled decode - pointing to two bases labeled things we have which they dont and things they have which we dont containg a box labelled hash(thing1) and hash(thing2) respectively">
</figure>
<p>The details are a bit fiddly but the really important part is that the number of symbols which must be sent is proportaional to the set difference between the two peers. Specifically, the number of symbols sent ranges from 1.7x (for small sets) down to 1.35x (for large sets) the set difference.</p>
<p>For example, If we have one billion items each, but only five differing items, we can reconcile in 5 * ~1.5 = 7.5 symbols. The symbols themselves are (in our case) 32 bytes long, so we can reconcile a billion items in 240 bytes.</p>
<p>The other important part is that the result of decoding is the set of hashes - not the things themselves. In fact, we can use any fixed length array which uniquely represents the thing.</p>
<h3 id="syncing-the-membership-graph"><a href="#syncing-the-membership-graph">Syncing the Membership Graph</a></h3>
<p>So, we use RIBLT sync to synchronise the membership graph. The process is mostly driven by the client (in the peer to peer case we arbitrarily choose that the peer who initiated the connection is the client).</p>
<p>First, the client sends a request to the server to begin membership sync. The server stores a pointer to the current set of ops which it thinks the other end needs and then responds with a session ID to identify this sync session, and the first 10 symbols of the RIBLT sync.</p>
<p>The client now receives the first 10 symbols and attempts to decode them. If they are able to decode then they are done and they know the set difference, otherwise, they send a request for the next 10 symbols, using the session ID to specify which state they are syncing with.</p>
<p>Eventually the client knows the set difference in terms of hashes of operations which only the server has, and operations which only the client has. Finally, the client requests the missing operations by sending their hash, and uploads the symbols which they believe the server is missing.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/beginsync-1.png" alt="begin sync">
</figure>
<h2 id="document-collection-sync"><a href="#document-collection-sync">Document Collection Sync</a></h2>
<p>At this point each end has determine what documents it thinks the other should have acces to. The next step is to determine which documents are out of sync. To achieve this we use RIBLT sync again, this time instead of the set we are synchronising being the set of membership operations it is the set of (document ID, state) pairs, where <code>state</code> here is a hash of the document state.</p>
<p>There are two components to the document state which we care about for the purposes of synchronisation. One is the heads of the Automerge document - the document content is encrypted but we keep the hashes of the Automerge commit graph outside of the encryption envelope, so the sync server knows the heads.</p>
<p>The other piece of state are the BeeKEM operations for the document. Recall that BeeKEM is a continuous group key agreement (CGKA) protocol which allows peers to concurrently decide on what keys to encrypt content to. We need to have the latest CGKA ops in order to be able to decrypt the document content.</p>
<p>How do we form our RIBLT symbols then? One way would be to make each symbol <code>hash(document ID, document heads, cgka ops)</code>. Then, once we‚Äôve performed RIBLT sync we make another network call to convert each symbol into the document ID which is out of sync. However, we can do a little better than this. Recall that the RIBLT symbol is just any fixed length byte array, and document IDs are a 32 byte array. This means that instead of a hash for the symbol, we use <code>(document ID, hash(heads, cgka ops)</code>. This means that once we have decoded the symbol we already know what the document ID is for the symbol in question without doing any more round trips.</p>
<p>The process for actually running this sync then is similar to the membership sync. Using the session ID from the membership sync the client fetches new document symbols from the server until it is able to decode the first symbol it received, at which point it knows which symbols are out of sync.</p>
<h2 id="document-sync"><a href="#document-sync">Document Sync</a></h2>
<p>By this point we have a list of document IDs which are out of sync. We now have to sync the CGKA ops and encrypted commit graph for each document. For the CGKA sync we can use our old friend RIBLT sync to sync the set of CGKA ops, but for the document content we need to do something a bit different because we want to be able to take advantage of the bandwidth gains we get from compacting Automerge documents.</p>
<h3 id="cgka-ops"><a href="#cgka-ops">CGKA Ops</a></h3>
<p>The set we are synchronizing here is the set of CGKA ops for the document. We use the hash of each op to create our RIBLT symbols. As with other RIBLT syncs, the client requests symbols from the server until it is able to decode it‚Äôs first symbols at which point it knows what ops to upload and what ops to request.</p>
<h3 id="sedimentree"><a href="#sedimentree">Sedimentree</a></h3>
<p>Syncing the document content is more complicated. Initially it might seem that we could just use RIBLT sync again where the symbols to sync are the commit hashes of the commits in the Automerge commit graph. This would certainly work, however, it would use <em>a lot</em> of bandwidth. Automerge commits are frequently made for each keystroke, adding a 32 byte hash for each keystroke would be very expensive.</p>
<p>This is a specific instance of a general problem which is that naive encodings of the Automerge commit graph contain enormous amounts of metadata overhead. We have a <a href="https://automerge.org/automerge-binary-format-spec/">compact binary encoding</a> which reduces this overhead to around 10% over the underlying data. What we need is a way to use this data in the sync protocol.</p>
<p>In the current sync protocol this is not a problem, the sync server has the plaintext in memory and so it can compact the document on the fly when a new peer comes online. For Beelay this isn‚Äôt an option because the server only has the ciphertext. What to do?</p>
<p>We have come up with a simple protocol for this which we call ‚Äúsedimentree‚Äù. The idea is that every so often we compress ranges of the commit graph into chunks and we do this recursively, so that every so often smaller chunks get compressed into larger chunks. We do this in such a way that older (i.e. closer to the root of the commit graph) end up in larger and larger chunks as time goes on. This forms a tree structure, with older chunks being closer to the root of the tree - hence sedimentree, with chunks being like layers of sedimentree rock.</p>
<p>Choosing the boundaries of the chunks is a little fiddly because we need to do it in such a way that peers with different sets of changes still agree on what should go into each chunk. We do this by using the number of trailing zeros in the hash of a commit as the boundary. There are more details on this <a href="https://github.com/inkandswitch/keyhive/blob/main/design/sedimentree.md">here</a>.</p>
<p>The end result of this structure is that we can sync the document in two steps:</p>
<ul>
<li>Download a ‚Äúsummary‚Äù of the sedimentree, which contains just the boundaries of the chunks.</li>
<li>Download the chunks we don‚Äôt have, and upload the ones the other end doesn‚Äôt have</li>
</ul>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>
<p>Overall then sync looks like this:</p>
<ul>
<li>Sync membership graph
<ul>
<li>Run RIBLT set reconciliation on the membership ops</li>
<li>Download ops we are missing</li>
<li>Upload ops the remote is missing</li>
</ul>
</li>
<li>Sync collection state
<ul>
<li>Run RIBLT set reconciliation on the set of document states</li>
</ul>
</li>
<li>Sync out of sync documents, for each document which is out of date
<ul>
<li>Run RIBLT sync on the CGKA ops</li>
<li>Download CGKA ops we are missing</li>
<li>UPload CGKA ops the remote is missing</li>
<li>Run sedimentree sync on the document content</li>
</ul>
</li>
</ul>
<p>One thing which may be concerning here is the number of round trips. We should especially worry about this in the common case where only one document has changed</p>
<ul>
<li>One round trip for the membership sync</li>
<li>One round trip for collection state</li>
<li>One round trip for CGKA sync</li>
<li>Two round trips for sedimentree sync</li>
</ul>
<p>We should be able to simplify this. One the initial message when we begin membership sync we can send the clients first 5 (say) membership RIBLT symbols and first 5 collection state symbols. In the common case the server will be able to decode these symbols (because only one document has changed) and immediately determine which document has changed, then the server can send back a response with the sedimentree summary for the changed document and the first 5 symbols of the server CGKA RIBLT state. The client will in most cases be able to determine if any CGKA ops are missing and immediately download any missing document state.</p>
<p>Thus in the common case we can sync graph updates (auth, content, etc) in just two round trips.</p>
<!-- External Links -->
</article>

  <article>
    <hr>
    <div>
  <h6>The Ink &amp; Switch Dispatch</h6>
  <p>Keep up-to-date with the lab's latest findings, appearances, and happenings by subscribing to our newsletter. For a sneak peek, <a href="https://www.inkandswitch.com/newsletter">browse the archive</a>.</p>
  

</div>
  </article>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cormac McCarthy's personal library (196 pts)]]></title>
            <link>https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/</link>
            <guid>45444694</guid>
            <pubDate>Wed, 01 Oct 2025 23:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/">https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/</a>, See on <a href="https://news.ycombinator.com/item?id=45444694">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Edge264 ‚Äì Minimalist, high-performance software decoder for H.264/AVC video (126 pts)]]></title>
            <link>https://github.com/tvlabs/edge264</link>
            <guid>45443462</guid>
            <pubDate>Wed, 01 Oct 2025 21:00:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tvlabs/edge264">https://github.com/tvlabs/edge264</a>, See on <a href="https://news.ycombinator.com/item?id=45443462">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">edge264</h2><a id="user-content-edge264" aria-label="Permalink: edge264" href="#edge264"></a></p>
<p dir="auto">Minimalist software decoder with state-of-the-art performance for the H.264/AVC video format.</p>
<p dir="auto"><em>Please note this is a work in progress and will be ready for use after making GStreamer/VLC plugins.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Supports <strong>Progressive High</strong> and <strong>MVC 3D</strong> profiles, up to level 6.2</li>
<li>Any resolution up to 8K UHD</li>
<li>8-bit 4:2:0 planar YUV output</li>
<li>Slices and Arbitrary Slice Order</li>
<li>Slice and frame multi-threading</li>
<li>Per-slice reference picture list</li>
<li>Memory Management Control Operations</li>
<li>Long-term reference frames</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported platforms</h2><a id="user-content-supported-platforms" aria-label="Permalink: Supported platforms" href="#supported-platforms"></a></p>
<ul dir="auto">
<li>Windows: x86, x64</li>
<li>Linux: x86, x64, ARM64</li>
<li>Mac OS: x64</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling and testing</h2><a id="user-content-compiling-and-testing" aria-label="Permalink: Compiling and testing" href="#compiling-and-testing"></a></p>
<p dir="auto">edge264 is entirely developed in C using 128-bit <a href="https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html" rel="nofollow">vector extensions</a> and vector intrinsics, and can be compiled with GNU GCC or LLVM Clang. <a href="https://www.libsdl.org/" rel="nofollow">SDL2</a> runtime library may be used (optional) to enable display with <code>edge264_test</code>.</p>
<p dir="auto">Here are the <code>make</code> options for tuning the compiled library file:</p>
<ul dir="auto">
<li><code>CC</code> - C compiler used to convert source files to object files (default <code>cc</code>)</li>
<li><code>CFLAGS</code> - additional compilation flags passed to <code>CC</code> and <code>TARGETCC</code></li>
<li><code>TARGETCC</code> - C compiler used to link object files into library file (default <code>CC</code>)</li>
<li><code>LDFLAGS</code> - additional compilation flags passed to <code>TARGETCC</code></li>
<li><code>TARGETOS</code> - resulting file naming convention among <code>Windows</code>|<code>Linux</code>|<code>Darwin</code> (default host)</li>
<li><code>VARIANTS</code> - comma-separated list of additional variants included in the library and selected at runtime (default <code>logs</code>)
<ul dir="auto">
<li><code>x86-64-v2</code> - variant compiled for x86-64 microarchitecture level 2 (SSSE3, SSE4.1 and POPCOUNT)</li>
<li><code>x86-64-v3</code> - variant compiled for x86-64 microarchitecture level 3 (AVX2, BMI, LZCNT, MOVBE)</li>
<li><code>logs</code> - variant compiled with logging support in YAML format (headers and slices)</li>
</ul>
</li>
<li><code>BUILD_TEST</code> - toggles compilation of <code>edge264_test</code> (default <code>yes</code>)</li>
<li><code>FORCEINTRIN</code> - enforce the use of intrinsics among <code>x86</code>|<code>ARM64</code> (for WebAssembly)</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="$ make CFLAGS=&quot;-march=x86-64&quot; VARIANTS=x86-64-v2,x86-64-v3 BUILD_TEST=no # example x86 build"><pre>$ make CFLAGS=<span><span>"</span>-march=x86-64<span>"</span></span> VARIANTS=x86-64-v2,x86-64-v3 BUILD_TEST=no <span><span>#</span> example x86 build</span></pre></div>
<p dir="auto">The automated test program <code>edge264_test</code> can browse files in a given directory, decoding each <code>&lt;video&gt;.264</code> file and comparing its output with each sibling file <code>&lt;video&gt;.yuv</code> if found. On the set of AVCv1, FRExt and MVC <a href="https://www.itu.int/wftp3/av-arch/jvt-site/draft_conformance/" rel="nofollow">conformance bitstreams</a>, 109/224 files are decoded without errors, the rest using yet unsupported features.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ make
$ ./edge264_test --help # prints all options available
$ ffmpeg -i vid.mp4 -vcodec copy -bsf h264_mp4toannexb -an vid.264 # optional, converts from MP4 format
$ ./edge264_test -d vid.264 # replace -d with -b to benchmark instead of display"><pre>$ make
$ ./edge264_test --help <span><span>#</span> prints all options available</span>
$ ffmpeg -i vid.mp4 -vcodec copy -bsf h264_mp4toannexb -an vid.264 <span><span>#</span> optional, converts from MP4 format</span>
$ ./edge264_test -d vid.264 <span><span>#</span> replace -d with -b to benchmark instead of display</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example code</h2><a id="user-content-example-code" aria-label="Permalink: Example code" href="#example-code"></a></p>
<p dir="auto">Here is a complete example that opens an input file in Annex B format from command line, and dumps its decoded frames in planar YUV order to standard output. See <a href="https://github.com/tvlabs/edge264/blob/master/edge264_test.c">edge264_test.c</a> for a more complete example which can also display frames.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <fcntl.h>
#include <unistd.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <sys/types.h>

#include &quot;edge264.h&quot;

int main(int argc, char *argv[]) {
	int fd = open(argv[1], O_RDONLY);
	struct stat st;
	fstat(fd, &amp;st);
	uint8_t *buf = mmap(NULL, st.st_size, PROT_READ, MAP_SHARED, fd, 0);
	const uint8_t *nal = buf + 3 + (buf[2] == 0); // skip the [0]001 delimiter
	const uint8_t *end = buf + st.st_size;
	// auto threads, no logs, auto allocs
	Edge264Decoder *dec = edge264_alloc(-1, NULL, NULL, 0, NULL, NULL, NULL);
	Edge264Frame frm;
	int res;
	do {
		res = edge264_decode_NAL(dec, nal, end, 0, NULL, NULL, &amp;nal);
		while (!edge264_get_frame(dec, &amp;frm, 0)) {
			for (int y = 0; y < frm.height_Y; y++)
				write(1, frm.samples[0] + y * frm.stride_Y, frm.width_Y);
			for (int y = 0; y < frm.height_C; y++)
				write(1, frm.samples[1] + y * frm.stride_C, frm.width_C);
			for (int y = 0; y < frm.height_C; y++)
				write(1, frm.samples[2] + y * frm.stride_C, frm.width_C);
		}
	} while (res == 0 || res == ENOBUFS);
	edge264_free(&amp;dec);
	munmap(buf, st.st_size);
	close(fd);
	return 0;
}"><pre><span>#include</span> <span>&lt;fcntl.h&gt;</span>
<span>#include</span> <span>&lt;unistd.h&gt;</span>
<span>#include</span> <span>&lt;sys/mman.h&gt;</span>
<span>#include</span> <span>&lt;sys/stat.h&gt;</span>
<span>#include</span> <span>&lt;sys/types.h&gt;</span>

<span>#include</span> <span>"edge264.h"</span>

<span>int</span> <span>main</span>(<span>int</span> <span>argc</span>, <span>char</span> <span>*</span><span>argv</span>[]) {
	<span>int</span> <span>fd</span> <span>=</span> <span>open</span>(<span>argv</span>[<span>1</span>], <span>O_RDONLY</span>);
	<span>struct</span> <span>stat</span> <span>st</span>;
	<span>fstat</span>(<span>fd</span>, <span>&amp;</span><span>st</span>);
	<span>uint8_t</span> <span>*</span><span>buf</span> <span>=</span> <span>mmap</span>(<span>NULL</span>, <span>st</span>.<span>st_size</span>, <span>PROT_READ</span>, <span>MAP_SHARED</span>, <span>fd</span>, <span>0</span>);
	<span>const</span> <span>uint8_t</span> <span>*</span><span>nal</span> <span>=</span> <span>buf</span> <span>+</span> <span>3</span> <span>+</span> (<span>buf</span>[<span>2</span>] <span>==</span> <span>0</span>); <span>// skip the [0]001 delimiter</span>
	<span>const</span> <span>uint8_t</span> <span>*</span><span>end</span> <span>=</span> <span>buf</span> <span>+</span> <span>st</span>.<span>st_size</span>;
	<span>// auto threads, no logs, auto allocs</span>
	<span>Edge264Decoder</span> <span>*</span><span>dec</span> <span>=</span> <span>edge264_alloc</span>(<span>-1</span>, <span>NULL</span>, <span>NULL</span>, <span>0</span>, <span>NULL</span>, <span>NULL</span>, <span>NULL</span>);
	<span>Edge264Frame</span> <span>frm</span>;
	<span>int</span> <span>res</span>;
	<span>do</span> {
		<span>res</span> <span>=</span> <span>edge264_decode_NAL</span>(<span>dec</span>, <span>nal</span>, <span>end</span>, <span>0</span>, <span>NULL</span>, <span>NULL</span>, <span>&amp;</span><span>nal</span>);
		<span>while</span> (!<span>edge264_get_frame</span>(<span>dec</span>, <span>&amp;</span><span>frm</span>, <span>0</span>)) {
			<span>for</span> (<span>int</span> <span>y</span> <span>=</span> <span>0</span>; <span>y</span> <span>&lt;</span> <span>frm</span>.<span>height_Y</span>; <span>y</span><span>++</span>)
				<span>write</span>(<span>1</span>, <span>frm</span>.<span>samples</span>[<span>0</span>] <span>+</span> <span>y</span> <span>*</span> <span>frm</span>.<span>stride_Y</span>, <span>frm</span>.<span>width_Y</span>);
			<span>for</span> (<span>int</span> <span>y</span> <span>=</span> <span>0</span>; <span>y</span> <span>&lt;</span> <span>frm</span>.<span>height_C</span>; <span>y</span><span>++</span>)
				<span>write</span>(<span>1</span>, <span>frm</span>.<span>samples</span>[<span>1</span>] <span>+</span> <span>y</span> <span>*</span> <span>frm</span>.<span>stride_C</span>, <span>frm</span>.<span>width_C</span>);
			<span>for</span> (<span>int</span> <span>y</span> <span>=</span> <span>0</span>; <span>y</span> <span>&lt;</span> <span>frm</span>.<span>height_C</span>; <span>y</span><span>++</span>)
				<span>write</span>(<span>1</span>, <span>frm</span>.<span>samples</span>[<span>2</span>] <span>+</span> <span>y</span> <span>*</span> <span>frm</span>.<span>stride_C</span>, <span>frm</span>.<span>width_C</span>);
		}
	} <span>while</span> (<span>res</span> <span>==</span> <span>0</span> <span>||</span> <span>res</span> <span>==</span> <span>ENOBUFS</span>);
	<span>edge264_free</span>(<span>&amp;</span><span>dec</span>);
	<span>munmap</span>(<span>buf</span>, <span>st</span>.<span>st_size</span>);
	<span>close</span>(<span>fd</span>);
	<span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">API reference</h2><a id="user-content-api-reference" aria-label="Permalink: API reference" href="#api-reference"></a></p>
<p dir="auto"><code>const uint8_t * <b>edge264_find_start_code(buf, end, four_byte)</b></code></p>
<p dir="auto">Return a pointer to the next three or four byte (0)001 start code prefix, or <code>end</code> if not found.</p>
<ul dir="auto">
<li><code>const uint8_t * buf</code> - first byte of buffer to search into</li>
<li><code>const uint8_t * end</code> - first invalid byte past the buffer that stops the search</li>
<li><code>int four_byte</code> - if 0 seek a 001 prefix, otherwise seek a 0001</li>
</ul>
<hr>
<p dir="auto"><code>Edge264Decoder * <b>edge264_alloc(n_threads, log_cb, log_arg, log_mbs, alloc_cb, free_cb, alloc_arg)</b></code></p>
<p dir="auto">Allocate and initialize a decoding context.</p>
<ul dir="auto">
<li><code>int n_threads</code> - number of background worker threads, with 0 to disable multithreading and -1 to detect the number of logical cores at runtime</li>
<li><code>void (* log_cb)(const char * str, void * log_arg)</code> - if not NULL, a <code>fputs</code>-compatible function pointer that <code>edge264_decode_NAL</code> will call to log every header, SEI or macroblock (requires the <code>logs</code> variant otherwise fails at runtime, called from the same thread except macroblocks in multithreaded decoding)</li>
<li><code>void * log_arg</code> - custom value passed to <code>log_cb</code></li>
<li><code>int log_mbs</code> - set to 1 to enable logging of macroblocks</li>
<li><code>void (* alloc_cb)(void ** samples, unsigned samples_size, void ** mbs, unsigned mbs_size, int errno_on_fail, void * alloc_arg)</code> - if not NULL, a function pointer that <code>edge264_decode_NAL</code> will call (on the same thread) instead of malloc to request allocation of samples and macroblock buffers for a frame (<code>errno_on_fail</code> is ENOMEM for mandatory allocations, or ENOBUFS for allocations that may be skipped to save memory but reduce playback smoothness)</li>
<li><code>void (* free_cb)(void * samples, void * mbs, void * alloc_arg)</code> - if not NULL, a function pointer that <code>edge264_decode_NAL</code> and <code>edge264_free</code> will call (on the same thread) to free buffers allocated through <code>alloc_cb</code></li>
<li><code>void * alloc_arg</code> - custom value passed to <code>alloc_cb</code> and <code>free_cb</code></li>
</ul>
<hr>
<p dir="auto"><code>int <b>edge264_decode_NAL(dec, buf, end, non_blocking, free_cb, free_arg, next_NAL)</b></code></p>
<p dir="auto">Decode a single NAL unit containing any parameter set or slice.</p>
<ul dir="auto">
<li><code>Edge264Decoder * dec</code> - initialized decoding context</li>
<li><code>const uint8_t * buf</code> - first byte of NAL unit (containing <code>nal_unit_type</code>)</li>
<li><code>const uint8_t * end</code> - first byte past the buffer (max buffer size is 2<sup>31</sup>-1 on 32-bit and 2<sup>63</sup>-1 on 64-bit)</li>
<li><code>int non_blocking</code> - set to 1 if the current thread has other processing thus cannot block here</li>
<li><code>void (* free_cb)(void * free_arg, int ret)</code> - callback that may be called from another thread when multithreaded, to signal the end of parsing and release the NAL buffer</li>
<li><code>void * free_arg</code> - custom value that will be passed to <code>free_cb</code></li>
<li><code>const uint8_t ** next_NAL</code> - if not NULL and the return code is <code>0</code>|<code>ENOTSUP</code>|<code>EBADMSG</code>, will receive a pointer to the next NAL unit after the next start code in an Annex B stream</li>
</ul>
<p dir="auto">Return codes are:</p>
<ul dir="auto">
<li><code>0</code> on success</li>
<li><code>ENOTSUP</code> on unsupported stream (decoding may proceed but could return zero frames)</li>
<li><code>EBADMSG</code> on invalid stream (decoding may proceed but could show visual artefacts, if you can check with another decoder that the stream is actually flawless, please consider filling a bug report üôè)</li>
<li><code>EINVAL</code> if the function was called with <code>dec == NULL</code> or <code>dec-&gt;buf == NULL</code></li>
<li><code>ENODATA</code> if the function was called while <code>dec-&gt;buf &gt;= dec-&gt;end</code></li>
<li><code>ENOMEM</code> if <code>malloc</code> failed to allocate memory</li>
<li><code>ENOBUFS</code> if more frames should be consumed with <code>edge264_get_frame</code> to release a picture slot</li>
<li><code>EWOULDBLOCK</code> if the non-blocking function would have to wait before a picture slot is available</li>
</ul>
<hr>
<p dir="auto"><code>int <b>edge264_get_frame(dec, out, borrow)</b></code></p>
<p dir="auto">Fetch the next frame ready for output.</p>
<ul dir="auto">
<li><code>Edge264Decoder * dec</code> - initialized decoding context</li>
<li><code>Edge264Frame *out</code> - a structure that will be filled with data for the frame returned</li>
<li><code>int borrow</code> - if 0 the frame may be accessed until the next call to <code>edge264_decode_NAL</code>, otherwise the frame should be explicitly returned with <code>edge264_return_frame</code>. Note that access is not exclusive, it may be used concurrently as reference for other frames.</li>
</ul>
<p dir="auto">Return codes are:</p>
<ul dir="auto">
<li><code>0</code> on success (one frame is returned)</li>
<li><code>EINVAL</code> if the function was called with <code>dec == NULL</code> or <code>out == NULL</code></li>
<li><code>ENOMSG</code> if there is no frame to output at the moment</li>
</ul>
<p dir="auto">While reference frames may be decoded ahead of their actual display (ex. B-Pyramid technique), all frames are buffered for reordering before being released for display:</p>
<ul dir="auto">
<li>Decoding a non-reference frame releases it and all frames set to be displayed before it.</li>
<li>Decoding a key frame releases all stored frames (but not the key frame itself which might be reordered later).</li>
<li>Exceeding the maximum number of frames held for reordering releases the next frame in display order.</li>
<li>Lacking an available frame buffer releases the next non-reference frame in display order (to salvage its buffer) and all reference frames displayed before it.</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="typedef struct Edge264Frame {
	const uint8_t *samples[3]; // Y/Cb/Cr planes
	const uint8_t *samples_mvc[3]; // second view
	const uint8_t *mb_errors; // probabilities (0..100) for each macroblock to be erroneous, NULL if there are no errors, values are spaced by stride_mb in memory
	int8_t pixel_depth_Y; // 0 for 8-bit, 1 for 16-bit
	int8_t pixel_depth_C;
	int16_t width_Y;
	int16_t width_C;
	int16_t height_Y;
	int16_t height_C;
	int16_t stride_Y;
	int16_t stride_C;
	int16_t stride_mb;
	uint32_t FrameId;
	uint32_t FrameId_mvc; // second view
	int16_t frame_crop_offsets[4]; // {top,right,bottom,left}, useful to derive the original frame with 16x16 macroblocks
	void *return_arg;
} Edge264Frame;"><pre><span>typedef</span> <span>struct</span> <span>Edge264Frame</span> {
	<span>const</span> <span>uint8_t</span> <span>*</span><span>samples</span>[<span>3</span>]; <span>// Y/Cb/Cr planes</span>
	<span>const</span> <span>uint8_t</span> <span>*</span><span>samples_mvc</span>[<span>3</span>]; <span>// second view</span>
	<span>const</span> <span>uint8_t</span> <span>*</span><span>mb_errors</span>; <span>// probabilities (0..100) for each macroblock to be erroneous, NULL if there are no errors, values are spaced by stride_mb in memory</span>
	<span>int8_t</span> <span>pixel_depth_Y</span>; <span>// 0 for 8-bit, 1 for 16-bit</span>
	<span>int8_t</span> <span>pixel_depth_C</span>;
	<span>int16_t</span> <span>width_Y</span>;
	<span>int16_t</span> <span>width_C</span>;
	<span>int16_t</span> <span>height_Y</span>;
	<span>int16_t</span> <span>height_C</span>;
	<span>int16_t</span> <span>stride_Y</span>;
	<span>int16_t</span> <span>stride_C</span>;
	<span>int16_t</span> <span>stride_mb</span>;
	<span>uint32_t</span> <span>FrameId</span>;
	<span>uint32_t</span> <span>FrameId_mvc</span>; <span>// second view</span>
	<span>int16_t</span> <span>frame_crop_offsets</span>[<span>4</span>]; <span>// {top,right,bottom,left}, useful to derive the original frame with 16x16 macroblocks</span>
	<span>void</span> <span>*</span><span>return_arg</span>;
} <span>Edge264Frame</span>;</pre></div>
<hr>
<p dir="auto"><code>void <b>edge264_return_frame(dec, return_arg)</b></code></p>
<p dir="auto">Give back ownership of the frame if it was borrowed from a previous call to <code>edge264_get_frame</code>.</p>
<ul dir="auto">
<li><code>Edge264Decoder * dec</code> - initialized decoding context</li>
<li><code>void * return_arg</code> - the value stored inside the frame to return</li>
</ul>
<hr>
<p dir="auto"><code>void <b>edge264_flush(dec)</b></code></p>
<p dir="auto">For use when seeking, stop all background processing, flush all delayed frames while keeping them allocated, and clear the internal decoder state.</p>
<ul dir="auto">
<li><code>Edge264Decoder * dec</code> - initialized decoding context</li>
</ul>
<hr>
<p dir="auto"><code>void <b>edge264_free(pdec)</b></code></p>
<p dir="auto">Deallocate the entire decoding context, and unset the pointer.</p>
<ul dir="auto">
<li><code>Edge264Decoder ** pdec</code> - pointer to a decoding context, initialized or not</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul dir="auto">
<li>Stress testing (in progress)</li>
<li>Multithreading (in progress)</li>
<li>Error recovery (in progress)</li>
<li>Integration in VLC/ffmpeg/GStreamer</li>
<li>ARM32</li>
<li>PAFF and MBAFF</li>
<li>4:0:0, 4:2:2 and 4:4:4</li>
<li>9-14 bit depths with possibility of different luma/chroma depths</li>
<li>Transform-bypass for macroblocks with QP==0</li>
<li>SEI messages</li>
<li>AVX-2 optimizations</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Programming techniques</h2><a id="user-content-programming-techniques" aria-label="Permalink: Programming techniques" href="#programming-techniques"></a></p>
<p dir="auto">I use edge264 to experiment on new programming techniques to improve performance and code size over existing decoders, and presented a few of these techniques at <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2931-innovations-in-h-264-avc-software-decoding-architecture-and-optimization-of-a-block-based-video-decoder-to-reach-10-faster-speed-and-3x-code-reduction-over-the-state-of-the-art-/" rel="nofollow">FOSDEM'24</a> and <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-5455-more-innovations-in-h-264-avc-software-decoding/" rel="nofollow">FOSDEM'25</a>.</p>
<ol dir="auto">
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">Single header file</a> - It contains all struct definitions, common constants and enums, SIMD aliases, inline functions and macros, and exported functions for each source file. To understand the code base you should look at this file first.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_slice.c">Code blocks instead of functions</a> - The main decoding loop is a forward pipeline designed as a DAG loosely resembling hardware decoders, with nodes being non-inlined functions and edges being tail calls. It helps mutualize code branches wherever possible, thus reduces code size to help fit in L1 cache.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_intra.c">Tree branching</a> - Directional intra modes are implemented with a jump table to the leaves of a tree then unconditional jumps down to the trunk. It allows sharing the bottom code among directional modes, to reduce code size.</li>
<li><del>Global context register - The pointer to the main structure holding context data is assigned to a register when supported by the compiler (GCC).</del> This technique was dropped as Clang eventually reached on-par performance, so there is little incentive to maintain this hack.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">Default neighboring values</a> (search <code>unavail_mb</code>) - Tests for availability of neighbors are replaced with fake neighboring macroblocks around each frame. It reduces the number of conditional tests inside the main decoding loop, thus reduces code size and branch predictor pressure.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">Relative neighboring offsets</a> (look for <code>A4x4_int8</code> and related variables) - Access to left/top macroblock values is done with direct offsets in memory instead of copying their values to a buffer beforehand. It helps to reduce the reads and writes in the main decoding loop.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_slice.c">Parsing uneven block shapes</a> (look at function <code>parse_P_sub_mb</code>) - Each Inter macroblock paving specified with mb_type and sub_mb_type is first converted to a bitmask, then iterated on set bits to fetch the correct number of reference indices and motion vectors. This helps to reduce code size and number of conditional blocks.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">Using vector extensions</a> - GCC's vector extensions are used along vector intrinsics to write more compact code. All intrinsics from Intel are aliased with shorter names, which also provides an enumeration of all SIMD instructions used in the decoder.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_deblock.c">Register-saturating SIMD</a> - Some critical SIMD algorithms use more simultaneous vectors than available registers, effectively saturating the register bank and generating stack spills on purpose. In some cases this is more efficient than splitting the algorithm into smaller bits, and has the additional benefit of scaling well with later CPUs.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_bitstream.c">Piston cached bitstream reader</a> - The bitstream bits are read in a size_t[2] intermediate cache with a trailing set bit to keep track of the number of cached bits, giving access to 32/64 bits per read from the cache, and allowing wide refills from memory.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_bitstream.c">On-the-fly SIMD unescaping</a> - The input bitstream is unescaped on the fly using vector code, avoiding a full preprocessing pass to remove escape sequences, and thus reducing memory reads/writes.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">Multiarch SIMD programming</a> - Using vector extensions along with aliased intrinsics allows supporting both Intel SSE and ARM NEON with around 80% common code and few #if #else blocks, while keeping state-of-the-art performance for both architectures.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">The Structure of Arrays pattern</a> - The frame buffer is stored with arrays for each distinct field rather than an array of structures, to express operations on frames with bitwise and vector operators (see <a href="https://en.wikipedia.org/wiki/AoS_and_SoA" rel="nofollow">AoS and SoA</a>). The task buffer for multithreading also relies on it partially.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_headers.c">Deferred error checking</a> - Error detection is performed once in each type of NAL unit (search for <code>return</code> statements), by clamping all input values to their expected ranges, then expecting <code>rbsp_trailing_bit</code> afterwards (with <em>very high</em> probability of catching an error if the stream is corrupted). This design choice is discussed in <a href="https://traffaillac.github.io/parsing.html" rel="nofollow">A case about parsing errors</a>.</li>
</ol>
<p dir="auto">Other yet-to-be-presented bits:</p>
<ul dir="auto">
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264.h">Minimalistic API</a> with FFI-friendly design (7 functions and 1 structure).</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_internal.h">The bitstream caches</a> for CAVLC and CABAC (search for <code>rbsp_reg</code>) are stored in two size_t variables each, which may be mapped to Global Register Variables in the future.</li>
<li><a href="https://github.com/tvlabs/edge264/blob/master/edge264_slice.c">The decoding of input symbols</a> is interspersed with their parsing (instead of parsing to a <code>struct</code> then decoding the data). It deduplicates branches and loops that are present in both parsing and decoding, and even eliminates the need to store some symbols (e.g. mb_type, sub_mb_type, mb_qp_delta).</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing (work in progress)</h2><a id="user-content-testing-work-in-progress" aria-label="Permalink: Testing (work in progress)" href="#testing-work-in-progress"></a></p>
<p dir="auto">With the help of a <a href="https://github.com/tvlabs/edge264/blob/master/tools/gen_avc.py">custom bitstream writer</a> using the same YAML format edge264 outputs, a set of extensive tests are being created in <a href="https://github.com/tvlabs/edge264/blob/master/tools/raw_tests">tools/raw_tests</a> to stress the darkest corners of this decoder. The following table lists them all, along with the files implementing them.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>General tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>All supported types of NAL units</td>
<td>All OK</td>
<td>supp-nals</td>
</tr>
<tr>
<td>All unsupported types of NAL units</td>
<td>All unsupp</td>
<td>unsupp-nals</td>
</tr>
<tr>
<td>Maximal header log-wise</td>
<td>All OK</td>
<td>max-logs</td>
</tr>
<tr>
<td>All conditions (incl. ignored) for detecting the start of a new frame</td>
<td>All OK</td>
<td>finish-frame</td>
</tr>
<tr>
<td>nal_ref_idc=0 on a IDR</td>
<td>All OK</td>
<td>non-ref-idr</td>
</tr>
<tr>
<td>Missing rbsp_trailing_bit for all supported NAL types</td>
<td>All OK</td>
<td>no-trailing-bit</td>
</tr>
<tr>
<td>NAL of less than 11 bytes starting/ending at page boundary</td>
<td>All OK</td>
<td>tiny-nal</td>
</tr>
<tr>
<td>SEI/slice referencing an uninitialized SPS/PPS</td>
<td>1 OK, 4 errors</td>
<td>missing-ps</td>
</tr>
<tr>
<td>Two non-ref frames with decreasing POC</td>
<td>All OK, any order</td>
<td>non-ref-dec-poc</td>
</tr>
<tr>
<td>Horizontal/vertical cropping leaving zero space</td>
<td>All OK, 1x1 frames</td>
<td>zero-cropping</td>
</tr>
<tr>
<td>P/B slice with nal_unit_type=5 or max_num_ref_frames=0</td>
<td>4 OK, 2 errors</td>
<td>no-refs-P-B-slice</td>
</tr>
<tr>
<td>IDR slice with frame_num&gt;0</td>
<td>All OK, clamped to 0</td>
<td>pos-frame-num-idr</td>
</tr>
<tr>
<td>A ref that must bump out higher POCs to enter DPB (C.4.5.2)</td>
<td>All OK, check output order</td>
<td>poc-out-of-order</td>
</tr>
<tr>
<td>Two ref frames with the same frame_num but differing POC, then a third frame referencing both</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Gap in frame_num while gaps_in_frame_num_value_allowed_flag=0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Stream starting with non-IDR I frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Stream starting with P/B frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ref slice with delta_pic_order_cnt_bottom=-2**31, then a second frame referencing it</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Two frames A/B with intersecting top/bottom POC intervals in all possible intersections</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A 32-bit POC overflow between 2 frames</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A B-frame referencing frames with more than 2**16 POC diff</td>
<td></td>
<td></td>
</tr>
<tr>
<td>num_ref_idx_active&gt;15 in SPS then no override in slice for L0 and L1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A slice with more ref_pic_list_modifications than num_ref_idx_active/16 for L0 and L1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A slice with ref_pic_list_modifications duplicating a ref then referencing the second one</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A slice with insufficient ref frames with and without override of num_ref_idx_active for L0 and L1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A modification of RefPicList[0/1] to a non-existing short/long term frame, then referencing it in mb</td>
<td></td>
<td></td>
</tr>
<tr>
<td>33 IDR with long_term_reference_flag=0/1 while max_num_ref_frames=0 (8.2.5.1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A new reference while max_num_ref_frames are already all long-term</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All combinations of mmco on all non-existing/short/long refs, with at least twice each mmco</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Two fields of the same frame being assigned different long-term frame indices then referenced</td>
<td></td>
<td></td>
</tr>
<tr>
<td>While all max_num_ref_frames are long-term, a ref_pic_list_modification that references all of them</td>
<td></td>
<td></td>
</tr>
<tr>
<td>An IDR picture with POC&gt;0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A picture with mmco=5 decoded after a picture with greater POC (8.2.1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A P/B frame with zero references before or received with a gap in frame_num equal to max_ref_frames</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A P/B frame referencing a non-existing/erroneous ref</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A B frame with colPic set to a non-existing frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A current frame mmco'ed to long-term while all max_num_ref_frames are already long-term</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A mmco marking a non-existing picture to long-term</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All combinations of IntraNxNPredMode with A/B/C/D unavailability with asserts for out-of-bounds reads</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A direct Inter reference from colPic that is not present in RefPicList0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A residual block with all coeffs at maximum 32-bit values</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Two slices of the same frame separated by a currPic reset (ex. AUD)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Two frames with the same POC yet differing TopFieldOrderCnt/BottomFieldOrderCnt</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Differing mmcos on two slices of the same frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sending 2 IDR, then reaching the lowest possible POC, then getting all frames</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Two slices with mmco=5 yet frame_num&gt;0 (to make it look like a new frame)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>POCs spaced by more than half max bits, such that relying on a stale prevPicOrderCnt yields wrong POC</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Filling the DPB with 16 refs then setting max_num_ref_frames=1 and adding a new ref frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Adding a frame cropping after decoding a frame</td>
<td>Crop should not apply retroactively</td>
<td></td>
</tr>
<tr>
<td>Making a Direct ref_pic be used after it has been unreferenced</td>
<td></td>
<td></td>
</tr>
<tr>
<td>poc_type=2 and non-ref frame followed by non-ref pic, and the opposite (7.4.2.1.1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>direct_8x8_inference_flag=1 with frame_mbs_only_flag=0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>checking that a gap in frame_num with poc_type==0 does not insert refs in B slices</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A SPS changing frame format while currPic&gt;=0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A frame allocator putting all allocs at start/end of a page boundary</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter sets tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>Invalid profile_idc=0/255</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Highest level_idc=255</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All unsupported values of chroma_format_idc</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All unsupported values of bit_depth_luma/chroma</td>
<td></td>
<td></td>
</tr>
<tr>
<td>qpprime_y_zero_transform_bypass_flag=1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All scaling lists default/fallback rules and repeated values for all indices, with residual macroblock</td>
<td></td>
<td></td>
</tr>
<tr>
<td>log2_max_frame_num=4 and a frame referencing another with the same frame_num%4</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>CAVLC tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>All valid total_zeros=0-8-prefix+3-bit-suffix for TotalCoeffs in [0;15] for 4x4 and 2x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Invalid total_zeros=31/63/127-prefix for TotalCoeffs in [0;15] for 4x4 and 2x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All valid coeff_token=0-14-prefix+4-bit-suffix for nC=0/2/4, and valid 6-bit-values for nC=8</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Invalid coeff_token=31/63/127-prefix for nC=0/2/4, and invalid 6-bit-values for nC=8</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All valid levelCode=25-prefix+suffixLength-bit-suffix for all values of suffixLength</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All valid run_before for all values of zerosLeft&lt;=7</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Invalid run_before=31/63/127 for zerosLeft=7</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Macroblock of maximal size for all values of mb_type</td>
<td></td>
<td></td>
</tr>
<tr>
<td>mb_qp_delta=-26/25 that overflows on both sides</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All valid inferences of nC for all values of nA/nB=unavail/other-slice/0-16</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All coded_block_pattern=[0;47] for I and P/B slices</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All combinations of intra_chroma_pred_mode and Intra4x4/8x8/16x16PredMode with A/B-unavailability</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All values of mb_type+sub_mb_types for I/P/B with ref_idx/mvds different than values from B_Direct</td>
<td></td>
<td></td>
</tr>
<tr>
<td>mvd=[-32768/0/32767,-32768/0/32767] in a single 16x16 macroblock</td>
<td></td>
<td></td>
</tr>
<tr>
<td>TotalCoeff=16 for a Intra16x16 AC block</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A residual block with run_length=14 making zerosLeft negative</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>CABAC tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mixing CAVLC and CABAC in a same frame</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Single slice with at least 8 cabac_zero_word</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>MVC tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>All wrong combinations of non_idr_flag with nal_unit_type=1/5 and nal_ref_idc=0/1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>nal_unit_type=14 then filler unit then nal_unit_type=1/5</td>
<td></td>
<td></td>
</tr>
<tr>
<td>An nal_unit_type=5 view paired with a non_idr_flag=0 P view, or a non_idr_flag=1 view</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Missing a base or non-base view</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Receiving a SSPS yet only base views then</td>
<td></td>
<td></td>
</tr>
<tr>
<td>16 ref base views while non base are non-refs</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A SSPS with different pic_width_in_mbs/pic_height_in_mbs/chroma_format_idc than its SPS</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A SSPS with num_views=1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A non-base view with weighted_bipred_idc=2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A non-base view with its base in RefPicList1[0] and direct_spatial_mv_pred_flag=0 (H.7.4.3)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A slice with num_ref_idx_l0_active&gt;8</td>
<td></td>
<td></td>
</tr>
<tr>
<td>svc_extension_flag=1 on a MVC stream</td>
<td></td>
<td></td>
</tr>
<tr>
<td>SSPS with additional_extension2_flag=1 and more trailing data</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Gap in frame_num of 16 frames on both views</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Specifying extra_frames=1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Receiving a non-base view before its base</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A stream sending non-base views after a few frames have been output</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Error recovery tests</th>
<th>Expected</th>
<th>Test files</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tests to implement</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A complete frame received twice</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A slice of a frame received twice</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Frame with correct and erroneous slice</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All combinations erroneous/correct and all interval intersections on 2 slices</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All failures of malloc</td>
<td></td>
<td></td>
</tr>
<tr>
<td>All (dis-)allowed bit positions at the end without rbsp_trailing_bit</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DARPA project for automated translation from C to Rust (2024) (123 pts)]]></title>
            <link>https://www.darpa.mil/news/2024/memory-safety-vulnerabilities</link>
            <guid>45443368</guid>
            <pubDate>Wed, 01 Oct 2025 20:53:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.darpa.mil/news/2024/memory-safety-vulnerabilities">https://www.darpa.mil/news/2024/memory-safety-vulnerabilities</a>, See on <a href="https://news.ycombinator.com/item?id=45443368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Memory safety vulnerabilities are the most prevalent type of disclosed software vulnerability<sup>1</sup> and affect a computer's memory in two primary ways. First, programming languages like C allow programmers to manipulate memory directly, making it easy to accidentally introduce errors in their program that would enable a seemingly routine operation to corrupt the state of memory. Second, memory safety issues can arise when a programming language exhibits an ‚Äúundefined behavior.‚Äù Undefined behaviors happen when the programming language standard provides no specification or guidance on how the program should behave under conditions not explicitly defined in the standard.</p><p>After more than two decades of grappling with memory safety issues in C and C++, the software engineering community has reached a consensus. Relying on bug-finding tools is not enough. Even the Office of the National Cyber Director has called for more proactive approaches to eliminate memory safety vulnerabilities to reduce potential attacks<sup>2</sup>.</p><p>While it's been no secret that memory safe programming languages can eliminate memory safety vulnerabilities, the challenge has been rewriting legacy code at scale that matches the vastness of the problem. The C language was created in the 1970s and has become ubiquitous. It has been used to develop applications that run everything from modern smartphones to space vehicles and beyond. And the Department of Defense has long-lived systems that disproportionately depend on programming languages like C.</p><p>However, in recent years, a cultural shift toward the programming language Rust and recent breakthroughs in machine learning techniques, like large language models (LLMs), have created an environment that may lend itself to a new class of solutions.</p><p>DARPA‚Äôs Translating All C to Rust (TRACTOR) program wants to seize this opportunity by substantially automating the translation of the world‚Äôs legacy C code to Rust.</p><p>‚ÄúYou can go to any of the LLM websites, start chatting with one of the AI chatbots, and all you need to say is ‚Äòhere's some C code, please translate it to safe idiomatic Rust code,‚Äô cut, paste, and something comes out, and it's often very good, but not always,‚Äù said Dr. Dan Wallach, DARPA program manager for TRACTOR. ‚ÄúThe research challenge is to dramatically improve the automated translation from C to Rust, particularly for program constructs with the most relevance."</p><p>TRACTOR will strive to create the same quality and style that a skilled Rust developer would produce, thereby eliminating the entire class of memory safety security vulnerabilities in C programs.</p><p>Wallach anticipates proposals that include novel combinations of software analysis, such as static and dynamic analysis, and large language models. The program will host public competitions throughout the effort to test the capabilities of the LLM-powered solutions.</p><p>"Rust forces the programmer to get things right,‚Äù said Wallach. ‚ÄúIt can feel constraining to deal with all the rules it forces, but when you acclimate to them, the rules give you freedom. They're like guardrails; once you realize they're there to protect you, you'll become free to focus on more important things."</p><p>DARPA will sponsor a Proposers Day on Aug. 26, 2024, which attendees can attend in person or virtually. Participants must register by Aug. 19, 2024. Details and registration info are available at <a href="https://sam.gov/opp/1e45d648886b4e9ca91890285af77eb7/view" target="_blank">SAM.Gov</a>.</p><p>[1]<a href="https://www.cisa.gov/sites/default/files/2023-12/The-Case-for-Memory-Safe-Roadmaps-508c.pdf" target="_blank">https://www.cisa.gov/sites/default/files/2023-12/The-Case-for-Memory-Safe-Roadmaps-508c.pdf</a></p><p>[2]<a href="https://www.whitehouse.gov/oncd/briefing-room/2024/02/26/memory-safety-fact-sheet/" target="_blank">https://www.whitehouse.gov/oncd/briefing-room/2024/02/26/memory-safety-fact-sheet/</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft declares bring your Copilot to work day, usurping IT authority (133 pts)]]></title>
            <link>https://www.theregister.com/2025/10/01/microsoft_consumer_copilot_corporate/</link>
            <guid>45443304</guid>
            <pubDate>Wed, 01 Oct 2025 20:48:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/01/microsoft_consumer_copilot_corporate/">https://www.theregister.com/2025/10/01/microsoft_consumer_copilot_corporate/</a>, See on <a href="https://news.ycombinator.com/item?id=45443304">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Your job may not support BYOD, but how about BYOC? Microsoft has declared that people can bring their personal Microsoft 365 subscriptions to work to access various Copilot features at companies that fail to provide an AI fix.</p>
<p>Redmond has done so unilaterally, effectively endorsing "shadow IT" ‚Äì the practice of bringing unapproved software and devices into the workplace.</p>
<p>Earlier this year, Microsoft said it had adopted a new approach to shadow IT. "While earlier eras of our IT history focused on trying to prevent shadow IT, we are now concentrating on managing it," the biz said in a <a href="https://www.microsoft.com/insidetrack/blog/digitally-transforming-microsoft-our-it-journey/">blog post</a>. By "managing," Microsoft also means "enabling."</p>

    

<p>Samer Baroudi, senior product marketing manager at Microsoft, insists this is for your own good.</p>

        


        

<p>"This offers a safer alternative to other bring-your-own-AI scenarios, and empowers users with Copilot in their daily jobs while keeping IT firmly in control and all enterprise data protections intact," Baroudi explained in a <a href="https://techcommunity.microsoft.com/blog/microsoft365copilotblog/employees-can-bring-copilot-from-their-personal-microsoft-365-plans-to-work---wh/4458212">blog post</a>.</p>
<p>Makers of competing AI products might disagree.</p>

        

<p>Microsoft says that employees can sign into Microsoft 365 apps using both personal and work accounts and now can use Copilot features from their personal plan (Personal, Family, or Premium) for business documents ‚Äì even if their work account lacks a Copilot license.</p>
<ul>

<li><a href="https://www.theregister.com/2025/10/01/raspberry_pi_price_hikes/">Raspberry Pi prices hiked as AI gobbles all the memory</a></li>

<li><a href="https://www.theregister.com/2025/10/01/ai_isnt_taking_people_jobs/">AI has had zero effect on jobs so far, says Yale study</a></li>

<li><a href="https://www.theregister.com/2025/10/01/us_air_force_investigates_breach/">Air Force admits SharePoint privacy issue as reports trickle out of possible breach</a></li>

<li><a href="https://www.theregister.com/2025/10/01/hundreds_businesses_urge_microsoft_not_end_win10_support/">Hundreds of orgs urge Microsoft: don't kill off free Windows 10 updates</a></li>
</ul>
<p>IT admins miffed at having their authority usurped by a diktat from Redmond can console themselves with the knowledge that Copilot's level of access "is strictly governed by the user‚Äôs work account permissions, ensuring enterprise data remains protected." The user's Entra (work) identity governs file permissions and access controls.</p>
<p>Also, "IT retains full control and oversight" ‚Äì apart from the bit about allowing this to happen in the first place.</p>
<p>Admins have the ability to disallow personal Copilot usage on work documents using cloud policy controls. And they can audit personal Copilot interactions and can apply enterprise identity, permission, and compliance policies.</p>
<p>Government tenants (GCC/DoD) for some reason don't support this capability, the one that Baroudi insists "does not create new data exposure risks."</p>

        

<p>Meanwhile, employees who decide to fire up their personal Copilot accounts within the workplace should be mindful that their prompts and responses will be captured by their employer.</p>
<p>As to why Microsoft would bother, Baroudi provides a hint in the FAQs detailing the bring-your-own-Copilot-to-work initiative that accompanies his post.</p>
<blockquote>Can use of Copilot from personal Microsoft 365 subscriptions help drive AI adoption? &nbsp;
<p>

Yes. It allows users to experience AI productivity benefits while IT retains control.</p></blockquote>
<p>Of course, when Microsoft next cites enterprise adoption statistics for its AI products, it will be worth asking whether the company is counting personal usage of Copilot. ¬Æ</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Company Man (163 pts)]]></title>
            <link>https://www.lesswrong.com/posts/JH6tJhYpnoCfFqAct/the-company-man</link>
            <guid>45443298</guid>
            <pubDate>Wed, 01 Oct 2025 20:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/JH6tJhYpnoCfFqAct/the-company-man">https://www.lesswrong.com/posts/JH6tJhYpnoCfFqAct/the-company-man</a>, See on <a href="https://news.ycombinator.com/item?id=45443298">Hacker News</a></p>
Couldn't get https://www.lesswrong.com/posts/JH6tJhYpnoCfFqAct/the-company-man: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Evaluating the impact of AI on the labor market: Current state of affairs (135 pts)]]></title>
            <link>https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs</link>
            <guid>45442743</guid>
            <pubDate>Wed, 01 Oct 2025 20:07:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs">https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs</a>, See on <a href="https://news.ycombinator.com/item?id=45442743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-budgetlab-content">
  
    
      

<article id="node-publication-1154" data-js="publication">
  

  <div>
          <section id="paragraph-key-takeaways-4326" data-js="key-takeaways">
        <h2>   Key Takeaways </h2>
  
      <ol>
              <li>
          <p>While the occupational mix is changing more quickly than it has in the past, it is not a large difference and predates the widespread introduction of AI in the workforce.</p>
        </li>
              <li>
          <p>Currently, measures of exposure, automation, and augmentation show no sign of being related to changes in employment or unemployment.</p>
        </li>
              <li>
          <p>Better data is needed to fully understand the impact of AI on the labor market.</p>
        </li>
              <li>
          <p>We plan on updating this analysis regularly moving forward to see how the impact of AI on the labor market changes over time.</p>
        </li>
          </ol>
  </section>

  <div id="paragraph-html-content-4287" data-js="html-content">
  <p>How has AI impacted the labor market? Since generative AI was first introduced nearly three years ago, surveys show widespread public anxiety about AI‚Äôs potential for job losses. While it is impossible to accurately predict the future, we can examine how U.S. employment has changed since ChatGPT‚Äôs release in November 2022.</p><p>Our analysis complements other recent studies that provide nascent evidence of possible AI impacts on specific occupations and sub-populations, such as early career workers. We took a broader lens, widening the aperture to the whole labor market, and asked two main questions.</p><p>First, is the pace of labor market change in this 33-month period of employment disruption different from past periods of early technological change? Second, is there evidence of economy-wide employment effects? To answer these questions, we compare how quickly the occupational mix has changed across a range of measures since ChatGPT‚Äôs launch, and compare this to past disruptions from computers and the internet.</p><p>Overall, our metrics indicate that the broader labor market has not experienced a discernible disruption since ChatGPT‚Äôs release 33 months ago, undercutting fears that AI automation is currently eroding the demand for cognitive labor across the economy.<sup>1</sup></p><p>While this finding may contradict the most alarming headlines, it is not surprising given past precedents. Historically, widespread technological disruption in workplaces tends to occur over decades, rather than months or years. Computers didn‚Äôt become commonplace in offices until nearly a decade after their release to the public, and it took even longer for them to transform office workflows. Even if new AI technologies will go on to impact the labor market as much, or more, dramatically, it is reasonable to expect that widespread effects will take longer than 33 months to materialize.</p><p>Of course, our analysis is not predictive of the future. We plan to continue monitoring these trends monthly to assess how AI‚Äôs job impacts might change. It is important to remember that the effects of new technologies are evolving and a simple snapshot in time is not enough to explicitly determine what the future holds.</p></div>

  <div aria-labelledby="heading-layout-4288">
                        <div id="paragraph-html-content-4289" data-js="html-content">
  <p>The current rhetoric about AI mirrors the anxiety over earlier generations of technological progress. So far, is this time different?</p><p>First, we look at how quickly the overall occupational mix changed in the first 33 months since ChatGPT‚Äôs relative to previous periods of technological change. Figure 1 compares the occupational mix by month to the mix in a baseline period at the start of a major technological development (e.g. January 1996 is the baseline month for the growing adoption of the internet). The job mix for AI appears to be changing faster than it has in the past, although not markedly so. (See the appendix for a discussion of pre-trends.)</p></div>
                                
                                <div id="paragraph-html-content-4290" data-js="html-content">
  <p>The occupational mix refers to the distribution of workers amongst all the jobs in the economy. In this context, a percentage point difference means that, relative to the start point, that percent of workers are in new occupations. This can occur by workers changing jobs, losing jobs, or unemployed people getting a new job. As such, this metric attempts to capture how different the sum of occupations that make up the labor force is relative to another point in time. By measuring this over the time generative AI has been publicly available, we can test the claim that AI is substantially changing the workforce by any of the methods mentioned above (pushing workers from one job to another, automating workers out of a job, or creating new jobs). Note that a change over this time period simply reflects <em>change</em> ‚Äî it does not take a stance on the <em>cause</em> of that change. Note that if recent grads are not getting hired, that would show up in this measure in as much as recent grads (as discussed below) are often in different occupations than older workers.</p><p>With the development of the internet and the growing prevalence of computers, the turn of the 21st century gave rise to concerns over an imminent computerization of many jobs. Despite this automation anxiety, the occupational mix by 2002 was at most around 7 percentage points different than it was in 1996; i.e., only 7 percent of workers in 2002 would need to switch occupations to match the composition of the 1996 labor market.</p><p>Changes in the occupational mix since the advent of generative AI in 2022 seem to mirror the trends seen during the three comparison periods. The recent changes appear to be on a path only about 1 percentage point higher than it was at the turn of the 21st century with the adoption of the internet. Although recent trends seemingly outpace historical shifts in the occupational mix, the potential effects of AI on the labor market so far are not out of the ordinary. In fact, taking a closer look at recent years, the data suggests that this recent trend is not necessarily attributable to AI (Figure 2). Shifts in the occupational mix were well on their way during 2021, before the release of generative AI, and more recent changes do not seem any more pronounced, even as the use of AI continues to grow in popularity.</p></div>
                                
                                <div id="paragraph-html-content-4291" data-js="html-content">
      

<p>Repeating this analysis by industry similarly suggests a limited effect of AI. Figure 3 reports the change in the occupational mix from November 2022 within different industries. The Information, Financial Activities, and Professional and Business Services sectors have all seen larger shifts in the job mix compared to the shifts in the aggregate labor market, with the largest changes in the Information sector. (As a reminder the information sector includes things like newspapers, movies, and data processing.) These industries are among those with the highest exposure to generative AI. Although at first glance these changes may seem attributable to generative AI, the data again suggests that the trends within these industries started before the release of ChatGPT (Figures 4-6). In fact, over a broader time horizon, the large shifts in the Information Industry seem to be a feature of the industry itself rather than a consequence of any one technological development (Figure 7).</p>

    </div>
                                
                                
                                
                                
                                
                                <div id="paragraph-html-content-4292" data-js="html-content">
      

<p>Looking over an even longer horizon, labor market volatility appears rather low. As a chart Jed Kolko shows, the change in the occupational mix seen in Figure 1 is sluggish compared to the change seen in the 40s and 50s (which reflected mass labor market changes due to world events).&nbsp;<a href="https://hbr.org/2018/12/5-questions-we-should-be-asking-about-automation-and-jobs">Kolko cautioned</a> that ‚Äúwe simply don‚Äôt know for sure whether automation, algorithms, and AI will ultimately create more jobs than they destroy.‚Äù&nbsp;</p>

    </div>
                                
                                <div id="paragraph-html-content-4293" data-js="html-content">
      

<p>The dissimilarity data we have examined indicates that there is no substantial acceleration in the rate of change in the composition of the labor market since the introduction of ChatGPT. Lacking that, there is nothing meaningful we can either attribute or misattribute to AI.</p>

    </div>
                                <div id="paragraph-html-content-4294" data-js="html-content">
      

<p>Figure 9 compares the occupational mix for recent college graduates (ages 20-24) to that of their older counterparts (ages 25-34).<sup>2</sup> If generative AI were in fact substantially changing the labor market for recent college graduates, we would expect to see a growing dissimilarity in the occupational mix between these two groups. The dissimilarity has increased slightly faster in recent months than it did in a previous time period, which could be consistent with a recent&nbsp;<a href="https://digitaleconomy.stanford.edu/publications/canaries-in-the-coal-mine/">paper</a> from Brynjolfsson et al. showing a possible impact of AI on employment of early career workers. It could also simply reflect a slowing labor market. However, our results should be interpreted with caution particularly given small sample sizes.</p>

    </div>
                                
                                <div id="paragraph-html-content-4295" data-js="html-content">
      

<p>Taking a closer look at the trend since January 2021, the dissimilarity between older and more recent college graduates rarely deviates outside of the 30-33% range (Figure 10). This implies that these trends of growing dissimilarity may pre-date ChatGPT‚Äôs release and may not be attributable to AI. However, there is perhaps some slight upward momentum more recently, though this is consistent with both Brynjolfsson et al.‚Äôs work and the CPS‚Äôs noisiness (and a slowing labor market hitting younger workers). Further, the same caution in interpretation given the small sample sizes holds in this figure as well.</p>

    </div>
                                
                                </div>

  <div aria-labelledby="heading-layout-4296">
                        <div id="paragraph-html-content-4297" data-js="html-content">
  <p>To better understand whether AI is impacting the labor market, we would want to analyze whether the share of workers in occupations that are most impacted by AI usage is changing over time. If AI were automating jobs at scale, we would expect to see a smaller share of workers in some of the jobs that are most negatively impacted.</p><p>Unfortunately, comprehensive usage data is not publicly available. The best available data we have is from&nbsp;<a href="https://www.brookings.edu/articles/generative-ai-the-american-worker-and-the-future-of-work/">OpenAI</a> and&nbsp;<a href="https://www.anthropic.com/economic-index">Anthropic</a>, respectively, that detail the occupations that are most ‚Äúexposed‚Äù to genAI tools (a theoretical, forward-looking metric across all jobs) and that have the highest actual usage of one specific AI tool, Claude (a more narrow, present-focused metric). While imperfect, these data are our best approximation of AI job ‚Äúrisk‚Äù. (See discussion of limitations in the next section and in the appendix.)</p><p>Importantly, OpenAI and Anthropic are measuring different things and we look at them separately.</p></div>
                                <div id="paragraph-html-content-4298" data-js="html-content">
  <p>We use data from OpenAI that shows a measure of ‚Äúexposure‚Äù to ChatGPT technology. This refers, generally, to whether utilizing ChatGPT4 technology can help reduce the time it takes to complete the occupation‚Äôs tasks by at least 50%. (The data appendix describes this metric in more detail.)</p><p>We utilize the ‚ÄúBeta‚Äù exposure metric, which also accounts for if a model with additional software built on top of it can help reduce task completion time, though this capability is weighted half that of ‚Äúdirect‚Äù exposure. An exposure score is created on a scale from 0 to 1 based on a percent of an occupation‚Äôs tasks that are ‚Äúexposed‚Äù to genAI. The data appendix describes this metric in more detail.</p><p>For our purposes, we categorize occupations into three groups using their exposure score quintile; an occupation has the lowest degree of exposure if it falls in the first two quintiles, a medium degree if in the 3rd and 4th quintiles, and the highest degree if in the top quintile. In other words, these metrics look at <em>relative</em> not <em>absolute</em> exposure. We provide a further discussion of this in the appendix.</p><p>We ask: has the share of workers in occupational exposure quintiles changed since ChatGPT‚Äôs launch? Our analysis shows that it has not (Figure 11). The share of workers in the lowest, middle, and highest occupational exposure groups stay stable at around 29%, 46% and 18%, respectively.</p></div>
                                
                                <div id="paragraph-html-content-4299" data-js="html-content">
      

<p>Even when specifically examining the unemployed population, there is no clear growth in exposure to generative AI. Figure 12 depicts the average percentage of tasks exposed amongst unemployed workers by duration of unemployment. AI-driven displacement might suggest a growth in the proportion of exposed tasks amongst recently unemployed workers. Irrespective of the duration of unemployment, however, unemployed workers were in occupations where about 25 to 35 percent of tasks, on average, could be performed by generative AI. Although there is some variation between months, the data demonstrate no clear upward trend and no clear difference by the duration of unemployment.&nbsp;</p>

    </div>
                                
                                
                                <div id="paragraph-html-content-4300" data-js="html-content">
  <p>Given Anthropic‚Äôs usage data‚Äôs novelty and uniqueness, there is no established standard for how to aggregate it. The usage Anthropic observes does not contain every single task in the O*NET task database, so the question of how to handle the missing tasks remains ambiguous. We proceed in two ways:</p><p>First, we ignore tasks that are not included in the Anthropic data and aggregate following the method detailed in the appendix. This method makes no assumption about how workers are using or could utilize Claude to perform the task, or how workers in occupations with tasks like those observed would use Claude. However, this method significantly limits the number of tasks and therefore occupations we can include. Further, an occupation may appear to have very high usage while in fact only a single of that occupation‚Äôs tasks were observed in the data.</p><p>Alternatively, we include all of the missing tasks and assume their usage is zero. There is some truth to this, as those tasks were not observed in Claude during the period in which the data was collected. However, it makes strong assumptions about those tasks‚Äô potential usage. Two comparable tasks, where one appears in the data and one does not, would have totally different usage values. Given how the observed Claude data is a representation of the users who happened to utilize the model over a sample period, the following period could have had that similar task included.</p><p>In pursuit of a balanced and well-informed exploration of this data, we include results from both methods below.</p><p>Anthropic‚Äôs data on AI usage shows similar trends of stability over time, rather than disruption. The proportion of employment in occupations with high levels of task AI usage, whether automation or augmentation (as defined as more than half of AI usage), is stable at around 70% or 11%, respectively (Figure 15). When assuming that unobserved tasks indicate zero usage, however, these proportions drop to 3% and 0%, respectively. Repeating a similar analysis as above, Figures 16 and 18 report the occupation-level share of tasks that are automation or augmentation, respectively, amongst unemployed workers by duration of unemployment. Note: for this analysis, we use Anthropic‚Äôs most recent data on AI usage, which was released in mid-September. We discuss Anthropic‚Äôs data vintages more fully in the Appendix.</p></div>
                                </div>

  

  

  

  

  

  

  <div aria-labelledby="heading-layout-4301">
                        <div id="paragraph-html-content-4302" data-js="html-content">
  <p>As previously noted, the metrics from OpenAI and Anthropic are imperfect proxies for AI risk and usage, while still being the best available.</p><p>A key limitation of OpenAI‚Äôs ‚Äúexposure‚Äù data is that it is not based on actual usage, and should therefore be interpreted as a theoretical estimate of the jobs and sectors that <em>could</em>, in theory, be impacted. In reality, actual AI usage and workplace diffusion has varied dramatically between sectors and occupations with similar levels of ‚Äúexposure.‚Äù For instance, generative AI tools were adopted extremely quickly and at mass scale among coders and software developers, who are in the top quintile of exposure. Meanwhile, adoption has lagged considerably in clerical sectors, despite a similar level of exposure. Thus analyzing occupations by exposure alone likely <em>under-</em>estimates potential labor market disruption, as the top quintiles of exposure will include occupations that are theoretically exposed but not actively using AI at a meaningful scale, and thus unlikely to see AI impacts.</p><p>A comparison of the OpenAI ‚Äúexposure‚Äù data with the Anthropic usage data makes this limitation clear. The two measures appear to have only a limited correlation with one another (Figure 20).</p></div>
                                
                                <div id="paragraph-html-content-4303" data-js="html-content">
      

<p>Figure 20 consists of occupations that have data for both the OpenAI and Anthropic measures, which amounts to about 80% of CPS occupations in our sample. Figure 21 splits the data from figure 20 into quadrants along the axes of low-high exposure and low-high usage and then groups the data into its SOC job categories. Particularly striking is the greater range of different job categories in the quadrants with low usage (the left side of figure 20) and conversely the concentration in just a handful of categories in the high usage quadrants. Across both high and low exposure, high usage occupations are dominated by scientific and quantitative professions and general business occupations. The occupations clustered in the low usage/exposure (bottom left of figure 20) tend to be production occupations with little computerization.</p>

    </div>
                                
                                
                                <div id="paragraph-html-content-4304" data-js="html-content">
  <p>Just as the OpenAI metric has limitations, so too does Anthropic‚Äôs usage data. Figure 22 shows the occupational shares of all ‚Äúconversations‚Äù with Claude (the AI chatbot), and illustrates the occupation groups that are over- and under- represented in this usage, compared to their exposure ranking and employment share.</p><p>It is clear from the data that Claude‚Äôs usage is heavily dominated by one occupational group ‚Äî computer and mathematical, which includes coders ‚Äî and that arts and media (including writers) is also considerably overrepresented. While certainly coding is among the most prominent use cases of AI, it is likely that Claude‚Äôs userbase skews more heavily to these tasks due to Claude‚Äôs stand-out reputation among LLMs as being particularly good at writing and coding. <a href="https://cdn.openai.com/pdf/3c7f7e1b-36c4-446b-916c-11183e4266b7/chatgpt-usage-and-adoption-patterns-at-work.pdf">New data recently published by OpenAI</a> shows a broad pattern of usage among ChatGPT customers across a range of industries, including not only information services (including software development) but also professional services and even manufacturing. It is entirely possible, and even likely, that usage data from other AI models like Google‚Äôs Gemini or Microsoft‚Äôs Copilot would show different and more varied patterns of usage. Thus data from Claude usage alone is not representative of how workers across the economy are using AI chatbots and tools.</p><p>To accurately measure AI‚Äôs impact on the labor force, the most important data needed is comprehensive usage data from all the leading AI companies at the individual and enterprise level, including APIs.&nbsp;<a href="https://www.linkedin.com/company/anthropicresearch/">Anthropic</a> has led the way in transparently sharing Claude usage data, including a new release of enterprise data. To further our understanding of AI‚Äôs impact, it is important that all leading AI labs do the same in a similarly transparent and privacy-protected way.&nbsp;</p></div>
                                </div>

  <div id="paragraph-html-content-4306" data-js="html-content" aria-labelledby="heading-layout-4305">
      

<p>While anxiety over the effects of AI on today‚Äôs labor market is widespread, our data suggests it remains largely speculative. The picture of AI‚Äôs impact on the labor market that emerges from our data is one that largely reflects stability, not major disruption at an economy-wide level. While generative AI looks likely to join the ranks of transformative, general purpose technologies, it is too soon to tell how disruptive the technology will be to jobs. The lack of widespread impacts at this early stage is not unlike the pace of change with previous periods of technological disruption. Preregistering areas where we would expect to see the impact and continuing to monitor monthly impacts will help us distinguish rumor from fact.&nbsp;</p>

    </div>

  <div aria-labelledby="heading-layout-4307">
                        <div id="paragraph-html-content-4308" data-js="html-content">
  <p>Code used to create the data can be found <a href="https://github.com/Budget-Lab-Yale/AI-Employment-Model">here</a>.</p><p>We adapt&nbsp;<a href="https://inequality.stanford.edu/sites/default/files/media/_media/pdf/Classic_Media/Dudley_1955_Measurement.pdf">Duncan and Duncan‚Äôs</a> methodology to construct a dissimilarity index of the change in the occupational mix over time using monthly CPS data. Going month by month, we measure each occupation‚Äôs constituent percentage of the workforce and compare it to the starting month. To address noise in the data, we take a 12 month moving average for each month. We then sum up the absolute differences in percentage of workforce across all occupations to get our dissimilarity index for that given month. This captures both the advent of new occupations and the expansion or contraction of existing ones.</p><p>To examine generative AI‚Äôs impact, we begin in November 2022 and continue into the latest monthly CPS release in July, as this lines up with AI‚Äôs public introduction and the beginning of its adoption. We compare AI‚Äôs dissimilarity index to three other time periods:</p><ol><li>1984-1989: Capturing the popularization of PCs and the start of the computer revolution.</li><li>1996-2002: Capturing mass adoption of the internet in public life and the workplace.</li><li>2016-2019: A control period following the 2008 Recession recovery during which there was little change to the occupational mix.</li></ol><p>Figure A1 adds pre-trends in the occupational mix for the prior 12 months to the data from Figure 1. In all but one period, the pre-trends show a similar degree of dissimilarity as compared to the trend observed over the first year. This lack of a substantial difference suggests the advent of new technologies has minimal immediate effects; i.e., shifts in the labor market take time to develop. Note that the large pre-trends in the ‚ÄúComputers‚Äù period are likely due to issues with the quality of data prior to 1981.</p></div>
                                
                                <div id="paragraph-html-content-4309" data-js="html-content">
  <p>Using&nbsp;<a href="https://arxiv.org/pdf/2303.10130">OpenAI‚Äôs occupational exposure data</a>, we classify occupations as mildly, moderately, or highly exposed to AI provided that generative AI can reduce the time to complete at least one task (or a greater portion of tasks given the exposure level) by 50%. The raw occupational exposure data allocates tasks into one of three categories:</p><ol><li>No exposure: Generative AI cannot reduce the time to complete the task or lowers the quality of the output.</li><li>Direct exposure: Generative AI can reduce the time to complete a task by at least 50%.</li><li>LLM+ Exposed: Generative AI alone cannot reduce task completion time, but a piece of software built on top of a model could.</li></ol><p>We utilize the GPT4 categorized ‚ÄúBeta‚Äù exposure, which gives a task a score of 1 if it is directly exposed, or a score of .5 if it is LLM+ Exposed. An occupation‚Äôs exposure is the weighted average of the exposure of each individual task.</p><p>Following the methods in OpenAI‚Äôs paper presenting these results, when aggregating exposure to the occupational level, a job‚Äôs ‚Äúcore‚Äù tasks have a weight of 1 while their ‚Äúsupplemental‚Äù tasks have a weight of .5. After exposure and usage are aggregated to the SOC code level, they are weighted by that occupation‚Äôs OES labor count. This weight is used when aggregating from SOC code to CPS code.</p><p>Given the exposure data was created a few years and thus does not include the more advanced capabilities of today‚Äôs large language models, a relative comparison of exposure appears more appropriate. Rather than measuring the now aged direct exposure, we broke GPT4 Beta exposure (after our aggregation and weighting) into quintiles and bucketed them as described in the text above. The average exposure, rounded to the second digit, for each quintile is as follows:</p></div>
                                
                                <div id="paragraph-html-content-4310" data-js="html-content">
      

<p>Figure A2 replicates the prior analysis in Figure 12 with occupation-level exposure groups instead defined using the absolute measure of exposure. The lowest and medium exposure groups (scores less than 0.4 and between 0.4 and 0.8, respectively) stably comprise around 45% of workers each, while the highest exposure group represents only around 2% of workers (scores greater than 0.8). Like in Figure 12, there is no observable trend over time.</p>

    </div>
                                
                                <div id="paragraph-html-content-4327" data-js="html-content">
  <p>Anthropic‚Äôs usage metrics are aggregated similarly to the OpenAI exposure data. We follow the method their researchers use <a href="https://huggingface.co/datasets/Anthropic/EconomicIndex/tree/main/release_2025_03_27">here</a>. We aggregate the individual kinds of usage into their respective categories for each task:</p><ul><li>Augmentation = Validation + Task Iteration + Learning</li><li>Automation = Directive + Feedback Loop.</li></ul><p>We then weight the tasks using the same core/supplemental weighting method described above. Following that, the aggregation to CPS code level is identical to the OpenAI aggregation.&nbsp;<br>Throughout this piece we use Anthropic‚Äôs AI usage data from their most recent release in August. This data, however, only provides a static snapshot of AI usage. As more data is made available in future releases, the Budget Lab will continue to update this analysis to provide a more comprehensive picture of how changes in AI usage may be affecting the labor market. Figure A3 shows the trend in the automation/augmentation of tasks using data from a prior March release until August 2025 (note that to ensure consistency between the two releases, the August usage data excludes enterprise usage).</p></div>
                                
                                
                                </div>

  <div id="paragraph-html-content-4311" data-js="html-content">
  <ol><li>Much of the press focuses on <a href="https://www.cnbc.com/2025/08/28/generative-ai-reshapes-us-job-market-stanford-study-shows-entry-level-young-workers.html">early career</a> and <a href="https://fortune.com/2025/08/10/ai-unemployment-white-collar-knowledge-workers-jobless-recovery-recession/">white collar</a> workers being in <a href="https://www.cnbc.com/2025/08/05/ai-labor-market-young-tech-workers-goldman-economist.html">lower demand</a>.&nbsp;</li><li>In any given year, recent and older college graduates account for around 1,100 and 5,600 observations (3% and 12% of the overall sample), respectively.</li></ol></div>


    </div>

  </article>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Lost 32,000 Private-Sector Jobs in September, Says Payroll Processor (208 pts)]]></title>
            <link>https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340</link>
            <guid>45442185</guid>
            <pubDate>Wed, 01 Oct 2025 19:30:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340">https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340</a>, See on <a href="https://news.ycombinator.com/item?id=45442185">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[ICE Is Buying a Tool to Track Phones, Without Warrants (140 pts)]]></title>
            <link>https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds</link>
            <guid>45441983</guid>
            <pubDate>Wed, 01 Oct 2025 19:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds">https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds</a>, See on <a href="https://news.ycombinator.com/item?id=45441983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!xTUX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!xTUX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 424w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 848w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!xTUX!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:400,&quot;width&quot;:600,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Several agents wearing green uniforms and heavy-duty face masks are seen up close. One of them has a patch that says ‚ÄúHSI,‚Äù a reference to Homeland Security Investigations.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="Several agents wearing green uniforms and heavy-duty face masks are seen up close. One of them has a patch that says ‚ÄúHSI,‚Äù a reference to Homeland Security Investigations." title="Several agents wearing green uniforms and heavy-duty face masks are seen up close. One of them has a patch that says ‚ÄúHSI,‚Äù a reference to Homeland Security Investigations." srcset="https://substackcdn.com/image/fetch/$s_!xTUX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 424w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 848w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!xTUX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F513e54a8-0c1a-40ab-a994-6f04fdba9089_600x400.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Federal agents stand guard on a road outside an agricultural facility where an immigration raid occurred in Camarillo, Calif., in July.Credit...Daniel Cole/Reuters</figcaption></figure></div><p data-attrs="{&quot;url&quot;:&quot;https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>While putting together my </span><a href="https://trumptyrannytracker.substack.com/" rel="">Trump Tyranny Tracker</a><span>, I came across alarming news that has gone largely unnoticed but needs our attention‚ÄîASAP. Documents reviewed by </span><em><a href="https://www.404media.co/ice-to-buy-tool-that-tracks-locations-of-hundreds-of-millions-of-phones-every-day/" rel="">404 Media</a></em><span> reveal that ICE is purchasing access to a powerful surveillance tool that harvests billions of pieces of location data daily from hundreds of millions of phones. This move reverses Biden-era curbs and marks a dramatic expansion of ICE‚Äôs ability to track people inside the U.S. without a warrant.</span></p><p>The contract has been awarded to PenLink, a little-known surveillance company headquartered in Nebraska that has quietly spent decades perfecting tools for geolocation data mining, mass communications interception, and real-time tracking, operating largely outside public scrutiny while steadily expanding its reach into the law enforcement and intelligence space. </p><p><span>This is not ICE‚Äôs first engagement with the company: in 2018, the agency signed a </span><a href="https://www.newsweek.com/ice-just-signed-24m-contract-secretive-data-surveillance-company-can-track-you-962493" rel="">$2.4 million contract</a><span> with PenLink, granting it access to the firm‚Äôs proprietary telecommunications analysis and intercept software suite, which was used to collect and analyze massive amounts of internet and social media communications data in real time. ICE has now deliberately selected PenLink over its competitors once again because it offers a comprehensive ‚Äúall-in-one‚Äù platform capable of merging immense repositories of location data with sophisticated social media monitoring capabilities, thereby giving the agency an unprecedented ability to track, map, and analyze individuals‚Äô movements and networks. In doing so, ICE is not simply reverting to its previous practice of warrantless location tracking; it is escalating this surveillance to a level of precision and integration that blurs the line between targeted investigation and dragnet monitoring.</span></p><p>Under the Biden administration, the Department of Homeland Security had suspended the purchase of commercial location data after the Inspector General found the agency had violated federal law, but that temporary safeguard has now been dismantled. Trump‚Äôs federal agencies are resurrecting these programs with renewed vigor, tapping into massive datasets assembled by surveillance contractors that systematically harvest and monetize the movements of hundreds of millions of people through their smartphones, effectively creating a parallel data-acquisition pipeline that allows federal agencies to sidestep judicial oversight and bypass the warrant requirements that govern direct requests to telecommunications providers. These practices were controversial even before Trump returned to power, and now, under his direction, they are being normalized, expanded, and institutionalized.</p><p>The threat posed by these capabilities is very real and happening now. These datasets can locate an individual within a single city block, construct detailed social graphs based on patterns of physical proximity, and generate real-time alerts when specific targets move, meet, or communicate. ICE has already tested similar analytical systems to assign ‚Äúgang membership‚Äù through algorithmic inference ‚Äî a program so deeply flawed that it infamously misidentified toddlers as gang members ‚Äî and under Trump, these same technologies are being scaled up and turned loose on entire communities, dramatically increasing their potential for error, abuse, and political weaponization.</p><p>The latest developments around ICE‚Äôs surveillance powers should be setting off alarms everywhere. Trump is quietly building the machinery of a domestic surveillance state using tools that, so far, have faced almost no scrutiny. Shortly after returning to power, he and Musk created unauthorized DOGE, a shadow structure created without congressional approval. Under the banner of ‚Äúefficiency,‚Äù DOGE quietly began consolidating massive amounts of federal data. It functioned as a bureaucratic Trojan horse, allowing Trump‚Äôs inner circle to merge agency datasets, centralize information flows, and bypass the oversight mechanisms that typically govern intelligence operations.</p><p>That initial framework is now being supercharged. ICE is being armed with a growing list of commercial surveillance tools: Graphite, an invasive spyware platform that can penetrate Signal and turn your phone into a surveillance tool using the camera and microphone; PenLink, which merges mass location tracking with social media monitoring; Flock‚Äôs license plate reader network; Clearview AI‚Äôs facial recognition database; and Palantir‚Äôs powerful data-integration and analysis systems. These are just a few examples. Together, they can weave DOGE‚Äôs centralized data stores with private-sector capabilities into a single, flexible, and largely unaccountable surveillance apparatus.</p><blockquote><p><strong>More on Graphite spyware‚Ä¶.</strong></p></blockquote><p>This is exactly how Russia built its surveillance state. It began with the quiet centralization of telecommunications data, followed by the rollout of SORM, which gave the government mass interception and geolocation powers, and ended with the targeted use of those capabilities against political opponents, journalists, and civil society. Immigrants, ethnic minorities, and marginalized groups were the first targets‚Äîpeople with little power to resist. Once the system was normalized, the net widened, and tools designed for ‚Äúsecurity‚Äù quickly became instruments of political control.</p><p>And Trump is following the same blueprint. Immigrants are the test case, but the surveillance architecture being built is meant to reach far beyond them. ICE is being transformed into a personal security force equipped with spyware, dragnet tracking, and powers that bypass the courts and Congress. This is a deliberate, methodical effort to fuse state power with commercial surveillance markets, creating a system that operates with no transparency or accountability. </p><p>Russia offers a chilling preview of where this leads. Once surveillance infrastructure is in place, legal limits become irrelevant. The tools designed for ‚Äúsecurity‚Äù end up targeting opposition politicians, journalists, NGOs, and eventually ordinary citizens. If this trajectory continues unchecked, the same will happen here.</p><p>This story should be front-page news, but it isn‚Äôt. So it is up to us to make noise.</p><ul><li><p><strong>Spread this story</strong><span> widely. Most Americans have no idea ICE is buying tools that let them track phones in real time without warrants.</span></p></li><li><p><strong>Contact your representatives</strong><span> in Congress and at the state level. Demand hearings, oversight, and legal restrictions on warrantless location tracking.</span></p></li><li><p><strong>Support watchdog groups</strong><span> like the </span><a href="https://www.aclu.org/" rel="">ACLU</a><span>, </span><a href="https://www.eff.org/" rel="">EFF</a><span>, and </span><a href="https://citizenlab.ca/" rel="">Citizen Lab</a><span> that investigate these surveillance programs.</span></p></li><li><p><strong>Harden your devices</strong><span>: keep phones updated, consider Lockdown Mode, and reduce app location sharing.</span></p></li></ul><div data-attrs="{&quot;url&quot;:&quot;https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Thanks for reading Unmasking Russia! This post is public, so feel free to share it.</p><p data-attrs="{&quot;url&quot;:&quot;https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://olgalautman.substack.com/p/ice-is-buying-a-tool-to-track-hundreds?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Increasing your practice surface area (122 pts)]]></title>
            <link>https://www.indiehackers.com/post/lifestyle/increasing-your-practice-surface-area-agxYGi9bL0gd1WYYQZAu</link>
            <guid>45441222</guid>
            <pubDate>Wed, 01 Oct 2025 18:20:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.indiehackers.com/post/lifestyle/increasing-your-practice-surface-area-agxYGi9bL0gd1WYYQZAu">https://www.indiehackers.com/post/lifestyle/increasing-your-practice-surface-area-agxYGi9bL0gd1WYYQZAu</a>, See on <a href="https://news.ycombinator.com/item?id=45441222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Budapest. Sometime around 1978. It's past 1am and all the lights in a high-rise apartment are out, except for one. A Hungarian girl ‚Äî not yet 10 years old ‚Äî sits on the cold bathroom floor balancing a chessboard on her knees.</p><p>Her father opens the door and finds her there, crying, "Sofia! Leave the pieces alone!"</p><p>The girl looks up at him. "Daddy," she says almost desperately, "they won't leave&nbsp;<em>me</em>&nbsp;alone!"</p><p>If you aren't familiar with <a target="_blank" href="https://x.com/ChanningAllen/status/1961850905709666428">this story</a>, the girl is Sofia Polgar. In the years following the above scene in the bathroom, she'd go on to achieve one of the highest-performing ratings in chess history, playing for Hungary in four Chess Olympiads and winning two team gold medals, one team silver, three individual golds, and one individual bronze.</p><p>A lot has been written about the training regimen that Sofia went through with her two sisters: 5‚Äì6 hours of daily chess practice alongside studies in multiple languages and high-level mathematics in an apartment packed with thousands of chess books and detailed filing systems of their opponents' histories.</p><p>But not much has been written ‚Äî how could it be? ‚Äî about all the hidden reps Sofia got in&nbsp;<em>outside</em>&nbsp;of her official sessions. Like most elite performers, she had dissolved the boundaries of what counts as training and become high in something I call "practice surface area." It means what it sounds like: the total volume of time and space in your life where practice can happen.</p><h2>The false dilemma of "talent vs training"</h2><p>Let's say you and a friend decide to learn something new together. Guitar, chess, coding, whatever. You both sign up for the same class, practice for the same scheduled hour each day, watch the same YouTube tutorials.</p><p>Six weeks later, they‚Äôre proficient and you‚Äôre still stuttering through the basics.</p><p>We all know the standard explanation: talent. They‚Äôve got it, you don‚Äôt. Some people are just wired for certain things. Better to cut your losses and find something that comes naturally to you.</p><p>Right?</p><p>Maybe! Usually what people mean when they call someone "talented" or a "natural" is that the person is genetically gifted. And genetics is real. But it's also not a very satisfying explanation because it's so nonspecific.</p><p>So if I may, I think what's actually taking place in most cases is a difference in practice surface area. You and your friend both&nbsp;<em>officially</em>&nbsp;practiced for the same "3 hours per week," but in reality your friend put in closer to 30. And they weren't even aware they were doing it.</p><p>They started hearing music differently. Every song on their commute became a lesson in chord progressions. Their fingers unconsciously worked through scales during meetings. They fell asleep running through the next day's session. They dreamed in tablature.</p><p>You began&nbsp;<em>practicing</em>&nbsp;guitar. They began&nbsp;<em>living</em>&nbsp;guitar.</p><h2>High surface area is the rule, not the exception</h2><p>I like studying world-class performers, and I can‚Äôt think of a single high-level pro who isn‚Äôt also high in practice surface area.</p><p>Take George Orwell. In his essay <a target="_blank" href="https://www.orwellfoundation.com/the-orwell-foundation/orwell/essays-and-other-works/why-i-write/">Why I Write</a>, he reveals something that should have disqualified him from ever becoming a writer: he had a terrible time actually sitting down to write. The physical act of writing was torture for him. By his own admission, he would avoid it whenever possible.</p><p>So how did this writing-avoidant person become one of the most famous prose stylists of the 20th century?</p><p>Here‚Äôs the secret he buried in that same essay:</p><blockquote><p><em>For fifteen years or more, I was carrying out a literary exercise of a quite different kind: this was the making up of a continuous ‚Äústory‚Äù about myself, a sort of diary existing only in the mind‚Ä¶ For minutes at a time this kind of thing would be running through my head: ‚ÄòHe pushed the door open and entered the room. A yellow beam of sunlight, filtering through the muslin curtains, slanted on to the table, where a matchbox, half-open, lay beside the inkpot. With his right hand in his pocket he moved across to the window. Down in the street a tortoiseshell cat was chasing a dead leaf,‚Äô etc. etc.</em></p></blockquote><p>From childhood until age twenty-five, Orwell was practicing descriptive prose every waking moment. He wasn‚Äôt "writing," he was just&nbsp;<em>existing</em>&nbsp;lol. But his brain was secretly logging thousands of hours of narrative practice.</p><p>This pattern shows up everywhere once you know to look for it.</p><p>Richard Feynman didn‚Äôt become a legendary teacher by practicing lectures. He became one by explaining physics to imaginary students while walking around campus. He‚Äôd work through problems out loud in empty rooms, turning every moment of solitude into a teaching rehearsal.</p><p>Bobby Fischer carried a pocket chess set everywhere and would analyze positions using ceiling tiles as boards while lying in bed. Insomnia became chess study. Waiting rooms became tournaments. His opponents thought they were facing someone with supernatural talent. They were actually facing someone who‚Äôd turned every idle moment into chess.</p><p>In fact I've found so many examples of high practice surface area that I created a companion piece to this essay filled with nothing but examples.</p><p>Here it is: <a target="_blank" href="https://www.indiehackers.com/post/the-hidden-training-habits-of-21-world-class-performers-m3AgqjN63WLHJGLrKJPa">The hidden training habits of 21 world-class performers.</a></p><div><header><hr><p><em>Btw if you're enjoying this, consider checking out the Indie Hackers Newsletter.</em></p><p><em>It's full of stories, trends, and insights to help you work for yourself and make $10k/mo from wherever, whenever:</em></p></header></div><hr><h2>How to increase your surface area</h2><p>It should go without saying that the best way to increase your practice surface area in a given field is to be obsessed with that field. Obsession makes quick work of formal and bounded training sessions, and it doesn't need "tips" on how to do so.</p><p>So the question then becomes, "How do I increase my practice surface area if I'm not already obsessed?"</p><p>I've got a few ideas:</p><h3>1. Find the ‚Äúminimum viable repetition‚Äù</h3><p>Identify the smallest possible practice unit that requires no equipment, setup, or specific location.</p><p>Like Bobby Fischer analyzing chess positions on ceiling tiles while lying in bed, you need a version of practice so minimal it can happen anywhere, requiring zero setup or equipment.</p><h3>2. Turn idle time into mental rehearsal</h3><p>Waiting periods and dead time are great opportunities for visualization sessions where you mentally simulate perfect performance.</p><p>Michael Phelps would run ‚Äúmental movies‚Äù of perfect races in waiting rooms and before sleep.</p><h3>3. Embed practice into routine activities</h3><p>Layer your craft directly onto daily activities.</p><p>Maya Angelou composed entire poems while mopping floors. She claims to have used the rhythm of physical work as a metronome for her words.</p><h3>4. Create background processing systems</h3><p>Develop automatic mental habits that keep your craft running in the background of consciousness throughout the day.</p><p>Eminem can‚Äôt turn off the part of his brain that rhymes everything. Every conversation, interview, even argument becomes inadvertent freestyle practice as he generates rhyme patterns for everything he hears.</p><h3>5. Use environmental constraints as creative parameters</h3><p>Convert physical limitations and situational constraints into practice parameters that force innovation.</p><p>The UFC fighter Anderson Silva would practice his striking combinations disguised as dancing at Brazilian clubs. He'd throw actual combat sequences to the rhythm while everyone thought he was just getting down.</p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Announcing Tinker (130 pts)]]></title>
            <link>https://thinkingmachines.ai/blog/announcing-tinker/</link>
            <guid>45441219</guid>
            <pubDate>Wed, 01 Oct 2025 18:20:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thinkingmachines.ai/blog/announcing-tinker/">https://thinkingmachines.ai/blog/announcing-tinker/</a>, See on <a href="https://news.ycombinator.com/item?id=45441219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">
    










    
<main id="main">
  
  
  
  
  
  
  
  

  

  
  
  

  

  <article>
    
    <nav id="left-toc" aria-label="Table of contents"></nav>
    
    <p>
  <a href="https://www.computerhistory.org/collections/catalog/X39.81/" target="_blank" rel="noopener">TinkerToy Computer</a> invented by <a href="https://en.wikipedia.org/wiki/Danny_Hillis" target="_blank" rel="noopener">Daniel Hillis</a> and <a href="https://en.wikipedia.org/wiki/Brian_Silverman" target="_blank" rel="noopener">Brian Silverman</a>
</p>
<p>Today, we are launching <a href="https://thinkingmachines.ai/tinker">Tinker</a>, a flexible API for fine-tuning language models. It empowers researchers and hackers to experiment with models by giving them control over the algorithms and data while we handle the complexity of distributed training. Tinker advances our mission of enabling more people to do research on cutting-edge models and customize them to their needs.</p>
<p>Tinker lets you fine-tune a range of large and small open-weight models, including large mixture-of-experts models such as Qwen-235B-A22B. Switching from a small model to a large one is as simple as changing a single string in your Python code.</p>
<p>Tinker is a managed service that runs on our internal clusters and training infrastructure. We handle scheduling, resource allocation, and failure recovery. This allows you to get small or large runs started immediately, without worrying about managing infrastructure. We use LoRA so that we can share the same pool of compute between multiple training runs, lowering costs.</p>
<p>Tinker‚Äôs API gives you low-level primitives like <code>forward_backward</code> and <code>sample</code>, which can be used to express most common post-training methods. Even so, achieving good results requires getting many details right. That‚Äôs why we‚Äôre releasing an open-source library, the <a href="http://github.com/thinking-machines-lab/tinker-cookbook">Tinker Cookbook</a>, with modern implementations of post-training methods that run on top of the Tinker API.</p>
<p>Groups at Princeton, Stanford, Berkeley, and Redwood Research have already been using Tinker:</p>
<ul>
<li>The <a href="https://blog.goedel-prover.com/">Princeton Goedel Team</a> trained mathematical theorem provers</li>
<li>The <a href="https://statmech.stanford.edu/">Rotskoff Chemistry group</a> at Stanford fine-tuned a model to complete chemistry reasoning tasks</li>
<li><a href="https://sky.cs.berkeley.edu/project/skyrl/">Berkeley‚Äôs SkyRL group</a> ran experiments on a custom async off-policy RL training loop with multi-agents and multi-turn tool-use.</li>
<li><a href="https://www.redwoodresearch.org/">Redwood Research</a> used Tinker to RL Qwen3-32B on difficult AI control tasks</li>
</ul>
<p>Tinker is now in private beta for researchers and developers. You can sign up for the Tinker waitlist <a href="https://thinkingmachines.ai/tinker">here</a>. We will be onboarding users to the platform starting today.</p>
<p>If you‚Äôre an organization interested in using Tinker, please contact us <a href="https://thinkingmachines.ai/cdn-cgi/l/email-protection#691d0007020c1b291d0100070200070e04080a0100070c1a470800">here</a>.</p>
<p>Tinker will be free to start. We will introduce usage-based pricing in the coming weeks.</p>
<p>We‚Äôre excited to see what you discover and make with Tinker!</p>

    
  </article>

  

  
  
  
  
  
  

  
  
  
  

  
  
</main>

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jane Goodall has died (1190 pts)]]></title>
            <link>https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead</link>
            <guid>45441069</guid>
            <pubDate>Wed, 01 Oct 2025 18:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead">https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead</a>, See on <a href="https://news.ycombinator.com/item?id=45441069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Jane Goodall, the trailblazing naturalist whose intimate observations of chimpanzees in the African wild produced powerful insights that transformed basic conceptions of humankind, has died. She was 91.</p><p>A tireless advocate of preserving chimpanzees‚Äô natural habitat, Goodall died on Wednesday morning in California of natural causes, the Jane Goodall Institute announced on its <a href="https://www.instagram.com/p/DPRn2HTCFYt/?igsh=NTc4MTIwNjQ2YQ%3D%3D" target="_blank">Instagram page</a>. </p><p>‚ÄúDr. Goodall‚Äôs discoveries as an ethologist revolutionized science,‚Äù the Jane Goodall Institute said in a statement. </p><p>A protege of anthropologist Louis S.B. Leakey, Goodall made history in 1960 when she discovered that chimpanzees, humankind‚Äôs closest living ancestors, made and used tools, characteristics that scientists had long thought were exclusive to humans.</p><p>She also found that chimps hunted prey, ate meat, and were capable of a range of emotions and behaviors similar to those of humans, including filial love, grief and violence bordering on warfare.</p><p>In the course of establishing one of the world‚Äôs longest-running studies of wild animal behavior at what is now Tanzania‚Äôs Gombe Stream National Park, she gave her chimp subjects names instead of numbers, a practice that raised eyebrows in the male-dominated field of primate studies in the 1960s. But within a decade, the trim British scientist with the tidy ponytail was a National Geographic heroine, whose books and films educated a worldwide audience with stories of the apes she called David Graybeard, Mr. McGregor, Gilka and Flo.</p><p>‚ÄúWhen we read about a woman who gives funny names to chimpanzees and then follows them into the bush, meticulously recording their every grunt and groom, we are reluctant to admit such activity into the big leagues,‚Äù the late biologist Stephen Jay Gould wrote of the scientific world‚Äôs initial reaction to Goodall.</p><p>But Goodall overcame her critics and produced work that Gould later characterized as ‚Äúone of the Western world‚Äôs great scientific achievements.‚Äù</p><p>Tenacious and keenly observant, Goodall paved the way for other women in primatology, including the late gorilla researcher Dian Fossey and orangutan expert Birutƒó Galdikas. She was honored in 1995 with the National Geographic Society‚Äôs Hubbard Medal, which then had been bestowed only 31 times in the previous 90 years to such eminent figures as North Pole explorer Robert E. Peary and aviator Charles Lindbergh.</p><p>In her 80s she continued to travel 300 days a year to speak to schoolchildren and others about the need to fight deforestation, preserve chimpanzees‚Äô natural habitat and promote sustainable development in Africa. She was in California as part of her speaking tour in the U.S. at the time of her death.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/4ac8360/2147483647/strip/true/crop/1024x680+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/482653b/2147483647/strip/true/crop/1024x680+0+0/resize/568x377!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/2a1995f/2147483647/strip/true/crop/1024x680+0+0/resize/768x510!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/169fbf0/2147483647/strip/true/crop/1024x680+0+0/resize/1024x680!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/f152c13/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1200w" sizes="100vw">       <img alt="Jane Goodall in Gombe National Park in Tanzania." srcset="https://ca-times.brightspotcdn.com/dims4/default/855f60f/2147483647/strip/true/crop/1024x680+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/2b83032/2147483647/strip/true/crop/1024x680+0+0/resize/568x377!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/b66c829/2147483647/strip/true/crop/1024x680+0+0/resize/768x510!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/7570df9/2147483647/strip/true/crop/1024x680+0+0/resize/1024x680!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/04e829c/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1200w" sizes="100vw" width="1200" height="797" src="https://ca-times.brightspotcdn.com/dims4/default/04e829c/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg" decoding="async" loading="lazy">   </picture>   <div>      <p>(Chase Pickering / Jane Goodall Institute)</p>   </div>   </figure> </div><p>Goodall was born April 3, 1934, in London and grew up in the English coastal town of Bournemouth. The daughter of a businessman and a writer who separated when she was a child and later divorced, she was raised in a matriarchal household that included her maternal grandmother, her mother, Vanne, some aunts and her sister, Judy.</p><p>She demonstrated an affinity for nature from a young age, filling her bedroom with worms and sea snails that she rushed back to their natural homes after her mother told her they would otherwise die.</p><p>When she was about 5, she disappeared for hours to a dark henhouse to see how chickens laid eggs, so absorbed that she was oblivious to her family‚Äôs frantic search for her. She did not abandon her study until she observed the wondrous event.</p><p>‚ÄúSuddenly with a plop, the egg landed on the straw. With clucks of pleasure the hen shook her feathers, nudged the egg with her beak, and left,‚Äù Goodall wrote almost 60 years later. ‚ÄúIt is quite extraordinary how clearly I remember that whole sequence of events.‚Äù</p><p>When finally she ran out of the henhouse with the exciting news, her mother did not scold her but patiently listened to her daughter‚Äôs account of her first scientific observation.</p><p>Later, she gave Goodall books about animals and adventure ‚Äî especially the Doctor Dolittle tales and Tarzan. Her daughter became so enchanted with Tarzan‚Äôs world that she insisted on doing her homework in a tree.</p><p>‚ÄúI was madly in love with the Lord of the Jungle, terribly jealous of his Jane,‚Äù Goodall wrote in her 1999 memoir, ‚ÄúReason for Hope: A Spiritual Journey.‚Äù ‚ÄúIt was daydreaming about life in the forest with Tarzan that led to my determination to go to Africa, to live with animals and write books about them.‚Äù</p><p>Her opportunity came after she finished high school. A week before Christmas in 1956 she was invited to visit an old school chum‚Äôs family farm in Kenya. Goodall saved her earnings from a waitress job until she had enough for a round-trip ticket.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/48fc7d0/2147483647/strip/true/crop/1992x1334+0+0/resize/320x214!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/95b8306/2147483647/strip/true/crop/1992x1334+0+0/resize/568x381!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/17a7894/2147483647/strip/true/crop/1992x1334+0+0/resize/768x515!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/1c876f0/2147483647/strip/true/crop/1992x1334+0+0/resize/1024x686!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/30c89ba/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall gives a little kiss to Tess, a 5- or 6-year-old female chimpanzee, in 1997." srcset="https://ca-times.brightspotcdn.com/dims4/default/ab5b58c/2147483647/strip/true/crop/1992x1334+0+0/resize/320x214!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/ef5412a/2147483647/strip/true/crop/1992x1334+0+0/resize/568x381!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/62ea93b/2147483647/strip/true/crop/1992x1334+0+0/resize/768x515!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/b8e4b6b/2147483647/strip/true/crop/1992x1334+0+0/resize/1024x686!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/d37bd3f/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1200w" sizes="100vw" width="1200" height="804" src="https://ca-times.brightspotcdn.com/dims4/default/d37bd3f/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG" decoding="async" loading="lazy">   </picture>   <div>      <p>(Jean-Marc Bouju / Associated Press)</p>   </div>   </figure> </div><p>She arrived in Kenya in 1957, thrilled to be living in the Africa she had ‚Äúalways felt stirring in my blood.‚Äù At a dinner party in Nairobi shortly after her arrival, someone told her that if she was interested in animals, she should meet Leakey, already famous for his discoveries in East Africa of man‚Äôs fossil ancestors.</p><p>She went to see him at what‚Äôs now the National Museum of Kenya, where he was curator. He hired her as a secretary and soon had her helping him and his wife, Mary, dig for fossils at Olduvai Gorge, a famous site in the Serengeti Plains in what is now northern Tanzania.</p><p>Leakey spoke to her of his desire to learn more about all the great apes. He said he had heard of a community of chimpanzees on the rugged eastern shore of Lake Tanganyika where an intrepid researcher might make valuable discoveries.</p><p>When Goodall told him this was exactly the kind of work she dreamed of doing, Leakey agreed to send her there.</p><p>It took Leakey two years to find funding, which gave Goodall time to study primate behavior and anatomy in London. She finally landed in Gombe in the summer of 1960.</p><p>On a rocky outcropping she called the Peak, Goodall made her first important observation. Scientists had thought chimps were docile vegetarians, but on this day about three months after her arrival, Goodall spied a group of the apes feasting on something pink. It turned out to be a baby bush pig.</p><p>Two weeks later, she made an even more exciting discovery ‚Äî the one that would establish her reputation. She had begun to recognize individual chimps, and on a rainy October day in 1960, she spotted the one with white hair on his chin. He was sitting beside a mound of red earth, carefully pushing a blade of grass into a hole, then withdrawing it and poking it into his mouth.</p><p>When he finally ambled off, Goodall hurried over for a closer look. She picked up the abandoned grass stalk, stuck it into the same hole and pulled it out to find it covered with termites. The chimp she later named David Graybeard had been using the stalk to fish for the bugs.</p><p>‚ÄúIt was hard for me to believe what I had seen,‚Äù Goodall later wrote. ‚ÄúIt had long been thought that we were the only creatures on earth that used and made tools. ‚ÄòMan the Toolmaker‚Äô is how we were defined...‚Äù What Goodall saw challenged man‚Äôs uniqueness.</p><p>When she sent her report to Leakey, he responded: ‚ÄúWe must now redefine man, redefine tool, or accept chimpanzees as human!‚Äù</p><p>Goodall‚Äôs startling finding, published in Nature in 1964, enabled Leakey to line up funding to extend her stay at Gombe. It also eased Goodall‚Äôs admission to Cambridge University to study ethology. In 1965, she became the eighth person in Cambridge history to earn a doctorate without first having a bachelor‚Äôs degree.</p><p>In the meantime, she had met and in 1964 married Hugo Van Lawick, a gifted filmmaker who had traveled to Gombe to make a documentary about her chimp project. They had a child, Hugo Eric Louis ‚Äî later nicknamed Grub ‚Äî in 1967.</p><p>Goodall later said that raising Grub, who lived at Gombe until he was 9, gave her insights into the behavior of chimp mothers. Conversely, she had ‚Äúno doubt that my observation of the chimpanzees helped me to be a better mother.‚Äù</p><p>She and Van Lawick were married for 10 years, divorcing in 1974. The following year she married Derek Bryceson, director of Tanzania National Parks. He died of colon cancer four years later.</p><p>Within a year of arriving at Gombe, Goodall had chimps literally eating out of her hands. Toward the end of her second year there, David Graybeard, who had shown the least fear of her, was the first to allow her physical contact. She touched him lightly and he permitted her to groom him for a full minute before gently pushing her hand away. For an adult male chimpanzee who had grown up in the wild to tolerate physical contact with a human was, she wrote in her 1971 book ‚ÄúIn the Shadow of Man,‚Äù ‚Äúa Christmas gift to treasure.‚Äù</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/fdcd33a/2147483647/strip/true/crop/1992x1344+0+0/resize/320x216!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/b6a5133/2147483647/strip/true/crop/1992x1344+0+0/resize/568x383!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/5652127/2147483647/strip/true/crop/1992x1344+0+0/resize/768x518!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/c9d1992/2147483647/strip/true/crop/1992x1344+0+0/resize/1024x691!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/0e0c1d4/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall shares a play with Bahati, a 3 year-old female chimpanzee" srcset="https://ca-times.brightspotcdn.com/dims4/default/d73d494/2147483647/strip/true/crop/1992x1344+0+0/resize/320x216!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/aa710d0/2147483647/strip/true/crop/1992x1344+0+0/resize/568x383!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/6f21bf4/2147483647/strip/true/crop/1992x1344+0+0/resize/768x518!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/45da23e/2147483647/strip/true/crop/1992x1344+0+0/resize/1024x691!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/dd65665/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1200w" sizes="100vw" width="1200" height="810" src="https://ca-times.brightspotcdn.com/dims4/default/dd65665/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG" decoding="async" loading="lazy">   </picture>   <div>   <p>Jane Goodall shares a play with Bahati, a 3 year-old female chimpanzee at the Sweetwaters Chimpanzee Sanctuary,  north of Nairobi Sunday December 6, 1997.</p>   <p>(Jean-Marc Bouju/Associated Press)</p>   </div>   </figure> </div><p>Her studies yielded a trove of other observations on behaviors, including etiquette (such as soliciting a pat on the rump to indicate submission) and the sex lives of chimps. She collected some of the most fascinating information on the latter by watching Flo, an older female with a bulbous nose and an amazing retinue of suitors who was bearing children well into her 40s.</p><p>Her reports initially caused much skepticism in the scientific community. ‚ÄúI was not taken very seriously by many of the scientists. I was known as a [National] Geographic cover girl,‚Äù she recalled in a CBS interview in 2012.</p><p>Her unorthodox personalizing of the chimps was particularly controversial. The editor of one of her first published papers insisted on crossing out all references to the creatures as ‚Äúhe‚Äù or ‚Äúshe‚Äù in favor of ‚Äúit.‚Äù Goodall eventually prevailed.</p><p>Her most disturbing studies came in the mid-1970s, when she and her team of field workers began to record a series of savage attacks.</p><p>The incidents grew into what Goodall called the four-year war, a period of brutality carried out by a band of male chimpanzees from a region known as the Kasakela Valley. The marauders beat and slashed to death all the males in a neighboring colony and subjugated the breeding females, essentially annihilating an entire community.</p><p>It was the first time a scientist had witnessed organized aggression by one group of non-human primates against another. Goodall said this ‚Äúnightmare time‚Äù forever changed her view of ape nature.</p><p>‚ÄúDuring the first 10 years of the study I had believed ... that the Gombe chimpanzees were, for the most part, rather nicer than human beings,‚Äù she wrote in ‚ÄúReason for Hope: A Spiritual Journey,‚Äù a 1999 book co-authored with Phillip Berman. ‚ÄúThen suddenly we found that the chimpanzees could be brutal ‚Äî that they, like us, had a dark side to their nature.‚Äù</p><p>Critics tried to dismiss the evidence as merely anecdotal. Others thought she was wrong to publicize the violence, fearing that irresponsible scientists would use the information to ‚Äúprove‚Äù that the tendency to war is innate in humans, a legacy from their ape ancestors. Goodall persisted in talking about the attacks, maintaining that her purpose was not to support or debunk theories about human aggression but to ‚Äúunderstand a little better‚Äù the nature of chimpanzee aggression.</p><p>‚ÄúMy question was: How far along our human path, which has led to hatred and evil and full-scale war, have chimpanzees traveled?‚Äù</p><p>Her observations of chimp violence marked a turning point for primate researchers, who had considered it taboo to talk about chimpanzee behavior in human terms. But by the 1980s, much chimp behavior was being interpreted in ways that would have been labeled anthropomorphism ‚Äî ascribing human traits to non-human entities ‚Äî decades earlier. Goodall, in removing the barriers, raised primatology to new heights, opening the way for research on subjects ranging from political coalitions among baboons to the use of deception by an array of primates.</p><p>Her concern about protecting chimpanzees in the wild and in captivity led her in 1977 to found the <a href="https://www.janegoodall.org/" target="_blank">Jane Goodall Institute</a> to advocate for great apes and support research and public education. She also established Roots and Shoots, a program aimed at youths in 130 countries, and TACARE, which involves African villagers in sustainable development.</p><p>She became an international ambassador for chimps and conservation in 1986 when she saw a film about the mistreatment of laboratory chimps. The secretly taped footage ‚Äúwas like looking into the Holocaust,‚Äù she told interviewer Cathleen Rountree in 1998. From that moment, she became a globe-trotting crusader for animal rights. </p><p>In the 2017 documentary ‚ÄúJane,‚Äù the producer poured through 140 hours of footage of Goodall that had been hidden away in the National Geographic archives. The film won a Los Angeles Film Critics Assn. Award, one of many honors it received.</p><div data-video-disable-history="" data-click="enhancement" data-align-center="">  <ps-youtubeplayer data-video-player="" data-player-id="f826de22fae514bee8031d59e313f3fbc" data-video-id="X6CW7dSXKWo" data-video-title="Jane Goodall discusses ‚ÄúThe Book of Hope‚Äù" data-slot-name="/21787098806/web.latimes/obituaries/video" data-lazy-offset="1.0" data-autoplay-threshold="50" data-miniplayer="" data-internal-video-id="X6CW7dSXKWo" data-ad-slot-name="/21787098806/web.latimes/obituaries/video" data-ad-provider="ima" data-ima-sdk-url="https://imasdk.googleapis.com/js/sdkloader/ima3.js" data-ima-ad-tag-url="https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&amp;gdfp_req=1&amp;env=vp&amp;output=vast&amp;unviewed_position_start=1&amp;cmsid=2652439&amp;ad_rule=0&amp;plcmt=1">  <picture> <source srcset="https://img.youtube.com/vi_webp/X6CW7dSXKWo/maxresdefault.webp" type="image/webp"> <source srcset="https://img.youtube.com/vi/X6CW7dSXKWo/maxresdefault.jpg"> <img id="yt-img-X6CW7dSXKWo" alt="" src="https://img.youtube.com/vi/X6CW7dSXKWo/hqdefault.jpg" loading="lazy" decoding="async"> </picture>       </ps-youtubeplayer> </div><p>In a <a href="https://www.latimes.com/la-oe-morrison18-2009jul18-column.html" target="_blank">ranging 2009 interview</a> with Times columnist Patt Morrison, Goodall mused on topics from traditional zoos ‚Äî she said most captive environments should be abolished ‚Äî to climate change, a battle she feared humankind was quickly losing, if not lost already. She also spoke about the power of what one human can accomplish.</p><p>‚ÄúI always say, ‚ÄòIf you would spend just a little bit of time learning about the consequences of the choices you make each day‚Äô ‚Äî what you buy, what you eat, what you wear, how you interact with people and animals ‚Äî and start consciously making choices, that would be beneficial rather than harmful.‚Äù</p><p>As the years  passed, Goodall continued to track Gombe‚Äôs chimps, accumulating enough information to draw the arcs of their lives ‚Äî from birth through sometimes troubled adolescence, maturity, illness and finally death.</p><p>She wrote movingly about how she followed Mr. McGregor, an older, somewhat curmudgeonly chimp, through his agonizing death from polio, and how the orphan Gilka survived to lonely adulthood only to have her babies snatched from her by a pair of cannibalistic female chimps.</p><div data-click="enhancement" data-align-left=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/fe7d253/2147483647/strip/true/crop/3960x2640+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/097a3cb/2147483647/strip/true/crop/3960x2640+0+0/resize/568x379!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/2cf83f8/2147483647/strip/true/crop/3960x2640+0+0/resize/768x512!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/fed4802/2147483647/strip/true/crop/3960x2640+0+0/resize/1024x683!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/66b9217/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall in San Diego." srcset="https://ca-times.brightspotcdn.com/dims4/default/e0c32f5/2147483647/strip/true/crop/3960x2640+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/7700788/2147483647/strip/true/crop/3960x2640+0+0/resize/568x379!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/fd7c124/2147483647/strip/true/crop/3960x2640+0+0/resize/768x512!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/f2aaab4/2147483647/strip/true/crop/3960x2640+0+0/resize/1024x683!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/4373298/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1200w" sizes="100vw" width="1200" height="800" src="https://ca-times.brightspotcdn.com/dims4/default/4373298/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG" decoding="async" loading="lazy">   </picture>   <div>      <p>(Sam Hodgson/The San Diego Union-Tribune)</p>   </div>   </figure> </div><p>Her reaction in 1972 to the death of Flo, a prolific female known as Gombe‚Äôs most devoted mother, suggested the depth of feeling that Goodall had for the animals. Knowing that Flo‚Äôs faithful son Flint was nearby and grieving, Goodall watched over the body all night to keep marauding bush pigs from violating her remains.</p><p>‚ÄúPeople say to me, thank you for giving them characters and personalities,‚Äù Goodall once told CBS‚Äôs ‚Äú60 Minutes.‚Äù ‚ÄúI said I didn‚Äôt give them anything. I merely translated them for people.‚Äù</p><p><i>Woo is a former Times staff writer.</i></p><div data-list-id="00000192-be42-da32-a3db-ff76fc3b0000" data-module-id="00000192-be42-da32-a3db-ff76fc3b0000" data-click="enhancement" data-align-center="">  <p data-element="element-header" data-click="liZZListTitleCTA">  <h3 data-element="element-header-title" data-counter="3">More to Read </h3>  </p>      </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Avoiding Politics (452 pts)]]></title>
            <link>https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/</link>
            <guid>45440571</guid>
            <pubDate>Wed, 01 Oct 2025 17:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/">https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/</a>, See on <a href="https://news.ycombinator.com/item?id=45440571">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Say the word ‚Äúpolitics‚Äù to most engineers and watch their face scrunch up like they just bit into a lemon. We‚Äôve all been conditioned to believe that workplace politics is this dirty game played by manipulative ladder-climbers while the ‚Äúreal‚Äù engineers focus on the code.</p>



<p>I used to think the same way. For years as an engineer, I wore my hatred of politics like a badge of honor. I was above all that nonsense. I just wanted to ship. Politics was for those other people, the ones who didn‚Äôt have what it takes technically.</p>



<p>Now I think the opposite: <strong>politics isn‚Äôt the problem; bad politics is.</strong> And pretending politics doesn‚Äôt exist? That‚Äôs how bad politics wins.</p>



<p>Politics is just how humans coordinate in groups. It‚Äôs the invisible network of relationships, influence, and informal power that exists in every organization. You can refuse to participate, but that doesn‚Äôt make it go away. It just means decisions get made without you.</p>



<p>Think about the last time a terrible technical decision got pushed through at your company. Maybe it was adopting some overcomplicated architecture, or choosing a vendor that everyone knew was wrong, or killing a project that was actually working. I bet if you dig into what happened, you‚Äôll find it wasn‚Äôt because the decision-makers were stupid. It‚Äôs because the people with the right information weren‚Äôt in the room. They ‚Äúdidn‚Äôt do politics.‚Äù</p>



<p>Meanwhile, someone who understood how influence works was in that room, making their case, building coalitions, showing they‚Äôd done their homework. And their idea won. Not because it was better, but because they showed up to play while everyone else was ‚Äútoo pure‚Äù for politics.</p>



<p>Ideas don‚Äôt speak. People do. And the people who understand how to navigate organizational dynamics, build relationships, and yes, play politics? Their ideas get heard.</p>



<p>When you build strong relationships across teams, understand what motivates different stakeholders, and know how to build consensus, you‚Äôre doing politics. When you take time to explain your technical decisions to non-technical stakeholders in language they understand, that‚Äôs politics. When you grab coffee with someone from another team to understand their challenges, that‚Äôs politics too.</p>



<p><strong>Good politics is just being strategic about relationships and influence in the service of good outcomes.</strong></p>



<p>The best technical leaders are incredibly political. They just don‚Äôt call it that. They call it ‚Äústakeholder management‚Äù or ‚Äúbuilding alignment‚Äù or ‚Äúorganizational awareness.‚Äù But it‚Äôs politics, and they‚Äôre good at it.</p>



<p>The engineers who refuse to engage with politics often complain that their companies make bad technical decisions. But they‚Äôre not willing to do what it takes to influence those decisions. They want a world where technical merit alone determines outcomes. That world doesn‚Äôt exist and never has.</p>



<p>This isn‚Äôt about becoming a scheming backstabber. As I wrote in <a href="https://terriblesoftware.org/2025/03/31/your-strengths-are-your-weaknesses/">Your Strengths Are Your Weaknesses</a>, the same trait can be positive or negative depending on how you use it. Politics is the same way. You can use political skills to manipulate and self-promote, or you can use them to get good ideas implemented and protect your team from bad decisions.</p>



<p>Here‚Äôs what good politics looks like in practice:</p>



<ol>
<li><strong>Building relationships before you need them.</strong> That random coffee with someone from the data team? Six months later, they‚Äôre your biggest advocate for getting engineering resources for your data pipeline project.</li>



<li><strong>Understanding the real incentives.</strong> Your VP doesn‚Äôt care about your beautiful microservices architecture. They care about shipping features faster. Frame your technical proposals in terms of what they actually care about.</li>



<li><strong>Managing up effectively.</strong> Your manager is juggling competing priorities you don‚Äôt see. Keep them informed about what matters, flag problems early with potential solutions, and help them make good decisions. When they trust you to handle things, they‚Äôll fight for you when it matters</li>



<li><strong>Creating win-win situations.</strong> Instead of fighting for resources, find ways to help other teams while getting what you need. It doesn‚Äôt have to be a zero-sum game.</li>



<li><strong>Being visible.</strong> If you do great work but nobody knows about it, did it really happen? Share your wins, present at all-hands, write those design docs that everyone will reference later.</li>
</ol>



<p>The alternative to good politics isn‚Äôt no politics. It‚Äôs bad politics winning by default. It‚Äôs the loud person who‚Äôs wrong getting their way because the quiet person who‚Äôs right won‚Äôt speak up. It‚Äôs good projects dying because nobody advocated for them. It‚Äôs talented people leaving because they couldn‚Äôt navigate the organizational dynamics.</p>



<p>Stop pretending you‚Äôre above politics. You‚Äôre not. Nobody is. The only question is whether you‚Äôll get good at it or keep losing to people who already are.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenTSLM: Language models that understand time series (239 pts)]]></title>
            <link>https://www.opentslm.com/</link>
            <guid>45440431</guid>
            <pubDate>Wed, 01 Oct 2025 17:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opentslm.com/">https://www.opentslm.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45440431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>The Future of AI Delivered on Time</p><div><p>Paper Released Sep 30, 2025</p><p>Stanford Repo Released Oct 1, 2025</p></div></div><section><p>AI understands text, images, audio, and video.<br>But the real world runs on time.</p><p>Every heartbeat, price tick, sensor pulse, machine log, and user click is a temporal signal.<br>Current models can't reason about them.</p><p>We're changing that.</p></section><section><h2>A New Class of Foundation Models</h2><div><p><span>Time-Series Language Models (TSLMs)</span> are multimodal foundation models with time series as a native modality, next to text, enabling direct reasoning, explanation, and forecasting over temporal data in natural language.</p><p>Our research shows order-of-magnitude gains in temporal reasoning while running on smaller, faster backbones. TSLMs are not an add-on. They're a new modality for AI.</p></div></section><section><h2>Open Core, Frontier Edge</h2><div><p><span>OpenTSLM:</span> Lightweight base models trained on public data, released openly. They set the standard for temporal reasoning and power a global developer and research ecosystem.</p><p><span>Frontier TSLMs:</span> Advanced proprietary models trained on specialized data, delivering enterprise-grade performance and powering APIs, fine-tuning, and vertical solutions.</p></div></section><section><h2>Our Vision</h2><div><p>We're building the temporal interface for AI - the layer that connects continuous real-world signals to intelligent decisions and autonomous agents.</p><p>A universal TSLM will power proactive healthcare, adaptive robotics, resilient infrastructure, and new forms of human-AI collaboration.</p></div></section><section><h2>About Us</h2><p>OpenTSLM is a team of scientists, engineers, and builders from ETH, Stanford, Harvard, Cambridge, TUM, CDTM, Google, Meta, AWS, and beyond. We are the original authors of the OpenTSLM paper.</p></section><section><h2><p>Discover how TSLMs could transform</p></h2></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Solar leads EU electricity generation as renewables hit 54% (271 pts)]]></title>
            <link>https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/</link>
            <guid>45440387</guid>
            <pubDate>Wed, 01 Oct 2025 17:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/">https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/</a>, See on <a href="https://news.ycombinator.com/item?id=45440387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="900" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?quality=82&amp;strip=all&amp;w=1600" alt="EU electricity" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">			<figcaption>
				Photo by Wolfgang Weiser on <a href="https://www.pexels.com/photo/historic-war-memorial-in-salzkotten-germany-30762864/" rel="nofollow">Pexels.com</a>			</figcaption>
			</figure>

<p>More than half of the European Union‚Äôs (EU) electricity came from renewables in the second quarter of 2025, and solar is leading from the front.</p>



<p>According to new data from Eurostat, renewable energy sources generated 54% of the EU‚Äôs net electricity in Q2 2025, up from 52.7% year-over-year. The growth came mainly from solar, which produced 122,317 gigawatt-hours (GWh) ‚Äì nearly 20% of the total electricity generation mix.</p>



<p>June 2025 was a milestone month: Solar became the EU‚Äôs single largest electricity source for the first time ever. It supplied 22% of all power that month, edging out nuclear (21.6%), wind (15.8%), hydro (14.1%), and natural gas (13.8%).</p>



<p>Some countries are already nearly 100% renewable. Denmark led with an impressive 94.7% share of renewables in net electricity generated, followed by Latvia (93.4%), Austria (91.8%), Croatia (89.5%), and Portugal (85.6%). At the other end of the spectrum, Slovakia (19.9%), Malta (21.2%), and the Czech Republic (22.1%) lagged behind.</p>	
	



<p>In total, 15 EU countries saw their share of renewable generation rise year-over-year. Luxembourg (+13.5 percentage points) and Belgium (+9.1 pp) posted the most significant gains, driven largely by solar power growth.</p>



<p>Across the EU, solar made up 36.8% of renewable generation, followed by wind at 29.5%, hydro at 26%, biomass at 7.3%, and geothermal at 0.4%.</p>



<p><strong>Read more:</strong> <a href="https://electrek.co/2025/09/24/eia-solar-and-wind-crush-coal-with-20-percent-more-power-in-2025/">EIA: Solar and wind crush coal with 20% more power in 2025</a></p>



<figure><a href="https://www.energysage.com/landing/home-solar/p/electrek-rsm-ml/?utm_medium=Partner&amp;utm_source=Electrek" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="750" height="150" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png 750w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=150,30 150w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=300,60 300w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=350,70 350w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=140,28 140w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<hr>



<p><strong><em>The 30% federal solar tax credit is ending this year. If you‚Äôve ever considered going solar, now‚Äôs the time to act. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out </em></strong><a href="https://c32b704.na1.hs-sales-engage.com/Ctc/P+23284/c32B704/JlF3crJ5W8wLKSR6lZ3p-W7s8QC84nlPDsW35x5rq5vFtfyW88cj9v1vtBqZVbfGXn1xzh51W8jvN5t8yhpLdW57_shc5Rp3MdMN0T8GbTR9LW5kbjcl41XSlfW1DWv0v4vFzCtW8zy2kd45l-lnW8TNZ_52QnSx-W54zS-f2SKtm5W5WK2df426XsKV7j3fd6CkxT7W7x6GCb20V3brW6qqHST3bthfYW6CpFKd7_yQ0XW2ysWt869bCphW6r8YtG4GrsVkW46V-MQ5bp2VwW5m6Bnn8b0H0_VsQ6Xw673G4GW2FfPnr6RDKb7W7dQjKN7Mqbk0W2D2_x791FrC9W84mN5P1JPzsPW5Ymmh58m7YHdW2RdHWF257Zzhf4hJ8JP04"><strong><em>EnergySage</em></strong></a><strong><em>, a free service that makes it easy for you to go solar. It has hundreds of pre-vetted solar installers competing for your business, ensuring you get high-quality solutions and save 20-30% compared to going it alone. Plus, it‚Äôs free to use, and you won‚Äôt get sales calls until you select an installer and share your phone number with them.&nbsp;</em></strong></p>



<p><strong><em>Your personalized solar quotes are easy to compare online and you‚Äôll get access to unbiased Energy Advisors to help you every step of the way. </em></strong><a href="https://c32b704.na1.hs-sales-engage.com/Ctc/P+23284/c32B704/JlF3crJ5W8wLKSR6lZ3p-W7s8QC84nlPDsW35x5rq5vFtfyW88cj9v1vtBqZVbfGXn1xzh51W8jvN5t8yhpLdW57_shc5Rp3MdMN0T8GbTR9LW5kbjcl41XSlfW1DWv0v4vFzCtW8zy2kd45l-lnW8TNZ_52QnSx-W54zS-f2SKtm5W5WK2df426XsKV7j3fd6CkxT7W7x6GCb20V3brW6qqHST3bthfYW6CpFKd7_yQ0XW2ysWt869bCphW6r8YtG4GrsVkW46V-MQ5bp2VwW5m6Bnn8b0H0_VsQ6Xw673G4GW2FfPnr6RDKb7W7dQjKN7Mqbk0W2D2_x791FrC9W84mN5P1JPzsPW5Ymmh58m7YHdW2RdHWF257Zzhf4hJ8JP04"><strong><em>Get started here</em></strong></a><strong><em>.</em></strong></p>
	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The RAG Obituary: Killed by agents, buried by context windows (163 pts)]]></title>
            <link>https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents</link>
            <guid>45439997</guid>
            <pubDate>Wed, 01 Oct 2025 16:51:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents">https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents</a>, See on <a href="https://news.ycombinator.com/item?id=45439997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I‚Äôve been working in AI and search for a decade. First building Doctrine, the largest European legal search engine and now building </span><a href="https://fintool.com/" rel="">Fintool</a><span>, an AI-powered financial research platform that helps institutional investors analyze companies, screen stocks, and make investment decisions. </span></p><p>After three years of building, optimizing, and scaling LLMs with retrieval-augmented generation (RAG) systems, I believe we‚Äôre witnessing the twilight of RAG-based architectures. As context windows explode and agent-based architectures mature, my controversial opinion is that the current RAG infrastructure we spent so much time building and optimizing is on the decline.</p><p>In late 2022, ChatGPT took the world by storm. People started endless conversations, delegating crucial work only to realize that the underlying model, GPT-3.5 could only handle 4,096 tokens... roughly six pages of text!</p><p><span>The AI world faced a fundamental problem: </span><strong>how do you make an intelligent system work with knowledge bases that are orders of magnitude larger than what it can read at once?</strong></p><p>The answer became Retrieval-Augmented Generation (RAG), an architectural pattern that would dominate AI for the next three years. </p><p>GPT-3.5 could handle 4,096 token and the next model GPT-4 doubled it to 8,192 tokens, about twelve pages. This wasn‚Äôt just inconvenient; it was architecturally devastating. </p><p><span>Consider the numbers: </span><strong>A single SEC 10-K filing contains approximately 51,000 tokens (130+ pages).</strong></p><p>With 8,192 tokens, you could see less than 16% of a 10-K filing. It‚Äôs like reading a financial report through a keyhole!</p><p>RAG emerged as an elegant solution borrowed directly from search engines. Just as Google displays 10 blue links with relevant snippets for your query, RAG retrieves the most pertinent document fragments and feeds them to the LLM for synthesis.</p><p><span>The core idea is beautifully simple: </span><strong>if you can‚Äôt fit everything in context, find the most relevant pieces and use those</strong><span>. It turns LLMs into sophisticated search result summarizers.</span></p><p>Basically, LLMs can‚Äôt read the whole book but they can know who dies at the end; convenient!</p><p>Long documents need to be chunked into pieces and it‚Äôs when problems start. Those digestible pieces are typically 400-1,000 tokens each which is basically 300-750 words.</p><p>The problem? It isn‚Äôt as simple as cutting every 500 words.</p><p>Consider chunking a typical SEC 10-K annual report. The document has a complex hierarchical structure:</p><p>- Item 1: Business Overview (10-15 pages)</p><p>- Item 1A: Risk Factors (20-30 pages)</p><p>- Item 7: Management‚Äôs Discussion and Analysis (30-40 pages)</p><p>- Item 8: Financial Statements (40-50 pages)</p><p>After naive chunking at 500 tokens, critical information gets scattered:</p><p>- Revenue recognition policies split across 3 chunks</p><p>- A risk factor explanation broken mid-sentence</p><p>- Financial table headers separated from their data</p><p>- MD&amp;A narrative divorced from the numbers it‚Äôs discussing</p><p>If you search for ‚Äúrevenue growth drivers,‚Äù you might get a chunk mentioning growth but miss the actual numerical data in a different chunk, or the strategic context from MD&amp;A in yet another chunk!</p><p>At Fintool, we‚Äôve developed sophisticated chunking strategies that go beyond naive text splitting:</p><p><span>- </span><strong>Hierarchical Structure Preservation</strong><span>: We maintain the nested structure from Item 1 (Business) down to sub-sections like geographic segments, creating a tree-like document representation</span></p><p><span>- </span><strong>Table Integrity</strong><span>: Financial tables are never split‚Äîincome statements, balance sheets, and cash flow statements remain atomic units with headers and data together</span></p><p><span>- </span><strong>Cross-Reference Preservation</strong><span>: We maintain links between narrative sections and their corresponding financial data, preserving the ‚ÄúSee Note X‚Äù relationships</span></p><p><span>- </span><strong>Temporal Coherence</strong><span>: Year-over-year comparisons and multi-period analyses stay together as single chunks</span></p><p><span>- </span><strong>Footnote Association</strong><span>: Footnotes remain connected to their referenced items through metadata linking</span></p><p>Each chunk at Fintool is enriched with extensive metadata:</p><p>- Filing type (10-K, 10-Q, 8-K)</p><p>- Fiscal period and reporting date</p><p>- Section hierarchy (Item 7 &gt; Liquidity &gt; Cash Position)</p><p>- Table identifiers and types</p><p>- Cross-reference mappings</p><p>- Company identifiers (CIK, ticker)</p><p>- Industry classification codes</p><p><span>This allows for more accurate retrieval but </span><strong>even our intelligent chunking can‚Äôt solve the fundamental problem: we‚Äôre still working with fragments instead of complete documents!</strong></p><p>Once you have the chunks, you need a way to search them. One way is to embed your chunks.</p><p>Each chunk is converted into a high‚Äëdimensional vector (typically 1,536 dimensions in most embedding models). These vectors live in a space where, theoretically, similar concepts are close together.</p><p>When a user asks a question, that question also becomes a vector. The system finds the chunks whose vectors are closest to the query vector using cosine similarity.</p><p><strong>It‚Äôs elegant in theory and in practice, it‚Äôs a nightmare of edge cases.</strong></p><p>Embedding models are trained on general text and struggle with specific terminologies. They find similarities but they can‚Äôt distinguish between ‚Äúrevenue recognition‚Äù (accounting policy) and ‚Äúrevenue growth‚Äù (business performance).</p><p><span>Consider that example: Query: ‚Äú</span><em>What is the company‚Äôs litigation exposure</em><span>?</span></p><p>RAG searches for ‚Äúlitigation‚Äù and returns 50 chunks:</p><p>- Chunks 1-10: Various mentions of ‚Äúlitigation‚Äù in boilerplate risk factors</p><p>- Chunks 11-20: Historical cases from 2019 (already settled)</p><p>- Chunks 21-30: Forward-looking safe harbor statements</p><p>- Chunks 31-40: Duplicate descriptions from different sections</p><p>- Chunks 41-50: Generic ‚Äúwe may face litigation‚Äù warnings</p><p><strong>What RAG Reports:</strong><span> $500M in litigation (from Legal Proceedings section)</span></p><p><strong>What‚Äôs Actually There:</strong></p><p>- $500M in Legal Proceedings (Item 3)</p><p>- $700M in Contingencies note (‚Äùnot material individually‚Äù)</p><p>- $1B new class action in Subsequent Events</p><p>- $800M indemnification obligations (different section)</p><p>- $2B probable losses in footnotes (keyword ‚Äúprobable‚Äù not ‚Äúlitigation‚Äù)</p><p>The actual Exposure is $5.1B. 10x what RAG found. Oupsy! By late 2023, most builders realized pure vector search wasn‚Äôt enough.</p><p>Enter hybrid search: combine semantic search (embeddings) with the traditional keyword search (BM25). This is where things get interesting.</p><p>BM25 (Best Matching 25) is a probabilistic retrieval model that excels at exact term matching. Unlike embeddings, BM25:</p><p><span>- </span><strong>Rewards Exact Matches</strong><span>: When you search for ‚ÄúEBITDA,‚Äù you get documents with ‚ÄúEBITDA,‚Äù not ‚Äúoperating income‚Äù or ‚Äúearnings‚Äù</span></p><p><span>- </span><strong>Handles Rare Terms Better</strong><span>: Financial jargon like ‚ÄúCECL‚Äù (Current Expected Credit Losses) or ‚ÄúASC 606‚Äù gets proper weight</span></p><p><span>- </span><strong>Document Length Normalization</strong><span>: Doesn‚Äôt penalize longer documents</span></p><p><span>- </span><strong>Term Frequency Saturation</strong><span>: Multiple mentions of ‚Äúrevenue‚Äù don‚Äôt overshadow other important terms</span></p><p>At Fintool, we‚Äôve built a sophisticated hybrid search system:</p><p><span>1. </span><strong>Parallel Processing</strong><span>: We run semantic and keyword searches simultaneously</span></p><p><span>2. </span><strong>Dynamic Weighting</strong><span>: Our system adjusts weights based on query characteristics:</span></p><p>- Specific financial metrics? BM25 gets 70% weight</p><p>- Conceptual questions? Embeddings get 60% weight</p><p>- Mixed queries? 50/50 split with result analysis</p><p><span>3. </span><strong>Score Normalization</strong><span>: Different scoring scales are normalized using:</span></p><p>- Min-max scaling for BM25 scores</p><p>- Cosine similarity already normalized for embeddings</p><p>- Z-score normalization for outlier handling</p><p>So at the end the embeddings search and the keywords search retrieve chunks and the search engine combines them using Reciprocal Rank Fusion. RRF merges rankings so items that consistently appear near the top across systems float higher, even if no system put them at #1!</p><p>So now you think it‚Äôs done right? But hell no!</p><p>Here‚Äôs what nobody talks about: even after all that retrieval work, you‚Äôre not done. You need to rerank the chunks one more time to get a good retrieval and it‚Äôs not easy. Rerankers are ML models that take the search results and reorder them by relevance to your specific query limiting the number of chunks sent to the LLM.</p><p><strong>Not only LLMs are context poor, they also struggle when dealing with too much information</strong><span>. It‚Äôs vital to reduce the number of chunks sent to the LLM for the final answer.</span></p><p><strong>The Reranking Pipeline:</strong></p><p>1. Initial search retrieval with embeddings + keywords gets you 100-200 chunks</p><p>2. Reranker ranks the top 10</p><p>3. Top 10 are fed to the LLM to answer the question</p><p>Here is the challenge with reranking:</p><p><span>- </span><strong>Latency Explosion</strong><span>: Rerank adds between 300-2000ms per query. Ouch.</span></p><p><span>- </span><strong>Cost Multiplication</strong><span>: it adds significant extra cost to every query. For instance, Cohere Rerank 3.5 costs $2.00 per 1,000 search units, making reranking expensive.</span></p><p><span>- </span><strong>Context Limits</strong><span>: Rerankers typically handle few chunks (Cohere Rerank supports only 4096 tokens), so if you need to re-rank more than that, you have to split it into different parallel API calls and merge them!</span></p><p><span>- </span><strong>Another Model to Manage</strong><span>: One more API, one more failure point</span></p><p>Re-rank is one more step in a complex pipeline.</p><p>What I find difficult with RAG is what I call the ‚Äúcascading failure problem‚Äù.</p><p>1. Chunking can fail (split tables) or be too slow (especially when you have to ingest and chunk gigabytes of data in real-time)</p><p>2. Embedding can fail (wrong similarity)</p><p>3. BM25 can fail (term mismatch)</p><p>4. Hybrid fusion can fail (bad weights)</p><p>5. Reranking can fail (wrong priorities)</p><p>Each stage compounds the errors of the previous stage. Beyond the complexity of hybrid search itself, there‚Äôs an infrastructure burden that‚Äôs rarely discussed.</p><p>Running production Elasticsearch is not easy. You‚Äôre looking at maintaining TB+ of indexed data for comprehensive document coverage, which requires 128-256GB RAM minimum just to get decent performance. The real nightmare comes with re-indexing. Every schema change forces a full re-indexing that takes 48-72 hours for large datasets. On top of that, you‚Äôre constantly dealing with cluster management, sharding strategies, index optimization, cache tuning, backup and disaster recovery, and version upgrades that regularly include breaking changes.</p><p>Here are some structural limitations:</p><p><span>1. </span><strong>Context Fragmentation</strong></p><p>- Long documents are interconnected webs, not independent paragraphs</p><p>- A single question might require information from 20+ documents</p><p>- Chunking destroys these relationships permanently</p><p><span>2. </span><strong>Semantic Search Fails on Numbers</strong></p><p>- ‚Äú$45.2M‚Äù and ‚Äú$45,200,000‚Äù have different embeddings</p><p>- ‚ÄúRevenue increased 10%‚Äù and ‚ÄúRevenue grew by a tenth‚Äù rank differently</p><p>- Tables full of numbers have poor semantic representations</p><p><span>3. </span><strong>No Causal Understanding</strong></p><p>- RAG can‚Äôt follow ‚ÄúSee Note 12‚Äù ‚Üí Note 12 ‚Üí Schedule K</p><p>- Can‚Äôt understand that discontinued operations affect continuing operations</p><p>- Can‚Äôt trace how one financial item impacts another</p><p><span>4. </span><strong>The Vocabulary Mismatch Problem</strong></p><p>- Companies use different terms for the same concept</p><p>- ‚ÄúAdjusted EBITDA‚Äù vs ‚ÄúOperating Income Before Special Items‚Äù</p><p>- RAG retrieves based on terms, not concepts</p><p><span>5. </span><strong>Temporal Blindness</strong></p><p>- Can‚Äôt distinguish Q3 2024 from Q3 2023 reliably</p><p>- Mixes current period with prior period comparisons</p><p>- No understanding of fiscal year boundaries</p><p>These aren‚Äôt minor issues. They‚Äôre fundamental limitations of the retrieval paradigm.</p><p>Three months ago I stumbled on an innovation on retrievial that blew my mind</p><p>In May 2025, Anthropic released Claude Code, an AI coding agent that works in the terminal. At first, I was surprised by the form factor. A terminal? Are we back in 1980? no UI?</p><p>Back then, I was using Cursor, a product that excelled at traditional RAG. I gave it access to my codebase to embed my files and Cursor ran a search n my codebase before answering my query. Life was good. But when testing Claude Code, one thing stood out:</p><p><strong>It was better and faster and not because their RAG was better but because there was no RAG.</strong></p><p>Instead of a complex pipeline of chunking, embedding, and searching, Claude Code uses direct filesystem tools:</p><p><span>1. </span><strong>Grep (Ripgrep)</strong><span> </span></p><p>- Lightning-fast regex search through file contents</p><p>- No indexing required. It searches live files instantly</p><p>- Full regex support for precise pattern matching</p><p>- Can filter by file type or use glob patterns</p><p>- Returns exact matches with context lines</p><p><span>2. </span><strong>Glob</strong><span> </span></p><p>- Direct file discovery by name patterns</p><p>- Finds files like `**/*.py` or `src/**/*.ts` instantly</p><p>- Returns files sorted by modification time (recency bias)</p><p>- Zero overhead‚Äîjust filesystem traversal</p><p><span>3. </span><strong>Task Agents</strong></p><p>- Autonomous multi-step exploration</p><p>- Handle complex queries requiring investigation</p><p>- Combine multiple search strategies adaptively</p><p>- Build understanding incrementally</p><p>- Self-correct based on findings</p><p>By the way, Grep was invented in 1973. It‚Äôs so... primitive. And that‚Äôs the genius of it.</p><p><strong>Claude Code doesn‚Äôt retrieve. It investigates:</strong></p><p>- Runs multiple searches in parallel (Grep + Glob simultaneously)</p><p>- Starts broad, then narrows based on discoveries</p><p>- Follows references and dependencies naturally</p><p>- No embeddings, no similarity scores, no reranking</p><p><strong>It‚Äôs simple, it‚Äôs fast and it‚Äôs based on a new assumption that LLMs will go from context poor to context rich.</strong></p><p>Claude Code proved that with sufficient context and intelligent navigation, you don‚Äôt need RAG at all. The agent can:</p><p>- Load entire files or modules directly</p><p>- Follow cross-references in real-time</p><p>- Understand structure and relationships</p><p>- Maintain complete context throughout investigation</p><p>This isn‚Äôt just better than RAG‚Äîit‚Äôs a fundamentally different paradigm. And what works for code can work for any long documents that are not coding files.</p><p>The context window explosion made Claude Code possible:</p><p><strong>2022-2025 Context-Poor Era:</strong></p><p>- GPT-4: 8K tokens (~12 pages)</p><p>- GPT-4-32k: 32K tokens (~50 pages)</p><p><strong>2025 and beyond Context Revolution:</strong></p><p>- Claude Sonnet 4: 200k tokens (~700 pages)</p><p>- Gemini 2.5: 1M tokens (~3,000 pages)</p><p>- Grok 4-fast: 2M tokens (~6,000 pages)</p><p>At 2M tokens, you can fit an entire year of SEC filings for most companies.</p><p>The trajectory is even more dramatic: we‚Äôre likely heading toward 10M+ context windows by 2027, with Sam Altman hinting at billions of context tokens on the horizon. This represents a fundamental shift in how AI systems process information. Equally important, attention mechanisms are rapidly improving‚ÄîLLMs are becoming far better at maintaining coherence and focus across massive context windows without getting ‚Äúlost‚Äù in the noise.</p><p>Claude Code demonstrated that with enough context, search becomes navigation:</p><p>- No need to retrieve fragments when you can load complete files</p><p>- No need for similarity when you can use exact matches</p><p>- No need for reranking when you follow logical paths</p><p>- No need for embeddings when you have direct access</p><p>It‚Äôs mind-blowing. LLMs are getting really good at agentic behaviors meaning they can organize their work into tasks to accomplish an objective.</p><p>Here‚Äôs what tools like ripgrep bring to the search table:</p><p><span>- </span><strong>No Setup</strong><span>: No index. No overhead. Just point and search.</span></p><p><span>- </span><strong>Instant Availability</strong><span>: New documents are searchable the moment they hit the filesystem (no indexing latency!)</span></p><p><span>- </span><strong>Zero Maintenance</strong><span>: No clusters to manage, no indices to optimize, no RAM to provision</span></p><p><span>- </span><strong>Blazing Fast</strong><span>: For a 100K line codebase, Elasticsearch needs minutes to index. Ripgrep searches it in milliseconds with zero prep.</span></p><p><span>- </span><strong>Cost</strong><span>: $0 infrastructure cost vs a lot of $$$ for Elasticsearch</span></p><p>So back to our previous example on SEC filings. An agent can SEC filing structure intrinsically:</p><p><span>- </span><strong>Hierarchical Awareness</strong><span>: Knows that Item 1A (Risk Factors) relates to Item 7 (MD&amp;A)</span></p><p><span>- </span><strong>Cross-Reference Following</strong><span>: Automatically traces ‚ÄúSee Note 12‚Äù references</span></p><p><span>- </span><strong>Multi-Document Coordination</strong><span>: Connects 10-K, 10-Q, 8-K, and proxy statements</span></p><p><span>- </span><strong>Temporal Analysis</strong><span>: Compares year-over-year changes systematically</span></p><p>For searches across thousands of companies or decades of filings, it might still use hybrid search, but now as a tool for agents:</p><p>- Initial broad search using hybrid retrieval</p><p>- Agent loads full documents for top results</p><p>- Deep analysis within full context</p><p>- Iterative refinement based on findings</p><p>My guess is traditional RAG is now a search tool among others and that agents will always prefer grep and reading the whole file because they are context rich and can handle long-running tasks.</p><p>Consider our $6.5B lease obligation question as an example:</p><p><strong>Step 1: Find ‚Äúlease‚Äù in main financial statements</strong></p><p>‚Üí Discovers ‚ÄúSee Note 12‚Äù</p><p><strong>Step 2: Navigate to Note 12</strong></p><p>‚Üí Finds ‚Äúexcluding discontinued operations (Note 23)‚Äù</p><p><strong>Step 3: Check Note 23</strong></p><p>‚Üí Discovers $2B additional obligations</p><p><strong>Step 4: Cross-reference with MD&amp;A</strong></p><p>‚Üí Identifies management‚Äôs explanation and adjustments</p><p><strong>Step 5: Search for ‚Äúsubsequent events‚Äù</strong></p><p>‚Üí Finds post-balance sheet $500M lease termination</p><p><strong>Final answer: $5B continuing + $2B discontinued - $500M terminated = $6.5B</strong></p><p>The agent follows references like a human analyst would. No chunks. No embeddings. No reranking. Just intelligent navigation.</p><p>Basically, RAG is like a research assistant with perfect memory but no understanding:</p><p>- ‚ÄúHere are 50 passages that mention debt‚Äù</p><p>- Can‚Äôt tell you if debt is increasing or why</p><p>- Can‚Äôt connect debt to strategic changes</p><p>- Can‚Äôt identify hidden obligations</p><p>- Just retrieves text, doesn‚Äôt comprehend relationships</p><p>Agentic search is like a forensic accountant:</p><p>- Follows the money systematically</p><p>- Understands accounting relationships (assets = liabilities + equity)</p><p>- Identifies what‚Äôs missing or hidden</p><p>- Connects dots across time periods and documents</p><p>- Challenges management assertions with data</p><p><strong>1. Increasing Document Complexity</strong></p><p>- Documents are becoming longer and more interconnected</p><p>- Cross-references and external links are proliferating</p><p>- Multiple related documents need to be understood together</p><p>- Systems must follow complex trails of information</p><p><strong>2. Structured Data Integration</strong></p><p>- More documents combine structured and unstructured data</p><p>- Tables, narratives, and metadata must be understood together</p><p>- Relationships matter more than isolated facts</p><p>- Context determines meaning</p><p><strong>3. Real-Time Requirements</strong></p><p>- Information needs instant processing</p><p>- No time for re-indexing or embedding updates</p><p>- Dynamic document structures require adaptive approaches</p><p>- Live data demands live search</p><p><strong>4. Cross-Document Understanding</strong></p><p>Modern analysis requires connecting multiple sources:</p><p>- Primary documents</p><p>- Supporting materials</p><p>- Historical versions</p><p>- Related filings</p><p>RAG treats each document independently. Agentic search builds cumulative understanding.</p><p><strong>5. Precision Over Similarity</strong></p><p>- Exact information matters more than similar content</p><p>- Following references beats finding related text</p><p>- Structure and hierarchy provide crucial context</p><p>- Navigation beats retrieval</p><p>The evidence is becoming clear. While RAG served us well in the context-poor era, agentic search represents a fundamental evolution. The potential benefits of agentic search are compelling:</p><p>- Elimination of hallucinations from missing context</p><p>- Complete answers instead of fragments</p><p>- Faster insights through parallel exploration</p><p>- Higher accuracy through systematic navigation</p><p>- Massive infrastructure cost reduction</p><p>- Zero index maintenance overhead</p><p>The key insight? Complex document analysis‚Äîwhether code, financial filings, or legal contracts‚Äîisn‚Äôt about finding similar text. It‚Äôs about understanding relationships, following references, and maintaining precision. The combination of large context windows and intelligent navigation delivers what retrieval alone never could.</p><p><strong>RAG was a clever workaround for a context-poor era</strong><span>. It helped us bridge the gap between tiny windows and massive documents, but it was always a band-aid. The future won‚Äôt be about splitting documents into fragments and juggling embeddings. It will be about agents that can navigate, reason, and hold entire corpora in working memory.</span></p><p>We are entering the post-retrieval age. The winners will not be the ones who maintain the biggest vector databases, but the ones who design the smartest agents to traverse abundant context and connect meaning across documents. In hindsight, RAG will look like training wheels. Useful, necessary, but temporary.</p><p>The next decade of AI search will belong to systems that read and reason end-to-end. Retrieval isn‚Äôt dead‚Äîit‚Äôs just been demoted.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Codeberg Reaches 300k Projects (205 pts)]]></title>
            <link>https://codeberg.org/</link>
            <guid>45439955</guid>
            <pubDate>Wed, 01 Oct 2025 16:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeberg.org/">https://codeberg.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45439955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<header>
		
	</header>

	<section id="home-section-about">
		<div>
				<div>
					<h3>NON-PROFIT</h3>
					<p>
						Codeberg is maintained by the non-profit organization <b>Codeberg e.V.</b>,
						based in <b>Berlin, Germany</b>. For us, supporting the commons comes <b>first</b>.
					</p>
					<p>
						<b>
							 Its future is in the hands of its users. You can help too!
						</b>
					</p>
				</div>
				<div>
					<h3>COMMUNITY</h3>
					<p>
						We are more than just Git hosting: Our community is comprised of like-minded
						developers, artists, academics, hobbyists and professionals.
					</p>
					<p>
						<b>
							We celebrate free culture, openness and creativity.
						</b>
					</p>
				</div>
				<div>
					<h3>RESPECT</h3>
					<p>
						No tracking. No third-party cookies. No profiteering.
						Everything runs on servers that we control. Your data is <b>not</b> for sale.
					</p>
					<p>
						<b>
							Hosted in Europe, we welcome the world.
						</b>
					</p>
				</div>
				
					
				
			</div>

		<div>
				<h4>POWERED BY</h4>
				
			</div>
	</section>

	<section id="home-section-support">
		<h3>Your support helps us grow!</h3>
		<div>
			<a href="https://join.codeberg.org/">
				
				Become a member
			</a>
			<p>
				Our non-profit structure reinforces our independence. Your donations and contributions sustain our community.
				Help us achieve our mission by joining Codeberg e.V. as a supporting or active member with full voting rights!
			</p>
		</div>
		<hr>
		<div>
			<a href="https://docs.codeberg.org/improving-codeberg/#donate-to-codeberg">
				
				Fund our project
			</a>
			<p>
				Free as in freedom, not as in beer! Maintaining our systems and developing our software has its costs, which
				are backed by optional donations. We appreciate them a lot, as they help provide a better service for everyone.
			</p>
		</div>
		<hr>
		<div>
			<a href="https://docs.codeberg.org/improving-codeberg/#contribute-to-codeberg">
				
				Develop Codeberg
			</a>
			<p>
				Powered by Free Software! Get involved with Codeberg and help improve your experience. We
				are always looking for contributions to our projects and services.
			</p>
		</div>
	</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DuckDuckGo Donates $25,000 to The Perl and Raku Foundation v2025 (152 pts)]]></title>
            <link>https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/</link>
            <guid>45439883</guid>
            <pubDate>Wed, 01 Oct 2025 16:42:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/">https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45439883">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              
              <p>Oct 1, 2025 by
              
              
                
                
                <a href="#author-bio-olaf-alders">Olaf Alders</a>
              
              </p>
               <img alt="" src="https://www.perl.com/images/duck-duck-go/DuckDuckGo-Logo-1.png">
                <p>For the second consecutive year, The Perl and Raku Foundation (TPRF) is
overjoyed to announce <a href="https://spreadprivacy.com/2025-duckduckgo-charitable-donations/">a donation of USD 25,000 from
DuckDuckGo</a>.</p>
<blockquote>
<p>DuckDuckGo has demonstrated how Perl and its ecosystem can deliver power and
scale to drive the DuckDuckGo core systems, plug-in framework and Instant
Answers. The Foundation is grateful that DuckDuckGo recognises the importance
of Perl, and for their generous funding support for a second year through
their charitable donations programme.</p></blockquote>
<p>‚Äì Stuart J Mackintosh, President of The Perl and Raku Foundation</p>
<p><a href="https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation/">Last year‚Äôs donation of USD 25,000 from
DuckDuckGo</a>
was instrumental in helping to fund the foundation‚Äôs Core Perl Maintenance Fund
and this year‚Äôs donation will help to fund more of the same crucial work that
keeps the Perl language moving forward.</p>
<p><img src="https://www.perl.com/images/duck-duck-go/fireworks.jpg" alt="Fireworks celebration"></p>
<p><a href="https://metacpan.org/author/PEVANS">Paul ‚ÄúLeoNerd‚Äù Evans</a> is one of the
developers who gets regular funding from the Perl Core Maintenance Fund. Here
is a short list of just some of the many contributions which Paul has made to
core Perl as part of the maintenance fund work:</p>
<hr>
<ul>
<li>The <a href="https://perldoc.perl.org/builtin">builtin</a> module (5.36), making
available many new useful language-level utilities that were previously
loaded from modules like <a href="https://metacpan.org/pod/Scalar::Util">Scalar::Util</a></li>
<li>The complete <a href="https://perldoc.perl.org/feature#The-'class'-feature">feature
‚Äòclass‚Äô</a> system
(5.38), adding proper object-orientation syntax and abilities</li>
<li>Lexical method support (5.42), adding <code>my method</code> and
the <code>$obj-&gt;&amp;method</code> invocation syntax for better object encapsulation</li>
<li>Stabilising some of the recent experiments - signatures (5.36),
try/catch (5.40), foreach on multiple vars (5.40)</li>
<li>Ability to use the //= and ||= operators in signatures (5.38),
performance improvements and named parameters (upcoming in next
release)</li>
<li>The new <a href="https://perldoc.perl.org/functions/any">any</a> and
<a href="https://perldoc.perl.org/functions/all">all</a> keywords (5.42)</li>
</ul>
<hr>
<p>We look forward to many more innovative contributions from Paul over the coming
year.</p>
<p>While TPRF never takes continued support for granted, when it does arrive, it
allows the foundation to plan for the future with much greater confidence.
Multi-year partnerships with our sponsors allow us to continue to prioritize
important work, knowing that we will have the runway that we need to fund the
work which helps to sustain the Perl Language and its associated communities.</p>
<p>For more information on how to become a sponsor, please contact:
<a href="mailto:olaf@perlfoundation.org">olaf@perlfoundation.org</a></p>
<hr>
<p><em>"<a href="https://www.flickr.com/photos/67458569@N00/7722577066">Fireworks</a>" by <a href="https://www.flickr.com/photos/67458569@N00">colink.</a> is licensed under <a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse">CC BY-SA 2.0</a>.</em></p>

              </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No more "check mail from other accounts" in Gmail web (353 pts)]]></title>
            <link>https://support.google.com/mail/answer/16604719?hl=en</link>
            <guid>45439670</guid>
            <pubDate>Wed, 01 Oct 2025 16:25:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.google.com/mail/answer/16604719?hl=en">https://support.google.com/mail/answer/16604719?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=45439670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hcfe-content" role="main">                   <article class="page" sc-render-smart-button="false" itemscope=""> <div data-stats-ve="35"><p>Starting January 2026, Gmail will no longer provide support for the following:</p>

<ul>
  <li><strong>Gmailify:</strong> This feature allows you to get special features like spam protection or inbox organization applied to your third-party email account. <a href="https://support.google.com/mail/answer/6304825" rel="noopener">Learn more about Gmailify</a>.</li>
  <li><strong>POP:</strong> This feature allows you to read your messages from a third-party account in Gmail. Unlike IMAP connections, POP only works with a single device and doesn‚Äôt sync your email in real time. Instead, emails are downloaded, and you decide how often you want to download new emails. As an alternative, you can still link your third-party accounts in the Gmail app.</li>
</ul>

<p>These changes help provide the most secure and current options to access your messages in Gmail.</p>

<h2>Learn about changes to Gmailify</h2>

<p>You won‚Äôt be able to get specific features in Gmail applied to your third-party account, like:</p>

<ul>
  <li><a href="https://safety.google/intl/en_us/gmail/" rel="noopener" target="_blank">Spam protection</a></li>
  <li>Better email notifications on mobile</li>
  <li><a href="https://support.google.com/mail/answer/3094499" rel="noopener">Inbox categories</a></li>
  <li>Faster search with <a href="https://support.google.com/mail/answer/7190" rel="noopener">advanced search operators</a></li>
</ul>

<h3>What you need to do</h3>

<ul>
  <li>You can still read and send emails from your other account within the Gmail app. This uses a standard IMAP connection, which is supported in the Gmail mobile app.</li>
  <li><a href="https://support.google.com/mail/answer/6078445" rel="noopener">Learn how to add another email account to the Gmail app</a>.</li>
</ul>

<h2>Learn about changes to POP connections</h2>

<ul>
  <li>Gmail will no longer support checking emails from third-party accounts through POP.</li>
  <li>The option to "Check mail from other accounts" will no longer be available in Gmail on your computer.</li>
</ul>

<h3>What you need to do</h3>

<p><strong>Important:</strong> If you have a work or school account, your administrator can help migrate your email data into Google Workspace. <a href="https://support.google.com/a/topic/14012345" rel="noopener">Learn more about the data migration service</a>.</p>

<ul>
  <li>To continue to receive messages from your other account in Gmail, you need to set up IMAP access.
    <ul>
      <li>Check your email provider‚Äôs documentation for instructions on how to enable IMAP for your account.</li>
    </ul>
  </li>
  <li>To read your messages from your other account, use the Gmail app. <a href="https://support.google.com/mail/answer/6078445" rel="noopener">Learn how to add another email account to the Gmail app</a>.</li>
</ul>

<h2>Frequently asked questions</h2>
<p><a>Will I lose the emails I already imported?</a></p><p>No. All messages synced before the deprecation stay in Gmail.</p>
<p><a>Can I still use other email accounts in the Gmail app?</a></p><p>Yes. For third-party accounts like Yahoo! and Outlook, you can add them to the Gmail mobile app on Android and iPhone and iPad.</p>

<h2>Related resources</h2>

<ul>
  <li><a href="https://support.google.com/mail/answer/6304825" rel="noopener">Get Gmail features for your other email accounts</a></li>
  <li><a href="https://support.google.com/mail/answer/21289" rel="noopener">Add another email account on your computer</a></li>
</ul>
</div>      </article>            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Who is hiring? (October 2025) (184 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=45438503</link>
            <guid>45438503</guid>
            <pubDate>Wed, 01 Oct 2025 15:01:06 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=45438503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bigbox"><td><table><tbody><tr id="45438503"><td><span></span></td><td><center><a id="up_45438503" href="https://news.ycombinator.com/vote?id=45438503&amp;how=up&amp;goto=item%3Fid%3D45438503"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=45438503">Ask HN: Who is hiring? (October 2025)</a></span></td></tr><tr><td colspan="2"></td><td><span><span id="score_45438503">111 points</span> by <a href="https://news.ycombinator.com/user?id=whoishiring">whoishiring</a> <span title="2025-10-01T15:01:06 1759330866"><a href="https://news.ycombinator.com/item?id=45438503">4 hours ago</a></span> <span id="unv_45438503"></span> | <a href="https://news.ycombinator.com/hide?id=45438503&amp;goto=item%3Fid%3D45438503">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Who%20is%20hiring%3F%20%28October%202025%29&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=45438503&amp;auth=e62bfd643e03dbfc11da0f07461353f48e2b6638">favorite</a> | <a href="https://news.ycombinator.com/item?id=45438503">162&nbsp;comments</a></span></td></tr><tr><td colspan="2"></td><td><div><p>Please state the location and include REMOTE for remote work, REMOTE (US)
or similar if the country is restricted, and ONSITE when remote work is <i>not</i> an option.</p><p>Please only post if you personally are part of the hiring company‚Äîno
recruiting firms or job boards. One post per company. If it isn't a household name,
explain what your company does.</p><p>Please only post if you are actively filling a position and are committed
to responding to applicants.</p><p>Commenters: please don't reply to job posts to complain about
something. It's off topic here.</p><p>Readers: please only email if you are personally interested in the job.</p><p>Searchers: try <a href="https://dheerajck.github.io/hnwhoishiring/" rel="nofollow">https://dheerajck.github.io/hnwhoishiring/</a>,
<a href="https://amber-williams.github.io/hackernews-whos-hiring/" rel="nofollow">https://amber-williams.github.io/hackernews-whos-hiring/</a>,
<a href="http://nchelluri.github.io/hnjobs/" rel="nofollow">http://nchelluri.github.io/hnjobs/</a>, <a href="https://hnresumetojobs.com/" rel="nofollow">https://hnresumetojobs.com</a>,
<a href="https://hnhired.fly.dev/" rel="nofollow">https://hnhired.fly.dev</a>, <a href="https://kennytilton.github.io/whoishiring/" rel="nofollow">https://kennytilton.github.io/whoishiring/</a>,
<a href="https://hnjobs.emilburzo.com/" rel="nofollow">https://hnjobs.emilburzo.com</a>, or this (unofficial) Chrome extension:
<a href="https://chromewebstore.google.com/detail/hn-hiring-pro/mpfaljjblphnlloddaplgicpkinikjlp" rel="nofollow">https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal...</a>.</p><p>Don't miss these other fine threads:</p><p><i>Who wants to be hired?</i> <a href="https://news.ycombinator.com/item?id=45438501">https://news.ycombinator.com/item?id=45438501</a></p><p><i>Freelancer? Seeking freelancer?</i> <a href="https://news.ycombinator.com/item?id=45438502">https://news.ycombinator.com/item?id=45438502</a></p></div></td></tr><tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr></tbody></table><br>
</td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building the heap: racking 30 petabytes of hard drives for pretraining (321 pts)]]></title>
            <link>https://si.inc/posts/the-heap/</link>
            <guid>45438496</guid>
            <pubDate>Wed, 01 Oct 2025 15:00:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://si.inc/posts/the-heap/">https://si.inc/posts/the-heap/</a>, See on <a href="https://news.ycombinator.com/item?id=45438496">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>We built a storage cluster in downtown SF to store 90 million hours worth of video data. Why? We‚Äôre pretraining models to solve computer use. Compared to text LLMs like LLaMa-405B, which require ~60 TB of text data to train, videos are sufficiently large that we need 500 times more storage. Instead of paying the $12 million / yr it would cost to store all of this on AWS, we rented space from a colocation center in San Francisco to bring that cost down ~40x to $354k per year, including depreciation.</p>
<h2 id="why">Why</h2>
<p>Our use case for data is unique. Most cloud providers care highly about redundancy, availability, and data integrity, which tends to be unnecessary for ML training data. Since pretraining data is a commodity‚Äîwe can lose any individual 5% with minimal impact‚Äîwe can handle relatively large amounts of data corruption compared to enterprises who need guarantees that their user data isn‚Äôt going anywhere. In other words, we don‚Äôt need AWS‚Äôs 13 nines of reliability; 2 is more than enough.</p>
<p>Additionally, storage tends to be priced substantially above cost. Most companies use relatively small amounts of storage (even ones like Discord still use <a href="https://discord.com/blog/how-discord-stores-trillions-of-messages">under a petabyte</a> for messages), and the companies that use petabytes are so large that storage remains a tiny fraction of their total compute spend.</p>
<p>Data is one of our biggest contraints, and would be prohibitively expensive otherwise. As long as the cost predictions work out in favor of a local datacenter, and it would not consume too much of the core team‚Äôs time, it would make sense to stack hard drives ourselves. 

<span data-note-content="We talked to some engineers at the Internet Archive, which had basically the same problem as us; even after massive friends &amp; family discounts on AWS, it was still 10 times more cost-effective to buy racks and store the data themselves\! " data-number="1">
<sup data-sidenote="sidenote-0">[1]</sup>
<span id="sidenote-0">1. We talked to some engineers at the Internet Archive, which had basically the same problem as us; even after massive friends &amp; family discounts on AWS, it was still 10 times more cost-effective to buy racks and store the data themselves!</span>
</span></p>
<h2 id="the-cost-breakdown-cloud-alternatives-vs-in-house">The Cost Breakdown: Cloud Alternatives vs In-House</h2>
<p>Internet and electricity total $17.5k as our only recurring expenses (the price of colocation space, cooling, etc were bundled into electricity costs). One-time costs were dominated by hard drive capex. 

<span data-note-content=" When deciding the datacenter location we had multiple options across the Bay Area, including options in Fremont through Hurricane Electric for around $10k in setup fees and $12.8k per month, saving us $38.5k initially and $4.7k per month, but ended up opting for a datacenter that was only a couple blocks from our office in SF. Though this came at a premium, it was extremely helpful to get the initial nodes setup and for ongoing maintenance. Our team is just 5 people, so any friction in going to the datacenter would come at a noticeable cost to team productivity." data-number="2">
<sup data-sidenote="sidenote-1">[2]</sup>
<span id="sidenote-1">2. When deciding the datacenter location we had multiple options across the Bay Area, including options in Fremont through Hurricane Electric for around $10k in setup fees and $12.8k per month, saving us $38.5k initially and $4.7k per month, but ended up opting for a datacenter that was only a couple blocks from our office in SF. Though this came at a premium, it was extremely helpful to get the initial nodes setup and for ongoing maintenance. Our team is just 5 people, so any friction in going to the datacenter would come at a noticeable cost to team productivity.</span>
</span></p>
<p><img src="https://si.inc/the-heap/datacenter_cost_comparison.png" alt="cost comparison">
<em>Table 1: Cost comparison of cloud alternatives vs in-house. AWS is $1,130,000/month including estimated egress, Cloudflare is $270,000/month (with bulk-discounted pricing), and our datacenter is $29,500/month (including recurring costs and depreciation).</em></p>
<h3 id="monthly-recurring-costs">Monthly Recurring Costs</h3>
<table>
<thead>
<tr>
<th>Item</th>
<th>Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Internet</td>
<td>$7,500/month</td>
<td>100Gbps DIA from Zayo, 1yr term.</td>
</tr>
<tr>
<td>Electricity</td>
<td>$10,000/month</td>
<td>1 kW/PB, $330/kW. Includes cabinet space &amp; cooling. 1yr term.</td>
</tr>
<tr>
<td><strong>Total Monthly</strong></td>
<td><strong>$17,500/month</strong></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="one-time-costs">One-Time Costs</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Item</th>
<th>Cost</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td>Storage</td>
<td>Hard drives (HDDs)</td>
<td>$300,000</td>
<td>2,400 drives. Mostly 12TB used enterprise drives (3/4 SATA, 1/4 SAS). The JBOD DS4246s work for either.</td>
</tr>
<tr>
<td>Storage Infrastructure</td>
<td>NetApp DS4246 chassis</td>
<td>$35,000</td>
<td>100 dual SATA/SAS chassis, 4U each</td>
</tr>
<tr>
<td>Compute</td>
<td>CPU head nodes</td>
<td>$6,000</td>
<td>10 Intel RR2000s from eBay</td>
</tr>
<tr>
<td>Datacenter Setup</td>
<td>Install fee</td>
<td>$38,500</td>
<td>One-off datacenter install fee</td>
</tr>
<tr>
<td>Labor</td>
<td>Contractors</td>
<td>$27,000</td>
<td>Contractors to help physically screw in / install racks and wire cables</td>
</tr>
<tr>
<td>Networking &amp; Misc</td>
<td>Install expenses</td>
<td>$20,000</td>
<td>Power cables, 100GbE QSFP CX4 NICs, Arista router, copper jumpers, one-time internet install fee</td>
</tr>
<tr>
<td><strong>Total One-Time</strong></td>
<td></td>
<td><strong>$426,500</strong></td>
<td></td>
</tr>
</tbody>
</table>
<p>Our price assuming three-year depreciation (including for the one-off install fees) is $17.5k/month in fixed monthly costs (internet, power, etc.) and $12k/month in depreciation, for $29.5k/month overall.</p>
<p>We compare our costs to two main providers: AWS‚Äôs public pricing numbers as a baseline, and Cloudflare‚Äôs discounted pricing for 30PB of storage. It‚Äôs important to note that AWS egress would be substantially lower if we utilized AWS GPUs. This is not reflected on our graph because AWS GPUs are priced at substantially above market prices and large clusters are difficult to attain, untenable at our compute scales.</p>
<p>Here are the pricing breakdowns:</p>
<h3 id="aws-pricing-breakdown">AWS Pricing Breakdown</h3>
<table>
<thead>
<tr>
<th>Cost Component</th>
<th>Rate</th>
<th>Monthly Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Storage</td>
<td>$0.021/GB/month</td>
<td>$630,000</td>
<td>For data over 500TB</td>
</tr>
<tr>
<td>Egress</td>
<td>$0.05/GB</td>
<td>$500,000</td>
<td>Entire dataset egressed quarterly (10 PB/month)</td>
</tr>
<tr>
<td><strong>Total AWS Monthly</strong></td>
<td></td>
<td><strong>$1,130,000</strong></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="cloudflare-r2-pricing">Cloudflare R2 Pricing</h3>
<table>
<thead>
<tr>
<th>Pricing Tier</th>
<th>Rate</th>
<th>Monthly Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Published Rate</td>
<td>$0.015/GB/month</td>
<td>$450,000</td>
<td>No egress fees</td>
</tr>
<tr>
<td>Estimated Private Pricing 

<span data-note-content="
Cloudflare has a more reasonable estimate for the 30 PB, placing it at an overall monthly cost of $270k without egress fees. We also have bulk-discounted pricing estimates after getting pricing quotes‚Äîthis was our main point of comparison for the datacenter.
" data-number="3">
<sup data-sidenote="sidenote-2">[3]</sup>
<span id="sidenote-2">3. Cloudflare has a more reasonable estimate for the 30 PB, placing it at an overall monthly cost of $270k without egress fees. We also have bulk-discounted pricing estimates after getting pricing quotes‚Äîthis was our main point of comparison for the datacenter.</span>
</span></td>
<td>$0.009/GB/month</td>
<td>$270,000</td>
<td>Estimated rate for &gt;20 PB scale</td>
</tr>
</tbody>
</table>
<p>That brings monthly costs to $38/TB/month for AWS, $10/TB/month for Cloudflare, and $1/TB/month for our datacenter‚Äîabout 38x lower and 10x lower respectively. (At the very cheapest end of the spectrum, Backblaze has a $6/TB product that is unsuitable for model training due to egress speed limitations; their $15/TB Overdrive AI-specific storage product is closer to Cloudflare‚Äôs in price &amp; performance)</p>
<p>While we use Cloudflare as a comparison point, we‚Äôve sometimes done too much load for their R2 servers. In particular, in the past we‚Äôve done enough load during large model training runs that they rate-limited us, later confirming we were saturating their metadata layer and the rate limit wasn‚Äôt synthetic. Because our metadata on the heap is so simple, and we have a 100Gbps DIA connection, we haven‚Äôt ran into any issues there. 

<span data-note-content=" We love Cloudflare and use many of their products often; we include this anecdote as a fact about our scale being difficult to handle, not as a dig! " data-number="4">
<sup data-sidenote="sidenote-3">[4]</sup>
<span id="sidenote-3">4. We love Cloudflare and use many of their products often; we include this anecdote as a fact about our scale being difficult to handle, not as a dig!</span>
</span></p>
<p>This setup was and is necessary for our video data pipelines, and we‚Äôre extremely happy that we made this investment. By gathering large scale data at low costs, we can be competitive with frontier labs with billions of dollars in capital.</p>
<h2 id="setupthe-process">Setup/The Process</h2>
<p>We cared a lot about getting this built <em>fast</em>, because this kind of project can easily stretch on for months if not careful. Hence Storage Stacking Saturday, or S3. We threw a hard drive stacking party in downtown SF and got our friends to come, offering food and custom-engraved hard drives to all who helped. The hard drive stacking started at 6am and continued for 36 hours (with a break to sleep), and by the end of that time we had 30 PB of functioning hardware racked and wired up. We brought in contractors for additional help and professional installation later on in the event.</p>
<p><img src="https://si.inc/the-heap/server-people.png" alt="hard drive stacking party">
<em>People at the hard drive stacking party!</em>
<img src="https://si.inc/the-heap/server.png" alt="hard drive stacking party">
<em>Cool shots of the servers</em></p>
<p>Our software is 200 lines of Rust code for writing (to determine the drive to write data onto) and a nginx webserver for reading data, with a simple SQLite db for tracking metadata like which heap node each file is on and what data split it belongs to. We kept this obsessively simple instead of using MinIO or Ceph because we didn‚Äôt need <em>any</em> of the features they provided; it‚Äôs much, much simpler to debug a 200-line program than to debug Ceph, and we weren‚Äôt worried about redundancy or sharding. All our drives were formatted with XFS.</p>
<p>The storage software landscape offers many options, but every option available comes with drawbacks. People experienced with Ceph strongly warned us to avoid it unless we were willing to hire dedicated Ceph specialists‚Äîour research confirmed this advice. Ceph appears far more complex than justified for most use cases, only worthwhile for companies that absolutely need maximum performance and customizability and are prepared to invest heavily in tuning. Minio presents an interesting option if S3 compatibility is essential, but otherwise remains a bit too fancy for us and similar use-cases. Weka and Vast are absurdly expensive at 2k / TB / year or so and are primarily designed for NVMEs, not spinning disks.</p>
<h2 id="post-mortem">Post-Mortem</h2>
<p>Building the datacenter was a large endeavor and we definitely learned lessons, both good and bad.</p>
<h3 id="things-that-we-got-correct">Things That We Got Correct</h3>
<ul>
<li>We think the redundancy &amp; capability tradeoffs we made are very reasonable at our disk speeds. We‚Äôre able to approximately saturate our 100G network for both read &amp; write.</li>
<li>Doing this locally a couple blocks away was well worth it because of the amount of debugging and manual work needed.</li>
<li>Ebay is good to find vendors but bad to actually buy things with. After finding vendors, they can often individually supply all the parts we need and provide warranties, which are extremely valuable.</li>
<li>100G dedicated internet is pretty important, and much much easier to debug issues with than using cloud products.</li>
<li>Having high-quality cable management during the racking process saved us a ton of time debugging in the long run; making it easy to switch up the networking saved us a lot of headache.</li>
<li>We had a very strong simplicity prior, and this saved an immense amount of effort. We are quite happy that we didn‚Äôt use ceph or minio. Unlike e.g. nginx, they do not work out of the box. We were willing to write a simple Rust script and roughly saturated our network read &amp; write at 100 Gbps without any fancy code.</li>
<li>We were basically right about the price and advantages this offered, and did not substantially overestimate the amount of time / effort it would take. While the improvements list is longer than this, <em>most of those are minor; fundamentally we built a cluster rivaling massive clouds for 40x cheaper.</em></li>
</ul>
<h3 id="difficult-bits">Difficult Bits</h3>
<p>A map of reality only gets you so far‚Äîwhile setting up the datacenter we ran into a couple problems and unexpected challenges. We‚Äôll include a list:</p>
<ul>
<li>We used frontloaders instead of toploaders for our server rack. This meant we had to screw every single individual drive in‚Äîtedious for 2.4k HDDs</li>
<li>Our storage was not dense‚Äîwe could have saved 5x the work on physical placement and screwing by having a denser array of hard drives</li>
<li>Shortcuts like daisy-chaining are usually a bad idea. We could have gotten substantially higher read/write speeds without daisy chaining networked nodes, giving each chassis its own HBA (Host Bus Adapter, not a significant cost).</li>
<li>Compatibility is key‚Äîspecifically in networking functionally everything is locked to a specific brand. We had many pain points here. Fiber transceivers will ~never work unless used with the right brand, but copper cables are much more forgiving. <a href="http://fs.com/">FS.com</a> is pretty good and well priced (though their speed estimates were pretty inconsistent); Amazon will also often have the parts you need rapidly.</li>
<li>Networking was a substantial cost and required experimentation. We did not use DHCP as most enterprise switches don‚Äôt support it and we wanted public IPs for the nodes for convenient and performant access from our servers. While this is an area where we would have saved time with a cloud solution, we had our networking up within days and kinks ironed out within ~3 weeks.</li>
<li>We were often bottlenecked by easy access to servers via monitor/keyboard; idle crash carts during setup are helpful.</li>
</ul>
<h3 id="ideas-worth-trying">Ideas Worth Trying</h3>
<ul>
<li>Working KVMs are extremely useful, and you shouldn‚Äôt go without them or good IPMI. Physically going to a datacenter is really inconvenient, even if it‚Äôs a block away. IPMI is good, but only if you have pretty consistent machines.</li>
<li>Think through your management Ethernet network as much as your real network - it‚Äôs really nice to be able to SSH into servers while configuring the network, and IPMI is great!</li>
<li>Overprovision your network‚Äîe.g. if doable it‚Äôs worth having 400 Gigabit internally (you can use 100G cards etc for this!)</li>
<li>We could have substantially increased density at additional upfront cost by buying 90-drive SuperMicro SuperServers and putting 20TB drives into them. This would allow us to use 2 racks instead of 10, given us had about the equivalent of 20 AMD 9654s in total CPU capacity, and used less total power.</li>
</ul>
<h2 id="how-you-can-build-this-yourself">How You Can Build This Yourself</h2>
<p>Here‚Äôs what you need to replicate our setup.</p>
<h3 id="storage">Storage</h3>
<ul>
<li>
<p>10 CPU head nodes.</p>
<ul>
<li>We used Intel Rr2000 with Dual Intel Gold 6148 and 128GB of DDR4 ECC RAM per server (which are incredibly cheap and roughly worked for our use cases) but you have a lot of flexibility in what you use.</li>
<li>If you use the above configuration you likely won‚Äôt be able to do anything at all CPU-intensive on the servers (like on-device data processing or ZFS data compression / deduplication / etc, which is valuable if you‚Äôre storing non-video data).</li>
<li>Our CPU nodes cost $600 each‚Äîit seems quite reasonable to us to spend up to $3k each if you want ZFS / compression or the abiliy to do data processing on-CPU.</li>
</ul>
</li>
<li>
<p>100 DS4246 chassis‚Äîeach can hold 24 hard drives.</p>
</li>
<li>
<p>2,400 3.5 inch HDDs‚Äîneed to be all SATA or all SAS in each chassis.</p>
<ul>
<li><em>We would recommend SAS hard drives if possible</em>

<span data-note-content="if you use SAS drives you‚Äôll need to deal with or disable mulipathing, which is reasonably simple" data-number="5">
<sup data-sidenote="sidenote-4">[5]</sup>
<span id="sidenote-4">5. if you use SAS drives you‚Äôll need to deal with or disable mulipathing, which is reasonably simple</span>
</span> as they roughly double speed over similar SATA drives.</li>
<li>We used a mix of 12TB and 14TB drives‚Äîbasically any size should work, roughly the larger the better holding price constant (density makes stacking easier + in general increases resale value).</li>
</ul>
</li>
<li>
<p>Physical parts to mount the chassis‚Äîyou‚Äôll need rails or l-brackets. We used l-brackets which worked well, as we haven‚Äôt needed to take the chassis out to slot hard drives. If you buy toploaders, you‚Äôll need rails.</p>
</li>
<li>
<p>Multiple ‚Äúcrash carts‚Äù with monitors and keyboards that allow you to physically connect to your CPU head nodes and configure them‚Äîthis is invaluable when you‚Äôre debugging network issues.</p>
</li>
</ul>
<h3 id="network">Network</h3>
<ul>
<li>
<p>A 100 GbE switch</p>
<ul>
<li>a used Arista is fine, should be QSFP28, should cost about $1-2k</li>
</ul>
</li>
<li>
<p>HBAs (Host Bus Adapters), which connect your head nodes to your DS4246 chassis.</p>
<ul>
<li>The best configuration we tried was with Broadcom 9305-16E HBAs, with 3x HBAs per server (make sure your server has physical space for them!) with SFF-8644 to QSFP mini SAS cables.</li>
<li>There are 4 slots per HBA, so you can cable each DS4246 chassis directly to the HBA.


<span data-note-content="The option we ended up going with for convenience was putting LSI SAS9207-8e HBAs, which have 2 ports each, into the CPU head nodes- then daisy-chaining the DS4246s together with QSFP+ to QSFP+ DACs.. We deployed this on Storage Stacking Saturday, then while debugging speeds tried the above method on one of the servers and got to \~4 Gbps per chassis-but didn‚Äôt find it worth it to swap everything out in pure labor because of the way we had set up some of our head nodes such that they were difficult to take out. Insofar as it is reasonably cheap to just do the above thing to start and we‚Äôve tested it to work, you should probably do as we say, not as we did in this case\!" data-number="6">
<sup data-sidenote="sidenote-5">[6]</sup>
<span id="sidenote-5">6. The option we ended up going with for convenience was putting LSI SAS9207-8e HBAs, which have 2 ports each, into the CPU head nodes- then daisy-chaining the DS4246s together with QSFP+ to QSFP+ DACs.. We deployed this on Storage Stacking Saturday, then while debugging speeds tried the above method on one of the servers and got to ~4 Gbps per chassis-but didn‚Äôt find it worth it to swap everything out in pure labor because of the way we had set up some of our head nodes such that they were difficult to take out. Insofar as it is reasonably cheap to just do the above thing to start and we‚Äôve tested it to work, you should probably do as we say, not as we did in this case!</span>
</span></li>
</ul>
</li>
<li>
<p>Network cards (NICs).</p>
<ul>
<li>We used Mellanox ConnectX-4 100GbE. Make sure they come in Ethernet mode and not Infiniband mode for ease of config.</li>
</ul>
</li>
<li>
<p>DAC (Direct Attach Copper) or AOC (Active Optical) cables, to connect the NICs in your head nodes to your switch and therefore the internet. You almost certainly want DACs if your racks are close together, as they are far more compatible with arbitrary networking equipment than AOCs.</p>
</li>
</ul>
<p>We would recommend that you find a supplier to sell you the CPU head nodes with the HBAs and NICs installed‚Äîthere are a number of used datacenter / enterprise parts suppliers who are willing to do this. This is a substantial positive because it means that you don‚Äôt have to spend hours installing the HBAs/NICs yourself and can have a substantially higher degree of confidence in your operations.</p>
<ul>
<li>
<p>Serial cables‚Äîyou‚Äôll need these to connect to your switch!</p>
</li>
<li>
<p><strong>Optional but recommended:</strong> an Ethernet management network of some kind. If you can‚Äôt easily get ethernet, we‚Äôd recommend getting a wifi adapter <a href="https://www.amazon.com/BrosTrend-600Mbps-Adapter-Wireless-WNA016/dp/B0118SPFCK">like this</a> and then a ethernet switch <a href="https://www.amazon.com/Ethernet-Splitter-Optimization-Unmanaged-TL-SG105/dp/B00A128S24">like this</a> ‚Äîit‚Äôs substantially easier to set up than the 100GbE, is a great backup for when that‚Äôs not working, and will allow you to do ~everything over SSH from the comfort of the office instead of in the datacenter.</p>
</li>
</ul>
<h3 id="datacenter-requirements">Datacenter Requirements</h3>
<ul>
<li>3.5 kW of usable power per cabinet, with 10 4U chassis + 1 2U (cabinets are 42U tall)</li>
<li>1 spare cabinet for the 1U or 2U 100GbE switch (you can obviously also just swap out one of the 4U chassis in another cabinet for the switch).</li>
<li>1 42U cabinet per 3 PB of storage</li>
<li>A dedicated 100G connection (will come in as a fiber pair probably via <a href="https://www.fs.com/products/104860.html">QSFP28 LR4</a>, but confirm with your datacenter provider before buying parts here!)</li>
<li>Ideally physically near your office‚Äîthere is a lot of value in being able to walk over and debug issues instead of e.g. dealing with remote hands services to get internet to the nodes.</li>
</ul>
<p><strong>Some setup tips:</strong></p>
<ul>
<li>Make sure to first properly configure your switch. Depending on your switch model this should be relatively straightforward‚Äîyou‚Äôll need to physically connect to the switch and then configure the specific port that your 100GbE is connected to (you‚Äôll get a fiber cross-connect from your datacenter that you should plug into a QSFP28 transceiver. <strong>Make sure that you get a transceiver that is compatible in form with the ISP, probably LR4, and specifically branded with your switch brand, otherwise it is very unlikely to work).</strong> Depending on your ISP you might have to talk to them to make sure that you can get ‚Äúlight‚Äù through the fiber cables from both ends, which might involve <a href="https://www.youtube.com/watch?v=OKtF97VT8ts">rolling the fiber</a> and otherwise making sure it‚Äôs working properly.
<ul>
<li>If your switch isn‚Äôt working / you haven‚Äôt configured one before, I‚Äôd suggest trying to directly plug the fiber cable from the ISP into one of your 10 heap servers, making sure to buy a transceiver that is compatible with your NIC brand (e.g. Mellanox). Once you get it working from there, move over to your switch and get it working.</li>
</ul>
</li>
<li>Once you can connect to the internet from your switch (simply ping 1.1.1.1 to check) you are ready to set up the netplans for the individual nodes. <strong>this is most easily done during the Ubuntu setup process, which will walk you through setting up internet for your CPU head nodes</strong>, but is also doable outside of that</li>
</ul>
<p>Once you have internet access to your nodes and have properly connected 1 cable to each DS4246, you should format &amp; mount the drives on each node, test that all of them are properly working, and then you are ready to deploy any software you want.</p>
<hr>
<p>If you end up building a similar storage cluster based on this writeup we‚Äôd love to hear from you‚Äîwe‚Äôre very curious what can be improved, both in our guidance and in the object-level process. You can reach us at <a href="https://si.inc/cdn-cgi/l/email-protection#4d2e2223392c2e390d3e246324232e"><span data-cfemail="73101c1d0712100733001a5d1a1d10">[email&nbsp;protected]</span></a></p>
<p>If you came away from this post excited about our work, we‚Äôd love to chat. We‚Äôre a research lab currently focused on pretraining models to use computers, with the long-term goal of building general models that can learn in-context and do arbitrary tasks while aligned with human values; we‚Äôre hiring top researchers and engineers to help us train these. If you‚Äôre interested in chatting, shoot us an email at <a href="https://si.inc/cdn-cgi/l/email-protection#a2c8cdc0d1e2d1cb8ccbccc1"><span data-cfemail="63090c011023100a4d0a0d00">[email&nbsp;protected]</span></a>.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Autism Simulator (537 pts)]]></title>
            <link>https://autism-simulator.vercel.app/</link>
            <guid>45438346</guid>
            <pubDate>Wed, 01 Oct 2025 14:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://autism-simulator.vercel.app/">https://autism-simulator.vercel.app/</a>, See on <a href="https://news.ycombinator.com/item?id=45438346">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Unix philosophy and filesystem access makes Claude Code amazing (264 pts)]]></title>
            <link>https://www.alephic.com/writing/the-magic-of-claude-code</link>
            <guid>45437893</guid>
            <pubDate>Wed, 01 Oct 2025 14:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alephic.com/writing/the-magic-of-claude-code">https://www.alephic.com/writing/the-magic-of-claude-code</a>, See on <a href="https://news.ycombinator.com/item?id=45437893">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>If you've talked to me lately about AI, you've almost certainly been subject to a long soliloquy about the wonders of Claude Code. What started as a tool I ran in parallel with other tools to aid coding has turned into my full-fledged agentic operating system, supporting all kinds of workflows.</p><div><p>Most notably, <a href="https://obsidian.md/"><span>Obsidian</span></a>, the tool I use for note-taking. The difference between Obsidian and Notion or Evernote is that all the files are just plain old Markdown files stored on your computer. You can sync, style, and save them, but ultimately, it's still a text file on your hard drive. A few months ago, I realized that this fact made my Obsidian notes and research a particularly interesting target for AI coding tools. What first started with trying to open my vault in <a href="https://cursor.com/"><span>Cursor</span></a> quickly moved to a sort of note-taking operating system that I grew so reliant on, I ended up standing up a server in my house so I could connect via SSH from my phone into my Claude Code + Obsidian setup and take notes, read notes, and think through things on the go.</p><p><img alt="CleanShot 2025-09-30 at 09.48.05@2x.png" height="2010" src="https://www.alephic.com/api/media/file/CleanShot%202025-09-30%20at%2009.48.05%402x.png" width="3248"></p><p>A few weeks ago, I went on <a href="https://every.to/podcast/how-to-use-claude-code-as-a-thinking-partner"><span>Dan Shipper's AI &amp; I Podcast</span></a> to wax poetic about my love for this setup. I did a pretty deep dive into the system I use, how it works, why it works, etc. I won't retread all those details‚Äîyou can read the transcript or listen to the podcast‚Äîbut I want to talk about a few other things related to Claude Code that I've come to realize since the conversation.</p><h2>Why is Claude Code special? What makes it better than Cursor?</h2><p>I've really struggled to answer this question. I'm also not sure it's better than Cursor for all things, but I do think there are a set of fairly exceptional pieces that work together in concert to make me turn to Claude Code whenever I need to build anything these days. Increasingly, that's not even about applying it to existing codebases as much as it's building entirely new things on top of its functionality (more on that in a bit).</p><p>So what's the secret? Part of it lies in how Claude Code approaches tools. As a terminal-based application, it trades accessibility for something powerful: native Unix command integration. While I typically avoid long blockquotes, the <a href="https://en.wikipedia.org/wiki/Unix_philosophy"><span>Unix Philosophy</span></a> deserves an exception‚ÄîDoug McIlroy's original formulation captures it perfectly:</p><p>The Unix philosophy is documented by <a href="https://en.wikipedia.org/wiki/Doug_McIlroy"><span>Doug McIlroy</span></a> in the <a href="https://en.wikipedia.org/wiki/Bell_System_Technical_Journal"><span>Bell System Technical Journal</span></a> from 1978:</p><ol><li value="1"><ol><li value="1">Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new "features".</li><li value="2">Expect the output of every program to become the input to another, as yet unknown, program. Don't clutter output with extraneous information. Avoid stringently columnar or binary input formats. Don't insist on interactive input.</li><li value="3">Design and build software, even operating systems, to be tried early, ideally within weeks. Don't hesitate to throw away the clumsy parts and rebuild them.</li><li value="4">Use tools in preference to unskilled help to lighten a programming task, even if you have to detour to build the tools and expect to throw some of them out after you've finished using them.</li></ol></li></ol><p>It was later summarized by <a href="https://en.wikipedia.org/wiki/Peter_H._Salus"><span>Peter H. Salus</span></a> in A Quarter-Century of Unix (1994):</p><ul><li value="1"><ul><li value="1">Write programs that do one thing and do it well.</li><li value="2">Write programs to work together.</li><li value="3">Write programs to handle text streams, because that is a universal interface.</li></ul></li></ul><p>These fifty-year-old principles are exactly how LLMs want to use tools. If you look at how these models actually use the tools they're given, they are constantly "piping" output to input (albeit using their own fuzziness in between). (As an aside, the Unix | command allows you to string the output from one command into the input of another.) When models fail to weld their tools effectively, it is almost always because the tools are overly complex.</p><p><img alt="CleanShot 2025-09-30 at 09.49.30.gif" height="628" src="https://www.alephic.com/api/media/file/CleanShot%202025-09-30%20at%2009.49.30.gif" width="800"></p><p>So part one of why Claude Code can be so mind-blowing is that the commands that power Unix happen to be perfectly suited for use by LLMs. This is both because they're simple and also incredibly well-documented, meaning the models had ample source material to teach them the literal ins and outs.</p><p>But that still wasn't the whole thing. The other piece was obviously Claude Code's ability to write code initially and, more recently, prose (for me, at least). But while other applications like ChatGPT and Claude can write output, there was something different going on here. Last week, while reading <a href="https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built"><span>The Pragmatic Engineer's deep dive into how Claude Code is built</span></a>. The answer was staring me in the face: filesystem access.&nbsp;</p><p>The filesystem changes everything. ChatGPT and Claude in the browser have two fatal flaws: no memory between conversations and a cramped context window. A filesystem solves both. Claude Code writes notes to itself, accumulates knowledge, and keeps running tallies. It has state and memory. It can think beyond a single conversation.</p><h2>AI Overhang</h2><p>Back in 2022, when I first played with the GPT-3 API, I said that even if models never got better than they were in that moment, we would still have a decade to discover the use cases. They did get better‚Äîreasoning models made tool calling reliable‚Äîbut the filesystem discovery proves my point.</p><p>I bring this up because <a href="https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built">in the Pragmatic Engineer interview</a>, Boris Cherney, who built the initial version of Claude Code, uses it to describe the aha:</p><p>In AI, we talk about ‚Äúproduct overhang‚Äù, and this is what we discovered with the prototype.&nbsp;Product overhang means that a model is able to do a specific thing, but the product that the AI runs in isn‚Äôt built in a way that captures this capability. What I discovered about Claude exploring the filesystem was pure product overhang. The model could already do this, but there wasn‚Äôt a product built around this capability!</p><p>Again, I'd argue it's filesystem + Unix commands, but the point is that the capability was there in the model just waiting to be woken up, and once it was, we were off to the races. Claude Code works as a blueprint for building reliable agentic systems because it captures model capabilities instead of limiting them through over-engineered interfaces.</p><h2>Going Beyond Code</h2><p>I talked about my Claude Code + Obsidian setup, and I've actually taken it a step further by open-sourcing "<a href="https://github.com/heyitsnoah/claudesidian"><span>Claudesidian</span></a>," which pulls in a bunch of the tools and commands I use in my own Claude Code + Obsidian setup. It also goes beyond that and was a fun experimental ground for me. Most notably, I built an initial upgrade tool so that if changes are made centrally, you can pull them into your own Claudesidian, and the AI will help you check to see if you've made changes to the files being updated and, if so, attempt to smartly merge your changes with the new updates. Both projects follow the same Unix philosophy principles‚Äîsimple, composable tools that do one thing well and work together. This is the kind of stuff that Claude Code makes possible, and why it's so exciting for me as a new way of building applications.</p><p>Speaking of which, one I'm not quite ready to release, but hopefully will be soon, is something I've been calling "Inbox Magic," though I'll surely come up with a better name. It's a Claude Code repo with access to a set of Gmail tools and a whole bunch of prompts and commands to effectively start operating like your own email EA. Right now, the functionality is fairly simple: it can obviously run searches or send emails on your behalf, but it can also do things like triage and actually run a whole training run on how you sound over email so it can more effectively draft emails for you. While Claude Code and ChatGPT both have access to my emails, they mostly grab one or two at a time. This system, because it can write things out to files and do lots of other fancy tricks, can perform a task like ‚Äúfind every single travel-related email in my inbox and use that to build a profile of my travel habits that I can use as a prompt to help ChatGPT/Claude do travel research that's actually aligned with my preferences.‚Äù Anyway, more on this soon, and if it's something you want to try out, ping me with your GitHub username, and as soon as I feel like I have something ready to test, I'll happily share it.</p><h2>A Few Takeaways</h2><p>While I generally shy away from conclusions, I think there are a few here worth reiterating.</p><ol><li value="1">The filesystem is a great tool to get around the lack of memory and state in LLMs and should be used more often.</li><li value="2">If you're trying to get tool calling working, focus on following the Unix philosophy.</li><li value="3">Claude Code represents a blueprint for future agentic systems‚Äîfilesystem + Unix philosophy should be the template for building reliable, debuggable AI agents rather than complex multi-agent stuff that's floating around today. Tactically, this means when you‚Äôre building tool calling into your own projects, keeping them simple and letting the main model thread ‚Äúpipe‚Äù them is the key. (As an aside, one big problem that needs to be solved in all these agents/chatbots is the ability to pipe things without it going through the context window.)</li><li value="4">Anyone who can't find use cases for LLMs isn't trying hard enough</li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cursor 1.7 (142 pts)]]></title>
            <link>https://cursor.com/changelog/1-7</link>
            <guid>45437735</guid>
            <pubDate>Wed, 01 Oct 2025 13:51:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cursor.com/changelog/1-7">https://cursor.com/changelog/1-7</a>, See on <a href="https://news.ycombinator.com/item?id=45437735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3 id="autocomplete-for-agent"><a href="#autocomplete-for-agent">Autocomplete for Agent</a></h3><p>When writing prompts, autocomplete suggestions will appear based on recent changes. Tab to accept suggestions and attach files to context.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/c59180ab6509a4c8cc6fe61d3cf7c36dd7ad4148.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="hooks-beta"><a href="#hooks-beta">Hooks (beta)</a></h3><p>You can now observe, control, and extend the Agent loop using custom scripts. Hooks give you a way to customize and influence Agent behavior at runtime.</p><p>Use Hooks to audit Agent usage, block commands, or redact secrets from context. It's still in beta and we'd love to hear your feedback.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/6bfb19e08fdc2162242aa94642df48cff1d7e680.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="team-rules"><a href="#team-rules">Team rules</a></h3><p>Teams can now define and share global rules from the dashboard that will be applied to all projects. We‚Äôve also shipped team rules for <a href="https://cursor.com/bugbot">Bugbot</a>, so behavior is consistent across repos.</p><figure></figure><p>Generate shareable deeplinks for reusable prompts. Useful for setup instructions in documentation, team resources, and sharing workflows. See our <a href="https://cursor.com/docs/integrations/deeplinks">documentation</a> for how to create them.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/8df68e08d1ec72cb5c16b9e29580c1e8be1a10dd.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="sandboxed-terminals"><a href="#sandboxed-terminals">Sandboxed terminals</a></h3><p>Commands now execute in a secure, sandboxed environment. If you‚Äôre on allowlist mode, non-allowlisted commands will automatically run in a sandbox with read/write access to your workspace and no internet access.</p><p>If a command fails and we detect the sandbox was the cause, you‚Äôll be prompted to retry outside of the sandbox.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/988f922156ea31ea5c4defb3f9d4a049e359b252.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><p>Quickly check the status of Cursor Agents right from your menubar.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/eb50983a08b4878f422c8fb6166e04453dd5a58f.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="image-file-support-for-agent"><a href="#image-file-support-for-agent">Image file support for Agent</a></h3><p>Agent can now read image files directly from your workspace and include them in context. Previously, only pasted images were supported.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/0d33834548eb1bbe7aae74f2e749b7d2b9d6d45d.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ChartDB Agent ‚Äì Cursor for DB schema design (111 pts)]]></title>
            <link>https://app.chartdb.io/ai</link>
            <guid>45437594</guid>
            <pubDate>Wed, 01 Oct 2025 13:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.chartdb.io/ai">https://app.chartdb.io/ai</a>, See on <a href="https://news.ycombinator.com/item?id=45437594">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Minimal files and config for a PWA (134 pts)]]></title>
            <link>https://github.com/chr15m/minimal-pwa</link>
            <guid>45437326</guid>
            <pubDate>Wed, 01 Oct 2025 13:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/chr15m/minimal-pwa">https://github.com/chr15m/minimal-pwa</a>, See on <a href="https://news.ycombinator.com/item?id=45437326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      



    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p>

<react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  
  
</react-partial>





      

          

              




<header role="banner" data-is-top="true" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      

      <div>
        <div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>
          GitHub Copilot

        </p><p>

        Write better code with AI
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
        <p>
          GitHub Spark

            <span>
              New
            </span>
        </p><p>

        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
        <p>
          GitHub Models

            <span>
              New
            </span>
        </p><p>

        Manage and compare prompts
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>
          GitHub Advanced Security

        </p><p>

        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>
          Actions

        </p><p>

        Automate any workflow
      </p></div>

    
</a></li>

                  </ul>
                </div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>
          Codespaces

        </p><p>

        Instant dev environments
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>
          Issues

        </p><p>

        Plan and track work
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>
          Code Review

        </p><p>

        Manage code changes
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>
          Discussions

        </p><p>

        Collaborate outside of code
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>
          Code Search

        </p><p>

        Find more, search less
      </p></div>

    
</a></li>

                  </ul>
                </div>
            
        </div>

          <p>
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              
</a>          </p>
      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>

                      <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                      <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
      

      <div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>
          GitHub Sponsors

        </p><p>

        Fund open source developers
      </p></div>

    
</a></li>

                  </ul>
                </div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>
          The ReadME Project

        </p><p>

        GitHub community articles
      </p></div>

    
</a></li>

                  </ul>
                </div>
                
            </div>
</li>


                <li>
      

      <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>
          Enterprise platform

        </p><p>

        AI-powered developer platform
      </p></div>

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:chr15m/minimal-pwa" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="m1iT7lo9LlWcjZIU5mQgCKXl1-KrcgGuINf6XNpLMWXY0tKmv0w-I64Xn52PlAeH99xzGeJX3_8yqNKtDaAcpg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="chr15m/minimal-pwa" data-current-org="" data-current-owner="chr15m" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=chr15m%2Fminimal-pwa" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/chr15m/minimal-pwa&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d26cbfff95843f3710249c937aee2c8e38ec6ac3f667c6f5be2db9c37918a046" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-f197728f-3b54-4d92-82b1-03a5c5de041b" for="icon-button-ed09aa16-7e48-41bb-9455-f3380047c5bd" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div>
</header>

      
    </div>

  








    


    






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div data-view-component="true" id="repo-content-pjax-container">      

<react-partial partial-name="repos-overview" data-ssr="true" data-attempted-ssr="true" data-react-profiling="false">
  
  
  <div data-target="react-partial.reactRoot"><div itemscope="" itemtype="https://schema.org/abstract"><h2>Repository files navigation</h2><nav aria-label="Repository files" data-variant="inset"><ul role="list"><li><a href="#" aria-current="page"><span data-component="icon"></span><span data-component="text" data-content="README">README</span></a></li></ul></nav></div><div data-hpc="true"><article itemprop="text"><p dir="auto">This is the minimal set of files for a "progressive web app" to be installable on Android and iOS.</p>
<p dir="auto">It contains the smallest possible <code>manifest.json</code> and service worker to trigger the install flow on Chrome.</p>
<p dir="auto">An even smaller implementation that fits in a single HTML file is in <a href="https://github.com/chr15m/minimal-pwa/blob/main/single-file-pwa.html">single-file-pwa.html</a>. It has a manifest.json that is dynamically generated from JavaScript, and it is installable without a service worker.</p>
</article></div></div>
</react-partial>


      </div>

</turbo-frame>


    </main>
  </div>

          



    <ghcc-consent id="ghcc" data-locale="en" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Detect Electron apps on Mac that hasn't been updated to fix the system wide lag (153 pts)]]></title>
            <link>https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58</link>
            <guid>45437112</guid>
            <pubDate>Wed, 01 Oct 2025 12:54:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58">https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58</a>, See on <a href="https://news.ycombinator.com/item?id=45437112">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Detect Electron apps on mac where the Electron hasn't yet been updated to fix the system wide lag
  </p><div id="file-readme-md" tabindex="0" role="region" aria-label="README.md content, created by tkafka on 12:53PM today.">
    <article itemprop="text"><p dir="auto"><h2 dir="auto">Electron Apps Causing System-Wide Lag on Tahoe</h2><a id="user-content-electron-apps-causing-system-wide-lag-on-tahoe" aria-label="Permalink: Electron Apps Causing System-Wide Lag on Tahoe" href="#electron-apps-causing-system-wide-lag-on-tahoe"></a></p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><a data-error-text="Failed to load title" data-id="3412185866" data-permission-text="Title is private" data-url="https://github.com/electron/electron/issues/48311" data-hovercard-type="issue" data-hovercard-url="/electron/electron/issues/48311/hovercard?comment_id=3332181420&amp;comment_type=issue_comment" href="https://github.com/electron/electron/issues/48311#issuecomment-3332181420">electron/electron#48311 (comment)</a></li>
<li><a href="https://mjtsai.com/blog/2025/09/30/electron-apps-causing-system-wide-lag-on-tahoe/" rel="nofollow">https://mjtsai.com/blog/2025/09/30/electron-apps-causing-system-wide-lag-on-tahoe/</a></li>
</ul>
<p dir="auto">Fixed versions:</p>
<ul dir="auto">
<li>36.9.2</li>
<li>37.6.0</li>
<li>38.2.0</li>
<li>39.0.0</li>
<li>and all above 39</li>
</ul>
<p dir="auto">This script detects apps with not yet updated versions of Electron.</p>
<p dir="auto"><h2 dir="auto">Temporary workaround:</h2><a id="user-content-temporary-workaround" aria-label="Permalink: Temporary workaround:" href="#temporary-workaround"></a></p>
<p dir="auto">Run</p>
<div dir="auto"><pre>launchctl setenv CHROME_HEADLESS 1</pre></div>
<p dir="auto">on every system start. The CHROME_HEADLESS flag has a side effect of disabling Electron app window shadows, which makes them ugly, but also stops triggering the issue.</p>
<p dir="auto"><h2 dir="auto">Example output</h2><a id="user-content-example-output" aria-label="Permalink: Example output" href="#example-output"></a></p>
<p dir="auto">(as of 1st oct 2025 - it lists all electron apps, but none shows the ‚úÖ checkmark so far)</p>
<pre><code>‚ùå OpenMTP.app: Electron 18.3.15 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå DaVinci Resolve.app: Electron 36.3.2 (Contents/Applications/Electron.app/Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Electron.app: Electron 36.3.2 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Visual Studio Code.app: Electron 37.3.1 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Cursor.app: Electron 34.5.8 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Windsurf.app: Electron 34.4.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Claude.app: Electron 36.4.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Signal.app: Electron 38.1.2 (Contents/Frameworks/Electron Framework.framework/Electron Framework)
‚ùå Figma Beta.app: Electron 37.5.1 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Beeper Desktop.app: Electron 33.2.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
‚ùå Slack.app: Electron 38.1.2 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
</code></pre>
<p dir="auto"><h2 dir="auto">A bit of promo</h2><a id="user-content-a-bit-of-promo" aria-label="Permalink: A bit of promo" href="#a-bit-of-promo"></a></p>
<p dir="auto">If you'd appreciate a visual (Tufte-like) hour by hour forecast for iOS/Apple Watch/mac with nice widgets, I made one - check out üå¶Ô∏è <a href="https://apps.apple.com/app/apple-store/id1501958576" rel="nofollow">Weathergraph</a>.</p>
<p dir="auto">Thanks! Tomas</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TigerBeetle is a most interesting database (287 pts)]]></title>
            <link>https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world</link>
            <guid>45436534</guid>
            <pubDate>Wed, 01 Oct 2025 11:33:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world">https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world</a>, See on <a href="https://news.ycombinator.com/item?id=45436534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>By many measures it‚Äôs safe to say that TigerBeetle is the most interesting database in the world. Like Costanza in Seinfeld, they seem to do the <em>opposite</em> of everyone else:</p><ul role="list"><li>Most teams write code fast. TigerBeetle tries to <strong>write code slow</strong>.</li><li>Most teams treat testing as a necessary evil. TigerBeetle is <strong>built entirely on Deterministic Simulation Testing (DST)</strong>.</li><li>Most teams build their software on top of loads of other software. TigerBeetle <strong>has zero dependencies</strong>.</li></ul><p>There‚Äôs even more. TigerBeetle enforces static memory allocation. They keep assertions enabled in production. They chose Viewstamped Replication over Raft, and even Zig instead of Rust!</p><p>This read is going to go behind the scenes of how TigerBeetle came to be, the incredibly novel software they‚Äôve built, and all of the wacky, wonderful things that make them so special. Based on extensive interviews with the TigerBeetle team, we‚Äôre going to cover a few topics in technical detail:</p><ul role="list"><li>Why transactional databases should think in debits and credits, not SQL</li><li>An (actually) modern database: distributed by default, handling storage faults, and why TigerBeetle uses Zig</li><li>VOPR, TigerBeetle‚Äôs Deterministic Simulation Testing cluster</li><li>TigerStyle, and why you should use assertions</li></ul><p>Click on any section to jump straight there, if you‚Äôre curious.&nbsp;&nbsp;</p><h2><strong>Why we need a database that thinks in debits and credits</strong></h2><p>TigerBeetle‚Äôs website calls it ‚ÄúThe Financial Transactions Database.‚Äù Its primitives are <strong>debits and credits</strong>, which are things you may be familiar with from your accounting requirement in college. And if you‚Äôre not a bank, you‚Äôre probably thinking this whole thing isn‚Äôt really for you. But Joran (TigerBeetle‚Äôs creator) would tell you otherwise: financial transactions, i.e. debits and credits, are actually <em>exactly</em> what transactional SQL was originally designed for.&nbsp;</p><p>Way back in 1985, Jim Gray (who would later win a Turing Award) wrote a seminal paper on transactions, titled <a href="https://jimgray.azurewebsites.net/papers/AMeasureOfTransactionProcessingPower.pdf">A Measure of Transaction Processing Power</a>. If you‚Äôve heard of it before, it‚Äôs because in it, Gray defined a metric that 40 years later is <em>still</em> the most important measure for a database: <strong>TPS</strong>, or transactions per second. This would end up leading to such a fervent benchmark war among databases that an objective <em>council</em> ‚Äì <a href="https://www.tpc.org/information/about/history5.asp">the TPC</a> ‚Äì needed to be formed to moderate.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f23346_3d394e75.png" loading="lazy" alt=""></p><figcaption><em>The TPC in action, deciding on whether a young database had gone to the Dark Side (Oracle).</em>&nbsp;</figcaption></figure><p>But what does the ‚ÄúT‚Äù in TPS actually mean? What is a transaction?</p><p>Your first guess might be a SQL transaction, but that‚Äôs not it. Gray actually defined it as a <strong>business transaction</strong> derived from the real world. Which is the reason databases were invented in the first place: to power businesses. And indeed, <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2005/04/tr-2005-39.doc">20 years later</a>, Gray continued to see the standard measure of transaction processing as a ‚ÄúDebitCredit:‚Äù</p><blockquote><em>‚ÄúA database system to debit a bank account, do the standard double-entry bookkeeping and then reply to the terminal.‚Äù</em></blockquote><p>Mind you, SQL had already been around since the 70s at this point. And yet the luminary Gray still chose the debit/credit model ‚Äì because it was the <em>canonical example</em> of an everyday transaction. Debit/credit is the lingua franca of <a href="https://www.youtube.com/watch?v=lGyMiW6PnKI&amp;ab_channel=TuringAwardeeClips"><strong>what it means to transact</strong></a>. It is <em>not</em> just for accounting and banks. It‚Äôs the reason for a database to provide guarantees like ACID in the first place.</p><p>And yet, if you want to use a SQL database to implement debits and credits today, you are probably going to have a bad time. To handle one debit/credit, a typical system ‚Äì like the <a href="https://mojaloop.io/">central bank switch</a> that Joran consulted on in 2020 ‚Äì needs to query account balances, lock those rows, wait for decisions in code, then write back and record the debit/credit. All in all, you‚Äôre looking at <strong>10-20 SQL queries</strong> back and forth, while holding row locks across the network roundtrip time, <em>for each transaction</em>. This gets even worse when you consider the problem of hot rows, where many transactions often need to touch the same set of ‚Äúhouse accounts‚Äù.&nbsp;</p><p>All the while (for better or worse), the world is moving faster and faster towards an ‚Äúeverything is a transaction‚Äù model. Countries like India and Brazil are doing billions of transactions per month in instant payments. With <a href="https://www.frbservices.org/financial-services/fednow">FedNow</a> in the U.S., we‚Äôre not far away from that reality either. Meanwhile, other sectors like energy, gaming, and cloud are all moving towards real-time billing. In less than a decade, the world has become at least three orders of magnitude more transactional. And yet the SQL databases we still use to power this are 20-30 years old. Can they hold up?</p><p><strong>This is where TigerBeetle comes in</strong>. They designed a state-of-the-art database, from the ground up, to power the next era of transactions. In TigerBeetle, a debit/credit is a first class primitive and 8,190 of them can pack into a single 1MiB query via a one solitary roundtrip to the database. They call it <a href="https://www.youtube.com/watch?v=yKgfk8lTQuE">‚ÄúThe 1000x Performance Idea,‚Äù</a> but in Joran‚Äôs words it‚Äôs ‚Äúnothing special‚Äù.</p><p>They say databases take a decade to build. But TigerBeetle is complete and pretty much <a href="https://jepsen.io/analyses/tigerbeetle-0.16.11">Jepsen-proof</a> after just 3 and a half years. In June 2025, Kyle Kingsbury showed he was unable to break TigerBeetle‚Äôs foundations (he found 1 correctness bug in the read query engine, not affecting durability), even while corrupting the whole thing on every machine in various places.&nbsp;</p><p>The obvious question here ‚Äì <strong>how</strong>? How did TigerBeetle ship a production-ready, Jepsen-passing consensus and storage engine in 3.5 years when it typically takes a decade or more?</p><h2><strong>An (actually) modern database: distributed by default, why TigerBeetle uses Zig, and handling storage faults</strong></h2><p>Imagine you wake up today and wisely decide to build a database from scratch. Instead of investing in the technology of 30 years ago ‚Äì when the most popular relational databases today were built ‚Äì you can pick <em>any</em> advancements in architecture, hardware, language, or research since then to implement. How would you build it? What would you utilize?</p><h3><strong>Distributed by default</strong></h3><p>One thing you‚Äôd probably start with is the deployment model.&nbsp;</p><p>When Postgres and MySQL were built, in a world of big iron (on-prem hardware), the dominant paradigm was <strong>single node</strong>. Now, in a world of shared cloud hardware, it‚Äôs <strong>distributed</strong>. It‚Äôs not safe enough to store your transactions only on a single disk or server. A modern database needs to replicate your transactions, with strict serializability, across machines, for redundancy, fault tolerance and high availability. And yet some of the most popular OLTP databases in the world today are still highly dependent on a single node architecture. Automated failover, at least with zero data loss in the cut over, is not always baked in by default.</p><p>So TigerBeetle built their database to be distributed by default. Doing that comes with some of the obvious things you need to do, like consensus. But the developer experience for running TigerBeetle distributed is very simple: you just install the binary on however many machines you want in the cluster. No async replication, no Zookeeper, etc. To make this possible, TigerBeetle invested heavily in their consensus protocol implementation, adopting the pioneering <a href="https://pmg.csail.mit.edu/papers/vr.pdf">Viewstamped Replication</a> from MIT. This is part of why TigerBeetle has zero dependencies, apart from the Zig toolchain ‚Äî they literally invested in all their core dependencies.</p><h3><strong>Clock fault tolerance</strong></h3><p>Distributed by default also shows up in some unlikely places. For example: have you ever thought of a clock fault model?&nbsp;</p><p>Though it‚Äôs not technically required or advised for consensus ‚Äì which uses logical clocks and not physical clocks ‚Äì remember that TigerBeetle is a <em>transactions</em> database. The physical timestamps of transactions need to be accurate and comparable across different financial systems for auditing and compliance.</p><p>And here, readers will note that Linux has several clocks: <code>CLOCK_MONOTONIC_RAW</code>, <code>CLOCK_MONOTONIC</code> and <code>CLOCK_BOOTTIME</code>. All have slight but important differences. Which is the best monotonic clock to use? (clue: It doesn‚Äôt say <code>MONOTONIC</code> on the tin)</p><p>The challenge is that physical imperfections in hardware clocks cause clocks to tick at different speeds, so that time passes faster or slower than it should. These kinds of ‚Äúdrift‚Äù errors eventually add up to significant ‚Äúskew‚Äù errors within a short space of time. Most of the time, Network Time Protocol (NTP) would correct for these errors. But if NTP silently stops working because of a partial network outage, then a highly available consensus cluster might otherwise be running blind, in the dark.</p><p>But even this is something TigerBeetle thought about. They combine <em>the majority of clocks</em> in the cluster to construct a fault-tolerant clock called ‚Äúcluster time‚Äù. This cluster time then gets used to bring a server‚Äôs system time back into line if necessary, or shut down safely if TigerBeetle detects that there are too many faulty clocks (e.g. TigerBeetle can actually detect when something like Chrony, PTP, or NTP have stopped working and alert the operator).&nbsp;</p><p>They do this by tracking offset clock times between different TigerBeetle servers, sampling them, and passing them through <a href="https://en.wikipedia.org/wiki/Marzullo%27s_algorithm">Marzullo‚Äôs algorithm</a> to estimate the most accurate possible interval (again, just to get a sense of whether clocks are being synced by the underlying clock sync protocol correctly).</p><p>Small things like this are exactly why distributed by default is hard, and doesn‚Äôt work as an add-on for older database models. You can read more about this in TigerBeetle's <a href="https://tigerbeetle.com/blog/2021-08-30-three-clocks-are-better-than-one/">3 clocks are better than one</a> blog post.</p><p>‚Äç</p><h3><strong>Handling storage faults</strong></h3><p>Another piece of ‚Äúdistributed by default‚Äù that deserves its own header is how TigerBeetle handles <strong>storage faults</strong> (or even the fact it handles them at all). Traditional databases assume that if disks fail, they do so predictably with a nice error message. For example, even <a href="https://www.sqlite.org/atomiccommit.html">SQLite‚Äôs docs</a> are clear that:</p><blockquote><em>SQLite does not add any redundancy to the database file for the purpose of detecting corruption or I/O errors. SQLite assumes that the data it reads is exactly the same data that it previously wrote.</em></blockquote><p>In reality, there are many more sinister possibilities: disks can silently return corrupt data, misdirect I/O (on the read or write path), or just suddenly get really slow (called <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf">gray failure</a> in the research), all without returning error codes.&nbsp;</p><p>TigerBeetle is built to be storage fault tolerant:</p><ul role="list"><li>TigerBeetle uses <a href="https://www.usenix.org/conference/fast18/presentation/alagappan">Protocol Aware Recovery</a> to remain available unless all copies of a piece of data get corrupted on every single replica.</li><li>All data in TigerBeetle is immutable, checksummed, and hash-chained, providing a strong guarantee that no corruption or tampering happened.</li><li>TigerBeetle puts as little software as possible between itself and the disk, including a custom page cache, writing data to disk with O_DIRECT, and even running on a raw block device directly (no filesystem necessary ‚Äî to sidestep filesystem bugs <a href="https://news.ycombinator.com/item?id=36113828">which do tend to happen</a> from time to time).</li><li>They built their own implementation of LSM instead of using an off-the-shelf one ‚Äì they call it an <a href="https://www.youtube.com/watch?v=yBBpUMR8dHw">LSM Forest</a>, which is something like 20 different LSM trees.</li></ul><p>As far as I‚Äôm aware TigerBeetle is the only distributed database that not only claims to be storage fault tolerant, but was also tested pretty hard and validated by Jepsen to be. If you have a local machine failure where even just a disk sector fails, then that storage engine is connected to the global consensus, and it can use the cluster to self heal. This is also a great example of why the modern database having access to modern research matters: <a href="https://www.usenix.org/conference/fast18/presentation/alagappan">Protocol-Aware Recovery</a>, which enables TigerBeetle to survive disk failures like this, is fairly recent (2018) research.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f23349_629bea61.png" loading="lazy" alt=""></p></figure><h3><strong>TigerBeetle in Zig</strong></h3><p>Another thing you‚Äôd think about when building a modern database from scratch is your choice of <strong>programming language</strong>. Postgres is written in C (c. 1970s), MySQL in C and C++ (1979), and MSSQL as well in C and C++. But programming languages have come a long way in the past 40 years. If you had your choice, what would you build a database in today?</p><p>The answer would probably be Rust or Zig. And indeed, TigerBeetle is built 100% in Zig:&nbsp;</p><ul role="list"><li>You get the whole C ecosystem available to you, extended with a phenomenal toolchain and compiler.</li><li>It‚Äôs easy to write, and especially easy to read, in some cases as easy as TypeScript (just a lot faster).</li><li>Zig lets you statically allocate memory, which is a core principle of TigerBeetle.</li><li>Zig has a great developer experience and you can learn it quickly (which ergo means you can get into the TigerBeetle src quickly).</li></ul><p>Of course, as new systems languages, Zig and Rust are related, and some of the early Rust team now work at TigerBeetle, including <a href="https://matklad.github.io/">Matklad</a> (creator of <a href="https://rust-analyzer.github.io/">Rust Analyzer</a>) and <a href="https://brson.github.io/">Brian Anderson</a> (co-creator of Rust with Graydon). They‚Äôve <a href="https://matklad.github.io/2023/03/26/zig-and-rust.html">written extensively</a> about these languages and why Joran chose Zig in particular for TigerBeetle, given their design goals.</p><p>And here, of course, TigerBeetle is fanatical about static memory allocation, which I‚Äôll talk more about in the next section. Not using dynamic memory allocation is ‚Äúhard mode‚Äù in Rust (as matklad wrote about <a href="https://matklad.github.io/2022/10/06/hard-mode-rust.html">here</a>), but a breeze in Zig.</p><p>‚Äç</p><h2><strong>Deterministic Simulation Testing and the VOPR</strong></h2><p>Sometimes, Deterministic Simulation Testing (DST) feels like the most transformational technology that the fewest developers know about. It‚Äôs a <a href="https://notes.eatonphil.com/2024-08-20-deterministic-simulation-testing.html">novel testing technique</a> made popular by the <a href="https://www.foundationdb.org/">FoundationDB</a> team (which now belongs to Apple); they used it to develop a more secure, bug-free distributed database in a shorter time span than arguably anyone had done before.&nbsp;</p><p>The <a href="https://www.youtube.com/watch?v=cHA8vyZvkCs">fundamentals of DST</a> go something like this. In distributed systems, there are essentially infinite combinations of concurrency issues: anything from lost messages to unpredictable thread execution order. You simply cannot use old-school unit and integration tests, or your system will suck. Formal verification, a more academic discipline that works on formulaic proofs that a program runs as intended, is too expensive and slow. So what are you to do?</p><p>The answer is a simulator that deterministically runs almost every possible scenario your system will face on a specific chronological timeline. The simulator accounts for external factors too, like issues with the OS, network, or disk, or simply different latencies. All in all, DST can give you the equivalent of years‚Äô worth of testing in a very short time period (because time itself becomes deterministic‚Äîa while true loop); and DST is particularly well suited towards databases (I/O intensive, not compute intensive). If you‚Äôre familiar with Jepsen testing, think of it as <a href="https://antithesis.com/blog/is_something_bugging_you/">a subset of what DST can do</a>.&nbsp;</p><p>TigerBeetle is one of the most pioneering startups on the planet when it comes to DST. They‚Äôve developed their own testing cluster ‚Äì it‚Äôs nicknamed VOPR, short for Viewstamped Operation Replicator (<a href="https://www.youtube.com/watch?v=iRsycWRQrc8">after the WOPR simulator in the movie WarGames</a>). The VOPR constantly (and tirelessly) tests TigerBeetle under countless different conditions, covering everything from how nodes elect a leader to individual states and network faults. But it can simulate a whole distributed cluster virtually, all on a single thread.</p><p>As far as your author is aware, TigerBeetle‚Äôs VOPR is the single largest DST cluster on the planet. <a href="https://us13.campaign-archive.com/?u=32cd932058e988b44c838f7bc&amp;id=0c749f7b07">It runs on</a> 1,000 CPU cores, a number so unusually large that Hetzner sent them a special email asking if they were sure they wanted that many cores. The so-called VOPR-1000 is running 24x7x365, to catch rare conditions as far as possible before production. With time abstracted deterministically, and accelerated in the simulator by a factor of (roughly) 700x, this adds up to nearly 2 millennia of simulated runtime per day.</p><p>‚Äç</p><h3><strong>But what if DST was fun?</strong></h3><p>Yea, distributed systems are cool. But you know what‚Äôs even cooler? Video games.</p><p>TigerBeetle turned DST into a game that lets you play through different failure scenarios in how the system reacts. You can play it <a href="https://sim.tigerbeetle.com/">here</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f2334c_13e94615.png" loading="lazy" alt=""></p></figure><p>What‚Äôs perhaps even cooler is that this game is running an actual instance of the VOPR, simulating TigerBeetle‚Ä¶in your browser. It‚Äôs compiled to WebAssembly, and then TigerBeetle‚Äôs own engineers built a gaming frontend on top to visualize the real system</p><p>You can read more about how and why TigerBeetle built the simulator in <a href="https://tigerbeetle.com/blog/2023-07-11-we-put-a-distributed-database-in-the-browser/">this blog post</a>.</p><p>‚Äç</p><h2><strong>TigerStyle and The Power of Ten</strong></h2><p>As you will continue to see with TigerBeetle, it is often not just the <em>what</em> they‚Äôve built that catches the eye but also the <em>how</em>. There‚Äôs no better example than <strong>TigerStyle</strong>.</p><p><a href="https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TIGER_STYLE.md">TigerStyle</a> is TigerBeetle‚Äôs engineering methodology, public on GitHub for all to see. Here‚Äôs how they describe it:</p><blockquote><em>‚ÄúTigerBeetle's coding style is evolving. A collective give-and-take at the intersection of engineering and art. Numbers and human intuition. Reason and experience. First principles and knowledge. Precision and poetry. Just like music. A tight beat. A rare groove. Words that rhyme and rhymes that break. Biodigital jazz. This is what we've learned along the way. The best is yet to come.‚Äù</em></blockquote><p>Biodigital jazz is a term from <a href="https://en.wikipedia.org/wiki/Tron:_Legacy">Tron: Legacy</a>. In the context of the film, it represents the intertwining of human and digital elements, the chaotic yet structured nature of the ‚ÄúGrid‚Äù (the digital world), and the improvisational spirit of human potential within the confines of technology (I copied this from AI). For TigerBeetle, it‚Äôs an ethos of code; remembering to infuse everything they do with not just science, but art too.</p><p>More practically, TigerStyle lays out engineering and code principles for TigerBeetle, many derived from the original <a href="https://spinroot.com/gerard/pdf/P10.pdf">Power of Ten</a>, NASA‚Äôs tenets for writing foolproof code. TigerStyle spans from the thematic, like simplicity and elegance, to the applied, like how to name things. It‚Äôs even starting to impact other companies like Resonate and Turso; and <a href="https://youtu.be/tNZnLkRBYA8?t=11167">TigerStyle has even been discussed on Lex Fridman</a>. Here are a few highlights.</p><h3><strong>Using assertions, and the Power of Ten</strong></h3><p>Speaking of the Power of Ten‚Ä¶one of them (Rule 5) is about <strong>assertions</strong>. The idea is simple: explicitly encode your expectations of code behavior <em>while</em> you are writing it, not after the fact. You write them simply in a single line as booleans: assert(a &gt; b). TigerStyle calls for:</p><ul role="list"><li>Asserting all function arguments, return values, preconditions, and invariants. On average there should be at least 2 assertions per function.</li><li>Using assertions <em>instead</em> of comments when the assertion is both important and surprising.</li><li>Asserting the relationships between compile-time constants, so you can check a program‚Äôs design integrity before it even runs.</li><li>Not just assert what <em>should</em> happen, but also the negative space that you don‚Äôt expect ‚Äì where interesting bugs can show up.</li></ul><p><a href="https://spinroot.com/gerard/pdf/P10.pdf">The Power of Ten</a> is an amazing artifact that covers so much more than just assertions‚Ä¶it‚Äôs a great resource for any modern programmer (and maybe we should train some LLMs on it too).</p><h3><strong>Thinking about performance</strong></h3><p>Much of TigerStyle centers around the idea that <em>writing</em> code is not the most important part of the cycle; instead, it‚Äôs <strong>reasoning about</strong> and <strong>designing</strong> the code. When it comes to performance, TigerStyle implores you to think about it from the start:&nbsp;</p><blockquote><em>‚ÄúThe best time to solve performance, to get the huge 1000x wins, is in the design phase, which is precisely when we can't measure or profile.‚Äù</em></blockquote><p>You should be doing basic napkin math on what TigerStyle calls ‚Äúthe four primary colors‚Äù ‚Äì network, storage, memory, CPU ‚Äì and how they‚Äôll perform with respect to (‚Äúthe two textures‚Äù ‚Äî art!) bandwidth and latency. Then, there are a few more tactical tips, like distinguishing between the control plane and data plane, batching accesses, and extracting hot loops into stand-alone functions to reduce dependence on the compiler.&nbsp;</p><p>For more about TigerStyle, watch <a href="https://www.youtube.com/watch?v=w3WYdYyjek4&amp;t=5s&amp;ab_channel=TigerBeetle">Joran‚Äôs talk at Systems Distributed</a>.</p><h2>Try it out for yourself</h2><p>So is TigerBeetle a database? Yes. But it‚Äôs not much like any other database I‚Äôve seen. They‚Äôve taken modern research and applied it to an age-old form, giving their database unprecedented performance and stability guarantees. They‚Äôve developed an art form around systems and storage engineering, and they haven‚Äôt forgotten to have fun along the way. And thanks to their clever use of DST, they were able to build this thing to Jepsen standards in only a few years.&nbsp;</p><p>You can get started with TigerBeetle <a href="https://tigerbeetle.com/#install">here</a> using a simple curl command.&nbsp;</p></div></div>]]></description>
        </item>
    </channel>
</rss>