<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 13 Feb 2024 20:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How to center a div in CSS (106 pts)]]></title>
            <link>https://www.joshwcomeau.com/css/center-a-div/</link>
            <guid>39360856</guid>
            <pubDate>Tue, 13 Feb 2024 18:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.joshwcomeau.com/css/center-a-div/">https://www.joshwcomeau.com/css/center-a-div/</a>, See on <a href="https://news.ycombinator.com/item?id=39360856">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-layout="tutorial"><a id="introduction"><h2>Introduction</h2></a><p>For a long time, centering an element within its parent was a surprisingly tricky thing to do. As CSS has evolved, we've been granted more and more tools we can use to solve this problem. These days, we're spoiled for choice!</p><p>I decided to create this tutorial to help you understand the trade-offs between different approaches, and to give you an arsenal of strategies you can use, to handle centering in all sorts of scenarios.</p><p>Honestly, this turned out to be <em>way more interesting</em> than I initially thought<!-- -->&nbsp;<!-- -->üòÖ. Even if you've been using CSS for a while, I bet you'll learn at least 1 new strategy!</p><div id="centering-with-auto-margins"><h2><a name="centering-with-auto-margins-1" id="centering-with-auto-margins-1" href="#centering-with-auto-margins-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering with auto margins</h2></div><p>The first strategy we'll look at is one of the oldest. If we want to center an element horizontally, we can do so using margins set to the special value <code>auto</code>:</p><!--$?--><template id="B:0"></template><!--/$--><p>First, we need to constrain the element's width; by default, elements in Flow layout will expand horizontally to fill the available space, and we can't really center something that is full-width.</p><p>I <em>could</em> constrain the width with a fixed value (eg. <code>200px</code>), but really what I want in this case is for the element to shrinkwrap around its content. <code>fit-content</code> is a magical value that does exactly this. Essentially, it makes ‚Äúwidth‚Äù behave like ‚Äúheight‚Äù, so that the element‚Äôs size is determined by its contents.</p><p><strong>Why am I setting <code>max-width</code> instead of <code>width</code>?</strong> Well, my goal is to stop the element from expanding horizontally. I want to clamp its maximum size. If I used <code>width</code> instead, it would lock it to that size, and the element would overflow when the container is really narrow. If you drag that ‚ÄúContainer Width‚Äù slider all the way to the left, you can see that the element shrinks with its container.</p><p>Now that our element is constrained, we can center it with <em>auto margins</em>.</p><p>I like to think of auto margins like <em>Hungry Hungry Hippos</em>. Each auto margin will try to gobble up as much space as possible. For example, check out what happens if we <em>only</em> set <code>margin-left: auto</code>:</p><!--$?--><template id="B:1"></template><!--/$--><p>When <code>margin-left</code> is the only side with auto margins, <em>all</em> of the extra space gets applied as margin to that side. When we set both <code>margin-left: auto</code> <em>and</em> <code>margin-right: auto</code>, the two hippos each gobble up an equal amount of space. This forces the element to the center.</p><p><em>Also:</em> I've been using <code>margin-left</code> and <code>margin-right</code> because they're familiar, but there's a better, more-modern way to do this:</p><!--$?--><template id="B:2"></template><!--/$--><p><code>margin-inline</code> will set both <code>margin-left</code> and <code>margin-right</code> to the same value (<code>auto</code>). It has <a href="https://caniuse.com/mdn-css_properties_margin-inline" rel="noopener noreferrer" target="_blank">very good browser support</a>, having landed in all major browsers several years ago.</p><p>Even though this centering method has been around forever, I still find myself reaching for it on a regular basis! It's particularly useful when we want to center a single child, without affecting any of its siblings (for example, an image in-between paragraphs in a blog post).</p><p>Let's continue on our centering journey.</p><div id="centering-with-flexbox"><h2><a name="centering-with-flexbox-2" id="centering-with-flexbox-2" href="#centering-with-flexbox-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering with Flexbox</h2></div><p>Flexbox is designed to give us a <em>ton</em> of control when it comes to distributing a group of items along a primary axis. It offers some <em>really</em> powerful tools for centering!</p><p>Let's start by centering a single element, both horizontally and vertically:</p><!--$?--><template id="B:3"></template><!--/$--><p>The really cool thing about Flexbox centering is that it works <em>even when the children don‚Äôt fit in their container!</em> Try shrinking the width/height, and notice that the element overflows symmetrically.</p><p>It also works for <em>multiple</em> children. We can control how they stack with the <code>flex-direction</code> property:</p><!--$?--><template id="B:4"></template><!--/$--><p>Out of all the centering patterns we'll explore in this tutorial, this is probably the one I use the most. It's a great jack-of-all-trades, a great default option.</p><div id="centering-within-the-viewport"><h2><a name="centering-within-the-viewport-3" id="centering-within-the-viewport-3" href="#centering-within-the-viewport-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering within the viewport</h2></div><p>So far, we've been looking at how to center an element within its parent container. But what if we want to center an element in a different context? Certain elements like dialogs, prompts, and GDPR banners need to be centered within the viewport.</p><p>This is the domain of <em>positioned layout,</em> a layout mode used when we want to take something out of flow and anchor it to something else.</p><p>Here's what this looks like:</p><!--$?--><template id="B:5"></template><!--/$--><p>Of all the strategies we'll discuss, this one is probably the most complex. Let's break it down.</p><p>We're using <code>position: fixed</code>, which anchors this element to the viewport. I like to think of the viewport like a pane of glass that sits in front of the website, like the window of a train that shows the landscape scrolling by. An element with <code>position: fixed</code> is like a ladybug that lands on the window.</p><p>Next, we're setting <code>inset: 0px</code>, which is a shorthand that sets <code>top</code>, <code>left</code>, <code>right</code>, and <code>bottom</code> all to the same value, <code>0px</code>.</p><p>With only these two properties, the element would stretch to fill the entire viewport, growing so that it's 0px from each edge. This can be useful in some contexts, but it's not what we're going for here. We need to constrain it.</p><p>The exact values we pick will vary on the specifics of each situation, but in general we want to set default values (with <code>width</code> and <code>height</code>), as well as max values (<code>max-width</code> and <code>max-height</code>), so that the element doesn't overflow on smaller viewports.</p><p><strong>There's something interesting here:</strong> we've set up an impossible condition. Our element can't be 0px from the left <em>and</em> 0px from the right <em>and</em> only 12rem wide (assuming the viewport is wider than 12rem). We can only pick 2:</p><!--$?--><template id="B:6"></template><!--/$--><p><strong>The CSS rendering engine resolves this tension by prioritizing.</strong> It will listen to the <code>width</code> constraint, since that seems important. And if it can't anchor to the left <em>and</em> the right, it'll pick an option based on the page's language; so, in a left-to-right language like English, it'll sit along the left edge.</p><p><em>But!</em> When we bring our old friend <code>margin: auto</code> into the equation, something interesting happens. It changes how the browser resolves the impossible condition; instead of anchoring to the left edge, <em>it centers it</em>.</p><p>And, unlike auto margins in <em>Flow</em> layout, we can use this trick to center an element both horizontally <em>and</em> vertically.</p><!--$?--><template id="B:7"></template><!--/$--><p>It's a lot to remember, but there are 4 key ingredients for this trick.</p><ol><li><p>Fixed positioning</p></li><li><p>Anchoring to all 4 edges with <code>inset: 0px</code></p></li><li><p>Constrained width and height</p></li><li><p>Auto margins</p></li></ol><p>We can use the same trick to center something in a single direction. For example, we can build a GDPR cookie banner that is horizontally centered, but anchored near the bottom of the viewport:</p><!--$?--><template id="B:8"></template><!--/$--><p>By omitting <code>top: 0px</code>, we remove the impossible condition in the vertical direction, and our banner is anchored to the bottom edge. As a nice touch, I used the <code>calc</code> function to clamp the max width, so that there's always a bit of buffer around the element.</p><p>I also swapped <code>margin: auto</code> for <code>margin-inline: auto</code>, which isn't strictly necessary, but feels more precise.</p><div id="centering-elements-with-unknown-sizes"><h3><a name="centering-elements-with-unknown-sizes-4" id="centering-elements-with-unknown-sizes-4" href="#centering-elements-with-unknown-sizes-4"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering elements with unknown sizes</h3></div><p>This ‚Äúfixed position‚Äù strategy requires that we give the element a fixed <code>width</code> and <code>height</code>; otherwise, the element will stretch to fill the entire viewport!</p><p>Sometimes, though, we don't want to give the element a fixed size. We want it to be sized based on its contents.</p><p>We can solve this problem using a clever trick with transforms:</p><!--$?--><template id="B:9"></template><!--/$--><p>This works because <code>top</code> and <code>left</code> percentages are based on the <em>viewport‚Äôs</em> size, while <code>transform</code> is based on the <em>element‚Äôs</em> size. You can think of this as a two-step process:</p><ol><li><p>Using <code>top</code> and <code>left</code>, position the modal so that its top-left corner is right in the center of the viewport.</p></li><li><p>Using <code>transform</code>, slide the element up and back by half of its <em>own</em> size.</p></li></ol><p>Honestly, this isn't my favourite approach. It feels like a hack, and there are some unintuitive consequences; for example, the element can't grow beyond 50% of the viewport‚Äôs size. As a result, I don't find myself reaching for this approach super often.</p><div id="centering-with-css-grid"><h2><a name="centering-with-css-grid-5" id="centering-with-css-grid-5" href="#centering-with-css-grid-5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering with CSS Grid</h2></div><p>The most terse way I know to center something both horizontally and vertically is with CSS Grid:</p><!--$?--><template id="B:a"></template><!--/$--><p>The <code>place-content</code> property is a shorthand for both <code>justify-content</code> and <code>align-content</code>, applying the same value to both rows and columns. The result is a 1√ó1 grid with a cell right in the middle of the parent container.</p><div id="differences-from-flexbox"><h3><a name="differences-from-flexbox-6" id="differences-from-flexbox-6" href="#differences-from-flexbox-6"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Differences from Flexbox</h3></div><p>This solution <em>looks</em> quite a bit like our Flexbox solution, but it's important to keep in mind that it uses a totally different layout algorithm. In my own work, I've found that the CSS Grid solution isn't as universally effective as the Flexbox one.</p><p>For example, consider the following setup:</p><!--$?--><template id="B:b"></template><!--/$--><p>Weird, right? Why does the CSS Grid version get so teensy-tiny?!</p><p><strong>Here's the deal:</strong> the child element is given <code>width: 50%</code> and <code>height: 50%</code>. In Flexbox, these percentages are calculated based on the parent element, <code>.container</code>, which is what we want.</p><p>In CSS Grid, however, the percentages are <em>relative to the grid cell.</em> We're saying that the child element should be 50% as wide as its column, and 50% as tall as its row.</p><p>Now, we haven't actually given the row/column an explicit size; we haven't defined <code>grid-template-columns</code> or <code>grid-template-rows</code>. When we omit this information, the grid tracks will calculate their size <em>based on their contents</em>, shrinkwrapping around whatever is in each row/column.</p><p>The end result is that our grid cell is the same size as <code>.element</code>‚Äôs original size, and then the element shrinks to 50% of that grid cell:</p><!--$?--><template id="B:c"></template><!--/$--><p>This is a whole rabbithole, and I don't want to get too far off track; my point is that CSS Grid is a sophisticated layout algorithm, and sometimes, the extra complexity gets in the way. We <em>could</em> add some more CSS to fix this code, but I think it's simpler to use Flexbox instead.</p><div id="centering-a-stack-of-elements"><h3><a name="centering-a-stack-of-elements-7" id="centering-a-stack-of-elements-7" href="#centering-a-stack-of-elements-7"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering a stack of elements</h3></div><p><strong>CSS Grid gives us one more centering super-power.</strong> With CSS Grid, we can assign multiple elements to the same cell:</p><!--$?--><template id="B:d"></template><!--/$--><p>We still have a 1√ó1 grid, except now we're cramming <em>multiple</em> children to sit in that cell with <code>grid-row</code> / <code>grid-column</code>.</p><p>In case it's not clear, here's a quick sketch of the HTML for this kind of setup:</p><pre></pre><p>In other layout modes, the elements would stack horizontally or vertically, but with this CSS Grid setup, the elements stack back-to-front, since they're all told to share the same grid space. Pretty cool, right?</p><p>Incredibly, this can work <em>even when the child elements are different sizes!</em> Check this out:</p><!--$?--><template id="B:e"></template><!--/$--><p>In this demo, dashed red lines are added to show the grid row and column. Notice that they expand to contain the largest child; with all the elements added, the resulting cell is as wide as the pink skyline image, and as tall as the colourful space image!</p><p>We do need one more property to make this work: <code>place-items: center</code>. <code>place-items</code> is a shorthand for <code>justify-items</code> and <code>align-items</code>, and these properties control the alignment of the images <em>within</em> the grid cell.</p><p>Without this property, the grid cell would still be centered, but the images <em>within</em> that cell would all stack in the top-left corner:</p><!--$?--><template id="B:f"></template><!--/$--><p><em>This is pretty advanced stuff!</em> You can learn more about how the CSS Grid layout mode works in a recent tutorial I published, <a href="https://www.joshwcomeau.com/css/interactive-guide-to-grid/">An Interactive Guide to CSS Grid</a>.</p><div id="centering-text"><h2><a name="centering-text-8" id="centering-text-8" href="#centering-text-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering text</h2></div><p>Text is its own special thing in CSS. We can't influence individual characters using the techniques explored in this post.</p><p>For example, if we try to center a paragraph with Flexbox, we'll center the <em>block of text</em>, not the text itself:</p><!--$?--><template id="B:10"></template><!--/$--><p>Flexbox is centering the paragraph within the viewport, but it doesn't affect the individual characters. They remain left-aligned.</p><p>We need to use <code>text-align</code> to center the text:</p><!--$?--><template id="B:11"></template><!--/$--><div id="centering-in-the-future"><h2><a name="centering-in-the-future-9" id="centering-in-the-future-9" href="#centering-in-the-future-9"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Centering in the future</h2></div><p>Earlier, we saw how we can use auto margins to center an element horizontally in Flow layout. If we want that element to be centered vertically as well, we need to switch to a different layout mode, like Flexbox or Grid.</p><p>‚Ä¶or do we?</p><p>Check this out:</p><!--$?--><template id="B:12"></template><!--/$--><p><em>What the heck??</em> <code>align-content</code> is a CSS Grid thing, but we aren't setting <code>display: grid</code> here. How is this working?</p><p>One of the biggest epiphanies I've ever had about CSS is that it's a <em>collection of layout algorithms.</em> The properties we write are <em>inputs</em> to those algorithms. <code>align-content</code> was first implemented in Flexbox, and took on an even bigger role in CSS Grid, but it wasn't implemented in the default layout algorithm, Flow layout. Until now.</p><p>As I write this in early 2024, browser vendors are in the process of implementing <code>align-content</code> in Flow layout, so that it controls the ‚Äúblock‚Äù direction alignment of content. It's still early days; this new behaviour is only available in Chrome Canary (<a href="chrome://flags/#enable-experimental-web-platform-features">behind a flag</a>) and Safari Technical Preview.</p><p>(I should note, the demo above is fake. I got a feel for the new <code>align-content</code> support in Chrome Canari and Safari TP, and then recreated the exact same behaviour using Flexbox. Sorry for the deception!)</p><div id="going-beyond-the-patterns"><h2><a name="going-beyond-the-patterns-10" id="going-beyond-the-patterns-10" href="#going-beyond-the-patterns-10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Going beyond the patterns</h2></div><p>So, for many years, I treated CSS like a collection of patterns. I had a bunch of memorized snippets that would paste from my brain, to solve whatever problem I was currently facing.</p><p>This worked alright, but it did feel pretty limiting. And every now and then, things would inexplicably break; a snippet I‚Äôd used hundreds of times would suddenly behave differently.</p><p>When I took the time to learn CSS at a deeper level, my experience with the language completely changed. So many things clicked into place. Instead of relying on memorized snippets, I could instead rely on my intuition! ‚ú®</p><p>In this tutorial, we‚Äôve explored a handful of useful centering patterns, and I hope they‚Äôll come in handy the next time you need to center something. Truthfully, though, we've only scratched the surface here; there are <em>so many ways</em> we can use modern CSS to center stuff! Instead of memorizing even more snippets, I think it's better to build a robust mental model of how CSS works, so that we can come up with solutions on-the-fly!</p><p>I spent 2 years of my life creating the ultimate resource for developing a deep understanding of CSS. It's called <a href="https://css-for-js.dev/" rel="noopener noreferrer" target="_blank"><strong>CSS for JavaScript Developers</strong></a>.</p><p>If you found this tutorial helpful, you‚Äôll get <em>so much</em> out of my course. We take a similar approach to the entire CSS language, building an intuition for how all of the different layout algorithms work.</p><p>It includes interactive text content like this blog post, but also videos, exercises, real-world-inspired workshops, and even a few minigames. It's unlike any other course you‚Äôve taken.</p><p>If this sounds interesting to you, you can learn more here:</p><ul><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span></li></ul><div id="when-to-use-which-method"><h2><a name="when-to-use-which-method-11" id="when-to-use-which-method-11" href="#when-to-use-which-method-11"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>When to use which method</h2></div><p>Before we wrap up, let's summarize what we've learned by building a sort of decision tree, so that we can figure out when to use which method.</p><ul><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>If we want to horizontally center a single element without disturbing any of its siblings, we can use the <a href="#centering-with-auto-margins">Flow layout margin strategy</a>.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>If we have a piece of floating UI, like a modal or a banner, we can center it using either <a href="#centering-within-the-viewport">Positioned layout margins</a> (if the width/height is known) or <a href="#centering-elements-with-unknown-sizes">the transform trick</a> (if the width/height is unknown).</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>If we want to center a stack of elements one on top of the other, we can use <a href="#centering-a-stack-of-elements">CSS Grid</a>.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>If we want to center text, we can use <a href="#centering-text">text-align</a>. This can be used in conjunction with any of the additional methods.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Finally, in most other situations, we can use <a href="#centering-with-flexbox">Flexbox</a>. It's the most versatile method; it can be used to center one or multiple children, horizontally and/or vertically, whether they're contained or overflowing.</p></li></ul><p>Like a carpenter‚Äôs workshop, we've assembled quite a lot of helpful tools in this tutorial, each with its own specialized purpose. I hope that you‚Äôve learned some new strategies here! Happy centering. ‚ù§Ô∏è</p><div><div><h3>Last Updated</h3><p>February 13th, 2024</p></div><div><h3>Hits</h3></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memory and new controls for ChatGPT (162 pts)]]></title>
            <link>https://openai.com/blog/memory-and-new-controls-for-chatgpt</link>
            <guid>39360724</guid>
            <pubDate>Tue, 13 Feb 2024 18:10:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/blog/memory-and-new-controls-for-chatgpt">https://openai.com/blog/memory-and-new-controls-for-chatgpt</a>, See on <a href="https://news.ycombinator.com/item?id=39360724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><!--[--><div><p>We‚Äôre testing memory with ChatGPT. Remembering things you discuss across all chats saves you from having to repeat information and makes future conversations more helpful.</p><p>You're in control of ChatGPT's memory. You can explicitly tell it to remember something, ask it what it remembers, and tell it to forget conversationally or through settings. You can also turn it off entirely.</p><p>We are rolling out to a small portion of ChatGPT free and Plus users this week to learn how useful it is. We will share plans for broader roll out soon.&nbsp;<br></p></div><!--]--><!--[--><div id="how-memory-works" data-heading=""><p><h2>How memory works</h2></p></div><!--]--><!--[--><div><p>As you chat with ChatGPT, you can ask it to remember something specific or let it pick up details itself. ChatGPT‚Äôs memory will get better the more you use it and you'll start to notice the improvements over time. For example:&nbsp;</p><ul><li>You‚Äôve explained that you prefer meeting notes to have headlines, bullets and action items summarized at the bottom. ChatGPT remembers this and recaps meetings this way.</li><li>You‚Äôve told ChatGPT you own a neighborhood coffee shop. When brainstorming messaging for a social post celebrating a new location, ChatGPT knows where to start.&nbsp;</li><li>You mention that you have a toddler and that she loves jellyfish. When you ask ChatGPT to help create her birthday card, it suggests a jellyfish wearing a party hat.&nbsp;</li><li>As a kindergarten teacher with 25 students, you prefer 50-minute lessons with follow-up activities. ChatGPT remembers this when helping you create lesson plans.<br></li></ul></div><!--]--><!--[--><div id="you-re-in-control" data-heading=""><p><h2>You‚Äôre in control</h2></p></div><!--]--><!--[--><div><p>You can turn off memory at any time (Settings &gt; Personalization &gt; Memory). While memory is off, you won't create or use memories.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>If you want ChatGPT to forget something, just tell it. You can also view and delete specific memories or clear all memories in settings (Settings &gt; Personalization &gt; Manage Memory). ChatGPT's memories evolve with your interactions and aren't linked to specific conversations. Deleting a chat doesn't erase its memories; you must delete the memory itself. You can find more details in our <a href="https://help.openai.com/en/articles/8590148-memory-faq" rel="noopener noreferrer" target="_blank">Help Center</a>.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>We may use content that you provide to ChatGPT, including memories, to improve our models for everyone. If you‚Äôd like, you can turn this off through your Data Controls. As always, we won't train on content from ChatGPT Team and Enterprise customers. Learn more about how we use content to train our models and your choices in our <a href="https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance" rel="noopener noreferrer" target="_blank">Help Center</a>.<br></p></div><!--]--><!--[--><div id="use-temporary-chat-for-conversations-without-memory" data-heading=""><p><h2>Use temporary chat for conversations without memory</h2></p></div><!--]--><!--[--><div><p>If you‚Äôd like to have a conversation without using memory, use temporary chat. Temporary chats won't appear in history, won't use memory, and won't be used to train our models. Learn more about temporary chats in our <a href="https://help.openai.com/en/articles/8914046-temporary-chat-faq" rel="noopener noreferrer" target="_blank">Help Center</a>.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="custom-instructions-also-allow-chatgpt-to-be-more-helpful" data-heading=""><p><h2>Custom instructions also allow ChatGPT to be more helpful</h2></p></div><!--]--><!--[--><div><p><a href="https://openai.com/blog/custom-instructions-for-chatgpt" rel="noopener noreferrer" target="_blank">Custom Instructions</a> continue to allow you to provide ChatGPT with direct guidance on what you‚Äôd like it to know about you and how you‚Äôd like it to respond. For explicit information or instructions, you can add it to your Custom Instructions. For information shared via conversations, ChatGPT can remember relevant details for you.<br></p></div><!--]--><!--[--><div id="evolving-our-privacy-and-safety-standards" data-heading=""><p><h2>Evolving our privacy and safety standards</h2></p></div><!--]--><!--[--><div><p>Memory brings additional privacy and safety considerations, such as what type of information should be remembered and how it‚Äôs used. We‚Äôre taking steps to assess and mitigate biases, and steer ChatGPT away from proactively remembering sensitive information, like your health details - unless you explicitly ask it to.<br></p></div><!--]--><!--[--><div id="team-and-enterprises-customers-can-work-more-efficiently" data-heading=""><p><h2>Team and Enterprises customers can work more efficiently</h2></p></div><!--]--><!--[--><div><p>For Enterprise and Team users, memory can be useful when using ChatGPT for work. It can learn your style and preferences, and build upon past interactions. This saves you time and leads to more relevant and insightful responses. For example:</p><ul><li>ChatGPT can remember your tone, voice, and format preferences, and automatically apply them to blog post drafts without needing repetition.</li><li>When coding, you tell ChatGPT your programming language and frameworks. It can remember these preferences for subsequent tasks, streamlining the process.</li><li>For monthly business reviews, you securely upload your data to ChatGPT and it creates your preferred charts with three takeaways each.</li></ul><p>As with any ChatGPT feature, you‚Äôre in control of your organization‚Äôs data. Memories and any other information on your workspace are excluded from training our models. Users have control on how and when their memories are used in chats. In addition, Enterprise account owners can turn memory off for their organization at any time.</p><p>Enterprise and Team users will have access to memory as part of our wider rollout.<br></p></div><!--]--><!--[--><div id="gpts-will-also-have-memory" data-heading=""><p><h2>GPTs will also have memory</h2></p></div><!--]--><!--[--><div><p>GPTs will have their own distinct memory. Builders will have the option to enable memory for their GPTs. Like your chats, memories are not shared with builders. To interact with a memory-enabled GPT, you will also need to have memory on. For example:&nbsp;</p><ul><li>The <a href="https://chat.openai.com/g/g-z77yDe7Vu-books" rel="noopener noreferrer" target="_blank">Books GPT</a> helps you find your next read. With memory enabled, it remembers your preferences, such as favorite genres or top books, and tailors recommendations accordingly, without needing repeated inputs.</li></ul><p>Each GPT has its own memory, so you might need to repeat details you‚Äôve previously shared with ChatGPT. For example:</p><ul><li>If you're using the <a href="https://chat.openai.com/g/g-SnF78wo4p-artful-greeting-ai-cards" rel="noopener noreferrer" target="_blank">Artful Greeting Card GPT</a> to create a birthday card for your daughter, it won‚Äôt know her age or that she loves jellyfish. You‚Äôll need to tell it the relevant details.</li></ul><p>Memory for GPTs will be available when we roll it out more broadly.<br></p></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[End of Life for Twilio Authy Desktop App (115 pts)]]></title>
            <link>https://help.twilio.com/articles/22771146070299-End-user-guide-End-of-Life-EOL-for-Twilio-Authy-Desktop-app</link>
            <guid>39360439</guid>
            <pubDate>Tue, 13 Feb 2024 17:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.twilio.com/articles/22771146070299-End-user-guide-End-of-Life-EOL-for-Twilio-Authy-Desktop-app">https://help.twilio.com/articles/22771146070299-End-user-guide-End-of-Life-EOL-for-Twilio-Authy-Desktop-app</a>, See on <a href="https://news.ycombinator.com/item?id=39360439">Hacker News</a></p>
<div id="readability-page-1" class="page"><title>Twilio Help Center</title></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stable Cascade (264 pts)]]></title>
            <link>https://github.com/Stability-AI/StableCascade</link>
            <guid>39360106</guid>
            <pubDate>Tue, 13 Feb 2024 17:23:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Stability-AI/StableCascade">https://github.com/Stability-AI/StableCascade</a>, See on <a href="https://news.ycombinator.com/item?id=39360106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:Stability-AI/StableCascade" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="UhYZomhH-S_LPKjBzc4B2ZJnlXEqvz5P5jw0150RetzU7A7tPsiSbOWclrxCtGxIlhOhrGfBDpP5DCvaSFDr4g" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="Stability-AI/StableCascade" data-current-org="Stability-AI" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=v5szzBiOSfJ4aal7CjhqYIQyDXVQyveM6W89y6o09DKb8224xdY8rqnXQ%2BL0qBfXdC%2BvZ49TpbdNlnG%2F%2Fk9Kh7cZujULPKfqCzkCmf26Y7mHt4PwUADhzVkkvEnkSnsdUkcajM5cJkjhIY9jcl9n4GdJ4hJp65EgMdxe9xG9DtlUz4qlZ3AE0UBiNXHr2Qdrh8MUAsSmOeXAdfPwGhyeEekTzn9YprNHGpvGTDCYzOkUfUWdduq%2FZzvIEi%2F519ZYGrUDXpet1%2BzUfTpSsAeLK7ZcrmkJZLV%2B5HcsqWstjRo3r2Y6%2FHHyRBQ3bhtsy8s8Vwh2C2E2%2FeLX%2Bch41UFqQj1QlhX3amLg86pCZajhgHuCbEnIpTPrSTUrk43RyF2gfSRgu6kDvXHGl7m6%2FCK4Hr9Ks%2BqCvwHNhJfLtCeeFLHB%2F7SwKXnXFV0OdBt3hU4TFuu1Rq6P7RLDlaf5vqqnV2wo%2BFXsxH%2FlNRkCSCatQeznN9whXJ1fzFgW0uHIUmVH26dpANWZTWKQBdcheXzm1FARtMjdqPBZqiI%3D--npqmYe%2FRfuiO5x8k--OHfdh6gMDZ3CPsnq%2F%2BvXGg%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=Stability-AI%2FStableCascade" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/Stability-AI/StableCascade&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2d35996b95193b2842baf9db6a527c87be8e560d545167d1e8c7d9b571c63dc7" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla worker killed in fiery crash may be first 'Full Self-Driving' fatality (130 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/interactive/2024/tesla-full-self-driving-fatal-crash/</link>
            <guid>39358509</guid>
            <pubDate>Tue, 13 Feb 2024 15:32:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/interactive/2024/tesla-full-self-driving-fatal-crash/">https://www.washingtonpost.com/technology/interactive/2024/tesla-full-self-driving-fatal-crash/</a>, See on <a href="https://news.ycombinator.com/item?id=39358509">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/interactive/2024/tesla-full-self-driving-fatal-crash/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia's Chat with RTX is an AI chatbot that runs locally on your PC (102 pts)]]></title>
            <link>https://www.theverge.com/2024/2/13/24071645/nvidia-ai-chatbot-chat-with-rtx-tech-demo-hands-on</link>
            <guid>39357900</guid>
            <pubDate>Tue, 13 Feb 2024 14:27:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/2/13/24071645/nvidia-ai-chatbot-chat-with-rtx-tech-demo-hands-on">https://www.theverge.com/2024/2/13/24071645/nvidia-ai-chatbot-chat-with-rtx-tech-demo-hands-on</a>, See on <a href="https://news.ycombinator.com/item?id=39357900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Nvidia is releasing an early version of <a href="https://go.redirectingat.com/?xs=1&amp;id=1025X1701640&amp;url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fai-on-rtx%2Fchat-with-rtx-generative-ai%2F">Chat with RTX</a> today, a demo app that lets you run a personal AI chatbot on your PC. You can feed it YouTube videos and your own documents to create summaries and get relevant answers based on your own data. It all runs locally on a PC, and all you need is an RTX 30- or 40-series GPU with at least 8GB of VRAM.</p><p>I‚Äôve been briefly testing out Chat with RTX over the past day, and although the app is a little rough around the edges, I can already see this being a valuable part of data research for journalists or anyone who needs to analyze a collection of documents.</p><p>Chat with RTX can handle YouTube videos, so you simply input a URL, and it lets you search transcripts for specific mentions or summarize an entire video. I found this ideal for searching through video podcasts, particularly for finding specific mentions in podcasts over the past week amid rumors of Microsoft‚Äôs new <a href="https://www.theverge.com/2024/2/12/24067370/microsoft-xbox-playstation-switch-games-future-hardware">Xbox strategy shift</a>.</p><p>It wasn‚Äôt perfect for searching YouTube videos, though. I tried to search through the transcript of a <em>Verge</em> YouTube video, and Chat with RTX downloaded the transcript for a completely different video. It wasn‚Äôt even one that I had queried before, so there are clearly bugs in this early demo.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Chat with RTX is great at searching your local documents." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/376x181/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/384x184/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/415x199/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/480x230/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/540x259/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/640x307/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/750x360/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/828x398/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1080x518/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1200x576/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1440x691/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1920x922/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2048x983/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2400x1152/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2400x1152/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283482/BQXE3at.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Chat with RTX is great at searching your local documents.</em></figcaption> <p><cite>Screenshot by Tom Warren / The Verge</cite></p></div></div><p>When it worked properly I was able to find references in videos within seconds. I also created a dataset of <em>FTC v. Microsoft</em> documents for Chat with RTX to analyze. When I was covering the court case last year, it was often overwhelming to search through documents at speed, but Chat with RTX helped me query them nearly instantly on my PC.</p><p>For example, the chatbot did a good job summarizing Microsoft‚Äôs entire Xbox Game Pass strategy from internal documents revealed at the trial:</p><div><blockquote><p>Based on the provided context information, Xbox Game Pass is a content subscription service in gaming that provides access to a library of games for a single monthly fee. It is envisioned as a platform that empowers players to play their games anywhere and allows publishers to reach players everywhere. The service is supported by Project xCloud and Xbox Series X, and it aims to create a fertile ground for publishers to monetize their games. The primary strategic objective for the Gaming CSA is to scale Xbox Game Pass, and it is believed that there is a significant subscriber opportunity globally, with a potential of 750 million subscribers. The service faces three primary content dynamics, including the need for differentiated content, expanding beyond console, and limited content supply.</p></blockquote></div><p>I‚Äôve also found this useful to scan through PDFs and fact-check data. Microsoft‚Äôs own Copilot system doesn‚Äôt handle PDFs well within Word, but Nvidia‚Äôs Chat with RTX had no problem pulling out all the key information. The responses are near instant as well, with none of the lag you usually see when using cloud-based ChatGPT or Copilot chatbots.</p><p>The big drawback to Chat with RTX is that it <em>really </em>feels like an early developer demo. Chat with RTX essentially installs a web server and Python instance on your PC, which then leverages Mistral or Llama 2 models to query the data you feed it. It then utilizes Nvidia‚Äôs Tensor cores on an RTX GPU to speed up your queries.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Chat with RTX isn‚Äôt always accurate, though." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/376x181/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/384x184/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/415x199/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/480x230/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/540x259/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/640x307/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/750x360/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/828x398/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1080x518/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1200x576/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1440x691/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/1920x922/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2048x983/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2400x1152/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2560x1229/2400x1152/filters:focal(1280x615:1281x616):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283483/5UYNJFi.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Chat with RTX isn‚Äôt always accurate, though.</em></figcaption> <p><cite>Screenshot by Tom Warren / The Verge</cite></p></div></div><p>It took around 30 minutes for Chat with RTX to install on my PC, which is powered by an Intel Core i9-14900K processor with an RTX 4090 GPU. The app is nearly 40GB in size, and the Python instance takes up around 3GB of RAM out of the 64GB available on my system. Once it‚Äôs running, you access Chat with RTX from a browser, while a command prompt runs in the background spewing out what‚Äôs being processed and any error codes.</p><p>Nvidia isn‚Äôt offering this as a polished app that all RTX owners should download and install immediately. There are a number of known issues and limitations, including that source attribution isn‚Äôt always accurate. I also initially attempted to get Chat with RTX to index 25,000 documents, but this seemed to crash the app, and I had to clear the preferences to get going again.</p><p>Chat with RTX also doesn‚Äôt remember context, so follow-up questions can‚Äôt be based on the context of a previous question. It also creates JSON files inside the folders you ask it to index, so I wouldn‚Äôt recommend using this on your entire Documents folder in Windows. </p><p>I love a good tech demo, though, and Nvidia has certainly delivered that here. It shows the promise of what an AI chatbot can do locally on your PC in the future, especially if you don‚Äôt want to have to subscribe to something like <a href="https://www.theverge.com/2024/1/15/24038711/microsoft-copilot-pro-office-ai-apps">Copilot Pro</a> or <a href="https://www.theverge.com/2023/10/29/23937497/chatgpt-plus-new-beta-all-tools-update-pdf-data-analysis">ChatGPT Plus</a> just to analyze your personal files.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Original WWW proposal is a Word for Macintosh 4 file from 1990, can we open it? (223 pts)]]></title>
            <link>https://blog.jgc.org/2024/02/the-original-www-proposal-is-word-for.html</link>
            <guid>39357709</guid>
            <pubDate>Tue, 13 Feb 2024 14:06:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jgc.org/2024/02/the-original-www-proposal-is-word-for.html">https://blog.jgc.org/2024/02/the-original-www-proposal-is-word-for.html</a>, See on <a href="https://news.ycombinator.com/item?id=39357709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1960659042426703991" itemprop="description articleBody">
<p>The W3C has a page with the <a href="https://www.w3.org/History/1989/proposal.html">original WWW proposal</a> from Tim Berners-Lee. One of the downloads says&nbsp;</p><ul><li><a href="https://www.w3.org/History/1989/proposal">The original document file (I think - I can't test it)</a></li></ul><p><span>The "I can't test it" made me sad. There are two other files (an RTF version and an HTML version generated in 1998 from the original file). But can we open the original document?</span></p><p><span>The original document is 68,608 bytes and <span>file</span> on my Mac says it's a&nbsp;<span>Microsoft Word for Macintosh 4.0</span><span> file</span>. That matches with TBL's note on the W3C page saying: "A hand conversion to HTML of the original MacWord (or Word for Mac?) document written in March 1989 and later redistributed unchanged apart from the date added in May 1990."&nbsp;</span></p><p><span>Microsoft Office for Mac came out in 1989 with System 6.0. That was Microsoft Word 4.0 so we're looking for compatibility with Microsoft Word for Macintosh 4.0. Let's see what modern software can open this. What I really want to be able to do is open it and convert it to, say, PDF with high fidelity.</span></p><h2><span>Microsoft Word</span></h2><p><span>Let's begin with Microsoft Word itself. I uploaded the file to Microsoft OneDrive with the extension .doc and clicked on it to open it in Microsoft Word.</span></p><div><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivCGzwNqeNyN4mZPNF593LeO14xECSZPabgJK43_trMY-NNlDrGrUYeGPAQ11lVk4vmh8o9U05sPW7xIYx1vDLIGDQWHFo9x6gEwqkvA3JzPkmLhyVS8HGHSCRXqH-yQXFo3Q9qxsje_rF5Vuzzm1YfxlIU2mlCXEvjDJ1ebeSl8G6gDD9zJ7iRA/s1358/proposal-1.png"><img data-original-height="524" data-original-width="1358" height="246" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivCGzwNqeNyN4mZPNF593LeO14xECSZPabgJK43_trMY-NNlDrGrUYeGPAQ11lVk4vmh8o9U05sPW7xIYx1vDLIGDQWHFo9x6gEwqkvA3JzPkmLhyVS8HGHSCRXqH-yQXFo3Q9qxsje_rF5Vuzzm1YfxlIU2mlCXEvjDJ1ebeSl8G6gDD9zJ7iRA/w640-h246/proposal-1.png" width="640"></a></p><h2>Apple Pages</h2><p>I switched to the Mac and hoped that Apple Pages might understand an old Microsoft Word for Macintosh file. No such luck.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEisHsxI8gafx3rr9vSA7jui-HrzV_8CQYERBqT-6gQJwr1QbIiaIzYedxMRkiULhHaDkE8f0Lc7F-9erQ620RSRR_9e0qgX2tqoN1cxfScEwu7zzk2XO4LFiHAUbdOnvnRQNUGp8jt_p0r8cfiTw84qyH1JKCUFGK7-WQD2A2SqIYNA8BVCM_iSZw/s744/proposal-2.png"><img data-original-height="664" data-original-width="744" height="358" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEisHsxI8gafx3rr9vSA7jui-HrzV_8CQYERBqT-6gQJwr1QbIiaIzYedxMRkiULhHaDkE8f0Lc7F-9erQ620RSRR_9e0qgX2tqoN1cxfScEwu7zzk2XO4LFiHAUbdOnvnRQNUGp8jt_p0r8cfiTw84qyH1JKCUFGK7-WQD2A2SqIYNA8BVCM_iSZw/w400-h358/proposal-2.png" width="400"></a></p><h2>Apache OpenOffice</h2><div><p>Next let's hope open source software will come to the rescue. I downloaded the latest Apache OpenOffice and it did open the file but the formatting is gone and the diagrams are missing.</p></div></div><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg8eASEUl_mTNLs2hF2Fi-omu_5WvEjHONP_sAi8Wwn5R5GO0gciGwx7E-TySj-NUiz-xFxQ0XjDgRMcvKtJFPP6MLWOcwwBwBrpG50e2f8m3ld6eD23Afq-kCRT4Eb9_K4W_j1OaqeWP9aOYnIY7uaJ0E3iWyH2xXnSDL2UJF5TSI_zhKa_fI6CQ/s2652/proposal-3.png"><img data-original-height="1920" data-original-width="2652" height="464" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg8eASEUl_mTNLs2hF2Fi-omu_5WvEjHONP_sAi8Wwn5R5GO0gciGwx7E-TySj-NUiz-xFxQ0XjDgRMcvKtJFPP6MLWOcwwBwBrpG50e2f8m3ld6eD23Afq-kCRT4Eb9_K4W_j1OaqeWP9aOYnIY7uaJ0E3iWyH2xXnSDL2UJF5TSI_zhKa_fI6CQ/w640-h464/proposal-3.png" width="640"></a></td></tr><tr><td><br></td></tr></tbody></table><h2>LibreOffice</h2><p>OK, maybe I need different open source software, so I switched to the latest <a href="https://www.libreoffice.org/">LibreOffice</a> and it opened it. And the diagrams are crisp! Although there's something weird about the margins and there are other formatting problems.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMG83H6sPE9zk7abtg9woYAM6ryYid5DOmz_yegn0x7U_B5rkalViax7vrgAI2b6Zy9dD39gsMjBwmMhMMlefWQu0DfdT9ELMSlFcNFKh2DNRr7KsKMGwJgGmXUvhXiEd_OrE93V99yBr6c4WMS7Ak_7W0DSH5ezoYX3ob1gut5Nhd0XDyp63szA/s2644/proposal-4.png"><img data-original-height="2158" data-original-width="2644" height="522" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMG83H6sPE9zk7abtg9woYAM6ryYid5DOmz_yegn0x7U_B5rkalViax7vrgAI2b6Zy9dD39gsMjBwmMhMMlefWQu0DfdT9ELMSlFcNFKh2DNRr7KsKMGwJgGmXUvhXiEd_OrE93V99yBr6c4WMS7Ak_7W0DSH5ezoYX3ob1gut5Nhd0XDyp63szA/w640-h522/proposal-4.png" width="640"></a></p><h2>CERN PDF</h2><p>CERN makes available <a href="https://cds.cern.ch/record/369245/files/dd-89-001.pdf">a PDF version</a> of the proposal which was apparently created in 1998 using&nbsp;Acrobat Distiller Daemon 2.1 for SunOS/Solaris (SPARC). It has 20 pages. The LibreOffice imported version has 24 pages.&nbsp;</p><p>To get an overview of what's different I created a PDF from the LibreOffice version and then looked at it and the CERN PDF in the contact sheet version in Apple Preview.</p><p>Here's the CERN PDF:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmLx2yw7hBNA1hZ0YGxlcvJee0qSv5IoSm6ytWun-nEFw7z-5yWT0Ckc7pzcW6SGZl72nM-jYZUbV5ZUhUlfrGjYWcmz6HVD_p6XI1bEegfQucRbHhjfaPwnlz4mH_V-ANzeCzsMNDX8Fr5vsBpTi8oY1M-zCB26mlpsvCwdUzWXGi9mSNUfBrg/s2444/proposal-5.png"><img data-original-height="700" data-original-width="2444" height="184" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmLx2yw7hBNA1hZ0YGxlcvJee0qSv5IoSm6ytWun-nEFw7z-5yWT0Ckc7pzcW6SGZl72nM-jYZUbV5ZUhUlfrGjYWcmz6HVD_p6XI1bEegfQucRbHhjfaPwnlz4mH_V-ANzeCzsMNDX8Fr5vsBpTi8oY1M-zCB26mlpsvCwdUzWXGi9mSNUfBrg/w640-h184/proposal-5.png" width="640"></a></p><p>Here's the LibreOffice-generated PDF:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKTElIxIWy-jOHKCzOuLo8pd1rk_9ChaGL93vgNMElSsu9eRgIh_LHJ3yDVXzOvHFfF5iDEwRoPMH_Dyeuk1HNcB5K6wZOKu229VWK7kNpvpgGMXF7oekB5C-O4sRxK9fRPFTxSqEj8u3fUH7t9p8Un9on_hKu8sh0vliaQ98GRtp-TYRrrQ2PYQ/s2444/proposal-6.png"><img data-original-height="1052" data-original-width="2444" height="276" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKTElIxIWy-jOHKCzOuLo8pd1rk_9ChaGL93vgNMElSsu9eRgIh_LHJ3yDVXzOvHFfF5iDEwRoPMH_Dyeuk1HNcB5K6wZOKu229VWK7kNpvpgGMXF7oekB5C-O4sRxK9fRPFTxSqEj8u3fUH7t9p8Un9on_hKu8sh0vliaQ98GRtp-TYRrrQ2PYQ/w640-h276/proposal-6.png" width="640"></a></p><p>Things that are different:</p><p>1. The right-hand margin is missing in the LibreOffice version.</p><p>2. The LibreOffice version is using 14 pt vs. 12 pt for most of the text.</p><p>3. The LibreOffice version has turned headers with TBL's initials in them into footers.</p><p>4. The page breaks look in the right places (see how the images are correctly placed towards the end); thus it's probably the font size that's the biggest problem.</p><p>5. There CERN PDF has a space under the heading and the LibreOffice version does not.</p><h2>Emulation</h2><p>To make sure that I knew what the actual original document looked like I decided to use <a href="https://infinitemac.org/1990/System%206.0.5">Infinite Mac</a> to boot a 1990-era Macintosh and run actual Word for Macintosh 4.0 on the original document.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiijOiXeCEF_J1oTZBDun1YT3lye7507nTXRpEAUjYW6CQOVFhI6Qb1jGJhDgAJeOEA1BwmDFLqPYnq25JSXaK5zw2oZOFBTvZiVqmNfhf8Vfp4UYQ_HwJzIKuC_a3kAfvGNhR3U6rSlB77KUFilVUX2lVL7SKnnaQU4ZHkwilImtVFGqKak4kG1w/s1411/proposal-9.png"><img data-original-height="1081" data-original-width="1411" height="490" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiijOiXeCEF_J1oTZBDun1YT3lye7507nTXRpEAUjYW6CQOVFhI6Qb1jGJhDgAJeOEA1BwmDFLqPYnq25JSXaK5zw2oZOFBTvZiVqmNfhf8Vfp4UYQ_HwJzIKuC_a3kAfvGNhR3U6rSlB77KUFilVUX2lVL7SKnnaQU4ZHkwilImtVFGqKak4kG1w/w640-h490/proposal-9.png" width="640"></a></p><p>That way I can see actual fonts, font sizes and layout to confirm how the document should have looked. And that's where it became obvious that the original document on the original Mac and the CERN PDF are quite different. The CERN PDF has 20 pages. On the Mac running Word for Macintosh 4.0 with A4 paper it has 22 pages. So I decided to aim to get us close to the original document on the Mac.</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjM3_thqxV_ZB-VqLJRytn7oA8LbAMlQ2a3kRZrubYhWt4M8ns2R-3nHFXFG-367BDUJQkHtLO6oqFNrZWGXhwlQfarVp_ih1SDBgBWsWGBKqKmZUYD51WLmLIGCQ1no0EcAPeTidkHBb52Y-EY7AXYnBX9nll33G7FuZofLN9XgpD0bWak-T1ONQ/s1389/proposal-10.png"><img data-original-height="1062" data-original-width="1389" height="490" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjM3_thqxV_ZB-VqLJRytn7oA8LbAMlQ2a3kRZrubYhWt4M8ns2R-3nHFXFG-367BDUJQkHtLO6oqFNrZWGXhwlQfarVp_ih1SDBgBWsWGBKqKmZUYD51WLmLIGCQ1no0EcAPeTidkHBb52Y-EY7AXYnBX9nll33G7FuZofLN9XgpD0bWak-T1ONQ/w640-h490/proposal-10.png" width="640"></a></td></tr><tr><td></td></tr></tbody></table><p><span>So... set to A4 paper and set right margin to same size as left margin. Change the first page format to be different since it doesn't have the same gutters, footers or headers.&nbsp;</span><span>Manually change the body text from 14 pt (and other sizes) to 12 pt. Manually deal with text that breaks across pages incorrectly and other alignment problems. Fix the footer that should be a header.</span></p><p><span>In the end I got pretty close to what's visible on the Mac.&nbsp;</span></p><div><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOA-gPDF3aSCcLgZumx8lW7yXDF34EKE6VIUUcyp7etjaA66vInZOvD7Dxa3DPBGQmKbKlTQQxThHv48XrTdcTWaaLYEacOYAvk2J0qLfEPLOeUWiii286namyfei9NHd2F3pokvQoOEFrRhxWnHi254ONzTxfgFhKMBr6mFcXOcSu7U2DgkIMWQ/s2408/proposal-11.png"><img data-original-height="1040" data-original-width="2408" height="276" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOA-gPDF3aSCcLgZumx8lW7yXDF34EKE6VIUUcyp7etjaA66vInZOvD7Dxa3DPBGQmKbKlTQQxThHv48XrTdcTWaaLYEacOYAvk2J0qLfEPLOeUWiii286namyfei9NHd2F3pokvQoOEFrRhxWnHi254ONzTxfgFhKMBr6mFcXOcSu7U2DgkIMWQ/w640-h276/proposal-11.png" width="640"></a></p><h2>Conclusion</h2></div><p>Converting this document from its original format was a bit of a victory for open source software. And a lesson in how hard document preservation is. To help preserve it a bit, and in an open format, I've uploaded my .odt version to GitHub <a href="https://github.com/jgrahamc/www-proposal">here</a>. It's interesting, and a little disheartening to see that this 34 year old document is difficult to open, and even when opened the resulting output isn't exactly the same as the original.</p><p>PS If you're wondering why I ever started this project. I just wanted a high quality version of the diagrams in the original proposal for a presentation. Took me a lot longer than I thought it would.</p><p>PPS A <a href="https://news.ycombinator.com/item?id=39358074">comment</a> on Hacker News pointed out that I could probably either create a PostScript file or a PDF via an emulated Mac. I was able to boot another Mac (System 7) that had Word from 1992 and Print2PDF (a driver that creates a printer that makes a PDF file) and print directly from Word for Macintosh 5.1a.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgx49b2BxnfgvZQp6amCJ3JWT_B0Fcgyv-hz6O4rG0vxhImvBWk_3WvYJhFcv6rwE45ySKg1GBJchujq4AJE2s8emtZm8B1YuwmXtEeCAE6m4wRhjQxnCrHRZ1XRTJK4CwjZJy9xsYQIH2ZFHEpRUzrMynlP2QddrGZl6ol5YJIRWA-xjRHY97jow/s1969/proposal-12.png" imageanchor="1"><img data-original-height="1573" data-original-width="1969" height="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgx49b2BxnfgvZQp6amCJ3JWT_B0Fcgyv-hz6O4rG0vxhImvBWk_3WvYJhFcv6rwE45ySKg1GBJchujq4AJE2s8emtZm8B1YuwmXtEeCAE6m4wRhjQxnCrHRZ1XRTJK4CwjZJy9xsYQIH2ZFHEpRUzrMynlP2QddrGZl6ol5YJIRWA-xjRHY97jow/w640-h512/proposal-12.png" width="640"></a></p><p>I've added the generated PDF file to the GitHub. This version has 20 pages and the fonts are different but it does meet my original requirement of a PDF.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Owners report rust forming on Tesla Cybertruck (119 pts)]]></title>
            <link>https://www.theregister.com/2024/02/13/tesla_cybertruck_rust/</link>
            <guid>39357595</guid>
            <pubDate>Tue, 13 Feb 2024 13:53:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/02/13/tesla_cybertruck_rust/">https://www.theregister.com/2024/02/13/tesla_cybertruck_rust/</a>, See on <a href="https://news.ycombinator.com/item?id=39357595">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>It's only been a few months since Tesla's long-awaited Cybertruck made its way to those at the front of the queue, but the arrival has been tarnished for some.</p>
<p>CEO Elon Musk first unveiled the electric pickup model <a target="_blank" href="https://www.theregister.com/2019/11/22/smashing_tesla_cybertruck/">back in 2019</a>, claiming that its "ultra-hard stainless steel" body and "transparent metal" glass were "literally bulletproof."</p>
<p>Though beset with <a target="_blank" href="https://www.theregister.com/2023/07/17/first_tesla_cybertrunk/">production issues</a> and missing its speculative 2021-22 release, its unique polygonal design ‚Äì as with anything Tesla and Musk-related ‚Äì attracted legions of devotees eager to get their hands on the steering wheel.</p>

    

<p>This unique design isn't without shortfalls, at least according to reports in the <a target="_blank" rel="nofollow" href="https://www.cybertruckownersclub.com/">Cybertruck Owners Club</a> forum. A trending thread titled "<a target="_blank" href="https://www.cybertruckownersclub.com/forum/threads/rust-spots-corrosion-is-the-norm.11988/">Rust Spots/Corrosion is the Norm</a>" from a user going by "Raxar" states:</p>

<p>This, as you might expect, provoked a strong reaction from the faithful. "Liar. Is this fun for you?" one asked, while another incorrectly riposted: "If it 'rusts', it's not stainless steel." This is a common misconception. Stainless steel is resistant to rust, but not completely immune.</p>
<p>Members pondered whether orange stains could be caused by "rail dust" from certain vehicles being delivered via train, yet Raxar <a target="_blank" rel="nofollow" href="https://www.cybertruckownersclub.com/forum/threads/rust-spots-corrosion-is-the-norm.11988/post-240328">posted some images</a> of his Cybertruck's body after driving it for "2 days in rain."</p>

        


        

<p>The tiny specks may not seem like a big deal, but given that the Cybertruck price went from $40,000 in 2019 to $60,000 in 2023, we understand why owners might want their cars to appear pristine at all times.</p>
<p>In a <a target="_blank" rel="nofollow" href="https://www.cybertruckownersclub.com/forum/threads/cybertruck-spots-corrosion.12242/">separate thread</a>, another user, vertigo3pc, reported that "corrosion was forming on the metal" of his brand-new Cybertruck after 11 days in the "LA rain," leading some to worry that the steel body was becoming contaminated during production.</p>
<ul>

<li><a href="https://www.theregister.com/2024/01/24/tesla_cybertruck_offroading_video/">Tesla Cybertruck gets cyberstuck during off-roading expedition</a></li>

<li><a href="https://www.theregister.com/2023/12/19/musk_says_boat_mod_package/">Musk floats idea of boat mod for Cybertruck</a></li>

<li><a href="https://www.theregister.com/2023/11/15/tesla_reverses_course_on_cybertruck/">Tesla Cybertruck no-resale clause vanishes faster than a Model S in Ludicrous Mode</a></li>

<li><a href="https://www.theregister.com/2023/11/13/want_a_cybertruck_then_youre/">Want a Cybertruck? You're stuck with it for a year, says Tesla</a></li>
</ul>
<p>However, corrosion reports may stem from owners believing that "ultra-hard stainless steel" doesn't require much care. Tesla, it appears, would vehemently disagree.</p>
<p>Another thread from January <a target="_blank" rel="nofollow" href="https://www.cybertruckownersclub.com/forum/threads/cybertruck-corrosion-per-owner-manual.11445/">included a screenshot of Cybertruck's maintenance documentation</a>, where it is said that the car does not have a clear coat. Clear coat is the outermost layer of transparent paint that serves as a protective barrier, preventing UV radiation and weather from damaging the colored paint layer. Clear coat also takes abrasions that might otherwise scratch the paint job.</p>

        

<p>The user warns: "The Cybertruck's exterior is susceptible to corrosion, as acknowledged in the manual. Once the oxide barrier is compromised, corrosion initiates. The manual advises prompt removal of corrosive substances, emphasizing not to wait until the Cybertruck is scheduled for a full wash."</p>
<p>The documentation says: "To prevent damage to the exterior, immediately remove corrosive substances (such as grease, oil, bird droppings, tree resin, dead insects, tar spots, road salt, industrial fallout, etc.). Do not wait until Cybertruck is due for a complete wash. If necessary use denatured alcohol to remove tar spots and stubborn grease stains, then immediately wash the area with water and a mild, non-detergent soap to remove the alcohol."</p>
<p>It sounds like a lot of work if even a five-minute dash for milk might result in a midge besmirching the body. Tesla explicitly states: "The stainless steel exterior of Cybertruck is more resistant to dents and dings than most other vehicles. However, Cybertruck does not have a clear coat on the surface of the exterior body panels, meaning any scratches that appear are in the stainless steel panels themselves."</p>

        

<p><em>The Register</em> asked Tesla whether it agreed with the description of Cybertruck corrosion as the "norm," and if not, what the company expected to cause the spots documented. We will update the article if a response is forthcoming. ¬Æ</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Git client for simultaneous branches on top of your existing workflow (123 pts)]]></title>
            <link>https://gitbutler.com</link>
            <guid>39357068</guid>
            <pubDate>Tue, 13 Feb 2024 12:41:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitbutler.com">https://gitbutler.com</a>, See on <a href="https://news.ycombinator.com/item?id=39357068">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="hero"> <p data-svelte-h="svelte-1ijtn23">A Git client for simultaneous branches on top of your existing workflow.</p> </div> <section id="features"> <div><article> <div><h3>Virtual Branches</h3> <p>You don‚Äôt need to switch branches if you can work on several simultaneously. Fix your bug while you work on your feature.</p> <a href="#faq"><span data-svelte-h="svelte-83s2i7">More</span> <svg width="10" height="10" viewBox="0 0 10 10" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 1L9 9M9 9L1 9M9 9L1 1" stroke-width="1.5"></path></svg></a></div></article>  </div>  <div><article> <div><h3>Branch Management</h3> <p>Undo, squash and amend your work by just dragging and dropping. No need to wrestle with rebase -i.</p> <a href="#faq"><span data-svelte-h="svelte-83s2i7">More</span> <svg width="10" height="10" viewBox="0 0 10 10" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 1L9 9M9 9L1 9M9 9L1 1" stroke-width="1.5"></path></svg></a></div></article>  </div>  <div><article> <div><h3>Quick Commits</h3> <p>How many times have you written git commit -m stuff? Generate a commit message with one click.</p> <a href="#faq"><span data-svelte-h="svelte-83s2i7">More</span> <svg width="10" height="10" viewBox="0 0 10 10" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 1L9 9M9 9L1 9M9 9L1 1" stroke-width="1.5"></path></svg></a></div></article>  </div> <a href="https://youtu.be/PWc4meBj4jo?si=WX5sleIMW5LX6LT5" target="_blank"><img src="https://gitbutler.com/images/video-thumb/watch-btn.svg" alt="">  <video loop="" muted="" playsinline="" preload="auto" src="https://gitbutler.com/images/video-thumb/video-thumb-loop.mp4#t=0.1"></video> </a> </section> <section id="developers-preview"><h2 data-svelte-h="svelte-1f2j6ms">What <i>developers<br>say</i> about us</h2>  </section>  <section id="faq"><h2 data-svelte-h="svelte-1cez4db">FAQ</h2> <section><article><div role="button" tabindex="0"><h3>Is GitButler compatible with my existing repositories and workflow? </h3> </div>  </article><article><div role="button" tabindex="0"><h3>Why build another Git client?</h3> </div>  </article><article><div role="button" tabindex="0"><h3>Why should I use GitButler?</h3> </div>  </article><article><div role="button" tabindex="0"><h3>What is GitButler's business model?</h3> </div>  </article><article><div role="button" tabindex="0"><h3>Can I use GitButler in the terminal?</h3> </div>  </article><article><div role="button" tabindex="0"><h3>Is there Windows support?</h3> </div>  </article><article><div role="button" tabindex="0"><h3>What are virtual branches under the hood?</h3> </div>  </article></section> </section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sparkle: A software update framework for macOS (151 pts)]]></title>
            <link>https://github.com/sparkle-project/Sparkle</link>
            <guid>39357014</guid>
            <pubDate>Tue, 13 Feb 2024 12:31:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sparkle-project/Sparkle">https://github.com/sparkle-project/Sparkle</a>, See on <a href="https://news.ycombinator.com/item?id=39357014">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><h2 tabindex="-1" dir="auto">Sparkle 2 <a target="_blank" rel="noopener noreferrer" href="https://github.com/sparkle-project/Sparkle/workflows/Build%20%26%20Tests/badge.svg?branch=2.x"><img src="https://github.com/sparkle-project/Sparkle/workflows/Build%20%26%20Tests/badge.svg?branch=2.x" alt="Build Status"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/62cbacf904c4ac903a7866e3562f2f23779ec011ef673a4ac57a1b90bc3596a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5377696674504d2d636f6d70617469626c652d3442433531442e7376673f7374796c653d666c6174"><img src="https://camo.githubusercontent.com/62cbacf904c4ac903a7866e3562f2f23779ec011ef673a4ac57a1b90bc3596a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5377696674504d2d636f6d70617469626c652d3442433531442e7376673f7374796c653d666c6174" alt="SwiftPM" data-canonical-src="https://img.shields.io/badge/SwiftPM-compatible-4BC51D.svg?style=flat"></a> <a href="https://github.com/Carthage/Carthage"><img src="https://camo.githubusercontent.com/8b87af3bf5ce1944f03f605b6cc694a58661e9e55fa23727ca12f91f2042b026/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f43617274686167652d636f6d70617469626c652d3442433531442e7376673f7374796c653d666c6174" alt="Carthage compatible" data-canonical-src="https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat"></a> <a href="https://cocoapods.org/pods/Sparkle" rel="nofollow"><img src="https://camo.githubusercontent.com/2465ea09b2ca5bd98ddb3eb580ca91322c8dd69f099192b35ce26edccd5fd40e/68747470733a2f2f696d672e736869656c64732e696f2f636f636f61706f64732f762f537061726b6c652e7376673f63616368655365636f6e64733d3836343030" alt="CocoaPods" data-canonical-src="https://img.shields.io/cocoapods/v/Sparkle.svg?cacheSeconds=86400"></a></h2>
<p dir="auto">Secure and reliable software update framework for macOS.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sparkle-project/Sparkle/blob/2.x/Resources/Screenshot.png"><img src="https://github.com/sparkle-project/Sparkle/raw/2.x/Resources/Screenshot.png" width="732" alt="Sparkle shows familiar update window with release notes"></a></p>
<p dir="auto">Sparkle 2 adds support for application sandboxing, custom user interfaces, updating external bundles, and a more modern architecture which includes faster and more reliable installs.</p>
<p dir="auto">Pre-releases when available can be found on the <a href="https://github.com/sparkle-project/Sparkle/releases">Sparkle's Releases</a> or on your favorite package manager. More nightly builds can be downloaded by selecting a recent <a href="https://github.com/sparkle-project/Sparkle/actions?query=event%3Apush+is%3Asuccess+branch%3A2.x">workflow run</a> and downloading the corresponding Sparkle-distribution artifact.</p>
<p dir="auto">The current status for future versions of Sparkle is tracked by <a href="https://github.com/sparkle-project/Sparkle/milestones">its roadmap</a>.</p>
<p dir="auto">Please visit <a href="http://sparkle-project.org/" rel="nofollow">Sparkle's website</a> for up to date documentation on using and migrating over to Sparkle 2. Refer to <a href="https://github.com/sparkle-project/Sparkle/blob/2.x/CHANGELOG">Changelog</a> for a more detailed list of changes. More internal design documents to the project can be found in the repository under <a href="https://github.com/sparkle-project/Sparkle/blob/2.x/Documentation">Documentation</a>.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Seamless. There's no mention of Sparkle; your icons and app name are used.</li>
<li>Secure. Updates are verified using EdDSA signatures and Apple Code Signing. Supports Sandboxed applications in Sparkle 2.</li>
<li>Fast. Supports delta updates which only patch files that have changed and atomic-safe installs.</li>
<li>Easy to install. Sparkle requires no code in your app, and only needs static files on a web server.</li>
<li>Customizable. Sparkle 2 supports plugging in a custom UI for updates.</li>
<li>Flexible. Supports applications, package installers, preference panes, and other plug-ins. Sparkle 2 supports updating external bundles.</li>
<li>Handles permissions, quarantine, and automatically asks for authentication if needed.</li>
<li>Uses RSS-based appcasts for release information. Appcasts are a de-facto standard supported by 3rd party update-tracking programs and websites.</li>
<li>Stays hidden until second launch for better first impressions.</li>
<li>Truly self-updating‚Ää‚Äî‚Ääthe user can choose to automatically download and install all updates in the background.</li>
<li>Ability to use channels for beta updates (in Sparkle 2), add phased rollouts to users, and mark updates as critical or major.</li>
<li>Progress and status notifications for the host app.</li>
</ul>
<h2 tabindex="-1" dir="auto">Requirements</h2>
<ul dir="auto">
<li>Runtime: macOS 10.13 or later.</li>
<li>Build: Latest major Xcode (stable or beta, whichever is latest) and one major version less.</li>
<li>HTTPS server for serving updates (see <a href="http://sparkle-project.org/documentation/app-transport-security/" rel="nofollow">App Transport Security</a>)</li>
</ul>
<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">See <a href="https://sparkle-project.org/documentation/" rel="nofollow">getting started guide</a>. No code is necessary, but a bit of configuration is required.</p>
<h3 tabindex="-1" dir="auto">Troubleshooting</h3>
<ul dir="auto">
<li>
<p dir="auto">Please check <strong>Console.app</strong> for logs under your application. Sparkle prints detailed information there about all problems it encounters. It often also suggests solutions to the problems, so please read Sparkle's log messages carefully.</p>
</li>
<li>
<p dir="auto">Use the <code>generate_appcast</code> tool which creates appcast files, correct signatures, and delta updates automatically.</p>
</li>
<li>
<p dir="auto">Make sure the URL specified in <a href="https://sparkle-project.org/documentation/customization/" rel="nofollow"><code>SUFeedURL</code></a> is valid (typos/404s are a common error!), and that it uses modern TLS (<a href="https://www.ssllabs.com/ssltest/" rel="nofollow">test it</a>).</p>
</li>
</ul>
<h3 tabindex="-1" dir="auto">API symbols</h3>
<p dir="auto">Sparkle is built with <code>-fvisibility=hidden -fvisibility-inlines-hidden</code> which means no symbols are exported by default.
If you are adding a symbol to the public API you must decorate the declaration with the <code>SU_EXPORT</code> macro (grep the source code for examples).</p>
<h3 tabindex="-1" dir="auto">Building the distribution package</h3>
<p dir="auto">You do not usually need to build a Sparkle distribution unless you're making changes to Sparkle itself.</p>
<p dir="auto">To build a Sparkle distribution, <code>cd</code> to the root of the Sparkle source tree and run <code>make release</code>. Sparkle-<em>VERSION</em>.tar.xz (or .bz2) will be created and revealed in Finder after the build has completed.</p>
<p dir="auto">Alternatively, build the Distribution scheme in the Xcode UI.</p>
<h3 tabindex="-1" dir="auto">Code of Conduct</h3>
<p dir="auto">We pledge to have an open and welcoming environment. See our <a href="https://github.com/sparkle-project/Sparkle/blob/2.x/CODE_OF_CONDUCT.md">Code of Conduct</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Something Bugging You? (663 pts)]]></title>
            <link>https://antithesis.com/blog/is_something_bugging_you/</link>
            <guid>39356920</guid>
            <pubDate>Tue, 13 Feb 2024 12:13:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antithesis.com/blog/is_something_bugging_you/">https://antithesis.com/blog/is_something_bugging_you/</a>, See on <a href="https://news.ycombinator.com/item?id=39356920">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <header>
            
            <h2>Is something bugging you?</h2>
            
            <p>February 13, 2024</p>
        </header>
        <p>It‚Äôs pretty weird for a startup to remain in stealth for over five years. People ask me why we did that, and my answer is always the same: ‚ÄúWe wanted to build something awesome before releasing it out into the wild, and we were lucky enough to be able to do that under the radar while also attracting great hires, finding early customers, and working with investors.‚Äù All the same, it‚Äôs an unnatural thing for a startup to do. A lot of muscles end up atrophying, including those you use to talk to the world.   Fortunately, we‚Äôre going to get a lot of practice at it now, because in those five years we‚Äôve built a lot of stuff ‚Äì way more than I can tell you about right now. But I can tell you the first part of it.</p>
<h4>Why We Built This</h4>
<p>Some of you have heard of our last company, FoundationDB. At first glance, Antithesis couldn‚Äôt be more different from FoundationDB, but it‚Äôs also a continuation of that story in a funny sort of way. When we sat down in 2010 to build a scalable, fault-tolerant distributed database with ACID transactions, most people didn‚Äôt even think it was possible.<sup><a href="#fn1" id="ref1">[1]</a></sup> We were agnostic as to whether it was possible or impossible, but we were certain that even under the best circumstances, it would be very hard. And the part that seemed hardest was how on earth you could test or validate such a thing, and how you could gain confidence in its correctness.</p>
<p>The fundamental problem of software testing‚Äîyou might say the fundamental problem of software <em>development</em>‚Äîis that software has to handle many situations that the developer has never thought of or will never anticipate. This limits the value of testing, because if you had the foresight to write a test for a particular case, then you probably had the foresight to make the code handle that case too. This makes conventional testing great for catching regressions, but really terrible at catching all the ‚Äúunknown unknowns‚Äù that life, the universe, and your endlessly creative users will throw at you.</p>
<p>
    <img alt="solving the wrong problem" src="https://antithesis.com/blog/is_something_bugging_you/images/wrong%20problem.jpeg">
</p>
<p>This isn‚Äôt unique to distributed databases: every kind of software has this problem, but a distributed storage system really turns it up to 11. Now you‚Äôve got concurrency, both within each machine and between machines. You‚Äôve got networks, which always seem to be delaying or reordering packets at the worst possible moments, and disks, which are just waiting for you to look away so they can start vomiting all over your data. And then you‚Äôve got all the stuff that can <em>really</em> go wrong‚Äîmachine failures and power outages and datacenters catching fire and, oh yeah, well-meaning human beings panicking and accidentally making things worse. What‚Äôs especially hard about these failure modes is that they‚Äôre <em>non-deterministic</em>‚Äîyou can easily have a catastrophic bug that‚Äôs exquisitely dependent on the precise ordering of events across multiple machines in a cluster. Even if your tests find it once, they may never find it again (but don‚Äôt worry, your customers will find it for you). And here we were, trying to make a software system that would behave <em>perfectly</em> and maintain its ACID guarantees in the face of all of this. How were we going to do that?</p>
<p>So we did something crazy, which turned out to be the best decision we made in the whole history of the company. Before we even started writing the database, we first wrote a fully-deterministic event-based network simulation that our database could plug into. This system let us simulate an entire cluster of interacting database processes, all within a single-threaded, single-process application, and all driven by the same random number generator. We could run this virtual cluster, inject network faults, kill machines, simulate whatever crazy behavior we wanted, and see how it reacted. Best of all, if one particular simulation run found a bug in our application logic, we could run it over and over again with the same random seed, and the exact same series of events would happen in the exact same order. That meant that even for the weirdest and rarest bugs, we got infinity ‚Äútries‚Äù at figuring it out, and could add logging, or do whatever else we needed to do to track it down. I gave a talk about this at Strangeloop in 2014, which you can watch <a href="https://www.youtube.com/watch?v=4fFDFbi3toc">here</a>.</p>
<p>Anyway, we did this for a while and found all of the bugs in the database. I know, I know, that‚Äôs an insane thing to say. It‚Äôs kind of true though. In the entire history of the company, I think we only ever had one or two bugs reported by a customer. <em>Ever</em>. Kyle Kingsbury aka ‚Äúaphyr‚Äù didn‚Äôt even bother testing it with Jepsen, because he didn‚Äôt think he‚Äôd find anything.</p>
<p>
    <img alt="aphyr-twitter-fdb" src="https://antithesis.com/blog/is_something_bugging_you/images/aphyr_twitter_fdb.png">
</p>
<p>It was a good database. But actually, this is not the cool part of the story.</p>
<p>Here is the cool part of the story. The cool part is what happened after we found all the bugs in the database. You see, once you‚Äôve found all the bugs in something, and you have very powerful tests which can find any new ones, programming feels completely different. I‚Äôve only gotten to do this a few times in my career, and it‚Äôs hard to convey the feeling in words, but I have to try. It‚Äôs like being half of a cyborg, or having a jetpack, or something. You write code, and then you ask the computer if the code is correct, and if not then you try again. Can you imagine having a genie, or an oracle, which just <em>tells you</em> whether you did something wrong? The closest comparison I have is the way some people talk about programming in Haskell or in Rust, where after half an hour of siege warfare against the compiler, it agrees to build something, and you can be confident that it won‚Äôt have certain kinds of bugs. But there‚Äôs a limit to what a compiler can tell you. I love me a powerful type system, but it‚Äôs not the same as actually running your software in thousands and thousands of crazy situations you‚Äôd never dreamed of.</p>
<p>At FoundationDB, once we hit the point of having ~zero bugs and confidence that any new ones would be found immediately, we entered into this blessed condition and we flew. Programming in this state is like living life surrounded by a force field that protects you from all harm. Suddenly, you feel like you can take risks. We did crazy stuff. We deleted all of our dependencies (including Zookeeper) because they had bugs, and wrote our own Paxos implementation in very little time and it <a href="https://www.foundationdb.org/files/fdb-paper.pdf">had no bugs</a>. We rewrote the entire transaction processing subsystem of our database to make it <a href="https://news.ycombinator.com/item?id=8729420">faster and more scalable</a> ‚Äì a bonkers thing to do btw ‚Äì and the project was shockingly not a debacle, and oh yeah it had no bugs. We had built this sophisticated testing system to make our database more solid, but to our shock that wasn‚Äôt the biggest effect it had. The biggest effect was that it gave our tiny engineering team the productivity of a team 50x its size.</p>
<p>In 2015, Apple acquired FoundationDB and began using it as the ‚Äúunderpinning of their cloud infrastructure‚Äù (that‚Äôs a <a href="https://www.foundationdb.org/files/fdb-paper.pdf">direct quotation</a> from Apple, so they can‚Äôt sue me), and then <a href="https://github.com/apple/foundationdb">open sourced</a> it a few years later. As our team began to disperse throughout other big tech companies, we were shocked to find that even in these sophisticated organizations, nothing like FoundationDB's deterministic simulation testing existed. The near-impossibility of anticipating unintended system impacts meant that changes to their backend systems happened at a snail's pace, and diagnosing and fixing production bugs consumed months of extremely valuable time from some of their most senior engineers.</p>
<p>So I called up my friend and former boss Dave Scherer (FoundationDB‚Äôs chief architect), and told him: ‚ÄúThere‚Äôs a $100 bill lying on the sidewalk here man.‚Äù Of course, economic theory will tell you that those don‚Äôt exist. There‚Äôs always a catch, always some horrible reason that the pot of gold is surrounded by corpses. But starting a company is about banishing that thought and telling yourself that when you reach the pit full of poisonous spikes, you‚Äôll figure something out. So in 2018, we started Antithesis with the goal of bringing the superpower of FoundationDB-style deterministic autonomous testing to everybody else.</p>
<p>
    <img alt="poison-spikes" src="https://antithesis.com/blog/is_something_bugging_you/images/poison%20spikes.png">
</p>
<h4>What We've Built</h4>
<p>Sure enough, the $100 bill is surrounded by an entire <em>field</em> of poisonous spike-pits, nay, a <em>continent</em> of them. Here‚Äôs an obvious one: how do you take an arbitrary piece of software, which is probably doing stuff like spawning threads, checking the time, asking the kernel for random numbers, and talking to other software over a network, and make it deterministic? At FoundationDB we had the benefit of a green-field project that we knew we wanted to test this way, and we had no dependencies (or at least, we didn‚Äôt once we‚Äôd deleted them all). But any new software development methodology that requires everybody to rewrite everything from scratch isn‚Äôt going to get very far. We thought about this and decided to just go all out and write a hypervisor which emulates a deterministic <em>computer</em>. Consequently, we can force anything inside it to be deterministic. That meant learning lots of fun new things about how Intel CPUs handle extended page tables and other related horrors. It‚Äôs a story for another time, but it‚Äôs a good example of the kind of poisonous spike-pit we‚Äôve gotten to explore (and it‚Äôs far from the worst one!).<sup><a href="#fn2" id="ref2">[2]</a></sup></p>
<p>Anyway, we‚Äôve built a platform that takes your software and hunts for bugs in it. When it finds one, that bug is always perfectly reproducible, no matter what crazy thing your software was doing‚Äìeven if it involves multiple services communicating across a network. Also, once we‚Äôve found a bug, we can bring some relatively space-age and insane debugging capabilities to bear on it. The platform is designed to be able to someday find many kinds of bugs in many kinds of software, but for now, we‚Äôre focused solely on distributed systems reliability / fault tolerance testing, because it‚Äôs an area where we already know what we‚Äôre doing.</p>
<p>Over the past several years we‚Äôve partnered with engineering teams at a bunch of organizations with big and complicated systems whose reliability they consider critical. We‚Äôve worked with <a href="https://antithesis.com/case_studies/mongodb_productivity">MongoDB for several years</a>, helping them test their core server software as well as their WiredTiger storage engine. We began working with the Ethereum Foundation about a year ahead of the Merge in order to <a href="https://antithesis.com/case_studies/ethereum_merge">help them test it</a>, and continue working with them today. And we‚Äôre working with Palantir‚Äîbut when I told them I was writing this blog post they just glared at me and said ‚Äúno comment‚Äù, so that‚Äôs all I can say about that.</p>
<p>Initially, these customers thought of Antithesis as a ‚Äúspecial forces‚Äù tool that primarily helped them find and replicate their most elusive and dangerous bugs. But as our platform has become more mature and interactive, we‚Äôve shifted to being an ‚Äúalways on‚Äù service that continuously tests the most recent builds of their software, thus shortening the time from bug introduction to bug discovery. When building FoundationDB, we found that this made diagnosing and fixing bugs dramatically easier, increasing our efficiency and improving our software quality. Our customers are seeing this effect now, and we‚Äôre excited to help many more of you reach the ~zero bugs promised land in the years to come.</p>
<h4>Get In Touch?</h4>
<p>If your organization runs a distributed system and values reliability and engineering productivity, <a href="https://antithesis.com/contact">we‚Äôd love to talk</a>.</p>
<p>Do you occasionally walk into a spike pit and say to yourself: ‚ÄúNot bad, but these spikes really aren‚Äôt poisonous enough‚Äù? If so, please take a look at our <a href="https://antithesis.com/company/careers">open positions</a>.</p>
<p>If you‚Äôve got questions or comments, feel free to reach out on <a href="https://twitter.com/antithesishq/"><s>Twitter</s>X</a> or <a href="mailto:contact@antithesis.com">contact@antithesis.com</a> (we‚Äôll actually reply).</p>
<p>If you‚Äôve made it this long ‚Äì thank you for reading. More to come soon.</p>
<hr>
<p><sup id="fn1">1. Back then Spanner wasn‚Äôt public yet and a lot of people misinterpreted the CAP theorem to say that a strongly consistent database couldn‚Äôt also be highly available in the face of network faults.<a href="#ref1" title="Jump back from footnote 1 to the text.">‚Ü©</a></sup>
</p>
<p><sup id="fn2">2. As Dave never ceases to remind me, the problem of exploring the state space for an arbitrary program, looking for violations of a property that could involve multiple rounds of universal and existential quantification, is actually worse than the Turing Halting Problem. There are test properties that would still be uncomputable even if you had a halting oracle for every program.<a href="#ref2" title="Jump back from footnote 2 to the text.">‚Ü©</a></sup>
</p>

    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Non-code contributions are the secret to open source success (238 pts)]]></title>
            <link>https://github.com/readme/featured/open-source-non-code-contributions</link>
            <guid>39356320</guid>
            <pubDate>Tue, 13 Feb 2024 10:26:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/readme/featured/open-source-non-code-contributions">https://github.com/readme/featured/open-source-non-code-contributions</a>, See on <a href="https://news.ycombinator.com/item?id=39356320">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="">



        <p>Mathematics teacher <a href="https://github.com/sarah11918"><u>Sarah Rainsberger</u></a> wasn‚Äôt planning to become an open source contributor when she started rebuilding her choir‚Äôs website. She just wanted to learn JavaScript and web development for fun. ‚ÄúI wasn't a programmer, but I often found I was the only remotely technical person in a group,‚Äù she explained. ‚ÄúThat‚Äôs how I ended up building the choir website in the first place.‚Äù</p>
<p>
She settled on using the front-end framework <a href="https://github.com/withastro/astro"><u>Astro</u></a>, which was brand new at the time. It had fewer resources for learners than more established frameworks, but she thought following along as the project grew would be a good way to learn. She soon found herself contributing a small piece of code‚Äîa configuration file‚Äîto the project. Then, as the project grew, Rainsberger became increasingly involved with the community, fielding questions and supporting new Astro users. ‚ÄúI wasn‚Äôt the person who knew the most about the inner workings of the project, but I knew how to explain stuff and guide people through the learning process,‚Äù she says. ‚ÄúAnd I knew who to ask when there was something I didn‚Äôt know.‚Äù</p>

<p>Today, Rainsberger is part of Astro‚Äôs core maintainer group. But she still isn‚Äôt particularly involved in the codebase, even as she‚Äôs deepened her web development skills. As the documentation lead, she spends her time helping others learn the ins and outs of Astro.</p>

<p>When we think about ‚Äúcontributors‚Äù in open source, all too often we think of those who write code, whether that's adding features or fixing bugs. But open source projects are more than just code. Much of the work that goes into open source is the type of work Rainsberger does.</p>

<p>‚ÄúThe things you need for a successful open source project overlap with what you need for a successful commercial product,‚Äù says <a href="https://github.com/geekygirldawn"><u>Dawn Foster</u></a>, an open source community manager currently working as director of open source community strategy at VMware. ‚ÄúThat includes documentation, localization, marketing, graphic design, testing, community management, and release management.‚Äù</p>

<p>It‚Äôs difficult to overstate how important non-code contributions are to open source. ‚ÄúEven if you write an amazing program, no one will use it if you don‚Äôt explain what it does and how to use it,‚Äù says <a href="https://github.com/nate-double-u"><u>Nate Waddington</u></a>, a developer advocate at the Cloud Native Computing Foundation with a background in design. A very simple project might just need a README, but the more complex the project, the more documentation, tutorials, and support are needed to make the code useful. Easy-to-source documentation boosts productivity by about 50% in both open source and enterprise software projects, according to the <a href="https://octoverse.github.com/2021/"><u>2021 State of the Octoverse</u></a> report. Graphic design, branding, and outreach, meanwhile, help signal the health and seriousness of a project that other projects or companies might leverage as dependencies.</p>

<p>While there are plenty of opportunities for non-technical folks to contribute to open source, non-code contributions aren‚Äôt necessarily non-technical. Certain testing, documentation, and support tasks might require deep knowledge of a codebase. As more and more people seek to contribute to open source to advance their careers, give back to the community, or both, it‚Äôs important to remember that these non-code contributions are crucial to open source and provide plenty of opportunities to develop technical and non-technical skills alike.</p>



<h3><b>Why YOU should make non-code contributions</b></h3>

<p>Adding features or fixing bugs might sound more glamorous than localizing documentation, providing support, or filing reproducible bug reports‚Äîespecially if your goal is to use open source contributions as a path toward employment. But making non-code contributions can be just as rewarding, as Rainsberger‚Äôs experience demonstrates.</p>
<p>
If you‚Äôre interested in technical communications, graphic design, user experience design, or other roles that don‚Äôt involve programming, open source provides an opportunity to build a portfolio. However, programmers also benefit from sharpening their non-code skills, particularly in writing and communication. Plus, experience in writing, support, or community organizing can help you pivot into roles like developer relations or product management.</p>

<p>There are opportunities for people of any skill level to get involved. ‚ÄúYou don‚Äôt need a computer science degree, or an English degree for that matter, to write documentation,‚Äù Waddington says. ‚ÄúEven if you‚Äôre not a strong writer, you have to start somewhere.‚Äù</p>
<p>Besides, it‚Äôs hard to make meaningful code contributions until you have a thorough understanding of a project. ‚ÄúFeature requests are fundamentally a different mindset for contributions,‚Äù <a href="https://github.com/wntrblm"><u>Winterbloom</u></a> founder Thea Flowers said in <a href="https://github.blog/2023-05-03-more-than-meets-the-pull-request-maintainers-talk-contributions/"><u>a recent contributor relations Q&amp;A with The ReadME Project</u></a>. ‚ÄúThe other contributions are really like patching up a wall or repainting a fence, but a feature request is like building a new shed in your backyard. You‚Äôve got to really think about it a bit.‚Äù Even what appears to be a small bug fix can have big ramifications.</p>

<p>‚ÄúOnly five percent of the effort to actually get something shipped is writing the code for it,‚Äù <a href="https://github.com/benbjohnson/litestream"><u>Litestream</u></a> maintainer <a href="https://github.com/benbjohnson"><u>Ben Johnson</u></a> said in our <a href="https://github.com/readme/featured/how-open-is-open-source"><u>article on different levels of openness for contributions</u></a>. ‚ÄúIt‚Äôs the years of maintenance afterwards, fixing bugs, writing documentation, making tutorials, and all this other stuff. That‚Äôs the hard part.‚Äù In an informal social media poll in April, The ReadME Project asked maintainers what type of open source contribution they would want if they had to choose only one type from now on. Although code was the most popular answer, with 62.2% of the vote, more than one-third of respondents would prefer documentation, design, or testing.</p>
<p><a href="https://github.com/msaroufim"><u>Mark Saroufim</u></a>, an AI engineer at Meta who helps maintain <a href="https://github.com/pytorch/pytorch"><u>PyTorch</u></a>, recommends reading the documentation for a project you might want to get involved in and fixing any parts that are outdated or broken as a good starting point. Prolific open source maintainer <a href="https://github.com/readme/stories/jordan-harband"><u>Jordan Harband</u></a> explained in the Q&amp;A that newcomers are often better at recognizing issues with existing documentation or spotting areas that lack documentation, specifically because they‚Äôre not already experts with a particular project. ‚ÄúAny documentation I write will inevitably be tainted by my already knowing how it works,‚Äù he said.
Likewise, reading and responding to other people‚Äôs questions will help you deepen your knowledge, get to know the maintainers, and learn a project‚Äôs build process. ‚ÄúIt gives you x-ray vision into a project,‚Äù Saroufim says.</p>
<p>
Even after you‚Äôve transitioned to making code contributions, there are plenty of reasons to keep working on the non-code side. ‚ÄúIf you don‚Äôt want to work on non-code tasks forever, by all means, don‚Äôt,‚Äù Saroufim says. ‚ÄúBut many of the best, most productive engineers at PyTorch are also active in support.‚Äù Providing support helps maintainers learn where users struggle and what features users really want and need, and, in turn, develop better software.
</p>
<p>Sustained community involvement is also a better way to make a name for yourself in open source than one-off code contributions, and there are often more long-term opportunities to help out with a project in non-coding tasks. Rainsberger‚Äôs experience is proof of that. Her Chromebook contributions were valuable, but what made her a core contributor was her active involvement in the community.</p>

<p>‚ÄúThe relationships and trust you build are important from a career standpoint,‚Äù says Foster. ‚ÄúYou will stand out more by consistently being helpful in a community‚Äôs Slack or Discord or by helping organize events like community meetups.‚Äù</p>


<picture>
  <source srcset="https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=2000&amp;fm=avif 2000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1600&amp;fm=avif 1600w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1200&amp;fm=avif 1200w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1000&amp;fm=avif 1000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=800&amp;fm=avif 800w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=400&amp;fm=avif 400w" sizes="(max-width: 930px) 90vw, 840px" type="image/avif">
  <source srcset="https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=2000&amp;fm=webp 2000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1600&amp;fm=webp 1600w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1200&amp;fm=webp 1200w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1000&amp;fm=webp 1000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=800&amp;fm=webp 800w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=400&amp;fm=webp 400w" sizes="(max-width: 930px) 90vw, 840px" type="image/webp">
  <source srcset="https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=2000&amp;fm=jpg 2000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1600&amp;fm=jpg 1600w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1200&amp;fm=jpg 1200w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=1000&amp;fm=jpg 1000w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=800&amp;fm=jpg 800w,https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=400&amp;fm=jpg 400w" sizes="(max-width: 930px) 90vw, 840px" type="image/jpeg">
  <img width="2000" height="1200" loading="lazy" decoding="async" alt="Inline1_Feature_Non-code-Contributions" src="https://images.ctfassets.net/s5uo95nf6njh/45uP9xPcJcgke37nYvFGKs/382b3251c64db1915d1cd8c1cc51edd2/annie-spratt-g9KFpAfQ5bc-unsplash.jpg?w=2000&amp;fm=jpg">
</picture>
<h3><b>Finding and appreciating non-code contributors</b></h3>

<p>The importance of non-code contributions is clear, but how can maintainers find people to pitch in? Ideally, contributors will follow Waddington‚Äôs advice and jump in without waiting for someone to tell them what to do. However, the opposite advice applies to maintainers: If they want contributions, the best thing to do is to ask people to do specific things. ‚ÄúI search Twitter and if I see someone tweeting about something missing or incorrect in the docs I ask them if they‚Äôre interested in fixing it,‚Äù said Rainsberger. ‚ÄúIt‚Äôs a simple way to get the docs fixed and to give people an opportunity to get involved.‚Äù
</p>
<p>Flowers recommends building a community on a chat platform like Discord, Gitter, or Slack to make it easier for people to get involved informally with a project. ‚ÄúIt makes people feel less hesitant to ask quick questions,‚Äù she said. ‚ÄúA lot of people are intimidated to ask questions on repositories.‚Äù Also, people outside a project‚Äôs core team might be more willing to pipe up with an answer.&nbsp;</p>

<p>Maintainers should also file issues and tag them with ‚ÄúHelp Wanted‚Äù and, when appropriate, ‚ÄúGood First Issue.‚Äù The State of the Octoverse report found that projects with about 25% of their issues marked with the ‚ÄúHelp Wanted‚Äù tag saw 13% more contributors than those without, and those with 40% of issues tagged as ‚ÄúGood First Issues‚Äù saw 21% more new contributors than those without.&nbsp;</p>

<p>Projects can also participate in programs like <a href="https://summerofcode.withgoogle.com/"><u>Summer of Code</u></a>, <a href="https://hacktoberfest.com/"><u>Hacktoberfest</u></a>, and <a href="https://developers.google.com/season-of-docs"><u>Season of Docs</u></a>. Astro focused specifically on non-code contributions at Hacktoberfest 2022. ‚ÄúIt was phenomenal. We had so much activity; it was really nice to help so many people make their first PR to open source,‚Äù Rainsberger says.</p>

<p>But just asking for help isn‚Äôt always enough. Depending on the size and complexity of your project, contributors may need additional onboarding and orientation. Mentorship is perhaps the best way to set contributors up for success. The 2021 State of the Octoverse report found that mentorship increased productivity in open source projects by 46% and tripled the chances of having a healthy culture. ‚ÄúHaving a dedicated person who engages with new community members helps them overcome hurdles and stay involved with the project,‚Äù <a href="https://github.com/GeorgLink"><u>Georg Link</u></a>, co-founder of open source health metrics organization <a href="https://github.com/chaoss"><u>CHAOSS</u></a>, told The ReadME Project for our <a href="https://github.com/readme/featured/contributor-onboarding"><u>article on onboarding contributors</u></a>. Mentorship is time-consuming and can take maintainers away from other tasks, but the time investment usually pays off in the long run. New contributors can take on increasingly important tasks and even become mentors themselves.
</p>
<p>It‚Äôs also crucial to elevate and appreciate non-code contributors. This not only helps keep current contributors motivated but also helps attract new contributors. ‚ÄúWe try to give lots of opportunities for people to feel valued and publicly recognized,‚Äù Rainsberger says. Early on, the Astro project required someone to make ‚Äúsignificant code contributions‚Äù to become a ‚Äúcore contributor.‚Äù That language has since changed to include non-code contributions when considering promoting people to core contributor status.</p>

<p>Non-code contributors are also included in the project‚Äôs other forms of recognition, such as badges that contributors can display on their GitHub profiles to highlight accomplishments within the project. To help ensure everyone gets their fair share of credit, Astro includes detailed instructions on specifying co-authorship on pull requests. Additionally, the GitHub avatar of every contributor is on the first page of the project‚Äôs documentation. For a more tangible reward, the project distributes funds raised on Open Collective to contributors once per quarter.
</p>
<p>It‚Äôs time for everyone to recognize the role that documentation, support, and other non-code contributions play in making open source viable. It‚Äôs never too late or too early to make your own contributions to your favorite projects.</p>



    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["PayPal took $80k from me and banned me" (140 pts)]]></title>
            <link>https://twitter.com/dannypostmaa/status/1757343318239813730</link>
            <guid>39356277</guid>
            <pubDate>Tue, 13 Feb 2024 10:19:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/dannypostmaa/status/1757343318239813730">https://twitter.com/dannypostmaa/status/1757343318239813730</a>, See on <a href="https://news.ycombinator.com/item?id=39356277">Hacker News</a></p>
Couldn't get https://twitter.com/dannypostmaa/status/1757343318239813730: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[The Catalogue of UK Entrances to Hell (311 pts)]]></title>
            <link>https://www.entrances2hell.co.uk/</link>
            <guid>39356066</guid>
            <pubDate>Tue, 13 Feb 2024 09:41:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.entrances2hell.co.uk/">https://www.entrances2hell.co.uk/</a>, See on <a href="https://news.ycombinator.com/item?id=39356066">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<table>
<tbody><tr>
<td><span face="Verdana"><a href="https://www.entrances2hell.co.uk/pageletters.html">Your emails</a></span></td>
<td><span face="Verdana"><a href="https://www.entrances2hell.co.uk/page272.html">First entrance</a></span></td>
</tr>
</tbody></table>

<div><align=center><span face="Verdana" size="50pt" color="586274"><strong><a href="https://www.entrances2hell.co.uk/page272.html">Welcome to the <br>entrances2hell website</a></strong></span></align=center></div>

<h3><span face="Verdana"><i>A constantly updated <br>catalogue of entrances <br>to Hell in and around the UK</i></span></h3>

<p>
<a href="https://www.entrances2hell.co.uk/page279.html"><img src="https://www.entrances2hell.co.uk/pic279.gif" width="90%" <="" a="">
</a></p><h3><a href="https://www.entrances2hell.co.uk/page279.html"><span face="Verdana">
</span></a><span face="Verdana"><a href="https://www.entrances2hell.co.uk/page279.html">This week's MOST POPULAR ENTRANCE is Quetty Orarna</a>
</span></h3>



<table>
<tbody><tr>
<td><span face="Verdana"><a href="https://www.entrances2hell.co.uk/pageletters.html">Your emails</a></span></td>

<td><span face="Verdana"><a href="https://www.entrances2hell.co.uk/page272.html">First entrance</a></span></td>
</tr>
</tbody></table>


<p><span face="Verdana" size="1">entrances2hell.co.uk ¬© J H Irvine 2002</span></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So You Think You Know Git ‚Äì Git Tips and Tricks by Scott Chacon (416 pts)]]></title>
            <link>https://blog.gitbutler.com/git-tips-and-tricks/</link>
            <guid>39356042</guid>
            <pubDate>Tue, 13 Feb 2024 09:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gitbutler.com/git-tips-and-tricks/">https://blog.gitbutler.com/git-tips-and-tricks/</a>, See on <a href="https://news.ycombinator.com/item?id=39356042">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				<main>
					<progress></progress>
<article>
	
	<div>
		<figure><iframe width="200" height="113" src="https://www.youtube.com/embed/aolI_Rz0ZqY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="UNLISTED FOR REVIEW Scott Fosdem 2 24 UNLISTED FOR REVIEW"></iframe><figcaption><p><span>My FOSDEM 2024 talk on little known Git stuff that this blog series is based off.</span></p></figcaption></figure><p>Years ago I used to do talks on <a href="https://www.youtube.com/watch?v=RiKJqtppKSM&amp;ref=blog.gitbutler.com" rel="noreferrer">advanced Git stuff</a>. For the last decade or so, I've sort of assumed that everyone knew all the advanced command line stuff by now.</p><p>However, in the last few months I‚Äôve been back on the speaking circuit, talking about Git and GitButler and I‚Äôve found that <em>lots</em> of people don‚Äôt know a <em>lot</em> of stuff about Git.</p><p>There is a whole generation of developers who just grew up only using Git, never having to switch to it from something else or relearn previous concepts from SVN or CVS or whatever.</p><p>Additionally, there are a few things that Git can do now that wasn‚Äôt possible years ago. Git has learned some stuff. Most of the changes are subtle or very targeted, but they could be useful to people, so I figured this would be a good time to do a little survey of some interesting Git things that might be new to you for whatever reason.</p><p>There are a million things, but I'm going to narrow them down to "still too many for one blog post", so instead I'll do a small series covering a few topics each.</p><h2 id="the-series">The Series</h2><p>So, I'm going to write 3 short articles on some interesting Git things for intermediate to advanced Git users that you may not know, either because they just never came up or because they're pretty new and you've been using Git the same way for years.</p><p>The topics are:</p><ul><li><a href="https://blog.gitbutler.com/git-tips-1-theres-a-git-config-for-that/" rel="noreferrer">Oldies but Goodies</a></li><li><a href="https://blog.gitbutler.com/git-tips-2-new-stuff-in-git/" rel="noreferrer">Some Subtle New Things</a></li><li><a href="https://blog.gitbutler.com/git-tips-3-really-large-repositories/" rel="noreferrer">Really Large Repositories and Monorepos</a></li></ul><p>I hope you find something interesting in there. Git continues to surprise even me, so have fun exploring!</p><p>Let's start with <a href="https://blog.gitbutler.com/git-tips-1-theres-a-git-config-for-that/" rel="noreferrer">Oldies but Goodies</a>!</p>
			</div>
</article>



					<div>
		<h3>Subscribe to new posts.</h3>
		
	</div>
				</main>
							</div><div id="notifications">
	<p>You‚Äôve successfully subscribed to GitButler</p>
	<p>Welcome back! You‚Äôve successfully signed in.</p>
	<p>Great! You‚Äôve successfully signed up.</p>
	<p>Success! Your email is updated.</p>
	<p>Your link has expired</p>
	<p>Success! Check your email for magic link to sign-in.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Locke's recipe for Pancakes (2021) (152 pts)]]></title>
            <link>https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/</link>
            <guid>39354870</guid>
            <pubDate>Tue, 13 Feb 2024 05:43:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/">https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/</a>, See on <a href="https://news.ycombinator.com/item?id=39354870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><a href="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg"><img data-attachment-id="3856" data-permalink="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/2021-12-14-10-48-28/" data-orig-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1639478908&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;64&quot;,&quot;shutter_speed&quot;:&quot;0.0082644628099174&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2021-12-14 10.48.28" data-image-description="" data-image-caption="" data-medium-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=300" data-large-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=676" src="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=676&amp;h=507" alt="cooked pancake on a plate" width="676" height="507" srcset="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=676&amp;h=507 676w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=1352&amp;h=1014 1352w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=150&amp;h=113 150w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=300&amp;h=225 300w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=768&amp;h=576 768w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.48.28.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 676px) 100vw, 676px"></a></p>
<p>A collection of philosopher <a href="https://plato.stanford.edu/entries/locke/">John Locke</a>‚Äòs<a href="https://archives.bodleian.ox.ac.uk/repositories/2/resources/9195"> papers at the Bodleian Library</a> includes letters, accounts, poetry, notes on medicine and books, and recipes. When David Armitage posted this recipe for pancakes in the Bodleian collection on <a href="https://twitter.com/DavidRArmitage/status/1420686951829618688?s=20">Twitter</a>, I knew that I wanted to try it. These rich, nutmeg-scented pancakes are absolutely delicious.&nbsp;(Many thanks to Rhae Lynn Barnes and the other readers who immediately sent this recipe my way.)</p>


<p>In <a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015005394641&amp;view=1up&amp;seq=22">Philip Long‚Äôs catalog</a> of the collection at the Bodleian, he notes that this recipe, and a few others, were written by Locke: ‚ÄúA collection of twelve recipes dated 1675-94, of which three (fols. 85, 89, 91) are in Locke‚Äôs hand‚Äù (2). The next time I visit Oxford for research, I will be excited to see this recipe as well as the eleven others in this set of miscellaneous papers.</p>
<p><a href="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg"><img data-attachment-id="3864" data-permalink="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/2021-12-14-10-53-59/" data-orig-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1639479239&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;160&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2021-12-14 10.53.59" data-image-description="" data-image-caption="" data-medium-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=300" data-large-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=676" src="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=676&amp;h=507" alt="coffee in cup, pancake on plate" width="676" height="507" srcset="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=676&amp;h=507 676w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=1352&amp;h=1014 1352w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=150&amp;h=113 150w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=300&amp;h=225 300w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=768&amp;h=576 768w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.53.59.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 676px) 100vw, 676px"></a></p>
<p><strong>Original Recipe</strong></p>
<p>Oxford, Bodleian Libraries MSS. Locke c. 25, fol. 85. (Photo from David Armitage)</p>
<p><a href="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png"><img data-attachment-id="3608" data-permalink="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/locke-pancakes-bodleian-ms-locke-c-25-f-85/" data-orig-file="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png" data-orig-size="1263,1684" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="locke pancakes Bodleian ms Locke c.25, f.85" data-image-description="" data-image-caption="" data-medium-file="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=225" data-large-file="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=676" loading="lazy" src="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=676&amp;h=901" alt="" width="676" height="901" srcset="https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=676&amp;h=901 676w, https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=113&amp;h=150 113w, https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=225&amp;h=300 225w, https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png?w=768&amp;h=1024 768w, https://rarecooking.files.wordpress.com/2021/08/locke-pancakes-bodleian-ms-locke-c.25-f.85.png 1263w" sizes="(max-width: 676px) 100vw, 676px"></a></p>
<p>pancakes<br>
Take sweet cream 3/4 + pint. Flower a<br>
quarter of a pound. Eggs <del>four</del> 7 leave out <del>two</del> 4 of<br>
the whites. Beat the Eggs very well. Then put in<br>
the flower, beat it a quarter of an hower. Then<br>
put in six spoonfulls of the Cream, beat it a litle<br>
Take new sweet butter half a pound. Melt it to oyle, &amp;<br>
take off the skum, power in all the clear by degrees<br>
beating it all the time. Then put in the rest of<br>
y<em>ou</em>r cream. beat it well. Half a grated nutmeg<br>
&amp; litle orangeflower water. Frie it without butter.<br>
This is the right way</p>
<p>From the start, I was intrigued by the cross-outs and other notes in the recipe. It appears that it was first drafted (or prepared) using significantly fewer eggs. The modifier ‚Äúnew‚Äù was added before ‚Äúsweet butter‚Äù at some point. Locke may have written the final note ‚ÄúThis is the right way‚Äù as part of the initial draft or after the recipe was prepared. Locke was attentive to the details of separating and whisking eggs as well as adding just the right amount of orange blossom water (‚Äúlitle‚Äù) and nutmeg (‚ÄúHalf a grated nutmeg‚Äù) ‚Äì an exceptional, expensive amount.</p>

<p>Like the other seventeenth- and eighteenth-century <a href="https://rarecooking.com/2016/02/09/pancakes-two-ways/">pancakes</a> that I‚Äôve tried, these fall somewhere between cr√™pes and American pancakes: They‚Äôre a bit fluffier and fattier than a classic French cr√™pe and have far less rise than my favorite American breakfast version. My spouse, Joseph, described Locke‚Äôs pancakes as somewhere between a classic English pancake and a Scotch pancake (or Scottish pancake).</p>
<p>Many of the commenters on Twitter balked at the instruction to beat the eggs and flour for a ‚Äúquarter of an hower.‚Äù These extended mixing times, however, are common in early modern recipes. While I did prepare my version using a hand-held mixer to ensure thorough beating, I did reduce the mixing time to avoid <a href="https://www.bonappetit.com/test-kitchen/common-mistakes/article/10-pancake-common-mistakes-avoid">over-mixing</a> which can lead to&nbsp;a chewy pancake. From what I know about historical and contemporary flour milling, this would not have been a concern for Locke or his cook.</p>

<p><strong>Updated Recipe</strong></p>
<p><em>Makes approximately 10 8-inch pancakes</em></p>
<p>1 cup butter (2 sticks, 1/2 lb, 226g)<br>
3 whole eggs plus 4 additional egg yolks<br>
1 cup flour (1/4 lb, 113g)<br>
1 1/2 cups heavy cream<br>
1 Tablespoon orange blossom water<br>
half a nutmeg, grated</p>
<p>First, melt the butter. Set it aside.</p>
<p>Put the whole eggs and egg yolks in a large bowl. Beat with a whisk or hand-held mixer until well combined.</p>
<p>Add the flour and beat until smooth and completely combined. Add 6 Tablespoons of the cream to the egg flour mixture and mix until combined. While stirring or beating, pour in the melted butter.&nbsp;Add the remaining cream and orange blossom water and stir to combine. Grate 1/2 a nutmeg and stir into batter.</p>
<p>Heat a frying pan or skillet on a high heat until a drop of water skitters across the surface. Lower the heat to medium.</p>
<p>Pour approximately half a cup of batter into the center of the pan and spread by swirling the pan to create an 8-inch pancake. Cook for 1 minute or until the edges of the pancake lift and appear lacy and the middle looks mostly set. Flip the pancake and cook for an additional 30 seconds.</p>
<p>Repeat until your batter is gone. Serve the pancakes immediately.</p>
<p><a href="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg"><img data-attachment-id="3866" data-permalink="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/2021-12-14-11-07-37/" data-orig-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1639480057&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2021-12-14 11.07.37" data-image-description="" data-image-caption="" data-medium-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=225" data-large-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=676" loading="lazy" src="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=676&amp;h=901" alt="1/3 eaten pancake" width="676" height="901" srcset="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=676&amp;h=901 676w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=1352&amp;h=1802 1352w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=113&amp;h=150 113w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=225&amp;h=300 225w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-11.07.37.jpg?w=768&amp;h=1024 768w" sizes="(max-width: 676px) 100vw, 676px"></a></p>
<p><strong>The Results</strong></p>
<p>Between the rich dairy and the fragrant nutmeg, these pancakes made for a decadent breakfast. When Locke wrote down, and perhaps prepared this recipe, the eggs, cream, butter, and flour would all have been ingredients ready to hand in many households. The addition of so much nutmeg and a dash of orange blossom water elevates this specific pancake recipe to a special treat.</p>
<p>I certainly enjoyed sitting down with a plate of pancakes drizzled with a little bit of honey, a cup of coffee, and an old, heavily annotated copy of Locke that I read for a class that I took more than a decade ago. If you make these pancakes on a future winter morning or as part of your holiday vacation, be sure to let me know.</p>
<p><a href="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg"><img data-attachment-id="3865" data-permalink="https://rarecooking.com/2021/12/14/john-lockes-recipe-for-pancakes/2021-12-14-10-55-44/" data-orig-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1639479344&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2021-12-14 10.55.44" data-image-description="" data-image-caption="" data-medium-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=300" data-large-file="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=676" loading="lazy" src="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=676&amp;h=507" alt="book Locke's two treatises, and plate with pancakes and fork" width="676" height="507" srcset="https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=676&amp;h=507 676w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=1352&amp;h=1014 1352w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=150&amp;h=113 150w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=300&amp;h=225 300w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=768&amp;h=576 768w, https://rarecooking.files.wordpress.com/2021/12/2021-12-14-10.55.44.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 676px) 100vw, 676px"></a></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Math as a habit (146 pts)]]></title>
            <link>https://kidswholovemath.substack.com/p/math-as-a-habit</link>
            <guid>39354155</guid>
            <pubDate>Tue, 13 Feb 2024 03:53:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kidswholovemath.substack.com/p/math-as-a-habit">https://kidswholovemath.substack.com/p/math-as-a-habit</a>, See on <a href="https://news.ycombinator.com/item?id=39354155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Just over 10 years ago, New York Times business reporter Charles Duhigg wrote a book called ‚ÄúThe Power of Habit‚Äù</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-141624052" href="https://kidswholovemath.substack.com/p/math-as-a-habit#footnote-1-141624052" target="_self" rel="">1</a></span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg" width="336" height="522" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:522,&quot;width&quot;:336,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac4a0f27-9777-4d19-88b8-33f789f55c08_336x522.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>In it, Duhigg explains why habits exist and how they can be changed.</p><p>In the book, which is a fun and easy read, Duhigg puts together a simple model for how behaviors happen.</p><p>The model is that in every behavior, three things that must take place</p><ol><li><p>Cue</p></li><li><p>Routine</p></li><li><p>Rewards</p></li></ol><p>He writes</p><blockquote><p>habits are created by putting together a cue, a routine, and a reward, and then cultivating a craving that drives the loop</p></blockquote><p><span>And then he breaks down how to establish habits and gives many examples you can use. Eventually, he writes a whole other book to give you even more information about how to put it to use.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-141624052" href="https://kidswholovemath.substack.com/p/math-as-a-habit#footnote-2-141624052" target="_self" rel="">2</a></span></p><p>After reading the book, we implemented new habits into our family life.</p><p>Our kids love math, so helping them do what they love seemed like a good daily goal.</p><p>However, life often got in the way, and we didn‚Äôt do enough math for them.</p><p>Making ‚Äúdoing math‚Äù a daily habit was a way to show them respect and honor their interests.</p><p>Once both kids had shown enough interest in math that it was apparent to us that we should give them more math, we decided to make doing daily math a habit.</p><p>The first thing we tried was being organized and establishing a ‚ÄúTime‚Äù Cue.</p><p>We tried to make it so that we would sit down and ‚Äúdo math‚Äù every day at 6 pm.</p><p>I put it in our family‚Äôs electronic calendar and had a reminder notification go off at the exact time every day.</p><p>Which somewhat worked, but mostly didn‚Äôt.</p><p>Sometimes, preparing dinner would take too long, so we started math at 6:30 pm.</p><p>Sometimes, we needed to go to bed early because of a [thing] the next day, so we had to do baths/shower early, so we started math at 5:30 pm on those days.</p><p>Sometimes, we were out of the house and didn‚Äôt have our math.</p><p>Sometimes, the kids were sick and napped in the afternoon, so we did math at 7:30 pm.</p><p>It slowly became a running joke that the notification was a notification of failure to do math rather than an invitation to sit down and do math.</p><p>Our ‚Äútime cue‚Äù for the math habit was not working.</p><p>The next thing we tried was having a floating ‚ÄúCheckbox Streak‚Äù cue.</p><p>Given our schedule was a bit more varied than we had realized, we decided to establish a ‚Äústreak‚Äù.</p><p>Growing up, I was a big fan of the comedian Seinfeld, so I was delighted to find something related to habit-making called the ‚ÄúSeinfeld Strategy.‚Äù</p><p><span>James Clear, who wrote a book about habits - Atomic Habits, shares this from Seinfeld</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-141624052" href="https://kidswholovemath.substack.com/p/math-as-a-habit#footnote-3-141624052" target="_self" rel="">3</a></span></p><blockquote><p><em>He said the way to be a better comic was to create better jokes and the way to create better jokes was to write every day.</em></p><p><em>He told me to get a big wall calendar that has a whole year on one page and hang it on a prominent wall. The next step was to get a big red magic marker. He said for each day that I do my task of writing, I get to put a big red X over that day.</em></p><p><em>‚ÄúAfter a few days you‚Äôll have a chain. Just keep at it and the chain will grow longer every day. You‚Äôll like seeing that chain, especially when you get a few weeks under your belt. Your only job is to not break the chain.‚Äù</em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-141624052" href="https://kidswholovemath.substack.com/p/math-as-a-habit#footnote-4-141624052" target="_self" rel="">4</a></span></p></blockquote><p>From this, we decided to start a streak and keep count.</p><p>It‚Äôs been a few years, but we either made it to 108 days or 180 days of 10-30 minutes of math a day.</p><p>The progress and the fun we had were spectacular.</p><p>But, and it‚Äôs a big one, the moment we fell off the streak, it broke completely.</p><p>If you haven‚Äôt experienced it yourself, it‚Äôs one of the downfalls of this strategy.</p><p>Going back to having a 1-day streak compared to a 10-day, 50-day, 100-day, etc. streak is so daunting that most people (us included) find it hard to start again.</p><p>The guilt of failing the streak really hurts and that was it.</p><p>We didn‚Äôt do math for a while.</p><p>The kids still wanted to do the math, but things came up, and it was easy to say, ‚ÄúWe‚Äôll just do a bit extra tomorrow, and let‚Äôs not do it now.‚Äù</p><p>The next thing we tried was habit stacking.</p><p><span>Continuing to look into Habit Formation books, I found one called ‚ÄúHabit Stacking: 127 Small Changes to Improve Your Health, Wealth, and Happiness‚Äù</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-141624052" href="https://kidswholovemath.substack.com/p/math-as-a-habit#footnote-5-141624052" target="_self" rel="">5</a></span><span> by S.J. Scott.</span></p><p>Though a bit of a funny title, the main idea I took away is that it‚Äôs hard to start a new habit.</p><p>The solution is adding a new habit as part of an existing one.</p><p>One of the examples, if memory serves, is that you (probably) already brush your teeth every day.</p><p>So if you want to start drinking a glass of water in the morning as a new habit (which you should be doing if you‚Äôre not :) ), is that you put a glass next to your bathroom sink, and as soon as you finish brushing your teeth you drink a glass of water.</p><p>BAM!</p><p>Now your two habits are tied together.</p><p>The ‚ÄúCue‚Äù is an already existing habit that will happen automatically and eventually grow to encompass your new habit (drinking a glass of water).</p><p>So we took that idea and tied the ‚Äúdoing math‚Äù habit to the ‚Äúdoing bathtime at night‚Äù habit.</p><p>While one kid is doing their bathtime routine, the other is doing math. Then when they finish, they swap places.</p><p>This worked for us.</p><p>It might work for you!</p><p>Try to think of a ‚Äúhabit‚Äù your family already has in place and see if adding ‚Äúmath time‚Äù at the end of that habit would make sense.</p><p>I‚Äôve heard from families that have the following as their cues</p><ul><li><p>after walking the dog at night</p></li><li><p>after dessert</p></li><li><p>right before dinner</p></li><li><p>when [parent] gets home</p></li><li><p>when [child-help] leaves</p></li><li><p>after their tv/screen time is over</p></li></ul><p>Try it out and let me know how it goes :)</p><p><span>That‚Äôs all for today :) For more </span><em><strong>Kids Who Love Math</strong></em><span> treats, check out our </span><a href="https://kidswholovemath.substack.com/archive" rel="">archives</a><span>.</span></p><p>Stay Mathy!</p><p><span>All the best,</span><br><span>Sebastian Gutierrez</span></p><p>P.S. When you‚Äôre ready, here are three ways I can help:</p><ol><li><p><a href="https://kidswholovemath.substack.com/subscribe" rel="">Become a paid subscriber</a><span> and join weekly office hours to chat about what‚Äôs going on in your life as well as participate in our ‚Äúbook group‚Äù</span></p></li><li><p>Reply to this email with your question(s), and I‚Äôll write you a response</p></li><li><p>Reply to this email and schedule a 1-on-1 consultation to chat about math, raising math kids, math competitions, math camps, math extracurriculars, starting a math circle, math books, or whatever else is on your mind.</p></li></ol></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stable-Audio-Demo (466 pts)]]></title>
            <link>https://stability-ai.github.io/stable-audio-demo/</link>
            <guid>39354138</guid>
            <pubDate>Tue, 13 Feb 2024 03:50:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability-ai.github.io/stable-audio-demo/">https://stability-ai.github.io/stable-audio-demo/</a>, See on <a href="https://news.ycombinator.com/item?id=39354138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      

      <p>‚ö†Ô∏è <em>Warning: This website may not function properly on Safari. For the best experience, please use Google Chrome.</em></p>

<p><a href="https://arxiv.org/abs/2402.04825"><code>arXiv</code></a>: Stable Audio‚Äôs paper</p>

<p><a href="https://github.com/Stability-AI/stable-audio-tools"><code>stable-audio-tools</code></a>: code to reproduce Stable Audio</p>

<p><a href="https://github.com/Stability-AI/stable-audio-metrics"><code>stable-audio-metrics</code></a>: code to evaluate Stable Audio</p>

<p>Our model can generate <strong>variable-length and long-form stereo music at 44.1kHz</strong>:</p>

<table>
  <thead>
    <tr>
      <th>Generated Stereo Music</th>
      <th>Prompt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/berlin-techno-rave-drum-machine-kick-ARP-synthesizer-dark-moody-hypnotic-evolving-135-bpm.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Berlin techno, rave, drum machine, kick, ARP synthesizer, dark, moody, hypnotic, evolving, 135 BPM. Loop.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/uplifting-acoustic-loop-120-bpm.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Uplifting acoustic loop. 120 BPM.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/Disco,%20Driving%20Drum%20Machine,%20Synthesizer,%20Bass,%20Piano,%20Guitars,%20Instrumental,%20Clubby,%20Euphoric,%20Chicago,%20New%20York,%20115%20BPM.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Disco, Driving Drum Machine, Synthesizer, Bass, Piano, Guitars, Instrumental, Clubby, Euphoric, Chicago, New York, 115 BPM.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/Calm%20meditation%20music%20to%20play%20in%20a%20spa%20lobby.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Calm meditation music to play in a spa lobby.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/drum%20solo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Drum solo.</td>
    </tr>
  </tbody>
</table>

<p>Differently from pervious state-of-the-art models, ours can generate <strong>stereo sound effects at 44.1kHz</strong>:</p>

<table>
  <thead>
    <tr>
      <th>Generated Stereo Sounds</th>
      <th>Prompt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/door-slam-high-quality-stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Door slam. High-quality, stereo.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/sports-car-passing-by-high-quality-stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Sports car passing by. High-quality, stereo.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/motorbike-passing-by-high-quality-stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Motorbike passing by. High-quality, stereo.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/fireworks-high-quality-stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Fireworks. High-quality, stereo.</td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/reverberant-foot-steps-inside-a-large-rocky-cave-high-quality-stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td>Reverberant footsteps inside a large rocky cave. High-quality, stereo.</td>
    </tr>
  </tbody>
</table>

<p>Note that all the examples in this website are generated with the same model that can generate both <strong>variable-length music and sound effects</strong> at 44.1kHz stereo. We append ‚Äúhigh-quality, stereo‚Äù to our sound effects prompts because it is generally helpful.</p>

<h2 id="long-form-stereo-music-comparison-with-state-of-the-art-with-musiccaps-prompts">Long-form stereo music: comparison with state-of-the-art with MusicCaps prompts</h2>

<p><strong>Prompt</strong>: This song contains someone strumming a melody on a mandolin while more people are whistling along. Then a mandolin, an e-bass and an acoustic guitar are playing a short melody in a lower key before breaking into the next part along with flutes and percussions. This song may be played outside by musicians performing.</p>

<table>
  <thead>
    <tr>
      <th>Our Model</th>
      <th>MusicGen-large</th>
      <th>MusicGen-stereo</th>
      <th>AudioLDM2</th>
    </tr>
    <tr>
      <th><em>(stereo, 44.1kHz)</em></th>
      <th><em>(mono, 32kHz)</em></th>
      <th><em>(stereo, 32kHz)</em></th>
      <th><em>(mono, 48kHz)</em></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZTVMsW1h3bI_stableaudio.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZTVMsW1h3bI_musicgenlarge.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZTVMsW1h3bI_musicgenstereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZTVMsW1h3bI_audioldm248k_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
    </tr>
  </tbody>
</table>

<p><strong>Prompt</strong>: The commercial music features a groovy piano melody played over snare rolls in the first half of the loop. Right after, there is a drop that consists of a punchy ‚Äú4 on the floor‚Äù kick pattern, shimmering hi hats, claps, groovy piano and wide synth lead melody. It sounds happy, fun, euphoric and exciting.</p>

<table>
  <thead>
    <tr>
      <th>Our Model</th>
      <th>MusicGen-large</th>
      <th>MusicGen-stereo</th>
      <th>AudioLDM2</th>
    </tr>
    <tr>
      <th><em>(stereo, 44.1kHz)</em></th>
      <th><em>(mono, 32kHz)</em></th>
      <th><em>(stereo, 32kHz)</em></th>
      <th><em>(mono, 48kHz)</em></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZK5M3DZejzk_stableaudio.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZK5M3DZejzk_musicgenlarge.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZK5M3DZejzk_musicgenstereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/ZK5M3DZejzk_audioldm248k_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
    </tr>
  </tbody>
</table>

<p>These prompts/audios were used for the qualitative study we report in our paper.</p>

<h2 id="sound-effects-comparison-with-state-of-the-art-with-audiocaps-prompts">Sound effects: comparison with state-of-the-art with AudioCaps prompts</h2>

<p><strong>Prompt</strong>: Clicking and sputtering then eventual revving of an idling engine.</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Audiogen-medium</th>
      <th>AudioLDM2</th>
    </tr>
    <tr>
      <th><em>(stereo, 44.1kHz)</em></th>
      <th><em>(mono, 32kHz)</em></th>
      <th><em>(mono, 48kHz)</em></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/103136_stableaudio_audio.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/103136_audiogen_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/103136_audioldm248k_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
    </tr>
  </tbody>
</table>

<p><strong>Prompt</strong>: Birds chirping loudly.</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Audiogen-medium</th>
      <th>AudioLDM2</th>
    </tr>
    <tr>
      <th><em>(stereo, 44.1kHz)</em></th>
      <th><em>(mono, 32kHz)</em></th>
      <th><em>(mono, 48kHz)</em></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/37008_stableaudio_audio.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/37008_audiogen_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/37008_audioldm248k_stereo.wav" type="audio/mpeg">Audio not supported by your browser.</audio></td>
    </tr>
  </tbody>
</table>

<p>These prompts/audios were used for the qualitative study we report in our paper. Note the (randomly) selected prompts from AudioCaps did not require substantial stereo movement, resulting in renders that are relatively non-spatial.</p>

<h2 id="autoencoder-reconstructions">Autoencoder: reconstructions</h2>

<p>This comparison is useful to evaluate the audio fidelity capabilities of the autoencoder. On the left, we have the ground truth recording. On the right, we take the ground truth recording and end pass it through the autoencoder. Note that the autoencoder reconstruction is fairly transparent, very close to the ground truth.</p>

<table>
  <thead>
    <tr>
      <th>Ground truth</th>
      <th>&nbsp;Autoencoder reconstruction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/1197.flac" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/1197_ae.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/1243.flac" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/1243_ae.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/233076.flac" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/233076_ae.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/451.flac" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/451_ae.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
    </tr>
    <tr>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/206251.flac" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
      <td><audio controls="" preload="none"><source src="https://stability-ai.github.io/stable-audio-demo/audio/206251_ae.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></td>
    </tr>
  </tbody>
</table>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It Is Somebody's Moral Imperative to Leak "Coyote vs. Acme" to the World (103 pts)]]></title>
            <link>https://aftermath.site/coyote-vs-acme-fuck-david-zaslav</link>
            <guid>39353562</guid>
            <pubDate>Tue, 13 Feb 2024 02:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/coyote-vs-acme-fuck-david-zaslav">https://aftermath.site/coyote-vs-acme-fuck-david-zaslav</a>, See on <a href="https://news.ycombinator.com/item?id=39353562">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Last week<a href="https://www.thewrap.com/coyote-vs-acme-update-offers-warner-bros/" target="_blank" rel="noreferrer noopener"> an excellent report on The Wrap revealed that</a>, despite initially walking back its decision, Warner Bros. is indeed intent on throwing <em>Coyote vs Acme</em>--a funded, shot and completed motion picture--in the trash. Not because it sucks, but to save some money on taxes.</p><p>It's not the first time this has happened recently--"content" ranging<a href="https://gizmodo.com/disney-streaming-cuts-tax-writeoffs-1850502594" target="_blank" rel="noreferrer noopener"> from Disney TV shows</a> to a <em>Batgirl </em>movie has met with the same fate--but this one stung a little more. Disney and HBO removing TV shows that people had already had a chance to see was one thing, and <em>Batgirl</em><a href="https://www.nme.com/en_au/news/film/batgirl-movie-so-bad-not-releasable-says-dc-studios-3390857#:~:text='Batgirl'%20movie%20was%20so%20bad%20it%20was%20%E2%80%9Cnot,releasable%E2%80%9D%2C%20says%20DC%20Studios%20boss&amp;text=Leslie%20Grace%20as%20'Batgirl'%20CREDIT,Grace%2C%20Brandon%20Fraser%20and%20J.K." target="_blank" rel="noreferrer noopener"><em> </em>was reportedly also very bad</a>, which was another.</p><p>But <em>Coyote vs Acme</em> has been seen by <em>nobody</em>. The movie--directed by Dave Green, written by <em>May December's</em> Samy Burch, produced by (among others) James Gunn and starring characters that define Warner Bros.' entire existence--was paid for, is finished, is ready to be seen, and now it stands a very real chance of being deleted forever, just to save a company some money.</p><p>It's an incredibly dystopian situation we all find ourselves in, where art is only made to be fed into a woodchipper to serve shareholders, and it's one<a href="https://www.looper.com/1161829/hollywood-creatives-are-breathing-fire-over-the-current-trend-of-tv-tax-write-offs/" target="_blank" rel="noreferrer noopener"> that's been covered extensively elsewhere</a>, so I'm not going to get into the reeds over the politics and economics of the decision here.</p><p>What I am going to say, though, is that if you work at Warner Bros., or anywhere related to Warner Bros., and you have any access to this movie whatsoever, it's your moral imperative to leak it to the world before it's too late. If Warner Bros. don't want to release it, and have reportedly blocked attempts for other companies to release it, then what does it matter?</p><p>(<strong>Please note</strong>: I am not a lawyer or law enforcement officer and this does not constitute actual advice).</p><p>As we <em>have </em>covered previously,<a href="https://aftermath.site/there-is-no-piracy-without-ownership" target="_blank" rel="noreferrer noopener"> there is no piracy without ownership</a>. If we can't buy or rent the thing, and likely never will be able to do so via legal means, then leaking this movie and putting it on torrent sites shouldn't be seen as stealing, either. By all accounts Warner CEO David Zaslav is happy throwing this movie in the bin, without selling a single theatre ticket or digital rental, so whether we get to see it for free or not doesn't move that financial needle one bit.</p><p>What leaking the movie <em>would </em>do is save a piece of art that hundreds of people poured their hearts and souls into for months or even <em>years</em>. That shouldn't be a crime. That's public service.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia is now more valuable than Amazon and Google (316 pts)]]></title>
            <link>https://www.forbes.com/sites/dereksaul/2024/02/12/nvidia-is-now-more-valuable-than-amazon-and-google/</link>
            <guid>39353325</guid>
            <pubDate>Tue, 13 Feb 2024 01:48:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/dereksaul/2024/02/12/nvidia-is-now-more-valuable-than-amazon-and-google/">https://www.forbes.com/sites/dereksaul/2024/02/12/nvidia-is-now-more-valuable-than-amazon-and-google/</a>, See on <a href="https://news.ycombinator.com/item?id=39353325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Topline</h2>
<p>Nvidia‚Äôs market value surpassed those of fellow technology titans Amazon and Alphabet on Monday, an almost unbelievable feat accomplished as Nvidia‚Äôs stock more than quadrupled over the last 15 months as investors bought into Nvidia‚Äôs market-leading<strong> </strong>position in artificial intelligence.</p>
<figure role="presentation"><figcaption><fbs-accordion current="-1"><p>Nvidia stock's 17,000% runup over the last 10 years is far and away the best of any S&amp;P 500 <span data-ga-track="caption expand">... [+]</span><span> constituent.</span></p></fbs-accordion><small>Getty Images</small></figcaption></figure> 

<h2>Key Facts</h2>
<div>
 <div>
  <p>Shares of Nvidia rose nearly 3% to an record high of over $740, bringing its market capitalization to $1.83 trillion, narrowly surpassing Alphabet‚Äôs $1.82 trillion and Amazon‚Äôs $1.8 trillion.</p>
  
 </div>
 <div>
  <p>The symbolic passing of the torch caps Nvidia‚Äôs remarkable journey as Wall Street flooded into the stock amid the AI boom.</p>
  
 </div>
 <div>
  <p>Nvidia‚Äôs market cap sat below $300 billion as recently as October 2022, just before the AI wave began to crest, lagging far behind Amazon and Alphabet‚Äôs above $1 trillion valuations at the time.</p>
  
  
 </div>
 <p>Nvidia is now the fourth most-valuable public company in the world, trailing only Microsoft ($3.1 trillion), Apple ($2.9 trillion) and Saudi Aramco ($2 trillion).</p>
</div>


<h2>Key Background</h2>
<p>Nvidia is by far the most prominent producer of the semiconductor chip technology powering generative AI. Investors have been impressed not just by the potential for Nvidia to capitalize on the growing interest and corporate spending in AI, but also by its already exploding results. Nvidia‚Äôs earnings before interest, taxes, depreciation and amortization (EBITDA) expanded by more than 500% last quarter on a year-over-year basis thanks to runaway growth in its AI unit, far stronger than Amazon and Alphabet‚Äôs robust 20% or more earnings growth during the comparable period. Nvidia‚Äôs gross revenue and profits are less eye-popping than its trillion-dollar company peers ‚Äì its $9.2 billion profit last quarter was far smaller than Apple‚Äôs and Microsoft‚Äôs over $22 billion profits during the comparable stretch ‚Äì but analysts expect Nvidia‚Äôs financials to soon close the gap. Nvidia remains among the most popular stocks on Wall Street even after its more than 50% run-up this year, and is a top pick for analysts at both Goldman Sachs and Bank of America, each of which has an $800 price target for Nvidia, implying 8% further upside for the stock.</p>
<h2>Surprising Fact</h2>
<p>Nvidia stock‚Äôs 17,000% gain over the last decade is by far the best return of any stock on the S&amp;P 500, nearly tripling the return of silver medalist and fellow chipmaker Advanced Micro Devices. A $1,000 investment in Nvidia a decade ago would now be worth about $175,000.</p>
<h2>What To Watch For</h2>
<p>Nvidia will report earnings next Wednesday for its fiscal quarter ending last month. Analysts project the company to report its third consecutive quarter of record sales and profits.</p>

<h2>Further Reading</h2><p><a href="https://www.forbes.com/sites/dereksaul/2023/05/25/bigger-than-amazon-nvidia-stock-surges-after-cosmological-profit-projections/" target="_blank" rel="noopener noreferrer" aria-label="Bigger Than Amazon? Nvidia Stock Surges After 'Cosmological' Profit Projections" data-ga-track="forbesEmbedly:https://www.forbes.com/sites/dereksaul/2023/05/25/bigger-than-amazon-nvidia-stock-surges-after-cosmological-profit-projections/"><span><span>MORE FROM FORBES</span><span>Bigger Than Amazon? Nvidia Stock Surges After 'Cosmological' Profit Projections</span><small>By <span>Derek Saul</span></small></span><span><span></span></span></a></p>
<p><a href="https://www.forbes.com/sites/dereksaul/2023/12/15/nvidia-is-this-years-hottest-stock-so-why-are-analysts-disappointed-by-its-230-gain/" target="_blank" rel="noopener noreferrer" aria-label="Nvidia Is This Year's Hottest Stock. So Why Are Analysts Disappointed By Its 230% Gain?" data-ga-track="forbesEmbedly:https://www.forbes.com/sites/dereksaul/2023/12/15/nvidia-is-this-years-hottest-stock-so-why-are-analysts-disappointed-by-its-230-gain/"><span><span>MORE FROM FORBES</span><span>Nvidia Is This Year's Hottest Stock. So Why Are Analysts Disappointed By Its 230% Gain?</span><small>By <span>Derek Saul</span></small></span><span><span></span></span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Abandoned villages of Hong Kong (225 pts)]]></title>
            <link>https://www.cnn.com/2024/02/13/style/hong-kong-abandoned-villages-stefan-irvine-photographer-hnk/index.html</link>
            <guid>39353231</guid>
            <pubDate>Tue, 13 Feb 2024 01:35:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/02/13/style/hong-kong-abandoned-villages-stefan-irvine-photographer-hnk/index.html">https://www.cnn.com/2024/02/13/style/hong-kong-abandoned-villages-stefan-irvine-photographer-hnk/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39353231">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main" data-reorderable="main">  <article data-uri="cms.cnn.com/_components/article/instances/clsjnaesg004ndxp8eeqm2gz3@published" role="main" data-unselectable="true">
      
  <section data-tabcontent="Content">
    <main>
        
        
            <div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Hong Kong</span>
      <span data-editable="source">CNN</span>
        &nbsp;‚Äî&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnaesg004mdxp891fd2v1v@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Thick roots tumble across a dilapidated house, the snake-like trunks of a banyan tree framing where the front door once stood. Its walls have been hollowed by decades of typhoons, monsoons and summer humidity, now little more than loose, moss-covered stones and mortar dust. Vines tease through cracks in the foundations and fallen leaves litter the rotten floorboards.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjndd8r00043b6h4ld04jb9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            This scene wouldn‚Äôt look out of place deep in the Malaysian rainforest or the verdant foothills of India. But photographer Stefan Irvine snapped these pictures just a stone‚Äôs throw from one of the most densely populated cities in the world, a global metropolis of steely skyscrapers and gridlocked traffic.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjne83700083b6hjnef25q1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Irvine, who has lived in <a href="https://www.cnn.com/world/asia/hong-kong">Hong Kong</a> since 2002, first stumbled across the city‚Äôs abandoned villages in 2012 while visiting a friend in the New Territories, a vast area to the city‚Äôs north. Accounting for over 85% of Hong Kong‚Äôs territory, the district is characterized by steep mountains, long stretches of rugged coastline and tree-covered country parks.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjne9e7000a3b6hgs4ltkyv@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúIt made me question, ‚ÄòWhy (were) so many of these places vacant in a place like Hong Kong, where the property prices are the highest in the world?‚Äô‚Äù Irvine recalled. Over the next 12 years, the London-born photographer explored more of these abandoned villages, documenting what would become the subject of his new book, ‚Äú<a href="https://www.stefanirvine.photo/book/abandoned-villages-of-hong-kong-stefan-irvine" target="_blank">Abandoned Villages of Hong Kong</a>.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjne9e7000b3b6haxqe9sq6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúIt‚Äôs opened my eyes to a different aspect of Hong Kong,‚Äù said Irvine. ‚ÄúThat‚Äôs what I‚Äôm hoping the project will do for other people as well.‚Äù
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clsjnelgs000d3b6hbdao8zlg@published" data-name="03 stefan irvine abandoned village hong kong" data-component-name="image" data-observe-resizes="" data-original-ratio="1.4981273408239701" data-original-height="2800" data-original-width="1869" data-url="https://media.cnn.com/api/v1/images/stellar/prod/240212162158-03-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" data-editable="settings">
       <picture><img src="https://media.cnn.com/api/v1/images/stellar/prod/240212162158-03-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" alt="Stefan Irvine, Tai Peng, Lamma #1, Hong Kong 2020, Courtesy of Blue Lotus Gallery" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="2800" width="1869" loading="lazy"></picture>
    </div>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjng8vv000h3b6h0kxzbxcr@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Although Irvine took the first image for the project ‚Äî an abandoned home with plants spilling out onto the road through a yellow door frame ‚Äî in 2012, it wasn‚Äôt until 2019 that he began actively hunting down locations to photograph.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjngadu000j3b6h8v67ixly@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúThese villages have existed in Hong Kong for hundreds of years, way before the colonial period,‚Äù explained Irvine. In the 1950s and ‚Äò60s, as Hong Kong grew as an industrial hub, many people migrated to the rapidly expanding urban centers for better working opportunities. ‚ÄúIt‚Äôs hard farming and fishing out there in these remote areas, so a lot of people moved to the city to work in the factories,‚Äù he added.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjngadu000k3b6hmc50phpk@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Through library research, the 48-year-old photographer found people who grew up in the villages or had relatives who lived there. In the book, he included essays from two women connected to the village: one whose father grew up in Wong Chuk Shan village, now completely overgrown, and another who spent several years of her childhood in Lai Chi Wo village, on the northeast coast of Hong Kong in the 1970s.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjngadu000l3b6hbh7vyacj@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúNow she lives in the UK with her own family, but she comes back to visit HK every few years, and still feels a deep sense of connection with Lai Chi Wo,‚Äù Irvine said of the latter woman, adding: ‚ÄúYou can tell they feel an intense bond with their ancestors and with the village itself.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjngadu000m3b6h5zvravrd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            While many of the villages emptied out slowly over decades, Irvine found some homes that appeared to have been ‚Äúabandoned pretty rapidly,‚Äù with personal items and furniture left behind.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clsjnjmik000o3b6h2iyl5lnp@published" data-name="02 stefan irvine abandoned village hong kong" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6675" data-original-height="1869" data-original-width="2800" data-url="https://media.cnn.com/api/v1/images/stellar/prod/240212162151-02-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" data-editable="settings">
       <picture><img src="https://media.cnn.com/api/v1/images/stellar/prod/240212162151-02-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" alt="Stefan Irvine, Queen's Hill #1, Hong Kong 2021, Courtesy of Blue Lotus Gallery" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1869" width="2800" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnl44u000q3b6hrxjqf4ik@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúThere were calendars on the wall, school certificates in drawers ‚Äî it‚Äôs quite poignant,‚Äù said Irvine.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnl5k4000s3b6hwg9meg6t@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúI think a lot of people left with the intention of coming back one day, or maybe retiring back in the village. But if you don‚Äôt maintain these properties, eventually they‚Äôll succumb to nature. Termites will start to burrow their way into the wooden beams. If one of those collapses, then the seeds can fall in from trees and plants, and then they really take over.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnl5k4000t3b6hqc4bwpvx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Rotting floorboards and unstable masonry made some of the building dangerous to explore. For Irvine, the biggest risk was posed by territorial village dogs that often became aggressive as he walked through remote areas. ‚ÄúI started the habit of carrying dog biscuits in my camera bag when I went out to these places,‚Äù he said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnl5k4000u3b6h6swjleh2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The project took Irvine to the furthest reaches of the city, using minibuses and ferries to access isolated towns and islands. One adventure saw him embark on a six-hour round trip to Tung Ping Chau, a far-flung island closer to the Chinese mainland than to Hong Kong. Once a&nbsp;<a href="https://www.geopark.gov.hk/en/discover/attractions/tung-ping-chau" target="_blank">thriving fishing and farming community</a>, most residents left the island in the 1960s to make a living in the city. Irvine ended up using just one image from the trip in his book ‚Äî but the trip was ‚Äútotally worth it,‚Äù he said.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clsjnlnxf000w3b6h5gaaoej0@published" data-name="05 stefan irvine abandoned village hong kong" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6675" data-original-height="1869" data-original-width="2800" data-url="https://media.cnn.com/api/v1/images/stellar/prod/240212162214-05-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" data-editable="settings">
       <picture><img src="https://media.cnn.com/api/v1/images/stellar/prod/240212162214-05-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" alt="Stefan Irvine, Yim Tin Tsai #1, Hong Kong 2021, Courtesy of Blue Lotus Gallery" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1869" width="2800" loading="lazy"></picture>
    </div>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnmp4200103b6hg5e8edxt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            While most of the villages Irvine photographed are abandoned, he was surprised to discover not all were.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnmywk00123b6hjioq2zjq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúI would hike for about an hour into the wilderness to find a beautiful old village and I assumed there would be nobody there ‚Äî and then around the corner would be someone with a wheelbarrow on their way to plant vegetables or something. So that was a bit of a shock,‚Äù he said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnmywk00133b6hbnw11sxt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Two of his favorite locations to shoot ‚Äî&nbsp;Luk Keng, a coastal area near the border with Shenzhen in mainland China, and Lai Chi Wo, a remote 400-year-old Hakka village accessible only by boat or a two-hour hike through the forest ‚Äî&nbsp;are both still home to small communities.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnmywk00143b6h83cw5dau@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúLai Chi Wo is quite interesting because (Hong Kong‚Äôs) government has realized the heritage value in this village and they‚Äôve invested a substantial amount of money to revitalize some of the old buildings,‚Äù said Irvine. ‚ÄúThey want to encourage young people to go out there and stay overnight and to experience a different side of Hong Kong.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnmywk00153b6hvu7e2qld@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Irvine found other deserted villages that were also being revitalized for tourism. Yim Tin Tsai, a former catholic missionary outpost and salt farming community, is completely abandoned ‚Äî but every summer, it hosts an art installation and festival.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clsjnnbce00173b6hvs79gjmi@published" data-name="04 stefan irvine abandoned village hong kong" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6675" data-original-height="1869" data-original-width="2800" data-url="https://media.cnn.com/api/v1/images/stellar/prod/240212162205-04-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" data-editable="settings">
       <picture><img src="https://media.cnn.com/api/v1/images/stellar/prod/240212162205-04-stefan-irvine-abandoned-village-hong-kong.jpg?c=original" alt="Stefan Irvine, Mau Ping Shan Uk, #1, Hong Kong 2020, Courtesy of Blue Lotus Gallery" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1869" width="2800" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnotrl00193b6h7qctmqu4@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúPeople take a little sampan (a flat-bottomed boat) across the water, it‚Äôs 15 minutes away from (the coast), and they can interact with these art installations that use some of the abandoned sites to great effect,‚Äù Irvine said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnovj8001b3b6hrat5k8z1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Irvine believes there is a growing sentimentality and nostalgia among Hong Kong‚Äôs people ‚Äúto save and relish their built heritage.‚Äù These rural sites are a key part of that, he said, adding: ‚ÄúI think it‚Äôs of great value to people and their sense of identity.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnovj8001c3b6h1dini1an@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The photographer‚Äôs book, published this month alongside an accompanying <a href="https://bluelotus-gallery.com/new-events/abandoned-villages-of-hong-kong-exhibition-by-stefan-irvine" target="_blank">exhibition</a> in Hong Kong, aims to ‚Äúpreserve for posterity‚Äù this built heritage. And while Irvine‚Äôs pictures speak to a loss of community, he views them as a ‚Äúcelebration‚Äù of nature, too.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnovj8001d3b6hdv77xlcj@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Hong Kong is one of the&nbsp;<a href="https://www.wwf.org.hk/en/biodiversity/" target="_blank">most biodiverse cities&nbsp;</a>in the world, and its villages, which were often built around natural features and relied on the land, are a microcosm of that. Tucked between the mountains and the sea, the Hakka village at&nbsp;<a href="https://ccsg.hku.hk/ruralsd/en/pages/about/introduction-to-lai-chi-wo/" target="_blank">Lai Chi Wo</a>, for instance, features mature woodlands, freshwater streams, agricultural wetlands, mud flats and mangroves.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnovj8001e3b6huwnkube6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            ‚ÄúAt the end of the day, nature will eventually take over,‚Äù Irvine said. ‚ÄúIt‚Äôs a reminder of the impermanence that we all experience: Things come and go, nothing endures really.‚Äù
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clsjnovj8001f3b6ht5x6pyi1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            <em>‚Äú</em><a href="https://bluelotus-gallery.com/new-events/abandoned-villages-of-hong-kong-exhibition-by-stefan-irvine" target="_blank"><em>Abandoned Villages of Hong Kong</em></a><em>,‚Äù published by Blue Lotus Editions, is available now. An accompanying exhibition is on show at Hong Kong‚Äôs Blue Lotus Gallery until Feb. 25, 2024.</em>
    </p>

                </div>
    </main>
  </section>
</article>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Visual calculus (204 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Visual_calculus</link>
            <guid>39353207</guid>
            <pubDate>Tue, 13 Feb 2024 01:32:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Visual_calculus">https://en.wikipedia.org/wiki/Visual_calculus</a>, See on <a href="https://news.ycombinator.com/item?id=39353207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Mamikons_Theorem.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Mamikons_Theorem.svg/300px-Mamikons_Theorem.svg.png" decoding="async" width="300" height="121" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Mamikons_Theorem.svg/450px-Mamikons_Theorem.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Mamikons_Theorem.svg/600px-Mamikons_Theorem.svg.png 2x" data-file-width="114" data-file-height="46"></a><figcaption>Mamikon's theorem - the area of the tangent clusters are equal. Here the original curve with the tangents drawn from it is a semicircle.</figcaption></figure>
<p><b>Visual calculus</b>, invented by <a href="https://en.wikipedia.org/wiki/Mamikon_Mnatsakanian" title="Mamikon Mnatsakanian">Mamikon Mnatsakanian</a> (known as Mamikon), is an approach to solving a variety of <a href="https://en.wikipedia.org/wiki/Integral" title="Integral">integral calculus</a> problems.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> Many problems that would otherwise seem quite difficult yield to the method with hardly a line of calculation. Mamikon collaborated with <a href="https://en.wikipedia.org/wiki/Tom_Apostol" title="Tom Apostol">Tom Apostol</a> on the 2013 book <i>New Horizons in Geometry</i> describing the subject.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Description">Description</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=1" title="Edit section: Description"><span>edit</span></a><span>]</span></span></h2>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Mamikon_annulus_area_visualisation.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Mamikon_annulus_area_visualisation.svg/170px-Mamikon_annulus_area_visualisation.svg.png" decoding="async" width="170" height="340" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Mamikon_annulus_area_visualisation.svg/255px-Mamikon_annulus_area_visualisation.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Mamikon_annulus_area_visualisation.svg/340px-Mamikon_annulus_area_visualisation.svg.png 2x" data-file-width="512" data-file-height="1024"></a><figcaption>Illustration of Mamikon's method showing that the areas of two annuli with the same chord length are the same regardless of inner and outer radii.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></figcaption></figure>
<p>Mamikon devised his method in 1959 while an undergraduate, first applying it to a well-known geometry problem: find the area of a ring (<a href="https://en.wikipedia.org/wiki/Annulus_(mathematics)" title="Annulus (mathematics)">annulus</a>), given the length of a <a href="https://en.wikipedia.org/wiki/Chord_(geometry)" title="Chord (geometry)">chord</a> tangent to the inner circumference. Perhaps surprisingly, no additional information is needed; the solution does not depend on the ring's inner and outer dimensions.
</p><p>The traditional approach involves algebra and application of the <a href="https://en.wikipedia.org/wiki/Pythagorean_theorem" title="Pythagorean theorem">Pythagorean theorem</a>. Mamikon's method, however, envisions an alternate construction of the ring: first the inner circle alone is drawn, then a constant-length tangent is made to travel along its circumference, "sweeping out" the ring as it goes.
</p><p>Now if all the (constant-length) tangents used in constructing the ring are translated so that their points of tangency coincide, the result is a circular disk of known radius (and easily computed area). Indeed, since the inner circle's radius is irrelevant, one could just as well have started with a circle of radius zero (a point)‚Äîand sweeping out a ring around a circle of zero radius is indistinguishable from simply rotating a line segment about one of its endpoints and sweeping out a disk.
</p><p>Mamikon's insight was to recognize the equivalence of the two constructions; and because they are equivalent, they yield equal areas. Moreover, the two starting curves need not be circular‚Äîa finding not easily proven by more traditional geometric methods. This yields <b>Mamikon's theorem</b>:
</p>
<dl><dd><i>The area of a tangent sweep is equal to the area of its tangent cluster, regardless of the shape of the original curve.</i></dd></dl>
<h2><span id="Applications">Applications</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=2" title="Edit section: Applications"><span>edit</span></a><span>]</span></span></h2>
<h3><span id="Area_of_a_cycloid">Area of a cycloid</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=3" title="Edit section: Area of a cycloid"><span>edit</span></a><span>]</span></span></h3>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Mamikon_Cycloid.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Mamikon_Cycloid.svg/300px-Mamikon_Cycloid.svg.png" decoding="async" width="300" height="105" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Mamikon_Cycloid.svg/450px-Mamikon_Cycloid.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Mamikon_Cycloid.svg/600px-Mamikon_Cycloid.svg.png 2x" data-file-width="2516" data-file-height="878"></a><figcaption>Finding the area of a <a href="https://en.wikipedia.org/wiki/Cycloid" title="Cycloid">cycloid</a> using Mamikon's theorem.</figcaption></figure>
<p>The area of a <a href="https://en.wikipedia.org/wiki/Cycloid" title="Cycloid">cycloid</a> can be calculated by considering the area between it and an enclosing rectangle. These tangents can all be clustered to form a circle. If the circle generating the cycloid has radius <span><i>r</i></span> then this circle also has radius <span><i>r</i></span> and area <span>œÄ<i>r</i><sup>2</sup></span>. The area of the rectangle is <span>2<i>r</i> √ó 2œÄ<i>r</i> = 4œÄ<i>r</i><sup>2</sup></span>. Therefore the area of the cycloid is <span>3œÄ<i>r</i><sup>2</sup></span>: it is 3 times the area of the generating circle.
</p><p>The tangent cluster can be seen to be a circle because the cycloid is generated by a circle and the tangent to the cycloid will be at right angle to the line from the generating point to the rolling point. Thus the tangent and the line to the contact point form a right-angled triangle in the generating circle. This means that clustered together the tangents will describe the shape of the generating circle.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=4" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Cavalieri%27s_principle" title="Cavalieri's principle">Cavalieri's principle</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hodograph" title="Hodograph">Hodograph</a> ‚Äì This is a related construct that maps the velocity of a point using a polar diagram.</li>
<li><i><a href="https://en.wikipedia.org/wiki/The_Method_of_Mechanical_Theorems" title="The Method of Mechanical Theorems">The Method of Mechanical Theorems</a></i></li>
<li><a href="https://en.wikipedia.org/wiki/Pappus%27s_centroid_theorem" title="Pappus's centroid theorem">Pappus's centroid theorem</a></li>
<li><a href="https://en.wikipedia.org/wiki/Planimeter" title="Planimeter">Planimeter</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=5" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><a rel="nofollow" href="http://www.cco.caltech.edu/~mamikon/calculus.html">Visual Calculus</a> Mamikon Mnatsakanian</span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFHaunspergerKennedy2006">Haunsperger, Deanna; Kennedy, Stephen (2006). <a rel="nofollow" href="https://books.google.com/books?id=I9oVP8TlyqIC&amp;pg=PA70"><i>The Edge of the Universe: Celebrating Ten Years of Math Horizons</i></a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780883855553" title="Special:BookSources/9780883855553"><bdi>9780883855553</bdi></a><span>. Retrieved <span>May 9,</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Edge+of+the+Universe%3A+Celebrating+Ten+Years+of+Math+Horizons&amp;rft.date=2006&amp;rft.isbn=9780883855553&amp;rft.aulast=Haunsperger&amp;rft.aufirst=Deanna&amp;rft.au=Kennedy%2C+Stephen&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DI9oVP8TlyqIC%26pg%3DPA70&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVisual+calculus"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFApostol,_Mnatsakanian2012">Apostol, Mnatsakanian (2012). <a rel="nofollow" href="https://doi.org/10.5948/9781614442103"><i>New Horizons in Geometry</i></a>. Mathematical Association of America. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9781614442103" title="Special:BookSources/9781614442103"><bdi>9781614442103</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=New+Horizons+in+Geometry&amp;rft.pub=Mathematical+Association+of+America&amp;rft.date=2012&amp;rft.isbn=9781614442103&amp;rft.au=Apostol%2C+Mnatsakanian&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.5948%2F9781614442103&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVisual+calculus"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Visual_calculus&amp;action=edit&amp;section=6" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="http://www.its.caltech.edu/~mamikon/">ProjMath Mamikon</a></li>
<li><a rel="nofollow" href="http://mathworld.wolfram.com/ProofwithoutWords.html">Proof without Words</a> from <a href="https://en.wikipedia.org/wiki/MathWorld" title="MathWorld">MathWorld</a></li>
<li><a rel="nofollow" href="https://demonstrations.wolfram.com/MamikonsMethodForTheAreaOfTheCycloid/">Wolfram Interactive Demonstration of Mamikon's theorem</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1427
Cached time: 20240213033504
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‚Äêrevision‚Äêsha1, show‚Äêtoc]
CPU time usage: 0.137 seconds
Real time usage: 0.191 seconds
Preprocessor visited node count: 663/1000000
Post‚Äêexpand include size: 6109/2097152 bytes
Template argument size: 1003/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 1/500
Unstrip recursion depth: 1/20
Unstrip post‚Äêexpand size: 6963/5000000 bytes
Lua time usage: 0.074/10.000 seconds
Lua memory usage: 3115390/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  165.086      1 -total
 51.81%   85.527      1 Template:Reflist
 43.04%   71.060      2 Template:Cite_book
 33.56%   55.397      1 Template:Short_description
 20.41%   33.702      2 Template:Pagetype
  8.85%   14.612      1 Template:Use_mdy_dates
  7.73%   12.756      9 Template:Main_other
  6.13%   10.124      1 Template:SDcat
  5.72%    9.437      1 Template:DMCA
  4.23%    6.986      1 Template:Dated_maintenance_category
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:10458716-0!canonical and timestamp 20240213033504 and revision id 1206785363. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unicomp's "New" Model M Keyboard (128 pts)]]></title>
            <link>https://www.pckeyboard.com/page/product/NEW_M</link>
            <guid>39352472</guid>
            <pubDate>Tue, 13 Feb 2024 00:07:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pckeyboard.com/page/product/NEW_M">https://www.pckeyboard.com/page/product/NEW_M</a>, See on <a href="https://news.ycombinator.com/item?id=39352472">Hacker News</a></p>
Couldn't get https://www.pckeyboard.com/page/product/NEW_M: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[6 months in, journalist-owned tech publication 404 Media is profitable (106 pts)]]></title>
            <link>https://www.niemanlab.org/2024/02/six-months-in-journalist-owned-tech-publication-404-media-is-profitable/</link>
            <guid>39351737</guid>
            <pubDate>Mon, 12 Feb 2024 22:59:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.niemanlab.org/2024/02/six-months-in-journalist-owned-tech-publication-404-media-is-profitable/">https://www.niemanlab.org/2024/02/six-months-in-journalist-owned-tech-publication-404-media-is-profitable/</a>, See on <a href="https://news.ycombinator.com/item?id=39351737">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Feb.  12, 2024, 10:57 a.m.</p><p>‚ÄúOwning our own work, and being beholden to no one but our readers and colleagues ‚Äî as opposed to say, investors, venture capitalists, or out-of-touch executives ‚Äî feels like the future.‚Äù</p><div id="content_div-222281">


<p>Until January, most stories from <a href="https://www.404media.co/">404 Media</a> were available to read for free. But after the four cofounders <a href="https://www.404media.co/why-404-media-needs-your-email-address/">discovered</a> ‚Äî through their own reporting ‚Äî that their stories were being scraped, paraphrased by AI text ‚Äúspinners,‚Äù and published on other websites, they decided to start requiring readers to provide their email addresses to access stories, and they explained why.</p>
<p>‚ÄúWe see how Google is degrading in quality. We see how AI content mills are digesting our stories and gaming the system to get more views than our original reporting they‚Äôre ripping off,‚Äù cofounder <a href="https://twitter.com/emanuelmaiberg">Emanuel Maiberg</a> told me an email. ‚ÄúIt‚Äôs important to us, and we think it‚Äôs important to our readers to know why we‚Äôre doing what we‚Äôre doing, but it‚Äôs also in the public interest to know what Google, AI, content mills, etc. are doing to the general health of the information environment.‚Äù</p>
<p>These are the types of stories, with that level of transparency, that 404 Media was founded to report, cofounder <a href="https://www.linkedin.com/in/jason-koebler-51339114/">Jason Koebler</a> said. It <a href="https://www.nytimes.com/2023/08/22/business/media/404-media-vice-motherboard.html">launched</a> last August as a news outlet covering the impacts of technology on users in ways that are accessible, transparent, and relatable.</p>
<p>‚ÄúOur goal is to find niche communities and see what they care about, what they‚Äôre happy and excited about, and what they‚Äôre really upset about,‚Äù Koebler said. ‚ÄúWe want the communities that we‚Äôre writing about to read these articles and be like, ‚ÄòOkay, they got it right.‚Äô But we don‚Äôt want to be so insular that only those people are interested.‚Äù</p>
<p>404 Media‚Äôs founders and co-owners ‚Äî&nbsp;a staff of four ‚Äî&nbsp;all come from <a href="https://www.vice.com/en/section/tech">Motherboard</a>, Vice‚Äôs tech vertical: Former Motherboard editor-in-chief <a href="https://www.linkedin.com/in/jason-koebler-51339114/">Koebler</a>, former Motherboard executive editor <a href="https://www.linkedin.com/in/emanuel-maiberg-0b777a25/">&nbsp;Maiberg</a>, and former Motherboard staff writers <a href="https://www.linkedin.com/in/samleecole/">Sam Cole</a> and <a href="https://www.linkedin.com/in/joseph-cox-2ba467173/">Joseph Cox</a>. Koebler said they decided to launch 404 Media after years of experiencing the financial ups and downs in the news industry ‚Äî&nbsp;and seeing what independent publications like Defector <a href="https://www.niemanlab.org/2023/11/good-blogs-are-good-for-business-and-other-lessons-from-defectors-third-year/">have been able to accomplish</a>. (Vice <a href="https://www.nytimes.com/2023/05/15/business/media/vice-bankruptcy.html">filed for bankruptcy</a> last May and was <a href="https://www.theguardian.com/media/2023/jun/22/vice-media-acquired-fortress-investment-group">sold to Fortress Investment Group</a> for $350 million in June; Motherboard <a href="https://www.vice.com/en/section/tech">still exists</a>.)</p>
<p>‚ÄúThere are so many things that big digital media companies waste money on, like consultants, software, offices,‚Äù Koebler said. Vice, in his view, ‚Äúwasn‚Äôt able to consistently invest in new hires and in the journalism in a way that felt sustainable. We wanted to start a new company and basically strip it to its essentials.‚Äù</p>
<p>The four cofounders each own 25% of the company, and at launch each put in $1,000 to cover initial costs. Koebler declined to share current revenue numbers, but said the company is profitable (and that everyone‚Äôs been able to pay themselves back the money they initially put in).</p>
<p>‚ÄúIt‚Äôs hard to look around at the environment we‚Äôre working in, which we all love and are in because we love it, and think the status quo is functioning in anything close to a sustainable way,‚Äù Cole said. ‚ÄúOwning our own work, and being beholden to no one but our readers and colleagues ‚Äî as opposed to say, investors, venture capitalists, or out-of-touch executives ‚Äî feels like the future.‚Äù</p>
<p>Recent stories include the New Jersey government <a href="https://www.404media.co/new-jersey-used-covid-relief-funds-to-buy-banned-dahua-chinese-surveillance-cameras/">using COVID-19 relief funding to buy banned surveillance cameras</a>; why advertisers <a href="https://www.404media.co/advertisers-dont-want-sites-like-jezebel-to-exist/">don‚Äôt want publications like Jezebel to exist</a>; and why <a href="https://www.404media.co/wickr-closed-down-is-dead/">Amazon Web Services shut down the Wickr app</a>. 404 Media also has a publishing partnership with <a href="https://www.courtwatch.news/">Court Watch</a>: writer Seamus Hughes shares documents with the team, they write stories up with him or separately, and both publications get to publish the story.</p>
<p>‚ÄúThe most personal thing I‚Äôve written for 404 Media so far has been <a title="https://www.404media.co/egg-freezing-experience-cost-side-effects/" href="https://www.404media.co/egg-freezing-experience-cost-side-effects/">about freezing my eggs</a>,‚Äù Cole said. ‚ÄúSo much of how we move through the world, plan our futures, and access care is influenced by technology, and a lot of it is obvious. But this was such a human, messy, emotional experience for me that it was an interesting experiment to look at it through that lens.‚Äù</p>
<p>404‚Äôs revenue streams are <a href="https://www.404media.co/advertise-with-404-media/">advertising</a>, podcast ads, donations, <a href="https://404media.myshopify.com/">merchandise</a>, and <a href="https://www.404media.co/faq/">paid subscriptions</a>. Paid subscriptions, which start at <a href="https://www.404media.co/">$100 per year</a>, include access to events like <a href="https://www.404media.co/404-medias-first-foia-forum/">FOIA forums</a>, where the staff teaches participants how to file records requests. (More than 40 people attended the first forum.) 404 Media is also in the early stages of turning some of its feature stories into podcasts and documentaries. Koebler said that direct ad sponsorships ‚Äî something he worked on for Motherboard ‚Äî are working, too.</p>
<p>‚ÄúWe went into this being like, ‚ÄòWe‚Äôll have subscribers and we‚Äôll have ads and hopefully that will work.‚Äô And what we‚Äôre finding is that, yes, that is working, but then there‚Äôs also all these other little ways that you can make small amounts of money, like selling merch,‚Äù Koebler said. ‚ÄúWe‚Äôre on Apple News now and in the process of enabling monetization there‚Ä¶I suspect that when we turn it on, we‚Äôll be making $20 to $100 per month, which is very little money but as we grow, all of those things start to add up.‚Äù</p>
<p>The 404 team DIYs as much as possible. They pay for hosting through Ghost and set up litigation insurance, for example, but everyone makes their own art for stories instead of paying for agency photos. (The reporters are also the merch models). Everyone works from home, so they don‚Äôt have an office and don‚Äôt plan on getting one anytime soon. The team communicates through a free Slack channel. Koebler mails out merchandise from his garage in Los Angeles. Every month, the team meets (virtually) to decide how much they can pay themselves. (The number changes each month, but everyone gets paid the same amount.)</p>
<p>The focus is now on growing the audience in ways that feel authentic. ‚ÄúIt‚Äôs imperative that we be on TikTok and Instagram in a way that‚Äôs feels native there,‚Äù Koebler said. ‚ÄúWe sort of launched [on every platform] and then we scaled back slightly in terms of what we‚Äôre focusing on. We will always focus on the reporting and the stories. Getting it out to other places is a priority of ours, but if there‚Äôs not enough time in the day, we‚Äôre not going to work 20-hour days just so we can have, like, a good TikTok.‚Äù</p>
<p>‚ÄúMy first journalism job was at a small-town newspaper, where we didn‚Äôt even have a real digital presence, and I was interacting with sources who were also my neighbors, people I saw at the farmer‚Äôs market or the coffee shop, and they could come to the newsroom and see the newspaper getting printed,‚Äù Cole said. ‚ÄúThat‚Äôs the kind of connection I think we want to have with our readers and subscribers. Come see how it‚Äôs made, and let us meet you where you are.‚Äù</p>
<p>The paywall will continue to evolve as the internet changes and the business grow. Right now, almost every story is free to read when it‚Äôs first published, but 404 Media is starting to put older stories behind the paywall. (FOIA reporting is an exception and ‚Äúwill always be free because it‚Äôs based on public documents that everyone has a right to access,‚Äù Maiberg said. Those stories often include an ask at the top for readers to subscribe or donate.)</p>
<p>One thing that will remain: The mix of in-depth investigations and shorter, voice-y blog posts. ‚ÄúSome viral news stories get a ton of eyeballs and a very low percentage of conversions to paid subscribers, and some deep, long investigations don‚Äôt get many eyeballs at all, but a much higher percentage of people who read those articles convert [to subscribers],‚Äù Maiberg said.</p>
<p>‚ÄúAt Vice, if we wrote a big investigation and not many people read it, that was kind of painful‚Ä¶it felt like shouting into the void,‚Äù he added. ‚ÄúHere, if we publish an investigation that reaches a small audience, but that audience really engages and pays for our work, it feels very good and productive.‚Äù</p>







<p><a href="https://www.niemanlab.org/author/htameez">Hanaa' Tameez</a> is a staff writer at Nieman Lab. You can reach her via <a href="mailto:hanaa@niemanlab.org">email</a> (hanaa@niemanlab.org) or <a href="https://twitter.com/HanaaTameez">Twitter DM</a> (@HanaaTameez).</p>





















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What If I‚Äôm Wrong? (2023) (197 pts)]]></title>
            <link>https://behavioralscientist.org/ive-been-thinking-daniel-dennett-what-if-im-wrong/</link>
            <guid>39351195</guid>
            <pubDate>Mon, 12 Feb 2024 22:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://behavioralscientist.org/ive-been-thinking-daniel-dennett-what-if-im-wrong/">https://behavioralscientist.org/ive-been-thinking-daniel-dennett-what-if-im-wrong/</a>, See on <a href="https://news.ycombinator.com/item?id=39351195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article id="post-41799">
  <!-- .entry-header -->  
  <div>
    
<p>I used to be a much more conscientious scholar than I am now. I would encounter a journal article or book that was relevant to my interests but forbiddingly technical (or, if the author was a philosopher, just forbiddingly badly written, convoluted, and jargon packed), and I would beat my head against it for hours and hours, running down and checking out all the references‚Äî‚Äãa time-‚Äãconsuming library job in the old days before internet links. I made it something of a point of honor to arrive at a state of confident understanding; I kept at it until I <em>owned</em> that argument. Now I give such candidates for my attention a quick skim, remembering that life is short and if this novelty is worth understanding, somebody I trust will soon explain it to me in terms I can readily digest. These days I almost always outsource the hard work of comprehension when I encounter difficulties, and the policy works wonders‚Äî‚Äãfor me.</p>



<div><figure><a href="https://bookshop.org/a/16880/9780393868050" target="_blank" rel="noopener"><img loading="lazy" width="200" height="300" src="https://behavioralscientist.org/wp-content/uploads/2023/10/ibt-200x300.png" alt="" srcset="https://behavioralscientist.org/wp-content/uploads/2023/10/ibt-200x300.png 200w, https://behavioralscientist.org/wp-content/uploads/2023/10/ibt-684x1024.png 684w, https://behavioralscientist.org/wp-content/uploads/2023/10/ibt-768x1151.png 768w, https://behavioralscientist.org/wp-content/uploads/2023/10/ibt.png 801w" sizes="(max-width: 200px) 100vw, 200px"></a></figure></div>



<p>Distributed understanding is a real phenomenon, but you have to get yourself into a community of communicators that can effectively summon the relevant expertise. I don‚Äôt know if other philosophers have the same policy; many of them seem to me to spend their whole careers working largely alone and grappling with a few narrow issues, voluntarily giving themselves tunnel vision. Perhaps, I think, they cannot do otherwise, given their training. After all, many scientists are in similar trenches. I once asked a promising young neuroscientist, after I‚Äôd spent hours watching him run experiments on monkeys with chronically implanted electrodes, what he thought the implications of his research might be, and his answer was ‚ÄúOh Dan, I don‚Äôt have time to think!‚Äù</p>



<p>All my early due diligence was probably good for me. It got me to confront the difficulty of the questions, seeing with my own eyes the pitfalls that trap many very smart and conscientious thinkers. This injected a small dose of modesty into my growing confidence that I had found‚Äî‚Äãand partly invented‚Äî‚Äãa prodigious explanation-‚Äãdevice that reliably devoured difficulties, day after day. The insights (if that is what they were) that I had struggled so hard to capture in my dissertation and my first book have matured and multiplied, generating answers to questions, solutions to problems, rebuttals to objections, and‚Äî‚Äãmost important‚Äî‚Äãsuggestions for further questions to ask with gratifying consilience. I just turn the crank and out they pour, falling into place like the last pieces in a jigsaw puzzle. Perhaps my whole perspective is a colossal mistake‚Äî‚Äãsome of my critics think so‚Äî‚Äãand perhaps its abundant fruits are chimeras.</p>



<p><em>What if I‚Äôm wrong?</em> Good thinkers frequently ask themselves this question, the way good doctors frequently check their practices against the Hippocratic oath they swore, and not just as a formulaic ritual.</p>



<blockquote><p><strong><em>What if I‚Äôm wrong?</em> Good thinkers frequently ask themselves this question, the way good doctors frequently check their practices against the Hippocratic oath they swore.</strong></p></blockquote>



<p>My favorite chapter of Mark Twain‚Äôs <em>Adventures of Tom Sawyer</em> tells of Tom‚Äôs brilliant stunt of getting his friends to pay him for the privilege of whitewashing the fence in front of his house, not just saving him a chore but enriching him. This inspired me to adopt the same strategy with my books: I invite Tufts students to help me write my books by sharing the penultimate draft with them in a seminar, where they are all encouraged to point out errors, challenge arguments, demand more clarity, and in general complain about anything that strikes them as amiss. They don‚Äôt get paid for this excellent editorial service‚Äî‚Äãin fact they are paying one of the highest rates of tuition in the country‚Äî‚Äãbut they do get thanked in the preface by name, and they get an autographed copy of the book when it‚Äôs published. I believe everyone involved has been quite content with this arrangement.</p>



<p>I particularly cherish the intrepid naysayers who force me to expand, revise, or drop what I had thought were good points. Students often come to my office to discuss their term-‚Äãpaper projects in my courses, and a familiar combination of ambition and anxiety is the enthusiastic student who has a Big Idea‚Äî‚Äãa Refutation of some well-‚Äãregarded claim of mine or of some other writer we have read. They‚Äôre itching to go for it, but <em>‚ÄúWhat if I‚Äôm wrong?‚Äù</em> I have some not-‚Äãquite-‚Äãfoolproof advice: take courage and set out to write up the Great Discovery; if after many hours of red-‚Äãhot thinking and writing you discover to your dismay a fatal flaw, something that you overlooked or underestimated, all is not lost. Go back to the first paragraph and write something along the lines of ‚ÄúIt is tempting to think that‚ÄØ.‚ÄØ.‚ÄØ.‚ÄØ, because there seems to be a powerful argument to the effect that‚ÄØ.‚ÄØ.‚ÄØ.‚ÄØ, but as we shall see, this is an error.‚Äù Then make a few minor adjustments to the rest of the paper, pointing carefully to the error that you almost made, and you‚Äôre ready to submit it. If your Big Idea was tempting to you, it might well be tempting to others. Showing the field that this is a cul-‚Äãde-‚Äãsac to be avoided is a genuine contribution. The same strategy, writ large, is good advice for a whole career. Try your Big Hunch out on a few knowledgeable people; if nobody can knock it down right away, then take a leap, make a major investment of your time (bearing in mind the large cost of lost opportunities if you make a bad choice) and hope for the best. You may at least be able to salvage a definitive refutation of your hunch, all the more credible for having been composed by somebody who was initially a partisan.</p>



<blockquote><p><strong>Take courage and set out to write up the Great Discovery; if after many hours of red-‚Äãhot thinking and writing you discover to your dismay a fatal flaw <strong>.‚ÄØ.‚ÄØ.‚ÄØ</strong> all is not lost. Go back to the first paragraph and write something along the lines of ‚ÄúIt is tempting to think that ‚ÄØ.‚ÄØ.‚ÄØ.‚ÄØ‚Äù</strong></p></blockquote>



<p>The Discovery Institute is the well-‚Äãfunded propaganda site for Intelligent Design, as creationism is now called. I have often scoffed publicly at the dismal ratio of propaganda to peer-‚Äãreviewed science in its output and urged its directors to put their money into some real science that might, conceivably, prove them right. So when they announced in 2005 that they were setting up a serious research facility, the Biologic Institute, to do experiments aiming to refute the theory of evolution by natural selection, they asked me to express my opinion of this innovation. I wrote back that I applauded this move, since there are scads of unasked questions in evolutionary biology that are neglected by biologists simply because they‚Äôre sure they already know the answer: How did species X with feature Y come to be? It evolved, of course, but we don‚Äôt know the details. Nobody wants to sic a graduate student or postdoc on any of those questions, because the reaction among the influential workers in the field to the results would be along the lines of ‚ÄúHo hum, what else is new?‚Äù‚Äînot a good way to start a career. If, however, the Biologic Institute wants to fund young scientists who are passionately committed to disproving evolution, this will harness their energy and training without our having any scruples about encouraging them to waste their precious time. They will see themselves as crusaders on a divine mission, and what could be more glorious than that? They will try to find hidden among these unasked questions embarrassing examples of ‚Äúirreducible complexity‚Äù that couldn‚Äôt have evolved gradually. They will eventually discover that they‚Äôre wrong, and we will have yet further examples of evolution‚Äôs devious paths. In my terminology, their dogged search for skyhooks will uncover heretofore unimagined cranes. And precisely because their conclusions will be the opposite of what they hoped to discover, we will take them seriously. Good theories thrive on serious attempts to refute them that fail in instructive ways.</p>



<p>What, though, if <em>my</em> supposed insights are just generated by a prodigiously fertile mistake? It‚Äôs worth remembering that this has happened before, on a cosmic scale. Descartes wrote his retrospectively preposterous books‚Äî‚Äã<em>Le Monde</em> (eventually published in full in 1667) and <em>Principia Philosophiae</em> (1644)‚Äîpresenting the first detailed TOE (theory of everything). He had deduced (he claimed) the truth about everything under the sun and beyond the sun, including starlight and planets, tides, volcanoes, magnets, and much, much more, most of it dead wrong. It was Newton‚Äôs majestic <em>Principia</em> (1687) that decisively refuted Descartes. Descartes‚Äôs theory of everything is, even in hindsight, remarkably coherent and persuasive. It is hard to imagine a <em>different</em> equally coherent and equally false theory! He was wrong, and so of course I may well be wrong, but enough other thinkers I respect have come to see things my way that when I ask myself, ‚ÄúWhat if <em>we</em> are wrong?‚Äù I can keep this skeptical murmur safely simmering on a back burner.</p>



<hr>



<p><em>Adapted from </em><a href="https://bookshop.org/a/16880/9780393868050" target="_blank" rel="noreferrer noopener">I‚Äôve Been Thinking</a><em>. Copyright (c) 2023 by Daniel C. Dennett. Used with permission of the publisher, W. W. Norton &amp; Company, Inc. All rights reserved.</em></p>



<hr>



<p><em>‚ÄãWhen you buy a book using a link on this page, we receive a commission. Thank you for supporting&nbsp;</em>Behavioral Scientist‚Äôs <em>nonprofit mission</em>.</p>
  </div><!-- .entry-content -->
</article><!-- #post-## -->

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Security flaws in an SSO plugin for Caddy (2023) (115 pts)]]></title>
            <link>https://blog.trailofbits.com/2023/09/18/security-flaws-in-an-sso-plugin-for-caddy/</link>
            <guid>39351026</guid>
            <pubDate>Mon, 12 Feb 2024 21:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trailofbits.com/2023/09/18/security-flaws-in-an-sso-plugin-for-caddy/">https://blog.trailofbits.com/2023/09/18/security-flaws-in-an-sso-plugin-for-caddy/</a>, See on <a href="https://news.ycombinator.com/item?id=39351026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

			
				
<article id="post-105094">
	<!-- .entry-header -->

	<div>
		<p><em>By Maciej Domanski, Travis Peters, and David Pokora</em></p>
<p>We identified 10 security vulnerabilities within the <a href="https://github.com/greenpau/caddy-security" target="_blank" rel="noopener">caddy-security plugin</a> for the <a href="https://github.com/caddyserver/caddy" target="_blank" rel="noopener">Caddy</a> web server that could enable a variety of high-severity attacks in web applications, including client-side code execution, OAuth replay attacks, and unauthorized access to resources.</p>
<p>During our evaluation, Caddy was deployed as a reverse proxy to provide access to several of our internal services. We explored a plugin configuration that would allow us to handle authentication and authorization with our Google SSO so that we didn‚Äôt have to implement this on a per-app basis.</p>
<p>In this blog post, we will briefly explore the security vulnerabilities we identified in the caddy-security plugin and discuss their potential impact. As with our typical security assessments, for each issue we identified, we present a recommendation for immediately fixing the issue, as well as long-term, more strategic advice for preventing similar issues and improving the overall security posture.</p>
<p>As security experts, our goal is not only to identify vulnerabilities in specific software but also to contribute to the larger community by sharing our recommendations for fixing these problems. We believe that these recommendations can help developers overcome similar challenges in other SSO systems and improve their security.</p>
<h2>Caddy Background</h2>
<p><a href="https://caddyserver.com/" target="_blank" rel="noopener">Caddy</a> (a.k.a. Caddy Server or Caddy 2) is a modern, open-source web server written in Golang that is designed to be easy to use and highly configurable. Caddy is built to streamline the process of hosting web applications while prioritizing security and performance. It aims to reduce the complexity associated with configuring and deploying web servers.</p>
<p>The caddy-security plugin is a middleware plugin for the Caddy web server. It provides various security-related functionalities to enhance the overall security posture of web applications. Some of the key features offered by the caddy-security plugin include an authentication plugin for implementing Form-Based, Basic, Local, LDAP, OpenID Connect, OAuth 2.0, SAML Authentication, and an authorization plugin for HTTP request authorization based on JWT/PASETO tokens.</p>
<h2>Findings</h2>
<h3>Issue #1: Reflected Cross-Site Scripting (XSS)</h3>
<p><em>Severity: High</em></p>
<p>Reflected XSS occurs when an application includes untrusted data in the HTML response sent to the user‚Äôs browser. In this case, the provided <code>/admin%22%3E%3Cscript%3Ealert(document.domain)%3C/script%3E/admin/login</code> or <code>/settings/mfa/delete/&lt;img%20src=x%20onerror=alert(document.domain)&gt;</code> API calls trigger an alert. An attacker can exploit this vulnerability to execute arbitrary JavaScript code within the target user‚Äôs browser, potentially leading to further attacks such as session hijacking.</p>
<p>To immediately address this issue, strategically treat all string values as potentially untrustworthy, regardless of their source, and escape them properly (using the <code>safehtml/template</code> package that generates output-safe HTML).</p>
<p>In addition to that remediation, we also suggest a few different ways to improve defense in depth:</p>
<ul>
<li>Extend unit tests with potentially malicious XSS payloads. Refer to the <a href="https://portswigger.net/web-security/cross-site-scripting/cheat-sheet" target="_blank" rel="noopener">Cross-site scripting (XSS) cheat sheet</a> for various attack vectors.</li>
<li>Consider using the Active Scanner from Burp Suite Professional in a testing environment for all API calls. Additionally, use the <a href="https://portswigger.net/burp/documentation/desktop/automated-scanning/live-tasks" target="_blank" rel="noopener">scanning with a live task</a> strategy to have underlying requests scanned automatically when interacting with the web interface.</li>
<li>Expand the caddy-security documentation to promote security headers‚Äîespecially the Content Security Policy (CSP) header that controls which resources can be loaded by the browser, limiting the impact of potential XSS attacks.</li>
</ul>
<h3>Issue #2: Insecure Randomness</h3>
<p><em>Severity: High</em></p>
<p>The caddy-security plugin uses the <code>math/rand</code> Golang library with a seed based on the Unix timestamp to generate strings for three security-critical contexts in the application, which could possibly be predicted via a brute-force search. Attackers could use the potentially predictable nonce value used for authentication purposes in the OAuth flow to conduct OAuth replay attacks. In addition, insecure randomness is used while generating multifactor authentication (MFA) secrets and creating API keys in the database package.</p>
<p>To immediately mitigate this vulnerability, use a cryptographically secure random number generator for generating the random strings. Golang‚Äôs library <code>crypto/rand</code> is designed for secure random number generation.</p>
<p>In addition to that fix, we recommend considering the following long-term recommendations:</p>
<ul>
<li>Review the application for other instances where the <code>math/rand</code> package is used for secure context. Create secure wrapping functions and use them throughout the code to serve a cryptographically secure string with the requested length.</li>
<li>Avoid duplicating code. Having a single function, such as <code>secureRandomString</code>, rather than multiple duplicate functions makes it easier to audit and verify the system‚Äôs security. It also prevents future changes to the codebase from reintroducing issues.</li>
<li>Implement Semgrep in the CI/CD. The <code>math-random-used</code> Semgrep rule will catch instances where <code>math/rand</code> is used. Refer to our <a href="https://appsec.guide/docs/static-analysis/semgrep/" target="_blank" rel="noopener">Testing Handbook on Semgrep</a> for more information.</li>
<li>Read textbooks such as <em>Real World Cryptography</em>, as it is a great resource for practical cryptographic considerations.</li>
</ul>
<h3>Issue #3: IP Spoofing via X-Forwarded-For Header</h3>
<p><em>Severity: Medium</em></p>
<p>By manipulating the <code>X-Forwarded-For</code> header, an attacker can spoof an IP address used in the user <code>identity</code> module (<code>/whoami</code> API endpoint). This could lead to unauthorized access if the system trusts this spoofed IP address.</p>
<p>To resolve this vulnerability, reimplement the application to not rely on user-provided headers when obtaining a user‚Äôs IP address. If user-provided headers are required (e.g., <code>X-Forwarded-For</code> for logging purposes), ensure the header is properly validated (i.e., the value is consistent with IP address format through regular expression) or sanitized (to avoid <a href="https://owasp.org/www-community/vulnerabilities/CRLF_Injection" target="_blank" rel="noopener">CRLF log injection attacks</a>, for example).</p>
<p>In addition to this immediate fix, we recommend considering these long-term recommendations:</p>
<ul>
<li>Implement appropriate checks for potential IP spoofing and <code>X-</code> headers on the unit testing level. Consider <a href="https://book.hacktricks.xyz/network-services-pentesting/pentesting-web/special-http-headers#headers-to-change-location" target="_blank" rel="noopener">other headers that can rewrite IP sources</a>.</li>
<li>Cover the IP spoofing scenarios and user-provided header processing in Golang‚Äôs native fuzz tests.</li>
<li>Use the dynamic testing approach with Burp Suite Professional and the <a href="https://portswigger.net/bappstore/17d2949a985c4b7ca092728dba871943" target="_blank" rel="noopener">Param Miner</a> extension to identify the processing of hidden headers.</li>
<li>Expand the caddy-security documentation to increase user awareness of this type of threat; show an example of misconfiguration, how to resolve, and how to test it.</li>
</ul>
<h3>Issue #4: Referer-Based Header XSS</h3>
<p><em>Severity: Medium</em></p>
<p>An XSS vulnerability can be triggered by rewriting the <code>Referer</code> header. Although the <code>Referer</code> header is sanitized by escaping some characters that can allow XSS (e.g., [<code>&amp;</code>], [<code>&lt;</code>], [<code>&gt;</code>], [<code>"</code>], [<code>'</code>]), it does not account for the attack based on the JavaScript URL scheme (e.g., <code>javascript:alert(document.domain)//</code> payload). Exploiting this vulnerability may not be trivial, but it could lead to the execution of malicious scripts in the context of the target user‚Äôs browser, compromising user sessions.</p>
<p>The mitigation for this issue is identical to issue #1.</p>
<h3>Issue #5: Open Redirection Vulnerability</h3>
<p><em>Severity: Medium</em></p>
<p>When a logged-in user clicks on a specially crafted link with a <code>redirect_url</code> parameter, the user can be redirected to an external website. The user must take an action, such as clicking on a portal button or using the browser‚Äôs back button, to trigger the redirection. This could lead to phishing attacks, where an attacker tricks users into visiting a malicious website by crafting a convincing URL.</p>
<p>To mitigate this vulnerability, perform proper <code>redirect_url</code> parameter validation to ensure that the redirection URLs are allowed only within the same domain or from trusted sources.</p>
<p>In addition, we also recommend the following long-term fixes:</p>
<ul>
<li>Implement robust unit tests with different bypassing scenarios of <code>redirect_url</code> parameter validation. Refer to the potential <a href="https://book.hacktricks.xyz/pentesting-web/ssrf-server-side-request-forgery/url-format-bypass" target="_blank" rel="noopener">URL Format Bypasses</a>. Keep in mind that different components can use different URI parsers, which can lead to <a href="https://snyk.io/blog/url-confusion-vulnerabilities/" target="_blank" rel="noopener">parsing confusion</a>.</li>
<li>Use Burp Suite Professional with a scanner with both these settings enabled:
<ul>
<li>Audit coverage ‚Äì maximum: to use the most extensive set of payload variations and insertion point options</li>
<li>Audit coverage ‚Äì thorough: to try more payload variations</li>
</ul>
</li>
</ul>
<h3>Issue #6: X-Forwarded-Host Header Manipulation</h3>
<p><em>Severity: Medium</em></p>
<p>The caddy-security plugin processes the <code>X-Forwarded-Host</code> header, which could lead to various security vulnerabilities (web cache poisoning, business logic flaws, routing-based server-side request forgery [SSRF], and classic server-side vulnerabilities). Additionally, the caddy-security plugin generates QR codes based on this header, which extends the attack surface.</p>
<p>To mitigate this issue, do not rely on the <code>Host</code> and <code>X-Forwarded-Host</code> headers in the caddy-security plugin logic. Instead, use the current domain manually specified in the configuration file to generate a QR code.</p>
<p>In addition, we recommend the following:</p>
<ul>
<li>Use Burp Suite Professional with the Param Miner extension to identify the processing of hidden headers.</li>
<li>Extend the caddy-security documentation to increase user awareness of the <a href="https://portswigger.net/web-security/host-header/exploiting" target="_blank" rel="noopener">HTTP <code>Host</code> header attacks</a>.</li>
</ul>
<h3>Issue #7: X-Forwarded-Proto Header Manipulation</h3>
<p><em>Severity: Low</em></p>
<p>The processing of the <code>X-Forwarded-Proto</code> header results in redirection to the injected protocol. While this scenario may have limited impact, improper handling of such headers could result in unpredictable security risks, such as bypass of security mechanisms or confusion in handling TLS.</p>
<p>To address this issue, do not rely on the <code>X-Forwarded-Proto</code> header. If it is required, validate the value of the <code>X-Forwarded-Proto</code> header against an allowlist of accepted protocols (e.g., HTTP/HTTPS) and reject unexpected values.</p>
<p>In addition, consider the long-term recommendations from issue #3.</p>
<h3>Issue #8: 2FA Bypass by Brute-Forcing Verification Codes</h3>
<p><em>Severity: Low</em></p>
<p>The current implementation of the application‚Äôs two-factor authentication (2FA) lacks sufficient protection against brute-force attacks. Although the application blocks the user after several failed attempts to provide 2FA codes, attackers can bypass this blocking mechanism by automating the application‚Äôs full multistep 2FA process.</p>
<p>To address this issue effectively, enforce a minimum six-digit code length in the MFA configuration. Additionally, to reduce the risk of automated brute-forcing, implement an account locking mechanism that triggers after a specified number of invalid 2FA code attempts. Finally, enforce reauthentication for critical actions involving sensitive account information or security settings. For actions such as changing passwords or disabling 2FA, users should be required to reauthenticate, either with their password or a 2FA token. An exception can be made for reauthentication if the user has logged in within the last 10 minutes. Check out <a href="https://blog.trailofbits.com/2019/06/20/getting-2fa-right-in-2019/" target="_blank" rel="noopener">Getting 2FA Right in 2019</a> at the Trail of Bits Blog for more information.</p>
<h3>Issue #9: Lack of User Session Invalidation on Logout</h3>
<p><em>Severity: Low</em></p>
<p>The caddy-security plugin lacks proper user session invalidation upon clicking the ‚ÄúSign Out‚Äù button; user sessions remain valid even after requests are sent to <code>/logout</code> and <code>/oauth2/google/logout</code>. Attackers who gain access to an active but supposedly logged-out session can perform unauthorized actions on behalf of the user.</p>
<p>To address this issue, review the sign-out process to identify the cause of the unexpected behavior. Ensure that the <code>/oauth2/google/logout</code> endpoint correctly terminates the user session and invalidates the associated tokens.</p>
<p>For more defense in depth, use the <a href="https://github.com/OWASP/ASVS/blob/master/4.0/en/0x12-V3-Session-management.md#v3-session-management" target="_blank" rel="noopener">OWASP Application Security Verification Standard (V3 Session Management)</a> to check whether the implementation handles sessions securely.</p>
<h3>Issue #10: Multiple Panics when Parsing Caddyfile</h3>
<p><em>Severity: Low</em></p>
<p>Multiple parsing functions do not validate whether their input values are <code>nil</code> before attempting to access elements, which can lead to a panic (<code>index</code> <code>out</code> <code>of</code> <code>range</code>). Panics during the parsing of a Caddyfile may not be perceived as immediate vulnerabilities, but they could indicate improperly enforced security controls (e.g., insufficient data validation), which could lead to issues in other code paths.</p>
<p>To address these issues, integrate <code>nil</code> checks for input values before element access across all relevant functions.</p>
<p>To prevent similar issues of this type, add Golang‚Äôs native fuzz tests for Caddyfile parsing functions.</p>
<h2>Golang Security for the Community</h2>
<p>We <em>love</em> writing and reviewing Golang codebases at Trail of Bits. Indeed, we are constantly working on Golang-related <a href="https://appsec.guide/docs/static-analysis/semgrep/" target="_blank" rel="noopener">(Semgrep) resources</a>, <a href="https://github.com/trailofbits/semgrep-rules/tree/main/go" target="_blank" rel="noopener">rules</a>, and <a href="https://blog.trailofbits.com/?s=go&amp;submit=Search" target="_blank" rel="noopener">blog posts</a> and look forward to any opportunity to take on pet audits (like this) and <a href="https://github.com/trailofbits/publications#security-reviews">client projects</a> where we examine Golang codebases.</p>
<p>Our aim in publishing our findings is to help protect others who may consider implementing a solution similar to the one we explored and to help them make informed decisions about their security infrastructure.</p>
<p>If you‚Äôre actively implementing a codebase in Golang or have questions, concerns, or other recommendations on open-source software you think we should look at, please <a href="https://www.trailofbits.com/contact/" target="_blank" rel="noopener">contact us</a>.</p>
<h2>Coordinated Disclosure Timeline</h2>
<p>As part of the disclosure process, we reported the vulnerabilities to the caddy-security plugin maintainers first. The timeline of disclosure is provided below:</p>
<ul>
<li>
<ul>
<li>August 7, 2023: We reported our findings to the caddy-security plugin maintainers.</li>
<li>August 23, 2023: The caddy-security plugin maintainers confirmed that there were no near-term plans to act on the reported vulnerabilities.</li>
<li>September 18, 2023: The disclosure blog post was released and issues were filed with the original project repository.</li>
</ul>
</li>
</ul>

			</div><!-- .entry-content -->

	
</article><!-- #post-105094 -->
						<!-- #nav-below -->
		
					<!-- #comments .comments-area -->

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prime Video cuts Dolby Vision, Atmos support from ad tier‚Äìand didn't tell subs (203 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/02/prime-video-cuts-dolby-vision-atmos-support-from-ad-tier-and-didnt-tell-subs/</link>
            <guid>39351023</guid>
            <pubDate>Mon, 12 Feb 2024 21:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/02/prime-video-cuts-dolby-vision-atmos-support-from-ad-tier-and-didnt-tell-subs/">https://arstechnica.com/gadgets/2024/02/prime-video-cuts-dolby-vision-atmos-support-from-ad-tier-and-didnt-tell-subs/</a>, See on <a href="https://news.ycombinator.com/item?id=39351023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Surprise    ‚Äî
</h4>
            
            <h2 itemprop="description">To get them back, you must pay an extra $2.99/month for the ad-free tier.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/LOTR.jpg" alt="High King Gil-galad and Elrond in The Lord of the Rings: The Rings of Power">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/LOTR.jpg" data-height="293" data-width="700">Enlarge</a> <span>/</span> The Rings of Power... now in HDR10+ for ad-tier users.</p></figcaption>  </figure>

  




<!-- cache hit 328:single/related:5fecf133d6d425efec99678933dff73b --><!-- empty -->
<p>On January 29, Amazon started showing <a href="https://arstechnica.com/gadgets/2023/09/amazon-jacks-up-price-of-ad-free-prime-video-by-2-99-starting-in-2024/">ads to Prime Video subscribers</a> in the US unless they pay an additional $2.99 per month. But this wasn't the only change to the service. Those who don't pay up also lose features; their accounts no longer support Dolby Vision or Dolby Atmos.</p>
<p>As noticed by German tech outlet <a href="https://www.4kfilme.de/amazon-prime-video-entfernt-dolby-atmos-und-dolby-vision-im-werbefinanzierten-abo/">4K Filme</a> on Sunday, Prime Video users who choose to sit through ads can no longer use Dolby Vision or Atmos while streaming. Ad-tier subscribers are limited to HDR10+ and Dolby Digital 5.1.</p>
<p>4K Filme confirmed that this was the case on TVs from both LG and Sony; <a href="https://www.forbes.com/sites/johnarcher/2024/02/11/amazon-prime-videos-new-ads-based-subscription-has-a-surprise/?sh=b2396657cd51">Forbes</a> also confirmed the news using a <a href="https://imageio.forbes.com/specials-images/imageserve/65c8ed7ffc888dc89a418c08/AmazonStoryJackRyanPics/960x0.jpg?format=jpg&amp;width=1440">TCL TV</a>.</p>
<p>"In the ads-free account, the TV throws up its own confirmation boxes to say that the show is playing in Dolby Vision HDR and Dolby Atmos. In the basic, with-ads account, however, the TV‚Äôs Dolby Vision and Dolby Atmos pop-up boxes remain stubbornly absent," Forbes said.</p>
<p>Amazon hasn't explained its reasoning for the feature removal, but it may be trying to cut back on licensing fees paid to Dolby Laboratories. Amazon may also hope to push HDR10+, a Dolby Vision competitor that's free and open. It also remains possible that we could one day see the return of Dolby Vision and Dolby Atmos to the ad tier through a refreshed licensing agreement.</p>
<p>Amazon has had a back-and-forth history with supporting Dolby features. In 2016, it first made Dolby Vision available on Prime Video. In 2017, though, Prime Video stopped supporting the format in favor of HDR10+. Amazon announced the HDR10+ format alongside Samsung, and it subsequently made the entire Prime Video library available in HDR10+. But in 2022, Prime Video started offering content like <em><a href="https://arstechnica.com/tech-policy/2023/08/amazon-tries-to-take-over-pirate-sites-that-sold-dvd-copies-of-rings-of-power/">The Lord of the Rings: The Rings of Power</a></em> in Dolby Vision once again.</p>                                            
                                                        
<h2>Amazon wasn‚Äôt upfront about removals</h2>
<p>Amazon announced in September 2023 that it would run ads on Prime Video accounts in 2024; in December, Amazon confirmed that the ads would start <a href="https://arstechnica.com/culture/2023/12/youll-be-paying-extra-for-ad-free-prime-video-come-january/">running on January 29</a> unless subscribers paid extra. In the interim, Amazon failed to mention that it was also removing support for Dolby Vision and Atmos from the ad-supported tier.</p>
<p>Forbes first reported on Prime Video's ad-based tier not supporting Dolby Vision and Atmos by assuming that it was a technical error. Not until after Forbes published its article did Amazon officially confirm the changes. That's not how people subscribing to a tech giant's service expect to learn about a diminishing of their current plan.</p>
<p>It also seems that Amazon's removal of the Dolby features has been done in such a way that it could lead some users to think they're getting Dolby Vision and Atmos support even when they're not.</p>
<p>As Forbes' John Archer reported, "To add a bit of confusion to the mix, on the TCL TV I used, the Prime Video header information for the<em> Jack Ryan</em> show that appears on the with-ads basic account shows Dolby Vision and Dolby Atmos among the supported technical features‚Äîyet when you start to play the episode, neither feature is delivered to the TV."</p>
<p>As <a href="https://arstechnica.com/culture/2024/02/new-streaming-app-from-fox-disney-wbd-is-about-more-than-sports/">streaming services</a> overtake traditional media, many customers are growing increasingly discouraged by how the industry seems to be evolving into something strongly reminiscent of cable. While there are some aspects of old-school TV <a href="https://www.theverge.com/24070601/super-bowl-streaming-delay-spoilers">worth emulating</a>, others‚Äîlike confusing plans that don‚Äôt make it clear what you get with each package‚Äîare not.</p>
<p>Amazon didn't respond to questions Ars Technica sent in time for publication, but we'll update this story if we hear back.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Time Series Forecasting vs Regression: An informal guide (162 pts)]]></title>
            <link>https://www.amorphousdata.com/blog/time-series-vs-regression</link>
            <guid>39350866</guid>
            <pubDate>Mon, 12 Feb 2024 21:37:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amorphousdata.com/blog/time-series-vs-regression">https://www.amorphousdata.com/blog/time-series-vs-regression</a>, See on <a href="https://news.ycombinator.com/item?id=39350866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The application of historical data for predicting future outcomes is pivotal across various domains, encompassing revenue projections, weather forecasts, stock market trends, sports predictions, and beyond. This dependence on predictive analytics relies on extracting valuable insights from historical data, addressing diverse forecasting challenges.</p>
<p>To predict future outcomes, a predictive model is built from historical data.  Over the past few years, I‚Äôve built dozens of predictive models using a range of techniques, from simple to complex, and from spreadsheets to machine learning. In this post, I‚Äôll discuss the general strategies employed to build predictive models. (If you‚Äôre a data scientist, you might scoff at how I‚Äôm defining things because you‚Äôve read <a href="https://otexts.com/fpp3/">Forecasting: Principles and Practice</a> backwards and forwards. That‚Äôs OK. The book is great!)</p>
<h2 id="time-series-forecasting">Time series forecasting</h2>
<p>Time series data is data that is collected or recorded sequentially over time. Each data point in a time series dataset is associated with a timestamp. Time series forecasting is a crucial analytical approach applied to such data, aiming to predict future values or trends based on the historical patterns observed. By leveraging the temporal order of the data, time series forecasting methods can capture and analyze trends, seasonality, and other recurring patterns to make informed predictions about future developments.</p>
<p>Imagine we are forecasting electricity ‚ö° demand for a town using a Simple Moving Average (SMA). We observe the electricity usage for the past 30 days, and each day, we calculate the average demand over that period. For instance, on day one, we take the average of the demand over the last 30 days. The next day, we recalculate the average by incorporating the newest day‚Äôs data and excluding the oldest. This dynamic approach allows us to consider recent trends and fluctuations in electricity demand. If, over the past 30 days, the demand has fluctuated between 3.4 MwH/day and 3.6 MwH/day, our SMA forecast for the next day would be a more adaptive estimate, considering the evolving pattern of demand over time.</p>
<p>Most people have likely used SMA to do time series forecasting, without necessarily using the term SMA. The benefit of SMA is that it creates a simple and intuitive predictive model, making it accessible for quick estimations and general trend observations. However, the tradeoffs of SMA are notable. SMA tends to smooth out extreme fluctuations, making it less responsive to sudden changes or outliers in the data. Additionally, it may lag behind abrupt shifts in the underlying pattern of the time series.</p>
<p>To address these problems, most forecasters end up using a more sophisticated strategy. Exponential Moving Average (EMA), which assigns different weights to recent data points, giving more importance to the most recent observations. This makes EMA more responsive to changes compared to SMA. Autoregressive integrated moving average (<a href="https://otexts.com/fpp3/arima.html">ARIMA</a>) is another popular strategy that works particularly well on time series data that has seasonality trends.</p>
<h2 id="regression-analysis">Regression analysis</h2>
<p>Regression analysis also relies on historical data, but it differs in its approach and objectives. In this method, the emphasis is on establishing a mathematical relationship between the input variables and the corresponding output variable. Unlike time series forecasting, where the primary goal is to predict future values based on temporal patterns, supervised regression aims to understand and quantify the relationships between variables. Through the training of a regression model on historical data, the algorithm learns to generalize and predict outcomes for new, unseen data points.</p>
<p>Again, using the electrical ‚ö° demand forecasting scenario, instead of using SMA to predict the demand, we could use regression analysis to look at independent variables such as the daily temperature and day of the week. We could then build a predictive model where the historical electrical demand serves as the dependent variable, and daily temperature and day of the week act as predictors. This approach allows us to capture not only the historical patterns but also the influence of external factors on electricity consumption. For instance, the model might reveal that higher temperatures are associated with increased demand for cooling systems, or that certain days of the week exhibit distinct usage patterns. By considering these variables, regression analysis provides a more nuanced and context-specific prediction, enhancing the accuracy and interpretability of our forecasting model for electrical demand.</p>
<p>Regression analysis is not a free lunch, however. In addition to greater complexity, regression analysis is heavily dependent on the selected independent variables and how each of these variables is encoded. This process is typically called ‚Äúfeature engineering‚Äù, and is part art and part science. Choices on including or excluding certain variables, and how they are translated into numerical parameters, can significantly impact the model‚Äôs performance.</p>
<h2 id="time-series-forecasting-with-covariates">Time series forecasting with covariates</h2>
<p>Time series forecasting with covariates combines elements of regression analysis with time series forecasting. In this approach, the traditional time series models is enhanced by incorporating additional independent variables, known as covariates or exogenous variables. These covariates may include external factors such as economic indicators, environmental conditions, or other relevant variables that influence the time series behavior. By integrating these covariates into the forecasting model, practitioners can capture more nuanced relationships and improve the accuracy of predictions, especially in situations where external factors play a significant role in shaping the time series patterns.</p>
<p>Using the electrical ‚ö° demand forecasting scenario, we first compute the historical SMA (e.g., a 30 day moving average) over the course of a year. We then examine the correlation between the SMA values and temperature, and calculate an adjustment factor to the SMA values based on temperature. Our final predictive model then takes historical consumption data, computes the 30 day moving average, and applies an adjustment factor to the SMA based on forecasted temperature.</p>
<p>While adding covariates to a time series forecast can improve accuracy, the feature engineering required for a successful model is even more complex and requires additional experimentation. Each independent variable needs to be mapped to the same time series. For example, temperature varies over the course of the day, so should we use the temperature at noon? The average temperature for a day? In addition, the dynamic nature of data demands continuous updates and adjustments to the predictive model to account for changing patterns and relationships.</p>
<h2 id="other-strategies-for-predictive-models">Other strategies for predictive models</h2>
<p>There are other techniques for building predictive models from historical data. These include <a href="https://facebook.github.io/prophet/">Facebook Prophet</a> and various forms of deep learning models (e.g., <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTMs</a>, a type of neural network, are a popular architecture for time series forecasting). In general, these strategies, while exciting, require significant engineering to outperform standard regression analysis or ARIMA forecasting techniques. That said, in cases where accuracy truly matters, ensemble approaches that combine multiple techniques can produce superior results. Uber used a <a href="https://www.uber.com/blog/m4-forecasting-competition/">hybrid exponential smoothing combined with a neural network</a> model to predict driver supply and demand with very strong results.</p>
<h2 id="summary">Summary</h2>
<p>When I started building predictive models, I frequently conflated time series forecasting and regression analysis. I realized that this was because both of these approaches predict a numerical output ‚Ä¶ but that‚Äôs where the similarities end. Understanding these different strategies, and how they apply to your data, is the first step to unlocking the power of predictive models.</p>
<p>In my next article, I‚Äôll talk about applying these different strategies to B2B analytics. In the meantime, if you have a bunch of B2B data that you want to analyze and don‚Äôt know where to start, please send an email to <a href="mailto:info@amorphousdata.com">info@amorphousdata.com</a> üòÄ.</p>
<p>PS Hi HN! If you want to sign up for an email when I write another post, here‚Äôs a <a href="https://docs.google.com/forms/d/e/1FAIpQLSdbTcNZSt69r_skAv7Zxxy3A5TIb40f5V3FHr3wvsi4bK1cJg/viewform?usp=sf_link">Google form</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wall found at bottom of Baltic Sea 'may be Europe‚Äôs oldest megastructure' (187 pts)]]></title>
            <link>https://www.theguardian.com/science/2024/feb/12/stone-age-wall-found-at-bottom-of-baltic-sea-may-be-europes-oldest-megastructure</link>
            <guid>39350700</guid>
            <pubDate>Mon, 12 Feb 2024 21:22:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2024/feb/12/stone-age-wall-found-at-bottom-of-baltic-sea-may-be-europes-oldest-megastructure">https://www.theguardian.com/science/2024/feb/12/stone-age-wall-found-at-bottom-of-baltic-sea-may-be-europes-oldest-megastructure</a>, See on <a href="https://news.ycombinator.com/item?id=39350700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>A stone age wall discovered beneath the waves off Germany‚Äôs Baltic coast may be the oldest known megastructure built by humans in Europe, researchers say.</p><p>The wall, which stretches for nearly a kilometre along the seafloor in the Bay of Mecklenburg, was spotted by accident when scientists operated a multibeam sonar system from a research vessel on a student trip about 10km (six miles) offshore.</p><p>Closer inspection of the structure, named the Blinkerwall, revealed about 1,400 smaller stones that appear to have been positioned to connect nearly 300 larger boulders, many of which were too heavy for groups of humans to have moved.</p><p>The submerged wall, described as a ‚Äúthrilling discovery‚Äù, is covered by 21 metres of water, but researchers believe it was constructed by hunter-gatherers on land next to a lake or marsh more than 10,000 years ago.</p><p>While the purpose of the wall is hard to prove, scientists suspect it served as a driving lane for hunters in pursuit of herds of reindeer.</p><p>‚ÄúWhen you chase the animals, they follow these structures, they don‚Äôt attempt to jump over them,‚Äù said Jacob Geersen at the Leibniz Institute for Baltic Sea Research in Warnem√ºnde, a German port town on the Baltic coast.</p><p>‚ÄúThe idea would be to create an artificial bottleneck with a second wall or with the lake shore,‚Äù he added.</p><p>A second wall that ran alongside the Blinkerwall may be buried in the seafloor sediments, the researchers write in <a href="https://www.pnas.org/cgi/doi/10.1073/pnas.2312008121" data-link-name="in body link">Proceedings of the National Academy of Sciences</a>.</p><figure id="1c4f68f3-901c-4c5d-9275-0cee5c52efef" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:8,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Stone age Dartmoor viewpoint uncovered by archaeologists&quot;,&quot;elementId&quot;:&quot;1c4f68f3-901c-4c5d-9275-0cee5c52efef&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2023/aug/30/stone-age-dartmoor-viewpoint-uncovered-by-archaeologists&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Alternatively, the wall may have forced the animals into the nearby lake, slowing them down and making them easy pickings for humans lying in wait in canoes armed with spears or bows and arrows.</p><p>Based on the size and shape of the 971 metre-long wall, Geersen and his colleagues consider it unlikely that it formed through natural processes, such as a huge tsunami moving the stones into place, or the stones being left behind by a moving glacier.</p><p>The angle of the wall, which is mostly less than 1 metre high, changes direction when it meets the larger boulders, suggesting the piles of smaller stones were positioned intentionally to link them up. In total, the wall‚Äôs stones are thought to weigh more than 142 tonnes.</p><p>If the wall was an ancient hunting lane, it was probably built more than 10,000 years ago and submerged with rising sea levels about 8,500 years ago.</p><p>‚ÄúThis puts the Blinkerwall into range of the oldest known examples of hunting architecture in the world and potentially makes it the oldest man-made megastructure in <a href="https://www.theguardian.com/world/europe-news" data-link-name="in body link" data-component="auto-linked-tag">Europe</a>,‚Äù the researchers said.</p><p>Geersen is now keen to revisit the site to reconstruct the ancient landscape and search for animal bones and human artefacts, such as projectiles used in hunting, which may be buried in sediments around the wall.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Government makes $42M bet on open cell networks: Open RAN dream stays alive (150 pts)]]></title>
            <link>https://www.theverge.com/2024/2/12/24070550/open-ran-standard-us-funding-5g-huawei</link>
            <guid>39350069</guid>
            <pubDate>Mon, 12 Feb 2024 20:31:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/2/12/24070550/open-ran-standard-us-funding-5g-huawei">https://www.theverge.com/2024/2/12/24070550/open-ran-standard-us-funding-5g-huawei</a>, See on <a href="https://news.ycombinator.com/item?id=39350069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The US government has <a href="https://www.ntia.gov/press-release/2024/biden-harris-administration-awards-42m-wireless-innovation">committed $42 million</a> to further the development of the 5G Open RAN (O-RAN) standard that would allow wireless providers to mix and match cellular hardware and software, opening up a bigger market for third-party equipment that‚Äôs cheaper and interoperable. The National Telecommunications and Information Administration (NTIA) grant would establish a Dallas O-RAN testing center to prove the standard‚Äôs viability as a way to head off Huawei‚Äôs steady cruise toward a global cellular network hardware monopoly. </p><p>Verizon global network and technology president Joe Russo <a href="https://go.redirectingat.com/?xs=1&amp;id=1025X1701640&amp;url=https%3A%2F%2Fwww.verizon.com%2Fabout%2Fnews%2Fnew-grant-ntia-o-ran-carriers-vendors-globally">promoted the funding</a> as a way to achieve ‚Äúfaster innovation in an open environment.‚Äù To achieve the standard‚Äôs goals, AT&amp;T vice president of RAN technology <a href="https://about.att.com/blogs/2024/open-ran.html">Robert Soni says</a> that AT&amp;T and Verizon have formed the Acceleration of Compatibility and Commercialization for Open RAN Deployments Consortium (ACCoRD), which includes a grab bag of wireless technology companies like Ericsson, Nokia, Samsung, Dell, Intel, Broadcom, and Rakuten. </p><p>Japanese wireless carrier Rakuten formed as the first O-RAN network in 2020. The company‚Äôs then CEO, Tareq Amin, <a href="https://www.theverge.com/23297756/5g-rakuten-mobile-ceo-oran-cloud-network-decoder">told <em>The Verge</em>‚Äôs Nilay Patel</a> in 2022 that Open RAN would enable low-cost network build-outs using smaller equipment rather than massive towers ‚Äî which has long been part of the promise of 5G. </p><p>But O-RAN is about more than that; establishing interoperability means companies like Verizon and AT&amp;T wouldn‚Äôt be forced to buy all of their hardware from a single company to create a functional network. For the rest of us, that means faster build-outs and ‚Äúmore agile networks,‚Äù <a href="https://symphony.rakuten.com/blog/open-ran-explained-all-you-need-to-know-and-more">according to Rakuten</a>.</p><p>In the US, Dish has been working on its own O-RAN network, under the name Project Genesis. The 5G network was <a href="https://www.theverge.com/2022/11/24/23445995/dish-5g-network-genesis-las-vegas-trial">creaky and unreliable</a> when former <em>Verge </em>staffer Mitchell Clarke tried it out in Las Vegas in 2022, but the company said in June last year that it had <a href="https://www.theverge.com/2023/6/15/23762646/dish-network-june-2023-boost-fcc-population-coverage-5g-genesis">made its goal</a> of covering 70 percent of the US population. Dish has struggled to <a href="https://www.lightreading.com/open-ran/wall-street-is-fed-up-with-dish-network">become the next big cell provider</a> in the US, though ‚Äî leading satellite communications company EchoStar, which spun off from Dish in 2008, to <a href="https://www.theverge.com/2024/1/2/24022413/dish-network-echostar-acquisition-5g-boost-mobile-wireless">purchase the company</a> in January.</p><p>All of this adds up to a united front against Huawei‚Äôs domination of global cellular equipment and infrastructure. <a href="https://www.washingtonpost.com/technology/2024/02/12/oran-biden-china-huawei-technology/"><em>The Washington Post </em>writes</a> that O-RAN ‚Äúis Washington‚Äôs anointed champion to try to unseat the Chinese tech giant Huawei Technologies‚Äù as the world‚Äôs biggest supplier of cellular infrastructure gear. The <em>Post</em> points out that Biden has made O-RAN a priority point of discussion with global leaders in recent years, and that both Congress and the NTIA have allocated around $2 billion for the advancement of the standard.</p><p>This $42 million grant is a drop in the bucket compared to all of that, but the establishment of a testing center is a key step in the process; it creates an arena where ACCoRD partners can establish that the standard can work and get the buy-in of other big players across the world. The <em>Post</em> notes that Ericsson and AT&amp;T made big commitments in December, with <a href="https://about.att.com/story/2023/commercial-scale-open-radio-access-network.html">a $14 billion, five-year contract</a> to infuse most or ‚Äî in the case of Ericsson ‚Äî all of their hardware with O-RAN compatibility within the next couple of years, giving the standard some hefty momentum.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neural network training makes beautiful fractals (269 pts)]]></title>
            <link>https://sohl-dickstein.github.io/2024/02/12/fractal.html</link>
            <guid>39349992</guid>
            <pubDate>Mon, 12 Feb 2024 20:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sohl-dickstein.github.io/2024/02/12/fractal.html">https://sohl-dickstein.github.io/2024/02/12/fractal.html</a>, See on <a href="https://news.ycombinator.com/item?id=39349992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <meta charset="utf-8">
<!-- Google tag (gtag.js) -->





<pre>




My five year old daughter came home from kindergarten a few months ago, and told my partner and I that math was stupid (!). We have since been working (so far successfully) to make her more excited about all things math, and more proud of her math accomplishments. One success we've had is that she is now very interested in fractals in general, and in particular enjoys watching deep zoom videos into [Mandelbrot](https://youtu.be/8cgp2WNNKmQ?si=PD7W2q4qDNY9AgzD) and [Mandelbulb](https://youtu.be/BLmAV6O_ea0?si=4iyAFMgzde0mTmsq) fractal sets, and eating [romanesco broccoli](https://en.wikipedia.org/wiki/Romanesco_broccoli). 
My daughter's interest has made me think a lot about fractals, and about the ways in which fractals relate to a passion of mine, which is artificial neural networks. 

I've realized that there are similarities between the way in which many fractals are generated, and the way in which we train neural networks. 
Both involve repeatedly applying a function to its own output. 
In both cases, that function has hyperparameters that control its behavior. 
In both cases the repeated function application can produce outputs that either diverge to infinity or remain happily bounded depending on those hyperparameters. 
Fractals are often defined by the boundary between hyperparameters where function iteration diverges or remains bounded.

Motivated by these similarities, I looked for fractal structure in the hyperparameter lanscapes of neural network training. And I found it! The boundary between hyperparameters for which neural network training succeeds or fails has (gorgeous, organic) fractal structure. Details, and beautiful videos, below.
  
For a more technical presentation, see the short paper [*The boundary of neural network trainability is fractal*](https://arxiv.org/abs/2402.06184).

# Neural network training and hyperparameters

In order to train an artificial neural network, we iteratively update its parameters to make it perform better. We often do this by performing [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) steps on a loss function. The loss function is a measure of the neural network's performance. By descending the loss by gradient descent, we find values of the parameters for which the neural network performs well.

Training depends on *hyperparameters*, which specify details about how parameter update steps should be performed and how the network should be initialized. For instance, one common hyperparameter is the learning rate, which sets the magnitude of the update we make to the model‚Äôs parameters at every training step.

If the learning rate is too large, then the parameter update steps are too large. This causes the parameters to diverge (grow towards infinity) during training, and as a result causes the training loss to become very bad. If the learning rate is too small, the training steps are too short, and it takes a very large number of training steps to train the neural network. Requiring a very large number of training steps makes training slow and expensive. In practice, we often want to make the learning rate as large as possible, without making it so large that the parameters diverge.

# Visualizing the hyperparameter landscape

We can visualize how adjusting hyperparameters (like the learning rate) affects how quickly a neural network either trains or diverges. In the following image, each pixel corresponds to training the same neural network from the same initialization on the same data -- but with *different hyperparameters*. Blue-green colors mean that training *converged* for those hyperparameters, and the network successfully trained. Red-yellow colors mean that training *diverged* for those hyperparameters. The paler the color the faster the convergence or divergence

The neural network I used in this experiment is small and simple; it consists of an input layer, a $\operatorname{tanh}$ nonlinearity, and an output layer[^netdetails]. In the image, the x-coordinate changes the learning rate for the input layer‚Äôs parameters, and the y-coordinate changes the learning rate for the output layer‚Äôs parameters.

![Figure [p_ml]: **Hyperparameter landscape: A visualization of how neural network training success depends on learning rate hyperparameters.** Each pixel corresponds to a training run with the specified input and output layer learning rates. Training runs shown in blue-green converged, while training runs shown in red-yellow diverged.[^saturation] Hyperparameters leading to the best performance (lightest blue-green) are typically very close to hyperparameters for which training diverges, so the boundary region is of particular interest.](/assets/fractal/zoom_sequence_width-16_depth-2_datasetparamratio-1.0_minibatch-None_nonlinearity-tanh_phasespace-lr_vs_lr_step-0.png width="444px" border="1")

The best performing hyperparameters -- those that are shown with the palest blue-green shade, and for which the neural network trains the most quickly -- are near the boundary between hyperparameters for which training converges and for which it diverges. This is a general property. The best hyperparameters for neural network training are usually very near the edge of stability. For instance, as suggested above, the best learning rate in a grid search is typically the largest learning rate for which training converges rather than diverges.

# The boundary of neural network trainability is fractal

Because it is where we find the best hyperparameters, the boundary between hyperparameters that lead to converging or diverging training is of particular interest to us. Let‚Äôs take a closer look at it. Play the following video (I recommend playing it full screen, and increasing the playback resolution):

<p>
    <iframe src="https://player.vimeo.com/video/903855670?h=ca2b077023&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>

As we zoom into the boundary between hyperparameter configurations where training succeeds (blue) and fails (red), we find intricate structure at every scale. The boundary of neural network trainability is fractal! 
<big>ü§Ø</big> (If you watched the video to the end, you saw it turn blocky in the last frames. During network training I used the $\operatorname{float64}$ numeric type, which stores numbers with around 16 decimal digits of precision. The blockiness is what happens when we zoom in so far that we need more than 16 digits of precision to tell pixels apart.)

This behavior is general. We see fractals if we change the data, change the architecture, or change the hyperparameters we look at. The fractals look qualitatively different for different choices though. Network and training design decisions also have artistic consequences! 

![Figure [paper]: **Neural network training produces fractals in all of the experimental configurations I tried.** The figure is taken from the [companion paper](https://arxiv.org/abs/2402.06184), and shows a region of the fractal resulting from each experimental condition. Experimental conditions changed the nonlinearity in the network, changed the dataset size, changed between minibatch and full batch training, and changed the hyperparameters we look at.](/assets/fractal/fractal_tiles_midres.png width="444px" border="1")

Here are the remaining fractal zoom videos for the diverse configurations summarized in Figure [paper]. You can find code for these experiments in [this colab](https://colab.research.google.com/github/Sohl-Dickstein/fractal/blob/main/the_boundary_of_neural_network_trainability_is_fractal.ipynb)[^beware].

- **Changing the activation function to the identity function:** i.e. the network is a deep linear network, with no nonlinearity.

<p>
    <iframe src="https://player.vimeo.com/video/903855710?h=0503f33948&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>

- **Change the activation function to $\operatorname{ReLU}$:** This is a neat fractal, since the piecewise linear structure of the $\operatorname{ReLU}$ is visually apparent in the straight lines dividing regions of the fractal.

<p>
    <iframe src="https://player.vimeo.com/video/903855690?h=6072a2020e&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>


- **Train with a dataset size of 1:** i.e. only train on a single datapoint. Other experiments have a number of training datapoints which is the same as the free parameter count of the model.

<p>
    <iframe src="https://player.vimeo.com/video/904781772?h=8bf3776954&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>

- **Train with a minibatch size of 16:** Other experiments use full batch training.

<p>
    <iframe src="https://player.vimeo.com/video/903855680?h=d8f341a934&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>
  
- **Look at different hyperparameters:** I add a hyperparameter which sets the mean value of the neural network weights at initialization. I visualize training success in terms of this weight initialization hyperparameter (*x-axis*) and a single learning rate hyperparameter (*y-axis*). Other experiments visualize training success in terms of learning rate hyperparameters for each layer. This fractal is **extra pretty** -- I like how it goes through cycles where what seems like noise is resolved to be structure at a higher resolution.

<p>
    <iframe src="https://player.vimeo.com/video/903855723?h=ed7eb562bb&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="1" allow="autoplay; fullscreen; picture-in-picture" title="0"></iframe>
</p>
  
# This isn‚Äôt so strange after all

Now that I‚Äôve shown you something surprising and beautiful, let me tell you why we should have expected it all along. In an academic paper I would put this section first, and tell the story as if I knew fractals would be there -- but of course I didn't know what I would find until I ran the experiment!

## Fractals result from repeated iteration of a function

One common way to make a fractal is to iterate a function repeatedly, and identify boundaries where the behavior of the iterated function changes. We can refer to these boundaries as bifurcation boundaries of the iterated function; the dynamics bifurcate at this boundary, in that function iteration leads to dramatically different sequences on either side of the boundary.

For instance, to generate the Mandelbrot set, we iterate the function $f( z; c ) = z^2 + c$ over and over again. The Mandelbrot fractal is the bifurcation boundary between the values of $c$ in the complex plane for which this iterated function diverges, and for which it remains bounded. The parameter $c$ is a (hyper)parameter of the function $f( z; c )$, similarly to how learning rates are hyperparameters for neural network training.

![Figure [mandelbrot fractal]: **The Mandelbrot fractal is generated by iterating a simple function, similar to the way in which update steps are iterated when training a neural network.** 
The image is color coded by whether iterations started at a point diverge (red-yellow colors) or remain bounded (blue-green colors). 
The boundary between the diverging and bounded regions is fractal. 
This image was generated by [this colab](https://colab.research.google.com/github/Sohl-Dickstein/fractal/blob/main/the_boundary_of_neural_network_trainability_is_fractal.ipynb).](/assets/fractal/mandelbrot_midres.png width="444px" border="1")

Other examples of fractals which are formed by bifurcation boundaries include [magnet fractals](https://paulbourke.net/fractals/magnet/), [Lyapunov fractals](https://en.wikipedia.org/wiki/Lyapunov_fractal), the [quadratic Julia set](https://mathworld.wolfram.com/JuliaSet.html), and the [Burning Ship fractal](Burning Ship fractal).

## Fractals can result from optimization

One particularly relevant class of bifurcation fractals are [Newton fractals](https://en.wikipedia.org/wiki/Newton_fractal). These are generated by iterating Newton's method to find the roots of a polynomial. 
[Newton's method is an optimization algorithm](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization). Newton fractals are thus a proof of principle that fractals can result from iterating steps of an optimization algorithm.

![Figure [newton fractal]: **Newton fractals, like the one shown, are formed by iterating Newton's method to find roots of a polynomial, and color coding initial conditions by the specific root the iterates converge to.** Newton fractals are a proof of principle that optimization can generate a fractal, since Newton's method is an optimization procedure. They motivate the idea of fractal behavior resulting from training (i.e. optimizing) a neural network.](/assets/fractal/Julia_set_for_the_rational_function.png width="444px" border="1")

## Artificial neural networks are trained by repeatedly iterating a function

When we train a neural network by iterating steps of gradient descent, we are iterating a fixed function, the same as for Mandelbrot, Newton, and other fractals. 
Like for Newton fractals, this fixed function corresponds to an optimization algorithm. 
Specifically, when we train a neural network using steepest gradient descent with a constant learning rate, we iterate the fixed function
$f(\theta; \eta ) = \theta( \eta ) - \eta\, g( \theta )$.
Here $\eta$ is the learning rate hyperparameter, $\theta$ are the parameters of the neural network, and $g( \theta )$ is the gradient of the loss function.

There are many differences between neural network training and traditional fractal generation. The fractals I just discussed all involve iterating a function of a single (complex valued) number. 
The equation definining the iterated function is short and simple, and takes less than a line of text to write down. 
On the other hand, neural network training iterates a function for all the parameters in the neural network. Some neural networks have trillions of parameters, which means the input and output of the iterated function is described with *trillions* of numbers, one for each parameter. The equation for a neural network training update is similarly far more complex than the function which is iterated for traditional fractals; it would require many lines, or possibly many pages, to write down the parameter update equations for a large neural network.

Nonetheless, training a neural network can be seen as a scaled up version of the type of iterative process that generates traditional fractals. 
We should not be surprised that it produces fractals in a similar way to simpler iterative processes.[^symmetry]

# Closing thoughts

## Meta-learning is hard

Meta-learning is a research area that I believe will transform AI over the next several years. In meta-learning we *learn* aspects of AI pipelines which are traditionally hand designed. For instance, we might meta-train functions to 
initialize, 
[optimize](https://github.com/google/learned_optimization/tree/main/learned_optimization/research/general_lopt), 
or regularize neural networks. If deep learning has taught us one thing, it's that with enough compute and data, trained neural networks can outperform and replace hand-designed heuristics; in meta-learning, we apply the same lesson to replace the hand-designed heuristics we use to train the neural networks themselves. 
Meta-learning is the reason I became interested in hyperparameter landscapes.

The fractal hyperparameter landscapes we saw above help us understand some of the challenges we face in meta-learning.
The process of meta-training usually involves optimizing hyperparameters (or meta-parameters) by gradient descent. 
The loss function we perform meta-gradient-descent on is called the meta-loss. 
The fractal landscapes we have been visualizing are also meta-loss landscapes; we are visually how well training succeeds (or fails) as we change hyperparameters. 
In practice, we often find the meta-loss atrocious to work with. It is often *chaotic* in the hyperparameters, which makes it [very difficult to descend](https://arxiv.org/abs/1810.10180)[^meta-descent]. 
Our results suggest a more nuanced and also more general perspective; meta-loss landscapes are chaotic because they are fractal. At every length scale, small changes in the hyperparameters can lead to large changes in training dynamics.

![Figure [meta landscape]: **Chaotic meta-loss landscapes make meta-learning challenging.** The image shows an example meta-loss landscape for a learned optimizer, with darker colors corresponding to better meta-loss. The two axes correspond to two of the meta-parameters of the learned optimizer (similar to the visualization in Figure [p_ml], where axes correspond to two hyperparameters). See [this paper](https://arxiv.org/abs/1810.10180) for details. This meta-loss landscape is difficult to meta-train on, since steepest gradient descent will become stuck in valleys or local minima, and because the gradients of the rapidly changing meta-loss function are exceptionally high variance.](/assets/fractal/meta-loss-landscape.png width="444px" border="1")

## Fractals are beautiful and relaxing

Recent AI projects I have collaborated on have felt freighted with historical significance. We are building tools that will change people's lives, and maybe bend the arc of history, for both [better and worse](/2023/09/10/diversity-ai-risk.html). This is incredibly exciting! But it is often also stressful.

This project on the other hand ... was just fun. I started the project because my daughter thought fractals were mesmerizing, and I think the final results are gorgeous. I hope you enjoy it in the same spirit!

<br>

-----

<br>

# Acknowledgements
Thank you to Maika Mars Miyakawa Sohl-Dickstein for inspiring the original idea, and for detailed feedback on the generated fractals.
Thank you to Asako Miyakawa for providing feedback on a draft of this post.

<p>

-----

<br>

[^netdetails]: </p><p>In more detail, the baseline neural network architecture, design, and training configuration is as follows:

- Two layer fully connected neural network, with 16 units in the input and hidden layers, and with no bias parameters. The only parameters are the input layer weight matrix, and the output layer weight matrix.
- $\operatorname{tanh}$ nonlinearity in the single hidden layer
- Mean square error loss
- Fixed random training dataset, with number of datapoints the same as the number of free parameters in the network
- Full batch steepest descent training, with a constant learning rate
- **A different learning rate for each layer.** That is rather than training the input and output layer weight matrices with the same learning rate, each weight matrix has its own learning rate hyperparameter.

All experiments change one aspect of this configuration, except for the baseline experiment, which follows this configuration without change. If you want even more detail, see the [arXiv note](https://arxiv.org/abs/2402.06184) or the [colab notebook I used for all experiments](https://colab.research.google.com/github/Sohl-Dickstein/fractal/blob/main/the_boundary_of_neural_network_trainability_is_fractal.ipynb).
</p>

[^saturation]: The discerning reader may have noticed that training diverges when the output learning rate is made large, but that if the input learning rate is made large, performance worsens but nothing diverges. This is due to the $\operatorname{tanh}$ nonlinearity saturating. When the input learning rate is large, the input weights become large, the hidden layer pre-activations become large, and the $\operatorname{tanh}$ units saturate (their outpus grow very close to either -1 or 1). The output layer can still train on the (essentially frozen) $[-1, 1]$ activations from the first layer, and so some learning can still occur.

[^beware]: Like the fractals, the research code in the colab has vibes of layered organic complexity ... user beware!

[^symmetry]: Many fractals are generated by iterating simple functions, such as low order polynomials, or ratios of low order polynomials. Iterating these simple functions often generates simple symmetries, that are visually obvious when looking at the resulting fractals. The fractals resulting from neural networks are more organic, with fewer visually obvious symmetries. This is likely due to the higher complexity of the iterated functions themselves, as well as the many random parameters in the function definitions, stemming from the random initialization of the neural network and random training data.

[^meta-descent]: My collaborators and I have done more research into how to optimize a chaotic meta-loss. Especially see the papers: [*Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies*](https://icml.cc/virtual/2021/poster/10175), and [*Variance-Reduced Gradient Estimation via Noise-Reuse in Online Evolution Strategies*](https://openreview.net/forum?id=VhbV56AJNt).

</pre>


<!-- Markdeep: -->





  </div><p><small>
BibTeX entry for post:<br>
<tt>

@misc{sohldickstein20240212,<br>
‚ÄÉ  author = {Sohl-Dickstein, Jascha},<br>
‚ÄÉ  title = {{ Neural network training makes beautiful fractals }},<br>
‚ÄÉ  howpublished = "\url{https://sohl-dickstein.github.io/2024/02/12/fractal.html}",<br>
‚ÄÉ  date    = {2024-02-12}<br>
}
</tt>
</small>

  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mornington Crescent (111 pts)]]></title>
            <link>https://www.isihac.net/mornington_crescent.php</link>
            <guid>39349817</guid>
            <pubDate>Mon, 12 Feb 2024 20:14:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.isihac.net/mornington_crescent.php">https://www.isihac.net/mornington_crescent.php</a>, See on <a href="https://news.ycombinator.com/item?id=39349817">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
									
									<h2>Mornington Crescent: A complete and abridged guide to the <br>history and rules of this quintessentially British institution.</h2>
								</p><div id="lefttopcol"> <p><a href="https://www.isihac.net/img/mornington_img01_popup.jpg" title="N J Stovold jr and his assistant demonstrate one of his less successful games: ‚ÄúTwickenham in a Basket‚Äù."><img src="https://www.isihac.net/img/mornington_img01.png"></a></p><p>Mornington Crescent is a complex strategy game (level H8) named after a London  Underground station on the Charing Cross branch of the Northern Line, between Euston and Camden Town in Travelcard Zone 2.  Mornington Crescent station is situated at the southern end of Camden High Street, where it meets Hampstead Road and Eversholt Street.</p>	
                                        <p>Closed for many years, the station was reopened on 27 April 1998 by the regular cast of I‚Äôm Sorry I Haven‚Äôt <span><a href="https://www.isihac.net/img/mornington_img02_popup.jpg" title="Members of the Awards Committee transport the 1895 winner‚Äôs giant bottle of port up Dollis Hill."><img src="https://www.isihac.net/img/mornington_img02.png"></a><a href="https://www.isihac.net/img/mornington_img03_popup.jpg" title="Mornington Crescent, 1879.  Commuters patiently wait for the station to re-open in 1888"><img src="https://www.isihac.net/img/mornington_img03.png"></a></span> a Clue and a memorial plaque to the late Willie Rushton was installed at the station in 2002.</p>
                                        <p>The dual-branch nature of the Northern Line means that, on the Charing Cross branch, Mornington  Crescent is between Camden Town and Euston, while the City branch (which also runs from Camden Town to Euston) runs via tunnels which take an entirely different route to the Charing Cross branch and which therefore do not pass through Mornington Crescent. <a href="https://www.isihac.net/img/mornington_img04_popup.jpg" title="Prince Mario Chigi in the Presidential robes of the European Chapter: la Societe de Mornington Croissant."><img src="https://www.isihac.net/img/mornington_img04.png"></a>  This unique feature opens up almost endless variations of play in the long game.  Grand Master players also take full advantage of the area‚Äôs transport links, namely the bus routes 24, 27, 29, 46, 88, 134, 168, 214, 253, 274, C2 and Night routes N5 N20, N28, N29, N253 and not of course forgetting N279.</p>
                                        
                                    </div></div>]]></description>
        </item>
    </channel>
</rss>