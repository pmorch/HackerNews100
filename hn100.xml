<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 14 Sep 2024 04:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[My 71 TiB ZFS NAS After 10 Years and Zero Drive Failures (158 pts)]]></title>
            <link>https://louwrentius.com/my-71-tib-zfs-nas-after-10-years-and-zero-drive-failures.html</link>
            <guid>41536088</guid>
            <pubDate>Fri, 13 Sep 2024 23:21:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://louwrentius.com/my-71-tib-zfs-nas-after-10-years-and-zero-drive-failures.html">https://louwrentius.com/my-71-tib-zfs-nas-after-10-years-and-zero-drive-failures.html</a>, See on <a href="https://news.ycombinator.com/item?id=41536088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>My <a href="https://louwrentius.com/71-tib-diy-nas-based-on-zfs-on-linux.html">4U 71 TiB ZFS NAS</a> built with twenty-four 4 TB drives is over 10 years old and still going strong.</p>
<p><img alt="my nas" src="https://louwrentius.com/static/images/zfsnas01.jpg"></p>
<p>Although now on its second motherboard and power supply, the system has yet to experience a single drive failure (knock on wood).</p>
<p>Zero drive failures in ten years, how is that possible?</p>
<h2>Let's talk about the drives first</h2>
<p>The 4 TB HGST drives have roughly 6000 hours on them after ten years. You might think something's off and you'd be right. That's only about 250 days worth of runtime. And therein lies the secret of drive longevity (I think):</p>
<p><strong>Turn the server off when you're not using it.</strong></p>
<hr>
<p>According to people on <a href="https://news.ycombinator.com/item?id=41536088">Hacker News</a> I have my bearings wrong. The chance of having zero drive failures over 10 years for 24 drives is much higher than I thought it was. So this good result may not be related to turning my NAS off and keeping it off most off the time.</p>
<hr>
<p>My NAS is turned off by default. I only turn it on (remotely) when I need to use it. I use a script to turn the IoT power bar on and once the BMC (Baseboard Management Controller) is done booting, I use <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a> to turn on the NAS itself. But I could have used <a href="https://en.wikipedia.org/wiki/Wake-on-LAN">Wake-on-Lan</a> too as an alternative.</p>
<p>Once I'm done using the server, I run a small script that turns the server off, wait a few seconds and then turn the wall socket off. </p>
<p>It wasn't enough for me to just turn off the server, but leave the motherboard, and thus the BMC powered, because that's just a constant 7 watts (about two Raspberry Pis at idle) being wasted (24/7).</p>
<p>This process works for me because I run other services on low-power devices such as Raspberry Pi4s or servers that use <em>much less power</em> when idling than my 'big' NAS. </p>
<p>This proces reduces my energy bill considerably (primary motivation) and also seems great for hard drive longevity.</p>
<p>Although zero drive failures to date is awesome, N=24 is not very representative and I could just be very lucky. Yet, it was the same story with the <a href="https://louwrentius.com/20-disk-18-tb-raid-6-storage-based-on-debian-linux.html">predecessor of this NAS</a>, a machine with 20 drives (1 TB Samsung Spinpoint F1s (remember those?)) and I also had zero drive failures during its operational lifespan (~5 years).</p>
<h2>The motherboard (died once)</h2>
<p>Although the drives are still ok, I had to replace the motherboard a few years ago. The failure mode of the motherboard was interesting: it was impossible to get into the BIOS and it would occasionally fail to boot. I tried the obvious like removing the CMOS battery and such but to no avail.</p>
<p>Fortunately, the [motherboard]<sup id="fnref:same"><a href="#fn:same">1</a></sup> was still available on Ebay for a decent price so that ended up not being a big deal. </p>
<h2>ZFS</h2>
<p>ZFS worked fine for all these years. I've switched operating systems over the years and I never had an issue importing the pool back into the new OS install.
If I would build a new storage server, I would definitely use ZFS again.</p>
<p>I run a zpool scrub on the drives a few times a year<sup id="fnref:longduration"><a href="#fn:longduration">2</a></sup>. The scrub has <em>never found a single checksum error</em>. I must have run so many scrubs, more than a <em>petabyte</em> of data must have been read from the drives (all drives combined) and ZFS didn't have to kick in.</p>
<p>I'm not surprised by this result at all. Drives tend to fail most often in two modes:</p>
<ol>
<li>Total failure, drive isn't even detected</li>
<li>Bad sectors (read or write failures)</li>
</ol>
<p>There is a third failure mode, but it's extremely rare: <strong>silent data corruption</strong>. Silent data corruption is 'silent' because a disk isn't aware it delivered corrupted data. Or the SATA connection didn't detect any checksum errors. </p>
<p>However, due to all the low-level checksumming, this risk is extremely small. It's a real risk, don't get me wrong, but it's a small risk. To me, it's a risk you mostly care about at scale, in datacenters<sup id="fnref:enterprise"><a href="#fn:enterprise">4</a></sup> but for residential usage, it's totally reasonable to accept the risk<sup id="fnref:risk"><a href="#fn:risk">3</a></sup>. </p>
<p>But ZFS is not that difficult to learn and if you are well-versed in Linux or FreeBSD, it's absolutely worth checking out. Just <a href="https://louwrentius.com/the-hidden-cost-of-using-zfs-for-your-home-nas.html">remember</a>!</p>
<p><img alt="inside" src="https://louwrentius.com/static/images/nano/topview.jpg"></p>
<h2>Sound levels (It's Oh So Quiet)</h2>
<p>This NAS is <em>very</em> quiet for a NAS (<a href="https://youtu.be/LS3cfl-7n-4">video with audio</a>). </p>
<p>But to get there, I had to do some work.</p>
<p>The chassis contains three sturdy 12V fans that cool the 24 drive cages. These fans are extremely loud if they run at their default speed. But because they are so beefy, they are fairly quiet when they run at idle RPM, yet they still provide enough airflow, most of the time. But running at idle speeds was not enough as the drives would heat up eventually, especially when they are being read from / written to.</p>
<p>Fortunately, the particular Supermicro motherboard I bought at the time allows all fan headers to be controlled through Linux. So I decided to create a <a href="https://github.com/louwrentius/storagefancontrol">script</a> that sets the fan speed according to the temperature of the hottest drive in the chassis.</p>
<p>I actually visited a math-related subreddit and asked for an algorithm that would best fit my need to create a silent setup and also keep the drives cool.
Somebody recommended to use a "<a href="https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%E2%80%93derivative_controller">PID controller</a>", which I knew nothing about. So I wrote some Python, stole some example Python PID controller code, and tweaked the parameters to find a balance between sound and cooling performance.</p>
<p>The script has worked very well over the years and kept the drives at 40C or below. PID controllers are awesome and I feel it should be used in much more equipment that controls fans, temperature, and so on, instead of 'dumb' on/of behaviour or less 'dumb' lookup tables.</p>
<h2>Networking</h2>
<p>I started out with quad-port gigabit network controllers and I used <a href="https://louwrentius.com/achieving-450-mbs-network-file-transfers-using-linux-bonding.html">network bonding</a> to get around 450 MB/s network transfer speeds between various systems. This setup required a ton of UTP cables so eventually I got bored with that and I bought some cheap <a href="https://louwrentius.com/using-infiniband-for-cheap-and-fast-point-to-point-networking.html">Infiniband</a> cards and that worked fine, I could reach around 700 MB/s between systems. As I decided to move away from Ubuntu and back to Debian, I faced a problem: the Infiniband cards didn't work anymore and I could not figure out how to fix it. So I decided to buy some second-hand 10Gbit Ethernet cards and those work totally fine to this day.</p>
<h2>The dead power supply</h2>
<p>When you turn this system on, all drives spin up at once (no staggered spinup) and that draws around 600W for a few seconds. I remember that the power supply was rated for 750W and the 12 volt rail would have been able to deliver enough power, but it would sometimes cut out at boot nonetheless.</p>
<h2>UPS (or lack thereof)</h2>
<p>For many years, I used a beefy UPS with the system, to protect against power failure, just to be able to shutdown cleanly during an outage. This worked fine, but I noticed that the UPS used another 10+ watts on top of the usage of the server and I decided it had to go.</p>
<p>Losing the system due to power shenanigans is a risk I accept.</p>
<h2>Backups (or a lack thereof)</h2>
<p>My most important data is backed up trice. But a lot of data stored on this server isn't important enough for me to backup. I rely on replacement hardware and ZFS protecting against data loss due to drive failure.</p>
<p>And if that's not enough, I'm out of luck. I've accepted that risk for 10 years. Maybe one day my luck will run out, but until then, I enjoy what I have.</p>
<h2>Future storage plans (or lack thereof)</h2>
<p>To be frank, I don't have any. I built this server back in the day because I didn't want to shuffle data around due to storage space constraints and I still have ample space left.</p>
<p>I have a spare motherboard, CPU, Memory and a spare HBA card so I'm quite likely able to revive the system if something breaks.</p>
<p>As hard drive sizes have increased tremendously, I may eventually move away from the 24-drive bay chassis into a smaller form-factor. It's possible to create the same amount of redundant storage space with only 6-8 hard drives with RAIDZ2 (RAID 6) redundancy. Yet, storage is always expensive. </p>
<p>But another likely scenario is that in the coming years this system eventually dies and I decide not to replace it at all, and my storage hobby will come to an end.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lisp implemented in Rust macros (149 pts)]]></title>
            <link>https://github.com/RyanWelly/lisp-in-rs-macros</link>
            <guid>41535354</guid>
            <pubDate>Fri, 13 Sep 2024 21:31:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RyanWelly/lisp-in-rs-macros">https://github.com/RyanWelly/lisp-in-rs-macros</a>, See on <a href="https://news.ycombinator.com/item?id=41535354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><code>lisp-in-rs-macros</code></h2><a id="user-content-lisp-in-rs-macros" aria-label="Permalink: lisp-in-rs-macros" href="#lisp-in-rs-macros"></a></p>
<p dir="auto">A simple, lexically scoped Lisp interpreter that operates fully in Rust's declarative macros. The <code>lisp!</code> macro expands to the lisp value computed by the code, and then stringifies it. This means that <code>lisp!(CAR (CONS (QUOTE A) (QUOTE (B))))</code> expands to the string "A" and that all this computation happens at compile time by rustc expanding macros.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why</h2><a id="user-content-why" aria-label="Permalink: Why" href="#why"></a></p>
<p dir="auto">It's a lisp interpreter written fully in Rust's macros, I think that's pretty cool. It's also less than 250 lines, which is neat.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="let output = lisp!(CAR (LIST (QUOTE A) (QUOTE B) (QUOTE C)));
assert_eq!(output, &quot;A&quot;); 

lisp!(PROGN
(DEFINE message (LAMBDA () (QUOTE &quot;hello there&quot;)))
(DISPLAY (message))
(DEFINE NOT (LAMBDA (X) (COND (X NIL) (TRUE TRUE))) )
(DISPLAY (NOT NIL))
); // will print &quot;hello there&quot; and &quot;TRUE&quot;
// &quot;DISPLAY&quot; forms first evaluate their arguments, then expand to a println!(&quot;{}&quot;, stringify!(evaled_argument))
"><pre><span>let</span> output = <span>lisp</span><span>!</span><span>(</span><span>CAR</span> <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>A</span><span>)</span> <span>(</span><span>QUOTE</span> <span>B</span><span>)</span> <span>(</span><span>QUOTE</span> <span>C</span><span>)</span><span>)</span><span>)</span><span>;</span>
<span>assert_eq</span><span>!</span><span>(</span>output, <span>"A"</span><span>)</span><span>;</span> 

<span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
<span>(</span><span>DEFINE</span> message <span>(</span><span>LAMBDA</span> <span>(</span><span>)</span> <span>(</span><span>QUOTE</span> <span>"hello there"</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>DISPLAY</span> <span>(</span>message<span>)</span><span>)</span>
<span>(</span><span>DEFINE</span> <span>NOT</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>COND</span> <span>(</span><span>X</span> <span>NIL</span><span>)</span> <span>(</span><span>TRUE</span> <span>TRUE</span><span>)</span><span>)</span><span>)</span> <span>)</span>
<span>(</span><span>DISPLAY</span> <span>(</span><span>NOT</span> <span>NIL</span><span>)</span><span>)</span>
<span>)</span><span>;</span> <span>// will print "hello there" and "TRUE"</span>
<span>// "DISPLAY" forms first evaluate their arguments, then expand to a println!("{}", stringify!(evaled_argument))</span></pre></div>
<p dir="auto">As another fun example, here is a quine:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!
       ((LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))
       (QUOTE (LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))));"><pre><span>lisp</span><span>!</span>
       <span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span>
       <span>(</span><span>QUOTE</span> <span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span></pre></div>
<p dir="auto">This code expands to:</p>
<div dir="auto" data-snippet-clipboard-copy-content="stringify!(((LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))
       (QUOTE (LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s))))));"><pre><span>stringify</span><span>!</span><span>(</span><span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span>
       <span>(</span><span>QUOTE</span> <span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span></pre></div>
<p dir="auto">In other words, the code evaluates to itself. Isn't that wonderful?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Recursion</h2><a id="user-content-recursion" aria-label="Permalink: Recursion" href="#recursion"></a></p>
<p dir="auto">This lisp does not currently support any explicit form of recursion. Luckily, explicit recursion is not needed, all we need is lambda.</p>
<p dir="auto">You can write a simple function that appends two lists by using self application:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!(PROGN
(DEFINE append 
    (LAMBDA (self X Y) 
        (COND 
            ((EQ X NIL) Y) 
            (TRUE (CONS (CAR X) (self self (CDR X) Y))) 
        )))
(append append (QUOTE (A B)) (QUOTE (C D)))

)"><pre><span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
<span>(</span><span>DEFINE</span> append 
    <span>(</span><span>LAMBDA</span> <span>(</span><span>self</span> <span>X</span> <span>Y</span><span>)</span> 
        <span>(</span><span>COND</span> 
            <span>(</span><span>(</span><span>EQ</span> <span>X</span> <span>NIL</span><span>)</span> <span>Y</span><span>)</span> 
            <span>(</span><span>TRUE</span> <span>(</span><span>CONS</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span> <span>(</span><span>self</span> <span>self</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span> <span>Y</span><span>)</span><span>)</span><span>)</span> 
        <span>)</span><span>)</span><span>)</span>
<span>(</span>append append <span>(</span><span>QUOTE</span> <span>(</span><span>A</span> <span>B</span><span>)</span><span>)</span> <span>(</span><span>QUOTE</span> <span>(</span><span>C</span> <span>D</span><span>)</span><span>)</span><span>)</span>

<span>)</span></pre></div>
<p dir="auto">This results in "(A B C D)". The append function does not mention <code>append</code> in its body, yet we can call it recursively. Wonderful!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes for use</h2><a id="user-content-notes-for-use" aria-label="Permalink: Notes for use" href="#notes-for-use"></a></p>
<p dir="auto">The lisp! macro only evaluates a single expression; if you want to evaluate multiple expressions, use <code>(PROGN expr1 expr2 expr3)</code>. This evaluates all the expressions, and returns the value of the last expression. The DISPLAY form evaluates a single expression, then generates a <code>println!("{}", stringify!(...))</code> statement which prints the stringified version of the tokens. The empty list is not self evaluating, you can use <code>NIL</code> or <code>(QUOTE ())</code> to obtain an empty list value. The empty list is the sole "falsy" object.
Dotted lists aren't supported, cons assumes its last argument is a list. The define form can be used anywhere and evaluates to the empty list, but does not support recursion. TRUE is the only self evaluating atom (that isn't a function).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported forms</h2><a id="user-content-supported-forms" aria-label="Permalink: Supported forms" href="#supported-forms"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="DEFINE 
QUOTE 
LAMBDA 
LET
PROGN 
CAR 
CDR 
CONS
LIST
EQ
ATOM
APPLY"><pre><span>DEFINE</span> 
<span>QUOTE</span> 
<span>LAMBDA</span> 
<span>LET</span>
<span>PROGN</span> 
<span>CAR</span> 
<span>CDR</span> 
<span>CONS</span>
<span>LIST</span>
<span>EQ</span>
<span>ATOM</span>
<span>APPLY</span></pre></div>
<p dir="auto">Note: dotted lists are not supported, CONS assumes its latter argument is a list. Define does not handle recursive definitions, it's more like internal definitions in Scheme than a true lispy define.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Metacircular interpreter</h2><a id="user-content-metacircular-interpreter" aria-label="Permalink: Metacircular interpreter" href="#metacircular-interpreter"></a></p>
<p dir="auto">Here is a lisp interpreter written in my lisp:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!(PROGN
            // Y &quot;combinator&quot; for two arguments
        (DEFINE Y2 
                        (LAMBDA (h)
                            ((LAMBDA (x) (h (LAMBDA (a b) ((x x) a b))))
                                (LAMBDA (x) (h (LAMBDA (a b) ((x x) a b)))))))
        
        (DEFINE CADR (LAMBDA (X) (CAR (CDR X))))
        (DEFINE CAAR (LAMBDA (X) (CAR (CAR X))))
        (DEFINE CADAR (LAMBDA (X) (CAR (CDR (CAR X)))))
        (DEFINE CADDR (LAMBDA (X) (CAR (CDR (CDR X)))))
        (DEFINE CADDAR (LAMBDA (X) (CAR (CDR (CDR (CAR X))))))
        (DEFINE CAADAR (LAMBDA (X) (CAR (CAR (CDR (CAR X))))))

        (DEFINE ASSOC (Y2 (LAMBDA (ASSOC) (LAMBDA (X ENV) 
                        (IF (EQ (CAAR ENV) X) (CADAR ENV) (ASSOC X (CDR ENV)))
                    )))
                )


            
        (DEFINE eval (Y2 (LAMBDA (EVAL) (LAMBDA (E A) 
                (COND
                    ((ATOM E) (ASSOC E A))
                    ((ATOM (CAR E)) 
                        (COND 
                            ((EQ (CAR E) (QUOTE quote)) (CADR E))
                            ((EQ (CAR E) (QUOTE atom)) (ATOM (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE car)) (CAR (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE cdr)) (CDR (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE equal)) (EQ (EVAL (CADR E) A) (EVAL (CADDR E) A)))
                            ((EQ (CAR E) (QUOTE cons)) (CONS (EVAL (CADR E) A) (EVAL (CADDR E) A)))
                            (TRUE (EVAL (CONS (ASSOC (CAR E) A) (CDR E)) A)) 
                        )
                    )
                    ((EQ (CAAR E) (QUOTE lambda)) (EVAL (CADDAR E) (CONS (LIST (CAADAR E) (EVAL (CADR E) A)) A)  )) //Evaluate the inner expression of the lambda, in the environment with the argument bound to the parameter
                
                )
            ))))

        (eval (QUOTE (quote (A))) NIL)
        // (eval (QUOTE (atom (quote A))) NIL )
        // (eval (QUOTE (cdr (cdr (quote (A B))))) NIL)
        // (eval (QUOTE (cons (quote a) (quote (a)))) NIL)
        // (eval (QUOTE ((lambda (x) (quote a)) (quote b))) NIL)
        (eval (QUOTE ((lambda (X) X) (quote a))) NIL)

        );"><pre><span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
            <span>// Y "combinator" for two arguments</span>
        <span>(</span><span>DEFINE</span> <span>Y2</span> 
                        <span>(</span><span>LAMBDA</span> <span>(</span>h<span>)</span>
                            <span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>x<span>)</span> <span>(</span>h <span>(</span><span>LAMBDA</span> <span>(</span>a b<span>)</span> <span>(</span><span>(</span>x x<span>)</span> a b<span>)</span><span>)</span><span>)</span><span>)</span>
                                <span>(</span><span>LAMBDA</span> <span>(</span>x<span>)</span> <span>(</span>h <span>(</span><span>LAMBDA</span> <span>(</span>a b<span>)</span> <span>(</span><span>(</span>x x<span>)</span> a b<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        
        <span>(</span><span>DEFINE</span> <span>CADR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CAAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADDR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADDAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CAADAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>

        <span>(</span><span>DEFINE</span> <span>ASSOC</span> <span>(</span><span>Y2</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>ASSOC</span><span>)</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span> <span>ENV</span><span>)</span> 
                        <span>(</span><span>IF</span> <span>(</span><span>EQ</span> <span>(</span><span>CAAR</span> <span>ENV</span><span>)</span> <span>X</span><span>)</span> <span>(</span><span>CADAR</span> <span>ENV</span><span>)</span> <span>(</span><span>ASSOC</span> <span>X</span> <span>(</span><span>CDR</span> <span>ENV</span><span>)</span><span>)</span><span>)</span>
                    <span>)</span><span>)</span><span>)</span>
                <span>)</span>


            
        <span>(</span><span>DEFINE</span> eval <span>(</span><span>Y2</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>EVAL</span><span>)</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>E</span> <span>A</span><span>)</span> 
                <span>(</span><span>COND</span>
                    <span>(</span><span>(</span><span>ATOM</span> <span>E</span><span>)</span> <span>(</span><span>ASSOC</span> <span>E</span> <span>A</span><span>)</span><span>)</span>
                    <span>(</span><span>(</span><span>ATOM</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span><span>)</span> 
                        <span>(</span><span>COND</span> 
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> quote<span>)</span><span>)</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> atom<span>)</span><span>)</span> <span>(</span><span>ATOM</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> car<span>)</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> cdr<span>)</span><span>)</span> <span>(</span><span>CDR</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> equal<span>)</span><span>)</span> <span>(</span><span>EQ</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> cons<span>)</span><span>)</span> <span>(</span><span>CONS</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>TRUE</span> <span>(</span><span>EVAL</span> <span>(</span><span>CONS</span> <span>(</span><span>ASSOC</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>CDR</span> <span>E</span><span>)</span><span>)</span> <span>A</span><span>)</span><span>)</span> 
                        <span>)</span>
                    <span>)</span>
                    <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> lambda<span>)</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDAR</span> <span>E</span><span>)</span> <span>(</span><span>CONS</span> <span>(</span><span>LIST</span> <span>(</span><span>CAADAR</span> <span>E</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span> <span>A</span><span>)</span>  <span>)</span><span>)</span> <span>//Evaluate the inner expression of the lambda, in the environment with the argument bound to the parameter</span>
                
                <span>)</span>
            <span>)</span><span>)</span><span>)</span><span>)</span>

        <span>(</span>eval <span>(</span><span>QUOTE</span> <span>(</span>quote <span>(</span><span>A</span><span>)</span><span>)</span><span>)</span> <span>NIL</span><span>)</span>
        <span>// (eval (QUOTE (atom (quote A))) NIL )</span>
        <span>// (eval (QUOTE (cdr (cdr (quote (A B))))) NIL)</span>
        <span>// (eval (QUOTE (cons (quote a) (quote (a)))) NIL)</span>
        <span>// (eval (QUOTE ((lambda (x) (quote a)) (quote b))) NIL)</span>
        <span>(</span>eval <span>(</span><span>QUOTE</span> <span>(</span><span>(</span>lambda <span>(</span><span>X</span><span>)</span> <span>X</span><span>)</span> <span>(</span>quote a<span>)</span><span>)</span><span>)</span> <span>NIL</span><span>)</span>

        <span>)</span><span>;</span></pre></div>
<p dir="auto">It appears to work, but trying to evaluate <code>((lambda (X) X) (quote a))</code> in the interpreter takes more than 30 seconds and generates far more than 1 million+ tokens before cargo gets sigkilled. Using the explicit y combinator for recursion isn't particularly efficient here! To fix this, I should add an explicit recursion primitive.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical explanation</h2><a id="user-content-technical-explanation" aria-label="Permalink: Technical explanation" href="#technical-explanation"></a></p>
<p dir="auto">Look at EXPLANATION.md. The macro essentially simulates a SECD machine, which is a simple stack-basd abstract machine for evaulating lambda calculus terms.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Awesome resources</h2><a id="user-content-awesome-resources" aria-label="Permalink: Awesome resources" href="#awesome-resources"></a></p>
<ul dir="auto">
<li>Functional Programming: Application and Implementation by Peter Henderson</li>
<li>Ager, Mads Sig, et al. "A functional correspondence between evaluators and abstract machines." Proceedings of the 5th ACM SIGPLAN international conference on Principles and practice of declaritive programming. 2003.</li>
<li>The Implementation of Functional Programming Languages by Simon Peyton Jones</li>
<li>Anything Matt Might has ever written about lisp on his blog (<a href="https://matt.might.net/" rel="nofollow">https://matt.might.net</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO</h2><a id="user-content-todo" aria-label="Permalink: TODO" href="#todo"></a></p>
<ul dir="auto">
<li>Add letrec</li>
<li>Add recursive defines</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CrowdStrike ex-employees: 'Quality control was not part of our process' (298 pts)]]></title>
            <link>https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage</link>
            <guid>41534716</guid>
            <pubDate>Fri, 13 Sep 2024 20:17:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage">https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage</a>, See on <a href="https://news.ycombinator.com/item?id=41534716">Hacker News</a></p>
Couldn't get https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Janet Jackson had the power to crash laptop computers (2022) (124 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</link>
            <guid>41534483</guid>
            <pubDate>Fri, 13 Sep 2024 19:44:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994">https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</a>, See on <a href="https://news.ycombinator.com/item?id=41534483">Hacker News</a></p>
Couldn't get https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI threatens to revoke o1 access for asking it about its chain of thought (422 pts)]]></title>
            <link>https://twitter.com/SmokeAwayyy/status/1834641370486915417</link>
            <guid>41534474</guid>
            <pubDate>Fri, 13 Sep 2024 19:43:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/SmokeAwayyy/status/1834641370486915417">https://twitter.com/SmokeAwayyy/status/1834641370486915417</a>, See on <a href="https://news.ycombinator.com/item?id=41534474">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I won't be renewing my Pinboard subscription (159 pts)]]></title>
            <link>https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html</link>
            <guid>41533958</guid>
            <pubDate>Fri, 13 Sep 2024 18:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html">https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html</a>, See on <a href="https://news.ycombinator.com/item?id=41533958">Hacker News</a></p>
Couldn't get https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Meta fed its AI on everything adults have publicly posted since 2007 (178 pts)]]></title>
            <link>https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data</link>
            <guid>41533060</guid>
            <pubDate>Fri, 13 Sep 2024 17:05:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data">https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data</a>, See on <a href="https://news.ycombinator.com/item?id=41533060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Meta has acknowledged that all text and photos that adult Facebook and Instagram users have publicly published since 2007 have been fed into its artificial intelligence models. <a href="https://www.abc.net.au/news/2024-09-11/facebook-scraping-photos-data-no-opt-out/104336170">Australia’s ABC News reports</a> that Meta’s global privacy director, Melinda Claybaugh, initially rejected claims about user data from 2007 being leveraged for AI training during a local government inquiry about AI adoption before relenting after additional questioning.</p><p>“The truth of the matter is that unless you have consciously set those posts to private since 2007, Meta has just decided that you will scrape all of the photos and all of the texts from every public post on Instagram or Facebook since 2007 unless there was a conscious decision to set them on private,” Green Party senator David Shoebridge pushed in the inquiry. “That’s the reality, isn’t it?”</p><p>“Correct,” Claybaugh responded.</p><p>Meta’s <a href="https://www.facebook.com/privacy/guide/generative-ai/">privacy center</a> and <a href="https://about.fb.com/news/2023/09/privacy-matters-metas-generative-ai-features/">blog posts</a> acknowledge hoovering up public posts and comments from Facebook and Instagram to train generative AI:</p><div><blockquote><p>We use public posts and comments on Facebook and Instagram to train generative AI models for these features and for the open source community.</p><p>We don’t use posts or comments with an audience other than Public for these purposes.</p></blockquote></div><p>But the company has been vague about how data is used, when it started scraping, and how far back its collection goes. Asked by <em>The New York Times</em> in June, Meta didn’t answer, other than to confirm that setting posts <a href="https://www.nytimes.com/2024/06/07/technology/meta-ai-scraping-policy.html">to anything besides “public” will prevent future scraping</a>. That still won’t delete data that has already been collected — and people posting back in 2007 (who may have been minors at the time) wouldn’t have known their photos and posts would be used in this way.</p><p>Claybaugh said that Meta doesn’t scrape data from users who are under the age of 18. When Labor Party senator Tony Sheldon asked if Meta would scrape the public photos of his children on his own account, Claybaugh confirmed it would and was unable to clarify if the company also scraped adult accounts that were created when the user was still a child.</p><p>European users can opt out <a href="https://www.theverge.com/2024/6/14/24178591/meta-ai-assistant-europe-ireland-privacy-objections">due to local privacy regulations</a>, and Meta was recently <a href="https://www.theverge.com/2024/7/3/24191405/meta-anpd-stop-training-ai-on-brazilian-facebook-instagram-data">banned from using Brazilian personal data</a> for AI training, but the billions of Facebook and Instagram users in other regions can’t opt out if they want to keep their posts public. Claybaugh was unable to say if Australian users (or anyone else) would be given a choice to opt out in the future, arguing that the option was given to European users because of <a href="https://www.theverge.com/2024/7/18/24201041/meta-multimodal-llama-ai-model-launch-eu-regulations">uncertainty regarding its regulatory landscape</a>.</p><p>“Meta made it clear today that if Australia had these same laws Australians’ data would also have been protected,” Shoebridge said to ABC News. “The government’s failure to act on privacy means companies like Meta are continuing to monetize and exploit pictures and videos of children on Facebook.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zero-Click Calendar invite – Critical zero-click vulnerability chain in macOS (354 pts)]]></title>
            <link>https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b</link>
            <guid>41532946</guid>
            <pubDate>Fri, 13 Sep 2024 16:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b">https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b</a>, See on <a href="https://news.ycombinator.com/item?id=41532946">Hacker News</a></p>
Couldn't get https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Defend against vampires with 10 gbps network encryption (166 pts)]]></title>
            <link>https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption</link>
            <guid>41531699</guid>
            <pubDate>Fri, 13 Sep 2024 14:42:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption">https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption</a>, See on <a href="https://news.ycombinator.com/item?id=41531699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="schema:text"><p>Let's say you have a fiber optic line running between two buildings, or between two spaces you rent in the same building. You use trunk ports on the switches connected to the fiber, in order to "stretch" your L2 Ethernet network and its different VLANs, so computers, servers, printers, cameras, etc. in both offices easily communicate with their peers.</p>
<p>But there is next to no physical security in the shared wiring closets and common cabling paths, and so you are concerned about someone <em>tapping</em>&nbsp;into the fiber line and capturing data.</p>
<p>First you may ask, is that really possible? And if so, is it easy to do? Would you need NSA-level hardware and skills or could anyone do it?</p>
<p>Turns out, it is both possible and easy, so you're right to worry! But there is a solution...</p>

<h3>Tapping on copper cables<br>
&nbsp;</h3>
<p>It's so simple to tap on copper network cables that back in the 80s, it was the official way to expand your 10BASE5 Ethernet network. IT people&nbsp;used so-called "vampire taps" that truly <em>bit</em> through the insulation of the cable to make contact with the conductors inside, enabling a new connection without interrupting ongoing data transmission.</p>
<figure role="group">
<img alt="photo of a 80s vampire tap showing bite marks on the cable" data-entity-type="file" data-entity-uuid="239417dc-b316-4b38-8a2e-a7a6589df581" src="https://www.synacktiv.com/sites/default/files/inline-images/vampiretap.jpg">
<figcaption>Vampire tap and 10BASE5 Ethernet cable showing "bite marks"</figcaption>
</figure>
<p><a href="https://www.tiktok.com/@davidbombal/video/7246772712696335643">This&nbsp;TikTok video</a> shows one of these devices in action.</p>
<p>Nowadays, people might still use copper cables instead of fiber for distances &lt; 100m, and <a href="https://en.wikipedia.org/wiki/Network_tap#Gigabit_Ethernet_issues">it's a bit more difficult to tap on 1000BASE-T modern cables</a>. Anyway, since our typical LAN-to-LAN scenario rather involves optical fibers running along not-well-protected cable runways, let's see if optical fibers are&nbsp;vulnerable too.</p>
<h3><br>
Tapping on optical fiber<br>
&nbsp;</h3>
<p>For a number of years it was commonly believed that tapping on optical fibers was possible, but that it needed both expertise and expensive hardware.</p>
<p>But in 2015, the late <a href="https://www.zdnet.com/article/infamous-hacker-kevin-mitnick-sniffs-fiber-reads-email/">Kevin Mitnick demonstrated just how easy it is to tap into a fiber and sniff the traffic</a>, using a 200$ optical "clip-on coupler".</p>
<p>These&nbsp;couplers are originally designed to be used by line technicians to talk to one another over long distances using so-called "optical talk sets", and&nbsp;coordinate with one another while installing these&nbsp;fibers, even when they have no access to the ends of the fiber.</p>
<p>They work by exposing a portion of the fiber core and bending it slightly,&nbsp;reflecting some 2-3% of the light inside the fiber (but still 100% of its data) and also allowing to inject light in it. Of course, it's better to have some practice and a steady hand in order to expose the fiber core without damaging the fiber.</p>
<p>In true hacker fashion, these&nbsp;couplers are creatively used by attackers to read data from the fiber, and inject data of their own.&nbsp;</p>
<figure role="group">
<img alt="clip-on coupler like the one used by Mitnick" data-entity-type="file" data-entity-uuid="f8ad2517-2643-41eb-b7d6-358848d41033" src="https://www.synacktiv.com/sites/default/files/inline-images/clip_on_coupler_small.jpg">
<figcaption>The&nbsp;FOD5516 Clip-on Coupler that can detect and inject light in (singlemode) optical fiber</figcaption>
</figure>
<p>This opens many classical man-in-the-middle attack scenarios such as forcing the downgrade&nbsp;of crypto protocols, redirecting traffic, etc. on top of simple sniffing.</p>

<h2>Encrypt ALL the things !<br>
&nbsp;</h2>
<p>So it seems there's not much you can do to prevent vampire tapping onto your easily-accessible cable paths. In fact, they might already be there...</p>
<p>As with any confidentiality issue, the best solution lies in encryption. If your whole network traffic is encrypted, the data vampires might still suck on your network cables, but instead of draining the very blood of your company, they will only gather encrypted gibberish of no use to them.</p>
<p>But how exactly can you encrypt "everything" in such a LAN-to-LAN scenario? And at what cost?</p>
<p>If you had routers on both ends of the fiber, with each site having its own dedicated IP zones with no overlap, you could easily setup a VPN tunnel like IPSec or Wireguard between the two routers and solve your problem.<br>
That said, if you used a "stretched L2" approach like in our scenario, it would not be easy to go back and re-segment&nbsp;all your networking, moving&nbsp;from bridging&nbsp;to&nbsp;routing traffic.<br>
You could try instead to enforce the policy that every applicative stream on your network, even print jobs, realtime video, DNS, etc. uses only a "secure" (encrypted) version of its protocol. It's certainly an impressive feat if you've managed to achieve that in a typical office environment ☺️.&nbsp;Even so, you'd likely still be interested into setting some kind of encrypted tunnel on the fiber, just in case someone sets up accidentaly some unsecure applicative stream...</p>
<p>The idea we had to solve such a problem, with the least disruption to existing networks and protocols, was to mix "802.1q trunk links" and VPN-like encryption between the two ends of the fiber. So&nbsp;instead of plugging the fiber directly into your switches, you plug them to an equipment with two network interfaces, that will on one end "swallow" all your 802.1q traffic (VLANs and all) and then transfer them over the fiber, through an encrypted tunnel, to a second "mirror" equipment that will decrypt the packets and transform them again into 802.1q frames and "spit them out" to its&nbsp;local network. This was dubbed the "wormhole" project.</p>
<h2>The quest for the encrypted trunk : MACsec</h2>
<p>If you search for ways to "encrypt/secure a 802.1q trunk" you will probably read about MACsec, aka the Cisco-designed 802.1ae standard, which on paper seems to do exactly what we want, with the added benefit that if you use MACsec-capable switches on each end of the fiber, you don't need additionnal equipements to do the secure tunneling.</p>
<p>MACsec creates point-to-point Secure Channels pairs (one for Tx, one for Rx) between two devices over an untrusted connection, using first a negotiation protocol called MKA (MACsec Key Agreement) and for example pre-shared keys (or a PKI). Over these Secure Channels, MACSec Frames are sent, which are only slightly modified Ethernet frames with their layer-3+ payload encrypted using GCM-AES-128 (or GCM-AES-256 in newer hardware). Since they are essentially Ethernet frames, MACSec can natively support 802.1q VLAN headers for example.</p>
<p>In order to test these promises, we bought a pair of the smallest Cisco switch that supports MACsec : the Catalyst 3560 CX WS-3560CX-8XPD-S, at ~1600€ each.</p>
<h3><br>
Testing MACsec</h3>
<p>Unfortunately, during our testing we found MACsec underwhelming for our LAN-to-LAN scenario.</p>
<p>First, it's difficult to find accurate MACsec documentation since it supports a variety of use cases (securing a link between a workstation and a switch, securing a link between two switches...) and as usual with Cisco, there are configuration directives that may or may not exist on a given Cisco switch, depending on its IOS image, feature level, generation, etc. So it was a bit of a pain to get it working for our trunk ports.</p>
<p>Then, we found out something that in hindsight was pretty clear in the MACsec specification&nbsp;: MACsec <em>does not hide the real MAC addresses of devices talking on your network</em> to the eavesdropping attacker. It may make sense, in order for traffic to be able go through MACsec-unaware bridges, to preserve the original MAC adresses of (for example) two computers talking to each other, but we expected to be able to see only the MAC Adresses of the two switches directly connected to the untrusted network and doing the MACsec tunnel. This could have been considered a minor inconvenience, but as MAC addresses are assigned by device manufacturers, it gives an attacker quite a good intel on what brand of computer, printer, appliances, etc. devices you have on your network, so that may help them plan a targeted attack. And if you're worried about industrial espionage, maybe you don't want your spying concurrent to know what brand of components you use on your R&amp;D VLANs either.</p>
<p>Last but not least, on several occasions during our offensive testing, we were able to mess with the MKA/MACsec traffic enough (using not-so-transparent software bridges and resetting MKA sessions on the switches ) so that half of the traffic (corresponding to one of the two secure channels) was being sent fully unencrypted, despite the <code>linksec policy must-secure</code> settings on the ports specifying to never send traffic in the clear on this interface according to Cisco documentation ("Must-Secure imposes that only MACsec encrypted traffic can flow. Hence, until the MKA session is secured, traffic is dropped."). Moreover, the switches were not reporting errors at all and happily continued sending/receiving clear traffic on MACsec must-secure interfaces. The end-user devices (laptops) had no way to know their traffic was being read, since their communications continued as usual (minus the loss of a few ICMP or UDP packets during MKA renegociation).</p>
<figure role="group">
<img alt="wireshard capture showing half the traffic in clear" data-entity-type="file" data-entity-uuid="7101fb11-ea1d-4bcb-81c4-10ca1c3fa7fb" src="https://www.synacktiv.com/sites/default/files/inline-images/pcap_macsec_clair.png">
<figcaption>Wireshark traffic capture : the ping replies are sent in clear over the MACsec link, although the ping echo requests are still sent encrypted.</figcaption>
</figure>
<p>This behaviour was observed with the most recent IOS firmware at that time, and although it then required both 1) an attacker on the fiber doing Man-in-the-Middle and dropping some frames, and 2) an admin action on the switch CLI itself (<code>clear mka sessions</code>), given that the MKA sessions have an expiry and must be renegociated after some time or when a port goes down, we think it's likely that there's a way to trigger that behavior only by "sitting on the wire" with no CLI access to the switch.</p>
<p>The bug tracker from Cisco showed bugs and behaviour that, although apparently not applying to our model, looked close to what we found:</p>
<ul>
<li><a href="https://bst.cisco.com/quickview/bug/CSCvx83835">"MACsec access-control must-secure is allowing the unencrypted traffic to pass through a link"</a></li>
<li><a href="https://bst.cisco.com/quickview/bug/CSCvw36505">"MACsec ports in Auth-pending state after changing to should secure policy with Empty keychain"</a></li>
<li><a href="https://bst.cisco.com/quickview/bug/CSCus74990">"MKA sessions struck in "pending" state after clear MKA sess"</a></li>
</ul>
<p>We had to drop there our experiments with our Cisco switches since the goal of this mission was to "find a reliable way to encrypt LAN to LAN fiber links at high speed", not to "break MACsec", but we may go back to it sometime in the future :)</p>
<h2>Native Linux solution : VXLAN+Wireguard</h2>
<p>Having set MACsec aside, we decided to PoC something that would use only native and well-known Linux kernel features on commodity hardware.</p>
<p>Since Wireguard is the state-of-the-art, in-kernel tunneling, was there a way to shove 802.1q L2 traffic inside a wireguard tunnel, and what speeds could be reached on customer-level hardware costing approximately the same as the Cisco switches we just tested ?</p>
<p>The "missing bit" to go from an L2 trunk to a L3 tunnel was solved by using VXLAN.&nbsp;</p>
<h3>VXLAN</h3>
<p>VXLAN is a protocol used to carry over L2 frames using UDP encapsulation (port 4789 or 8472 depending on the implementation) to a distant endpoint (called VTEP, for "VXLAN termination endpoint"). It works by hooking onto L2 forwarding tables (like on a Linux bridge), and sending to the remote VTEP the frames that must be broadcasted on the segment, along with the frames that have no local destination ("flood and learn"). The remote VTEP decapsulates the L2 frame from the UDP packet and sends it to its local network.</p>
<p>VXLAN real-world use case mostly involves "datacenter bridging", so that VMs from Datacenter 1 could behave like they are "on the same Ethernet segment" than VMs from Datacenter 2 so they can really share the same IP subnet (respond to ARP "who-has", etc).&nbsp;</p>
<p>Despite its name, VXLAN is only "inspired" by the concept of L2 VLANs : it is not something that will, out-of-the box, listen on a trunk port and carry 802.1q tagged frames to the remote endpoint. But it's very possible to do so using Linux wonderful networking stack ! You just need to to map each&nbsp;802.1q VLAN ID to a VXLAN "vid" and do the same thing in reverse on the other VTEP.</p>
<p>Most of the documentation you find online about injecting L2 VLAN info into a VXLAN&nbsp;tunnel has you creating a Linux bridge + a VLAN interface + a VXLAN interface <em>per VLAN </em>that&nbsp;you want to transmit.&nbsp;<br>
If you use all 4096 VLANs, or want to be able to add/drop VLANs on your network without having to do so many steps each time, you can use iproute2 commands <code>bridge</code> and <code>ip</code>&nbsp;with some recent feature flags (<code>vlan_filtering, vlan_default_pvid,&nbsp;vlan_tunnel + tunnel_info</code>)&nbsp;to spare yourself some time and have less clutter on your Linux "wormhole" boxes. The <code>vlan_default_pvid&nbsp;</code>flag is very important to be able to keep 802.1q headers "inside the bridge" and have them reach the vxlan interface where they will then be mapped to a vxlan <code>vid</code>.</p>
<p>With these commands you can have a single bridge and VXLAN interface that handles every VLAN coming its way.</p>
<pre><code># Create a Linux bridge with the right options
/sbin/ip link add br0 type bridge vlan_filtering 1 vlan_default_pvid 0 vlan_stats_enabled 1 vlan_stats_per_port 1

# Enslave the trunk eth interface (connected to the switch trunk port)
# to the bridge
/sbin/ip link set dev ${TRUNK_IFACE} master br0

# Create a vxlan interface and enslave it to the same bridge
/sbin/ip link add vxlan0 type vxlan vni ${VXLAN_DEFAULT_VNI} local ${VTEP_LOCALIP} remote ${VTEP_REMOTEIP} dstport 4789
/sbin/ip link set dev vxlan0 master br0

# Activate vlan tunneling !
/sbin/bridge link set dev vxlan0 vlan_tunnel on</code></pre>
<p>Then, adding a specific VLAN ID to the bridge so its extracted and mapped to a VXLAN vid requires these 3 commands</p>
<pre><code>/sbin/bridge vlan add vid $vid dev ${TRUNK_IFACE}
/sbin/bridge vlan add vid $vid dev vxlan0
/sbin/bridge vlan set dev vxlan0 vid $vid tunnel_info id $vid</code></pre>
<p>You can easily run a little script to do the mapping once and for all for every possible VLAN ID :</p>
<pre><code># extract vlans from trunk, map them to same vxlan vid
for vid in $(seq 2 4095); do
/sbin/bridge vlan add vid $vid dev ${TRUNK_IFACE}
/sbin/bridge vlan add vid $vid dev vxlan0
/sbin/bridge vlan set dev vxlan0 vid $vid tunnel_info id $vid
done</code></pre>

<h3>Wireguard</h3>
<p><br>
Plugging this VXLAN configuration to a wireguard tunnel is surprisingly easy. We won't be covering setting up a wireguard tunnel between two Linux hosts since there are many great resources online (and it just&nbsp;works out of the box).</p>
<p>Indeed, if you've already set up a wg0 interface over the (insecure) fiber connection, with (secure) IP addresses for both of your "wormholes", you can specify the remote peer's wireguard IP address directly as ${VTEP_REMOTEIP}. Linux in-kernel networking will then do its magic and dutifully forward over the wire your 802-1q frames, encapsulated in UDP VXLAN, and encapsulated again in UDP Wireguard.</p>
<p>Having read that, you might worry like we did at the potential performance cost of such many-levels of encapsulation and encryption on top of it.</p>

<h2>Performance&nbsp;</h2>
<p><img alt="scheme of the multiple layers of encapsulation between the wormholes" data-entity-type="file" data-entity-uuid="3c48c427-11f2-416a-b2fe-c228fc8c3a54" src="https://www.synacktiv.com/sites/default/files/inline-images/max-encap.png"></p><p>So, the final packets that will transit "on the wire" between our wormholes will end up looking something&nbsp;&nbsp;like&nbsp;<code>Eth/IP/UDP/WG/IP/UDP/VXLAN/Eth/802.1q/IP/Payload</code>. That's quite an overhead indeed!</p>
<p>But this overhead is only present during the&nbsp;transit on the fiber, which on our&nbsp;scenario is a local, short-distance (read : low latency) optical fiber, typically using at least&nbsp;10 Gbps SFP+ optical transceivers. So the latency and bandwidth should be good, and we will be able to maximize the Maximum Transfer Unit (MTU) on the fiber interface ports, so that a typical Ethernet data payload of 1500 bytes will be able to&nbsp;"sit" easily in the payload of our jumbo wireguard+vxlan frame :&nbsp;&nbsp;there will be&nbsp;no need for segmentation and retransmits.&nbsp;</p>
<p>Regarding wireguard encryption, we did a little research and felt confident after reading&nbsp;<a href="https://restoreprivacy.com/optimizations-in-wireguard-achieve-record-10gbit-sec-throughput/">resources</a> &nbsp;that we could reach high speeds with the right hardware offloads, altough 10 Gbps seemed like the "record".</p>
<p>The corresponding <code>ethtool</code> vars that matched offloads that enabled good performance for VXLAN+wireguard were determined to be :&nbsp;<code>tx-udp_tnl-segmentation,&nbsp;generic-segmentation-offload,&nbsp;generic-receive-offload,&nbsp;rx-vlan-offload</code> and&nbsp;<code>tx-vlan-offload</code>.</p>
<p>The next step was to find server hardware that had&nbsp;10 Gbps SFP+ ports with&nbsp;<strong>UDP Segmentation Offload</strong>&nbsp;(Generic Segmentation Offload),&nbsp;<strong>UDP Receive Coalescing</strong>&nbsp;(Generic Receive Offload) and <strong>VXLAN offloading</strong> capabilites</p>
<p>The search was over when we found out about SuperMicro SuperServer&nbsp;5019D-4C-FN8TP, that had everything we needed with an&nbsp;Intel Xeon D-2123IT&nbsp;SoC that directly handles 2x 10Gbps SFP+ and 2x 10Gbps base-T ports, both the CPU and NICs supporting the aforementioned offload instructions. It costed about 1300€ (you then have to add ECC RAM and local hard drive yourself).</p>
<p><img alt="picture of chosen supermicro server" data-entity-type="file" data-entity-uuid="ff622867-34b4-409c-b904-49fc587e2ef8" src="https://www.synacktiv.com/sites/default/files/inline-images/supermicro.png"></p><h3>Test setup</h3>
<p>Our test setup was like this :</p>
<p><img alt="schema of our test setup described below" data-entity-type="file" data-entity-uuid="592259de-dcc4-40cd-bac4-bb474ba78e6b" src="https://www.synacktiv.com/sites/default/files/inline-images/maquette_0.png"></p><p>We planned to measure throughput using <code>iperf3</code> in the following conditions:</p>
<ul>
<li>Between the Supermico wormholes on the untrusted fiber</li>
<li>Between the&nbsp;Supermico wormholes through the wireguard tunnel built over the untrusted fiber (to measure wireguard encryption penalty)</li>
<li>Between a pair of two 1 Gbps laptops, each on one side&nbsp;of the wormholes, to measure end-device to end-device performance</li>
<li>Between <em>two</em> pairs of such laptops, each pair on a different VLAN and simultaneously trying to use their 1 Gbps max bandwidth, just&nbsp;to be sure we were scaling... and this was quite a good intuition to do this test, as you will read further.</li>
</ul>
<p>We also measured the base performance of the four laptops with a classical setup (just the network switches linked by a trunk port, no vxlan or wireguard, no "wormholing") : they were able to reach 942 Mbps.</p>
<p>Just out-of-the box, with no particular tuning, here were the first&nbsp;tests results:</p>
<ul>
<li>9.81 Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - so it seems we really did buy 10 Gbps-capable NICs!&nbsp;nice</li>
<li>8.18 Gbits/sec between the Supermicros on&nbsp;wg0 (AES) - a 17% performance penalty, seemed to be expected from encrypting...</li>
<li>874 Mbits/sec between two&nbsp;laptops (compared to 942 Mbps in a classical setup) - a 8% performance "end-user" penalty, did not seem so bad</li>
<li>But only 658 Mbits/sec when there&nbsp;were 4 laptops each connected in pairs (again compared to 942 Mbps for each pair) - oops, something seemed off!&nbsp;</li>
</ul>
<p>It looked like we were stalling somewhere around a ~1 Gbps shared bandwith for every end-user devices. Looked like a waste of our "next to 10 Gbps" bandwidth, surely there was something to do about it.</p>
<h3>Tuning Linux networking</h3>
<p>So we activated all the network-related tuning we had thought off beforehand:</p>
<pre><code># enable Jumbo frames (9000 bytes MTU) on 10 Gbps fiber
/sbin/ip li set dev ${UNTRUSTED_IFACE} mtu 9000

# https://cromwell-intl.com/open-source/performance-tuning/ethernet.html
/sbin/ip link set dev ${UNTRUSTED_IFACE} txqueuelen 13888 
/sbin/ethtool -G ${UNTRUSTED_IFACE} rx 4096 tx 4096

# setup a 8020 MTU on wg0 interface to account for the 80 bytes wireguard headers overhead
# 20-byte IPv4 header or 40 byte IPv6 header,&nbsp;8-byte UDP header&nbsp;&nbsp;4-byte type,&nbsp;4-byte key index,&nbsp;8-byte nonce,&nbsp;16-byte authentication tag)
/sbin/ip li set dev wg0 mtu 8020</code></pre>
<p>we added some <code>sysctl</code> tuning for 10Gbps ethernet as well:</p>
<pre><code># Maximum receive socket buffer size
net.core.rmem_max = 134217728 

# Maximum send socket buffer size
net.core.wmem_max = 134217728 

# Minimum, initial and max TCP Receive buffer size in Bytes
net.ipv4.tcp_rmem = 4096 87380 134217728 

# Minimum, initial and max buffer space allocated
net.ipv4.tcp_wmem = 4096 65536 134217728 

# Maximum number of packets queued on the input side
net.core.netdev_max_backlog = 300000 

# Auto tuning
net.ipv4.tcp_moderate_rcvbuf =1

# Don't cache ssthresh from previous connection
net.ipv4.tcp_no_metrics_save = 1

# If you are using jumbo frames set this to avoid MTU black holes.
net.ipv4.tcp_mtu_probing = 1</code></pre>

<p>After that we had the following test results:</p>
<ul>
<li>9.91&nbsp;Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - 100 Mbps better than&nbsp;9.81 Gbits/sec !</li>
<li>8.41&nbsp;Gbits/sec between the Supermicros on&nbsp;wg0 (wireguard) - more than 200 Mbps better than&nbsp;8.18 Gbits/sec !!</li>
<li>942 Mbits/sec between two&nbsp;laptops - now equivalent to the legacy setup without wormholes - yay !</li>
<li>still 658 Mbits/sec when they were 4 laptops each connected in pairs - something's still off...</li>
</ul>
<p>Having tuned everything network-related we could think of, it then occured to us that a good part of the networking ( bridging, forwarding, encapsulating) was really done in-kernel (read: "in-memory") and not on NICs. So surely some default Linux performance setting was stalling us around ~ 1 Gbps .</p>
<h3>Last tunables</h3>
<p>We then set the CPU governor to <code>performance</code> and tuned virtual memory <code>sysctl</code>s to match what RedHat's <code>tuned</code> tool does when setting the profile <code>throughput-performance</code>:</p>
<pre><code>vm.dirty_ratio = 40
vm.dirty_background_ratio = 10
vm.swappiness=10
# set cpu/power options
governor=performance
energy_perf_bias=performance
min_perf_pct=100</code></pre>
<p>And<em> lo&nbsp;and behold</em>, here were the tests results:</p>
<ul>
<li>9.86&nbsp;Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - bit lower than previous test</li>
<li><strong>9.71 Gbits/sec</strong> between the Supermicros on&nbsp;wg0 &nbsp;- the crypto impact was becoming negligible!</li>
<li>942 Mbits/sec between two&nbsp;laptops (still equivalent to the legacy setup without wormholes)</li>
<li>finally 942 Mbits/sec even when they were 4 laptops each connected in pairs - job done!</li>
</ul>
<p>In fact, the performance was so great we felt the need to vampire tap the&nbsp;fiber to make sure everythink was still encrypted - and it&nbsp;still was ;-)</p>
<h2>Conclusion</h2>
<p>So, we were able to build a fully open-source pair of appliances that will strongly encrypt a 10 Gbps 802.1q trunk at almost wire-speed (less than 2% performance penalty), defeating any spying vampire tapping onto the underlying network link. And this appliance costs less than a flagship smartphone.</p>
<p>This truly speaks levels about the performance of today's affordable server hardware&nbsp;and the maturity of Linux networking stack. You can chain network technologies like trunking, bridging, routing, VXLAN and Wireguard almost like you chain CLI commands in true UNIX fashion, and the kernel makes it "just work". It just takes quite a bit of time and trial &amp; error to find the right feature flags and tuning settings so you can get the most out of it. We hope this blog article will do its part as well for future researchers.</p>
<p>If you liked this article and building secure-yet-performant infrastructure, speak French and are living near Paris, note that we are hiring an experienced profile to join&nbsp;our Infrastructure team ! More info (in French) :&nbsp;<a href="https://www.synacktiv.com/apt-search-sysadmin">https://www.synacktiv.com/apt-search-sysadmin</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porting SBCL to the Nintendo Switch (309 pts)]]></title>
            <link>https://reader.tymoon.eu/article/437</link>
            <guid>41530783</guid>
            <pubDate>Fri, 13 Sep 2024 12:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reader.tymoon.eu/article/437">https://reader.tymoon.eu/article/437</a>, See on <a href="https://news.ycombinator.com/item?id=41530783">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      
        <header>
          
        </header>
        <div id="article-body">
          <blockquote><article><figure><a href="https://filebox.tymoon.eu//file/TWpjNU5nPT0=" target="_blank"><img alt="https://filebox.tymoon.eu//file/TWpjNU5nPT0=" src="https://filebox.tymoon.eu//file/TWpjNU5nPT0="></a></figure><p>For the past two years Charles Zhang and I have been working on getting my game engine, Trial, running on the Nintendo Switch. The primary challenge in doing this is porting the underlying Common Lisp runtime to work on this platform. We knew going into this that it was going to be hard, but it has proven to be quite a bit more tricky than expected. I'd like to outline some of the challenges of the platform here for posterity, though please also understand that due to Nintendo's NDA I can't go into too much detail.</p><h2 id="current status">Current Status</h2><p>I want to start off with where we are at, at the time of writing this article. We managed to port the runtime and compiler to the point where we can compile and execute arbitrary lisp code directly on the Switch. We can also interface with shared libraries, and I've ported a variety of operating system portability libraries that Trial needs to work on the Switch as well.</p><p>The above photo shows Trial's REPL example running on the Switch devkit. Trial is setting up the OpenGL context, managing input, allocating shaders, all that good stuff, to get the text shown on screen; the Switch does not offer a terminal of its own.</p><figure><iframe width="100%" height="240" frameborder="no" allowfullscreen="yes" src="//www.youtube.com/embed/zLoEkvnoGKY?"></figure><p>Unfortunately it also crashes shortly after as SBCL is trying to engage its garbage collector. The Switch has some unique constraints in that regard that we haven't managed to work around quite yet. We also can't output any audio yet, since the C callback mechanism is also broken. And of course, there's potentially a lot of other issues yet to rear their head, especially with regards to performance.</p><p>Whatever the case, we've gotten pretty far! This work hasn't been free, however. While I'm fine not paying myself a fair salary, I can't in good conscience have Charles invest so much of his valuable time into this for nothing. So I've been paying him on a monthly basis for all the work he's been doing on this port. Up until now that has cost me ~17'000 USD. As you may or may not know, I'm self-employed. All of my income stems from sales of <a class="external-link" href="https://kandria.com">Kandria</a> and donations from generous supporters on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, and <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. On a good month this totals about 1'200 USD. On a bad month this totals to about 600 USD. That would be hard to get by in a cheap country, and it's practically impossible in Zürich, Switzerland.</p><p>I manage to get by by living with my parents and being relatively frugal with my own personal expenses. Everything I actually earn and more goes back into hiring people like Charles to do cool stuff. Now, I'm ostensibly a game developer by trade, and I am working on a currently unannounced project. Games are very expensive to produce, and I do not have enough reserves to bankroll it anymore. As such, it has become very difficult to decide what to spend my limited resources on, and especially a project like this is much more likely to be axed given that I doubt Kandria sales on the Switch would even recoup the porting costs.</p><p>To get to the point: if you think this is a cool project and you would like to help us make the last few hurdles for it to be completed, please consider supporting me on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, or <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. On Patreon you get news for every new library I release (usually at least one a month) and an exclusive monthly roundup of the current development progress of the unannounced game. Thanks!</p><h2 id="an overview">An Overview</h2><p>First, here's what's publicly known about the Switch's environment: user code runs on an ARM64 Cortex-A57 chip with four cores and 4 GB RAM, and on top of a proprietary microkernel operating system that was initially developed for the Nintendo 3Ds.</p><p>SBCL already has an ARM64 Linux port, so the code generation side is already solved. Kandria also easily fits into 4GB RAM, so there's no issues there either. The difficulties in the port reside entirely in interfacing with the surrounding proprietary operating system of the switch. The system has some constraints that usual PC operating systems do not have, which are especially problematic for something like Lisp as you'll see in the next section.</p><p>Fortunately for us, and this is the reason I even considered a port in the first place, the Switch is also the only console to support the OpenGL graphics library for rendering, which Trial is based upon. Porting Trial itself to another graphics library would be a gigantic effort that I don't intend on undertaking any time soon. The Xbox only supports DirectX, though supposedly there's an OpenGL -&gt; DirectX layer that Microsoft developed, so that <em>might</em> be possible. The Playstation on the other hand apparently still sports a completely proprietary graphics API, so I don't even want to think about porting to that platform.</p><p>Anyway, in order to get started developing I had to first get access. I was lucky enough that Nintendo of Europe is fairly accommodating to indies and did grant my request. I then had to buy a devkit, which costs somewhere around 400 USD. The devkit and its SDK only run on Windows, which isn't surprising, but will also be a relevant headache later.</p><p>Before we can get on to the difficulties in building SBCL for the Switch, let's first take a look at how SBCL is normally built on a PC.</p><h2 id="building sbcl">Building SBCL</h2><p>SBCL is primarily written in Lisp itself. There is a small C runtime as well, which you use a usual C compiler to compile, but before it can do that, there's some things it needs to know about the operating system environment it compiles for. The runtime also doesn't have a compiler of its own, so it can't compile any Lisp code. In order to get the whole process kicked off, SBCL requires another Lisp implementation to bootstrap with, ideally another version of itself.</p><p>The build then proceeds in roughly five phases:</p><ol><li value="1"><p><code>build-config</code><br/>This step just gathers whatever build configuration options you want for your target and spits them out into a readable format for the rest of the build process.</p></li><li value="2"><p><code>make-host-1</code></p><p>Now we build the cross-compiler with the host Lisp compiler, and at the same time emit C header files describing Lisp object layouts in memory as C structs for the next step.</p></li><li value="3"><p><code>make-target-1</code></p><p>Next we run the target C compiler to create the C runtime. As mentioned, this uses a standard C compiler, which can itself be a cross-compiler. The C runtime includes the garbage collector and other glue to the operating system environment. This step also produces some constants the target Lisp compiler and runtime needs to know about by using the C compiler to read out relevant operating system headers.</p></li><li value="4"><p><code>make-host-2</code></p><p>With the target runtime built, we build the target Lisp system (compiler and the standard library) using the Lisp cross-compiler built by the Lisp host compiler in <code>make-host-1</code>. This step produces a &quot;cold core&quot; that the runtime can jump into, and can be done purely on the host machine. This cold core is not complete, and needs to be executed on the target machine with the target runtime to finish bootstrapping, notably to initialize the object system, which requires runtime compilation. This is done in</p></li><li value="5"><p><code>make-target-2</code></p><p>The cold core produced in the last step is loaded into the target runtime, and finishes the bootstrapping procedure to compile and load the rest of the Lisp system. After the Lisp system is loaded into memory, the memory is dumped out into a &quot;warm core&quot;, which can be loaded back into memory in a new process with the target runtime. From this point on, you can load new code and dump new images at will.</p></li></ol><p>Notable here is the need to run Lisp code on the <em>target machine</em> itself. We can't cross-compile &quot;purely&quot; on the host, not in the least because user Lisp code cannot be compiled without also being run like batch-compiled C code can, and when it is run it assumes that it is in the target environment. So we really don't have much of a choice in the matter.</p><p>In order to deploy an application, we proceed similar to <code>make-target-2</code>: We compile in Lisp code incrementally and then when we have everything we need we dump out a core with the runtime attached to it. This results in a single binary with a data blob attached.</p><p>When the SBCL runtime starts up it looks for a core blob, maps it into memory, marks pages with code in them as executable, and then jumps to the entry function the user designated. This all is a problem for the Switch.</p><h2 id="building for the switch">Building for the Switch</h2><p>The Switch is not a PC environment. It doesn't have a shell, command line, or compiler suite on it to run the build as we usually do. Worse still, its operating system does not allow you to create executable pages, so even if we could run the compilation steps on there we couldn't incrementally compile anything on it like we usually do for Lisp code.</p><p>But all is not lost. Most of the code is not platform dependent and can simply be compiled for ARM64 as usual. All we need to do is make sure that anything that touches the surrounding environment in some way knows that we're actually trying to compile for the Switch, then we can use another ARM64 environment like Linux to create our implementation.</p><p>With that in mind, here's what our steps look like:</p><ol><li value="1"><p><code>build-config</code><br/>We run this on some host system, using a special flag to indicate that we're building for the Switch. We also enable the <code>fasteval</code> contrib. We need <code>fasteval</code> to step in for any place where we would usually invoke the compiler at runtime, since we absolutely cannot do that on the Switch.</p></li><li value="2"><p><code>make-host-1</code></p><p>This step doesn't change. We just get different headers that prep for the Switch platform.</p></li><li value="3"><p><code>make-target-1</code></p><p>Now we use the C compiler the Nintendo SDK provides for us, which can cross-compile for the Switch. Unfortunately the OS is not POSIX compliant, so we had to create a custom runtime target in SBCL that stubs out and papers over the operating system environment differences that we care about, like dynamic linking, mapping pages, and so on.<br/>Here is where things get a bit weird. We are now moving on to compiling Lisp code, and we want to do so on a Linux host system. So we have to...</p></li><li value="4"><p><code>build-config</code> (2)</p><p>We now create a normal ARM64 Linux system with the same feature set as for the Switch. This involves the usual steps as before, though with a special flag to inform some parts of the Lisp process that we're going to ultimately target the Switch.</p></li><li value="5"><p><code>make-host-1</code> (2)</p></li><li value="6"><p><code>make-target-1</code> (2)</p></li><li value="7"><p><code>make-host-2</code></p></li><li value="8"><p><code>make-target-2</code></p><p>With all of this done we now have a slightly special SBCL build for Linux ARM64. We can now move on to compiling user code.</p></li><li value="9"><p>For user code we now perform some tricks to make it think it's running on the Switch, rather than on Linux. In particular we modify <code>*features*</code> to include <code>:nx</code> (the Switch code name) and not <code>:linux</code>, <code>:unix</code>, or <code>:posix</code>. Once that is set up and ASDF has been neutered, we can compile our program (like Trial) &quot;as usual&quot; and at the end dump out a new core.</p></li></ol><p>We've solved the problem of actually compiling the code, but we still need to figure out how to get the code started on the Switch, since it does not allow us to do the usual core-mapping strategy. As such, attaching the new core to the runtime we made for the Switch won't work.</p><p>To make this work, we make use of two relatively unknown features of SBCL: immobile-code, and elfination. Usually when SBCL compiles code at runtime, it sticks it into a page somewhere, and marks that page executable. The code itself however could become unneeded at some point, at which point we'd like to garbage collect it. We can then reclaim the space it took up, and to do so compact the rest of the code around it. The immobile-code feature allows SBCL to take up a different strategy, where code is put into special reserved code pages and remains there. This means it can't be garbage collected, but it instead can take advantage of more traditional operating system support. Typically executables have pre-marked sections that the operating system knows to contain code, so it can take care of the mapping when the program is started, rather than the program doing it on its own like SBCL usually does.</p><p>OK, so we can generate code and prevent it from being moved. But we still have a core at the end of our build that we now need to transform into the separate code and data sections needed for a typical executable. This is done with the elfination step.</p><p>The elfinator looks at a core and performs assembly rewriting to make the code position-independent (a requirement for Address Space Layout Randomisation), and then tears it out into two separate files, a pure code assembly file, and a pure data payload file.</p><p>We can now take those two files and link them together with the runtime that the C compiler produced and get a completed SBCL that runs like any other executable would. So here's the last steps of the build process:</p><ol><li value="10"><p>Run the elfinator to generate the assembly files</p></li><li value="11"><p>Link the final binary</p></li><li value="12"><p>Run the Nintendo SDK's authoring tools to bundle metadata, shared libraries, assets, and the application binary into one final package</p></li></ol><p>That's quite an involved build setup. Not to mention that we need at least an ARM64 Linux machine to run most of the build on, as well as either an AMD64 Windows machine (or an AMD64 Linux machine with Wine) to run the Nintendo SDK compiler and authoring tools.</p><p>I usually use an AMD64 Linux machine, so there's a total of three machines involved: The AMD64 &quot;driver,&quot; the ARM64 build host, and a Windows VM to talk to the devkit with.</p><p>I wrote a special build system with all sorts of messed up caching and cross-machine synchronisation logic to automate all of this, which was quite a bit of work to get going, especially since the build should also be drivable from an MSYS2/Windows setup. Lots of fun with path mangling!</p><p>So now we have a full Lisp system, including user code, compiling for and being able to run on the Switch. Wow! I've skipped over a lot of the nitty-gritty dealing with getting the build properly aware of which target it's building for, making the elfinator and immobile-code working on ARM64, and porting all of the support libraries like pathname-utils, libmixed, cl-gamepad, etc. Again, most of the details we can't openly talk about due to the NDA. However, we have upstreamed what work we could, and all of the Lisp libraries don't have a private fork.</p><p>It's worth noting though that elfination wasn't initially designed to produce position independent executable Lisp code, which is usually full of absolute pointers. So we needed to do a lot of work in the SBCL compiler and runtime to support load time relocation of absolute pointers and make sure code objects (which usually contain code constants) no longer have absolute pointers, as the GC can't modify executable sections. Not even the OS loader is allowed to modify executable sections to relocate absolute pointer. We did this by relocating absolute pointers like code constants outside of the text space into a read-writable space close enough to rewrite constant references in code to load from this r/w space instead, which the loader and the moving GC can fixup pointers at.</p><p>Instead of interfacing directly with the Nintendo SDK, I've opted to create my own C libraries that have a custom interface the Lisp libraries interface with in order to access the operating system functionality it needs. That way I can at least publish the Lisp bits openly, and only keep the small C library private. Anyway, now that we can run stuff we're not done yet. Our system actually needs to keep running, too, and that brings us to</p><h2 id="the garbage collector">The Garbage Collector</h2><p>Garbage collection is a huge topic in itself and there's a ton of different techniques to make it work efficiently. The standard GC for SBCL is called &quot;gencgc&quot;, a Generational Garbage Collector. Generational meaning it keeps separate &quot;generations&quot; of objects and scans the generations in different frequencies, copying them over to another generation's location to compact the space. None of this is inherently an issue for the Switch, if it weren't for multithreading.</p><p>When multiple threads are involved, we can't just move objects around, as another thread could be accessing it at any time. The easiest way to resolve this conflict is to park all threads before engaging garbage collection. So the question becomes: when a thread wants to start garbage collection, how does it get the other threads to park?</p><p>On Unix systems a pretty handy trick is used: we can use the signalling mechanism to send a signal to the other threads, which then take that hint to park.</p><p>On the Switch we don't have any signal mechanism. In fact, we can't interrupt threads at all. So we instead need to somehow get each thread to figure out that it should park on its own. The typical strategy for this is called &quot;safepoints&quot;.</p><p>Essentially we modify the compiler a little bit to inject some extra code that checks whether the thread should park or not. This strategy has some issues, namely:</p><ul><li><p>Adding a check isn't free. So we want to check as little as possible</p></li><li><p>If we don't check frequently enough, we are going to stall all the other threads because GC can't begin until they're all parked</p></li><li><p>If we have to inject a lot of instructions for a check, it is going to disrupt CPU cache lines and pipelining optimisations</p></li></ul><p>The current safepoint system in SBCL was written for Windows, which similarly does not have inter-process signal handlers. However, unlike the Switch, it <em>does</em> still have signal handling for the current thread. So the current safepoint implementation was written with this strategy:</p><p>Each thread keeps a page around that a safepoint just writes a word to. When GC is engaged, those pages are marked as read-only, so that when the safepoint is hit and the other thread tries to write to the page, a segmentation fault is triggered and the thread can park. This is efficient, since we only need a single instruction to write into the page.</p><p>On the Switch we can't use this trick either, so we have to actually insert a more complex check, which can be tricky to get working as intended, as all parallel algorithms tend to be.</p><p>Since safepoints aren't necessary on any other platform than Windows, it also hasn't been tested anywhere else, so aside from modifying it for this new platform it's also just unstable. It is apparently quite a big mess in the code base and would ideally be redone from scratch, but hopefully we don't have to go quite that far.</p><p>I'd also like to give special mention to the issue that CLOS presents. Usually SBCL defers compilation of the &quot;discriminating function&quot; that is needed to dispatch to methods to the first call of the generic function. This is done because CLOS is highly dynamic and allows adding and removing methods pretty much at any time, and there's usually no good point in time that the system knows it is complete. Of course, on the Switch we can't invoke the compiler, so we can't really do this. For now our strategy has been to instead rely on the fast evaluator. We stub out the <code>compile</code> function to create a lambda that executes the code via the evaluator instead. This has the advantage of working with any user code that relies on <code>compile</code> as well, though it is obviously much slower for execution than it would be if we could actually compile.</p><p>This neatly brings us to</p><h2 id="future work">Future Work</h2><p>The fasteval trick is mostly a fallback. Ideally I'd like to explore options to freeze as much of CLOS in place as possible right before the final image is dumped and compile as much as possible ahead of time. I'd also like to investigate the block compilation mode that Charles restored some years back more closely.</p><p>It's very possible that the Switch's underpowered processor will also force us to implement further optimisations, especially on the side of my engine and the code in Kandria itself. Up until now I've been able to get away with comparatively little optimisation, since even computers of ten years ago are more than fast enough to run what I need for the game. However, I'm not so sure that the Switch could match up to that even if it didn't also introduce additional constraints on performance with its lack of operating system support.</p><p>First, though, we need to get the garbage collector running fully. It runs enough to boot up and get into Trial's main loop, but as soon as it hits multi-generation compaction, it falls flat on its face.</p><p>Next we need to get callbacks from C working again. Apparently this is a part of the SBCL codebase that can only be described as &quot;a mess,&quot; involving lots of hand-rolled assembly routines, which probably need some adjustments to work correctly with immobile-code and elfination. Callbacks fortunately are relatively rare, Trial only needs them for sound playback via libmixed.</p><p>There's also been some other issues that we've kept in the back of our heads but don't require our immediate attention, as well as some extra portability features I know I'll have to work on in Trial before its selftest suite fully passes on the Switch.</p><h2 id="conclusion">Conclusion</h2><p>I'll be sure to add an addendum here should the state of the port significantly change in the future. Some people have also asked me if the work could be made public, or if I'd be willing to share it.</p><p>The answer to that is that while I would desperately like to share it all publicly, the NDA prevents us from doing so. We still upstream and publicise whatever we can, but some bits that tie directly into the Nintendo SDK cannot be shared with anyone that hasn't <em>also</em> signed the NDA. So, in the very remote possibility that someone other than me is crazy enough to want to publish a Common Lisp game on the Nintendo Switch, they can reach out to me and I'll happily give them access to our porting work once the NDA has been signed.</p><p>Naturally, I'll also keep people updated more closely on what's going on in the monthly updates for Patrons. With that all said, I once again plead with you to consider supporting me on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, or <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. All the income from these will, for the foreseeable future, be going towards funding the SBCL port to the Switch as well as the current game project.</p><p>Thank you as always for reading, and I hope to share more exciting news with you soon!</p></article></blockquote>
          <div class="notice">
            Written by <a href="https://user.tymoon.eu/shinmera/" id="author-avatar" title="shinmera">shinmera</a>
          </div>
        </section>
      
      <footer>
        <nav id="move">
          
            <a class="prev" href="https://reader.tymoon.eu/article/436">SRS, Zürich 2024 Edition</a>
          
          
        </nav>
        <nav id="default-linkage">
          <ul/>
        </nav>
      </footer>
    </article>
  </body>
</html>
</iframe></figure></article></blockquote></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: FlowTracker – Track data flowing through Java programs (261 pts)]]></title>
            <link>https://github.com/coekie/flowtracker</link>
            <guid>41530190</guid>
            <pubDate>Fri, 13 Sep 2024 11:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/coekie/flowtracker">https://github.com/coekie/flowtracker</a>, See on <a href="https://news.ycombinator.com/item?id=41530190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">FlowTracker</h2><a id="user-content-flowtracker" aria-label="Permalink: FlowTracker" href="#flowtracker"></a></p>
<p dir="auto"><em>Track data flowing through Java programs, gain new understanding at a glimpse.</em></p>
<p dir="auto">FlowTracker is a Java agent that tracks how a program reads, manipulates, and writes data.
By watching a program run, it can show what file and network I/O happened, but more importantly connecting its inputs and outputs to show where its output came from.
This helps you understand what any Java program's output means and why it wrote it.</p>
<p dir="auto">This proof-of-concept explores what insights we get by looking at program behaviour from this perspective.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">Spring PetClinic is a demo application for the Spring framework.
To demonstrate FlowTracker's abilities, we let it observe PetClinic handling an HTTP request and generating an HTML page based on a template and data from a database.
You can use this demo in your browser, without installing anything.
Open the <a href="https://flowtracker-demo.coekie.com/petclinic/#Server%20socket/*/%2F127.0.0.1%3A*/Write" rel="nofollow">FlowTracker PetClinic demo</a>, or watch the video below.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description petclinic.mp4">petclinic.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/271022/352298644-af1af08e-0a7c-4d10-b105-c60d4222e13c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYyNDE3MDMsIm5iZiI6MTcyNjI0MTQwMywicGF0aCI6Ii8yNzEwMjIvMzUyMjk4NjQ0LWFmMWFmMDhlLTBhN2MtNGQxMC1iMTA1LWM2MGQ0MjIyZTEzYy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxM1QxNTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NTAyNTAwYmIwMWYwZTk0NjAwNDc3MGQ5NTZhMjlkMjQ5NTU3MDI0ZTNhNGRkMDYxNzhjZWE5NDk3ZmE4MmI3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tFdJnmlbL4dcWi2x4iKNe1_Jjc7HzkTLo72dtMWqzwI" data-canonical-src="https://private-user-images.githubusercontent.com/271022/352298644-af1af08e-0a7c-4d10-b105-c60d4222e13c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYyNDE3MDMsIm5iZiI6MTcyNjI0MTQwMywicGF0aCI6Ii8yNzEwMjIvMzUyMjk4NjQ0LWFmMWFmMDhlLTBhN2MtNGQxMC1iMTA1LWM2MGQ0MjIyZTEzYy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxM1QxNTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NTAyNTAwYmIwMWYwZTk0NjAwNDc3MGQ5NTZhMjlkMjQ5NTU3MDI0ZTNhNGRkMDYxNzhjZWE5NDk3ZmE4MmI3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tFdJnmlbL4dcWi2x4iKNe1_Jjc7HzkTLo72dtMWqzwI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You see the HTTP response that FlowTracker saw PetClinic send over the network.
Click on a part of the contents of the HTTP response to see in the bottom view where that part came from.
You can select another tracked origin/input or sink/output in the tree on the left (or bottom left button on mobile).</p>
<p dir="auto">Exploring this HTTP response, we navigate through multiple layers of the software stack:</p>
<ul dir="auto">
<li><strong>HTTP handling</strong> <em>FlowTracker shows what code produced what output</em>.
Click on "HTTP/1.1" or the HTTP headers. You see that this part of the response was generated by apache coyote (classes in the <code>org.apache.coyote</code> package), pointing you to where exactly each header came from.</li>
<li><strong>Thymeleaf templates</strong> <em>FlowTracker shows how the input the program reads (the HTML templates) corresponds to the output</em>.
Click on an HTML tag name, like "html" or "head". You see the <code>layout.html</code> file, where this part of the HTML page comes from.
If you click on <code>layout.html</code>, and then on the colorful <code>+</code> button at the bottom, then everything coming from that file will be marked in the same color.
Scrolling down you'll then notice part of the response comes from a different file, <code>ownerDetails.html</code>.
Click on a <code>&lt;</code> or <code>&gt;</code> to see that those characters were written by the Thymeleaf templating library.</li>
<li><strong>Database</strong>
The HTML page contains a table with information that comes from the database.
Clicking on <code>George</code> in that table does not only show that that value came from the database.
It goes further: it traced it all the way back to the SQL script that inserted that value in the database in first place.</li>
</ul>
<p dir="auto">In that demo, the tracking up to the SQL script works because it was using an in-memory database.
The database content never left the JVM, so FlowTracker could fully keep track of it.
When we run the same demo but with a mysql database, then we track those values up to the database connection: we see the SQL query sent before to produce them, and details of how the mysql jdbc driver talks to the database.
See <a href="https://flowtracker-demo.coekie.com/petclinic-mysql/#Server%20socket/*/%2F127.0.0.1%3A*/Write" rel="nofollow">FlowTracker PetClinic mysql demo</a>.
Notice that FlowTracker intercepts the decrypted contents sent over the SSL connection to the database.</p>
<p dir="auto">This Spring PetClinic demo is just an example.
FlowTracker does not depend on your application using any particular framework or library.</p>
<p dir="auto">Another demo, showing how by watching the java compiler, FlowTracker helps you understand the format of the generated class file and the bytecode in it:
<a href="https://flowtracker-demo.coekie.com/javac/#Files/home/coekie/flowtracker-demo/HelloWorld.class" rel="nofollow">javac demo</a>, <a href="https://github.com/user-attachments/assets/5884c8fd-342b-471e-b13d-a2fe7219e8e6">video</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Warning:
In its current state, FlowTracker is closer to a proof of concept than production ready.
It has proven itself to work well on a number of example programs, but it is not going to work well for everything, your mileage may vary.
Also be aware that it adds a lot of overhead, making programs run much slower.</p>
<p dir="auto">Download the FlowTracker agent jar from the <a href="https://github.com/coekie/flowtracker/releases">Github releases pages</a> (<code>flowtracker-*.jar</code> under "Assets").
Add the agent to your java command line: <code>-javaagent:path/to/flowtracker.jar</code>.
Disable some JVM optimizations that disrupt flowtracker by also adding the output of <code>java -jar flowtracker.jar jvmopts</code> to the command line.
By default, FlowTracker starts a webserver on port 8011, so open <a href="http://localhost:8011/" rel="nofollow">http://localhost:8011/</a> in your browser.</p>
<p dir="auto">For more detailed instructions, including configuration options, see <a href="https://github.com/coekie/flowtracker/blob/master/USAGE.md">USAGE.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works internally</h2><a id="user-content-how-it-works-internally" aria-label="Permalink: How it works internally" href="#how-it-works-internally"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Short version</h2><a id="user-content-short-version" aria-label="Permalink: Short version" href="#short-version"></a></p>
<p dir="auto">FlowTracker is an instrumenting agent.
The agent injects its code into class files (bytecode) when the JVM loads them.
That code maintains a mapping of in-memory data to its origin, while the program reads, passes around, and writes data.
The focus is on tracking textual and binary data (like Strings, char and byte arrays), not on numerical, structured or computed data.</p>
<p dir="auto">This achieved with a combination of:</p>
<ul dir="auto">
<li>Replacing some calls to JDK methods with calls to FlowTracker's version of those methods.</li>
<li>Injecting code into key places in the JDK, mostly to track input and output.</li>
<li>Dataflow analysis and deeper instrumentation within methods to track local variables and values on the stack.</li>
<li>Adding code before and after method invocations, and at the start and end of invoked methods, to track method arguments and return values using ThreadLocals.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data model: Trackers</h2><a id="user-content-data-model-trackers" aria-label="Permalink: Data model: Trackers" href="#data-model-trackers"></a></p>
<p dir="auto">Core classes and concepts of FlowTracker's data model:</p>
<ul dir="auto">
<li>Tracker: holds information about a tracked object's content and source:
<ul dir="auto">
<li>content: the data that passed through them. e.g. all bytes passed through an <code>InputStream</code> or <code>OutputStream</code>.</li>
<li>source: associate ranges of its content to their source ranges in other trackers. For example, for the bytes of a <code>String</code> that could be pointing to the range of the tracker of the <code>FileInputStream</code> that the <code>String</code> was read from; telling us from which file and where exactly in that file it came from.</li>
</ul>
</li>
<li>TrackerRepository: holds a large global <code>Map&lt;Object, Tracker&gt;</code> that associates interesting objects with their tracker.</li>
<li>TrackerPoint: Pointer to a position in a tracker, representing a single primitive value being tracked, e.g. the source of one <code>byte</code>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Basic instrumentation</h2><a id="user-content-basic-instrumentation" aria-label="Permalink: Basic instrumentation" href="#basic-instrumentation"></a></p>
<p dir="auto">To keep Trackers up-to-date, our instrumentation inserts calls to <em>hook</em> methods in flowtracker when some specific JDK methods are being called.</p>
<p dir="auto">The simplest example of that is for System.arraycopy.
We intercept that on the caller's side: Calls to <code>java.lang.System.arraycopy</code> are replaced with calls to <code>com.coekie.flowtracker.hook.SystemHook.arraycopy</code>.
For this and other instrumentation, we use the ASM bytecode manipulation library.
In <code>SystemHook</code> we call the real <code>arraycopy</code>, get the <code>Trackers</code> of the source and destination arrays from the <code>TrackerRepository</code>, and update the target <code>Tracker</code> to point to its source.</p>
<p dir="auto">For example, given this code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="char[] abc = ...; char[] abcbc = new char[5];
System.arraycopy(abc, 0, abcbc, 0, 3);
System.arraycopy(abc, 1, abcbc, 3, 2);"><pre><span>char</span>[] <span>abc</span> = ...; <span>char</span>[] <span>abcbc</span> = <span>new</span> <span>char</span>[<span>5</span>];
<span>System</span>.<span>arraycopy</span>(<span>abc</span>, <span>0</span>, <span>abcbc</span>, <span>0</span>, <span>3</span>);
<span>System</span>.<span>arraycopy</span>(<span>abc</span>, <span>1</span>, <span>abcbc</span>, <span>3</span>, <span>2</span>);</pre></div>
<p dir="auto">This gets rewritten to the following.
Note that instrumentation happens on bytecode, not source code, but we show equivalent source code here because that's much easier to read.</p>
<div dir="auto" data-snippet-clipboard-copy-content="char[] abc = ...; char[] abcbc = new char[5];
SystemHook.arraycopy(abc, 0, abcbc, 0, 3);
SystemHook.arraycopy(abc, 1, abcbc, 3, 2);"><pre><span>char</span>[] <span>abc</span> = ...; <span>char</span>[] <span>abcbc</span> = <span>new</span> <span>char</span>[<span>5</span>];
<span>SystemHook</span>.<span>arraycopy</span>(<span>abc</span>, <span>0</span>, <span>abcbc</span>, <span>0</span>, <span>3</span>);
<span>SystemHook</span>.<span>arraycopy</span>(<span>abc</span>, <span>1</span>, <span>abcbc</span>, <span>3</span>, <span>2</span>);</pre></div>
<p dir="auto">After executing this, the tracker for abcbc would look like: <code>{[0-2]: {tracker: abcTracker, sourceIndex: 0, length: 3}, [3-4]: {tracker: abcTracker, sourceIndex: 1, length: 2}}</code></p>
<p dir="auto">That was an example of a hook on the caller side.
But most calls to <em>hook</em> methods are added on the callee side, inside the methods in the JDK.
For example take <code>FileInputStream.read(byte[])</code>, which reads data from a File and stores the result in the provided <code>byte[]</code>.
We add the call to our hook method (<code>FileInputStreamHook.afterReadByteArray</code>) at the end of the <code>FileInputStream.read(byte[])</code> method.
We have our own instrumentation micro-framework for that, driven by annotations, implemented using ASM's <code>AdviceAdapter</code>.</p>
<p dir="auto">That way we add hooks to a number of classes in the JDK responsible for input and output, such as <code>java.io.FileInputStream</code>, <code>java.io.FileOutputStream</code>, and internal classes like <code>sun.nio.ch.FileChannelImpl</code>, <code>sun.nio.ch.IOUtil</code>, <code>sun.nio.ch.NioSocketImpl</code> and more.</p>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/SystemHook.java">SystemHook</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/FileInputStreamHook.java">FileInputStreamHook</a>,
and other classes in the <a href="https://github.com/coekie/flowtracker/tree/master/core/src/main/java/com/coekie/flowtracker/hook">hook package</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Primitive values, dataflow analysis</h2><a id="user-content-primitive-values-dataflow-analysis" aria-label="Permalink: Primitive values, dataflow analysis" href="#primitive-values-dataflow-analysis"></a></p>
<p dir="auto">A bigger challenge is tracking primitive values.
Consider this example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="byte[] x; byte[] y;
// ...
byte b = x[1];
// ...
y[2] = b;"><pre><span>byte</span>[] <span>x</span>; <span>byte</span>[] <span>y</span>;
<span>// ...</span>
<span>byte</span> <span>b</span> = <span>x</span>[<span>1</span>];
<span>// ...</span>
<span>y</span>[<span>2</span>] = <span>b</span>;</pre></div>
<p dir="auto">When that code is executed, we would need to update the Tracker of <code>y</code>, to remember that the value at index 2 comes from the value at index 1 in <code>x</code>.
If those had been <code>String[]</code>s and <code>b</code> was a <code>String</code> instead of a <code>byte</code>, then we wouldn't need to modify code like this, because the TrackerRepository would know what the Tracker of the String is, and keeps that association no matter how that String object is passed around.
But the TrackerRepository can't keep a mapping of primitive values like bytes to Trackers, because primitive values don't have an identity: any <code>Map</code> having a byte as key would mix up different occurrences of the same byte.
Instead, we store the association of <code>b</code> to its tracker in a local variable in the method itself.
The code gets rewritten to roughly something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="byte[] x; byte[] y;
// ...
byte b = x[1];
TrackerPoint bTracker = ArrayHook.getElementTracker(x, 1);
// ...
y[2] = b;
ArrayHook.setElementTracker(y, 2, bTracker);"><pre><span>byte</span>[] <span>x</span>; <span>byte</span>[] <span>y</span>;
<span>// ...</span>
<span>byte</span> <span>b</span> = <span>x</span>[<span>1</span>];
<span>TrackerPoint</span> <span>bTracker</span> = <span>ArrayHook</span>.<span>getElementTracker</span>(<span>x</span>, <span>1</span>);
<span>// ...</span>
<span>y</span>[<span>2</span>] = <span>b</span>;
<span>ArrayHook</span>.<span>setElementTracker</span>(<span>y</span>, <span>2</span>, <span>bTracker</span>);</pre></div>
<p dir="auto">To do that FlowTracker needs to understand how exactly values flow through a method.
We build upon ASM's analysis support to analyze the code (<em>symbolic interpretation</em>).
That way we construct a model of where values in local variables and on the stack come from at every point in the method, and where they end up.</p>
<p dir="auto">This is implemented in</p>
<ul dir="auto">
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowValue.java">FlowValue</a> and its subclasses (e.g. <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ArrayLoadValue.java">ArrayLoadValue</a>) that model where values come from, and can generate the instructions that create the TrackerPoints that point to that source.
A particularly interesting one is <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/MergedValue.java">MergedValue</a>, which handles situations where because of control flow (e.g. if-statements, loops) a value can come from multiple possible places.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowInterpreter.java">FlowInterpreter</a>: extension of ASM's <code>Interpreter</code>, <em>interprets</em> bytecode instructions, creates the appropriate <code>FlowValue</code>s.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/Store.java">Store</a> and its subclasses (e.g. <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ArrayStore.java">ArrayStore</a>) that represent places that FlowValues go to, that consume the TrackerPoints.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowTransformer.java">FlowTransformer</a>: drives the whole analysis and instrumentation process. See its docs for a more detailed walkthrough of how this all fits together.</li>
</ul>
<p dir="auto">We don't track the source of <em>all</em> primitive values.
The focus is on <code>byte</code> and <code>char</code> values, and to a lesser extent <code>int</code>s and <code>long</code>s.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Method invocations</h2><a id="user-content-method-invocations" aria-label="Permalink: Method invocations" href="#method-invocations"></a></p>
<p dir="auto">The dataflow analysis from the previous section is limited to handling flow of primitive values within a single method.
Those values also flow into other methods, as arguments and return values of method invocations.
We model that in <code>Invocation</code>, which stores <code>PointTracker</code>s for arguments and return values.
The <code>Invocation</code> is stored in a <code>ThreadLocal</code> just before a method invocation, and retrieved at the start of the implementation of the method.</p>
<p dir="auto">For example, take this code passing a primitive value to a "write" method:</p>
<div dir="auto" data-snippet-clipboard-copy-content="void caller() {
  byte b = ...;
  out.write(b);  
}

...

class MyOutputStream {
  void write(byte value) {
    ... // do something with value
  }
}"><pre><span>void</span> <span>caller</span>() {
  <span>byte</span> <span>b</span> = ...;
  <span>out</span>.<span>write</span>(<span>b</span>);  
}

...

<span>class</span> <span>MyOutputStream</span> {
  <span>void</span> <span>write</span>(<span>byte</span> <span>value</span>) {
    ... <span>// do something with value</span>
  }
}</pre></div>
<p dir="auto">To get the TrackerPoint of <code>b</code> into the <code>write</code> method, the code is instrumented like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="void caller() {
  byte b = ...;
  TrackerPoint bTracker = ...;
  Invocation.create(&quot;write(byte)&quot;)
    .setArg(0, bTracker)
    // this puts the Invocation in the ThreadLocal
    .calling(); 
  out.write(b);  
}

...

class MyOutputStream {
  void write(byte value) {
    // this extracts the Invocation from the ThreadLocal
    Invocation invocation = Invocation.start(&quot;write(byte)&quot;);
    TrackerPoint valueTracker = invocation.getArg0();
    ... // do something with value &amp; valueTracker
  }
}"><pre><span>void</span> <span>caller</span>() {
  <span>byte</span> <span>b</span> = ...;
  <span>TrackerPoint</span> <span>bTracker</span> = ...;
  <span>Invocation</span>.<span>create</span>(<span>"write(byte)"</span>)
    .<span>setArg</span>(<span>0</span>, <span>bTracker</span>)
    <span>// this puts the Invocation in the ThreadLocal</span>
    .<span>calling</span>(); 
  <span>out</span>.<span>write</span>(<span>b</span>);  
}

...

<span>class</span> <span>MyOutputStream</span> {
  <span>void</span> <span>write</span>(<span>byte</span> <span>value</span>) {
    <span>// this extracts the Invocation from the ThreadLocal</span>
    <span>Invocation</span> <span>invocation</span> = <span>Invocation</span>.<span>start</span>(<span>"write(byte)"</span>);
    <span>TrackerPoint</span> <span>valueTracker</span> = <span>invocation</span>.<span>getArg0</span>();
    ... <span>// do something with value &amp; valueTracker</span>
  }
}</pre></div>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/Invocation.java">Invocation</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationArgStore.java">InvocationArgStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationArgValue.java">InvocationArgValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationReturnStore.java">InvocationReturnStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationReturnValue.java">InvocationReturnValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationOutgoingTransformation.java">InvocationOutgoingTransformation</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationIncomingTransformation.java">InvocationIncomingTransformation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code as origin</h2><a id="user-content-code-as-origin" aria-label="Permalink: Code as origin" href="#code-as-origin"></a></p>
<p dir="auto">There are two main types of tracked origins of data.
There is I/O, which is tracked as explained in the "Basic instrumentation" section.
And there are values coming from the code itself, such as primitive and String constants (<code>'a'</code>, <code>"abc"</code>).
For those, we create a tracker for each class (a <code>ClassOriginTracker</code>), that contains a textual representation of that class and the constants that it references.
When those constants are referenced, we then point the trackers for those values at the corresponding place in that textual representation.
That is <em>as if</em> our textual representation of the class is where the values were read from.
That makes our model for constants look very similar to how we model I/O.</p>
<p dir="auto">For example for this code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyClass {
  void myMethod() {
    char a = 'x';
    ... // do something with a
  }
}"><pre><span>class</span> <span>MyClass</span> {
  <span>void</span> <span>myMethod</span>() {
    <span>char</span> <span>a</span> = <span>'x'</span>;
    ... <span>// do something with a</span>
  }
}</pre></div>
<p dir="auto">We generate a <code>ClassOriginTracker</code> with content that looks like this:</p>
<div data-snippet-clipboard-copy-content="class MyClass
void myMethod():
  (line 3): x"><pre><code>class MyClass
void myMethod():
  (line 3): x
</code></pre></div>
<p dir="auto">And the code gets rewritten to something like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyClass {
  void myMethod() {
    char a = 'x';
    TrackerPoint aTracker = ConstantHook.constantPoint(
      1234 /* id for MyClass*/,
      81 /* offset of 'x' in the ClassOriginTracker content */);
    
    ... // do something with a and aTracker
  }
}"><pre><span>class</span> <span>MyClass</span> {
  <span>void</span> <span>myMethod</span>() {
    <span>char</span> <span>a</span> = <span>'x'</span>;
    <span>TrackerPoint</span> <span>aTracker</span> = <span>ConstantHook</span>.<span>constantPoint</span>(
      <span>1234</span> <span>/* id for MyClass*/</span>,
      <span>81</span> <span>/* offset of 'x' in the ClassOriginTracker content */</span>);
    
    ... <span>// do something with a and aTracker</span>
  }
}</pre></div>
<p dir="auto">For performance reasons, we actually use ConstantDynamic (<a href="https://openjdk.org/jeps/309" rel="nofollow">JEP 309</a>) to ensure that the <code>constantPoint</code> methods are only invoked once instead of every time <code>myMethod</code> executes.</p>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/ClassOriginTracker.java">ClassOriginTracker</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantValue.java">ConstantValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantsTransformation.java">ConstantsTransformation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">String literals</h2><a id="user-content-string-literals" aria-label="Permalink: String literals" href="#string-literals"></a></p>
<p dir="auto">For String literals, we create a new copy of the String, and associate the content of the String (the <code>byte[]</code> in <code>String.value</code>) with the <code>ClassOriginTracker</code>.
A statement like <code>String s = "abc";</code> gets rewritten to <code>String s = StringHook.constantString("abc", 1234, 81);</code>.
This breaks a guarantee that the JVM normally provides, that all String constants are <em>interned</em>: all occurrences of the same String constant should refer to the same instance.
Most code doesn't actually rely on String interning, but code that does would get broken by our instrumentation.
We avoid most of the issues that could cause because:</p>
<ul dir="auto">
<li>We use ConstantDynamic, so the same String literal (at the same line of code) executed multiple times still gives the same instance every time.</li>
<li>We rewrite some <code>stringA == stringB</code> expressions as <code>Objects.equals(stringA, stringB)</code>, so that from some points of view they look like the same instance again.</li>
<li>We disable tracking of String literals in some packages (such as <code>java.lang.*</code>). This is configurable (see <code>breakStringInterning</code> in <a href="https://github.com/coekie/flowtracker/blob/master/USAGE.md">USAGE.md</a>).</li>
</ul>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringLdc.java">StringLdc</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantsTransformation.java">ConstantsTransformation</a>
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringComparison.java">StringComparison</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Fallback for untracked values</h2><a id="user-content-fallback-for-untracked-values" aria-label="Permalink: Fallback for untracked values" href="#fallback-for-untracked-values"></a></p>
<p dir="auto">FlowTracker does not track every value in the program.
That is partly because of performance concerns, partly because we just haven't implemented everything we would want, and partly because it just doesn't seem relevant or would require building a more complicated data model where values can come from a combination of places (e.g. calculated numerical values).
When values that are not being tracked end up in places where we do want to start tracking them, then we treat them similar to constants: we add a link to the <code>ClassOriginTracker</code>, to where they became tracked, represented there as <code>"&lt;?&gt;"</code>.
For example, lengths of arrays are values that are not tracked, so suppose a method calls <code>write(array.length)</code>, then in that <code>Invocation</code> we pass a <code>PointTracker</code> that refers to that place in the code where the <code>write</code> method is called.</p>
<p dir="auto">In practice, the result of that is when you look at some output, particularly if it's in a binary format, while you don't see where a value originally came from, you can often still quickly decipher what it means (e.g. "that value just before that tracked String points to <code>write(array.length)</code>, so that must be the length of that String").</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More</h2><a id="user-content-more" aria-label="Permalink: More" href="#more"></a></p>
<p dir="auto">More topics about the implementation that could be talked about, but didn't make the cut. Most of this is documented in the code, if you really want to learn more:</p>
<ul dir="auto">
<li>Details of <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/MergedValue.java">MergedValue</a>: the hardest part of dataflow analysis, how to instrument code to keep track of values through branches and loops.</li>
<li>How we hook String concatenation through its indification (<a href="https://openjdk.org/jeps/280" rel="nofollow">JEP 280</a>) by adding hooks to the MethodHandles returned by StringConcatFactory in <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringConcatenation.java">StringConcatenation</a> and <a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/StringConcatFactoryHook.java">StringConcatFactoryHook</a>.</li>
<li>Finding the source code, decompiling with Vineflower, associating bytecode with source code lines.
See <a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/SourceCodeGenerator.java">SourceCodeGenerator</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/VineflowerCodeGenerator.java">VineflowerCodeGenerator</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/AsmCodeGenerator.java">AsmCodeGenerator</a>.</li>
<li>The ClassLoader setup. How we avoid dependencies on the bootclasspath colliding with the app, without shading (because that makes debugging annoying) and without nested jars.
Development setup that allows changing an agent without repackaging it, to ensure fast development cycles.
See <a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/FlowTrackerAgent.java">FlowTrackerAgent</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/DevAgent.java">DevAgent</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/SpiderClassLoader.java">SpiderClassLoader</a>.</li>
<li>How class loading can intervene with tracking of method invocations, and how we work around that.
See <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/SuspendInvocationTransformer.java">SuspendInvocationTransformer</a>,
<a href="https://github.com/coekie/flowtracker/blob/72ab61da96cbbb236a7395f9226f1797fa851892/core/src/main/java/com/coekie/flowtracker/tracker/Invocation.java#L163-L189">Invocation#suspend</a>.
<em>Interesting problem, simple solution kinda obvious in retrospect.</em></li>
<li>Tracking of primitive values stored in fields:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/FieldRepository.java">FieldRepository</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FieldStore.java">FieldStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FieldValue.java">FieldValue</a>.
<em>Just more of the same, nothing surprising.</em></li>
<li>How we add comments into instrumented code to help understand and debug instrumentation. <em>ASM/Bytecode doesn't support comments, but that won't stop me!</em></li>
<li>Avoiding circularity problems when instrumenting core JDK classes. <em>I eat <code>ClassCircularityError</code>s and <code>StackOverFlowError</code>s for breakfast</em>.</li>
<li>Front-end: Web server with jetty, JAX-RS. Web UI built with Svelte. <em>Beautiful UI design by... nobody.</em></li>
<li>Our optimized ThreadLocal abomination in <code>ContextSupplier</code>. <em>On second thought, never mind, you don't want to know.</em></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Entire staff of game publisher Annapurna Interactive has reportedly resigned (392 pts)]]></title>
            <link>https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns</link>
            <guid>41528266</guid>
            <pubDate>Fri, 13 Sep 2024 05:34:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns">https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns</a>, See on <a href="https://news.ycombinator.com/item?id=41528266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Annapurna Interactive, the game company famous for publishing indie hits like <a href="https://www.theverge.com/2022/7/18/23220428/stray-video-game-review-ps4-ps5-steam"><em>Stray</em></a>, <a href="https://www.polygon.com/2019/12/13/21011871/outer-wilds-goty-best-games-of-the-year"><em>Outer Wilds</em></a>, <a href="https://www.theverge.com/2017/12/14/16774194/gorogoa-game-review-iphone-switch-steam"><em>Gorogoa</em></a>, <a href="https://www.theverge.com/23169390/neon-white-review-steam-nintendo-switch"><em>Neon White</em></a>, <a href="https://www.theverge.com/2017/3/24/15042182/what-remains-of-edith-finch-preview-interview"><em>What Remains of Edith Finch</em></a><em>,</em> <a href="https://en.wikipedia.org/wiki/Annapurna_Interactive#Games_published">and many more</a>, may not be the same company anymore. </p></div><p><a href="https://www.bloomberg.com/news/articles/2024-09-12/annapurna-video-game-team-resigns-leaving-partners-scrambling?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcyNjE3NzQyOSwiZXhwIjoxNzI2NzgyMjI5LCJhcnRpY2xlSWQiOiJTSlBZWklUMEFGQjQwMCIsImJjb25uZWN0SWQiOiJCMUVBQkI5NjQ2QUM0REZFQTJBRkI4MjI1MzgyQTJFQSJ9.BpoA_wBJDrNbDbgj_LjnVUJQg6SM_vsIzWUEM6v85xE"><em>Bloomberg </em>reports</a> that the entire staff of Annapurna Interactive, the gaming division of Megan Ellison’s Annapurna, has resigned after failing to convince Ellison to let them spin off its games division into a new company. <a href="https://www.ign.com/articles/annapurnas-entire-gaming-team-has-resigned"><em>IGN </em>is corroborating the report</a>. </p><p>“All 25 members of the Annapurna Interactive team collectively resigned,’’ former president Nathan Gary and staffers told <em>Bloomberg. </em>“This was one of the hardest decisions we have ever had to make and we did not take this action lightly.”</p><p>An Annapurna spokesperson told <em>Bloomberg</em> that existing games and projects will remain under the company. Annapurna didn’t immediately reply to a request for comment from <em>The Verge</em>. </p><p>Last week, <a href="https://www.hollywoodreporter.com/movies/movie-news/annapurna-president-nathan-gary-exits-1235993653/"><em>The Hollywood Reporter</em> said</a> that Gary and the coheads of Annapurna Interactive, Deborah Mars and Nathan Vella,&nbsp;would be leaving. <em>THR</em> also reported that Annapurna planned to “integrate its in-house gaming operations with the rest of Annapurna’s divisions, which include film, TV and theater.” Hector Sanchez, who most recently headed up the Unreal Engine games business at Epic Games<strong> </strong>and is an Annapurna Interactive cofounder, <a href="https://www.linkedin.com/feed/update/urn:li:activity:7232373566179094528/">announced last month</a> that he would be president of interactive and new media at Annapurna.</p><p>Annapurna Pictures, the company’s film arm, has won countless awards for a variety of films, including <em>Her</em>,&nbsp;<em>American Hustle</em>, and&nbsp;<em>Zero Dark Thirty, </em>and the company had only been expanding its ambitions alongside its video game publishing hot streak. </p><div><p>In 2020, Annapurna announced that it would <a href="https://www.theverge.com/2020/10/29/21540676/annapurna-games-indie-publisher-development-studio">begin developing its own games, too</a>; it launched <a href="https://www.theverge.com/2022/12/1/23487911/annapurna-animation-nimona-andrew-millstein-robert-baird">an in-house animation division in 2022</a>, one that soon announced <a href="https://www.theverge.com/2023/9/5/23859805/stray-movie-cat-video-game-annapurna-interactive-animation">a movie based on <em>Stray</em></a>. Annapurna Pictures produced the <a href="https://www.theverge.com/2023/5/18/23728236/nimona-teaser-trailer">excellent animated film <em>Nimona</em></a> for Netflix, and it just last month partnered with Remedy Entertainment to begin exploring <a href="https://www.theverge.com/2024/8/29/24231469/control-sequel-movie-tv-remedy-annapurna">film and TV adaptations of <em>Control</em> and <em>Alan Wake</em></a>. </p></div><p>This year, Annapurna Interactive published <a href="https://www.theverge.com/24157530/lorelei-and-the-laser-eyes-review-switch-steam"><em>Lorelei and the Laser Eyes</em></a> and <a href="https://www.theverge.com/24119962/open-roads-annapurna-xbox-ps5-switch-steam"><em>Open Roads</em></a>; upcoming games include its own developed <em>Blade Runner 2033: Labyrinth </em>as well as<em> Ghost Bike</em> and <em>Wanderstop</em>. </p><p><strong>Update, September 12th: </strong>Added Gary’s statement to <em>Bloomberg </em>about how all 25 staffers have resigned.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing workers vote to strike in resounding defeat for troubled company (524 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/</link>
            <guid>41528075</guid>
            <pubDate>Fri, 13 Sep 2024 04:41:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/">https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/</a>, See on <a href="https://news.ycombinator.com/item?id=41528075">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>