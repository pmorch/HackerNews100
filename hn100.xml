<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 18 May 2025 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ditching Obsidian and building my own (121 pts)]]></title>
            <link>https://amberwilliams.io/blogs/building-my-own-pkms</link>
            <guid>44022448</guid>
            <pubDate>Sun, 18 May 2025 16:21:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://amberwilliams.io/blogs/building-my-own-pkms">https://amberwilliams.io/blogs/building-my-own-pkms</a>, See on <a href="https://news.ycombinator.com/item?id=44022448">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><blockquote><p>"You can’t really know where you are going until you know where you have been." - Maya Angelou. </p></blockquote><p>The age-old mission to capture and make sense of our knowledge and experiences echoes through history, from Thomas Jefferson's Commonplace book detailing his ideas on government to Marcus Aurelius's Meditations saturated with quotations and personal reflections.</p><p>However, this pursuit to preserve knowledge isn't without its own set of fears. Are our deepest thoughts private? Are we spending a disproportionate time customizing our notes system than benefiting from it? Will our preferred notes system last the sands of time? </p><p>These were the questions that motivated me to step outside conventional offerings and build my own solution. I'm sharing my story here not to prescribe, but to demonstrate it's okay to color outside the lines. Perhaps my journey to create a simple, secure, and lasting 'note vault' will spark ideas for how you can better cultivate your own knowledge garden.</p><h2 id="conventional-knowledge-gardens"><span>Conventional<!-- --> </span><span>knowledge<!-- --> </span><span>gardens<!-- --> </span></h2><p>A personal knowledge management systems (PKMS), also known as "second brain" is are central repositories for actively collecting one's meaningful insights, ideas and inspirations encountered throughout life. The benefit of decades of notes accruing and reinforcing knowledge is immense. That is why critically analyzing what you need your PKMS to achieve is crucial. </p><p>The most commonly used PKMS or note-taking apps today are Notion, Obsidian, Evernote and Logseq. The problem is that PKMS come and go. Could you see yourself using your note-taking app you use today in 30 years? Probably not. Do you ever have concerns around the privacy of your notes? Are you spending more time setting up your notes system rather than managing your notes? What does an effective and timeless PKMS even look like?</p><h2 id="pulling-at-a-thread"><span>Pulling<!-- --> </span><span>at<!-- --> </span><span>a<!-- --> </span><span>thread<!-- --> </span></h2><p>My PKMS journey started with Obsidian. For those unfamiliar with Obsidian, it's a digital notebook that lives only on your computer. Its special feature is letting you internally link related notes together similar to Wikipedia. Beyond linking, its true power comes from the huge range of plugins. Out of all the great community plugins, Dataview is my personal favorite. <a target="_blank" rel="noreferrer" href="https://obsidian.rocks/dataview-in-obsidian-a-beginners-guide/">Dataview</a> is a powerful scripting tool which pulls data from markdown notes to generate tables, graphs, and other insights.</p><p>Obsidian was a great tool for me personally for a long time. But I felt frustrated when I wanted to access my notes on my phone while on-the-go and saw that I had to pay for this feature. Obsidian charges $8 a month to access the same notes across multiple devices. While not a huge amount for such a useful app, it adds up to an eye-watering amount - almost $1,000 if I planned to use Obsidian for a decade. I was surprised at this fee because I thought Obsidian was open-source. I later realized that the Obsidian community plugins are open-source, but Obsidian itself is, in fact, not. These were the same plugins I was spending an inordinate abount of time <a target="_blank" rel="noreferrer" href="https://github.com/s-blu/obsidian_dataview_example_vault/blob/b6740b4d8a7e0b408669563e1b3c4028df36e207/20%20Dataview%20Queries/Show%20a%20Goals%20Overview%20with%20progress%20bars%20for%20included%20projects%20and%20overall%20progress.md">personalizing Obsidian with</a>, rather than being productive.</p><p>I started to have concerns about the longevity of the plugins and app itself. Some of you may remember when Evernote aggressively limited free users to <a target="_blank" rel="noreferrer" href="https://henry-chong.com/blog/the-downfall-of-evernote/">50 notes</a>, many users migrated their notes elsewhere. I was one of those users.</p><p>After some mental gymnastics weighing if I should continue with Obsidian, I found solace when asking myself <em>"Can I see myself using this in 20 years?"</em>. I couldn't. The thought of cyclically migrating notes from one PKMS to another every 5 years, as I had done from Evernote to Notion to Obsidian, made me feel tired. So I grabbed some coffee and began my search for the digital equivalent of the <a target="_blank" rel="noreferrer" href="https://en.wikipedia.org/wiki/Svalbard_Global_Seed_Vault">Svalbard Global Seed Vault</a>, but for my notes.</p><h2 id="my-perfect-note-vault"><span>My<!-- --> </span><span>perfect<!-- --> </span><span>note<!-- --> </span><span>vault<!-- --> </span></h2><p>Key requirements were that my new PKMS needed to be easy to use, offer a plugin-like experience and be secure. Privacy and security were paramount. I didn't want my innermost thoughts being exposed to a <a target="_blank" rel="noreferrer" href="https://en.wikipedia.org/wiki/23andMe_data_leak">23andMe data leak</a> scenario. Data security aside, I have a hard time trusting for-profit companies will keep their hands out of the cookie jar. I can imagine there's a killing to be made from targeted advertisements online using your notes or for them to be used to train AI. I wanted to know with certainty that I control my data. Entrusting a company to store my notes for free, couldn't give me that assurance.</p><p>Being a full-stack software engineer, the answer was obvious. I should step outside the commercial-PKM ecosystem entirely - I should build my own.</p><p>But if it's so obvious, why aren't other developers rolling out their own PKMS? Perhaps I'm the first to discover this or perhaps developers aren't writing about their custom PKMS. My guess is that commercial note-taking apps have larger, more vocal communities that drown out the murmurings of other DIY solutions.</p><p>It was here I decided to pull the trigger to build and host my own PKMS. It felt pertinent to write about it so others feel confident to do so too. Spoiler - it sounds like a daunting feat, but in reality it was so comically easy my only regret is that I hadn't done it years ago.</p><h2 id="the-note-vault"><span>The<!-- --> </span><span>note<!-- --> </span><span>vault<!-- --> </span></h2><p>Here's how my PKMS looks as of writing. I can create a note, update it in markdown format and then preview what the note looks like in rendered markdown.</p><p><img alt="gif using the PKMS's markdown editor" src="https://notes.holeytriangle.com/assets/0f1cfdfb-ed3d-450e-8701-8ef7a9f2d7a5"></p><p>Finally, I can access my notes from my phone too, right where I left off. No monthly fees for this feature either.</p><p><img alt="Using the PKMS from my phone with a thumbs up sign" src="https://notes.holeytriangle.com/assets/e12f4587-b8a5-4739-9b16-7e925037ac9b"></p><p>Since my PKMS is hosted online to manage notes across devices, I have multiple layers of security to ensure my notes are kept private.</p><p><img alt="the PKMS's login screen with an empty form" src="https://notes.holeytriangle.com/assets/c42ab6b2-4eae-4956-b886-50d70aacba70"></p><p>And if I ever want to move to greener pastures, all my notes are stored in Markdown so I can export them with two command lines to my terminal. Here's an under-the-hood view of how my notes are stored in the database - just text! <a target="_self" rel="noreferrer" href="#1"><sup>1</sup></a></p><p><img alt="shows the markdown output from a database query" src="https://notes.holeytriangle.com/assets/2847aa38-5356-4e1d-80d9-feb5e738eee2"></p><h2 id="benefits-of-a-note-vault"><span>Benefits<!-- --> </span><span>of<!-- --> </span><span>a<!-- --> </span><span>note<!-- --> </span><span>vault<!-- --> </span></h2><p>I've found that consistently collecting and reviewing valuable information promotes a deeper engagement with ideas. As a result, I've noticed my memory improving, and I started seeing surprising links between seemingly unrelated topics. Plus, it's created this incredible record of my learning and personal growth.</p><p>I found Ryan Holiday's take on the <a target="_blank" rel="noreferrer" href="https://ryanholiday.net/how-and-why-to-keep-a-commonplace-book/">Commonplace Book</a> particularly insightful for efficiently using a PKM. While Ryan advocates for analog notes, the same principles can be applied to digital notes. While physical writing has its merits, digital notes provide superior search capabilities and flexible organization. Ryan himself states how impracticability of a physical PKMS - "Because mine is a physical box with literally thousands of cards, I don’t carry the whole thing with me". </p><p><img alt="Illustration featuring a system for filing notes" src="https://notes.holeytriangle.com/assets/85ba3989-f61c-4f4f-8764-b1f8c267cbaa"></p><p><small><center>Image sourced from Houghton Library, Public domain, via Wikimedia Commons</center></small></p><p>And that's the beauty of a digital PKMS – it all fits on my phone!</p><p>Additonally, now with AI code generation creating custom PKMS plugins are more accessible than ever before. No longer do we need to install a random developer's plugin that sends our private thoughts who knows where. We can vibe-code our own or use open-source tooling. I used to use an Obsidian plugin to pull uncompleted tasks from todo checklists that were scattered around various notes, but after 10 minutes of prompting Anthropic's Claude, I had my own private equivalent tool.</p><h2 id="a-look-inside"><span>A<!-- --> </span><span>look<!-- --> </span><span>inside<!-- --> </span></h2><p>Using essentially a wrapper around a database made creating my PKMS easy. This wrapper does the heavy lifting, keeping things simple and secure. I went with an open-source platform called <a target="_blank" rel="noreferrer" href="https://directus.io/">Directus</a>, which can be used as a PKMS amongst other things such as a CMS. Directus has authentication and security layers already included, so I was able to start using it in less than a day.</p><p>For readers who have worked with SQL databases or docker containers - I wrote a <a target="_blank" rel="noreferrer" href="https://amberwilliams.io/blogs/the-last-note-system">step-by-step guide on building my own PKMS with Directus</a>.</p><h2 id="a-final-note"><span>A<!-- --> </span><span>final<!-- --> </span><span>note<!-- --> </span></h2><p>I’ve always believed that, much like a garden, how we manage our own knowledge system needs cultivation and continuity to flourish. My own knowledge garden was cultivated from a deep dive into the subject of note systems, driven by a search for a solution to those nagging frustrations I think many of us feel with commercialized systems.</p><p>A knowledge garden isn't always straightforward, and I'll be the first to admit I’ve been guilty of spending considerably more time fiddling with a system, rather than actually using it. It's easy  to fall into analysis paralysis with these system as well as become plagued with paranoia worrying about privacy. So for any system to stick, it has to be genuinely secure and simple.</p><p>There isn't a one-size-fits-all approach to a sizeable amount of things in life, knowledge management being one of these. Inquisitive individuals are likely to be rewarded for exploring different avenues, even unconventional ones, as they lead to a system tailored to one's personal way of thinking and working.</p><p>The path I eventually took, building my own, put an end to exhausting cyclical migrations. It helped me reclaim control over my privacy, and significantly cut down on recurring costs. Especially because it's ran from <a target="_blank" rel="noreferrer" href="https://amberwilliams.io/blogs/vps-for-web-apps">my own VPS</a>. Commercial apps certainly offer out-of-the-box convenience, but by stepping back and focusing on what mattered to me, I found a way that worked profoundly better. <a target="_blank" rel="noreferrer" href="https://amberwilliams.io/blogs/the-last-note-system">Here's how I built my PKMS step-by-step</a>. </p><p>After dogfooding my PKMS for over a year now, I'm capturing and connecting ideas more efficiently than I ever managed with commercial apps. While I sometimes miss the community around commercial apps, I'm hopeful I'll find a niche community of like minded individuals one day. </p><p>If my PKMS journey has resonated with you, or if you're on a similar path, I'd genuinely love to connect. You can find me at any of the socials in the footer.</p><hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I modeled the Voynich Manuscript with SBERT to test for structure (202 pts)]]></title>
            <link>https://github.com/brianmg/voynich-nlp-analysis</link>
            <guid>44022353</guid>
            <pubDate>Sun, 18 May 2025 16:09:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/brianmg/voynich-nlp-analysis">https://github.com/brianmg/voynich-nlp-analysis</a>, See on <a href="https://news.ycombinator.com/item?id=44022353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">📜 Voynich Manuscript Structural Analysis</h2><a id="user-content--voynich-manuscript-structural-analysis" aria-label="Permalink: 📜 Voynich Manuscript Structural Analysis" href="#-voynich-manuscript-structural-analysis"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔍 Overview</h2><a id="user-content--overview" aria-label="Permalink: 🔍 Overview" href="#-overview"></a></p>
<p dir="auto">This started as a personal challenge to figure out what modern NLP could tell us about the Voynich Manuscript — without falling into translation speculation or pattern hallucination. I'm not a linguist or cryptographer. I just wanted to see if something as strange as Voynichese would hold up under real language modeling: clustering, POS inference, Markov transitions, and section-specific patterns.</p>
<p dir="auto">Spoiler: it kinda did.</p>
<p dir="auto">This repo walks through everything — from suffix stripping to SBERT embeddings to building a lexicon hypothesis. No magic, no GPT guessing. Just a skeptical test of whether the manuscript has <em>structure that behaves like language</em>, even if we don’t know what it’s saying.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧠 Why This Matters</h2><a id="user-content--why-this-matters" aria-label="Permalink: 🧠 Why This Matters" href="#-why-this-matters"></a></p>
<p dir="auto">The Voynich Manuscript remains undeciphered, with no agreed linguistic or cryptographic solution. Traditional analyses often fall into two camps: <em>statistical entropy checks</em> or <em>wild guesswork</em>. This project offers a middle path — using computational linguistics to assess whether the manuscript encodes real, structured language-like behavior.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📁 Project Structure</h2><a id="user-content--project-structure" aria-label="Permalink: 📁 Project Structure" href="#-project-structure"></a></p>
<div data-snippet-clipboard-copy-content="/data/
  AB.docx                         # Full transliteration with folio/line tags
  voynichese/                     # Root word .txt files
  stripped_cluster_lookup.json    # Cluster ID per stripped root
  unique_stripped_words.json      # All stripped root forms
  voynich_line_clusters.csv       # Cluster sequences per line

/scripts/
  cluster_roots.py                # SBERT clustering + suffix stripping
  map_lines_to_clusters.py        # Maps manuscript lines to cluster IDs
  pos_model.py                    # Infers grammatical roles from cluster behavior
  transition_matrix.py            # Builds and visualizes cluster transitions
  lexicon_builder.py              # Creates a candidate lexicon by section and role
  cluster_language_similarity.py  # (Optional) Compares clusters to real-world languages

/results/
  Figure_1.png                    # SBERT clusters (PCA reduced)
  transition_matrix_heatmap.png  # Markov transition matrix
  cluster_role_summary.csv
  cluster_transition_matrix.csv
  lexicon_candidates.csv"><pre><code>/data/
  AB.docx                         # Full transliteration with folio/line tags
  voynichese/                     # Root word .txt files
  stripped_cluster_lookup.json    # Cluster ID per stripped root
  unique_stripped_words.json      # All stripped root forms
  voynich_line_clusters.csv       # Cluster sequences per line

/scripts/
  cluster_roots.py                # SBERT clustering + suffix stripping
  map_lines_to_clusters.py        # Maps manuscript lines to cluster IDs
  pos_model.py                    # Infers grammatical roles from cluster behavior
  transition_matrix.py            # Builds and visualizes cluster transitions
  lexicon_builder.py              # Creates a candidate lexicon by section and role
  cluster_language_similarity.py  # (Optional) Compares clusters to real-world languages

/results/
  Figure_1.png                    # SBERT clusters (PCA reduced)
  transition_matrix_heatmap.png  # Markov transition matrix
  cluster_role_summary.csv
  cluster_transition_matrix.csv
  lexicon_candidates.csv
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✅ Key Contributions</h2><a id="user-content--key-contributions" aria-label="Permalink: ✅ Key Contributions" href="#-key-contributions"></a></p>
<ul dir="auto">
<li>Clustering of stripped root words using multilingual SBERT</li>
<li>Identification of function-word-like vs. content-word-like clusters</li>
<li>Markov-style transition modeling of cluster sequences</li>
<li>Folio-based syntactic structure mapping (Botanical, Biological, etc.)</li>
<li>Generation of a data-driven lexicon hypothesis table</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Preprocessing Choices</h2><a id="user-content--preprocessing-choices" aria-label="Permalink: 🔧 Preprocessing Choices" href="#-preprocessing-choices"></a></p>
<p dir="auto">One of the most important assumptions I made was about how to handle the Voynich words before clustering. Specifically: I stripped a set of recurring suffix-like endings from each word — things like aiin, dy, chy, and similar variants. The goal was to isolate what looked like root forms that repeated with variation, under the assumption that these suffixes might be:</p>
<ul dir="auto">
<li>Phonetic padding</li>
<li>Grammatical particles</li>
<li>Chant-like or mnemonic repetition</li>
<li>Or… just noise</li>
</ul>
<p dir="auto">This definitely improved the clustering behavior — similar stems grouped more tightly, and the transition matrix showed cleaner structural patterns. But it's also a strong preprocessing decision that may have:</p>
<ul dir="auto">
<li>Removed actual morphological information</li>
<li>Disguised meaningful inflectional variants</li>
<li>Introduced a bias toward function over content</li>
</ul>
<p dir="auto">So it’s not neutral — it helped, but it also shaped the results.
If someone wants to fork this repo and re-run the pipeline without suffix stripping — or treat suffixes as their own token class — I’d be genuinely interested in the comparison.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📈 Key Findings</h2><a id="user-content--key-findings" aria-label="Permalink: 📈 Key Findings" href="#-key-findings"></a></p>
<ul dir="auto">
<li><strong>Cluster 8</strong> exhibits high frequency, low diversity, and frequent line-starts — likely a <em>function word group</em></li>
<li><strong>Cluster 3</strong> has high diversity and flexible positioning — likely a <em>root content class</em></li>
<li><strong>Transition matrix</strong> shows strong internal structure, far from random</li>
<li>Cluster usage and POS patterns differ by <em>manuscript section</em> (e.g., Biological vs Botanical)</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧬 Hypothesis</h2><a id="user-content--hypothesis" aria-label="Permalink: 🧬 Hypothesis" href="#-hypothesis"></a></p>
<p dir="auto">The manuscript encodes a structured constructed or mnemonic language using syllabic padding and positional repetition. It exhibits syntax, function/content separation, and section-aware linguistic shifts — even in the absence of direct translation.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto"><g-emoji alias="arrow_forward">▶️</g-emoji> How to Reproduce</h2><a id="user-content-️-how-to-reproduce" aria-label="Permalink: ▶️ How to Reproduce" href="#️-how-to-reproduce"></a></p>
<div data-snippet-clipboard-copy-content="# 1. Install dependencies
pip install -r requirements.txt

# 2. Run each stage of the pipeline
python scripts/cluster_roots.py
python scripts/map_lines_to_clusters.py
python scripts/pos_model.py
python scripts/transition_matrix.py
python scripts/lexicon_builder.py"><pre><code># 1. Install dependencies
pip install -r requirements.txt

# 2. Run each stage of the pipeline
python scripts/cluster_roots.py
python scripts/map_lines_to_clusters.py
python scripts/pos_model.py
python scripts/transition_matrix.py
python scripts/lexicon_builder.py
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Example Visualizations</h2><a id="user-content--example-visualizations" aria-label="Permalink: 📊 Example Visualizations" href="#-example-visualizations"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">📌 Figure 1: SBERT cluster embeddings (PCA-reduced)</h4><a id="user-content--figure-1-sbert-cluster-embeddings-pca-reduced" aria-label="Permalink: 📌 Figure 1: SBERT cluster embeddings (PCA-reduced)" href="#-figure-1-sbert-cluster-embeddings-pca-reduced"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/brianmg/voynich-nlp-analysis/blob/main/results/Figure_1.png"><img src="https://github.com/brianmg/voynich-nlp-analysis/raw/main/results/Figure_1.png" alt="Cluster visualization"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">📌 Figure 2: Transition Matrix Heatmap</h4><a id="user-content--figure-2-transition-matrix-heatmap" aria-label="Permalink: 📌 Figure 2: Transition Matrix Heatmap" href="#-figure-2-transition-matrix-heatmap"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/brianmg/voynich-nlp-analysis/blob/main/results/transition_matrix_heatmap.png"><img src="https://github.com/brianmg/voynich-nlp-analysis/raw/main/results/transition_matrix_heatmap.png" alt="Transition matrix heatmap"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📌 Limitations</h2><a id="user-content--limitations" aria-label="Permalink: 📌 Limitations" href="#-limitations"></a></p>
<ul dir="auto">
<li>Cluster-to-word mappings are indirect — frequency estimates may overlap</li>
<li>Suffix stripping is heuristic and may remove meaningful endings</li>
<li>No semantic translation attempted — only structural modeling</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✍️ Authors Note</h2><a id="user-content-️-authors-note" aria-label="Permalink: ✍️ Authors Note" href="#️-authors-note"></a></p>
<p dir="auto">This project was built as a way to learn — about AI, NLP, and how far structured analysis can get you without assuming what you're looking at. I’m not here to crack the Voynich. But I do believe that modeling its structure with modern tools is a better path than either wishful translation or academic dismissal.</p>
<p dir="auto">So if you're here for a Rosetta Stone, you're out of luck.</p>
<p dir="auto">If you're here to model a language that may not want to be modeled — welcome.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributions Welcome</h2><a id="user-content--contributions-welcome" aria-label="Permalink: 🤝 Contributions Welcome" href="#-contributions-welcome"></a></p>
<p dir="auto">This project is open to extensions, critiques, and collaboration — especially from linguists, cryptographers, conlang enthusiasts, and computational language researchers.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Card Disabled My iCloud, App Store, and Apple ID Accounts (2021) (133 pts)]]></title>
            <link>https://dcurt.is/apple-card-can-disable-your-icloud-account</link>
            <guid>44021792</guid>
            <pubDate>Sun, 18 May 2025 14:47:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dcurt.is/apple-card-can-disable-your-icloud-account">https://dcurt.is/apple-card-can-disable-your-icloud-account</a>, See on <a href="https://news.ycombinator.com/item?id=44021792">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="container">
  <article id="joY8W3tvZQnd4STUybDLAs">
	<time datetime="2021-03-01">March  1, 2021</time>
  <h2>
    <a href="https://dcurt.is/apple-card-can-disable-your-icloud-account">Apple Card disabled my iCloud, App Store, and Apple ID accounts</a>
  </h2>
	<p>About ten days ago, when I went to update a few apps in the App Store on my Mac, I was met with a curious error.</p>

<p><a href="https://svbtleusercontent.com/qest5zgsbPZ36zkUp7CHo40xspap.png"><img src="https://svbtleusercontent.com/qest5zgsbPZ36zkUp7CHo40xspap_small.png" alt="mac_app_store.png"></a></p>

<p>The internet is filled with stories from people whose Google accounts were locked for unexplained reasons, causing them to lose all of their data, including years of email, so I was somewhat concerned. But I’d never heard of similar cases involving Apple’s services, and I wouldn’t expect such behavior from a customer-focused company like Apple, so I figured it was a glitch and made a mental note to try again later.</p>

<p>The next day, Music.app stopped working.</p>

<p><a href="https://svbtleusercontent.com/oyQJaCT4RtgroGwU2afbHb0xspap.png"><img src="https://svbtleusercontent.com/oyQJaCT4RtgroGwU2afbHb0xspap_small.png" alt="mac_music_app.png"></a></p>

<p>Now I was genuinely worried. I checked my phone and neither the App Store nor Apple Music would work there, either. A few minutes later, Calendar popped up an error – it had stopped syncing. I immediately tried to call Apple Support from my Mac, but Apple’s Handoff feature had been disabled as well. </p>

<p>The first person I spoke to at Apple spent a while researching the issue and then told me there was nothing she could do but escalate the issue, and that I should expect a call <em>“hopefully”</em> within the next day. I asked what the problem might be, and she seemed as confused as I was. Although some Apple services were still working, like iMessage (thank God) and Photos, I was terrified that more services would suddenly become inaccessible or that I would lose the considerable amount of data I have stored in iCloud.</p>

<p>A couple of days later, I became impatient and contacted Apple Support again. This time, the representative mumbled something about Apple Card before saying that he also had no power to help me. Apple ID was a different department, he said, and they could only be contacted by email. He emailed them. I continued to wait.</p>

<p>The next time I tried to use my Apple Card, it was declined. Strange. I checked the Wallet app, and the balance was below the limit. I remembered the Apple support representative mumbling about Apple Card, so I did some digging through my email to see if I could find a connection.</p>

<hr>

<p>As it turns out, my bank account number changed in January, causing Apple Card autopay to fail. Then the Apple Store made a charge on the card. Less than fifteen days after that, my App Store, iCloud, Apple Music, and Apple ID accounts had all been disabled by Apple Card. </p>

<hr>
<h3 id="so-what-happened_3">So what happened? <a href="#so-what-happened_3">#</a></h3>
<p>In mid-January, I bought an M1 MacBook Pro. The checkout flow offered a trade-in credit for an old MacBook Pro I had laying around. The Apple Store said I would receive a “trade-in kit” by mail and then have two weeks to send the old MacBook to Apple. Sounds easy, and definitely a very Apple-like experience. </p>

<p>But the trade-in kit never arrived. I had forgotten about it. When I received an email in mid-February asking about the trade-in, I responded (as it had invited me to do) explaining that I never received the kit and asked for another one. I didn’t get a response.</p>

<p>Very soon after, it seems that Apple simply added the amount of the credit I received when I purchased the M1 MacBook Pro to my Apple Card balance. Normally, this wouldn’t be a problem. Imagine if I had used any other credit card – it would have just been an ordinary charge. But because it was the Apple Store and Apple Card, apparently, things escalated very quickly.</p>

<p>On February 15th, Apple sent me this email:</p>
<blockquote><p><strong>Action Required: Apple Card</strong></p>

<p>From: Apple <a href="mailto:payment@apple.com">payment@apple.com</a><br>
Reply-to: <a href="mailto:preceivables@apple.com">preceivables@apple.com</a></p>

<p>We’ve been unable to collect full payment for your new iPhone. As a result, we will block the device on the order from further access to the Apple iTunes and Mac App stores, and disable all accounts associated with the device purchased on the order.</p>

<p>To resolve this issue, please call 1-877-255-5923 to speak with an Apple Card Specialist at Goldman Sachs. Once the issue has been resolved, reply to this email so we can charge your card for the difference in value.</p>

<p>For your protection, do not submit credit card information via email.</p>
</blockquote>
<p>It appears as though charges from Apple are special, and if your account is not 100% current, Apple will quickly take drastic action. Unfortunately, this email got lost in my inbox and I didn’t see it until I went looking. But it is extremely concerning for several reasons.</p>

<ul>
<li>Apple says it will hold my Apple accounts hostage in order to collect a payment.</li>
<li>It says it is related to an iPhone when it was actually regarding a MacBook Pro. And iTunes no longer exists. The lack of attention to detail is not great given the seriousness of the threat that follows.</li>
<li>It was sent when Apple Card was only a few days past due.</li>
<li>It suggests that charges by Apple on Apple Card are different from other purchases, and this can have serious consequences. (Also: the Apple Card agreement does not mention this technicality.)</li>
</ul>

<p>After fixing the Apple Card issue, I replied to the email as it says, and received this in response: </p>

<p><a href="https://svbtleusercontent.com/7SNnHHaXX7jK7ewzeX4WLC0xspap.png"><img src="https://svbtleusercontent.com/7SNnHHaXX7jK7ewzeX4WLC0xspap_small.png" alt="bounce.png"></a></p>

<p>Great. </p>

<p>By this point, Apple Support had been unable to help me – or to even identify the issue. My App Store, Apple Music, iCloud, and Apple ID accounts were disabled. Replying to the email as instructed resulted in a bounce. </p>

<p>So I used Apple Business Chat to talk with Goldman Sachs. The representative there seemed confused, asked me to wait for quite a while, and then said the only way to reactivate my Apple ID was for him to email a department at Apple and wait for a call back within “a few days”. </p>

<p>Earlier today, I received a call from someone at Apple who explained that I had found the right department – finally! – but that the Apple account re-activation team can only be contacted by email and the process takes <em>at least 3-5 business days</em>. He emailed them.</p>

<p>And now I am once again waiting. </p>

<hr>

<p><strong>Update:</strong> My accounts have been reactivated. </p>

  <figure id="kudo_joY8W3tvZQnd4STUybDLAs">
    <a href="#kudo">
      
    </a>
    <p>2,340</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_joY8W3tvZQnd4STUybDLAs">
    <a href="#kudo">
      
    </a>
    <p>2,340</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Logo Ligature Bug (118 pts)]]></title>
            <link>https://www.jefftk.com/p/google-logo-ligature-bug</link>
            <guid>44021028</guid>
            <pubDate>Sun, 18 May 2025 12:51:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jefftk.com/p/google-logo-ligature-bug">https://www.jefftk.com/p/google-logo-ligature-bug</a>, See on <a href="https://news.ycombinator.com/item?id=44021028">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div>

    <p><span>

Jeffrey Yasskin recently </span><a href="https://hachyderm.io/@jyasskin/114520767683101962">pointed
out</a> an <a href="https://issues.chromium.org/issues/391788835">interesting
security bug</a>:

</p><p>

<a href="https://www.jefftk.com/google-logo-ligature-example-big.png"><img src="https://www.jefftk.com/google-logo-ligature-example.png" width="550" height="1152" srcset="https://www.jefftk.com/google-logo-ligature-example.png 550w,https://www.jefftk.com/google-logo-ligature-example-2x.png 1100w"></a></p>


<p>

The idea is, if you had registered <code>googlelogoligature.net</code>
then Chrome on Android (and possibly other Google products) would have
displayed it as <code>Google.net</code>, potentially tricking users
into thinking they were really interacting with Google.

</p>
<p>

To see how this worked, you can try searching Google for <a href="https://www.google.com/search?q=%22googlelogoligature%22">["googlelogoligature"]</a>,
and you'll see it shows up as "Google":

</p>
<p>

<a href="https://www.jefftk.com/google-logo-ligature-devtools-big.png"><img src="https://www.jefftk.com/google-logo-ligature-devtools.png" width="550" height="376" srcset="https://www.jefftk.com/google-logo-ligature-devtools.png 550w,https://www.jefftk.com/google-logo-ligature-devtools-2x.png 1100w"></a></p>


<p>

Poking in devtools, this is dependent on the specific font they're
using, "Google Sans".  If I turn that off my "googlelogoligature"
shows just as I typed it:

</p>
<p>

<a href="https://www.jefftk.com/google-logo-ligature-devtools-off-big.png"><img src="https://www.jefftk.com/google-logo-ligature-devtools-off.png" width="550" height="376" srcset="https://www.jefftk.com/google-logo-ligature-devtools-off.png 550w,https://www.jefftk.com/google-logo-ligature-devtools-off-2x.png 1100w"></a></p>


<p>

Fonts can include "ligatures", which let font designers special-case
specific combinations of letters.  These were intended to support
things like "f" followed by "i" blending into "fi" nicely, but the
feature has been (ab)used for many other things, including <a href="https://type.today/en/journal/emoji01">complex emoji</a>.  In
this case, Google Sans has a specific way of drawing
"googlelogoligature" that looks like a mildly stylized "Google".

</p>
<p>

Using a ligature to get the Google logo into text-only interfaces is a
reasonable product decision, but it shouldn't have been added to a
general-purpose font.  And especially shouldn't have been added to a
font used for rendering attacker-controlled text in
security-sensitive contexts.

</p>
<p>

(When I first saw it I thought this might be an example of a <a href="https://www.jefftk.com/p/is-unicode-safe">unicode-driven
vulnerability</a>, but sadly not.)

  </p>
</div>


  
<p>Comment via: <a href="https://www.facebook.com/jefftk/posts/pfbid0y9mmbyqjWm6bVhAVH8MUmQKuirGiCkxEfFnL2QGrcrDkQqCv1HtvuukqqrYcJsTpl">facebook</a>, <a href="https://lesswrong.com/posts/MGGm8B7StJtbhQs56">lesswrong</a>, <a href="https://mastodon.mit.edu/@jefftk/114526485794379433">mastodon</a>, <a href="https://bsky.app/profile/jefftk.com/post/3lpfzcbfi4c2w">bluesky</a></p>

</div><section>
  <h3>Recent posts on blogs I like:</h3>
  <section>
    
    <div>
      <h4>
        <a href="https://thingofthings.substack.com/p/brief-solution-focused-therapy">Solution-Focused Brief Therapy</a>
      </h4>
      <p>Look! A therapy technique people don't already know!</p>
      <p><small>
        via <a href="https://thingofthings.substack.com/">Thing of Things</a>
      </small>
      <small>May 14, 2025</small>
    </p></div>
    
    <div>
      <h4>
        <a href="https://lincolnquirk.com/2025/04/30/workshop.html">Workshop House case study</a>
      </h4>
      <p>Lauren Hoffman interviewed me about Workshop House and wrote this post about a community I’m working on building in DC.</p>
      <p><small>
        via <a href="https://lincolnquirk.com/">Home</a>
      </small>
      <small>April 30, 2025</small>
    </p></div>
    
    <div>
      <h4>
        <a href="https://www.benkuhn.net/impact/">Impact, agency, and taste</a>
      </h4>
      <p>understand + work backwards from the root goal • don’t rely too much on permission or encouragement • make success inevitable • find your angle • think real hard • reflect on your thinking</p>
      <p><small>
        via <a href="https://www.benkuhn.net/">benkuhn.net</a>
      </small>
      <small>April 19, 2025</small>
    </p></div>
    
  </section>
  <p>
    <a href="https://www.jefftk.com/ring">more</a>
    &nbsp;&nbsp;&nbsp;
    (<a href="https://git.sr.ht/~sircmpwn/openring">via openring</a>)
  </p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hardtime.nvim – break bad habits and master Vim motions (128 pts)]]></title>
            <link>https://github.com/m4xshen/hardtime.nvim</link>
            <guid>44020734</guid>
            <pubDate>Sun, 18 May 2025 12:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/m4xshen/hardtime.nvim">https://github.com/m4xshen/hardtime.nvim</a>, See on <a href="https://news.ycombinator.com/item?id=44020734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">hardtime.nvim</h2><a id="user-content-hardtimenvim" aria-label="Permalink: hardtime.nvim" href="#hardtimenvim"></a></p>
<p dir="auto">Break bad habits, master Vim motions</p>
<p dir="auto"><a href="https://github.com/m4xshen/hardtime.nvim/actions/workflows/tests.yml"><img src="https://camo.githubusercontent.com/d1d6f981bc21b383754af8e2007357bcebf9fa94a61e704fb36ced25b03ecafd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6d34787368656e2f6861726474696d652e6e76696d2f74657374732e796d6c3f6c6162656c3d427573746564266c6f676f3d4c7561" alt="Busted" data-canonical-src="https://img.shields.io/github/actions/workflow/status/m4xshen/hardtime.nvim/tests.yml?label=Busted&amp;logo=Lua"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6c6dbaf22b36ec46ba00d8ce883e3a9a2cc67afcb30003102b68997329e1374f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e656f76696d2d302e31302d3537413134333f6c6f676f3d6e656f76696d"><img src="https://camo.githubusercontent.com/6c6dbaf22b36ec46ba00d8ce883e3a9a2cc67afcb30003102b68997329e1374f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e656f76696d2d302e31302d3537413134333f6c6f676f3d6e656f76696d" alt="Neovim version" data-canonical-src="https://img.shields.io/badge/Neovim-0.10-57A143?logo=neovim"></a></p>
<p dir="auto"><a href="#-features">Features</a> • <a href="#-installation">Installation</a> • <a href="#-usage">Usage</a> • <a href="#-configuration">Configuration</a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description RestrictKeys.mov">RestrictKeys.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/74842863/444841941-3cc1bcdd-1ace-40f0-b295-f84a78051d6a.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1ODk3MDMsIm5iZiI6MTc0NzU4OTQwMywicGF0aCI6Ii83NDg0Mjg2My80NDQ4NDE5NDEtM2NjMWJjZGQtMWFjZS00MGYwLWIyOTUtZjg0YTc4MDUxZDZhLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTE4VDE3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIxN2Y1Y2FjOWZkZDI4M2UwYjM2NjNkNjA3ZTNjNzU3YzJmMGNkMWMxNDA2MGVjYWFmNWE1OTQwOGY0M2JlOTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9Vl5wDOOcPw9P92HLI-yGgdQWhss_LpNDSNssrSVrME" data-canonical-src="https://private-user-images.githubusercontent.com/74842863/444841941-3cc1bcdd-1ace-40f0-b295-f84a78051d6a.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1ODk3MDMsIm5iZiI6MTc0NzU4OTQwMywicGF0aCI6Ii83NDg0Mjg2My80NDQ4NDE5NDEtM2NjMWJjZGQtMWFjZS00MGYwLWIyOTUtZjg0YTc4MDUxZDZhLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTE4VDE3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIxN2Y1Y2FjOWZkZDI4M2UwYjM2NjNkNjA3ZTNjNzU3YzJmMGNkMWMxNDA2MGVjYWFmNWE1OTQwOGY0M2JlOTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9Vl5wDOOcPw9P92HLI-yGgdQWhss_LpNDSNssrSVrME" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description Hints.mov">Hints.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/74842863/444842107-1c120fe5-c57d-4cb3-8313-25f2395e95fa.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1ODk3MDMsIm5iZiI6MTc0NzU4OTQwMywicGF0aCI6Ii83NDg0Mjg2My80NDQ4NDIxMDctMWMxMjBmZTUtYzU3ZC00Y2IzLTgzMTMtMjVmMjM5NWU5NWZhLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTE4VDE3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTljN2I2M2YzNTZiZmZiOWU2OTA0Y2U3YmNiNzQ2ZjlmYzkwMDNiNmVjNzQxNzE1NmViMDk5MTNiMDJlOTEwYmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.CauNmeTwvQH90Lkauit5kDtDIc0lJs3LmvCwtL8YgcE" data-canonical-src="https://private-user-images.githubusercontent.com/74842863/444842107-1c120fe5-c57d-4cb3-8313-25f2395e95fa.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1ODk3MDMsIm5iZiI6MTc0NzU4OTQwMywicGF0aCI6Ii83NDg0Mjg2My80NDQ4NDIxMDctMWMxMjBmZTUtYzU3ZC00Y2IzLTgzMTMtMjVmMjM5NWU5NWZhLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTE4VDE3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTljN2I2M2YzNTZiZmZiOWU2OTA0Y2U3YmNiNzQ2ZjlmYzkwMDNiNmVjNzQxNzE1NmViMDk5MTNiMDJlOTEwYmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.CauNmeTwvQH90Lkauit5kDtDIc0lJs3LmvCwtL8YgcE" controls="controls" muted="muted">

  </video>
</details>

</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features</h2><a id="user-content--features" aria-label="Permalink: ✨ Features" href="#-features"></a></p>
<ul dir="auto">
<li>Block repeated keys within a short period of time</li>
<li>Provide hints for faster Vim motion</li>
<li>Get report of your most common bad habits</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">👍🏻 Recommended workflow</h2><a id="user-content--recommended-workflow" aria-label="Permalink: 👍🏻 Recommended workflow" href="#-recommended-workflow"></a></p>
<p dir="auto">Instead of only relying on <code>hjkl</code>, arrow keys and mouse, you should:</p>
<ol dir="auto">
<li>Use relative jump (eg: <code>5j</code> <code>12-</code>) for vertical movement within the screen.</li>
<li>Use <code>CTRL-U</code> <code>CTRL-D</code> <code>CTRL-B</code> <code>CTRL-F</code> <code>gg</code> <code>G</code> for vertical movement outside the screen.</li>
<li>Use word-motion (<code>w</code> <code>W</code> <code>b</code> <code>B</code> <code>e</code> <code>E</code> <code>ge</code> <code>gE</code>) for short-distance horizontal movement.</li>
<li>Use <code>f</code> <code>F</code> <code>t</code> <code>T</code> <code>,</code> <code>;</code> <code>0</code> <code>^</code> <code>$</code> for medium to long-distance horizontal movement.</li>
<li>Use operator + motion/text-object (eg: <code>ci{</code> <code>y5j</code> <code>dap</code>) whenever possible.</li>
<li>Use <code>%</code> and square bracket commands (see <code>:h [</code>) to jump between brackets.</li>
</ol>
<p dir="auto">Learn more in this <a href="https://m4xshen.dev/posts/vim-command-workflow/" rel="nofollow">blog post</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡ Requirements</h2><a id="user-content--requirements" aria-label="Permalink: ⚡ Requirements" href="#-requirements"></a></p>
<ul dir="auto">
<li>Neovim &gt;= <a href="https://github.com/neovim/neovim/releases/tag/v0.10.0">v0.10.0</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Installation</h2><a id="user-content--installation" aria-label="Permalink: 📦 Installation" href="#-installation"></a></p>
<ol dir="auto">
<li>Install via your favorite package manager.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="{
   &quot;m4xshen/hardtime.nvim&quot;,
   lazy = false,
   dependencies = { &quot;MunifTanjim/nui.nvim&quot; },
   opts = {},
},"><pre>{
   <span><span>"</span>m4xshen/hardtime.nvim<span>"</span></span>,
   <span>lazy</span> <span>=</span> <span>false</span>,
   <span>dependencies</span> <span>=</span> { <span><span>"</span>MunifTanjim/nui.nvim<span>" </span></span>},
   <span>opts</span> <span>=</span> {},
},</pre></div>
<ol start="2" dir="auto">
<li>Setup the plugin in your <code>init.lua</code>. This step is not needed with lazy.nvim if <code>opts</code> is set as above.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="require(&quot;hardtime&quot;).setup()"><pre><span>require</span>(<span><span>"</span>hardtime<span>"</span></span>).<span>setup</span>()</pre></div>
<p dir="auto">If you want to see the hint messages in insert and visual mode, set the <code>'showmode'</code> to false.</p>
<p dir="auto">But if you want to see both the hint message and current mode you can setup with one of the following methods:</p>
<ul dir="auto">
<li>Display the mode on status line and set <code>'showmode'</code> to false. You can do this with some statusline plugin such as lualine.nvim.</li>
<li>Set the <code>'cmdheight'</code> to 2 so that the hint message won't be replaced by mode message.</li>
<li>Use nvim-notify to display hint messages on the right top corner instead of commandline.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Usage</h2><a id="user-content--usage" aria-label="Permalink: 🚀 Usage" href="#-usage"></a></p>
<p dir="auto">Hardtime is enabled by default. You can change its state with the following commands:</p>
<ul dir="auto">
<li><code>:Hardtime enable</code> enable Hardtime</li>
<li><code>:Hardtime disable</code> disable Hardtime</li>
<li><code>:Hardtime toggle</code> toggle Hardtime</li>
</ul>
<p dir="auto">You can view the most frequently seen hints with <code>:Hardtime report</code>.</p>
<p dir="auto">Your log file is at <code>~/.local/state/nvim/hardtime.nvim.log</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Configuration</h2><a id="user-content--configuration" aria-label="Permalink: 🔧 Configuration" href="#-configuration"></a></p>
<p dir="auto">You can pass your config table into the <code>setup()</code> function or <code>opts</code> if you use lazy.nvim.</p>
<p dir="auto">If the option is a table (<code>key = value</code> pair), you can set <code>value</code> to <code>false</code> to disable the default value.</p>
<p dir="auto">Examples:</p>
<div dir="auto" data-snippet-clipboard-copy-content="disabled_keys = {
   [&quot;<Up>&quot;] = false, -- Allow <Up> key
   [&quot;<Space>&quot;] = { &quot;n&quot;, &quot;x&quot; }, -- Disable <Space> key in normal and visual mode
},"><pre><span>disabled_keys</span> <span>=</span> {
   [<span><span>"</span>&lt;Up&gt;<span>"</span></span>] <span>=</span> <span>false</span>, <span><span>--</span> Allow &lt;Up&gt; key</span>
   [<span><span>"</span>&lt;Space&gt;<span>"</span></span>] <span>=</span> { <span><span>"</span>n<span>"</span></span>, <span><span>"</span>x<span>" </span></span>}, <span><span>--</span> Disable &lt;Space&gt; key in normal and visual mode</span>
},</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="disabled_filetypes = { 
   lazy = false, -- Enable Hardtime in lazy filetype
   [&quot;dapui*&quot;] = false, -- Enable Hardtime in filetype starting with dapui
},"><pre><span>disabled_filetypes</span> <span>=</span> { 
   <span>lazy</span> <span>=</span> <span>false</span>, <span><span>--</span> Enable Hardtime in lazy filetype</span>
   [<span><span>"</span>dapui*<span>"</span></span>] <span>=</span> <span>false</span>, <span><span>--</span> Enable Hardtime in filetype starting with dapui</span>
},</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Options</h3><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option Name</th>
<th>Type</th>
<th>Default Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>max_time</code></td>
<td>number</td>
<td><code>1000</code></td>
<td>Maximum time (in milliseconds) to consider key presses as repeated.</td>
</tr>
<tr>
<td><code>max_count</code></td>
<td>number</td>
<td><code>3</code></td>
<td>Maximum count of repeated key presses allowed within the <code>max_time</code> period.</td>
</tr>
<tr>
<td><code>disable_mouse</code></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Disable mouse support.</td>
</tr>
<tr>
<td><code>hint</code></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Enable hint messages for better commands.</td>
</tr>
<tr>
<td><code>notification</code></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Enable notification messages for restricted and disabled keys.</td>
</tr>
<tr>
<td><code>timeout</code></td>
<td>number or boolean</td>
<td><code>3000</code></td>
<td>Time to show notification in milliseconds, set to <code>false</code> to disable timeout.</td>
</tr>
<tr>
<td><code>allow_different_key</code></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Allow different keys to reset the count.</td>
</tr>
<tr>
<td><code>enabled</code></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Whether the plugin is enabled by default or not.</td>
</tr>
<tr>
<td><code>resetting_keys</code></td>
<td>table</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td>Keys in what modes that reset the count.</td>
</tr>
<tr>
<td><code>restricted_keys</code></td>
<td>table</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td>Keys in what modes triggering the count mechanism.</td>
</tr>
<tr>
<td><code>restriction_mode</code></td>
<td>string (<code>"block" or "hint"</code>)</td>
<td><code>"block"</code></td>
<td>The behavior when <code>restricted_keys</code> trigger count mechanism.</td>
</tr>
<tr>
<td><code>disabled_keys</code></td>
<td>table</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td>Keys in what modes are disabled.</td>
</tr>
<tr>
<td><code>disabled_filetypes</code></td>
<td>table</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td>Hardtime is disabled under these filetypes.</td>
</tr>
<tr>
<td><code>hints</code></td>
<td>table</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td><code>key</code> is a string pattern you want to match, <code>value</code> is a table of hint message and pattern length. Learn more about <a href="https://www.lua.org/pil/20.2.html" rel="nofollow">Lua string pattern</a>.</td>
</tr>
<tr>
<td><code>callback</code></td>
<td>function(text)</td>
<td><code>vim.notify</code></td>
<td><code>callback</code> function can be used to override the default notification behavior.</td>
</tr>
<tr>
<td><code>force_exit_insert_mode</code></td>
<td>boolean</td>
<td><code>false</code></td>
<td>Enable forcing exit Insert mode if user is inactive in Insert mode.</td>
</tr>
<tr>
<td><code>max_insert_idle_ms</code></td>
<td>number</td>
<td><code>5000</code></td>
<td>Maximum amount of idle time, in milliseconds, allowed in Insert mode.</td>
</tr>
<tr>
<td><code>ui</code></td>
<td>table of strings/table pair</td>
<td><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">See Config</a></td>
<td>An option to customize the popup for the <code>Hardtime report</code>.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>hints</code> example</h3><a id="user-content-hints-example" aria-label="Permalink: hints example" href="#hints-example"></a></p>
<p dir="auto">These are two default hints:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hints = {
   [&quot;k%^&quot;] = {
      message = function()
         return &quot;Use - instead of k^&quot; -- return the hint message you want to display
      end,
      length = 2, -- the length of actual key strokes that matches this pattern
   },
   [&quot;d[tTfF].i&quot;] = { -- this matches d + {t/T/f/F} + {any character} + i
      message = function(keys) -- keys is a string of key strokes that matches the pattern
         return &quot;Use &quot; .. &quot;c&quot; .. keys:sub(2, 3) .. &quot; instead of &quot; .. keys
         -- example: Use ct( instead of dt(i
      end,
      length = 4,
   },
}"><pre><span>hints</span> <span>=</span> {
   [<span><span>"</span>k%^<span>"</span></span>] <span>=</span> {
      <span>message</span> <span>=</span> <span>function</span>()
         <span>return</span> <span><span>"</span>Use - instead of k^<span>" </span></span><span><span>--</span> return the hint message you want to display</span>
      <span>end</span>,
      <span>length</span> <span>=</span> <span>2</span>, <span><span>--</span> the length of actual key strokes that matches this pattern</span>
   },
   [<span><span>"</span>d[tTfF].i<span>"</span></span>] <span>=</span> { <span><span>--</span> this matches d + {t/T/f/F} + {any character} + i</span>
      <span>message</span> <span>=</span> <span>function</span>(<span>keys</span>) <span><span>--</span> keys is a string of key strokes that matches the pattern</span>
         <span>return</span> <span><span>"</span>Use <span>" </span></span><span>..</span> <span><span>"</span>c<span>" </span></span><span>..</span> <span>keys</span>:<span>sub</span>(<span>2</span>, <span>3</span>) <span>..</span> <span><span>"</span> instead of <span>" </span></span><span>..</span> <span>keys</span>
         <span><span>--</span> example: Use ct( instead of dt(i</span>
      <span>end</span>,
      <span>length</span> <span>=</span> <span>4</span>,
   },
}</pre></div>
<p dir="auto">Check out some examples of custom hint in <a href="https://github.com/m4xshen/hardtime.nvim/discussions/categories/custom-hints">discussion</a>!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/m4xshen/hardtime.nvim/blob/main/lua/hardtime/config.lua">Default config</a></h3><a id="user-content-default-config" aria-label="Permalink: Default config" href="#default-config"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">🦾 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🦾 Contributing" href="#-contributing"></a></p>
<p dir="auto">Please read <a href="https://github.com/m4xshen/hardtime.nvim/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">👥 Contributors</h2><a id="user-content--contributors" aria-label="Permalink: 👥 Contributors" href="#-contributors"></a></p>
<a href="https://github.com/m4xshen/hardtime.nvim/graphs/contributors">
  <img src="https://camo.githubusercontent.com/a5e5f82d81b6692ac12ae01ee2265b3e0a1bbf86afb62a4baecf0778ad6ae557/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6d34787368656e2f6861726474696d652e6e76696d" data-canonical-src="https://contrib.rocks/image?repo=m4xshen/hardtime.nvim">
</a>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thank you Google for breaking my YouTube addiction (103 pts)]]></title>
            <link>https://rakhim.exotext.com/thank-you-google-for-breaking-my-youtube-addiction</link>
            <guid>44020653</guid>
            <pubDate>Sun, 18 May 2025 11:55:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rakhim.exotext.com/thank-you-google-for-breaking-my-youtube-addiction">https://rakhim.exotext.com/thank-you-google-for-breaking-my-youtube-addiction</a>, See on <a href="https://news.ycombinator.com/item?id=44020653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Over the past few years, Google has done a surprisingly great job of making YouTube less interesting and engaging — and in turn, less addictive. Maybe they've got some ethical guidelines in the top management now? If so, well done, Google.</p>
<p>Back in the day, when YouTube was mostly about your subscriptions, it was mildly addictive. You’d watch a C++ talk, and the sidebar would actually show you other useful C++ videos. It was relevant, and it kept you watching without feeling like you were drowning in content.</p>
<p>Then they introduced the algorithmic home feed, and that’s when things got intense. You’d open YouTube and get hit with an endless grid of videos tailored to your weird, eclectic mix of interests. Every refresh was like, “Oh, wow, more stuff I didn’t even know I wanted to watch!” It was like YouTube was infinite. </p>
<p>Now? Now it feels like YouTube is trying to bore us into logging off. The homepage just recycles the same 10-20 videos for weeks. It's like a kid in high school trying really hard to expand two sentences into a required 2-page essay by <a href="https://jayd.ml/2025/04/30/someone-at-youtube-needs-glasses.html">increasing the line height and font size</a>, and re-phrasing the same point over and over again.</p>
<p><img src="https://img.exotext.com/1/qcCGARM0puK0m-pSLhwkR.jpg" alt="">
<em>YouTube app on Apple TV feels particularly empty. The same few videos shuffled on each row.</em></p>
<p>Watch two bee videos, and suddenly YouTube decides you’re a bee person for life. Over a decade of watch history, interests, searches, playlists — none of that matters anymore. The user is into bees now. </p>
<p>The search now serves up a couple of videos from channels you've interacted with, prioritizing them over the actual relevance, throws in completely unrelated recommendations, and then sprinkles random Shorts on top. It’s like they’re trying to convince you there’s nothing good left to watch.</p>
<p><img src="https://img.exotext.com/1/PVnazyRa12Es4UyRKeozA.jpg" alt="">
<em>Interested in nautical route planning algorithms? Sure, but what about sexy girls and cars?</em></p>
<p>Honestly, it’s kind of brilliant. If you wanted to make YouTube less addictive, this is how you’d do it — by making it feel pointless and lame. So, thanks, Google. You're actually doing the "don't be evil" thing!</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A web browser agent in your Chrome side panel (108 pts)]]></title>
            <link>https://github.com/parsaghaffari/browserbee</link>
            <guid>44020626</guid>
            <pubDate>Sun, 18 May 2025 11:48:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/parsaghaffari/browserbee">https://github.com/parsaghaffari/browserbee</a>, See on <a href="https://news.ycombinator.com/item?id=44020626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">BrowserBee 🐝</h2><a id="user-content-browserbee-" aria-label="Permalink: BrowserBee 🐝" href="#browserbee-"></a></p>
<p dir="auto"><em>Your in-browser AI assistant. Control the web with natural language.</em></p>
<details open="">
  <summary>
    
    <span aria-label="Video description BrowserBee.mp4">BrowserBee.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/3098913/444794185-209c7042-6d54-4fce-92a7-ddf8519156c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1OTY5MDEsIm5iZiI6MTc0NzU5NjYwMSwicGF0aCI6Ii8zMDk4OTEzLzQ0NDc5NDE4NS0yMDljNzA0Mi02ZDU0LTRmY2UtOTJhNy1kZGY4NTE5MTU2YzYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDUxOCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA1MThUMTkzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTNlMWM1NjExYzNhOTMwODc4Yzg5NTA0NTBkMzdmZDUzNTFiZTQ1YzM5YzRlZGZlZTEzNWM1ZmQ2ZTE5N2I4NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.N5YjxKDp4BysxgpsacneRd-JQGb6wVCwuHgTzwhruIA" data-canonical-src="https://private-user-images.githubusercontent.com/3098913/444794185-209c7042-6d54-4fce-92a7-ddf8519156c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDc1OTY5MDEsIm5iZiI6MTc0NzU5NjYwMSwicGF0aCI6Ii8zMDk4OTEzLzQ0NDc5NDE4NS0yMDljNzA0Mi02ZDU0LTRmY2UtOTJhNy1kZGY4NTE5MTU2YzYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDUxOCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA1MThUMTkzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTNlMWM1NjExYzNhOTMwODc4Yzg5NTA0NTBkMzdmZDUzNTFiZTQ1YzM5YzRlZGZlZTEzNWM1ZmQ2ZTE5N2I4NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.N5YjxKDp4BysxgpsacneRd-JQGb6wVCwuHgTzwhruIA" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">BrowserBee is a privacy-first open source Chrome extension that lets you control your browser using natural language. It combines the power of an LLM for instruction parsing &amp; planning, and Playwright for robust browser automation to accomplish tasks.</p>
<p dir="auto">Since BrowserBee runs entirely within your browser (with the exception of the LLM), it can safely interact with logged-in websites, like your social media accounts or email, without compromising security or requiring backend infrastructure. This makes it more convenient for personal use than other "browser use" type products out there.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎲 Features</h2><a id="user-content--features" aria-label="Permalink: 🎲 Features" href="#-features"></a></p>
<ul dir="auto">
<li>Supports major LLM providers such as <strong>Anthropic</strong>, <strong>OpenAI</strong>, <strong>Gemini</strong>, and <strong>Ollama</strong> with more coming soon</li>
<li>Tracks <strong>token use</strong> and <strong>price</strong> so you know how much you're spending on each task</li>
<li>Has access to a wide range of <strong>🕹️ browser tools</strong> (listed below) for interacting and understanding browser state</li>
<li>Uses <strong>Playwright</strong> in the background which is a robust browser automation tool</li>
<li>The <strong>memory</strong> feature captures useful tool use sequences and stores them locally to make future use more efficient</li>
<li>The agent knows when to ask for user's <strong>approval</strong>, e.g. for purchases or posting updates on social media</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🕹️ Supported tools</h2><a id="user-content-️-supported-tools" aria-label="Permalink: 🕹️ Supported tools" href="#️-supported-tools"></a></p>
<details>
<summary><b>Navigation Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_navigate</strong></p>
<ul dir="auto">
<li>Navigate the browser to a specific URL. Input must be a full URL, e.g. <a href="https://example.com/" rel="nofollow">https://example.com</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_wait_for_navigation</strong></p>
<ul dir="auto">
<li>Wait until network is idle (Playwright).</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_navigate_back</strong></p>
<ul dir="auto">
<li>Go back to the previous page (history.back()). No input.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_navigate_forward</strong></p>
<ul dir="auto">
<li>Go forward to the next page (history.forward()). No input.</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Tab Context Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_get_active_tab</strong></p>
<ul dir="auto">
<li>Returns information about the currently active tab, including its index, URL, and title.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_navigate_tab</strong></p>
<ul dir="auto">
<li>Navigate a specific tab to a URL. Input format: 'tabIndex|url' (e.g., '1|<a href="https://example.com/" rel="nofollow">https://example.com</a>')</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_screenshot_tab</strong></p>
<ul dir="auto">
<li>Take a screenshot of a specific tab by index. Input format: 'tabIndex[,flags]' (e.g., '1,full')</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Interaction Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_click</strong></p>
<ul dir="auto">
<li>Click an element. Input may be a CSS selector or literal text to match on the page.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_type</strong></p>
<ul dir="auto">
<li>Type text. Format: selector|text (e.g. input[name="q"]|hello)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_handle_dialog</strong></p>
<ul dir="auto">
<li>Accept or dismiss the most recent alert/confirm/prompt dialog. Input <code>accept</code> or <code>dismiss</code>. For prompt dialogs you may append <code>|text</code> to supply response text.</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Observation Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_get_title</strong></p>
<ul dir="auto">
<li>Return the current page title.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_snapshot_dom</strong></p>
<ul dir="auto">
<li>Capture DOM snapshot of the current page with options for selector, clean, structure, and limit.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_query</strong></p>
<ul dir="auto">
<li>Return up to 10 outerHTML snippets for a CSS selector you provide.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_accessible_tree</strong></p>
<ul dir="auto">
<li>Return the AX accessibility tree JSON (default: interesting‑only). Input 'all' to dump full tree.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_read_text</strong></p>
<ul dir="auto">
<li>Return all visible text on the page, concatenated in DOM order.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_screenshot</strong></p>
<ul dir="auto">
<li>Take a screenshot of the current page with options for full page capture.</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Mouse Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_move_mouse</strong></p>
<ul dir="auto">
<li>Move the mouse cursor to absolute screen coordinates. Input format: <code>x|y</code> (example: <code>250|380</code>)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_click_xy</strong></p>
<ul dir="auto">
<li>Left‑click at absolute coordinates. Input format: <code>x|y</code> (example: <code>250|380</code>)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_drag</strong></p>
<ul dir="auto">
<li>Drag‑and‑drop with the left button. Input format: <code>startX|startY|endX|endY</code> (example: <code>100|200|300|400</code>)</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Keyboard Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_press_key</strong></p>
<ul dir="auto">
<li>Press a single key. Input is the key name (e.g. <code>Enter</code>, <code>ArrowLeft</code>, <code>a</code>).</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_keyboard_type</strong></p>
<ul dir="auto">
<li>Type arbitrary text at the current focus location. Input is the literal text to type. Use <code>\n</code> for new lines.</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Tab Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>browser_tab_list</strong></p>
<ul dir="auto">
<li>Return a list of open tabs with their indexes and URLs.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_tab_new</strong></p>
<ul dir="auto">
<li>Open a new tab. Optional input = URL to navigate to (otherwise blank tab).</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_tab_select</strong></p>
<ul dir="auto">
<li>Switch focus to a tab by index. Input = integer index from browser_tab_list.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>browser_tab_close</strong></p>
<ul dir="auto">
<li>Close a tab. Input = index to close (defaults to current tab if blank).</li>
</ul>
</li>
</ul>
</details>
<details>
<summary><b>Memory Tools</b></summary>
<ul dir="auto">
<li>
<p dir="auto"><strong>save_memory</strong></p>
<ul dir="auto">
<li>Save a memory of how to accomplish a specific task on a website. Use this when you want to remember a useful sequence of actions for future reference.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>lookup_memories</strong></p>
<ul dir="auto">
<li>Look up stored memories for a specific website domain. Use this as your FIRST step when starting a task on a website to check if there are any saved patterns you can reuse.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>get_all_memories</strong></p>
<ul dir="auto">
<li>Retrieve all stored memories across all domains. Use this when you want to see all available memories.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>delete_memory</strong></p>
<ul dir="auto">
<li>Delete a specific memory by its ID. Use this when a memory is no longer useful or accurate.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>clear_all_memories</strong></p>
<ul dir="auto">
<li>Clear all stored memories. Use this with caution as it will delete all memories across all domains.</li>
</ul>
</li>
</ul>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">✅ Use Cases</h2><a id="user-content--use-cases" aria-label="Permalink: ✅ Use Cases" href="#-use-cases"></a></p>
<ul dir="auto">
<li><strong>Social media butler</strong>: Checks your social media accounts, summarizes notifications and messages, and helps you respond.</li>
<li><strong>News curator</strong>: Gathers and summarizes the latest headlines from your preferred news sources and blogs, giving you a quick, personalized briefing.</li>
<li><strong>Personal assistant</strong>: Helps with everyday tasks like reading and sending emails and messages, booking flights, finding products, and more.</li>
<li><strong>Research assistant</strong>: Assists with deep dives into topics like companies, job listings, market trends, and academic publications by gathering and organizing information.</li>
<li><strong>Knowledge bookmarking &amp; summarization</strong>: Quickly summarizes articles, extracts key information, and saves useful insights for later reference.</li>
<li><strong>Chat with any website</strong>: Ask questions, generate summaries, fill out forms, etc.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛫 Roadmap</h2><a id="user-content--roadmap" aria-label="Permalink: 🛫 Roadmap" href="#-roadmap"></a></p>
<p dir="auto">Please refer to <a href="https://github.com/parsaghaffari/browserbee/blob/main/ROADMAP.md">ROADMAP.md</a> for an up to date list of features we're aiming to add to BrowserBee.</p>
<ul dir="auto">
<li>Support for saving and replaying sessions (macros)</li>
<li>Ability to memorize key information as needed (in your local Chrome instance using <a href="https://developer.chrome.com/docs/devtools/storage/indexeddb" rel="nofollow">IndexedDB</a>)</li>
<li>Scheduled task execution (e.g. check news and social media every morning)</li>
</ul>
<p dir="auto">If you're interested in contributing to build any of these features or to improve BrowserBee in any way, please head over to <a href="https://github.com/parsaghaffari/browserbee/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><g-emoji alias="arrow_forward">▶️</g-emoji> Installation</h2><a id="user-content-️-installation" aria-label="Permalink: ▶️ Installation" href="#️-installation"></a></p>
<p dir="auto">You have three options to install BrowserBee:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Download the latest release (Recommended)</h3><a id="user-content-option-1-download-the-latest-release-recommended" aria-label="Permalink: Option 1: Download the latest release (Recommended)" href="#option-1-download-the-latest-release-recommended"></a></p>
<ol dir="auto">
<li>Download the latest release from <a href="https://github.com/parsaghaffari/browserbee/releases/tag/v0.2.0-beta">GitHub Releases</a></li>
<li>Unzip the downloaded file</li>
<li>Load the extension in Chrome:
<ul dir="auto">
<li>Go to <code>chrome://extensions/</code></li>
<li>Enable "Developer mode" (toggle in the top-right corner)</li>
<li>Click "Load unpacked" and select the unzipped directory</li>
<li>Set your LLM API key(s) for Anthropic, OpenAI, Gemini, and/or configure Ollama in the options page that pops up</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Build from source</h3><a id="user-content-option-2-build-from-source" aria-label="Permalink: Option 2: Build from source" href="#option-2-build-from-source"></a></p>
<ol dir="auto">
<li>Clone this repository</li>
<li>Install dependencies with <code>npm install</code> or <code>pnpm install</code> (this takes ~3 minutes)</li>
<li>Build the extension with <code>npm run build</code> or <code>pnpm build</code></li>
<li>Load the extension in Chrome:
<ul dir="auto">
<li>Go to <code>chrome://extensions/</code></li>
<li>Enable "Developer mode"</li>
<li>Click "Load unpacked" and select the <code>dist</code> directory</li>
<li>Set your LLM API key(s) for Anthropic, OpenAI, Gemini, and/or configure Ollama in the options page that pops up</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Chrome Web Store (Coming Soon)</h3><a id="user-content-option-3-chrome-web-store-coming-soon" aria-label="Permalink: Option 3: Chrome Web Store (Coming Soon)" href="#option-3-chrome-web-store-coming-soon"></a></p>
<p dir="auto">BrowserBee will soon be available on the Chrome Web Store, pending review. Once approved, you'll be able to install it directly from the store with a single click.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏃‍♂️ Usage</h2><a id="user-content-️-usage" aria-label="Permalink: 🏃‍♂️ Usage" href="#️-usage"></a></p>
<ol dir="auto">
<li>Click the BrowserBee icon in your Chrome toolbar, or press <em>Alt+Shift+B</em>, to open the side panel</li>
<li>Type your instruction (e.g., <em>"Go to Google, search for Cicero, and click the first result"</em>)</li>
<li>Hit Enter and watch BrowserBee go to work 🐝</li>
</ol>
<p dir="auto"><strong>Note:</strong></p>
<ol dir="auto">
<li>Since BrowserBee uses Chrome DevTools Protocol (CDP) to attach to tabs, it's best to leave it attached to a base tab that you leave open throughout your session (BrowserBee can open new tabs if needed). If you close the attached tab, use the <a target="_blank" rel="noopener noreferrer" href="https://github.com/parsaghaffari/browserbee/blob/main/reattach-button.png"><img src="https://github.com/parsaghaffari/browserbee/raw/main/reattach-button.png" alt="reattach button"></a> button to reattach to a new tab.</li>
<li>You can have one instance of BrowserBee running per Chrome window and the instances will be working in isolation from one another.</li>
<li>BrowserBee can't attach to tabs without a URL (e.g. a new tab), or with URLs starting with 'chrome://' or 'chrome-extension://'.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">🫂 Acknowledgements</h2><a id="user-content--acknowledgements" aria-label="Permalink: 🫂 Acknowledgements" href="#-acknowledgements"></a></p>
<p dir="auto">BrowserBee is built using these amazing open source projects:</p>
<ul dir="auto">
<li><a href="https://github.com/cline/cline">Cline</a> enabled us to vibe-code the first version of BrowserBee and inspired me to build a "Cline for the web"</li>
<li><a href="https://github.com/ruifigueira/playwright-crx">playwright-crx</a> by <a href="https://github.com/ruifigueira">@ruifigueira</a> for in-browser use of Playwright</li>
<li><a href="https://github.com/microsoft/playwright-mcp">playwright-mcp</a> for the browser tool implementations</li>
<li><a href="https://daisyui.com/" rel="nofollow">daisyUI</a> 🌼 for the <del>pollen and nectar</del> UI components :)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">💡 Learnings &amp; what's worth stealing</h2><a id="user-content--learnings--whats-worth-stealing" aria-label="Permalink: 💡 Learnings &amp; what's worth stealing" href="#-learnings--whats-worth-stealing"></a></p>
<ol dir="auto">
<li><strong>Running Playwright in the browser.</strong> Playwright provides a robust and standard interface to LLMs for interacting with modern websites and web apps. Most "browser use" approaches I've come across like <a href="https://github.com/browser-use">Browser Use</a> and <a href="https://github.com/microsoft/playwright-mcp">Playwright MCP</a> are primarily designed for controlling a browser remotely in a backend service-browser fashion which is powerful for enterprise automations, whereas <a href="https://github.com/ruifigueira">@ruifigueira</a> has shown we can neatly wrap Playwright with a browser extension and reduce complexity for end-user use cases.</li>
<li><strong>"Reflect and learn" memory pattern.</strong> Certain setups are rich in feedback for AI agents. This is one of them, where the agent not only has a broad range of tools available to interact with the environment, but also has powerful observation abilities to understand the impact of its actions on the environment. For example, if the agent is tasked with completing a product purchase, where there is a good chance it's able to brute force its way to the end goal by using different tools (such as mouse and keyboard interactions), it can usually tell whether it has succeeded in the task or not by regularly taking screenshots. There is a valuable learning signal here for the agent and by invoking the agent to encode and memorise these learnings we can enhance future performance and increase efficiency on similar tasks, especially for smaller less capable models. In my limited testing, we can sometimes reduce the number of tokens needed (and therefore cost) for a task by 5x or more if we memorize the optimal tool sequence.</li>
<li><strong>Interacting with web pages remains a hard task for LLM-powered agents.</strong> DOMs and screenshots are complex, low-information-density modalities that are slow, expensive, and challenging to process for LLMs. Compare a web page to a piece code for instance: each token in a piece of code carries a lot more information on average than a token in an HTML page or pixels in a screenshot. Therefore we need a combination of cleverly simplified representations as well as cheaper/faster models for this type of product to become fully feasible.</li>
<li><strong>Why use an LLM at all?</strong>. The core value that an LLM agent can provide in this context is in <em>discovering</em> a path or a sequence of actions to accomplish a task which can then be encoded as a set of tool calls, or in fact plain JavaScript (see <a href="https://playwright.dev/docs/codegen" rel="nofollow">Playwright Codegen</a>); once a sequence is already known, it's trivial to follow - no LLM needed.</li>
<li><strong>Privacy-first personal AI tools are the way to go.</strong> There is no doubt that most of us will have some form of an always-on AI servant in the future, and I think the only way we can get there safely is through open source software that interacts transparently with our data and with LLMs. There is a lot of scope for building this type of software, and business models to support it (e.g. offering a hosted version), so I really hope to see and use more robust open source AI assistants.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">📜 License</h2><a id="user-content--license" aria-label="Permalink: 📜 License" href="#-license"></a></p>
<p dir="auto"><a href="https://github.com/parsaghaffari/browserbee/blob/main/LICENSE">Apache 2.0</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spaced repetition systems have gotten way better (534 pts)]]></title>
            <link>https://domenic.me/fsrs/</link>
            <guid>44020591</guid>
            <pubDate>Sun, 18 May 2025 11:42:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://domenic.me/fsrs/">https://domenic.me/fsrs/</a>, See on <a href="https://news.ycombinator.com/item?id=44020591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">
<article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
<h3 id="spaced-repetition-recap">Spaced repetition recap</h3>
<p>Mastering any subject is built on a foundation of knowledge: knowledge of facts, of heuristics, or of problem-solving tactics. If a subject is part of your full-time job, then you’ll likely master it through repeated exposure to this knowledge. But for something you’re working on part-time—like myself <a href="https://domenic.me/part-time-japanese">learning Japanese</a>—it’s very difficult to get that level of practice.</p>
<p>The same goes for subjects in school: a few hours of class or homework a week is rarely enough to build up an enduring knowledge base, especially in fact-heavy subjects like history or medicine. Even parts of your life that you might not think of as learning-related can be seen through this lens: wouldn’t all those podcasts and Hacker News articles feel more worthwhile, if you retained the information you gathered from them indefinitely?</p>
<p>Spaced repetition systems are one of the most-developed answers to this problem. They’re software programs which essentially display flashcards, with the prompt on the front of the card asking you to recall the information on the back of the card. You can read more about them <a href="https://notes.andymatuschak.org/Spaced_repetition_memory_system">in Andy’s notes</a>, or get a flavor from the images below drawn from my personal collection:</p>
<figure>
  <img src="https://domenic.me/images/fsrs-flashcard-sample-1-front.webp" width="912" height="1839" alt="A flashcard front containing the Japanese word 眼科医">
  <img src="https://domenic.me/images/fsrs-flashcard-sample-1-back.webp" width="912" height="1839" alt="A flashcard back containing the pronunciation of 眼科医, as well as its meaning and an example sentence">
  <img src="https://domenic.me/images/fsrs-flashcard-sample-2-front.webp" width="912" height="1839" alt="A flashcard front containing the prompt &quot;Number of neurons in a typical human brain&quot;">
  <img src="https://domenic.me/images/fsrs-flashcard-sample-2-back.webp" width="912" height="1839" alt="A flashcard back containing the answer &quot;86 billion&quot;">
</figure>
<p>What gives these programs their name is how they space out repeatedly prompting you to review the same card, depending on how you self-grade your response. Increasing intervals after correct answers prevents daily reviews from piling up. This is how you can, for example, learn 10 new second-language words a day (3,650 per year!) with only 20 minutes of daily review time.</p>
<p>(If you’re still unconvinced and have some time to spare, I suggest Michael Nielsen’s post <a href="https://augmentingcognition.com/ltm.html">Augmenting Long-term Memory</a>.)</p>
<h3 id="improving-the-scheduling-algorithm">Improving the scheduling algorithm</h3>
<p>So far, this is all well-known. But what’s less widely known is that a quiet revolution has greatly improved spaced repetition systems over the last couple of years, making them significantly more efficient and less frustrating to use. The magic ingredient is a new scheduling algorithm known as <a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/ABC-of-FSRS">FSRS</a>, by <a href="https://l-m-sherlock.github.io/">Jarrett Ye</a>.</p>
<p>To understand how these systems have improved, first let’s consider how they used to work. Roughly speaking, you’d get shown a card one day after creating it. If you got it right, you’d get shown it again after 6 days. If you get it right a second time, it’d be next scheduled for 15 days later. If you get the card right three times in a row, then it’s 37.5 days later. In general, after the 6-day interval, there’s an exponential backoff, defaulting to 6&nbsp;×&nbsp;2.5<sup>times&nbsp;correct&nbsp;+&nbsp;1</sup>. You can see how, if you keep getting the card right, this can lead to a large knowledge base, with only a small number of reviews per day!</p>
<p>But what if you get it wrong? Then, you’d reset back to day 1! You’d see the card again the next day, then 6 days after that, and so on. (Although missing the card can also adjust its “ease factor”, i.e. the base in the exponential that is by default set to 2.5.) This can be a fairly frustrating experience, as you experience a card ping-ponging between long and short intervals.</p>
<p>If we step back, we realize that this scheduling system (called “SuperMemo-2”) is pretty arbitrary. Where does the rule of 1, 6, 2.5<sup>times&nbsp;correct&nbsp;+&nbsp;1</sup>, reset back on failure come from? It turns out it was <a href="https://super-memory.com/english/ol/sm2.htm">developed by a college student in 1987</a> based on his personal experiments. Can’t we do better?</p>
<p>Recall <a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/Spaced-Repetition-Algorithm:-A-Three%E2%80%90Day-Journey-from-Novice-to-Expert#spaced-repetition">the theory behind spaced repetition</a>: we’re trying to beat the “forgetting curve”, by testing ourselves on the material “just before we were about to forget it”. It seems pretty unlikely that the forgetting curve for every single piece of knowledge is the same: that no matter what I’m learning, I’ll be just about to forget it after 1 day, then 6 more days, then 15, etc. And sure, we can throw in some modifications to the ease factor, but it’s still pretty unlikely that the ideal review schedule is a perfect exponential, even if you let the base vary a bit in response to feedback.</p>
<figure>
  <img src="https://domenic.me/images/fsrs-forgetting-curve.webp" width="1813" height="1019" alt="An illustration of the forgetting curve as a graph, with retention on the y-axis and time on the x-axis. You learn something on day 0, and your retention decays over time according to the forgetting curve, but reviewing it periodically spikes the retention back upward.">
  <figcaption>One of many illustrations of the forgetting curve. This one seems to have originated in <a href="https://www.osmosis.org/learn/Spaced_repetition">a lecture on osmosis.org</a>.</figcaption>
</figure>
<p>The insight of the FSRS algorithm is to concretize our goal (testing “just before we are about to forget”) as a prediction problem: <em>when does the probability of recalling a card drop to 90%?</em>. And this sort of prediction problem is something that machine learning systems excel at.</p>
<h3 id="some-neat-facts-about-how-fsrs-works">Some neat facts about how FSRS works</h3>
<p>The above insight—let’s apply machine learning to find the right intervals, instead of using an arbitrary formula—is the core of FSRS. You don’t really need to know how it works to benefit from it. But here’s a brief explanation of some of the details, since I think they’re cool.</p>
<p>FSRS calls itself a “three-component” model because it uses machine learning to fit curves for three main functions:</p>
<ul>
<li>Difficulty, a per-card number between 1 and 10 roughly representing how difficult the card is</li>
<li>Stability, which is how long a card takes to fall from 100% probability of recall to 90% probability of recall</li>
<li>Retrievability, which is the probability of recall after a given number of days</li>
</ul>
<p>For each card, it computes values for these based on <a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Algorithm">various formulas</a>. For example, the retrievability curve has been <a href="https://expertium.github.io/Algorithm.html#r-retrievability">tweaked over time</a> from an exponential to a power function, to better fit observed data.</p>
<p>The curve-fitting is done using 21 parameters. These parameters start with values derived to fit the curves from tens of thousands of reviews people have previously done. But the best results are found when you run the FSRS optimizer over your own set of reviews, which will adjust the parameters to fit your personal difficulty/stability/retrievability functions. (This parameter adjustment is where the machine learning comes in: the parameter values <a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-mechanism-of-optimization">are found</a> using techniques you may have heard of, like maximum likelihood estimation and stochastic gradient descent.)</p>
<p>Although the core FSRS algorithm concerns itself with predicting these three functions, as a user what you care about is card scheduling. For that, FSRS lets you pick a desired retention rate, with a default of 90%, and then uses those three functions to calculate the next time you’ll see a card, after you review it and grade yourself.</p>
<p>But if you want, you can change this desired retention rate. And because FSRS has detailed models of how you retain information, with its difficulty/stability/retrievability functions, it can simulate what your workload will be for any given rate. The maintainers <a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Optimal-Retention">suggest</a> that you set the desired retention to minimize your workload-to-knowledge ratio.</p>
<p>This can have fairly dramatic effects: below we see two simulations for my personal Japanese vocab deck, with the orange line being the default 90% desired retention, and the blue line being the 70% desired retention which FSRS has suggested I use to minimize the workload-to-knowledge ratio. The simulation runs for 365 days, adding 10 new cards per day as long as I have less than 200 reviews. As you can see, the 70% desired retention settings have dramatically fewer reviews per day, in less time, while ending with many more cards memorized (because it doesn’t hit the 200 card limit that caps new cards).</p>
<figure>
  <img src="https://domenic.me/images/fsrs-simulation-reviews.webp" width="751" height="367" alt="A graph with the orange line (90% target retention) quickly reaching 200, occasionally dropping below it for a day or two but always coming back, whereas the blue line (70% target retention) slowly trends up from around 60 at the start to 130 by the end.">
  <figcaption>Reviews per day</figcaption>
</figure>
<figure>
  <img src="https://domenic.me/images/fsrs-simulation-time.webp" width="751" height="367" alt="A graph with the orange line (90% target retention) oscillating around 24 minutes, whereas the blue line (70% target retention) slowly trends up from around 13 minutes at the start to 23 minutes by the end.">
  <figcaption>Time spent per day</figcaption>
</figure>
<figure>
  <img src="https://domenic.me/images/fsrs-simulation-memorized.webp" width="751" height="367" alt="A graph with the orange line (90% target retention) growing in a logarithmic fashion from 1639 cards memorized to 2602 cards memorized, whereas the blue line (70% target retention) trends more linearly from 1639 to 4476.">
  <figcaption>Number of cards memorized</figcaption></figure>

<p>(Note that the 90% number used when calculating the stability function is not the same as desired retention. It’s just used to predict the shape of the forgetting curve. The <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539081">original paper</a> used half-life, i.e. how long until the card reaches 50% probability of recall, since that’s more academic.)</p>
<h3 id="fsrs-in-practice">FSRS in practice</h3>
<p>If you want to use FSRS, instead of other <a href="https://github.com/open-spaced-repetition/srs-benchmark/blob/main/README.md#superiority">outperformed</a> algorithms, you have to use software that supports it. Thankfully, the leading spaced repetition software, <a href="https://apps.ankiweb.net/">Anki</a>, has incorporated FSRS as its default scheduling algorithm since version 23.10, released in 2023-11. You might already be using it!</p>
<p>(The <a href="https://l-m-sherlock.notion.site/The-History-of-FSRS-for-Anki-1e6c250163a180a4bfd7fb1fee2a3043">story</a> of how it got into Anki, by the way, is pretty cool. The creator of FSRS, <a href="https://medium.com/@JarrettYe/how-did-i-publish-a-paper-in-acmkdd-as-an-undergraduate-c0199baddf31">an undergrad at the time</a>, posted on the Anki subreddit about his new algorithm. A commenter challenged him to go implement his algorithm in software, instead of just publishing a paper. He first implemented it as an Anki add-on, and its growing popularity eventually convinced the Anki developers to bring it into the core code!)</p>
<p>Subjectively, I’ve found FSRS to be a huge upgrade to my quality of reviews over the previous, SuperMemo-2–derived Anki algorithm. The review load is much lighter. The feeling of despair when missing a card is significantly minimized, since doing so no longer resets you back to day 1. And the better statistical modeling FSRS provides gives me much more confidence that the cards Anki counts me as having learned, are actually sticking in my brain.</p>
<p>For Japanese language learning specifically, the advantages of FSRS are even stronger when you compare them to the “algorithms” used by two popular subscription services. <a href="https://www.wanikani.com/">WaniKani</a>, a kanji/vocab-learning site, and <a href="https://bunpro.jp/">Bunpro</a>, a grammar-learning site, use <em>extremely</em> unfortunate algorithms, even worse than the 1, 6, 2.5<sup>times&nbsp;correct&nbsp;+&nbsp;1</sup> rule from SuperMemo-2. They instead have picked out other interval patterns, seemingly from thin air:</p>
<ul>
<li><a href="https://knowledge.wanikani.com/wanikani/srs-stages/">For WaniKani</a>: 4 hours, 8 hours, 1 day, 2 days, 7 days, 14 days, 1 month, 4 months, never seen again</li>
<li><a href="https://community.bunpro.jp/t/bunpro-faq-frequently-asked-questions/876/1#heading--21">For Bunpro</a>: 4 hours, 8 hours, 1 day, 2 days, 4 days, 8 days, 2 weeks, 1 month, 2 months, 4 months, 6 months, never seen again</li>
</ul>
<p>These intervals don’t change per user or per card: they don’t even have an adjustable difficulty factor like the 2.5 base. And the idea that you’ll literally never see a card again after the last interval is terrifying, as it means you’re constantly losing knowledge.</p>
<p>But these aren’t even the worst part: the worst thing about these sites’ algorithms is that failing a card <em>moves it down one or two steps in the interval ladder</em>, instead of resetting to the first interval like SuperMemo-2, or predicting the best next interval using machine learning like FSRS. This greatly sabotages retention, wastes a lot of user time, and in general transforms these sites into a daily ritual of feeling bad about what you’ve forgotten, instead of feeling good about what you’ve retained. I wrote about this <a href="https://community.bunpro.jp/t/bunpros-bad-srs-algorithm-is-discouraging/90066">on the Bunpro forums</a> when I decided to ragequit about a year ago, in favor of Anki.</p>
<p>Stepping back, my takeaway from this experience is that Anki is king. People complain about how its UI is created by developers instead of designers, or how you have to find or make your own decks instead of using prepackaged ones. These are all fair complaints. But Anki is maintained by people who actually care about learning efficiently. It receives <a href="https://github.com/ankitects/anki/releases">frequent updates</a> that make it better at that goal. And it’s flexible enough to carry you through any stage of your knowledge-acquisition journey. Putting in the time to master it will provide a foundation that lasts you a literal lifetime.</p>
<h3 id="learn-more">Learn more</h3>
<p>If you’d like to learn more about this area, here are some of the links I recommend:</p>
<ul>
<li>Understanding the value of spaced repetition in general:
<ul>
<li><a href="https://augmentingcognition.com/ltm.html">Augmenting Long-term Memory</a> explains how the author uses Anki to “make memory a choice”, across all areas of his life.</li>
<li><a href="https://notes.andymatuschak.org/z2D1qPwddPktBjpNuwYFVva">Spaced repetition memory system</a> in Andy’s notes links to a variety of musings and resources on the subject.</li>
</ul>
</li>
<li>More on the story of spaced repetition
<ul>
<li><a href="https://expertium.github.io/History.html">Abridged history of spaced repetition</a> gives a short overview of how spaced repetition algorithms have evolved over time, mostly to highlight the big gap between SuperMemo-2 and FSRS.</li>
<li><a href="https://medium.com/@JarrettYe/how-did-i-publish-a-paper-in-acmkdd-as-an-undergraduate-c0199baddf31">How did I publish a paper in ACMKDD as an undergraduate?</a> is Jarrett’s first-person explanation of how he got interested in this space and ended up publishing.</li>
<li><a href="https://l-m-sherlock.notion.site/The-History-of-FSRS-for-Anki-1e6c250163a180a4bfd7fb1fee2a3043">The History of FSRS for Anki</a> is Jarrett’s account of how FSRS ended up in Anki, and how its integration has evolved over time.</li>
</ul>
</li>
<li>Details of how FSRS works:
<ul>
<li><a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/Spaced-Repetition-Algorithm:-A-Three%E2%80%90Day-Journey-from-Novice-to-Expert">Spaced repetition algorithm: a three-day journey from novice to expert</a> goes into more detail on the forgetting curve and other models behind creating a good spaced repetition algorithm.</li>
<li><a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Algorithm">The algorithm</a> gives the full details of the FSRS algorithm, and how it’s changed over time. (It’s best read bottom to top.)</li>
<li><a href="https://expertium.github.io/Algorithm.html">A technical explanation of FSRS</a> is a more-understandable-to-me explanation of the FSRS algorithm.</li>
<li><a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-mechanism-of-optimization">The mechanism of optimization</a> explains the exact training process for the FSRS parameters, in more detail than just “use machine learning”.</li>
<li><a href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Optimal-Retention">The optimal retention</a> discusses the knowledge acquisition vs. workload tradeoff.</li>
<li><a href="https://www.reddit.com/r/Anki/comments/1h9g1n7/clarifications_about_fsrs5_shortterm_memory_and/">Clarifications about FSRS-5, short-term memory and learning steps</a> dives into the extent to which FSRS can be used for short-term cramming, despite its design focused around long-term memory.</li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539081">A Stochastic Shortest Path Algorithm for Optimizing Spaced Repetition Scheduling</a> is the original paper that kicked this all off. Although the exact algorithm has been updated since then, it has all the usual academic paper goodies like comparison to previous work and pretty figures.</li>
</ul>
</li>
<li><a href="https://github.com/open-spaced-repetition/awesome-fsrs">open-spaced-repetition/awesome-fsrs</a> lists FSRS implementations in many programming languages, as well as flashcard and note-taking software that uses FSRS.</li>
<li><a href="https://github.com/open-spaced-repetition/srs-benchmark">open-spaced-repetition/srs-benchmark</a> benchmarks FSRS against a bunch of other systems, including SuperMemo-2, previous versions of FSRS, the Duolingo algorithm, and more. (Interestingly, the only consistent winner against FSRS is a LSTM neural network, based on OpenAI’s <a href="https://openai.com/index/reptile/">Reptile algorithm</a>. I’d love to learn more about that.)</li>
</ul>
<p><em>Thanks to <a href="https://expertium.github.io/">Expertium</a> who reviewed an earlier draft of this essay for their comments and corrections.</em></p>
<!--
  Removed for now because it's too old. Add back when it gets updated.

  * [Compare Anki's built in scheduler and FSRS](https://github.com/open-spaced-repetition/fsrs4anki/wiki/Compare-Anki's-built-in-scheduler-and-FSRS) gives a more detailed comparison of Anki's previous SuperMemo-2 algorithm with FSRS, taking into account the fact that the user can rate cards on a 1-4 difficulty scale, and that Anki has slightly tweaked its formula from the original SuperMemo-2 one discussed above.
-->

  </div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mexican Navy ship crashes into Brooklyn Bridge leaving two people dead (129 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/may/18/mexican-navy-ship-hits-brooklyn-bridge-during-promotional-tour</link>
            <guid>44019386</guid>
            <pubDate>Sun, 18 May 2025 06:23:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/may/18/mexican-navy-ship-hits-brooklyn-bridge-during-promotional-tour">https://www.theguardian.com/us-news/2025/may/18/mexican-navy-ship-hits-brooklyn-bridge-during-promotional-tour</a>, See on <a href="https://news.ycombinator.com/item?id=44019386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Two sailors from the Mexican navy were killed and another 11 critically hurt when a sailing ship taking part in a promotional tour in New York City collided with the iconic <a href="https://www.theguardian.com/us-news/brooklyn" data-link-name="in body link" data-component="auto-linked-tag">Brooklyn</a> Bridge, Mexico’s president Claudia Sheinbaum said.</p><p>The crash happened on Saturday night when the Cuauhtémoc – an academy training vessel with 277 people on board who shares a name with the last Aztec ruler – lost power and struck the bridge. <a href="https://x.com/newsnoteworthy/status/1923928821088108804?s=42" data-link-name="in body link">Eyewitness videos</a> showed dozens of sailors in ceremonial uniforms spread across yardarms shortly before the collision, which snapped the Cuauhtémoc’s three masts.</p><p>In an update <a href="https://x.com/Claudiashein/status/1923970585484267628" data-link-name="in body link">posted to X</a> on Sunday morning, Sheinbaum said: “We are deeply saddened by the loss of two crew members of the training ship Cuauhtémoc, who lost their lives in the unfortunate accident in New York.</p><p>“Our solidarity and support go out to their families. The ministry of the navy, with the support of local authorities, is currently attending to the wounded.”</p><p>A Mexican <a href="https://www.gob.mx/semar/prensa/la-secretaria-de-marina-informa-sobre-los-hechos-ocurridos-con-el-buque-escuela-velero-cuauhtemoc?idiom=es" data-link-name="in body link">government bulletin</a> said 22 crew members were injured, 11 of them critically, with nine in a stable condition. It confirmed that the two who died were navy cadets – and that officials were taking steps to reunite survivors with their families.</p><figure id="37764ae5-dd90-4521-a265-ca9658dda087" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-1"><picture><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="The New York Fire Department confirmed authorities were responding to injuries but had no details about how many people might have been hurt." src="https://i.guim.co.uk/img/media/16ec2375cac0d9937d754dece0e846bb478305a8/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Pedestrians walking along Brooklyn Bridge Park look on as a masted Mexican Navy training ship sits stranded near the Manhattan Bridge after colliding with the Brooklyn Bridge, Saturday.</span> Photograph: Nick Corso/AP</figcaption></figure><p>“The navy, aware of the risks naval personnel face in their operations, deeply regrets what happened and reaffirms its commitment to the crew’s families to provide timely attention and follow-up to the investigations into the events that occurred to accurately determine the causes of this incident,” the bulletin said.</p><p>The extent of the damage became apparent at first light on Sunday when images showed the vessel docked on the East River with the tops of two masts splintered – and a third dangling at a 45-degree angle.</p><p>Seven uniformed navy members were spotted boarding the ship, CNN reported.</p><p>Multiple videos of the crash showed the masts snapping and partially collapsing as they crashed into the deck of the bridge. There was heavy traffic on the bridge at the time of the collision.</p><p>The vessel, which was flying a giant green, white and red Mexican flag, then drifted toward the edge of the river as onlookers scrambled away from shore. Nobody was reported injured on the bridge, which was undamaged, said Eric Adams, the mayor of New York City, <a href="https://www.facebook.com/NYCMayor/posts/pfbid02pZzWkEVvQpnebCuW7W7YNrVUaR2dZfNGZEo37FMhJedpvzvEteaaJiamAEKY86m8l?__cft__[0]=AZXo-JFYY3Jt6RxrdPpvEDcZRiOb6MfB5QWjVFaQWOO7IUSJEZ8f8EO6zEGjwOK7Dq4Y_MnAqL2e83DjcB19OhQu-JH7YYqLCgI7Wj1cukYH5Bvf_d5cePfbjb7QD3IhUPL4X6sMEjtD__qUvMYKUf4PIyzZ8jIPx-bmRzUisZeeYw&amp;__tn__=%2CO%2CP-R" data-link-name="in body link">in a Facebook post</a>.</p><p>An earlier statement <a href="https://www.gob.mx/semar/prensa/por-la-exaltacion-del-espiritu-marinero-zarpa-el-buque-escuela-cuauhtemoc-para-iniciar-el-crucero-de-instruccion-consolidacion-de-la-independencia-de-mexico-2025?idiom=es" data-link-name="in body link">posted by the Mexican navy</a> said the Cuauhtémoc would be prevented from continuing its scheduled 254-day voyage. It was taking part in an ongoing celebration of the 200th anniversary of the independence of Mexico – achieved from Spain in 1821 – and was to have visited 22 ports in 15 countries to “carry the message of peace and goodwill of the Mexican people to the seas and ports of the world”.</p><p>It sailed from Acapulco on Mexico’s Pacific coast on 6 April and was due to make stops in a succession of countries around the Caribbean before crossing the Atlantic to Europe, including stopovers in Aberdeen and London.</p><p>Its crew consisted of 64 women and 213 men.</p><div><p>Sydney Neidell and Lily Katz told the Associated Press they were sitting outside to watch the sunset when they saw the vessel strike the bridge and one of its masts snap. </p><p>
 “We saw someone dangling, and I couldn’t tell if it was just blurry or my eyes, and we were able to zoom in on our phone and there was someone dangling from the harness from the top for like at least like 15 minutes before they were able to rescue them,” Katz said.</p><p>
 They said they saw two people removed from the ship on stretchers on to smaller boats.</p></div><p>The Brooklyn Bridge, which opened in 1883, has a nearly 1,600-foot (490 metres) main span that is supported by two masonry towers. More than 100,000 vehicles and an estimated 32,000 pedestrians cross every day, according to the city’s transportation department, and its walkway is a major tourist attraction.</p><p>The Cuauhtémoc – about 297 feet long and 40 feet wide (90.5 metres long and 12 metres wide), according to the Mexican navy – sailed for the first time in 1982. Each year it sets out at the end of classes at the naval military school to finish cadets’ training.</p><ul>
 <li>
  <p><em>The Associated Press contributed to this report</em></p></li>
</ul><figure id="b61b72b4-8ddb-4860-937e-3cb003e4919a" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Multiple people stand in front of a rocky outcrop looking at a damaged vessel." src="https://i.guim.co.uk/img/media/732638f1bf6077766f3cbb1bfd0c6f1f3d979ef6/0_0_3000_2001/master/3000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="296.815" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Pedestrians walking along Brooklyn Bridge Park look on as the training ship sits stranded near the Manhattan Bridge.</span> Photograph: Yuki Iwamura/AP</figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Experts have it easy (2024) (177 pts)]]></title>
            <link>https://boydkane.com/essays/experts</link>
            <guid>44018301</guid>
            <pubDate>Sun, 18 May 2025 01:31:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://boydkane.com/essays/experts">https://boydkane.com/essays/experts</a>, See on <a href="https://news.ycombinator.com/item?id=44018301">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Something that’s painfully understudied is how experts are more efficient
than novices while achieving better results. I say understudied and not
unstudied, because it’s common knowledge that charging people for their time
results in experts being paid less since they work faster, which is why experts
charge more for their time.</p>
<p>This effect is understudied in the impact it has on novices entering a field. A
Novice will start out being woefully inefficient, putting in incredible amounts
of effort and running through all number of mental hoops in order to maintain
the growing pile of unmaintainable abstractions they’ve developed. An expert
doesn’t have to jump through these hoops. They can more clearly see the actual
problem at hand and will more efficiently put their time and effort towards
making progress against the problem. In contrast, novices will spend more time
battling problems they created for themselves. Let’s explore this idea by
looking at two characters entrapped in a maze, and how they go about escaping.</p>
<h3 id="stuck-in-a-maze-expert-vs-novice">Stuck in a maze: Expert vs Novice</h3>
<blockquote>
<p>Imagine a world-class navigator being set in a maze. They come well prepared
with compass and paper, and have previously escaped some of the most
dastardly mazes designed by man. Also, imagine yourself. You’re the Novice in
this scenario. You didn’t realise you were being thrown into a maze. You
don’t even know if the goal is to get out or to find the centre.</p>
<p>As you go deeper and deeper into the maze, you realise that you’re helplessly
lost. Through a miracle of literary convenience, your expert friend calls you
up and offers advice: “As soon as you start, keep track of where you’ve been
using your ball of twine. It’ll help you keep track of the decisions you make”.</p>
<p>You didn’t realise the criticality of feline playthings, and so didn’t bring
a ball of twine. You also don’t remember where you started. You ask your
expert friend for advice on what to do, to which they respond “Oh I’ve got no
idea. I never go anywhere without my ball of twine. You just shouldn’t have
gotten yourself into this mess in the first place.”</p>
</blockquote>
<p>Some of the trickiest tangles I’ve tackled haven’t been because the core
problem is difficult, but rather because I was helping someone with less
experience, and they spent several hours getting themselves more and more tied
up. Before asking for help, they made a wrong decision, which maybe solved
their short term problems but shot them in the foot in the long term. This bad
decision made other bad decisions more likely until they were helplessly stuck
in a trap of their own making.</p>
<p>Often this trap is far trickier than anything an expert would let themselves
get into. Novices, on the other hand, can easily make a sequence of bad
decisions that result in an ever increasing cost of solving the problem at
hand. Not only are you lost in the maze without your twine, but you also went
in a mysterious cave that looked kinda interesting at first and now you’re lost
in the dark. Meanwhile, the world-class expert is happily skipping through the
warm sunny parts of the maze, because they knew that the cave would eventually
lead to a dead end.</p>
<p>I’d like to stress at this point that this is in no way the Novice’s fault.
They followed the same policy as any expert: “take best action available to you
at the time”. Telling a Novice to “just be better” is not constructive
feedback. This feedback does not lead to them improving over time, since from
the only perspective that matters in this scenario (the Novice’s), they were
taking the best action available to them. And if you’re giving feedback that
doesn’t lead to improvement, what’s the point of the feedback?</p>
<h3 id="the-novice-has-a-genius-idea">The Novice has a genius idea</h3>
<blockquote>
<p>Still lost in the maze, you keep walking. Your friend mentioned the ball of
twine, and after thinking for a bit you realise your woollen jumper, if
carefully dismantled, could be a good replacement. Dutifully and with a
concrete objective, you sit down and begin to unravel your jumper. After an
hour or so, you’ve got your ball of yarn. After some failed attempts at
unspooling the yarn behind you, you realise one strand of yarn is hopelessly
weak. You decide to braid the yarn, and sit down for another hour to do so.
It’s pretty boring, but you assume that this is just what solving mazes is
all about.</p>
<p>A bit later, your expert friend calls you up and lambastes you for wasting
time with this yarn business. “It was clearly never going to work” he says.
He instructs you to use broken branches from the hedge that makes up
the maze as a way of marking your path. You hadn’t realised the maze was made
of hedge until this point.</p>
</blockquote>
<p>Novices often spend energy fixing things that are orthogonal to the actual
problem they want to solve, whereas experts are able to better direct their
energy towards the problems they want to solve. This leads to novices having an
extremely distorted view of a field, because the problems they end up solving
are both more difficult and less interesting than those being tackled by
experts. Nobody wants to put more effort into figuring out a more boring
problem.</p>
<h3 id="the-novices-search-strategy">The Novice’s search strategy</h3>
<blockquote>
<p>Finally, with a means of marking the paths you’ve taken, you set out to
traverse the maze. Or maybe to escape it, you’re still not sure. You stride
along, breaking and placing branches as you go. You’re not really sure which
paths are the best, so you mostly just pick at random.</p>
</blockquote>
<p>For a Novice, the vast majority of decisions have to be made essentially
randomly, with very little information going into the choice. If all decisions
were sequential and did not depend on any other decision, a dedicated Novice
could come up with a solution better than random chance after thinking hard
about the decision. But the world we live in is fractal and complexly
dependent; many decisions depend on other decisions in ways that a Novice has
no idea about. Even a dedicated Novice will be confronted with situations in
which they must make several inter-dependent decisions before they can get
feedback on the efficacy of those decisions. The Novice is (at first) forced to
make completely arbitrary choices and face the consequences. Hopefully they can
learn which consequences were due to which decisions, but this isn’t always
feasible.</p>
<p>From the perspective of an expert, the decisions taken while solving a problem
are often second nature, and yet are carefully crafted so as to avoid
unnecessary trouble down the road. A Novice looking upon an expert’s work would
be hard-pressed to distinguish these few important decisions (based on years of
hard work and study) from the myriad of far less important decisions (based
largely on personal taste).</p>
<h3 id="novices-dont-even-see-the-decision">Novices don’t even see the decision</h3>
<blockquote>
<p>You’re breezing through a particularly long and straight bit of the maze when
your expert friend calls you up once again. “Why didn’t you take that right a
few meters back?”, they ask. There was none, you assert, and glancing behind
you confirms this fact.</p>
<p>Just in case, you retrace your steps, and sure enough there’s a sliver of a
gap in the hedges which you suppose could be a path to take. It’s terribly
cramped and overgrown compared to the wide clean paths you’ve been taking so
far, but it <em>is</em> a path. Looking around carefully now, you realise the hedges
are actually packed with cracks and gaps and thin spots. Who knows how many
paths you’ve missed?</p>
</blockquote>
<p>Sometimes the Novice doesn’t even know that there’s a decision to make. When
the decision is pointed out by the friendly expert, the Novice can often either
make the correct decision or appreciate the correct solution when it’s shown to
them. But the Novice <em>didn’t even know there was a decision in the first
place</em>. This makes it incredibly difficult for the ambitious Novice to make
progress without outside help. They cannot just “check their work for
mistakes”, because for any substantial body of work the Novice likely wouldn’t
be able to point out half their decisions.</p>
<h3 id="experts-cant-explain-their-decisions">Experts can’t explain their decisions</h3>
<blockquote>
<p>You squeeze through this gap in the hedge recommended by your expert friend.
Before long, you come to a fork in the maze: one path leads left, the other
right. The left path looks a bit wider and a bit brighter, but having learnt
from your mistakes you decide to call up your expert friend to get their
advice and learn from their wisdom. “The right path is better.”, your friend
declares. You ask for an explanation, but they are unable to give anything
more specific than “The right path is a stronger option, it’s clearly got the
right look about it. There’s no chance it’ll let you down.”</p>
<p>Frustrated at the lack of intelligible wisdom, you take the right path. And
sure enough, it looks like it was the correct decision. The path clears up
and starts to head towards the exit, as far as you can tell. But you still
don’t understand what your expert friend saw, and it seems like they don’t
understand what they saw either.</p>
</blockquote>
<p>The expert’s intuition is often formidable, but rarely comprehensible. This
inability to clearly explain their decisions is what makes it so useful for
novices to spend time with experts. Often there’s an underlying pattern that
the novice can pick up through careful observation, even if neither the expert
nor the novice can properly articulate this pattern.</p>
<h3 id="the-experts-ensemble">The Expert’s ensemble</h3>
<blockquote>
<p>Your expert friend is chastising you for missing the obvious gap in the
hedge, and for not realising you could climb over hedges, and for not
bringing a hedge trimmer, and for a myriad of other choices that you made
without even realising you had the option to do differently. As your eyes
glaze over, you hear someone call to your friend through the phone. Turns
out, your expert friend has expert friends of their own, and they’re all
helping each other! “I thought I was meant to figure it out on my own” you
cry, but your friend asks whatever gave you that idea.</p>
<p>You ask how you too can get a network of peers who can help you through the
maze. Your friend says to join some online chat rooms. Unfortunately for you,
they’re all speaking incomprehensible jargon or debating optimal twine
spooling techniques.</p>
</blockquote>
<p>Experts often have either a network of people, or (more frequently nowadays)
know the online network of websites and usernames which can guide their
thoughts. They can quickly distinguish useful insight from helplessly generic
summaries, and don’t have to spend much time looking for the information
they’re after. But a Novice has <em>no clue</em> about how to distinguish the two, nor
how to find communities who can help them effectively.</p>
<h3 id="escape">Escape</h3>
<blockquote>
<p>Eventually, you finish the maze. Not wanting to repeat the experience of
being a complete Novice, you dedicate yourself to learning more and to not
falling ill to the traps of being a Novice. But how, exactly, should you do
that?</p>
</blockquote>
<p>As a Novice, you <em>need</em> to find a sympathetic expert on your side to help you
out and to whom you can ask all questions, regardless of how trivial the
questions might be. A replacement for this is finding a lot of experts so you
can spread the load amongst them. You can go very far online nowadays, and even
more so with AI tools. But many of the above trappings that novice’s succumb to
do not magically disintegrate because you have access to the internet or to a
chatbot. You still don’t know how to recognise subtle decisions. You still
don’t know how to distinguish good ideas from bad. You still don’t know how to
avoid long-term cascades due to bad choices. The internet helps, for sure, but
having someone by your side is monumentally better.</p>
<p>One thing that can be tricky to convey to your friendly expert, is that
sometimes you just need to be able to show them what you’re doing without any
specific question in mind. I’ve often found that I can feel uneasy about what
I’m doing, and then talking with an expert friend will quickly surface that
I’ve made some error that will cause pain later. Having someone who’s happy to
spend time “just talking”, without any specific goal to solve, will go a long
way.</p>
<p>In the workplace, this style of “just talking” interactions between novices and
experts is critical for knowledge transfer and training. But novices rarely
have a voice with key decision makers, and so promoting these interactions is
often neglected. It is not sufficient to instruct senior employees to answer
the newcomer’s questions, since the vast majority of learning comes from a
novice watching how the expert plies their skills, and not from direct
questions and answers. What makes this scenario even trickier is that the
expert will likely think “just talking” interactions are basically worthless,
but answering concrete questions <em>feel</em> much more useful. The novice, on the
other hand, could likely discover answers to concrete questions on their own,
given enough time. But developing the intuitions that come through while an
expert is “just talking” with a novice is incredibly valuable to the novice.
This explains the difficulty of training new employees when all your experts
are working remotely, as remote work practically eliminates any sort of casual
unguided “water-cooler” interaction.</p>
<p>Something you can do independently (and possibly it’s best done without expert
supervision), is exploration of the field. You know nothing, and have no biases
about what may or may not be useful. <em>Any</em> time you come across something that
feels like it has some depth to it, such as a well-written essay series or a
deep technical dive, you need to invest heavily into it. As a novice, your one
advantage is that <em>everything</em> is new and nobody expects you to be fast.
Because of this, you can afford to spend the time to learn as much as possible.</p>
<p>I honestly don’t think it’s possible to overdo this. Spending a week exploring
some specific arcana of your field is probably going to pay dividends, because
all of a sudden you’re expert-level in this (<em>tiny</em>) aspect of the field. You
can go head-to-head with an expert, since they last read about that weird
subdomain 5 years ago. Don’t study the “common” things, but go all-in on the
niche pockets. The common things are common enough that you’ll learn them
through osmosis regardless of what your main activity is. But the niche things
require active study, and ignoring the niches is how you remain a novice.</p>
<p>Amongst all of this, the novice needs courage (to make decisions without
knowing the consequences) and confidence (so that they whole-heartedly commit
to their decisions and grant them the greatest chance of success). These traits
are not trivial, and confidence can easily be crushed by a snide comment from
an expert. I don’t want to imagine how many promising novices have been spurned
by unimpressive experts. In this way, advice from a sour-hearted expert is
worse than no expert advice at all due to the risk of destroying the novice’s
confidence.</p>
<h3 id="closing-thoughts">Closing thoughts</h3>
<p>The lack of consistent empathy between experts and novices would suggest that,
despite feeling easy, it is in fact difficult. I’ve written more about this
<a href="https://boydkane.com/hard" data-slug="hard">here</a>.</p>
<p>In the extreme case, this lack of empathy leads to experts deriding the work of
novices as not having the prestige/class/taste/status expressed so deftly by
the work of the experts.</p>
<p>This is self-fulfilling: novices will either conform to the expert’s sense of
aesthetics, dismiss the field of study as “not for them”, or (in rare cases)
work incredibly hard to prove the experts wrong after all. In this last case,
the Novice becomes an expert anyway. Experts tend to have an aesthetic
preference towards technically challenging work rather than
simple-but-interesting work, and I’ve written more about this phenomenon here:
<a href="https://boydkane.com/expert_aesthetics" data-slug="expert_aesthetics">expert aesthetics</a>.</p>
<hr>
<p>Discuss this essay on <a href="https://www.reddit.com/r/programming/comments/1knu1w1/senior_devs_arent_just_faster_theyre_dodging/">r/programming<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://www.reddit.com/r/theprimeagen/comments/1knescv/senior_devs_arent_just_faster_theyre_dodging/">r/ThePrimeagen<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://news.ycombinator.com/item?id=43664345">Hacker
News<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://www.lesswrong.com/posts/rfrRxFuas2mgv8RGY/experts-have-it-easy">Less Wrong<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://beyarkay.substack.com/p/experts-have-it-easy">Substack<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://lobste.rs/s/qwmcoa/senior_devs_aren_t_just_faster_they_can">lobse.rs<svg viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, or using the comment
box below.</p>
<p>Thanks to Daniël Goosen, Paul Hoft von Hoesslin, Dr Lisa Kane, and Tegan Green,
and the AI Safety Cape Town writing group chat for reviewing drafts of this
essay.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tornado warnings delayed because of DOGE cuts (136 pts)]]></title>
            <link>https://www.mesoscalenews.com/p/tornado-warnings-delayed-because</link>
            <guid>44018247</guid>
            <pubDate>Sun, 18 May 2025 01:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mesoscalenews.com/p/tornado-warnings-delayed-because">https://www.mesoscalenews.com/p/tornado-warnings-delayed-because</a>, See on <a href="https://news.ycombinator.com/item?id=44018247">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Of all the disasters I’ve studied, tornadoes scare me the most.</p><p>They come with little warning and can erase entire communities in minutes — even seconds.</p><p>There’s no four-day lead-up to prepare like we often have with major hurricanes, and the winds of these storms can far exceed the most violent tropical cyclones.</p><p>In those few moments before one hits, especially if you’re sleeping, you’re at the mercy of your local weather station. </p><p>If someone is watching, they can issue a warning in those critical minutes before it’s too late.</p><p><span>Those few minutes after an emergency alert is issued are the </span><a href="https://www.cnn.com/2019/05/29/us/weather-alert-tech-saved-lives-trnd/index.html#:~:text=They%20also%20save%20lives&amp;text=He%20shepherded%20the%20flock%20to,Hennen%20contributed%20to%20this%20story." rel="">difference between life and death</a><span>. </span></p><p><span>That’s why experts were shocked and outraged by</span><a href="https://www.latimes.com/california/story/2025-04-17/californias-national-weather-service-offices-reduce-services-amid-trump-admin-cuts#:~:text=On%20Thursday%2C%20the%20department%20announced,staffing%20limitations%20or%20operational%20priorities.%E2%80%9D" rel=""> budget cuts </a><span>made to the National Weather Service earlier this year.</span></p><p><span>Some offices were forced to </span><a href="https://www.cnn.com/2025/05/02/weather/nws-forecasting-layoffs-trump#:~:text=One%20NWS%20forecast%20office%2C%20in,stretch%20into%20the%20Pacific%20Northwest." rel="">no longer operate 24 hours a day </a><span>back in April.</span></p><p>In the Jackson, Kentucky NWS office, one of the positions they were forced to cut was the full-time overnight forecaster.</p><p>The office's website even lists the "Meteorologist in Charge" position as vacant.</p><p><a href="https://www.nbcnews.com/science/environment/noaa-scrambling-fill-forecasting-jobs-cuts-national-weather-service-rcna207050" rel="">Overnight forecasters </a><span>are responsible for monitoring severe weather outbreaks and issuing warnings while one of the most tornado-prone areas in the countries is sound asleep.</span></p><p>“It’s only a matter of time before these cuts lead to tragedy,” I said back in February.</p><p>Just before midnight last night, tragedy struck.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg" width="1456" height="1820" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf1204d0-dd21-493d-b55a-0394aebc6880_1800x2250.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Photo by Austin Anthony for the New York Times. </span><a href="https://www.nytimes.com/2025/05/17/weather/storms-tornadoes-missouri-kentucky.html" rel="">Link here.</a></figcaption></figure></div><p><strong><span>At least </span><a href="https://www.foxweather.com/weather-news/deadly-tornado-outbreak-ohio-valley-kentucky-missouri-indiana" rel="">27 people are dead</a><span>,</span></strong><span> with more still missing, across Missouri and Kentucky.</span></p><p>Tornado warnings were delayed because of reduced staff. Those critical moments — a midnight warning to your phone waking you up, giving you precious seconds to find shelter — came too late for some.</p><p>The risk of these cuts creating this exact problem was known before last night.</p><p><span>Just one day before the disaster, on May 15, the New York Times ran an </span><a href="https://www.nytimes.com/2025/05/15/us/politics/national-weather-service-cuts-trump.html" rel="">investigative piece</a><span> about how DOGE cuts were undermining weather forecasting improvements.</span></p><p><span>The piece </span><em><strong>specifically included the Jackson, Kentucky</strong></em><span> NWS office as one targeted by DOGE for layoffs.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png" width="1456" height="618" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:618,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:276785,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.mesoscalenews.com/i/163800038?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F084c8936-1c9d-40d8-b331-551a34dfcefa_1782x756.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Severe weather is expected to continue today and tomorrow, and NOAA’s new PR team, now run by Trump loyalists, is scrambling to deny and diffuse the situation.</p><p>We can’t ask those who died if they received the warning, so we might never know how many lives would have been saved by having minimal staffing standards in NWS offices. </p><p>As the MAGA-rampage against science continues unabated, how many more will pay for the ignorance of this administration?</p><p><span>With an </span><a href="https://www.mesoscalenews.com/p/2025-atlantic-hurricane-season-outlook" rel="">above-normal hurricane season </a><span>starting in two week, how far will Americans let these threats to public safety go?</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AniSora: Open-source anime video generation model (312 pts)]]></title>
            <link>https://komiko.app/video/AniSora</link>
            <guid>44017913</guid>
            <pubDate>Sat, 17 May 2025 23:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://komiko.app/video/AniSora">https://komiko.app/video/AniSora</a>, See on <a href="https://news.ycombinator.com/item?id=44017913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>The most powerful open-source animated video generation model presented by Bilibili. AniSora enables one-click video generation across diverse anime styles including series episodes, Chinese animations, manga adaptations, VTuber content, anime PVs, and more.</p></div><div><div tabindex="-1"><div><h2>Input</h2></div><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M537.6 226.6c4.1-10.7 6.4-22.4 6.4-34.6 0-53-43-96-96-96-19.7 0-38.1 6-53.3 16.2C367 64.2 315.3 32 256 32c-88.4 0-160 71.6-160 160 0 2.7.1 5.4.2 8.1C40.2 219.8 0 273.2 0 336c0 79.5 64.5 144 144 144h368c70.7 0 128-57.3 128-128 0-61.9-44-113.6-102.4-125.4zM393.4 288H328v112c0 8.8-7.2 16-16 16h-48c-8.8 0-16-7.2-16-16V288h-65.4c-14.3 0-21.4-17.2-11.3-27.3l105.4-105.4c6.2-6.2 16.4-6.2 22.6 0l105.4 105.4c10.1 10.1 2.9 27.3-11.3 27.3z"></path></svg><p>Tap to upload or drag your image here</p></div><p><label>Prompt</label></p></div><div tabindex="-1"><h2><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"></path></svg> <!-- -->Animation Results</h2><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="48" width="48" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M15 2c-2.71 0-5.05 1.54-6.22 3.78a7.062 7.062 0 0 0-3 3A7.014 7.014 0 0 0 2 15c0 3.87 3.13 7 7 7 2.71 0 5.05-1.54 6.22-3.78a7.062 7.062 0 0 0 3-3A7.014 7.014 0 0 0 22 9c0-3.87-3.13-7-7-7zM9 20a5.002 5.002 0 0 1-4-8c0 3.87 3.13 7 7 7-.84.63-1.88 1-3 1zm3-3a5.002 5.002 0 0 1-4-8c0 3.86 3.13 6.99 7 7-.84.63-1.88 1-3 1zm4.7-3.3c-.53.19-1.1.3-1.7.3-2.76 0-5-2.24-5-5 0-.6.11-1.17.3-1.7.53-.19 1.1-.3 1.7-.3 2.76 0 5 2.24 5 5 0 .6-.11 1.17-.3 1.7zM19 12c0-3.86-3.13-6.99-7-7a5.002 5.002 0 0 1 7 7z"></path></svg><p>Your animation results will appear here</p><p>Upload an image and provide a prompt to get started</p></div></div></div><div><h2>AniSora AI Anime Video Generation Examples</h2><p>Explore a variety of AI-generated videos created with Bilibili's AniSora. Witness its capability to animate still images into dynamic anime and manga scenes, bringing your favorite characters and stories to life with smooth, coherent animation and rich detail. Discover the power of open-source AI in anime video creation.</p></div><h2>What is AniSora?</h2><p>AniSora is the most powerful open-source animated video generation model developed by Bilibili. As part of Project Index-AniSora, it represents Bilibili's open-source gift to the anime world. AniSora enables one-click video creation across a wide range of anime styles, including series episodes, Chinese original animations, manga adaptations, VTuber content, anime PVs, and more. It is powered by IJCAI'25-accepted research: AniSora — Exploring the Frontiers of Animation Video Generation in the Sora Era.</p><p>🤗 <a href="https://huggingface.co/IndexTeam/Index-anisora" target="_blank" rel="noopener noreferrer nofollow">Hugging Face</a>&nbsp;&nbsp; | &nbsp;&nbsp; 🤖 <a href="https://www.modelscope.cn/organization/bilibili-index" target="_blank" rel="noopener noreferrer nofollow">Model Scope</a></p><div><h2>How to Use AniSora with Komiko</h2><div><div><p>1</p><div><h3>Upload Your Image</h3><p>Begin by uploading a high-quality reference image you wish to animate into a dynamic video using AniSora AI Video Generator.</p></div></div><div><p>2</p><div><h3>Select Your AI Model</h3><p>Choose from available AI video generation models tailored for various visual styles and video qualities to match your creative vision.</p></div></div><div><p>3</p><div><h3>Generate and Download Video</h3><p>Click the generate button to initiate AniSora's AI-powered video creation. Once processing is complete, preview and download your high-quality AI-generated video for instant use.</p></div></div></div></div><div><h2>Explore Popular AI Tools</h2><p>Expand your creative horizons with more related AI tools.</p></div><div><h2>Why use AniSora AI Video Generator?</h2><p>AniSora by Bilibili offers a specialized, open-source approach to AI video generation, meticulously tailored for anime, manga and comics content. This makes it the ideal tool for creators aiming to materialize their artistic visions with AI-powered animation, particularly for Japanese anime, Chinese animation, and manga adaptations.</p><div><div><div><p><span>🌸</span></p><h3>Specialized for Anime &amp; Manga Styles</h3></div><p>AniSora's AI models are expertly trained on vast datasets of anime and manga, ensuring high-quality animation that authentically captures the unique visual characteristics and artistic nuances of these beloved styles, including popular manga adaptations.</p></div><div><div><p><span>🎨</span></p><h3>Intuitive Interface</h3></div><p>AniSora provides an intuitive interface, making AI video generation accessible to everyone, regardless of technical expertise. Bring your anime, manga, and VTuber content to life effortlessly with our one-click generation.</p></div><div><div><p><span>🌟</span></p><h3>High-Quality Animated Video</h3></div><p>AniSora supports high-resolution video output, ensuring your AI-generated animated creations, from series episodes to promotional videos, look crisp and professional across all platforms. Share your AI-powered anime and manga videos with confidence.</p></div></div></div><div><h2>AniSora AI Video Generator FAQ</h2><p>Find answers to common questions about AniSora, the open-source AI anime video generator. Learn about its features for creating animations, usage tips, and how it can help you bring your stories to life, including for VTuber content and manga adaptations.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal agencies continue terminating all funding to Harvard (109 pts)]]></title>
            <link>https://arstechnica.com/science/2025/05/feds-continue-effort-to-defund-research-at-harvard/</link>
            <guid>44017740</guid>
            <pubDate>Sat, 17 May 2025 23:23:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2025/05/feds-continue-effort-to-defund-research-at-harvard/">https://arstechnica.com/science/2025/05/feds-continue-effort-to-defund-research-at-harvard/</a>, See on <a href="https://news.ycombinator.com/item?id=44017740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>On Tuesday, the federal government's Joint Task Force to Combat Anti-Semitism announced that it had terminated research grants to Harvard totalling $450 million, spread out across eight federal agencies. The move comes on the heels of $2.2 billion in earlier cuts and an announcement that the university will be prevented from receiving any future grants. The ongoing campaign appears to be heading toward a point where no researchers at Harvard will receive federal funding.</p>
<p><a href="https://www.hhs.gov/press-room/anti-semitism-task-force-statement-on-additional-harvard-grants.html">The announcement</a> reiterates accusations that are familiar from earlier federal funding terminations. It references antisemitic incidents during earlier protests about Israel's actions in Gaza and the fact that the Harvard Law Review has taken steps to diversify the authors it publishes, which the government considers illegal discrimination. Notably, the letter does not mention any more recent events, nor Harvard's efforts to address antisemitism on campus, saying:</p>
<blockquote><p>Harvard’s campus, once a symbol of academic prestige, has become a breeding ground for virtue signaling and discrimination. This is not leadership; it is cowardice. And it’s not academic freedom; it’s institutional disenfranchisement. There is a dark problem on Harvard’s campus, and by prioritizing appeasement over accountability, institutional leaders have forfeited the school's claim to taxpayer support.</p></blockquote>
<p>It's generally difficult to understand the big picture of these cuts and the reasons for them from this announcement. Instead, it has to be pieced together from the multitude of letters that individual agencies have sent Harvard.</p>
<p>Multiple federal agencies, including the&nbsp;<a href="https://storage.courtlistener.com/recap/gov.uscourts.mad.283718/gov.uscourts.mad.283718.59.7.pdf" target="_blank" rel="noopener">Department of Energy</a><span>,&nbsp;</span><a href="https://storage.courtlistener.com/recap/gov.uscourts.mad.283718/gov.uscourts.mad.283718.59.9.pdf" target="_blank" rel="noopener">the National Science Foundation</a><span>,</span> and the <a href="https://storage.courtlistener.com/recap/gov.uscourts.mad.283718/gov.uscourts.mad.283718.59.8.pdf" target="_blank" rel="noopener">Department of Defense</a><span>, </span>also sent letters announcing the grant terminations on Tuesday. These sometimes contain more specific accusations, such as the Department of Energy letter, which specifically terms Harvard's efforts to address past problems as insufficient. "Harvard has refused to take immediate, definitive and appropriate remedial action," the letter said.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lost Japanese ROM of the Macintosh Plus (147 pts)]]></title>
            <link>https://www.journaldulapin.com/2025/05/17/the-lost-japanese-rom-of-the-macintosh-plus-which-isnt-lost-anymore/</link>
            <guid>44017692</guid>
            <pubDate>Sat, 17 May 2025 23:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.journaldulapin.com/2025/05/17/the-lost-japanese-rom-of-the-macintosh-plus-which-isnt-lost-anymore/">https://www.journaldulapin.com/2025/05/17/the-lost-japanese-rom-of-the-macintosh-plus-which-isnt-lost-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=44017692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p>If you look for information about the Macintosh Plus and its ROM, you’ll usually find that the ROM has a capacity of 128 KB and that it exists in <a href="https://www.tech-insider.org/mac/research/acrobat/8803-f.pdf">three revisions</a>. But that’s incorrect: there’s a fourth ROM, 256 KB in size, which includes fonts for kanji (Japanese characters). And I found (and preserved) this ROM.<br>
<span id="more-112672"></span><br>
I’m Belgian, and the article was originally written in French before being translated automatically.</p>
<p>I had talked about this mysterious ROM <a href="https://www.journaldulapin.com/2019/05/04/macintosh-plus-rom/">a few years ago</a>. It’s documented by Apple in <a href="https://spinsidemacintosh.neocities.org/tn405#tn138">some old documents</a>, but without much detail. According to Apple, the ROM contains fonts for kanji in 12 and 18 points, and they are loaded at startup by <a href="https://www.journaldulapin.com/2018/05/29/kanjitalk-%E6%BC%A2%E5%AD%97talk/">KanjiTalk</a>. On a regular Macintosh Plus, you need a floppy disk with the files, which slows down startup and uses some RAM, whereas on a Japanese Macintosh Plus, the font is in ROM and doesn’t take up RAM. You also avoid loading files from a floppy disk, theoretically saving 6 seconds during startup. That’s a conservative estimate, as we’ll see—it assumes you’re not switching disks manually.</p>
<div id="attachment_112658"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4.jpg"><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-112658" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-640x360.jpg" alt="" width="640" height="360" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-640x360.jpg 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-850x478.jpg 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-320x180.jpg 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-768x432.jpg 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4-1536x864.jpg 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/01-4.jpg 1920w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112658">When booting with a Western ROM, it asks for the floppy with the 12-point font</p></div>
<p>Now, one question remained: how to find the ROM? Getting a Japanese Macintosh Plus shipped was out of the question—it’s bulky and heavy, and there was no guarantee that it had the Japanese ROM… or even that it existed. Searching the internet brings up <a href="https://68kmla.org/bb/index.php?threads/unique-japanese-mac-plus-rom.33029/">this thread</a> questioning its existence, and <a href="https://tinkerdifferent.com/threads/the-mac-plus-kanji-rom.1088/">another one</a> explaining that according to failed tests (as we’ll see), the Japanese ROM has the same content as a v2 ROM. A Japanese author <a href="https://note.com/kaigian/n/n40f4c4248e96">tried</a> to find information with no success (he concluded that the ROM was 128 KB, not 256 KB). But <a href="http://tamaru.world.coocan.jp/Tips/ROM/rom.html">this other Japanese site</a> does reference the Japanese ROM (<code>342-0441-A</code> and <code>342-0442-A</code>), and <a href="http://web.kyoto-inet.or.jp/people/s-oga/mac80/index.html">this one</a> confirms a 256 KB capacity.</p>
<p>In short, no one really knew if the ROM existed, but there were quite a few clues. So I kept digging. Instead of looking for a full Macintosh Plus, I searched for a Macintosh Plus motherboard in Japan, hoping a seller would upload photos that showed the chip references. My first purchase failed: the reference wasn’t fully readable, but the yellow sticker misled me.</p>
<div id="attachment_112661"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3.jpeg"><img decoding="async" aria-describedby="caption-attachment-112661" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-640x459.jpeg" alt="" width="640" height="459" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-640x459.jpeg 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-850x609.jpeg 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-320x229.jpeg 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-768x550.jpeg 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-1536x1101.jpeg 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/04-3-2048x1468.jpeg 2048w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112661">This time, it’s the right one.</p></div>
<p>With the second one, I had the correct chip reference—and a yellow sticker again. I now had a Macintosh Plus motherboard and its ROM, but no actual Macintosh Plus to test it on. The first step was trying to dump the ROM (two chips), but it didn’t work at first. I used an old device for the dump and ended up with two 64 KB files, which wasn’t what I expected. But I didn’t give up, for a simple reason I noticed with the help <a href="https://x86.fr/">of Doc TB</a>: the markings on the chips indicated a 1,024 kilobit capacity, meaning 128 KB.</p>
<div id="attachment_112660"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3.jpeg"><img decoding="async" aria-describedby="caption-attachment-112660" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-640x468.jpeg" alt="" width="640" height="468" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-640x468.jpeg 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-850x622.jpeg 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-320x234.jpeg 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-768x562.jpeg 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-1536x1124.jpeg 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/03-3-2048x1498.jpeg 2048w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112660">The marking helped, with the 1024 in the reference.</p></div>
<p>I had followed the information on <a href="https://www.instructables.com/Create-Macintosh-Plus-ROMs/">this site</a>, which says the Macintosh Plus can use 27C512 chips (64 KB), and I didn’t understand how you could have a 128 KB ROM with that pinout. Until I found a page that explained it. On <a href="http://www.synack.net/~bbraun/plusrom/index.html">Rob Braun’s site</a>, it’s clearly stated that the Macintosh Plus has a slightly different pinout than a 27C512 chip. It includes one extra address line, allowing it to address 128 KB, placed where the programming voltage pin would normally be. Since the Macintosh Plus socket isn’t meant for writing to an EPROM, this is entirely transparent. Doc TB helped again: <a href="https://x86.fr/the-uca-now-supports-roms-eeproms/">he developed a device</a> that can read many ROM and EPROM types, and he was able to dump my two chips. With a standard adapter, it’s not really possible directly, since it’s a proprietary pinout. That was the earlier cited person’s mistake: the lower half of Apple’s ROM (128 KB) matches a standard ROM.</p>
<div id="attachment_112659"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3.jpeg"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112659" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-640x529.jpeg" alt="" width="640" height="529" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-640x529.jpeg 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-850x702.jpeg 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-320x264.jpeg 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-768x635.jpeg 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-1536x1269.jpeg 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/02-3-2048x1692.jpeg 2048w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112659">The two ROMs with the yellow sticker</p></div>
<p>Before continuing, <a href="http://down.dandu.be/MacPlusROMv4.zip">here’s a link to the files</a>.</p>
<h3>Testing the Japanese ROM</h3>
<p>At this point, I had a 256 KB dump of the Japanese Macintosh Plus ROM… but nothing to test it with. I didn’t have a Macintosh Plus (just two motherboards), and my first emulator tests failed. The reason is simple: they expect a known ROM, and not necessarily a Macintosh Plus ROM. That’s important to remember when it comes to Mac emulation—there are many models, and emulators don’t always emulate a specific Mac. Sometimes it’s more like a clone, as with Basilisk or SheepShaver. Technically, they emulate something close to a compatible machine. Mini vMac is better suited for this, but it checks the ROM’s checksum, so I couldn’t boot with mine—it’s not in the recognized list.</p>
<p>That’s when I asked for help. And I’d like to thank <a href="https://x86.fr/">Samuel</a> (for the ROM dump), <a href="https://www.polysoft.fr/">Gilles</a>—for the Macintosh Plus—and <a href="https://www.downtowndougbrown.com/">Doug</a>, for the software part.</p>
<p>Let’s talk hardware first. I didn’t have a Macintosh Plus, just a <a href="https://www.journaldulapin.com/2017/04/10/usb-souris-m0100/">mouse</a>. Gilles sent me a Macintosh Plus and a keyboard (which didn’t work). But with a <a href="https://www.tindie.com/products/lazaj/ps2-keyboard-to-macintosh-plus/">PS/2 adapter</a>, I managed. I had originally considered using the <a href="https://www.journaldulapin.com/2017/02/04/floppy-emu-macintosh/">Floppy Emu</a>, but I got odd results, and the sound of the floppy drive is more satisfying anyway. So I pulled out two 800 KB 3.5″ floppy disks to copy KanjiTalk 1.0 onto them. A tip: KanjiTalk really doesn’t like running from an English system—every time I put the system disk into a newer Mac, I couldn’t boot again on the Macintosh Plus without recreating the disk.</p>
<p>Now for the software part. First, I had to find an old version of KanjiTalk. You can (for example) find it on <a href="https://macintoshgarden.org/apps/kanjitalk">Macintosh Garden</a> or on <a href="https://winworldpc.com/product/mac-os-0-6/system-3x">WinWorld</a>. KanjiTalk 1.0 is based on System 3.1 and comes on two floppies. The first is 800 KB and holds the system itself. The second contains the fonts and is 400 KB (I copied it to an 800 KB disk with no issue).</p>
<div id="attachment_112664"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/07-6.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112664" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/07-6.png" alt="" width="512" height="342" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/07-6.png 512w, https://www.journaldulapin.com/wp-content/uploads/2025/05/07-6-320x214.png 320w" sizes="auto, (max-width: 512px) 100vw, 512px"></a></p><p id="caption-attachment-112664">KanjiTalk isn’t entirely in Japanese</p></div>
<p>This is where the Japanese ROM shines. The usual behavior on a Western Macintosh Plus is quite long. After around 10 seconds, the system asks for the font disk to load the 12-point font. After about 6 seconds of loading, it asks again for the system disk. Five seconds later, it loads the 18-point font (13 seconds), and finally it needs 15 more seconds with the system disk. Even if you swap floppies quickly, it still takes over a minute (about 1:14 in my video) and a few steps to get the Macintosh Plus started.</p>
<p><iframe loading="lazy" width="853" height="480" src="https://www.youtube.com/embed/Hf1H-CNeZAg?si=utw83nXQh00I8V8Z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>With the Japanese ROM, the system loads the 12-point font from ROM, and asks for the 18-point font disk after a little over 10 seconds. About 12 seconds later, it requests the system disk again, and the rest loads quickly (about 15 seconds). So it avoids a few swaps and the Mac is ready after around 52 seconds.</p>
<p><iframe loading="lazy" width="853" height="480" src="https://www.youtube.com/embed/CAqU1_ls6Qo?si=yn41aj8FmVAUX7PL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>You can also skip loading the 18-point font entirely, which reduces boot time further—to about 25 seconds. I only tested this with the Japanese ROM because swapping ROMs means disassembling the Macintosh Plus motherboard, and I don’t like getting close to a CRT.</p>
<div id="attachment_112662"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/05-8.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112662" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/05-8.png" alt="" width="512" height="342" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/05-8.png 512w, https://www.journaldulapin.com/wp-content/uploads/2025/05/05-8-320x214.png 320w" sizes="auto, (max-width: 512px) 100vw, 512px"></a></p><p id="caption-attachment-112662">This checkbox (checked here) prevents loading the 18-point font</p></div>
<p>In any case, it provides a time gain even greater than Apple’s estimate. Booting with the Japanese ROM saves around 15 seconds—and also frees about 113 KB of RAM, which is significant given the Macintosh Plus could be limited to just 1 MB. Skipping the 18-point font saves even more RAM, since it uses slightly more memory.</p>
<div id="attachment_112663"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/06-7.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112663" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/06-7.png" alt="" width="512" height="342" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/06-7.png 512w, https://www.journaldulapin.com/wp-content/uploads/2025/05/06-7-320x214.png 320w" sizes="auto, (max-width: 512px) 100vw, 512px"></a></p><p id="caption-attachment-112663">The developers of KanjiTalk</p></div>
<h3>The Emulation Case</h3>
<p>This part is a bit tricky. By default, emulators don’t recognize the 256 KB ROM and won’t run it. Doug, much more experienced than I am in development, modified <a href="https://www.mamedev.org/">MAME</a> to allow the Japanese ROM. It works the same as a regular Macintosh: with a standard ROM, you’ll need the font disk. With the Japanese ROM, you’ll only need it for the optional 18-point font. My tests with a manually compiled version were successful, and the necessary changes to use the Japanese ROM with MAME should be integrated into the software soon.</p>
<div id="attachment_112669"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112669" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-640x466.png" alt="" width="640" height="466" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-640x466.png 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-850x619.png 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-320x233.png 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-768x559.png 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-1536x1119.png 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.04.05-2048x1492.png 2048w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112669">The Japanese ROM</p></div><br>
<div id="attachment_112667"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112667" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-640x502.png" alt="" width="640" height="502" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-640x502.png 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-850x666.png 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-320x251.png 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-768x602.png 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1-1536x1204.png 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.02.51-1.png 1822w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112667">It boots</p></div><br>
<div id="attachment_112668"><p><a href="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1.png"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-112668" src="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-640x502.png" alt="" width="640" height="502" srcset="https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-640x502.png 640w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-850x666.png 850w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-320x251.png 320w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-768x602.png 768w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1-1536x1204.png 1536w, https://www.journaldulapin.com/wp-content/uploads/2025/05/Capture-decran-2025-05-11-a-18.03.09-1.png 1822w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-112668">It does indeed ask for the 18-point font directly</p></div>
<p>In any case, this was a project that took time, required persistence, and is personally rewarding: I managed to find something rare, undocumented, and unusual.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeBASIC is a free/open source BASIC compiler for Windows DOS and Linux (106 pts)]]></title>
            <link>https://freebasic.net/</link>
            <guid>44017592</guid>
            <pubDate>Sat, 17 May 2025 22:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://freebasic.net/">https://freebasic.net/</a>, See on <a href="https://news.ycombinator.com/item?id=44017592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <h2>Welcome to FreeBASIC</h2>
        <p>
          FreeBASIC is a free/open source (GPL), BASIC compiler for Microsoft Windows, DOS and Linux.
        </p>
        
        <p>
          When used in its "QB" language mode, FreeBASIC provides a high level of support for programs
          written for QuickBASIC. Many programs written for QuickBASIC will compile and run in this mode
          with no changes needed. However, for compilation in the FreeBASIC default language mode,
          most substantial programs will require changes.
        </p>
        <div>
        	 <div>
        	 	<ul>
        	 		<li>Compatible</li>
        	 		<li>Powerful</li>
        	 		<li>Expressive</li>
        	 		<li>100% Free Software</li>
        	 	</ul>
        	 </div>
        	 <div>
    				<p>Simple Example showing procedures.</p>
            <ol><li><p><span>function</span> AddNumbers<span>(</span> a <span>as</span> <span>integer</span>, b <span>as</span> <span>integer</span> <span>)</span> <span>as</span> <span>integer</span></p></li>
            <li><p><span>return</span> a + b</p></li>
            <li><p><span>end</span> <span>function</span></p></li>
            <li></li>
            <li><p><span>sub</span> hello<span>(</span> <span>)</span></p></li>
            <li><p><span>print</span> <span>"hello"</span></p></li>
            <li><p><span>end</span> <span>sub</span></p></li>
            <li></li>
            <li><p><span>declare</span> <span>sub</span> myprint<span>(</span> num <span>as</span> <span>integer</span> <span>)</span></p></li>
            <li></li>
            <li><p><span>'Code outside any procedures is the main part of the program</span></p></li>
            <li><p>hello<span>(</span> <span>)</span></p></li>
            <li><p><span>print</span> AddNumbers<span>(</span> <span>1</span>, <span>1</span> <span>)</span></p></li>
            <li><p>myprint <span>5</span></p></li>
            <li></li>
            <li><p><span>sub</span> myprint<span>(</span> num <span>as</span> <span>integer</span> <span>)</span></p></li>
            <li><p><span>print</span> num</p></li>
            <li><p><span>end</span> <span>sub</span></p></li>
            <!--<li class="li1"><div class="de1">&nbsp;</div></li>-->
            </ol>
          </div>
        </div>
        <p>
          FreeBASIC is a self-hosting compiler which makes use of the GNU binutils programming tools as
          backends and can produce console, graphical/GUI executables, dynamic and static libraries.
          FreeBASIC fully supports the use of C libraries and has partial C++ library support. This lets
          programmers use and create libraries for C and many other languages. It supports a C style
          preprocessor, capable of multiline macros, conditional compiling and file inclusion.
        </p>
        <p>
          FreeBASIC has been rated close in speed with mainstream tools, such as GCC.
        </p>
        
        <hr>
        <h2>More about FreeBASIC</h2>
        <p>
          The FreeBASIC project is a set of cross-platform development tools, consisting of a compiler, 
          GNU-based assembler, linker and archiver, and supporting runtime libraries, including a software-based 
          graphics library. The compiler, fbc, currently supports building for i386-based architectures on the DOS, 
          Linux, Windows and Xbox platforms. The project also contains thin bindings (header files) to some popular 
          3rd party libraries such as the C runtime library, Allegro, SDL, OpenGL, GTK+, the Windows API and many 
          others, as well as example programs for many of these libraries.
        </p>
        <p>
          FreeBASIC is a high-level programming language supporting procedural, object-orientated and
          meta-programming paradigms, with a syntax compatible to Microsoft QuickBASIC. In fact, the
          FreeBASIC project originally began as an attempt to create a code-compatible, free alternative
          to Microsoft QuickBASIC, but it has since grown into a powerful development tool. FreeBASIC
          can be seen to extend the capabilities of Microsoft QuickBASIC in a number of ways, supporting
          more data types, language constructs, programming styles, and modern platforms and APIs.
        </p>
        <p>
        	Any type of program can be written with FreeBASIC, see our <a href="https://freebasic.net/gallery.html">Gallery of Applications</a>
        	for some notable examples.
        </p>
        <p>
			<a href="https://freebasic.net/about.html">Continue reading about FreeBASIC</a>        
        </p>
      </div></div>]]></description>
        </item>
    </channel>
</rss>