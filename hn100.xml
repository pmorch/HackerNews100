<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Aug 2025 16:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cognitive Load is what matters (272 pts)]]></title>
            <link>https://github.com/zakirullin/cognitive-load</link>
            <guid>45074248</guid>
            <pubDate>Sat, 30 Aug 2025 12:58:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zakirullin/cognitive-load">https://github.com/zakirullin/cognitive-load</a>, See on <a href="https://news.ycombinator.com/item?id=45074248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Cognitive Load is what matters</h2><a id="user-content-cognitive-load-is-what-matters" aria-label="Permalink: Cognitive Load is what matters" href="#cognitive-load-is-what-matters"></a></p>
<p dir="auto"><a href="https://minds.md/zakirullin/cognitive" rel="nofollow">Readable version</a> | <a href="https://github.com/zakirullin/cognitive-load/blob/main/README.zh-cn.md">Chinese translation</a> | <a href="https://github.com/zakirullin/cognitive-load/blob/main/README.ko.md">Korean translation</a> | <a href="https://github.com/zakirullin/cognitive-load/blob/main/README.tr.md">Turkish translation</a></p>
<p dir="auto"><em>It is a living document, last update: <strong>August 2025</strong>. Your contributions are welcome!</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">There are so many buzzwords and best practices out there, but most of them have failed. We need something more fundamental, something that can't be wrong.</p>
<p dir="auto">Sometimes we feel confusion going through the code. Confusion costs time and money. Confusion is caused by high <em>cognitive load</em>. It's not some fancy abstract concept, but rather <strong>a fundamental human constraint</strong>. It's not imagined, it's there and we can feel it.</p>
<p dir="auto">Since we spend far more time reading and understanding code than writing it, we should constantly ask ourselves whether we are embedding excessive cognitive load into our code.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Cognitive load</h2><a id="user-content-cognitive-load" aria-label="Permalink: Cognitive load" href="#cognitive-load"></a></p>
<blockquote>
<p dir="auto">Cognitive load is how much a developer needs to think in order to complete a task.</p>
</blockquote>
<p dir="auto">When reading code, you put things like values of variables, control flow logic and call sequences into your head. The average person can hold roughly <a href="https://github.com/zakirullin/cognitive-load/issues/16" data-hovercard-type="issue" data-hovercard-url="/zakirullin/cognitive-load/issues/16/hovercard">four such chunks</a> in working memory. Once the cognitive load reaches this threshold, it becomes much harder to understand things.</p>
<p dir="auto"><em>Let's say we have been asked to make some fixes to a completely unfamiliar project. We were told that a really smart developer had contributed to it. Lots of cool architectures, fancy libraries and trendy technologies were used. In other words, <strong>the author had created a high cognitive load for us.</strong></em></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/cognitiveloadv6.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/cognitiveloadv6.png" alt="Cognitive load" width="750"></a>
</p>
<p dir="auto">We should reduce the cognitive load in our projects as much as possible.</p>
<details>
  <summary><b>Cognitive load and interruptions</b></summary>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/interruption.jpeg"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/interruption.jpeg"></a><br>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Types of cognitive load</h2><a id="user-content-types-of-cognitive-load" aria-label="Permalink: Types of cognitive load" href="#types-of-cognitive-load"></a></p>
<p dir="auto"><strong>Intrinsic</strong> - caused by the inherent difficulty of a task. It can't be reduced, it's at the very heart of software development.</p>
<p dir="auto"><strong>Extraneous</strong> - created by the way the information is presented. Caused by factors not directly relevant to the task, such as smart author's quirks. Can be greatly reduced. We will focus on this type of cognitive load.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/smartauthorv14thanksmari.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/smartauthorv14thanksmari.png" alt="Intrinsic vs Extraneous" width="600"></a>
</p>
<p dir="auto">Let's jump straight to the concrete practical examples of extraneous cognitive load.</p>
<hr>
<p dir="auto">We will refer to the level cognitive load as follows:<br>
<code>🧠</code>: fresh working memory, zero cognitive load<br>
<code>🧠++</code>: two facts in our working memory, cognitive load increased<br>
<code>🤯</code>: cognitive overload, more than 4 facts</p>
<blockquote>
<p dir="auto">Our brain is much more complex and unexplored, but we can go with this simplistic model.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Complex conditionals</h2><a id="user-content-complex-conditionals" aria-label="Permalink: Complex conditionals" href="#complex-conditionals"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="if val > someConstant // 🧠+
    &amp;&amp; (condition2 || condition3) // 🧠+++, prev cond should be true, one of c2 or c3 has be true
    &amp;&amp; (condition4 &amp;&amp; !condition5) { // 🤯, we are messed up by this point
    ...
}"><pre><span>if</span> <span>val</span> <span>&gt;</span> <span>someConstant</span> <span>// 🧠+</span>
    <span>&amp;&amp;</span> (<span>condition2</span> <span>||</span> <span>condition3</span>) <span>// 🧠+++, prev cond should be true, one of c2 or c3 has be true</span>
    <span>&amp;&amp;</span> (<span>condition4</span> <span>&amp;&amp;</span> <span>!</span><span>condition5</span>) { <span>// 🤯, we are messed up by this point</span>
    <span>...</span>
}</pre></div>
<p dir="auto">Introduce intermediate variables with meaningful names:</p>
<div dir="auto" data-snippet-clipboard-copy-content="isValid = val > someConstant
isAllowed = condition2 || condition3
isSecure = condition4 &amp;&amp; !condition5 
// 🧠, we don't need to remember the conditions, there are descriptive variables
if isValid &amp;&amp; isAllowed &amp;&amp; isSecure {
    ...
}"><pre><span>isValid</span> <span>=</span> <span>val</span> <span>&gt;</span> <span>someConstant</span>
<span>isAllowed</span> <span>=</span> <span>condition2</span> <span>||</span> <span>condition3</span>
<span>isSecure</span> <span>=</span> <span>condition4</span> <span>&amp;&amp;</span> <span>!</span><span>condition5</span> 
<span>// 🧠, we don't need to remember the conditions, there are descriptive variables</span>
<span>if</span> <span>isValid</span> <span>&amp;&amp;</span> <span>isAllowed</span> <span>&amp;&amp;</span> <span>isSecure</span> {
    <span>...</span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Nested ifs</h2><a id="user-content-nested-ifs" aria-label="Permalink: Nested ifs" href="#nested-ifs"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="if isValid { // 🧠+, okay nested code applies to valid input only
    if isSecure { // 🧠++, we do stuff for valid and secure input only
        stuff // 🧠+++
    }
} "><pre><span>if</span> <span>isValid</span> { <span>// 🧠+, okay nested code applies to valid input only</span>
    <span>if</span> <span>isSecure</span> { <span>// 🧠++, we do stuff for valid and secure input only</span>
        <span>stuff</span> <span>// 🧠+++</span>
    }
} </pre></div>
<p dir="auto">Compare it with the early returns:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if !isValid
    return
 
if !isSecure
    return

// 🧠, we don't really care about earlier returns, if we are here then all good

stuff // 🧠+"><pre><span>if</span> <span>!</span><span>isValid</span>
    <span>return</span>
 
<span>if</span> <span>!</span><span>isSecure</span>
    <span>return</span>

<span>// 🧠, we don't really care about earlier returns, if we are here then all good</span>

<span>stuff</span> <span>// 🧠+</span></pre></div>
<p dir="auto">We can focus on the happy path only, thus freeing our working memory from all sorts of preconditions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inheritance nightmare</h2><a id="user-content-inheritance-nightmare" aria-label="Permalink: Inheritance nightmare" href="#inheritance-nightmare"></a></p>
<p dir="auto">We are asked to change a few things for our admin users: <code>🧠</code></p>
<p dir="auto"><code>AdminController extends UserController extends GuestController extends BaseController</code></p>
<p dir="auto">Ohh, part of the functionality is in <code>BaseController</code>, let's have a look: <code>🧠+</code><br>
Basic role mechanics got introduced in <code>GuestController</code>: <code>🧠++</code><br>
Things got partially altered in <code>UserController</code>: <code>🧠+++</code><br>
Finally we are here, <code>AdminController</code>, let's code stuff! <code>🧠++++</code></p>
<p dir="auto">Oh, wait, there's <code>SuperuserController</code> which extends <code>AdminController</code>. By modifying <code>AdminController</code> we can break things in the inherited class, so let's dive in <code>SuperuserController</code> first: <code>🤯</code></p>
<p dir="auto">Prefer composition over inheritance. We won't go into detail - there's <a href="https://www.youtube.com/watch?v=hxGOiiR9ZKg" rel="nofollow">plenty of material</a> out there.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Too many small methods, classes or modules</h2><a id="user-content-too-many-small-methods-classes-or-modules" aria-label="Permalink: Too many small methods, classes or modules" href="#too-many-small-methods-classes-or-modules"></a></p>
<blockquote>
<p dir="auto">Method, class and module are interchangeable in this context</p>
</blockquote>
<p dir="auto">Mantras like "methods should be shorter than 15 lines of code" or "classes should be small" turned out to be somewhat wrong.</p>
<p dir="auto"><strong>Deep module</strong> - simple interface, complex functionality<br>
<strong>Shallow module</strong> - interface is relatively complex to the small functionality it provides</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/deepmodulev8.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/deepmodulev8.png" alt="Deep module" width="700"></a>
</p>
<p dir="auto">Having too many shallow modules can make it difficult to understand the project. <strong>Not only do we have to keep in mind each module responsibilities, but also all their interactions</strong>. To understand the purpose of a shallow module, we first need to look at the functionality of all the related modules. Jumping between such shallow components is mentally exhausting, <a href="https://blog.separateconcerns.com/2023-09-11-linear-code.html" rel="nofollow">linear thinking</a> is more natural to us humans.</p>
<blockquote>
<p dir="auto">Information hiding is paramount, and we don't hide as much complexity in shallow modules.</p>
</blockquote>
<p dir="auto">I have two pet projects, both of them are somewhat 5K lines of code. The first one has 80 shallow classes, whereas the second one has only 7 deep classes. I haven't been maintaining any of these projects for one year and a half.</p>
<p dir="auto">Once I came back, I realised that it was extremely difficult to untangle all the interactions between those 80 classes in the first project. I would have to rebuild an enormous amount of cognitive load before I could start coding. On the other hand, I was able to grasp the second project quickly, because it had only a few deep classes with a simple interface.</p>
<blockquote>
<p dir="auto">The best components are those that provide powerful functionality yet have a simple interface.<br>
<strong>John K. Ousterhout</strong></p>
</blockquote>
<p dir="auto">The interface of the UNIX I/O is very simple. It has only five basic calls:</p>
<div dir="auto" data-snippet-clipboard-copy-content="open(path, flags, permissions)
read(fd, buffer, count)
write(fd, buffer, count)
lseek(fd, offset, referencePosition)
close(fd)"><pre><span>open</span>(<span>path</span>, <span>flags</span>, <span>permissions</span>)
<span>read</span>(<span>fd</span>, <span>buffer</span>, <span>count</span>)
<span>write</span>(<span>fd</span>, <span>buffer</span>, <span>count</span>)
<span>lseek</span>(<span>fd</span>, <span>offset</span>, <span>referencePosition</span>)
<span>close</span>(<span>fd</span>)</pre></div>
<p dir="auto">A modern implementation of this interface has <strong>hundreds of thousands of lines of code</strong>. Lots of complexity is hidden under the hood. Yet it is easy to use due to its simple interface.</p>
<blockquote>
<p dir="auto">This deep module example is taken from the book <a href="https://web.stanford.edu/~ouster/cgi-bin/book.php" rel="nofollow">A Philosophy of Software Design</a> by John K. Ousterhout. Not only does this book cover the very essence of complexity in software development, but it also has the greatest interpretation of Parnas' influential paper <a href="https://www.win.tue.nl/~wstomv/edu/2ip30/references/criteria_for_modularization.pdf" rel="nofollow">On the Criteria To Be Used in Decomposing Systems into Modules</a>. Both are essential reads. Other related readings: <a href="https://github.com/johnousterhout/aposd-vs-clean-code">A Philosophy of Software Design vs Clean Code</a>, <a href="https://qntm.org/clean" rel="nofollow">It's probably time to stop recommending Clean Code</a>, <a href="https://copyconstruct.medium.com/small-functions-considered-harmful-91035d316c29" rel="nofollow">Small Functions considered Harmful</a>.</p>
</blockquote>
<p dir="auto">P.S. If you think we are rooting for bloated God objects with too many responsibilities, you got it wrong.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Responsible for one thing</h2><a id="user-content-responsible-for-one-thing" aria-label="Permalink: Responsible for one thing" href="#responsible-for-one-thing"></a></p>
<p dir="auto">All too often, we end up creating lots of shallow modules, following some vague "a module should be responsible for one, and only one, thing" principle. What is this blurry one thing? Instantiating an object is one thing, right? So <a href="https://minds.md/benji/frameworks" rel="nofollow">MetricsProviderFactoryFactory</a> seems to be just fine. The names and interfaces of such classes tend to be more mentally taxing than their entire implementations, what kind of abstraction is that? Something went wrong.</p>
<p dir="auto">We make changes to our systems to satisfy our users and stakeholders. We are responsible to them.</p>
<blockquote>
<p dir="auto">A module should be responsible to one, and only one, user or stakeholder.</p>
</blockquote>
<p dir="auto">This is what this Single Responsibility Principle is all about. Simply put, if we introduce a bug in one place, and then two different business people come to complain, we've violated the principle. It has nothing to do with the number of things we do in our module.</p>
<p dir="auto">But even now, this rule can do more harm than good. This principle can be understood in as many different ways as there are individuals. A better approach would be to look at how much cognitive load it all creates. It's mentally demanding to remember that change in one place can trigger a chain of reactions across different business streams. And that's about it, no fancy terms to learn.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Too many shallow microservices</h2><a id="user-content-too-many-shallow-microservices" aria-label="Permalink: Too many shallow microservices" href="#too-many-shallow-microservices"></a></p>
<p dir="auto">This shallow-deep module principle is scale-agnostic, and we can apply it to microservices architecture. Too many shallow microservices won't do any good - the industry is heading towards somewhat "macroservices", i.e., services that are not so shallow (=deep). One of the worst and hardest to fix phenomena is so-called distributed monolith, which is often the result of this overly granular shallow separation.</p>
<p dir="auto">I once consulted a startup where a team of five developers introduced 17(!) microservices. They were 10 months behind schedule and appeared nowhere close to the public release. Every new requirement led to changes in 4+ microservices. Diagnostic difficulty in integration space skyrocketed. Both time to market and cognitive load were unacceptably high. <code>🤯</code></p>
<p dir="auto">Is this the right way to approach the uncertainty of a new system? It's enormously difficult to elicit the right logical boundaries in the beginning. The key is to make decisions as late as you can responsibly wait, because that is when you have the most information at hand. By introducing a network layer up front, we make our design decisions hard to revert right from the start. The team's only justification was: "The FAANG companies proved microservices architecture to be effective". <em>Hello, you got to stop dreaming big.</em></p>
<p dir="auto">The <a href="https://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate" rel="nofollow">Tanenbaum-Torvalds debate</a> argued that Linux's monolithic design was flawed and obsolete, and that a microkernel architecture should be used instead. Indeed, the microkernel design seemed to be superior "from a theoretical and aesthetical" point of view. On the practical side of things - three decades on, microkernel-based GNU Hurd is still in development, and monolithic Linux is everywhere. This page is powered by Linux, your smart teapot is powered by Linux. By monolithic Linux.</p>
<p dir="auto">A well-crafted monolith with truly isolated modules is often much more flexible than a bunch of microservices. It also requires far less cognitive effort to maintain. It's only when the need for separate deployments becomes crucial, such as scaling the development team, that you should consider adding a network layer between the modules, future microservices.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature-rich languages</h2><a id="user-content-feature-rich-languages" aria-label="Permalink: Feature-rich languages" href="#feature-rich-languages"></a></p>
<p dir="auto">We feel excited when new features got released in our favourite language. We spend some time learning these features, we build code upon them.</p>
<p dir="auto">If there are lots of features, we may spend half an hour playing with a few lines of code, to use one or another feature. And it's kind of a waste of time. But what's worse, <strong>when you come back later, you would have to recreate that thought process!</strong></p>
<p dir="auto"><strong>You not only have to understand this complicated program, you have to understand why a programmer decided this was the way to approach a problem from the features that are available.</strong> <code>🤯</code></p>
<p dir="auto">These statements are made by none other than Rob Pike.</p>
<blockquote>
<p dir="auto">Reduce cognitive load by limiting the number of choices.</p>
</blockquote>
<p dir="auto">Language features are OK, as long as they are orthogonal to each other.</p>
<details>
  <summary><b>Thoughts from an engineer with 20 years of C++ experience ⭐️</b></summary>
  <br>
  I was looking at my RSS reader the other day and noticed that I have somewhat three hundred unread articles under the "C++" tag. I haven't read a single article about the language since last summer, and I feel great!<p>
  I've been using C++ for 20 years for now, that's almost two-thirds of my life. Most of my experience lies in dealing with the darkest corners of the language (such as undefined behaviours of all sorts). It's not a reusable experience, and it's kind of creepy to throw it all away now.</p><p>
  Like, can you imagine, the token <code>||</code> has a different meaning in <code>requires ((!P&lt;T&gt; || !Q&lt;T&gt;))</code> and in <code>requires (!(P&lt;T&gt; || Q&lt;T&gt;))</code>. The first is the constraint disjunction, the second is the good-old logical OR operator, and they behave differently.</p><p>
  You can't allocate space for a trivial type and just <code>memcpy</code> a set of bytes there without extra effort - that won't start the lifetime of an object. This was the case before C++20. It was fixed in C++20, but the cognitive load of the language has only increased.</p><p>
  Cognitive load is constantly growing, even though things got fixed. I should know what was fixed, when it was fixed, and what it was like before. I am a professional after all. Sure, C++ is good at legacy support, which also means that you <b>will face</b> that legacy. For example, last month a colleague of mine asked me about some behaviour in C++03. <code>🤯</code></p><p>
  There were 20 ways of initialization. Uniform initialization syntax has been added. Now we have 21 ways of initialization. By the way, does anyone remember the rules for selecting constructors from the initializer list? Something about implicit conversion with the least loss of information, <i>but if</i> the value is known statically, then... <code>🤯</code></p><p>
  <b>This increased cognitive load is not caused by a business task at hand. It is not an intrinsic complexity of the domain. It is just there due to historical reasons</b> (<i>extraneous cognitive load</i>).</p><p>
  I had to come up with some rules. Like, if that line of code is not as obvious and I have to remember the standard, I better not write it that way. The standard is somewhat 1500 pages long, by the way.</p><p>
  <b>By no means I am trying to blame C++.</b> I love the language. It's just that I am tired now.</p><p dir="auto">Thanks to <a href="https://0xd34df00d.me/" rel="nofollow">0xd34df00d</a> for writing.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Business logic and HTTP status codes</h2><a id="user-content-business-logic-and-http-status-codes" aria-label="Permalink: Business logic and HTTP status codes" href="#business-logic-and-http-status-codes"></a></p>
<p dir="auto">On the backend we return:<br>
<code>401</code> for expired jwt token<br>
<code>403</code> for not enough access<br>
<code>418</code> for banned users</p>
<p dir="auto">The engineers on the frontend use backend API to implement login functionality. They would have to temporarily create the following cognitive load in their brains:<br>
<code>401</code> is for expired jwt token // <code>🧠+</code>, ok just temporary remember it<br>
<code>403</code> is for not enough access // <code>🧠++</code><br>
<code>418</code> is for banned users // <code>🧠+++</code></p>
<p dir="auto">Frontend developers would (hopefully) introduce some kind <code>numeric status -&gt; meaning</code> dictionary on their side, so that subsequent generations of contributors wouldn't have to recreate this mapping in their brains.</p>
<p dir="auto">Then QA engineers come into play:
"Hey, I got <code>403</code> status, is that expired token or not enough access?"
<strong>QA engineers can't jump straight to testing, because first they have to recreate the cognitive load that the engineers on the backend once created.</strong></p>
<p dir="auto">Why hold this custom mapping in our working memory? It's better to abstract away your business details from the HTTP transfer protocol, and return self-descriptive codes directly in the response body:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;code&quot;: &quot;jwt_has_expired&quot;
}"><pre>{
    <span>"code"</span>: <span><span>"</span>jwt_has_expired<span>"</span></span>
}</pre></div>
<p dir="auto">Cognitive load on the frontend side: <code>🧠</code> (fresh, no facts are held in mind)<br>
Cognitive load on the QA side: <code>🧠</code></p>
<p dir="auto">The same rule applies to all sorts of numeric statuses (in the database or wherever) - <strong>prefer self-describing strings</strong>. We are not in the era of 640K computers to optimise for memory.</p>
<blockquote>
<p dir="auto">People spend time arguing between <code>401</code> and <code>403</code>, making decisions based on their own mental models. New developers are coming in, and they need to recreate that thought process. You may have documented the "whys" (ADRs) for your code, helping newcomers to understand the decisions made. But in the end it just doesn't make any sense. We can separate errors into either user-related or server-related, but apart from that, things are kind of blurry.</p>
</blockquote>
<p dir="auto">P.S. It's often mentally taxing to distinguish between "authentication" and "authorization". We can use simpler terms like <a href="https://ntietz.com/blog/lets-say-instead-of-auth/" rel="nofollow">"login" and "permissions"</a> to reduce the cognitive load.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Abusing DRY principle</h2><a id="user-content-abusing-dry-principle" aria-label="Permalink: Abusing DRY principle" href="#abusing-dry-principle"></a></p>
<p dir="auto">Do not repeat yourself - that is one of the first principles you are taught as a software engineer. It is so deeply embedded in ourselves that we can not stand the fact of a few extra lines of code. Although in general a good and fundamental rule, when overused it leads to the cognitive load we can not handle.</p>
<p dir="auto">Nowadays, everyone builds software based on logically separated components. Often those are distributed among multiple codebases representing separate services. When you strive to eliminate any repetition, you might end up creating tight coupling between unrelated components. As a result changes in one part may have unintended consequences in other seemingly unrelated areas. It can also hinder the ability to replace or modify individual components without impacting the entire system. <code>🤯</code></p>
<p dir="auto">In fact, the same problem arises even within a single module. You might extract common functionality too early, based on perceived similarities that might not actually exist in the long run. This can result in unnecessary abstractions that are difficult to modify or extend.</p>
<p dir="auto">Rob Pike once said:</p>
<blockquote>
<p dir="auto">A little copying is better than a little dependency.</p>
</blockquote>
<p dir="auto">We are tempted to not reinvent the wheel so strong that we are ready to import large, heavy libraries to use a small function that we could easily write by ourselves.</p>
<p dir="auto"><strong>All your dependencies are your code.</strong> Going through 10+ levels of stack trace of some imported library and figuring out what went wrong (<em>because things go wrong</em>) is painful.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tight coupling with a framework</h2><a id="user-content-tight-coupling-with-a-framework" aria-label="Permalink: Tight coupling with a framework" href="#tight-coupling-with-a-framework"></a></p>
<p dir="auto">There's a lot of "magic" in frameworks. By relying too heavily on a framework, <strong>we force all upcoming developers to learn that "magic" first</strong>. It can take months. Even though frameworks enable us to launch MVPs in a matter of days, in the long run they tend to add unnecessary complexity and cognitive load.</p>
<p dir="auto">Worse yet, at some point frameworks can become a significant constraint when faced with a new requirement that just doesn't fit the architecture. From here onwards people end up forking a framework and maintaining their own custom version. Imagine the amount of cognitive load a newcomer would have to build (i.e. learn this custom framework) in order to deliver any value. <code>🤯</code></p>
<p dir="auto"><strong>By no means do we advocate to invent everything from scratch!</strong></p>
<p dir="auto">We can write code in a somewhat framework-agnostic way. The business logic should not reside within a framework; rather, it should use the framework's components. Put a framework outside of your core logic. Use the framework in a library-like fashion. This would allow new contributors to add value from day one, without the need of going through debris of framework-related complexity first.</p>
<blockquote>
<p dir="auto"><a href="https://minds.md/benji/frameworks" rel="nofollow">Why I Hate Frameworks</a></p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Layered architecture</h2><a id="user-content-layered-architecture" aria-label="Permalink: Layered architecture" href="#layered-architecture"></a></p>
<p dir="auto">There is a certain engineering excitement about all this stuff.</p>
<p dir="auto">I myself was a passionate advocate of Hexagonal/Onion Architecture for years. I used it here and there and encouraged other teams to do so. The complexity of our projects went up, the sheer number of files alone had doubled. It felt like we were writing a lot of glue code. On ever changing requirements we had to make changes across multiple layers of abstractions, it all became tedious. <code>🤯</code></p>
<p dir="auto">Abstraction is supposed to hide complexity, here it just adds <a href="https://fhur.me/posts/2024/thats-not-an-abstraction" rel="nofollow">indirection</a>. Jumping from call to call to read along and figure out what goes wrong and what is missing is a vital requirement to quickly solve a problem. With this architecture’s layer uncoupling it requires an exponential factor of extra, often disjointed, traces to get to the point where the failure occurs. Every such trace takes space in our limited working memory. <code>🤯</code></p>
<p dir="auto">This architecture was something that made intuitive sense at first, but every time we tried applying it to projects it made a lot more harm than good. In the end, we gave it all up in favour of the good old dependency inversion principle. <strong>No port/adapter terms to learn, no unnecessary layers of horizontal abstractions, no extraneous cognitive load.</strong></p>
<details>
  <summary><b>Coding principles and experience</b></summary>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/complexity.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/complexity.png"></a><br>
  <a href="https://twitter.com/flaviocopes" rel="nofollow">@flaviocopes</a>
</details>
<p dir="auto">If you think that such layering will allow you to quickly replace a database or other dependencies, you're mistaken. Changing the storage causes lots of problems, and believe us, having some abstractions for the data access layer is the least of your worries. At best, abstractions can save somewhat 10% of your migration time (if any), the real pain is in data model incompatibilities, communication protocols, distributed systems challenges, and <a href="https://www.hyrumslaw.com/" rel="nofollow">implicit interfaces</a>.</p>
<blockquote>
<p dir="auto">With a sufficient number of users of an API,<br>
it does not matter what you promise in the contract:<br>
all observable behaviors of your system<br>
will be depended on by somebody.</p>
</blockquote>
<p dir="auto">We did a storage migration, and that took us about 10 months. The old system was single-threaded, so the exposed events were sequential. All our systems depended on that observed behaviour. This behavior was not part of the API contract, it was not reflected in the code. A new distributed storage didn't have that guarantee - the events came out-of-order. We spent only a few hours coding a new storage adapter, thanks to an abstraction. <strong>We spent the next 10 months on dealing with out-of-order events and other challenges.</strong> It's now funny to say that abstractions helps us replace components quickly.</p>
<p dir="auto"><strong>So, why pay the price of high cognitive load for such a layered architecture, if it doesn't pay off in the future?</strong> Plus, in most cases, that future of replacing some core component never happens.</p>
<p dir="auto">These architectures are not fundamental, they are just subjective, biased consequences of more fundamental principles. Why rely on those subjective interpretations? Follow the fundamental rules instead: dependency inversion principle, single source of truth, cognitive load and information hiding. Your business logic should not depend on low-level modules like database, UI or framework. We should be able to write tests for our core logic without worrying about the infrastructure, and that's it. <a href="https://github.com/zakirullin/cognitive-load/discussions/24" data-hovercard-type="discussion" data-hovercard-url="/zakirullin/cognitive-load/discussions/24/hovercard">Discuss</a>.</p>
<p dir="auto">Do not add layers of abstractions for the sake of an architecture. Add them whenever you need an extension point that is justified for practical reasons.</p>
<p dir="auto"><strong><a href="https://blog.jooq.org/why-you-should-not-implement-layered-architecture" rel="nofollow">Layers of abstraction aren't free of charge</a>, they are to be held in our limited working memory</strong>.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/layers.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/layers.png" alt="Layers" width="400"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Domain-driven design</h2><a id="user-content-domain-driven-design" aria-label="Permalink: Domain-driven design" href="#domain-driven-design"></a></p>
<p dir="auto">Domain-driven design has some great points, although it is often misinterpreted. People say "We write code in DDD", which is a bit strange, because DDD is about problem space, not about solution space.</p>
<p dir="auto">Ubiquitous language, domain, bounded context, aggregate, event storming are all about problem space. They are meant to help us learn the insights about the domain and extract the boundaries. DDD enables developers, domain experts and business people to communicate effectively using a single, unified language. Rather than focusing on these problem space aspects of DDD, we tend to emphasise particular folder structures, services, repositories, and other solution space techniques.</p>
<p dir="auto">Chances are that the way we interpret DDD is likely to be unique and subjective. And if we build code upon this understanding, i.e., if we create a lot of extraneous cognitive load - future developers are doomed. <code>🤯</code></p>
<p dir="auto">Team Topologies provides a much better, easier to understand framework that helps us split the cognitive load across teams. Engineers tend to develop somewhat similar mental models after learning about Team Topologies. DDD, on the other hand, seems to be creating 10 different mental models for 10 different readers. Instead of being common ground, it becomes a battleground for unnecessary debates.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Cognitive load in familiar projects</h2><a id="user-content-cognitive-load-in-familiar-projects" aria-label="Permalink: Cognitive load in familiar projects" href="#cognitive-load-in-familiar-projects"></a></p>
<blockquote>
<p dir="auto">The problem is that <strong>familiarity is not the same as simplicity</strong>. They <em>feel</em> the same — that same ease of moving through a space without much mental effort — but for very different reasons. Every “clever” (read: “self-indulgent”) and non-idiomatic trick you use incurs a learning penalty for everyone else. Once they have done that learning, then they will find working with the code less difficult. So it is hard to recognise how to simplify code that you are already familiar with. This is why I try to get “the new kid” to critique the code before they get too institutionalised!</p>
<p dir="auto">It is likely that the previous author(s) created this huge mess one tiny increment at a time, not all at once. So you are the first person who has ever had to try to make sense of it all at once.</p>
<p dir="auto">In my class I describe a sprawling SQL stored procedure we were looking at one day, with hundreds of lines of conditionals in a huge WHERE clause. Someone asked how anyone could have let it get this bad. I told them: “When there are only 2 or 3 conditionals, adding another one doesn’t make any difference. By the time there are 20 or 30 conditionals, adding another one doesn’t make any difference!”</p>
<p dir="auto">There is no “simplifying force” acting on the code base other than deliberate choices that you make. Simplifying takes effort, and people are too often in a hurry.</p>
<p dir="auto"><em>Thanks to <a href="https://dannorth.net/" rel="nofollow">Dan North</a> for his comment</em>.</p>
</blockquote>
<p dir="auto">If you've internalized the mental models of the project into your long-term memory, you won't experience a high cognitive load.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/mentalmodelsv15.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/mentalmodelsv15.png" alt="Mental models" width="700"></a>
</p>
<p dir="auto">The more mental models there are to learn, the longer it takes for a new developer to deliver value.</p>
<p dir="auto">Once you onboard new people on your project, try to measure the amount of confusion they have (pair programming may help). If they're confused for more than ~40 minutes in a row - you've got things to improve in your code.</p>
<p dir="auto">If you keep the cognitive load low, people can contribute to your codebase within the first few hours of joining your company.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<ul dir="auto">
<li>Our architecture is a standard CRUD app architecture, <a href="https://danluu.com/simple-architectures/" rel="nofollow">a Python monolith on top of Postgres</a></li>
<li>How Instagram scaled to 14 million users with <a href="https://read.engineerscodex.com/p/how-instagram-scaled-to-14-million" rel="nofollow">only 3 engineers</a></li>
<li>The companies where we were like ”woah, these folks are <a href="https://kenkantzer.com/learnings-from-5-years-of-tech-startup-code-audits/" rel="nofollow">smart as hell</a>” for the most part failed</li>
<li>One function that wires up the entire system. If you want to know how the system works - <a href="https://www.infoq.com/presentations/8-lines-code-refactoring" rel="nofollow">go read it</a></li>
</ul>
<p dir="auto">These architectures are quite boring and easy to understand. Anyone can grasp them without much mental effort.</p>
<p dir="auto">Involve junior developers in architecture reviews. They will help you to identify the mentally demanding areas.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Conclusion</h2><a id="user-content-conclusion" aria-label="Permalink: Conclusion" href="#conclusion"></a></p>
<p dir="auto">Imagine for a moment that what we inferred in the second chapter isn’t actually true. If that’s the case, then the conclusion we just negated, along with the conclusions in the previous chapter that we had accepted as valid, might not be correct either. <code>🤯</code></p>
<p dir="auto">Do you feel it? Not only do you have to jump all over the article to get the meaning (shallow modules!), but the paragraph in general is difficult to understand. We have just created an unnecessary cognitive load in your head. <strong>Do not do this to your colleagues.</strong></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zakirullin/cognitive-load/blob/main/img/smartauthorv14thanksmari.png"><img src="https://github.com/zakirullin/cognitive-load/raw/main/img/smartauthorv14thanksmari.png" alt="Smart author" width="600"></a>
</p>
<p dir="auto">We should reduce any cognitive load above and beyond what is intrinsic to the work we do.</p>
<hr>
<p dir="auto"><a href="https://www.linkedin.com/in/zakirullin/" rel="nofollow">LinkedIn</a>, <a href="https://twitter.com/zakirullin" rel="nofollow">X</a>, <a href="https://github.com/zakirullin">GitHub</a></p>
<p dir="auto"><a href="https://minds.md/zakirullin/cognitive" rel="nofollow">Readable version</a></p>
<details>
    <summary><b>Comments</b></summary>
    
    <p dir="auto"><strong>Rob Pike</strong><br>Nice article.</p>
    <p dir="auto"><strong><a href="https://x.com/karpathy/status/1872038630405054853" rel="nofollow">Andrej Karpathy</a></strong> <i>(ChatGPT, Tesla)</i><br>Nice post on software engineering. Probably the most true, least practiced viewpoint.</p>
    <p dir="auto"><strong><a href="https://x.com/elonmusk/status/1872346903792566655" rel="nofollow">Elon Musk</a></strong><br>True.</p>
    <p dir="auto"><strong><a href="https://www.linkedin.com/feed/update/urn:li:activity:7277757844970520576/" rel="nofollow">Addy Osmani</a></strong> <i>(Chrome, the most complex software system in the world)</i><br>I've seen countless projects where smart developers created impressive architectures using the latest design patterns and microservices. But when new team members tried to make changes, they spent weeks just trying to understand how everything fits together. The cognitive load was so high that productivity plummeted and bugs multiplied.</p>
    <p dir="auto">The irony? Many of these complexity-inducing patterns were implemented in the name of "clean code."</p>
    <p dir="auto">What really matters is reducing unnecessary cognitive burden. Sometimes this means fewer, deeper modules instead of many shallow ones. Sometimes it means keeping related logic together instead of splitting it into tiny functions.</p>
    <p dir="auto">And sometimes it means choosing boring, straightforward solutions over clever ones. The best code isn't the most elegant or sophisticated - it's the code that future developers (including yourself) can understand quickly.</p>
    <p dir="auto">Your article really resonates with the challenges we face in browser development. You're absolutely right about modern browsers being among the most complex software systems. Managing that complexity in Chromium is a constant challenge that aligns perfectly with many of the points you made about cognitive load.</p>
    <p dir="auto">One way we try to handle this in Chromium is through careful component isolation and well-defined interfaces between subsystems (like rendering, networking, JavaScript execution, etc.). Similar to your deep modules example with Unix I/O - we aim for powerful functionality behind relatively simple interfaces. For instance, our rendering pipeline handles incredible complexity (layout, compositing, GPU acceleration) but developers can interact with it through clear abstraction layers.</p>
    <p dir="auto">Your points about avoiding unnecessary abstractions really hit home too. In browser development, we constantly balance between making the codebase approachable for new contributors while handling the inherent complexity of web standards and compatibility. </p>
    <p dir="auto">Sometimes the simplest solution is the best one, even in a complex system.</p>
    <p dir="auto"><strong><a href="https://x.com/antirez" rel="nofollow">antirez</a></strong> <i>(Redis)</i><br>Totally agree about it :) Also, what I believe is missing from mentioned "A Philosophy of Software Design" is the concept of "design sacrifice". That is, sometimes you sacrifice something and get back simplicity, or performances, or both. I apply this idea continuously, but often is not understood.</p>
    <p dir="auto">A good example is the fact that I always refused to have hash items expires. This is a design sacrifice because if you have certain attributes only in the top-level items (the keys themselves), the design is simpler, values will just be objects. When Redis got hash expires, it was a nice feature but required (indeed) many changes to many parts, raising the complexity.</p>
    <p dir="auto">Another example is what I'm doing right now, Vector Sets, the new Redis data type. I decided that Redis would not be the source of truth about vectors, but that it can just take an approximate version of them, so I was able to do on-insert normalization, quantization without trying to retain the large floats vector on disk, and so forth. May vector DBs don't sacrifice the fact of remembering what the user put inside (the full precision vector).</p>
    <p dir="auto">These are just two random examples, but I apply this idea everywhere. Now the thing is: of course one must sacrifice the right things. Often, there are 5% features that account for a very large amount of complexity: that is a good thing to kill :D</p>
    <p dir="auto"><strong><a href="https://working-for-the-future.medium.com/about" rel="nofollow">A developer from the internet</a></strong><br>You would not hire me... I sell myself on my track record of released enterprise projects.</p>
    <p dir="auto">I worked with a guy that could speak design patterns. I could never speak that way, though I was one of the few that could well understand him. The managers loved him and he could dominate any development conversation. The people working around him said he left a trail of destruction behind him. I was told that I was the first person that could understand his projects. Maintainability matters. I care most about TCO. For some firms, that's what matters.</p>
    <p dir="auto">I logged into Github after not being there for a while and for some reason it took me to an article in a repository by someone that seemed random. I was thinking "what is this" and had some trouble getting to my home page, so I read it. I didn't really register it at the time, but it was amazing. Every developer should read it. It largely said that almost everything we've been told about programming best practices leads to excessive "cognitive load", meaning our minds are getting kicked by the intellectual demands. I've known this for a while, especially with the demands of cloud, security and DevOps.</p>
    <p dir="auto">I also liked it because it described practices I have done for decades, but never much admit to because they are not popular... I write really complicated stuff and need all the help I can get.</p>
    <p dir="auto">Consider, if I'm right, it popped up because the Github folks, very smart people, though that developers should see it. I agree.</p>
    <p dir="auto"><a href="https://news.ycombinator.com/item?id=42489645" rel="nofollow">Comments on Hacker News</a></p>
</details>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Agent Client Protocol (107 pts)]]></title>
            <link>https://agentclientprotocol.com/overview/introduction</link>
            <guid>45074147</guid>
            <pubDate>Sat, 30 Aug 2025 12:42:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://agentclientprotocol.com/overview/introduction">https://agentclientprotocol.com/overview/introduction</a>, See on <a href="https://news.ycombinator.com/item?id=45074147">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-page-title="Introduction" data-page-href="/overview/introduction"><p><span data-as="p">The Agent Client Protocol standardizes communication between code editors (IDEs, text-editors, etc.) and coding agents (programs that use generative AI to autonomously modify code).</span>
<span data-as="p">The protocol is still under development, but it should be complete enough to build interesting user experiences using it.</span></p><h2 id="why-acp%3F"><span>Why ACP?</span></h2>
<p><span data-as="p">AI coding agents and editors are tightly coupled but interoperability isn’t the default. Each editor must build custom integrations for every agent they want to support, and agents must implement editor-specific APIs to reach users.
This creates several problems:</span></p><ul>
<li>Integration overhead: Every new agent-editor combination requires custom work</li>
<li>Limited compatibility: Agents work with only a subset of available editors</li>
<li>Developer lock-in: Choosing an agent often means accepting their available interfaces</li>
</ul>
<p><span data-as="p">ACP solves this by providing a standardized protocol for agent-editor communication, similar to how the <a href="https://microsoft.github.io/language-server-protocol/" target="_blank" rel="noreferrer">Language Server Protocol (LSP)</a> standardized language server integration.</span>
<span data-as="p">Agents that implement ACP work with any compatible editor. Editors that support ACP gain access to the entire ecosystem of ACP-compatible agents.
This decoupling allows both sides to innovate independently while giving developers the freedom to choose the best tools for their workflow.</span></p><h2 id="overview"><span>Overview</span></h2>
<p><span data-as="p">ACP assumes that the user is primarily in their editor, and wants to reach out and use agents to assist them with specific tasks.</span>
<span data-as="p">Agents run as sub-processes of the code editor, and communicate using JSON-RPC over stdio. The protocol re-uses the JSON representations used in MCP where possible, but includes custom types for useful agentic coding UX elements, like displaying diffs.</span>
<span data-as="p">The default format for user-readable text is Markdown, which allows enough flexibility to represent rich formatting without requiring that the code editor is capable of rendering HTML.</span></p><h2 id="supported-editors"><span>Supported Editors</span></h2>
<ul>
<li><a href="https://zed.dev/docs/ai/external-agents" target="_blank" rel="noreferrer">Zed</a></li>
<li><a href="https://neovim.io/" target="_blank" rel="noreferrer">neovim</a> through the <a href="https://github.com/olimorris/codecompanion.nvim" target="_blank" rel="noreferrer">CodeCompanion</a> plugin</li>
</ul>
<h2 id="supported-agents"><span>Supported Agents</span></h2>
<ul>
<li><a href="https://github.com/google-gemini/gemini-cli" target="_blank" rel="noreferrer">Gemini</a></li>
<li>… more coming soon ;)</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nokia’s legendary font makes for a great user interface font (142 pts)]]></title>
            <link>https://www.osnews.com/story/143222/it-turns-out-nokias-legendary-font-makes-for-a-great-general-user-interface-font/</link>
            <guid>45074071</guid>
            <pubDate>Sat, 30 Aug 2025 12:31:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.osnews.com/story/143222/it-turns-out-nokias-legendary-font-makes-for-a-great-general-user-interface-font/">https://www.osnews.com/story/143222/it-turns-out-nokias-legendary-font-makes-for-a-great-general-user-interface-font/</a>, See on <a href="https://news.ycombinator.com/item?id=45074071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page"><article itemscope="" itemtype="http://schema.org/BlogPosting"><div id="content_box"><div><p><span itemscope="" itemprop="itemlistElement"><a itemprop="item" rel="v:url" property="v:title" href="https://www.osnews.com/"><i></i>&nbsp;Home</a></span>&nbsp;&gt;&nbsp;<span itemscope="" itemprop="itemlistElement" typeof="v:Breadcrumb"><a itemprop="item" href="https://www.osnews.com/topic/osnews/" rel="v:url" property="v:title">OS News</a></span>&nbsp;&gt;&nbsp;<span><span>It turns out Nokia’s legendary font makes for a great general user interface font</span></span></p><header></header><div itemprop="articleBody"><p>If you’re of a certain age (and not American), there’s a specific corporate font you’re most likely aware of. You may not know its exact name, and you may not actively remember it, but once you see it, you know exactly what you’re looking at. The font’s called Nokia Sans (and Nokia Serif), and it was used by pretty much every single Nokia device between roughly 2002 and 2013 or so, when it was replaced by <a href="https://en.wikipedia.org/wiki/Nokia_Pure">a very bland font</a> made by Bruno Maag (with help from the person who designed Comic Sans) that they used after that.</p><p>I can’t remember why, exactly, but I got majorly nostalgic for Nokia’s characteristic, recognisable font, and decided to see if it would work as a user interface font. Now, the font is still owned by Nokia and I couldn’t find a proper place to download it, but I eventually stumbled upon a site that had <a href="https://en.maisfontes.com/font-family/nokia-sans-font-family-download-free">each individual variant listed for download</a>. I downloaded each of them, installed them using KDE’s font installation method, and tried it out as my user interface font.</p><figure><figure><a href="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-scaled.png"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDI0IiBoZWlnaHQ9IjQyMSIgdmlld0JveD0iMCAwIDEwMjQgNDIxIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" fetchpriority="high" decoding="async" width="1024" height="421" data-id="143225" data-src="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-1024x421.png" alt="" data-srcset="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-1024x421.png 1024w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-300x123.png 300w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-768x316.png 768w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-1536x632.png 1536w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250821_232812-1-2048x843.png 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px"></a></figure><figure><a href="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250829_234813.png"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI5ODMiIGhlaWdodD0iODY1IiB2aWV3Qm94PSIwIDAgOTgzIDg2NSI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2NmZDRkYjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" decoding="async" width="983" height="865" data-id="143223" data-src="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250829_234813.png" alt="" data-srcset="https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250829_234813.png 983w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250829_234813-300x264.png 300w, https://www.osnews.com/wp-content/uploads/2025/08/Screenshot_20250829_234813-768x676.png 768w" data-sizes="(max-width: 983px) 100vw, 983px"></a></figure></figure><p>You’ll quickly discover you shouldn’t use the regular variant, but should instead opt for the Nokia Sans Wide variant. Back in 2011, when Nokia originally announced it was replacing Nokia Sans, the creator of the font, Erik Spiekermann, <a href="https://spiekermann.com/en/nokia-sans-character/">responded to the announcement on his blog</a>. Apparently, one of the major reasons for Nokia to change fonts was that they claimed Nokia Sans wouldn’t work as a user interface font, but Spiekermann obviously disagrees, pointing specifically to the Wide variant. In fact, Spiekermann does not pull any punches.</p><blockquote><p>After 10 years it was high time to look at Nokia’s typefaces as the dominant visual voice of the brand but whoever decided on a completely new direction was either not aware of what was available or was persuaded by Bruno Maag to start over. Bruno may not create the most memorable typefaces, but he certainly knows how to sell them. And technically, their fonts are excellent. Too bad they didn’t have the confidence to work with me on an update. Instead they’re throwing out ten years of brand recognition in favour of blandness.</p>
<cite><a href="https://spiekermann.com/en/nokia-sans-character/">↫ Erik Spiekermann</a></cite></blockquote><p>I was pleasently surprised by just how nice the font looks when used as a general user interface font. It’s extremely legible at a variety of sizes, and has a ton of character without becoming gimmicky or overbearing. What originally started as mere curiosity has now become my UI font of choice on all my machines, finally displacing <a href="https://rsms.me/inter/">Inter</a> after many years of uncontested service. Of course, all of this is deeply personal and 95% an issue of taste, but I wanted to write about it to see if I’m just entirely crazy, or if there’s some method to my madness.</p><p>Do note that I’m using high DPI displays, and KDE on Wayland, and that all of this may look different on Windows or macOS, or on displays with lower DPI. One of Inter’s strengths is that it renders great on both high and lower DPI displays, but since I don’t have any lower DPI displays anymore, I can’t test it in such an environment. I’m also not entirely sure about the legal status of downloading fonts like this, but I am fairly sure you’re at least allowed to use non-free fonts for personal, non-commercial use, but please don’t quote me on that. Since downloading each variant of these Nokia fonts is annoying, I’d love to create and upload a zip file containing all of them, but I’m sure that’s illegal.</p><p>I’m not a font connoisseur, so I may be committing a huge faux pas here? Not that I care, but reading about font nerds losing their minds over things I never even noticed is always highly entertaining.</p></div></div><div><h4>About The Author</h4>
<p><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3MiIgaGVpZ2h0PSI3MiIgdmlld0JveD0iMCAwIDcyIDcyIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" alt="" data-src="https://www.osnews.com/wp-content/litespeed/avatar/8f4c2152b7e9c06a31bd3f75f0549996.jpg?ver=1756328442" data-srcset="https://www.osnews.com/wp-content/litespeed/avatar/a9c5be496e027f80968deb12c93dd064.jpg?ver=1756328441 2x" height="72" width="72" decoding="async"></p><h5><a href="https://www.osnews.com/story/author/thom-holwerda/" rel="nofollow">Thom Holwerda</a></h5><p>Follow me on Mastodon <a href="https://exquisite.social/@thomholwerda">@<span data-cfemail="c0b4a8afada8afacb7a5b2a4a180a5b8b1b5a9b3a9b4a5eeb3afa3a9a1ac">[email&nbsp;protected]</span></a></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From Multi-Head to Latent Attention: The Evolution of Attention Mechanisms (115 pts)]]></title>
            <link>https://vinithavn.medium.com/from-multi-head-to-latent-attention-the-evolution-of-attention-mechanisms-64e3c0505f24</link>
            <guid>45072160</guid>
            <pubDate>Sat, 30 Aug 2025 05:45:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vinithavn.medium.com/from-multi-head-to-latent-attention-the-evolution-of-attention-mechanisms-64e3c0505f24">https://vinithavn.medium.com/from-multi-head-to-latent-attention-the-evolution-of-attention-mechanisms-64e3c0505f24</a>, See on <a href="https://news.ycombinator.com/item?id=45072160">Hacker News</a></p>
Couldn't get https://vinithavn.medium.com/from-multi-head-to-latent-attention-the-evolution-of-attention-mechanisms-64e3c0505f24: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hacker News em dash user leaderboard pre-ChatGPT (198 pts)]]></title>
            <link>https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html</link>
            <guid>45071722</guid>
            <pubDate>Sat, 30 Aug 2025 03:40:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html">https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html</a>, See on <a href="https://news.ycombinator.com/item?id=45071722">Hacker News</a></p>
Couldn't get https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Why Romania excels in international Olympiads (198 pts)]]></title>
            <link>https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/</link>
            <guid>45070793</guid>
            <pubDate>Sat, 30 Aug 2025 00:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/">https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/</a>, See on <a href="https://news.ycombinator.com/item?id=45070793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><span>Olympiads are international student intellectual competitions in which students from across the world go toe-to-toe answering questions in mathematics, physics, informatics, chemistry, and more. The best performers tend to be from countries like China, the United States, India, and Japan. But, somehow, the southeastern European country of Romania also frequently tops the list.</span></p>
<p><span>Since 2020, Romania’s performance in the International Mathematical Olympiad (IMO) has been nothing short of amazing. In 2022, Romania came in fifth overall, fourth in 2023, and twelfth in 2024. In 2023, Romania placed fourth globally and first in Europe at the International Physics Olympiad, seventeenth globally and third in Europe at the International Olympiad in Informatics, sixth globally and second in Europe in the European Girls’ Mathematical Olympiad, first in the Balkan Mathematical Olympiad—which also included France, Italy, and the United Kingdom—and first in the Central European Olympiad in Informatics. Romania also performed well in the International Chemistry Olympiad and many others.</span></p>
<p><span>It’s an understatement to call Romania’s skill in Olympiads merely “overperformance”. Romania’s lackluster performance in international assessments and its relatively small population size of just over 19 million people makes the things they do in Olympiads downright miraculous.</span></p>
<p><span>Average Romanian educational performance is unimpressive. Romanian youth routinely perform below the average of OECD countries and near the bottom of the pack of European nations. Romania has a poor-to-mediocre showing whether you include or exclude migrants from the calculations, and its scores on assessments like the PISA aren’t low due to being tainted by bias in the examinations. Romania genuinely underperforms. But underperformance is not the impression you would get if you only knew of Romanian education from Olympiads.</span></p>
<p><span>One possibility is that Romanian students have more variable performance on international assessments than students in other countries. No dice: </span><a href="https://www.oecd.org/en/about/programmes/pisa.html"><span>they</span></a> <a href="https://timssandpirls.bc.edu/timss-landing.html"><span>aren’t</span></a> <a href="https://www.iea.nl/studies/iea/pirls"><span>much</span></a><span> more variable than the student populations in other countries, and a handful of comparably-sized nations with worse Olympiad performance are more variable. Another possibility is that, for some reason, there’s a fat right tail in Romanian educational performance. If this is true, it just doesn’t show up in any existing data. Given the fact that international assessments indicate Romania’s sampling tends to be population-representative, we should have a strong prior against this possibility. Romanian test scores tend to be distributed along a symmetrical bell curve.&nbsp;</span></p>
<p><span>Yet another possibility is that Romania has an undersampled ethnic group that overperforms, but whose schools aren’t tested very well. The only group this might be is Romanian Jews and using them as an explanation is problematic for two reasons. The first is that there are too few to realistically explain Romanian Olympiad performance. The second is that we know the identities of Olympiad participants from Romania, and they don’t seem to be Jewish.</span></p>
<p><span>Something else, something more mysterious, explains why Romania is such an outlier in international intellectual competitions. That thing is, in fact, the unique design of the Romanian educational system.</span></p>
<p><span>In the late 19</span><span>th</span><span> century, Romanian prince regnant Alexandru Ioan Cuza attempted to raise the status of the nation by instituting a mass literacy campaign centered around building free schools that children were compelled to attend. This effort was largely a failure, with literacy failing to break 50% by the 1930s. But World War II precipitated change. In 1948, Romania’s new governing communist party began to bring about serious educational reform at a breakneck pace.The Education Law of 1948 was passed to provoke a military-grade offensive against illiteracy, involving the mass participation of the literate from all walks of life in uplifting the poor, the abandoned, and those who simply shunned education. By the end of the 1950s, illiteracy was practically eradicated among Romania’s youth.</span></p>
<p><span>The education system that existed in Romania’s communist period was modeled on the system in place in the Soviet Union, and it included a fair helping of political propaganda in addition to physical labor. The system also overproduced schools, resulting in shoddy but widely available facilities dotting the country. Like the Soviet school system, Romania’s was marked by increasing lengths of compulsory education, poor availability of qualified teachers and educational supplies, high budgetary costs, and an extreme level of credential inflation.</span></p>
<p><span>After the fall of communism, the new democratic government went on to shutter many of these schools and to immediately lower compulsory schooling requirements to put an end to the bureaucratic nightmare that Soviet influence had saddled the country with. In the following years, how Romania wished to ration scarce governmental resources for education was a matter of intense debate, and out of that debate came a strong sentiment that, whatever the system, Romanian education would be structured competitively.</span></p>
<p><span>Nowadays, the most prestigious Romanian high schools are the National Colleges, or </span><i><span>Colegiu Național</span></i><span>. These schools are often international and frequently uphold old educational traditions sometimes dating back more than a century. Below these schools are the </span><i><span>Liceu Teoretic</span></i><span>, which are the norm, offering standard educations. Romania also has three military colleges—</span><i><span>Colegiu Militar</span></i><span>—managed directly by the Ministry of National Defense. There are also schools focused on service, technical schools, vocational schools, and apprenticeship programs. The brightest students get their pick among these schools after they take the national placement test, the </span><i><span>Evaluarea Națională, </span></i><span>when they are graduating the 8</span><span>th</span><span> grade around ages fourteen to fifteen.</span></p>
<p><span>The high school placement test is a standardized test covering Romanian language and literature as well as mathematics. Performance on the examination is reported publicly when students are issued a score on a one-to-ten scale with precision to two decimal places. A student who receives a high grade—say 9.65—would have their pick from most any school, whereas a student scoring 5.00 or below would usually be constrained to a less academically-focused form of education like a vocational program. Most students elect to go to the best school they are able to test into, and so the degree of sorting across schools is very high. To make this setup even more extreme, there is also often—but not universally—sorting </span><i><span>within</span></i><span> schools, as students select into educational tracks. This is done directly when applying to schools.</span></p>
<p><span>At the end of the Romanian high school experience, there is a graduation test, the </span><i><span>Bacalaureat</span></i><span>, or </span><i><span>bac</span></i><span>. This test is marked like the entrance examination and, to pass, students must obtain a score of at least five in the subjects they have elected to take. This testing includes written and oral examinations, assessments of foreign language and computer skills, and, for ethnic minorities, assessment of their skill with their maternal language other than Romanian. The need for a given score on this examination can range from requiring just passing to requiring a high score, depending on the university one intends to attend, if that is their goal.</span></p>
<p><span>The design of Romania’s educational system makes it perhaps the most stratified educational system in the world. The fact that they have a centralized repository containing all student and teacher educational data makes their system perfect for a high-powered evaluation of exactly what happens when a country opts to hyper-stratify education.</span></p>
<p><span>One of the cruel parts of the Romanian system is that, though sorting is nationally available, students do not have equal opportunities to sort. Students located in smaller towns have fewer high school options to select from unless they’re among the few who opt into a military academy, which means joining the military. The extent of sorting is far more intense in areas with larger numbers of schools. In a </span><a href="https://direct.mit.edu/rest/article-abstract/doi/10.1162/rest_a_01438/120190/School-Choice-Student-Sorting-and-Academic"><span>recent paper</span></a><span>, the Romanian economist Andrei Munteanu provided an illustration of how this works: essentially, the fewer schools in a locale, the more each individual school contains students with a wider range of ability and, the more schools in a locale, the more each individual school will be stratified into low, middle, or high ability.&nbsp;</span></p>
<p><span>This combined sorting between schools and tracks means that low-ability students get stuck with other low-ability students, and high-ability students are surrounded by other high-ability students. In effect, peer groups throughout high school are extremely homogeneous. This matters because then low-performing students drag down low-performing students, and high performers cause each other to rise. Romania’s educational system has causal peer impacts on student performance on the graduation test that are very large in both directions, but primarily where there are opportunities for sorting to take place.</span></p>
<figure id="attachment_7695" aria-describedby="caption-attachment-7695"><img decoding="async" src="https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy.png" alt="" width="3600" height="2400" srcset="https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-300x200.png 300w, https://pdmedia.b-cdn.net/2025/08/sIOqtz0e-SchoolSortBusy-1024x683.png 1024w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-768x512.png 768w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-1536x1024.png 1536w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-2048x1365.png 2048w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-450x300.png 450w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-900x600.png 900w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy.png 3600w" sizes="(max-width: 999px) 96vw, (max-width: 1359px) 80vw, (max-width: 1519px) 75vw, 1175px"><figcaption id="caption-attachment-7695">Jordan Lasker/The more schools a town has the more intense the sorting of students is. Graduation scores are positively impacted for top performers and negatively for bottom performers with more intense sorting.</figcaption></figure>
<p><span>But peer effects are not everything to Romania’s exceptional Olympiad performance; they are just the fertile ground in which exceptional performance is fostered. The next part has to do with teachers. Like students, Romania’s teachers must take tests to be able to do what they want to do. Teachers naturally prefer to lecture smarter students, and the smartest teachers have their pick of the schools, and even of the tracks. In a paper with extremely robust results, researchers from the last decade </span><a href="https://www.aeaweb.org/articles?id=10.1257/aer.103.4.1289"><span>described</span></a><span> this as such:</span></p>
<blockquote><p><i><span>[Teachers] with higher certification standards are more likely to work at better-ranked schools. This sorting persists even within schools as one moves from a weaker to a stronger track, and even within tracks as one moves from a weaker to a stronger class.</span></i></p></blockquote>
<p><span>The best teachers also opt into towns with more schools. It’s apparent, then, that teachers prefer teaching in the highest-achieving places they can be, both within and between towns. The effect of teacher-student ability pairing is accentuated even more by incentives to compete. The government of Romania is not unique in providing monetary rewards for those who win Olympiads, those who teach winners of Olympiads, or those schools Olympiad winners attend, but they are unique in having all the previously-mentioned institutional characteristics </span><a href="https://archive.md/ki6Do"><span>on top of</span></a><span> providing comprehensive monetary incentives for Olympiad achievement.&nbsp;</span></p>
<p><span>Romania’s immense success in Olympiads and the widely recognized importance of Olympiad wins for signaling student human capital has also spawned a small number of private schools that advertise their prominence and tutoring capabilities. Many teachers also recommend to parents that they obtain additional tutoring for their brighter pupils, and tutoring services are commonplace. The commonality of tutoring for Olympiad winners is a global constant, whereas the things distinguishing Romania are not.</span></p>
<p><span>Two notable factors do not increase performance in the same direction. These are very slight decrements in funding allocated to the highest-ability schools, and when parents reduce the time they spend helping their students with homework, conditional on their kids matching into better schools. Another potential factor that militates against the synchrony of resource allocation in Romania is that children in more selective schools report feeling marginalized because they realize that they’re not as strong of students as they believed. The decrements in funding are likely to be unproblematic, because higher-scoring schools tend to be larger and more urban, lending them economies of scale. Due to this, they may have effectively more funding.</span></p>
<p><span>With all the pieces on the board, the key to Romania’s Olympiad success is three-fold: put the best students in the same classrooms, put the best teachers with the best students, and then incentivize schools, teachers, and students each to win Olympiads.</span></p>
<p><span>This system has proved amazingly fruitful. Given its underlying human capital, the poverty from its communist legacy, and its modest population size, Romania should not perform the way it does in academic Olympiads. And yet it does</span><i><span>. </span></i><span>The trade-off for Romania, however, is palpable.</span></p>
<p><span>Large portions of Romania’s Olympiad winners leave the country. Because Romania is a member state of the European Union, the people the country has put great effort into training and credentialing are easily able to leave the country and acquire jobs elsewhere.</span></p>
<p><span>Losing the right tail to brain drain is damaging for many countries, but it’s arguably worse for Romania because its educational system is so zero-sum: the top performers do better, while the low-performers do worse. This sorting does not “lift all boats,” as it were. In Romania, the system makes for an incredibly well-trained right tail and a neglected left tail, and that left tail might hurt more than the right tail is helped, if effects on test scores are any indication. On its own, Romania’s system might be a stellar boon to the country. But with free movement of talent between countries, Romania ends up subsidizing talent discovery for other countries with less apt educational systems.&nbsp;</span></p>
<p><span>Most of the growth we see around us is due to the innovations of the right tail, and if they do better, we all do better. Though I doubt Romania’s schooling raises the intelligence</span> <span>of the right tail, even raising aptitude is worth something, because we must get capable people to the frontiers of their respective fields in order to innovate, and Romania has fostered a system that seems to do just that. Moreover, even if Olympiad training does not make those on the right tail more capable but instead simply prepares them better, then it can still</span> <span>have large, socially beneficial effects simply through providing Romania’s highly capable people with a means of having their talents recognized internationally.&nbsp;</span></p>
<p><span>But these benefits are returned only very indirectly to Romania, if at all on net. Rather than changing Romania’s educational system or closing the borders, the right solution is for more nations to choose to be like Romania, getting a lot more juice out of their smart kids by designing a system just for them.</span></p>
<p>Jordan Lasker is a bioinformatician. He writes on his <a href="https://www.cremieux.xyz/">website</a> and you can follow him at <a href="https://x.com/cremieuxrecueil">@cremieuxrecueil</a>.</p>


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Theoretical Limitations of Embedding-Based Retrieval (122 pts)]]></title>
            <link>https://arxiv.org/abs/2508.21038</link>
            <guid>45068986</guid>
            <pubDate>Fri, 29 Aug 2025 20:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2508.21038">https://arxiv.org/abs/2508.21038</a>, See on <a href="https://news.ycombinator.com/item?id=45068986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2508.21038">View PDF</a>
    <a href="https://arxiv.org/html/2508.21038v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. While prior works have pointed out theoretical limitations of vector embeddings, there is a common assumption that these difficulties are exclusively due to unrealistic queries, and those that are not can be overcome with better training data and larger models. In this work, we demonstrate that we may encounter these theoretical limitations in realistic settings with extremely simple queries. We connect known results in learning theory, showing that the number of top-k subsets of documents capable of being returned as the result of some query is limited by the dimension of the embedding. We empirically show that this holds true even if we restrict to k=2, and directly optimize on the test set with free parameterized embeddings. We then create a realistic dataset called LIMIT that stress tests models based on these theoretical results, and observe that even state-of-the-art models fail on this dataset despite the simple nature of the task. Our work shows the limits of embedding models under the existing single vector paradigm and calls for future research to develop methods that can resolve this fundamental limitation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Orion Weller [<a href="https://arxiv.org/show-email/fae50c49/2508.21038" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 28 Aug 2025 17:43:53 UTC (195 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do the simplest thing that could possibly work (879 pts)]]></title>
            <link>https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/</link>
            <guid>45068091</guid>
            <pubDate>Fri, 29 Aug 2025 19:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/">https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/</a>, See on <a href="https://news.ycombinator.com/item?id=45068091">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>When designing software systems, do the simplest thing that could possibly work.</p>
<p>It’s surprising how far you can take this piece of advice. I genuinely think you can do this <em>all the time</em>. You can follow this approach for fixing bugs, for maintaining existing systems, and for architecting new ones.</p>
<p>A lot of engineers design by trying to think of the “ideal” system: something well-factored, near-infinitely scalable, elegantly distributed, and so on. I think this is entirely the wrong way to go about software design. Instead, spend that time understanding the current system deeply, then do the simplest thing that could possibly work.</p>
<h3>Simple can be underwhelming</h3>
<p><a href="https://www.seangoedecke.com/good-system-design">System design</a> requires competence with a lot of different tools: app servers, proxies, databases, caches, queues, and so on. As they gain familiarity with these tools, junior engineers naturally want to use them. It’s fun to construct systems out of many different components! And it feels very satisfying to draw boxes and arrows on a whiteboard - like you’re doing real engineering.</p>
<p>However, as with many skills, real mastery often involves learning when to do less, not more. The fight between an ambitious novice and an old master is a well-worn cliche in martial arts movies: the novice is a blur of motion, flipping and spinning. The master is mostly still. But somehow the novice’s attacks never seem to quite connect, and the master’s eventual attack is decisive.</p>
<p>In software, this means that <a href="https://www.seangoedecke.com/great-software-design">great software design looks underwhelming</a>. It doesn’t look like anything much is happening at all. You can tell you’re in the presence of great software design because you start having thoughts like “oh, I didn’t realise the problem was that easy” or “oh nice, you don’t actually have to do anything difficult”.</p>
<p><a href="https://github.com/defunkt/unicorn">Unicorn</a> is great software design, because it delivers all the most important guarantees in a web server (request isolation, horizontal scaling, crash recovery) by leaning on Unix primitives<sup id="fnref-1"><a href="#fn-1">1</a></sup>. The industry-standard Rails REST API is great software design, because it gives you exactly what you need for a CRUD app in the most boring way possible. I don’t think any of these are impressive <em>software</em>. But they’re impressive feats of <em>design</em>, because <strong>they do the simplest thing that could possibly work</strong>.</p>
<p>You should do that too! Suppose you’ve got a Golang application that you want to add some kind of rate limiting to. What’s the simplest thing that could possibly work? Your first idea might be to add some kind of persistent storage (say, Redis) to track per-user request counts with a leaky-bucket algorithm. That would work! But do you need a whole new piece of infrastructure? What if instead you kept those per-user request counts in-memory? Sure, you’d lose some rate limiting data when the application is restarted, but does that matter? Actually, are you sure your edge proxy<sup id="fnref-2"><a href="#fn-2">2</a></sup> doesn’t support rate limiting already? Could you just write a couple of lines in a config file instead of implementing the feature at all?</p>
<p>Maybe your edge proxy doesn’t support rate limiting. Maybe you can’t track it in-memory because you have too many server instances running in parallel, so the tightest rate limit you could enforce that way is too wide. Maybe it’s a dealbreaker if you ever lose rate limiting data, because people are hammering your service <em>that</em> hard. In that case, the simplest thing that could possibly work is adding persistent storage, so you should go and do that. But if you could do one of the easier approaches, wouldn’t you want to?</p>
<p>You really can build a whole application from scratch this way: start with the absolute simplest thing, and then only extend it when you have new requirements that force you to. It sounds silly, but it works. Think of it as taking <a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">YAGNI</a> as the ultimate design principle: above single-responsibility, above choosing the best tool for the job, and above “good design”.</p>
<h3>What’s wrong with doing the simplest thing?</h3>
<p>Of course, there are three big problems with always doing the simplest thing that could possibly work. The first is that, by not anticipating future requirements, you end up with an inflexible system or a <a href="http://laputan.org/mud/">big ball of mud</a>. The second is that it’s not clear what “simplest” means, so at worst I’m saying “to design well, always do good design”. The third is that you ought to be building systems that can <em>scale</em>, not systems that just work right now. Let’s take those objections in order.</p>
<h4>Big balls of mud</h4>
<p>To some engineers, “do the simplest thing that could possibly work” sounds like I’m telling them to stop doing engineering. If the simplest thing is usually a quick kludge, does that mean this advice will inevitably lead to a complete mess? We’ve all seen codebases with hacks stacked on top of hacks, and they definitely don’t look like good design.</p>
<p>But are hacks simple? I actually don’t think so. The problem with a hack or a kludge is precisely that it <em>isn’t</em> simple: that it adds complexity to the codebase by introducing another thing you have to always remember. Hacks are just <em>easier to think of</em>. Figuring out the proper fix is hard because it requires having to understand the entire codebase (or large sections of it). In fact, the proper fix is almost always much simpler than the hack.</p>
<p>It is not easy to do the simplest thing that could possibly work. When you’re looking at a problem, the first few solutions that come to mind are unlikely to be the simplest ones. Figuring out the simplest solution requires considering many different approaches. In other words, it requires doing engineering.</p>
<h4>What is simplicity?</h4>
<p>Engineers disagree a lot about what constitutes simple code. If “simplest” already means “with good design”, is it just a tautology to say “you should do the simplest thing that could possibly work?” In other words, is Unicorn really simpler than <a href="https://github.com/puma/puma">Puma</a><sup id="fnref-3"><a href="#fn-3">3</a></sup>? Is adding in-memory rate limiting really simpler than using Redis? Here’s a rough, intuitive definition of simplicity<sup id="fnref-4"><a href="#fn-4">4</a></sup>:</p>
<ol>
<li>Simple systems have fewer “moving pieces”: fewer things you have to think about when you’re working with them</li>
<li>Simple systems are less <em>internally-connected</em>. They are composed from components with clear, straightforward interfaces</li>
</ol>
<p>Unix processes are simpler than threads (and thus Unicorn is simpler than Puma) because processes are less connected: they do not share memory. This makes a lot of sense to me! But I don’t think it gives you the tools to figure out what’s simpler in every case.</p>
<p>What about in-memory rate limiting vs Redis? On the one hand, in-memory is simpler because you don’t have to think about all the things involved in standing up a separate service with persistent memory. On the other hand, Redis is simpler because the rate limiting guarantees it offers are more straightforward - you don’t have to worry about the case where one server instance thinks a user is rate limited and another one doesn’t.</p>
<p>When I’m not sure what “seems” simpler to me, I like to use this tiebreaker: <strong>simple systems are stable</strong>. If you’re comparing two states of a software system, and one will require more ongoing work <em>if no requirements change</em>, the other one is simpler. Redis must be deployed and maintained, it can have its own incidents, it requires its own monitoring, it requires a separate deployment in any new environments the service finds itself in, and so on. Thus in-memory rate limiting is simpler than Redis<sup id="fnref-5"><a href="#fn-5">5</a></sup>.</p>
<h4>Why wouldn’t you want to be scalable?</h4>
<p>A certain type of engineer is now screaming to themselves “but in-memory rate limiting won’t scale!” Doing the simplest thing that could possibly work will emphatically not deliver the most web-scale system. It will deliver a system that works well at the current scale. Is this irresponsible engineering?</p>
<p>No. In my view, the cardinal sin of big tech SaaS engineering is an obsession with scale. I’ve seen so much unavoidable pain caused by over-engineering systems to prepare for several orders of magnitude more than the current scale.</p>
<p>The main reason to not try this is that <strong>it doesn’t work</strong>. In my experience, for any non-trivial codebase, you can’t anticipate how it will behave at several orders of magnitude more traffic, because you don’t know ahead of time where all the bottlenecks are going to be. At most you can try to make sure you’re ready for 2x or 5x the current traffic, and then stand by to deal with problems as they come in.</p>
<p>The other reason not to try this is that <strong>it makes your codebase inflexible</strong>. It’s fun to decouple your service into two pieces so they can be scaled independently (I have seen this happen maybe ten times, and I have seen them <em>actually be usefully scaled independently</em> maybe once). But that makes certain features very hard to implement, because they now require coordination over the wire. In the worst case, they require <em>transactions</em> over the wire, which is a genuinely hard engineering problem. Most of the time you just don’t have to do any of this!</p>
<h3>Final thoughts</h3>
<p>The longer I spend working in tech, the less optimistic I become about our collective ability to predict where a system is going. It’s hard enough to get your head around where a system currently is. And in fact, that’s the main practical difficulty in doing good design: getting an accurate big-picture understanding of the system. Most design is done without that understanding, and most design is thus pretty bad.</p>
<p>There are, broadly speaking, two ways to develop software. The first is to predict what your requirements might look like six months or a year from now, and then design the best system for that purpose. The second is to design the best system for what your requirements actually look like right now: in other words, to do the simplest thing that could possibly work.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Income Equality in Nordic Countries: Myths, Facts, and Lessons (110 pts)]]></title>
            <link>https://www.aeaweb.org/articles?id=10.1257/jel.20251636</link>
            <guid>45067423</guid>
            <pubDate>Fri, 29 Aug 2025 18:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aeaweb.org/articles?id=10.1257/jel.20251636">https://www.aeaweb.org/articles?id=10.1257/jel.20251636</a>, See on <a href="https://news.ycombinator.com/item?id=45067423">Hacker News</a></p>
<div id="readability-page-1" class="page"><section role="main">

    
    




    
    <ul>
            
    <li>
         Kjell G. Salvanes    </li>
    <li>
         Gaute Torsvik    </li>

    </ul>

		<div>

			<p>Journal of Economic Literature </p>

			                

		</div>
                <p>(pp. 791–839)</p>
		
    
	
    <section>
        <a href="https://www.aeaweb.org/articles/pdf/doi/10.1257/jel.20251636">
            Download Full Text PDF <br>
                    </a>
    </section>

	
	
    <div>

		   <ul>
				<li>
					<a href="#article-information">Article Information</a>
				</li>
											</ul>
		
		
        <section id="article-information">

							<section>
					<h4>Abstract</h4>
					Policymakers, public commentators, and researchers often cite the Nordic countries as examples of a socioeconomic model that combines low income inequality with prosperity and growth. This article critically assesses that claim by integrating theoretical perspectives and empirical evidence to explain how the Nordic model functions and why these countries experience low inequality. Our analysis suggests that income equality in the Nordics is largely driven by a significant compression of hourly wages, reducing returns to labor market skills and education. This appears to result from a wage bargaining system characterized by strong coordination within and across industries. This finding challenges other commonly cited explanations for Nordic income equality, such as redistribution through the tax transfer system, public spending on goods that complement employment, and public policies promoting equal skills and human capital. We consider broader lessons for economies aiming to reduce inequality and conclude by highlighting several under-explored or unresolved questions.				</section>
			
							<section>
					<h4>Citation</h4>
					<cite>

                        Mogstad, Magne, Kjell G. Salvanes, and Gaute Torsvik.
						<span>2025.</span>

						
						
							<span>"Income Equality in the Nordic Countries: Myths, Facts, and Lessons."</span>
						
						<span>Journal of Economic Literature</span>
							  <span>
					63 (3):
					 791–839<span>.</span>
				  </span>
						<span>DOI: 10.1257/jel.20251636</span>
					</cite>

					
				</section>
								
					<section>
						
							<h4>Additional Materials</h4>

						
						<ul id="additionalMaterials">
							<li>                    <a target="_blank" href="https://doi.org/10.3886/E221423V1" doi="10.1257/jel.20251636" accesstype="Article View">
                Replication Package                                            </a>
        </li><li>                    <a href="https://www.aeaweb.org/articles/materials/23773" doi="10.1257/jel.20251636" accesstype="Article View">
                Author Disclosure Statement(s)                                            </a>
        </li>
						</ul>
					</section>


				
									<section>
						<h4>JEL Classification</h4>
						<ul>
														<li>
								<strong>D31</strong>
								Personal Income, Wealth, and Their Distributions
															</li><li>
								<strong>E23</strong>
								Macroeconomics: Production
															</li><li>
								<strong>H23</strong>
								Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies
															</li><li>
								<strong>J24</strong>
								Human Capital; Skills; Occupational Choice; Labor Productivity
															</li><li>
								<strong>J31</strong>
								Wage Level and Structure; Wage Differentials
															</li><li>
								<strong>J52</strong>
								Dispute Resolution: Strikes, Arbitration, and Mediation; Collective Bargaining
															</li>
						</ul>
					</section>
				
			</section>

		
		
        
		 </div> 
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite's documentation about its durability properties is unclear (141 pts)]]></title>
            <link>https://www.agwa.name/blog/post/sqlite_durability</link>
            <guid>45066999</guid>
            <pubDate>Fri, 29 Aug 2025 17:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.agwa.name/blog/post/sqlite_durability">https://www.agwa.name/blog/post/sqlite_durability</a>, See on <a href="https://news.ycombinator.com/item?id=45066999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>
One of the most important properties of a database is durability.  Durability means that after a transaction commits, you
can be confident that, absent catastrophic hardware failure, the changes made by the commit won't be lost.  This should
remain true even if the operating system crashes or the system loses power soon after the commit.  On Linux, and most other Unix operating systems, durability is ensured by calling the <a href="https://man7.org/linux/man-pages/man2/fsync.2.html" rel="external">fsync</a> system call at the right time.
</p>

<p>
Durability comes at a performance cost, and sometimes applications don't need durability.  Some applications can tolerate
losing the last several seconds of commits in the event of a power failure, as long as the database doesn't end up
corrupted.  Thus, databases typically provide knobs to configure if and when they call fsync.  This is fine, but it's essential
that the database clearly documents what its default durability properties are, and what each configuration setting guarantees.
</p>

<p>
Unfortunately, SQLite's documentation about its durability properties is far from clear.  I cannot tell whether SQLite is durable
by default, and if not, what are the minimal settings you need to use to ensure durability.
</p>

<p>The two relevant configuration
options are <a href="https://sqlite.org/pragma.html#pragma_journal_mode" rel="external"><code>journal_mode</code></a> and <a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external"><code>synchronous</code></a>.  <code>journal_mode</code> has several possible values, but most people use either DELETE or WAL.  <code>synchronous</code> has four possible values: EXTRA, FULL, NORMAL, and OFF.
</p>

<p>
This is how I interpret SQLite's documentation after a careful reading:
</p>

<ul><li><p>The default value of <code>journal_mode</code> is DELETE:</p><blockquote>The DELETE journaling mode is the normal behavior (<a href="https://sqlite.org/pragma.html#pragma_journal_mode" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_journal_mode" rel="external">archived</a>)</blockquote></li><li><p>The default value of <code>synchronous</code> is FULL:</p><blockquote>If not overridden at compile-time, the default setting is 2 (FULL) (<a href="https://sqlite.org/compile.html#default_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826070702/https://sqlite.org/compile.html#default_synchronous" rel="external">archived</a>)</blockquote></li><li><p>The default value of <code>synchronous</code> is FULL even in WAL mode:</p><blockquote>If not overridden at compile-time, this value is the same as SQLITE_DEFAULT_SYNCHRONOUS. (<a href="https://sqlite.org/compile.html#default_wal_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826070702/https://sqlite.org/compile.html#default_wal_synchronous" rel="external">archived</a>)</blockquote></li><li><p>When <code>journal_mode</code> is DELETE, you need to set <code>synchronous</code> to EXTRA to get durability:</p><blockquote>EXTRA synchronous is like FULL with the addition that the directory containing a rollback journal is synced after that journal is unlinked to commit a transaction in DELETE mode. EXTRA provides additional durability if the commit is followed closely by a power loss. (<a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_synchronous" rel="external">archived</a>)</blockquote>
<p>
Edited to add: I confirmed this to be true through testing - see <a href="https://news.ycombinator.com/item?id=45069533" rel="external">my Hacker News comment</a> for the methodology.
</p>
</li><li><p>When <code>journal_mode</code> is WAL, FULL is sufficient for durability:</p><blockquote>With synchronous=FULL in WAL mode, an additional sync operation of the WAL file happens after each transaction commit. The extra WAL sync following each transaction helps ensure that transactions are durable across a power loss (<a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_synchronous" rel="external">archived</a>)</blockquote><p>Note that this is not mentioned under the definition of FULL, but rather further down in the documentation for <code>synchronous</code>.</p></li></ul>

<p>
Based on the above, I conclude that:
</p>

<ul><li><p>By default, SQLite is <strong>not</strong> durable, because the default value of <code>journal_mode</code> is DELETE, and the default value of <code>synchronous</code> is FULL, which doesn't provide durability in DELETE mode.</p></li><li><p>If you change <code>journal_mode</code> to WAL, then SQLite <strong>is</strong> durable, because <code>synchronous=FULL</code> provides durability in WAL mode.</p></li></ul>



<p>
However, a recent <a href="https://news.ycombinator.com/item?id=45014296" rel="external">Hacker News comment</a> by a user who credibly claims to be Richard Hipp, the creator of SQLite, says:
</p>

<ul><li><p>"In its default configuration, SQLite is durable."</p></li><li><p>"If you switch to WAL mode, the default behavior is that transactions ... are not necessarily durable across OS crashes or power failures"</p></li></ul>

<p>
That's literally the opposite of what the documentation seems to say!
</p>

<p>
A Hacker News commenter who agrees with my reading of the documentation <a href="https://news.ycombinator.com/item?id=45015366" rel="external">asked Hipp</a> how his comment is consistent with the documentation, but received no reply.
</p>

<p>
Hipp also says that WAL mode used to be durable by default, but it was changed after people complained about poor performance.
This surprised me, since I had the impression that SQLite cared deeply about backwards compatibility, and weakening the
default durability setting is a nasty breaking change for any application which needs durability.
</p>

<p>
There are a couple other pitfalls around SQLite durability that you should be aware of, though I don't necessarily
blame the SQLite project for these:
</p>

<ul><li><p>Libraries that wrap SQLite can override the default value of <code>synchronous</code>.  For example, the most popular Go driver for SQLite <a href="https://github.com/mattn/go-sqlite3/blob/8bf7a8a844faf952aa0245b4c0ad0a47e84f4efd/sqlite3.go#L1318-L1320" rel="external">sets it to NORMAL</a> when in WAL mode, which does not provide durability.</p></li><li><p>On macOS, <a href="https://lactoseintolerant.dev/fsync-may-not-be-enough-to-guarantee-data-durability-on-mac-os/" rel="external">fsync is nerfed</a> to make macOS appear faster.  If you want a real fsync, you have to make a different, macOS-specific system call.  SQLite can do this, but it's <a href="https://sqlite.org/pragma.html#pragma_fullfsync" rel="external">off by default</a>.</p></li></ul>

<p>
My takeaway is that if you need durability, you'd better set the <code>synchronous</code> option explicitly because who knows what the default is, or what it will be in the future.  With WAL mode, FULL seems to suffice.  As for DELETE mode, who knows if FULL is enough, so you'd better go with EXTRA to be safe. And if your application might be used on macOS, enable <code>fullfsync</code>.
</p>

<p>
The SQLite project ought to clarify their documentation.  Since the meaning of <code>synchronous</code> depends on the value of <code>journal_mode</code>, I think it would be quite helpful to document the values of <code>synchronous</code> separately for each possible <code>journal_mode</code>, rather than mixing it all together.  A table with <code>synchronous</code> values on one axis and <code>journal_mode</code> on the other which tells you if the combination provides durability would do wonders.
</p>

<p>
By the way, there are definitely many applications for which losing a few seconds of data in exchange for better performance is a great tradeoff, which is why SQLite and macOS have made the choices they have made.  But programmers need to know what guarantees their tools provide, which is why unclear documentation and breaking previously-held assumptions is not cool.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Carmack's arguments against building a custom XR OS at Meta (451 pts)]]></title>
            <link>https://twitter.com/ID_AA_Carmack/status/1961172409920491849</link>
            <guid>45066395</guid>
            <pubDate>Fri, 29 Aug 2025 16:45:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ID_AA_Carmack/status/1961172409920491849">https://twitter.com/ID_AA_Carmack/status/1961172409920491849</a>, See on <a href="https://news.ycombinator.com/item?id=45066395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The web does not need gatekeepers: Cloudflare’s new “signed agents” pitch (426 pts)]]></title>
            <link>https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers</link>
            <guid>45066258</guid>
            <pubDate>Fri, 29 Aug 2025 16:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers">https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers</a>, See on <a href="https://news.ycombinator.com/item?id=45066258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Do you register with Google, Amazon or Microsoft to use the web?</p><p><span>Cloudflare’s new “</span><strong>signed agents</strong><span>” pitch sounds like safety but it’s a wolf in sheep’s clothing. They’ve built an allowlist for the open web and told builders to apply for permission. That’s not how the internet works. An </span><a href="https://dash.cloudflare.com/?to=/:account/configurations/verified-bots" rel="nofollow ugc noopener">application form</a><span> is not a standard.</span></p><p>Yes, identity for agents is a real problem. But Cloudflare is solving it like a border checkpoint. Get on their list or get treated like a trespasser. That’s vendor approval  not an internet protocol. An allowlist run by ONE company?</p><p>Authentication for that world isn’t “ask Cloudflare for a hall pass.” It’s verifiable chains of delegation and request-level proof: open, portable, and independent of any one company.</p><p><span>The web thrived because </span><strong>no one owned it</strong><span>. </span></p><p>In the 90s, Microsoft tried to “embrace and extend” the web, but failed. And that failure was a blessing. Because no single company controlled it, anyone could publish, anyone could innovate, and protocols carried more weight than corporate policies.</p><p><span>We’ve seen this movie before. </span><strong>Open standards beat closed plug-ins.</strong><span> HTML5 and the Open Web Platform displaced proprietary runtimes like Flash (Adobe) and Silverlight (Microsoft). Flash was formally ended in 2020 and Silverlight in 2021, while HTML5 became a W3C Recommendation back in 2014.</span></p><p>The pattern is consistent: when the commons defines the interface, innovation compounds; when a vendor hands out permission slips, it stalls.</p><p><span>Agents are inevitable. They will be the next major users of the web: retrieving information, automating workflows, making purchases, negotiating contracts. </span><strong>Sometimes ai agents will be explicitly directed by humans, other times they’ll act as subroutines inside bigger tasks</strong><span>.</span></p><p>The line between human and agent action will blur. </p><p><span>When I’m driving, I hand my phone to a friend and say, “Reply ‘on my way’ to my Mom.” They act on my behalf, through my identity, even though the software has no built-in concept of delegation. </span><strong>That is the world we are entering.</strong></p><p><strong>Authentication </strong><span>asks: </span><em>who is acting?</em></p><p><strong>Authorization</strong><span> asks: </span><em>what are they allowed to do?</em></p><div><p><span>They are not the same. Yet Cloudflare treats them as if a single passport could solve both. It can’t. In the real world, showing a passport is not enough to open a bank account, the actual person must be present!. </span></p><p><span>The same is true online. A cryptographic signature that claims “I am acting on behalf of X” means nothing unless it is tied to something real, like a verifiable infrastructure or a range of IPs. Without that, I can simply hand the passport to another agent, and they can act as if they were me. The passport becomes nothing more than a token anyone can pass around.</span></p></div><p>This is why the whole idea of a “bot passport” is deeply flawed. </p><p>Authentication and authorization matter more than ever but they must be rethought for the era of agents and for an authentic web.</p><p>And here’s the truth: on the internet, nobody knows you’re a dog.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!kD6s!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!kD6s!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 424w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 848w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1272w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic" width="299" height="334" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:334,&quot;width&quot;:299,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:34738,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://positiveblue.substack.com/i/172206112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!kD6s!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 424w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 848w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1272w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><p><span>A single signature proves nothing if it can simply be passed along. What we need is a way to prove both the chain of delegation and the authenticity of each request. The chain is like a certificate :</span></p><p><em>User X on Service Y delegated to Agent Z, who delegated to Agent K</em><span>. </span></p><p><span>But when Agent K actually makes a request to Service Y, it must add its own signature to prove it is truly Agent K. Without both pieces, authentication collapses.</span></p></div><p>The system must have a few key features:</p><ul><li><p><strong>Verifiable</strong><span>: you can check the claim independently.</span></p></li><li><p><strong>Composable</strong><span>: it works across chains of delegation.</span></p></li><li><p><strong>Decentralized</strong><span>: no single gatekeeper decides who is “valid.”</span></p></li></ul><p><span>Public key cryptography already gives us a model. Companies prove ownership today through DNS; they could publish public keys in the same way. That would let a service authenticate a third party simply by checking DNS (without anyone filling forms, asking permission, or registering with a central directory). Sites could still blacklist or whitelist as they choose, but the </span><strong>default is open</strong><span>.</span></p><p><strong>This is what authentication for the agentic era should look like: open, verifiable, and decentralized.</strong></p><p><span>Until now, software usually had a </span><strong>narrow scope</strong><span>. </span></p><p>Think a weekly cron job that emails a “new signups” report: it gets read-only access to the analytics DB, nothing else. Or a finance app via Plaid to fund your trading account: it can initiate transfers within limits but can’t browse your transaction history. </p><div><p><span>OAuth scopes worked because the software had a clear, predictable purpose.</span></p><p><span>Agents are different. They are </span><strong>general-purpose</strong><span>. The same agent might book a flight, pay for dinner, and then summarize your bank statement. They may also be short-lived, spun up for a single task and gone after it.</span></p></div><p>One way to make this work is to give the agent an “admin key”: full access to everything  It’s convenient, but dangerous. We must resist this pattern.</p><p><strong>Agents should not hold permanent credentials, authorizations must be per-task, not per-agent.</strong></p><p><span>Think of a bank account: I might tell my agent </span><em>“pay for dinner.”</em><span> That token should allow payment. But when I ask </span><em>“show me three months of spending,”</em><span> the agent should not be able to move money. Same agent, different task, different token. </span><strong>Credentials must follow tasks, not agents.</strong></p><p><span>Fortunately, cryptography and authorization models have evolved a lot in the last last years. We now have tools that allow us to issue tokens with </span><strong>constraints</strong><span>: granular, short-lived, and delegable (like </span><a href="https://en.wikipedia.org/wiki/Macaroons_(computer_science)" rel="nofollow ugc noopener">macaroons</a><span> or </span><a href="https://github.com/eclipse-biscuit/biscuit" rel="nofollow ugc noopener">biscuits</a><span>) and Open policy engines (like </span><a href="https://www.openpolicyagent.org/" rel="nofollow ugc noopener">OPA</a><span> or </span><a href="https://www.cedarpolicy.com/en" rel="nofollow ugc noopener">AWS Cedar</a><span>) can also be used for RBAC/ABAC for this use case.</span></p><p>Imagine:</p><ul><li><p>User X on Service Y holds an admin token.</p></li><li><p>They derive a narrower token for Agent Z to perform one task.</p></li><li><p>Agent Z can then derive an even narrower token for a sub-agent, all without bothering the service.</p></li><li><p>Each request can be verified against the chain.</p></li></ul><p>Coupled with the authentication model above, this approach gives us a foundation for managing agents without creating new gatekeepers.</p><p>This challenge is bigger than Cloudflare, Google, Microsoft or any single company. The future of the web cannot hinge on who controls the keys. We need protocols, not gatekeepers.</p><p><strong>Authentication, authorization, and monetization must remain open, interoperable, and standardized.</strong></p><p>Cloudflare’s launch is useful only because it exposes the danger. If we let a handful of companies decide which agents are “valid,” the agentic web will collapse into walled gardens. We’ve seen this movie before.</p><p>Here’s the line in the sand: I’m open-sourcing a first cut of these ideas chains of delegation,  request-level authorization , and task-scoped authorization so anyone can implement them, today.</p><p>If this resonates with you, if you want to collaborate, criticize, or help shape the protocols that will keep the web open for agents, please reach out jordi@fewsats.com</p><p><span>The future should not be about who holds the gates. It should be about </span><strong>protocols that let everyone build, share, and innovate</strong><span>.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
    </channel>
</rss>