<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 06 Apr 2025 08:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple's Darwin OS and XNU Kernel Deep Dive (272 pts)]]></title>
            <link>https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/</link>
            <guid>43597778</guid>
            <pubDate>Sat, 05 Apr 2025 23:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/">https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=43597778">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-gjtny2mx="">    <article data-astro-cid-gjtny2mx="">  <p>This post is the result of me going down a several week long XNU rabbit-hole
after reading <a href="https://www.theregister.com/2025/03/08/kernel_sanders_apple_rearranges_xnu/">this post by Thomas Claburn on
Exclaves</a>,
more on that later. I’ve tried my best to condense all the information into a
single blog post. I’ve also tried to keep sections self-contained so you can
skip around using the table of contents, this does come at the cost of
repeating myself in some places, so thanks in advance for your patience. While
I’m confident of my understanding on this topic, some errors are inevitable
when dealing with content this dense, if you spot any errors, assume them to be
mine and please reach out so I can correct it, also let me know your thoughts
by reaching out via email or mastodon. Thanks in advance and let’s begin!</p>
<h2 id="introduction">Introduction</h2>
<p>Apple’s Darwin operating system is the Unix-like core underpinning macOS, iOS,
and all of Apple’s modern OS platforms. At its heart lies the XNU kernel – an
acronym humorously standing for “X is Not Unix.” XNU is a unique <strong>hybrid
kernel</strong> that combines a Mach microkernel core with components of BSD Unix.
This design inherits the rich legacy of Mach (originating from 1980s
microkernel research) and the robust stability and POSIX compliance of BSD. The
result is a kernel architecture that balances modularity and performance by
blending microkernel message-passing techniques with a monolithic Unix kernel
structure. We’ll go through a chronological exploration of Darwin and XNU’s
evolution – from Mach and BSD origins to the modern kernel features in macOS on
Apple Silicon and iOS on iPhones. We’ll follow this with a deep dive into the
architectural milestones, analyze XNU’s internal design (Mach-BSD interaction,
IPC, scheduling, memory management, virtualization), and examine how the kernel
and key user-space components have adapted to new devices and requirements over
time.</p>
<h2 id="darwin-and-xnu-development-history">Darwin and XNU Development History</h2>
<h3 id="mach-microkernel-origins-19851996">Mach Microkernel Origins (1985–1996)</h3>
<p>Darwin’s story begins with <strong>Mach</strong>, a project at Carnegie Mellon University
(1985) led by Richard Rashid and Avie Tevanian. Mach was envisioned as a
next-generation <strong>microkernel</strong> to address the growing complexity of UNIX
kernels. Instead of a single large kernel binary, Mach provided only
fundamental low-level functions – <strong>memory management</strong> (virtual memory,
address spaces), <strong>CPU scheduling</strong> (threads and tasks), and <strong>inter-process
communication</strong> (IPC via message passing). Higher-level services (file systems,
networking, device drivers, etc.) were intended to run as user-space <em>servers</em>
on top of Mach. This separation promised improved reliability (a crashed driver
wouldn’t crash the whole system) and flexibility (multiple OS personalities
could run concurrently). In fact, Mach’s design allowed running several
“personalities” – for example, UNIX and another OS – on one microkernel, a
concept analogous to modern virtualization.</p>
<p>By 1990, Mach had progressed to <strong>Mach 2.5</strong>, which was a microkernel but still
co-located some BSD kernel code in kernel space for performance. The true
microkernel version, <strong>Mach 3.0</strong>, arrived in 1991–1994. Mach’s <strong>virtual
memory (VM) system</strong> was influential beyond the project – it was adopted by
4.4BSD and later FreeBSD as their memory management subsystem. Importantly,
Mach introduced the concept of <strong>tasks</strong> (encapsulating an address space and
resources, roughly equivalent to a process) and <strong>threads</strong> (unit of CPU
execution) as first-class kernel objects. It also implemented an efficient VM
with copy-on-write and memory object abstractions, and a message-based IPC
mechanism using <strong>Mach ports</strong>.</p>
<p>Parallel to Mach’s development, <strong>NeXT Computer</strong> (founded by Steve Jobs in
1985) needed a modern OS for its workstations. NeXT adopted Mach early:
<strong>NeXTSTEP</strong>, released in 1989, was built on a Mach 2.5 kernel with a 4.3BSD
Unix subsystem layered on top. Crucially, NeXTSTEP’s kernel (later named
<strong>XNU</strong>) was not a pure microkernel system with user-space servers; instead, it
took Mach and <strong>integrated the BSD code into the kernel address space</strong> for
speed. In other words, NeXT used Mach’s abstractions (tasks, threads, IPC, VM)
and ran a BSD kernel <em>in kernel mode</em> on top of Mach primitives. This hybrid
approach sacrificed some of Mach’s extreme modularity in favor of performance:
it avoided the heavy context-switching and messaging overhead that plagued
fully microkernel systems of the era. NeXTSTEP’s kernel also included an
object-oriented driver framework called <strong>DriverKit</strong> (written in Objective-C)
to develop device drivers as objects, reflecting NeXT’s preference for
higher-level languages.</p>
<p>By the mid-1990s, Apple’s original Mac OS (classic Mac OS) was aging and lacked
modern OS features like proper multitasking and memory protection. In 1996,
Apple sought an existing OS as its foundation for the future. The company
acquired NeXT in December 1996, choosing NeXTSTEP as the core of the new <strong>Mac
OS X</strong>. With this acquisition, NeXT’s Mach/BSD hybrid kernel came to Apple,
bringing along the engineering leadership of Avie Tevanian (Mach co-author) as
Apple’s VP of Software. Apple named the new OS project <strong>Rhapsody</strong>, which
would later become Mac&nbsp;OS&nbsp;X.</p>
<h3 id="rhapsody-to-mac-os-x-integrating-mach-30-and-bsd-19972005">Rhapsody to Mac OS X: Integrating Mach 3.0 and BSD (1997–2005)</h3>
<p>After acquiring NeXT, Apple set out to merge the NeXTSTEP kernel with
additional features and hardware support needed for Macs. The kernel was
further updated with newer Mach and BSD technology. Notably, Apple incorporated
code from <strong>OSFMK 7.3</strong>, the Open Software Foundation’s Mach 3.0 kernel, into
XNU. This meant the Mach portion of XNU now drew from Mach 3.0’s true
microkernel lineage (including contributions from University of Utah’s Mach 4
research). On the BSD side, the NeXTSTEP kernel’s 4.3BSD subsystem was upgraded
with <strong>4.4BSD and FreeBSD</strong> code. This brought in a more modern BSD
implementation with features like improved networking and a robust filesystems
infrastructure. By combining Mach 3.0 and FreeBSD elements, Apple shaped XNU
into a powerful hybrid: Mach provided the low-level kernel architecture and
abstractions, while BSD provided the <strong>Unix APIs and services</strong> on top.</p>
<p>Apple also replaced NeXT’s old DriverKit with a new driver framework called
<strong>I/O Kit</strong>, written in a subset of C++. I/O Kit introduced a object-oriented
device driver model within the kernel, supporting features like dynamic device
matching and hot-plugging in a robust way. The choice of C++ (minus exceptions
and multiple inheritance, using Embedded C++ subset) for I/O Kit was likely to
improve performance and avoid the runtime overhead of Objective-C in the
kernel. By the late 1990s, XNU was thus composed of three core parts: the Mach
microkernel layer (now OSFMK 7.3 based), the BSD layer (largely
FreeBSD-derived), and the I/O Kit for drivers.</p>
<p>Apple delivered the first developer previews of Mac OS X in 1999, and in 2000
released the open source Darwin 1.0, which exposed the XNU kernel and basic
Unix userland to developers. The commercial debut, <strong>Mac&nbsp;OS&nbsp;X 10.0 (Cheetah)</strong>,
came in early 2001 (Darwin 1.3.1). While the initial releases were rough in
performance, they cemented the architectural paradigm. Key early milestones
included:</p>
<ul>
<li><strong>Mac OS X 10.1 (Puma, 2001)</strong> – Improved performance in threading and added
missing Unix features. Darwin 1.4.1 in 10.1 introduced faster thread
management and real-time threads support.</li>
<li><strong>Mac OS X 10.2 (Jaguar, 2002)</strong> – Darwin 6.0 brought the synchronicity of
the BSD layer with FreeBSD 4.4/5, plus large new features: IPv6 and IPSec
networking, the new <code>mDNSResponder</code> service for discovery
(Bonjour/Rendezvous), and journaling in HFS+ file system. It also upgraded
the toolchain (GCC3) and added modern Unix utilities.</li>
<li><strong>Mac OS X 10.3 (Panther, 2003)</strong> – Darwin 7.0/7.1 integrated <strong>FreeBSD 5</strong>
kernel improvements. This brought <strong>fine-grained kernel locking</strong> (moving
away from the earlier giant-lock model) to better utilize multiprocessors.
Panther’s kernel also introduced <strong>integrated BFS</strong> (basic firewall) and
other performance tuning like improved VM and I/O.</li>
</ul>
<p>Throughout these releases, XNU remained a 32-bit kernel (with limited 64-bit
user process support introduced in 10.4 for specific tasks). Apple maintained
support for PowerPC the Mac CPU architecture of choice in the early days while
also quietly keeping the Intel x86 compatibility (inherited from NeXTSTEP’s x86
support) in the source, preparing for future transitions.</p>
<p>A major architectural change arrived in <strong>Mac&nbsp;OS&nbsp;X 10.4 (Tiger, 2005)</strong>. This
was the first version where Apple declared OS&nbsp;X to be <strong>UNIX&nbsp;03 certified</strong>,
meaning the system conformed to the Single UNIX Specification and could legally
use the UNIX name. Darwin 8 (Tiger’s core) achieved this UNIX certification by
virtue of the robust BSD layer integrated in XNU. Tiger also introduced new
kernel features like <strong>kqueue/kevent</strong> (from FreeBSD, for scalable event
handling), and laid groundwork for Intel Macs by keeping XNU cross-platform.
Apple then announced in 2005 the switch to Intel x86 processors for Macs. XNU’s
Mach foundations made such platform adaptability easier, as Mach abstracted
many low-level hardware details behind a portability layer. In early 2006,
Apple released <strong>Mac&nbsp;OS&nbsp;X 10.4.4 for Intel</strong>, demonstrating XNU running on
x86_32 with much of the code shared with the PowerPC build.</p>
<h3 id="transition-to-64-bit-multi-core-and-iphone-os-20052010">Transition to 64-bit, Multi-Core and iPhone OS (2005–2010)</h3>
<p>By the mid-2000s, computing had shifted to multi-core 64-bit architectures, and
Apple’s OS had to evolve accordingly. <strong>Mac&nbsp;OS&nbsp;X 10.5 Leopard (2007)</strong>, based
on Darwin 9, was a landmark release for XNU. It introduced extensive 64-bit
support: while earlier versions could run 64-bit user applications in limited
form, Leopard’s kernel itself could run in 64-bit mode on appropriate hardware
(x86-64) and support 64-bit drivers. Leopard also dropped official support for
older architectures like PowerPC G3 and brought in stronger security and
performance features: <strong>address space layout randomization (ASLR)</strong> to thwart
exploits, an advanced <strong>sandbox</strong> facility for restricting processes, and the
<strong>DTrace</strong> instrumentation framework from Solaris for low-level tracing.
Notably, Leopard was the last Mac OS X version to fully support PowerPC – Apple
was transitioning its entire lineup to Intel by this time.</p>
<p>In 2007, Apple also debuted the <strong>iPhone</strong> with “iPhone OS” (later named iOS),
which was built on Darwin as well. The first iPhone OS was based on Darwin 9
(same core as Leopard). This demonstrated the versatility of XNU: within the
same kernel version, Apple could target high-end PowerPC and x86 servers,
consumer Intel laptops, and resource-constrained ARM mobile devices. The kernel
gained support for the ARM architecture and tailor-made modifications for
mobile. For example, because early iPhones had very limited RAM and no swap,
the kernel’s memory management had to incorporate aggressive <strong>memory-pressure
handling</strong>. Apple introduced a <strong>Jetsam</strong> mechanism in iPhone OS, which
monitored low-memory conditions and killed background apps to free memory
(since traditional swapping to disk was not feasible on flash storage). iPhone
OS also ran all third-party apps in a <em>sandbox</em> by design and required strict
code signing for binaries – security measures facilitated by XNU’s Mach and BSD
layers (Mach’s task port and codesign enforcement in the kernel, with help from
user-space daemons like <code>amfid</code> for signature validation).</p>
<p><strong>Mac&nbsp;OS&nbsp;X 10.6 Snow Leopard (2009)</strong> marked the maturation of XNU on 64-bit
Intel. Snow Leopard (Darwin 10) discontinued support for PowerPC entirely,
making XNU a dual-architecture kernel (x86_64 and i386 for Intel Macs). It
also was the first to ship with an <em>optional</em> fully 64-bit kernel on capable
Macs (most defaulted to 32-bit kernel with 64-bit userland, except Xserve).
Snow Leopard brought major concurrency advances: the introduction of <strong>Grand
Central Dispatch (libdispatch)</strong> for user-space task parallelization and kernel
support for <strong>dispatch queues</strong>. While <code>libdispatch</code> is a user-space library,
it works closely with the kernel, which provides the underlying thread pools
and scheduling for dispatch queues. Another addition was <strong>OpenCL</strong> for GPU
computing, again requiring tight integration between user frameworks and kernel
drivers. Snow Leopard’s streamlined focus on Intel and multi-core optimizations
made XNU more efficient.</p>
<p>On the mobile side, <strong>iPhone OS 3 (2009)</strong> and <strong>iOS 4 (2010)</strong> (renamed “iOS”
in 2010) evolved alongside, adding support for the Apple A4/A5 ARM chips and
features like multitasking. XNU’s scheduler was adapted in iOS 4 to handle the
concept of background apps with different priority bands (foreground,
background, etc.), and to support <strong>multi-core ARM SoCs</strong> as they appeared
(e.g., the Apple A5 in 2011 was dual-core). iOS and macOS kernels remained
largely unified, with conditional code for platform differences. By <strong>OS&nbsp;X 10.7
Lion (2011)</strong>, XNU dropped support for 32-bit Intel kernels entirely – it
required a 64-bit CPU on Mac, reflecting the industry’s move beyond 32-bit.
Lion (Darwin 11) also improved sandboxing and added full support for new
features like <strong>Automatic Reference Counting (ARC)</strong> in Obj-C (with compiler
and runtime changes reflected in the system).</p>
<h3 id="modern-macos-and-ios-evolution-20112020">Modern macOS and iOS Evolution (2011–2020)</h3>
<p>From 2011 onward, Apple’s OS releases came in a yearly cadence, and Darwin
continued to get incremental but significant enhancements to support new
hardware and features:</p>
<ul>
<li><strong>OS&nbsp;X 10.8 Mountain Lion (2012)</strong> and <strong>10.9 Mavericks (2013)</strong> (Darwin 12
and 13) introduced power- and memory-optimizations in the kernel. Mavericks
added <strong>Compressed Memory</strong>, a kernel feature where inactive pages are
compressed in RAM to avoid swapping to disk. This was in line with iOS
techniques to cope with low RAM, and it benefited Macs by improving
responsiveness under memory pressure. Mavericks also implemented <strong>Timer
Coalescing</strong>, where the kernel aligns wake-ups from idle to reduce CPU power
usage. These changes show how the kernel adapted to energy-efficiency
demands, influenced by mobile design philosophies. Additionally, around this
time, Apple introduced <strong>App Nap</strong> and increased use of Quality-of-Service
(QoS) classes for threads, which required kernel scheduling awareness to
throttle or prioritize threads based on QoS hints (e.g., background vs
user-initiated tasks). XNU’s scheduler evolved to support these multiple
priority bands and energy-efficient scheduling.</li>
<li><strong>OS&nbsp;X 10.10 Yosemite (2014)</strong> and <strong>10.11 El Capitan (2015)</strong> (Darwin 14 and
15) continued the trend. A major security addition in El Capitan was <strong>System
Integrity Protection (SIP)</strong>. SIP (also called “rootless”) is enforced by the
kernel’s security framework, preventing even root user processes from
tampering with critical system files and processes. Implemented via the BSD
layer’s Mandatory Access Control (MAC) framework, SIP hardened the OS by
moving more trust into the kernel and away from user space. For iOS (iOS 9 in
2015), similar “rootless” concepts were applied. Darwin 15 also saw Apple
unifying the code base for OS X and iOS further, as they introduced
<strong>watchOS</strong> and <strong>tvOS</strong> (both also Darwin-based) – XNU had to accommodate
running on tiny Apple Watch hardware (S1 chip) up to powerful Mac Pros, with
scalable scheduling, memory, and I/O capabilities. By now, XNU supported
ARM64 (64-bit ARMv8, first used in iPhone 5s in 2013) and would go on to drop
32-bit ARM support for iOS by <strong>iOS 11 (2017)</strong>.</li>
<li><strong>macOS 10.12 Sierra (2016)</strong>, <strong>10.13 High Sierra (2017)</strong>, <strong>10.14 Mojave
(2018)</strong> (Darwin 16–18) brought filesystem evolution and further security.
High Sierra introduced <strong>APFS (Apple File System)</strong> as the new default
filesystem, replacing HFS+. APFS required kernel support for snapshots,
cloning, and encryption at the container level. XNU’s VFS layer (in the BSD
component) was extended to accommodate APFS’s advanced features and
performance characteristics. During this era, kext (kernel extension)
security was tightened – macOS High Sierra requires user approval for loading
third-party kexts, and macOS Mojave introduced stricter code signing checks
and hardened runtime for user-space processes that also influence how the
kernel validates and allows certain operations. Another adaptation was
graphics and external device support, High Sierra’s eGPU support via
Thunderbolt required hot-plug handling improvements in I/O Kit and scheduling
of external PCIe devices.</li>
<li><strong>macOS 10.15 Catalina (2019)</strong> (Darwin 19) was a significant modernization
step for XNU. Catalina was the first to <strong>deprecate most 32-bit code</strong> (only
64-bit apps, and the kernel had been 64-bit only for years already). More
notably, Apple introduced a new approach for device drivers: <strong>DriverKit</strong>,
reviving the name of NeXT’s old driver framework but with a new design.
DriverKit in modern macOS allows many drivers to run in user space as
<strong>Driver Extensions (dexts)</strong>, outside of the kernel. This is a shift towards
microkernel philosophy for third-party code – by moving drivers (USB,
network, etc.) to user-space processes, Apple improved system stability and
security (a buggy driver can’t crash the kernel if it’s outside it). XNU was
adapted to facilitate this: the kernel provides user-space drivers with
controlled access to hardware (via IPC and shared memory) instead of loading
their code as kexts. At the same time, Catalina split the OS filesystem into
a read-only system volume, reinforcing the kernel’s SIP protections (the
kernel now treats system files as immutable during runtime). These changes
show how even decades after its birth, XNU’s architecture can pivot to
incorporate more user-space responsibilities when beneficial, leveraging the
Mach IPC mechanisms to do so safely.</li>
</ul>
<h3 id="apple-silicon-era-2020present">Apple Silicon Era (2020–Present)</h3>
<p>In 2020, Apple undertook another monumental transition: moving the Mac lineup
from Intel CPUs to Apple’s custom <strong>ARM64 SoCs</strong> (the <strong>Apple Silicon</strong> chips,
starting with M1). Darwin had long supported ARM due to iOS, but running macOS
on ARM64 introduced new challenges and opportunities. <strong>macOS 11 Big Sur
(2020)</strong>, corresponding to Darwin 20, was the first release for Apple Silicon
Macs. XNU was already cross-platform, but it now had to support a heterogeneous
<strong>big.LITTLE CPU architecture</strong>: Apple Silicon chips combine high-performance
cores and energy-efficient cores. The scheduler was enhanced to be
<strong>heterogeneity-aware</strong>, ensuring high-priority and heavy threads run on
performance cores, while background and low-QoS threads can be scheduled on
efficiency cores to save power. Apple likely utilizes the thread <strong>QoS
classes</strong> (which had been introduced in earlier macOS/iOS) to map threads to
appropriate core types – this is an extension of Mach scheduling concepts to a
new domain of asymmetric multiprocessing.</p>
<p>Another aspect of Apple Silicon is the unified memory architecture (shared
memory between CPU/GPU). While largely abstracted by frameworks, the kernel’s
memory manager works with the GPU drivers (which are now Apple’s own,
integrated via I/O Kit) to manage buffer sharing without expensive copies. The
Mach VM abstraction fits well here – memory objects can be shared between
user-space and the GPU with VM remapping rather than duplication. Additionally,
Apple Silicon brought hardware features like <strong>Pointer Authentication (PAC)</strong>
and <strong>Memory Tagging Extension (MTE)</strong> for security. XNU’s ARM64 backend had to
support PAC (which it does by using PAC keys in exception frames and system
pointers to mitigate ROP<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> attacks) and potentially MTE to detect memory
errors – these are deep architecture-specific enhancements in the kernel to
improve security on new hardware.</p>
<p>On the virtualization front, Apple Silicon prompted a reevaluation of
virtualization strategy. On Intel Macs, XNU has long supported virtualization
via the <strong>Hypervisor framework</strong> (introduced in macOS 10.10 Yosemite) which
allows user-space programs to run VMs using hardware VT-x support. With Apple
Silicon, macOS 11 introduced a new <strong>Virtualization framework</strong> built on top of
an in-kernel hypervisor for ARM64 (taking advantage of the ARM VMM features).
Notably, while the <strong>open-source XNU</strong> code does not include the Apple Silicon
hypervisor, the shipped kernel does initialize hypervisor support if running on
the appropriate Apple chip. This allows macOS on M1/M2 to run lightweight
virtual machines (for Linux, macOS guests, etc.) entirely from user-space
controllers, similar to Linux KVM. On iOS devices, Apple has kept the
hypervisor disabled or restricted (no public API), but the hardware capability
appeared with A14 chips. Enthusiasts quickly found that on jailbroken A14
devices, the hypervisor could be enabled to run Linux VMs<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>.</p>
<p>Beyond CPU and virtualization, Apple Silicon Macs run many of the same daemons
and services as iOS, indicating a convergence in system architecture. The XNU
kernel now powers everything from servers (macOS), personal computers, phones,
watches, TVs, and even the <strong>bridgeOS</strong> (a variant of Darwin running on the
Apple T2/M1 auxiliary processors for device management). Darwin’s <strong>flexibility
and scalability</strong> stem from the Mach foundation: it abstracts hardware
specifics in a platform layer, so adding a new CPU architecture (PowerPC → x86
→ ARM64) or scaling down to limited hardware largely requires implementing the
Mach low-level interfaces (like pmap for MMU, thread context switches, etc.)
and leaving higher-level kernel logic untouched. This design has paid dividends
in Apple’s transitions.</p>
<p>In summary, over two decades, XNU has undergone major transformations while
retaining its core identity. <strong>Table 1</strong> highlights a timeline of Darwin/XNU
milestones and architectural changes:</p>































































































<table><thead><tr><th><strong>Year</strong></th><th><strong>Release (Darwin ver.)</strong></th><th><strong>Key Kernel Developments</strong></th></tr></thead><tbody><tr><td><strong>1989</strong></td><td>NeXTSTEP 1.0 (Mach 2.5 + 4.3BSD)</td><td>NeXT’s XNU kernel hybrid introduced: Mach microkernel with BSD in kernel space for performance. Drivers via Obj-C DriverKit.</td></tr><tr><td><strong>1996</strong></td><td>NeXT acquired by Apple</td><td>Rhapsody OS development begins, based on OpenStep. Mach 2.5 + 4.3BSD XNU to be upgraded with Mach 3 and FreeBSD.</td></tr><tr><td><strong>1999</strong></td><td>Mac&nbsp;OS&nbsp;X Server 1.0 (Darwin 0.x)</td><td>First Darwin releases (0.1–0.3) as Apple integrates OSFMK Mach 3.0 (OSF/1) and FreeBSD into XNU.</td></tr><tr><td><strong>2001</strong></td><td>Mac&nbsp;OS&nbsp;X 10.0 (Darwin 1.3)</td><td>Darwin 1.x: Core OS X launched with hybrid kernel, BSD userland, Cocoa APIs. Early performance tuning of Mach/BSD integration.</td></tr><tr><td><strong>2003</strong></td><td>Mac&nbsp;OS&nbsp;X 10.3 (Darwin 7)</td><td>XNU sync with FreeBSD 5, bringing SMP scalability (fine-grained locking).</td></tr><tr><td><strong>2005</strong></td><td>Mac&nbsp;OS&nbsp;X 10.4 (Darwin 8)</td><td>UNIX&nbsp;03 certified kernel. Intel x86 support readied (Mach portability layer leveraged).</td></tr><tr><td><strong>2006</strong></td><td>Mac&nbsp;OS&nbsp;X on Intel (Darwin 8.x)</td><td>Apple transitions Macs to x86. XNU supports <strong>Universal Binary</strong> drivers and Rosetta translation (user-space emulation of PowerPC on x86).</td></tr><tr><td><strong>2007</strong></td><td>Mac&nbsp;OS&nbsp;X 10.5 (Darwin 9)</td><td>64-bit support in kernel (on x86_64); last PowerPC support. Security: NX support, ASLR, code signing, sandbox introduced. <strong>iPhone OS 1</strong> (Darwin 9) released on ARM, with XNU scaled to mobile (no swap, sandbox always on).</td></tr><tr><td><strong>2009</strong></td><td>Mac&nbsp;OS&nbsp;X 10.6 (Darwin 10)</td><td>Intel-only (drops PowerPC). Fully 64-bit kernel on capable Macs; Grand Central Dispatch (kernel task queues); OpenCL support. iPhone OS -&gt; <strong>iOS 3</strong> (Darwin 10) adds improved power management.</td></tr><tr><td><strong>2011</strong></td><td>Mac&nbsp;OS&nbsp;X 10.7 (Darwin 11)</td><td>Drops 32-bit kernel support on Mac; Requires x86_64. Expands sandboxing, FileVault 2 encryption (kernel crypto). <strong>iOS 5</strong> brings dual-core scheduling.</td></tr><tr><td><strong>2013</strong></td><td>OS&nbsp;X 10.9 (Darwin 13)</td><td>Power optimizations: compressed memory, timer coalescing in kernel. Improved multicore scheduling with QoS introduction.</td></tr><tr><td><strong>2015</strong></td><td>OS&nbsp;X 10.11 (Darwin 15)</td><td><strong>System Integrity Protection</strong> (kernel-enforced security). Enhanced AMFI (Apple Mobile File Integrity) for code signing in kernel and user helper (amfid). iOS 9 / watchOS debut (Darwin 15) on new device categories, kernel runs on Apple Watch (ARM Cortex-A7).</td></tr><tr><td><strong>2017</strong></td><td>macOS 10.13 (Darwin 17)</td><td>New APFS filesystem default on Mac (already in iOS 10). Kernel changes for cloning, snapshots. Kext loading requires user approval. iOS 11 drops 32-bit ARM, fully 64-bit kernel.</td></tr><tr><td><strong>2019</strong></td><td>macOS 10.15 (Darwin 19)</td><td>Legacy I/O Kit model shifts: <strong>DriverKit</strong> introduced for user-space drivers. System extensions modularize networking and endpoint security features out of kernel. macOS split system volume (read-only) to strengthen kernel’s protection of OS files.</td></tr><tr><td><strong>2020</strong></td><td><strong>macOS 11.0 (Darwin 20)</strong></td><td><strong>Apple Silicon support</strong> – XNU on ARM64 Mac (M1). Kernel adapts to heterogeneous cores, unified memory. Rosetta 2 translation tier (user-space JIT, with kernel enforcing memory protections for translated code). <strong>iOS 14</strong> – exposes new virtualization features for developers (e.g., running lightweight VMs on iPadOS).</td></tr><tr><td><strong>2022</strong></td><td>macOS 13 (Darwin 22)</td><td>Continued refinement for Apple Silicon (e.g., high-power mode on M1 Max, kernel scheduling tweaks). <strong>iOS 16</strong> – XNU adds support for virtualizing iOS/macOS guests (used in Xcode Simulator and Developer Mode features).</td></tr><tr><td><strong>2024</strong></td><td>macOS 14 (Darwin 23)</td><td>Ongoing improvements (Memory tagging support and fine-tuning for M2/M3 chips). Darwin remains the common core for <strong>visionOS</strong> (Apple Vision Pro AR headset) as well.</td></tr></tbody></table>
<p><strong>Table 1:</strong> Timeline of Darwin/XNU evolution with selected kernel milestones and architectural changes.</p>
<p>This timeline shows how XNU’s Mach/BSD core proved to be a stable foundation
that Apple could incrementally enhance: adding 64-bit support, embracing
multicore, tightening security, and porting to new architectures, all while
retaining backward compatibility. Next, we delve into the internal architecture
of XNU – the hybrid kernel design that made all of this possible.</p>
<h2 id="xnu-kernel-architecture-and-design">XNU Kernel Architecture and Design</h2>
<p><img alt="MacOS-Architecture.png" width="2169" height="2048" loading="lazy" decoding="async" src="https://tansanrao.com/_astro/MacOS-Architecture.B0qOydhL_Z1GQHHd.webp"></p>
<blockquote>
<p>File: Diagram of Mac OS X architecture.svg. (2024, December 29). <em>Wikimedia
Commons</em>. Retrieved 22:59, April 3, 2025 from
<a href="https://commons.wikimedia.org/w/index.php?title=File:Diagram_of_Mac_OS_X_architecture.svg&amp;oldid=976998015">https://commons.wikimedia.org</a>.</p>
</blockquote>
<h3 id="hybrid-kernel-design-mach--bsd-integration">Hybrid Kernel Design: Mach + BSD Integration</h3>
<p>XNU’s kernel design is often described as a <strong>hybrid kernel</strong>, because it
merges characteristics of microkernels (Mach) and monolithic kernels (BSD). In
a traditional microkernel, the kernel provides minimal services (IPC,
scheduling, VM) and everything else runs as user-space servers. In a monolithic
UNIX kernel, all OS services run in kernel mode as one large program. XNU
attempts to get “the best of both”: it uses Mach to modularize and abstract
low-level functions, but co-locates the critical BSD services in kernel space
for efficiency.</p>
<p>In XNU, the Mach component and the BSD component <strong>run as a single kernel
entity</strong> – they are linked into one binary and share the same address space.
There is no Mach vs BSD protection boundary; Mach functions and BSD functions
call each other via normal function calls within the kernel, not via IPC
messages. This co-location avoids the significant context-switch overhead that
a pure Mach system would incur (where a Unix system call would require
messaging a user-space BSD server). As a result, standard UNIX system calls
(file I/O, socket operations, etc.) in XNU perform comparably to other
monolithic Unix kernels, since the BSD code executes directly in kernel mode.
For instance, when a process calls <code>read()</code>, it traps into the kernel and the
BSD file system code is invoked directly; there’s no Mach message to a separate
process as would happen in a Mach 3.0 microkernel with an external BSD server.</p>
<p><strong>Mach’s Role:</strong> Mach in XNU provides the core kernel <strong>infrastructure and
abstractions</strong>. Mach manages CPU <em>threads</em> and task address spaces, implements
low-level scheduling, and handles virtual memory management (memory mapping,
paging). It also provides the fundamental <strong>IPC mechanism</strong> – Mach messages
sent over Mach <em>ports</em> (communication endpoints). In XNU, every process (BSD
process) is backed by a Mach <strong>task</strong> and every thread by a Mach thread. The
Mach layer is responsible for creating and terminating tasks/threads, context
switching threads on the CPU, and implementing primitives like locks, timers,
and scheduling queues. It also implements the VM system: each task has a
virtual address map, memory regions are backed by Mach <strong>memory objects</strong>, and
Mach can perform copy-on-write copy optimizations and map propagation. Notably,
Mach supports <strong>IPC-based memory sharing</strong> – one task can send a memory object
(or a port right to it) to another, enabling efficient shared memory or
transfer of large buffers without copying.</p>
<p><strong>BSD’s Role:</strong> The BSD component sits logically “on top” of Mach and provides
the traditional <strong>OS personality</strong> and services. This includes managing
<strong>processes</strong> (the BSD process table, PID allocation, user IDs, signals, etc.),
<strong>POSIX threads</strong> (which are mapped to Mach threads), and the entire set of
UNIX system calls (file systems, networking, IPC, device I/O, etc.). The BSD
kernel in XNU is derived primarily from FreeBSD (with substantial
OpenBSD/NetBSD influences and custom Apple modifications). It handles things
like:</p>
<ul>
<li><strong>VFS and File Systems:</strong> XNU’s BSD layer implements a VFS (Virtual File
System) and supports many file systems (HFS+, APFS, NFS, etc.). The file
system code runs in the kernel and interacts with storage drivers via I/O
Kit. Mach VM and BSD file systems meet when implementing memory-mapped files
– Mach calls into BSD to fetch pages from files on disk (via the vnode
pager).</li>
<li><strong>Network Stack:</strong> The entire TCP/IP stack (and other protocols like UDP,
ICMP, as well as higher-level sockets API) is in the BSD kernel. This code
came from BSD and is updated with modern standards. It interfaces with
network drivers (in I/O Kit) for packet send/receive.</li>
<li><strong>UNIX IPC:</strong> Besides Mach IPC, XNU provides traditional Unix IPC (signals,
pipes, SysV IPC, POSIX message queues, etc.) through the BSD layer. Signals,
for example, are implemented by the BSD kernel, but interestingly signals are
delivered using Mach exceptions under the hood – Mach exceptions are the
low-level mechanism, and the BSD code translates them to Unix signals for
processes as needed.</li>
<li><strong>Security and Credentials:</strong> The BSD layer manages user IDs, permissions,
access control, and integrates several security frameworks. For instance,
<strong>KAuth</strong> (Kernel Authorization) and the MAC Framework (Mandatory Access
Control) operate in the BSD layer. Features like the Sandbox, SIP, code
signing enforcement involve cooperation between BSD security modules and Mach
task port restrictions. The sandbox (Seatbelt) in macOS/iOS uses the
TrustedBSD MAC framework – when a system call is made, the MAC policy can vet
it. This happens in the BSD layer, though the sandbox’s configuration is set
from user space by launchd or other daemons.</li>
<li><strong>POSIX APIs and Environment:</strong> The BSD layer is what makes Darwin a UNIX. It
provides <code>/dev</code> management (which often links to I/O Kit devices), system
call table for standard C library calls, process forking (<code>fork()</code> is
implemented partly by Mach (VM copy-on-write) and partly by BSD (duplicating
file descriptors, etc.), and execve (loading binaries, setting up Mach task
states and BSD process states).</li>
</ul>
<p>In essence, one can think of Mach as the <strong>core kernel supervisor</strong> in XNU, and
BSD as a high-level kernel server that depends on Mach. The two are tightly
coupled – e.g., when a new BSD process is created via <code>fork()</code>, the kernel
internally calls Mach to create a new task and thread, then BSD code populates
the process structure and file descriptors. The BSD code calls Mach kernel
functions directly (not via message) using an internal API. Conversely, Mach
relies on some BSD services; for example, Mach has an abstraction called
“default pager” for managing swap. In XNU, the default pager is implemented
partly in user space (the <code>dynamic_pager</code> daemon) which uses Mach VM APIs to
create and manage swap files, but the BSD layer is involved in the actual file
I/O to the swap file. This shows a cooperative multi-tier design rather than
strictly separated layers.</p>
<p><strong>I/O Kit:</strong> The third pillar of XNU is the <strong>I/O Kit</strong>, Apple’s
object-oriented driver framework. I/O Kit runs in kernel space (as part of the
XNU kernel), but it is written in a restricted form of C++ for type-safety and
code reuse. The I/O Kit defines a class hierarchy for devices (buses, storage,
network, display, etc.) and drivers subclass these to implement support for
specific hardware. Drivers in I/O Kit live as C++ objects within the kernel,
but they interact with user space through well-defined interfaces. For
instance, an I/O Kit driver can publish properties accessible via the I/O
Registry, and can provide <strong>user client</strong> interfaces that allow user-space
applications or daemons to call into the driver in a controlled way. I/O Kit
also supports limited <strong>user-space drivers</strong> historically (via user clients),
but in practice, until recent DriverKit, most drivers ran in kernel. The Mach
component provides threading and synchronization primitives used by I/O Kit
(like locks and workloops), while the BSD component interacts with I/O Kit for
networking and disk I/O (e.g., the BSD filesystem code calls an I/O Kit disk
driver to read a block). The decision to use C++ in kernel (contrary to the
“not written in C++” myth; the core kernel logic is C, but drivers are C++
classes) was made to improve extensibility. By eliminating multiple inheritance
and exceptions, Apple ensured the kernel would not suffer C++ runtime overhead.
Many drivers can be loaded and unloaded dynamically as <strong>Kexts</strong> (kernel
extensions), which are essentially loadable bundles of I/O Kit C++ classes or
additional BSD/Mach code. XNU’s modularity in this sense is reminiscent of
other OS kernels that allow loadable modules, but Mach’s abstractions also help
here (each kext is essentially a Mach-O image loaded into kernel memory and
linked).</p>
<p><strong>Mach IPC and Message Passing:</strong> Even though XNU does not use Mach messages
for Unix <em>system calls</em>, Mach IPC is still heavily used throughout the system
for what we might call “RPC”-style interactions and for connecting
user-space services to kernel or to each other. Mach ports are the
foundation of various high-level features:</p>
<ul>
<li>Many kernel abstractions are represented as Mach ports to user space. For
example, each task (process) has a Mach port (the task port) that represents
its control handle. The kernel holds the rights, but certain privileged tasks
(like <code>launchd</code> or debugging tools) can obtain send rights to manipulate
other tasks (to start/stop them, inspect memory, etc.).</li>
<li>Mach <strong>notifications</strong> are used for event delivery. The WindowServer
(graphics system) receives user input events from the kernel via Mach
messages. Likewise, higher-level APIs like Grand Central Dispatch under the
hood use Mach ports to sleep threads waiting for events, leveraging Mach’s
port-set and message mechanism. The <code>kqueue/kevent</code> mechanism in BSD is
integrated: an event queue can wait on Mach port messages as well as file
descriptors, unifying the event sources.</li>
<li><strong>Inter-process Communication</strong> for system services: Apple’s entire <strong>XPC</strong>
framework (used by modern macOS/iOS for lightweight IPC between apps and
services) is built on Mach messages. Each XPC connection is essentially a
Mach port behind the scenes. The reason Mach IPC is chosen is its security
model – Mach ports have an associated rights system and live in the kernel,
so the kernel mediates who can send to whom. This allows checks like “is the
sender task entitled to send this message?” which is used in services like
the Keychain (securityd) to validate callers. Mach messages also support
carrying out-of-line memory (shared memory regions) and port rights, which is
extremely powerful for building higher-level RPC: you can send a file
descriptor (which is a BSD concept) as a Mach port right in a message,
enabling UNIX domain socket semantics via Mach. Under the hood, the file
descriptor send uses a Mach port representing that file in the receiving
task’s space.</li>
<li><strong>Remote Procedure Calls:</strong> Mach introduced MIG (Mach Interface Generator),
which is used to define interfaces where one side is in kernel and the other
in user. For example, the bootstrap server (launchd) and various system
servers use MIG to auto-generate code for sending/receiving messages. The
macOS <code>notify</code> system (for system-wide notifications) and many daemon APIs
are implemented with MIG definitions.</li>
</ul>
<p>Therefore, Mach IPC is a backbone for the macOS/iOS architecture beyond the
kernel boundary. It’s how user-space components talk to each other and to the
kernel in many cases. Even certain device drivers use Mach port notifications
(e.g., I/O Kit user clients might deliver an asynchronous event to a client via
a Mach message). The hybrid kernel thus uses Mach messaging where appropriate
(for asynchronous, out-of-band communication), and uses direct function calls
for in-kernel interactions. This hybrid approach retains Mach’s <strong>modularity</strong>
benefits – for instance, one can imagine refactoring a component to run in
user space with Mach messages without changing the other parts, since they
might already use a Mach port interface to talk to it. In fact, Apple did
exactly this with DriverKit: they moved certain drivers to user space and
replaced their in-kernel part with a Mach IPC conduit. The
performance-critical path (e.g., actual packet sending) might still be in
kernel, but higher-level policy or USB logic can be in a user process
communicating via Mach.</p>
<h3 id="scheduler-and-thread-management">Scheduler and Thread Management</h3>
<p>XNU’s scheduling is rooted in Mach’s scheduler, which was originally a
priority-based round-robin scheduler with support for threads and processor
sets. Over time, Apple has modified the scheduler significantly to meet the
needs of desktop and mobile. The scheduler manages threads (Mach threads)
across CPU cores (XNU supports SMP and on Apple Silicon, asymmetric cores). Key
points of XNU scheduling:</p>
<ul>
<li><strong>Priority Levels:</strong> Mach defines a range of thread priorities (0–127,
historically) with certain bands reserved for real-time, kernel, and normal
threads. Apple uses these priorities along with abstractions called
<strong>“sched_pri”</strong> and <strong>“base_pri”</strong> for each thread. Time-sharing threads have
priorities that can float based on usage (to implement favoring I/O-bound
threads), whereas real-time threads have fixed priorities. The highest
priorities are for critical kernel threads or timers.</li>
<li><strong>Run Queues:</strong> In classic Mach, each processor or processor-set had a run
queue for threads. XNU has per-CPU run queues for efficiency. It also has
mechanisms for <strong>scheduler interrupts</strong> to load-balance or preempt when
necessary.</li>
<li><strong>Extended Policies:</strong> Apple added features like <strong>container-level
prioritization</strong>. When iOS introduced App Sandbox with backgrounding, the
scheduler got a concept of a “task role” or “priority group”. In Darwin 9
(Leopard/iPhone OS), an “improved hierarchical process scheduling model” was
noted, which suggests that threads were grouped by tasks or by “workload”,
possibly to enforce limits on background tasks. This is likely the origin of
<strong>boosts and throttles</strong> that iOS uses to ensure the foreground app gets more
CPU than background apps.</li>
<li><strong>Quality of Service (QoS):</strong> In iOS 8 / OS X 10.10 and beyond, Apple
introduced QoS classes (user-interactive, user-initiated, default, utility,
background, etc.) for threads. The kernel scheduler integrates QoS by mapping
them to priority bands and scheduling deadlines. Threads created by Grand
Central Dispatch or NSThreads inherit a QoS that influences their scheduling
priority and which core they run on. This was further refined on Apple
Silicon where the scheduler might steer “background QoS” threads to
efficiency cores. Internally, XNU’s <code>sched_prim.c</code> and <code>sched_perf.c</code> (for
performance controller) handle these decisions. There is also an interface
for the kernel to ask the power management firmware about energy vs
performance (used in macOS’s power management QoS).</li>
<li><strong>Realtime and Multimedia:</strong> macOS supports realtime threads for audio or
critical tasks. The scheduler has a realtime queue and will preempt other
work to run RT threads to meet latency requirements. Also, since Mac OS X
10.4, XNU has <strong>scheduler deadlines</strong> for real-time threads (used for audio
playback, etc.), which is an EDF-like (Earliest deadline first) feature.</li>
<li><strong>Idle and Power:</strong> On mobile devices, the scheduler cooperates with the
power management to aggressively idle cores. Mach scheduler invokes an idle
thread when no work is available, and in iOS, if all cores are idle, the
system can enter low-power states quickly. Timer coalescing (10.9 Mavericks)
means the scheduler tries to batch wakeups – effectively, if several threads
have timers expiring, it aligns them to let CPU sleep longer intervals.</li>
</ul>
<p>Overall, XNU’s scheduler has evolved from Mach’s general-purpose design to one
aware of <strong>multi-core</strong> and <strong>heterogeneous</strong> cores, <strong>energy vs performance</strong>
trade-offs, and <strong>workload groupings</strong> (like apps vs system daemons vs kernel
threads). It still uses Mach’s thread data structures, but many scheduling
algorithms have been tuned by Apple (sometimes influenced by developments in
FreeBSD or other OSes).</p>
<h3 id="memory-management-and-virtual-memory">Memory Management and Virtual Memory</h3>
<p>Memory management in XNU is primarily handled by Mach’s VM subsystem, which is
one of Mach’s strongest components. Key aspects:</p>
<ul>
<li><strong>Virtual Address Space:</strong> Each Mach task has a virtual address space
represented by a set of <strong>VM maps</strong> and <strong>VM regions</strong>. When a process (task)
is created, it starts with a copy of the parent’s address space. Mach’s VM is
inherently copy-on-write – <code>fork()</code> doesn’t duplicate all memory immediately;
instead, both parent and child share pages marked copy-on-write until either
writes, then a fault triggers an actual copy. This makes <code>fork()</code> efficient
despite potentially large processes.</li>
<li><strong>Memory Objects and Pagers:</strong> Mach introduces the concept of <em>memory
objects</em> to represent a backing store for memory (like a file or the swap
area) and <em>pagers</em> which supply data to those memory objects on demand. In
XNU, the <strong>default pager</strong> (for anonymous memory) is implemented by the
<code>dynamic_pager</code> user-space daemon which manages swap files. That is, when the
kernel decides to evict a page from RAM, Mach will send a message to the
default pager indicating the page should be written to swap. The
<code>dynamic_pager</code> then writes to the swap file (via normal file I/O). This is a
classic microkernel design: the <strong>pager runs in user space</strong>, meaning the
policy of how to manage swap space is not fixed in kernel. By adjusting or
replacing dynamic_pager, one could change swapping behavior (e.g., macOS’s
dynamic_pager can create multiple swap files on demand). File memory is
managed by a different pager: the <strong>vnode pager</strong> inside the kernel (this one
is not user-space, but part of XNU’s BSD layer) which interacts with file
system code to read/write file data for memory mapped files. Having this
modular pager design made features like <strong>compressed memory</strong> feasible to
implement – in Mavericks, an in-kernel compression pager was added: when
pressure is high, instead of immediately paging to disk, XNU can compress
inactive pages and keep them in a reserved VM object (the “compressor pool”)
in RAM. The VM considers that as a form of pseudo-swapping (faster than
disk). Only if compression is insufficient does it resort to disk swap via
dynamic_pager.</li>
<li><strong>Physical Memory Management:</strong> XNU abstracts physical memory operations in a
machine-dependent layer called <strong>pmap</strong> (physical map). The pmap manages page
tables or equivalent structures on each architecture. When Mach allocates a
new VM region, it uses pmap to map virtual pages to physical frames. On
ARM64, pmap also integrates with security features (like marking pages with
the appropriate permission keys for PAC, or handling aliasing issues with
caches). The kernel uses a <strong>zone allocator</strong> for many kernel memory
structures (zones are pools for objects of fixed size, like VM map entries,
IPC port structures, etc.). There’s also a general-purpose <strong>kernel malloc</strong>
(kmem) for variable sizes. Notably, the XNU kernel employs strategies to
mitigate fragmentation and has guard pages for certain allocations to detect
overruns (on debug kernels, typically).</li>
<li><strong>Shared Memory and Map Inheritance:</strong> Mach VM allows tasks to share regions
– either explicitly via Mach IPC (sending a port for a memory object) or via
inheritance (a child can inherit memory from parent on fork with
copy-on-write or shared semantics). This is how the dynamic linker works in
macOS: the shared cache of frameworks is mapped into every process at launch
via a shared memory region provided by <code>dyld</code>. Mach makes this efficient by
mapping the same physical pages into all tasks read-only.</li>
<li><strong>Kernel Virtual Memory:</strong> The kernel itself has a virtual address space.
Mach manages kernel memory similarly to user memory, but there are
differences: the kernel uses a single map for all of kernel space, and some
regions are wired (non-pageable). XNU historically had a 32-bit kernel for
which it used tricky schemes like a shared address space with user processes
(in early OS X on 32-bit, kernel and user shared space to avoid costly
segment switches, but on 64-bit this was not an issue). Modern XNU (64-bit)
uses a separate address space for kernel, with portions (like the shared
cache, comm page) mapped into user for communication.</li>
<li><strong>Memory Protection:</strong> Mach’s design enforces that one task cannot access
another task’s memory unless explicitly allowed. This is basic memory
protection via separate address spaces. The only controlled sharing is via
Mach VM APIs or if the kernel (or a privileged daemon) maps memory into
another task (used by things like the debugger or by the system frameworks to
implement features like XPC shared memory). The kernel also zero-fills memory
on allocation to avoid leakage between processes.</li>
<li><strong>Evolution for Apple Silicon:</strong> On Apple Silicon, with large physical memory
and unified memory, XNU’s VM had to consider not having distinct GPU memory.
Instead, I/O Kit drivers for GPU allocate from general memory with certain
attributes (e.g., contiguous, protected). The pmap might have optimizations
for the extremely large virtual address space (ARMv8.5 supports 52-bit VA).
Also, memory tagging (MTE) if used would mean the kernel must manage tag
bits in pointers and memory; Apple hasn’t announced using it, but the
hardware is there on M2. If enabled, the kernel would tag allocations and
check tags on load/store, catching use-after-free or overflow.</li>
</ul>
<p>XNU’s VM is regarded as quite advanced due to its Mach heritage – it was built
for 64-bit from the start (Mach had 64-bit addressing on 32-bit hardware via
abstractions), and it’s relatively decoupled from the rest of kernel logic,
which is why Apple could plug in new features (compressor, different
pagers) without massive overhaul.</p>
<h3 id="virtualization-support">Virtualization Support</h3>
<p>While Mach’s original vision could be seen as a form of virtualization
(multiple OS personalities on one kernel), modern hardware virtualization is a
different beast. XNU did not originally include a hypervisor in early releases,
but as virtualization became important, Apple added support. On <strong>Intel Macs</strong>,
XNU gained the ability to manage the hardware virtualization extensions (Intel
VT-x) around 2014. Apple provided a <strong>Hypervisor.framework</strong> API to developers
from OS&nbsp;X 10.10 onward, enabling user-space virtualization without third-party
kernel extensions. Under the hood, a kernel extension (or part of XNU) would
configure VMX operations, allowing a user-space process to act as a virtual
machine monitor. This was used by tools like <strong>xhyve</strong> (a port of FreeBSD’s
bhyve to macOS), and by virtualization apps when running without their own
drivers.</p>
<p>On <strong>Apple Silicon (ARM64)</strong>, the approach is similar conceptually: XNU on
these devices can act as a Type-2 hypervisor using ARM’s virtualization
extensions (EL2 on ARM). Apple introduced a more full-featured
<strong>Virtualization.framework</strong> in macOS 11, which builds on an in-kernel
hypervisor to let developers run Linux or even macOS VMs in user space. One
design decision on Apple Silicon was to not allow arbitrary third-party
hypervisors in kernel; instead, the hypervisor is part of XNU but only
accessible via Apple’s frameworks with proper entitlements (to maintain
security).</p>
<p>From a kernel perspective, the XNU hypervisor functionality includes: managing
<strong>guest physical memory</strong>, handling <strong>trap and emulate</strong> for sensitive
instructions, and exposing virtual CPU interfaces to user space (for instance,
allowing a user program to set register state and run a vCPU until the next VM
exit). The Mach scheduling is leveraged to schedule vCPUs (which are just
threads from the host’s point of view). The memory subsystem is used to map
guest memory. On Apple Silicon, features like Stage 2 page tables for guests
are managed likely by an in-kernel hypervisor module.</p>
<p>Additionally, XNU supports containers and emulation in various ways (not full
virtualization but worth noting): the <strong>XNU kernel supports multiple user-space
“personalities”</strong> only in a limited sense now (for example, the Rosetta 2
x86_64 code translator on ARM is not a separate OS but it does require the
kernel to manage alternate CPU context for x86 state). The kernel includes an
<strong>x86 emulator</strong> or at least support for handling x86 code segmentation, etc.,
when Rosetta translates x86 code to ARM64 – primarily done in user space by
Rosetta’s JIT, the kernel might assist e.g. with syscall translation or by
providing an x86_64 syscall ABI on ARM.</p>
<p>The design choices around virtualization emphasize security and performance:
Apple’s approach is to keep the hypervisor simple and lean and to strongly
isolate guest OSes from the host (different Mach task, limited communication).
As of iOS 15, Apple even allows <strong>virtualization on iOS</strong> (to run Linux inside
an iPad app, for example, which some developers have demoed), indicating the
XNU hypervisor is capable on mobile as well, though subject to entitlement.</p>
<p>In summary, virtualization in XNU spans from the conceptual Mach
multi-personality support (not widely used in products outside early Classic
environment on OS&nbsp;X which ran Mac OS 9 in a para-virtualized setup), to robust
hardware-assisted virtualization on modern Macs.</p>
<h3 id="secure-computing">Secure Computing</h3>
<p>MacOS uses two complementary but distinct isolation mechanisms—<strong>Secure
Enclaves</strong> and the more recently introduced <strong>exclaves</strong>—to protect sensitive
operations and data.</p>
<p>The <strong>Secure Enclave</strong> is a dedicated, hardened subsystem integrated into
Apple’s SoCs (found in iPhones, iPads, Macs with T2 or Apple Silicon, etc.). It
runs its own microkernel‐based operating system (historically a variant of L4
called sepOS) and is used to manage and protect cryptographic keys, biometric
data, and other sensitive information. Its design isolates critical data even
if the main application processor or kernel is compromised. In short, it’s a
“trusted box” built into the hardware that handles security‑critical tasks
independently.</p>
<p><strong>Exclaves</strong>, by contrast, are a newer security innovation (first appearing in
macOS 14.4 and iOS 17) that further subdivide the operating system’s
privileges. Instead of having all sensitive operations run in the same
privileged domain as the main XNU kernel, Apple is now isolating key resources
into separate, “externally located” domains. These resources—such as Apple ID
services for virtual machines, audio buffers, sensor data, and even components
that manage indicator lights—are pre‑configured at boot and are managed by
specialized kernel extensions (e.g., ExclaveKextClient.kext,
ExclaveSEPManagerProxy.kext, and ExclavesAudioKext.kext) along with private
frameworks.</p>
<p>In geographical terms, an enclave is a territory entirely enclosed within
another, which aptly describes the Secure Enclave’s containment within the SoC.
An exclave, on the other hand, is a fragment that is separated from the main
territory yet still associated with it—mirroring how these isolated resources
exist outside the main XNU kernel while remaining tightly integrated with the
overall system. This separation means that even if the main kernel is
compromised, the operations running in exclaves remain insulated, offering
additional defense in depth.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Darwin and XNU offer a fascinating case study of an operating system that is
<em>neither fully microkernel nor monolithic</em>, but a judicious mix. Its evolution
illustrates trade-offs in OS design: performance vs. modularity, generality vs.
specialization. XNU’s Mach-based core, once considered a performance liability,
has proven to be a strength in adapting to new architectures and enabling
system-wide features (like seamless multi-OS integration on Apple Silicon, or
fine-grained sandboxing). Meanwhile, the BSD layer ensured that developers and
applications have a rich, POSIX-compliant environment, with all the expected
UNIX tools and APIs, greatly smoothing the adoption and software portability
for the platform.</p>
<p>In the modern era, as hardware trends move towards specialized processors and
increased parallelism, XNU continues to incorporate new techniques (e.g.,
dispatch queues, QoS scheduling, and direct support for machine learning
accelerators through drivers) while maintaining robustness. The Darwin OS,
through open source releases, also provides researchers a window into a
commercial-grade hybrid kernel (albeit not a very good window), inspiring
efforts in OS architecture that blend ideas from both camps of the classic
microkernel debate.</p>
<p>Apple’s Darwin has thus grown from a niche NeXTSTEP OS to the core of millions
of devices, all the while <strong>tracing a line of continuity back to Mach and
BSD</strong>. Each major transition – be it new CPU architectures (PowerPC→Intel→ARM),
new device categories, or new security paradigms – has been met by XNU with an
architectural answer: <em>extend</em> (not rewrite) the kernel, <em>integrate</em> components
tightly when needed, and <em>isolate</em> through Mach IPC when possible. This
balanced evolution of Darwin’s kernel showcases a successful long-term OS
design, one that remains at the forefront of commercial operating systems while
rooted in decades of operating systems research.</p>
<p><strong>References:</strong></p>
<ul>
<li>Singh, Amit. <em>Mac OS X Internals: A Systems Approach</em>. Addison-Wesley, 2006
(for historical and architectural insights).</li>
<li>Apple Developer Documentation – Kernel Architecture Overview (<a href="https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/Architecture/Architecture.html">Kernel
Architecture
Overview</a>).</li>
<li>Wikipedia: <em>XNU Kernel</em> (<a href="https://en.wikipedia.org/wiki/XNU">XNU -
Wikipedia</a>), <em>Darwin OS</em> release history
(<a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)">Darwin (operating system) -
Wikipedia</a>).</li>
<li>Chisnall, David. “What Is Mac OS X?” InformIT (2010) (<a href="https://www.informit.com/articles/article.aspx?p=1552774">What Is Mac OS X? | A
Mach-O System |
InformIT</a>).</li>
<li>24C3: <em>Inside the Mac OS X Kernel</em> (Ilja van Sprundel, 2007) (<a href="https://fahrplan.events.ccc.de/congress/2007/Fahrplan/attachments/986_inside_the_mac_osx_kernel.pdf">Inside the Mac
OS X
Kernel</a>).</li>
<li>Mazurek, Karol. “Snake&amp;Apple X.NU” Medium (2024) (<a href="https://karol-mazurek.medium.com/snake-apple-x-nu-0bc5c36170da">Snake&amp;Apple X.NU |
Medium</a>).
(Security-focused kernel internals series).</li>
</ul>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p><a href="https://en.wikipedia.org/wiki/Return-oriented_programming">Return-oriented
programming</a> is
a computer security exploit technique that allows an attacker to execute
code in the presence of security defenses such as executable-space
protection and code signing. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://worthdoingbadly.com/hv/">Hardware-accelerated virtual machines on jailbroken iPhone 12 / iOS 14.1
| Worth Doing Badly</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section>   </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ADHD Body Double: A Unique Tool for Getting Things Done (156 pts)]]></title>
            <link>https://add.org/the-body-double/</link>
            <guid>43597425</guid>
            <pubDate>Sat, 05 Apr 2025 22:45:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://add.org/the-body-double/">https://add.org/the-body-double/</a>, See on <a href="https://news.ycombinator.com/item?id=43597425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>Can something as simple as another person’s presence make it easier to stay on task?</p>



<p>While there’s no research to prove its effectiveness, ADHD body doubling is helping many people get things done – starting with my client, David.</p>



<p>When I first met David, he was a retired vice president of a major corporation. In his “retirement,” he ran three businesses out of his home office, two of them overseas.</p>



<p>Observing David in his workspace, I found him to be quite organized. He wasn’t sitting eyeball-high in papers. In fact, he hardly had any papers around him at all.</p>



<p>He had working systems in place, but felt terribly disorganized and distracted.</p>



<p>David contacted me because I specialize in coaching <a href="https://add.org/adhd-in-adults/">adults with Attention Deficit Hyperactivity Disorder (ADHD)</a>. During my twenty-three years of coaching, I have gathered many tools and strategies for helping clients accomplish desired change and create order out of chaos.</p>



<p>The tool I want to share with you today is one born of the unique mix of client and coach inventing together. I call it <em>the body double.</em></p>



<p><em><strong>Originally published in 1996, this article was republished on February 20th, 2025.</strong></em></p>



<figure><img decoding="async" width="1920" height="1280" src="https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online.jpg" alt="A man reading an article online" srcset="https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online.jpg 1920w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-300x200.jpg 300w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-1024x683.jpg 1024w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-768x512.jpg 768w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-800x533.jpg 800w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-1536x1024.jpg 1536w, https://add.org/wp-content/uploads/2025/02/A-man-reading-an-article-online-600x400.jpg 600w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>



<h2><strong>What Is ADHD Body Doubling?</strong></h2>



<p>The methodology of ADHD body doubling is a productivity strategy used by individuals with ADHD to finish possibly annoying jobs while having another person beside them. This person is the body double. The body double’s duty is to keep the individual with ADHD focused on the task at hand to reduce potential distractions and increase motivation.</p>



<p>David had been surprised by a recent diagnosis of ADD, which explained his lifelong difficulty accomplishing mundane tasks that others seemed to handle with ease.</p>



<p>As a VP in the corporate world, he had always had an executive assistant to connect the dots and pull loose ends together. Now, however, he had the time to do these tasks. He even had the will to do them. He just couldn’t stay on track.</p>



<p>David’s wife also ran a business out of their home and had her own well-organized office. She offered to advise him, but they both quickly agreed this just didn’t work.</p>



<p>That’s when they asked for help.</p>



<p>First, I helped David modify his storage systems. Then, together, we honed his time management and prioritization systems.</p>



<p>Nothing, however, seemed to address the problem of his inattention and distraction. There were days, too many days, when he easily got off track or found it hard to transition from one task to another.</p>



<p>Frustrated, puzzled, and somewhat embarrassed, he confessed, “You know, it seems that, sometimes, if I just have my wife sitting in a chair nearby, I can accomplish more than if I’m alone.”</p>



<p>Though reluctantly, David had identified a strategy that really worked for him. I instantly realized that I had seen this same effect before with other clients.</p>



<p>There were times when just having someone in proximity (not advising, sorting, or strategizing) brought clarity and focus. I felt it. I knew my clients felt it, too.</p>



<p>This phenomenon of <em>just being there</em>, which David first described out loud, I named the body double.</p>



<figure><img decoding="async" width="1280" height="853" src="https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double.jpg" alt="Working productively with a body double" srcset="https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double.jpg 1280w, https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double-300x200.jpg 300w, https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double-1024x682.jpg 1024w, https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double-768x512.jpg 768w, https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double-800x533.jpg 800w, https://add.org/wp-content/uploads/2024/04/Working-productively-with-a-body-double-600x400.jpg 600w" sizes="(max-width: 1280px) 100vw, 1280px"></figure>



<h2><strong>How Does Body Doubling Work?</strong></h2>



<p>For many people with ADHD, finding the motivation to get the ball rolling can be quite a challenge. This can lead to procrastination. <a href="https://www.tandfonline.com/doi/full/10.1080/00050067.2023.2218540#abstract" target="_blank" rel="noreferrer noopener"><sup>[1]</sup></a> They may also find themselves easily distracted by unrelated thoughts or activities<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10421702/" target="_blank" rel="noreferrer noopener"><sup>[2]</sup></a></p>



<p>This is where body doubling comes into play!&nbsp;</p>



<p>To start body doubling, all you need is a family member, colleague, or peer. It can be done physically or virtually, as long as someone is present while you work. You and your body double will agree on a set time and block the session out on your calendar.&nbsp;</p>



<p>The aim of a body doubling session is for you and your body double to work alongside each other. You don’t have to do the same thing. What’s most important is that both of you are working on <em>something</em>. That could be doing the laundry, paying bills, exercising, or completing a work project.&nbsp;</p>



<p>It also helps to share your goals with your body double at the start of the session. This allows them to hold you accountable for what you need or want to achieve.&nbsp;</p>



<p>Body doubling is effective because it helps create a strong sense of accountability. That extra bit of pressure from being watched can go a long way toward holding you responsible. That way, you’re more likely to follow through on your actions.&nbsp;</p>



<p>Body doubling can also help to mix things up. It adds freshness to a boring routine. This can be helpful since the ADHD brain craves novelty.<a href="https://link.springer.com/article/10.1007/s40806-024-00400-8" target="_blank" rel="noreferrer noopener"><sup>[3]</sup></a></p>



<h2><strong>Why Does Body Doubling Work?</strong></h2>



<p>There are a few possible explanations as to why a body double works as a strategy for getting through challenging or boring tasks. In the moment, it can counter <a href="https://add.org/signs-of-adhd/">ADHD symptoms</a> that sap motivation, focus, and energy.</p>



<h3><strong>A Supportive Presence Adds Motivation</strong></h3>



<p>The simplest is that the body double serves as a physical anchor for the distracted individual who feels more focused by the presence of another person in their space.</p>



<p>The distracted person feels responsible to and for the body double.</p>



<p>This perception translates as­–<em>I can’t waste this gift of time.</em></p>



<p>Another explanation might be that the body double serves as a kind of <em>mirror – </em>a calm reflection for the individual with ADHD of how their <a href="https://add.org/sensory-overload-adhd/">over-stimulated mind and body</a> would like to be at the moment.</p>



<p>This concept is called ADHD mirroring. It happens when someone with ADHD follows the behaviors of other people, often unconsciously, to fit in. In many cases, ADHD mirroring can be draining, as it takes energy to mask symptoms of ADHD by copying others.&nbsp;</p>



<p>However, in the case of body doubling, the unconscious act of mirroring can be beneficial. Watching someone else stay focused on a task can naturally encourage the person with ADHD to do the same.&nbsp;</p>



<figure><img loading="lazy" decoding="async" width="1920" height="1280" src="https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique.jpg" alt="People with ADHD practicing the body double technique" srcset="https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique.jpg 1920w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-300x200.jpg 300w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-1024x683.jpg 1024w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-768x512.jpg 768w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-800x533.jpg 800w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-1536x1024.jpg 1536w, https://add.org/wp-content/uploads/2024/04/People-with-ADHD-practicing-the-body-double-technique-600x400.jpg 600w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>



<h3><strong>It Provides a Model of Calm Focus</strong></h3>



<p>The body double becomes a model of control and a mirror, confidently reflecting the message: <em>I can concentrate. I am working. I am focused</em>.</p>



<p>This theory might actually carry some weight. In the 1980s, neuroscientist Giacomo Rizzolatti, MD, along with colleagues at the University of Parma, made a serendipitous discovery while researching macaque monkeys. They observed that specific neurons in the macaque’s brain fired when watching another monkey, or a human, reach for a peanut. They named these neurons “mirror neurons.”<a href="http://blogs.scientificamerican.com/guest-blog/whats-so-special-about-mirror-neurons/" target="_blank" rel="noreferrer noopener"><sup>[4]</sup></a></p>



<p>The researchers theorized that mirror neurons also existed in humans and were the likely explanation for our ability to emulate and empathize with others.</p>



<p>As much as this makes sense and sounds like the perfect validation for the body double effect, please note that the scientific community is somewhat divided about whether humans actually have mirror neurons.</p>



<p>So, the mirror neuron theory does not give us a definitive answer.</p>



<h3><strong>Adds Positive Energy to the Workspace</strong></h3>



<p>I have one more explanation to offer as to why the body double might work.</p>



<p>In Eastern cultures, energy is referred to as chi (or qi). It is viewed as being either in or out of balance in the human body and the surrounding environment.</p>



<p>Acupuncturists move chi, or energy, to recreate balance and promote health. There are many forms of exercise and meditation, tai chi and chi gong, to name a few, which are about the management and flow of energy.</p>



<p>Feng shui (fung shway) is the 5,000-year-old art of balancing positive and negative chi in the space around us, with the goal of optimizing healthy energy in one’s living and working space.</p>



<p>What would chi have to do with a body double? The body double might be a chi balancer or protective barrier helping to contain and calm the energy in and around the person with ADHD. The body double might also be a buffer against distracting energy from the outside, ready to bombard the vulnerable <a href="https://add.org/adhd-brain/">ADHD brain</a>.</p>



<p>Whichever explanation you prefer, there’s no denying the effectiveness of the body double.</p>



<p>Consider this strategy a gift from David and the many other ADHDers who have experienced its magic. If a task requires your attention and seems impossible to complete alone – beg, borrow, or pay for a body double to sit in the chair next to you.</p>



<figure><img loading="lazy" decoding="async" width="1280" height="853" src="https://add.org/wp-content/uploads/2024/04/Colleagues-working-together.jpg" alt="Colleagues working together" srcset="https://add.org/wp-content/uploads/2024/04/Colleagues-working-together.jpg 1280w, https://add.org/wp-content/uploads/2024/04/Colleagues-working-together-300x200.jpg 300w, https://add.org/wp-content/uploads/2024/04/Colleagues-working-together-1024x682.jpg 1024w, https://add.org/wp-content/uploads/2024/04/Colleagues-working-together-768x512.jpg 768w, https://add.org/wp-content/uploads/2024/04/Colleagues-working-together-800x533.jpg 800w, https://add.org/wp-content/uploads/2024/04/Colleagues-working-together-600x400.jpg 600w" sizes="(max-width: 1280px) 100vw, 1280px"></figure>



<h2><strong>Benefits of Body Doubling</strong></h2>



<p>Body doubling can be a powerful tool, especially if you struggle with focus and motivation.&nbsp;</p>



<p>If you’re not already convinced to give it a try, here are the possible benefits of body doubling:&nbsp;</p>



<ul>
<li><strong>Improved focus:</strong> Having a body double helps you stay accountable. This technique creates positive reinforcement by gently nudging you to focus and stay on track.&nbsp;</li>



<li><strong>Increased motivation:</strong> The presence of someone else can create a sense of accountability and novelty, increasing your motivation to get the ball rolling.&nbsp;</li>



<li><strong>Reduced procrastination:</strong> By planning and setting aside time to work alongside someone else, you’re more likely to get started when the time comes. This helps you avoid postponing and delaying your tasks.&nbsp;</li>



<li><strong>Improved time management:</strong> You can dedicate a specific time block in your day to body doubling sessions. This reduces wasted time due to delays and can save time by minimizing distractions.&nbsp;</li>



<li><strong>Improved mood:</strong> Having someone around you when you work can create a positive atmosphere and reduce stress. Your body double can also serve as a source of support, cheering you on as you reach your session goals.&nbsp;</li>



<li><strong>Boosted productivity:</strong> When focused and motivated, you’re bound to get more done in less time.&nbsp;</li>
</ul>



<p>Of course, if you want to reap these benefits and get the best results, it’s essential to find a suitable body double. The right body double won’t distract you or create <em>too much</em> pressure. Instead, their presence should help you feel encouraged, empowered, and ready to tackle your to-do list!&nbsp;</p>



<h2><strong>What to Look for in a Body Double</strong></h2>



<p>Who and what should you look for in a body double?</p>



<p>Find someone who can be quiet and independent. They can sit, read, knit, or work quietly on a laptop. Their job is to not engage with you.</p>



<p>It requires energy to instruct, supervise, or be interrupted by another person, and that expenditure of energy equates to distraction.</p>



<p>This is not to say that you do not need to hire outside help – a professional organizer or office assistant.</p>



<p>You may also consider finding an <a href="https://add.org/how-to-find-an-adhd-coach/">ADHD coach</a> to help you identify the best strategies for you.</p>



<p>I encouraged David to hire a student, retiree, or fellow church member to sit and keep him company. His wife may not be the best person for the job, but he could use her in a pinch.</p>



<p>Following our discovery, David occasionally hired short-term office support help, who sometimes served as a body double and other times as office assistants. Knowing when to hire someone to help with office work or with just paying the bills is a valuable skill in getting things done.</p>



<p>There are also many different ways to try this technique. Some people prefer body doubling for longer periods, while others find shorter sessions with small breaks in between more effective.</p>



<p>You can also choose between in-person groups, online sessions with your camera and microphone on, or virtual focus groups with a chat-only feature.</p>



<p>Additionally, try to experiment with different times of the day. Some ADHDers find that body doubling boosts their productivity in the morning but doesn’t work as well in the evening, or vice versa.</p>



<p>Ultimately, not all body-doubling techniques work for everyone. To find what works best for you, you can test it with different people, groups, timings, and structures.</p>



<p>Regardless of the approach, body doubling can be an effective accountability tool for hitting your daily goals.</p>



<figure><img loading="lazy" decoding="async" width="1920" height="1280" src="https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work.jpg" alt="Colleagues focused on their work" srcset="https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work.jpg 1920w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-300x200.jpg 300w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-1024x683.jpg 1024w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-768x512.jpg 768w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-800x533.jpg 800w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-1536x1024.jpg 1536w, https://add.org/wp-content/uploads/2025/02/Colleagues-focused-on-their-work-600x400.jpg 600w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>



<h2><strong>Where to Find a Body Double?</strong></h2>



<p>One of the best places to find a suitable body double is in your own community. You can get a friend or family member to work alongside you physically or virtually.</p>



<p>Alternatively, you can consider hiring someone to spend time sitting beside you as you get things done.</p>



<p>Virtual body doubling can also work wonders. You can work with a group or partner from anywhere in the world at any time. For this, you’d typically be matched through an online platform.</p>



<p>Various websites and apps can connect you to a body double from their own community. For instance, FocusMate allows you to connect with a virtual body double from anywhere in the world to co-work and get things done.</p>



<p>Another example is the <a href="https://add.org/adda-virtual-peer-support-group-studyhall-pomodoro-style/">ADDA Productivity PowerHour+ support group</a>, which combines body doubling with another time management strategy called the Pomodoro technique. You’d participate in these sessions with a group of ADDA members.</p>



<h2><strong>Using Body Doubling for ADHD</strong></h2>



<p>In lieu of any proven scientific explanation, the body double is a chair holder, space taker-upper, karmic anchor, or a wedge between you and the door.</p>



<p>Hopefully, it might be a helpful tool in your magic bag of tricks to use at just the right time to get a job done and stay on track.</p>



<h2><strong>Using External Accountability to Boost Your Productivity</strong></h2>



<p>Because of how the ADHD brain is wired, being productive can be easier said than done. The good news is that you don’t have to rely on willpower alone!&nbsp;</p>



<p>External accountability is one of many practical tools for boosting productivity. Body doubling enables you to find this external accountability in an easy and structured way.&nbsp;</p>



<p>If you’d like to learn more about adult ADHD, <a href="https://add.org/adda-plus/">ADDA+</a> offers 200+ webinars, peer support groups, work groups, and much more.</p>



<p>Linda Anderson, MA, MCC, SCAC, is a master certified coach, a leader in the field of ADHD coaching, and the founder of <a href="https://gettingclear.com/">Getting Clear</a>.</p>



<h2><strong>References</strong></h2>



<p>[1] Ruth Netzer Turgeman, &amp; Pollak, Y. (2023). Using the temporal motivation theory to explain the relation between ADHD and procrastination. Using the Temporal Motivation Theory to Explain the Relation between ADHD and Procrastination, 58(6), 1–9. <a href="https://doi.org/10.1080/00050067.2023.2218540" target="_blank" rel="noreferrer noopener">https://doi.org/10.1080/00050067.2023.2218540</a></p>



<p>‌[2] Osborne, J. B., Zhang, H., Carlson, M., Shah, P., &amp; Jonides, J. (2023). The association between different sources of distraction and symptoms of attention deficit hyperactivity disorder. Frontiers in psychiatry, 14, 1173989. <a href="https://doi.org/10.3389/fpsyt.2023.1173989" target="_blank" rel="noreferrer noopener">https://doi.org/10.3389/fpsyt.2023.1173989</a></p>



<p>[3] Anne-Laure Le Cunff. (2024). Distractibility and Impulsivity in ADHD as an Evolutionary Mismatch of High Trait Curiosity. Evolutionary Psychological Science. <a href="https://doi.org/10.1007/s40806-024-00400-8" target="_blank" rel="noreferrer noopener">https://doi.org/10.1007/s40806-024-00400-8</a></p>



<p>[4] Thomas, B. (November 6, 2012) What’s So Special about Mirror Neurons? Scientific American. Retrieved May 1, 2016, from <a href="http://blogs.scientificamerican.com/guest-blog/whats-so-special-about-mirror-neurons/" target="_blank" rel="noreferrer noopener">http://blogs.scientificamerican.com/guest-blog/whats-so-special-about-mirror-neurons/</a></p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ten Rules for Negotiating a Job Offer (339 pts)]]></title>
            <link>https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</link>
            <guid>43596864</guid>
            <pubDate>Sat, 05 Apr 2025 21:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/">https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</a>, See on <a href="https://news.ycombinator.com/item?id=43596864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>When <a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">the story of how I landed a job at Airbnb</a> went viral, I was surprised at how infatuated people were with my negotiations. Media stories portrayed me as some kind of master negotiator—a wily ex-poker-player who was able to con the tech giants into a lucrative job offer.</p>

<p>This is silly. It’s silly for a lot of reasons, but one of the main ones is that in reality, my negotiation skills are nothing special. There are lots of job candidates who are better negotiators than I, to speak nothing of recruiters and other professional negotiators.</p>

<p>It just so happens that most people don’t negotiate at all, or if they do, they just negotiate just enough to satisfy themselves that they did.</p>

<p>Worse yet, most of the advice out there on negotiation is borderline useless. Almost anything you read on the subject will be a vague and long-winded exhortation to “make sure you negotiate” and “never say the first number.” Beyond those two morsels of advice, you’re pretty much on your own.</p>

<p>I thought to myself: why is there so little actionable advice out there about negotiation? I suspect it’s because deep down, many people believe that negotiation is inexplicable, that it’s something some people can do and others can’t, and that there’s no real way to break it down so anyone can learn it.</p>

<p>I say that’s bullshit. Negotiation is a skill that can be learned just like any other, and I don’t believe it’s particularly elusive or hard to understand. So I’m going to try to explain how anyone can do it.</p>

<p>Three caveats.</p>

<p>First: I’m not an expert. There are people who really are experts at this, and when my advice contradicts theirs, you should assume I’m wrong.</p>

<p>Second: negotiation is tricky to generalize about because it’s deeply intertwined with social dynamics and power. The appropriate advice for an Asian male in Silicon Valley may not be appropriate for a black woman in Birmingham, Alabama. Racial, sexual, and political dynamics accompany you to the negotiating table.</p>

<p>At the same time, I want to caution against overemphasizing these factors. Being afraid to negotiate out of fear of discrimination can often be just as deleterious as discrimination itself.</p>

<p>Ceteris paribus, negotiate aggressively.</p>

<p>Third: I’m the first to admit that negotiation is stupid. It’s a practice that inherently benefits those who are good at it, and is an absurd axis on which to reward people. But it’s a reality of our economic system. And like most collective action problems, we’re probably not going to be able to abolish it any time soon. In which case, you might as well improve at it.</p>

<p>So here’s my guide to negotiation. It’s going to be split into two parts: this first part will be about conceptualizing the negotiating process, about how to begin the process and set yourself up for maximal success. The second part will be advice on the actual back-and-forth portion of negotiating and how to ask for what you want.</p>

<p>Let’s take it from the top.</p>

<h2 id="what-it-means-to-get-a-job">What it means to “get a job”</h2>

<p>In our culture we call entering the employment market “trying to get a job.” This is an unfortunate turn of phrase. “Getting a job” implies that jobs are a resource out in the world, and you’re attempting to secure one of these resources. But that’s completely backwards. What you are actually doing is selling your labor, and a company is bidding for it.</p>

<p><strong>Employment is just striking a mutual deal in the labor market.</strong></p>

<p>Like any market, the labor market only functions well if it’s competitive. This is the only way to ensure fair and equitable pricing. Imagine you were a farmer selling watermelons. Would you just sell your watermelons to the first buyer who agreed to purchase them? Or would you survey the marketplace of buyers, see the best price (and business partner) you could get, and then make an informed decision on which buyer to sell to?</p>

<p>And yet, when people talk about the labor market, they think “oh, a company wants to <em>give me a job</em>! What a relief!” As though having a job were in itself some special privilege for which a company is the gatekeeper.</p>

<p>Dispel yourself of this mindset.</p>

<p>A job is just a deal. It is a deal between you and a company to exchange labor for money (and other things you value).</p>

<p>This might sound like an abstract point, but you should absolutely approach negotiation from this perspective.</p>

<h2 id="the-role-of-negotiation">The role of negotiation</h2>

<p>Negotiating is a natural and expected part of the process of trying to make a deal. It’s also a signal of competence and seriousness. Companies generally respect candidates who negotiate, and most highly attractive candidates negotiate (if for no other reason, because they often have too many options to choose from).</p>

<p>At the risk of spouting truisms: always, always negotiate. Doesn’t matter how good or bad you think you are. You never damage a relationship by negotiating.</p>

<p>In all my time as an instructor at App Academy, out of hundreds of offers negotiated, only once or twice were offers ever rescinded in negotiations. It basically never happens. And when it does, usually the candidate was being an unconscionable asshole, or the company was imploding and needed an excuse to rescind the offer.</p>

<p>You might think to yourself: “<em>well, I don’t want to set high expectations, and the offer is already generous, so I ought to just take it.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>Or maybe: “<em>I don’t want to start off on the wrong foot and look greedy with my future employer.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>“<em>But this company is small and—</em>“</p>

<p><strong>No. Shut up. Negotiate.</strong></p>

<p>We’ll talk more in the next section about why a lot of these objections are bullshit, and fundamentally misapprehend the dynamics of hiring. But for now, just trust me that you should always negotiate.</p>



<p>I’ve tried to boil down negotiation to ten rules. The rules, in order of appearance, are:</p>

<ol>
  <li>Get everything in writing</li>
  <li>Always keep the door open</li>
  <li>Information is power</li>
  <li>Always be positive</li>
  <li>Don’t be the decision maker</li>
  <li>Have alternatives</li>
  <li>Proclaim reasons for everything</li>
  <li>Be motivated by more than just money</li>
  <li>Understand what they value</li>
  <li>Be winnable</li>
</ol>

<p>We’ll only get through some of these in this blog post, and the rest will appear in the second part. But I’ll explain each rule as we get to it.</p>

<p>So let’s start from the top and try to walk through a negotiation process from the very beginning. For most, that starts when you receive an offer.</p>

<h2 id="the-offer-conversation">The offer conversation</h2>

<p>You’ve just received the phone call: your interview went well, and after much deliberation they decided they like you. They want to make you an offer. Congratulations!</p>

<p>Don’t get too excited though. The fun is just getting started.</p>

<p>Thank your recruiter. Sound excited—hopefully this won’t be hard. Before jumping into details, try to ask for specific feedback on your interview performance. If they give it to you, this will help you gauge how much they want you, as well as tell you things you can improve on in your next interview(s).</p>

<p>Now time to explore the offer.</p>

<p><strong>Rule #1 of negotiating: have everything in writing.</strong></p>

<p>Eventually, they’ll give you information about the offer. Write it all down. Doesn’t matter if they’re going to send you a written version later, <strong>write everything down</strong>. Even if there are things that are not directly monetary, if they relate to the job, write them down. If they tell you “we’re working on porting the front-end to Angular,” write that down. If they say they have 20 employees, write that down. You want as much information as you can. You’ll forget a lot of this stuff, and it’s going to be important in informing your final decision.</p>

<p>Depending on the company, they’ll also tell you about the equity package. We’ll look more specifically at equity in part II, but be sure to write everything down.</p>

<p>The rule from here on out is that everything significant you discuss will have some kind of a paper trail. Often, the company won’t even send you an official offer letter until a deal is finalized. So it falls to you to confirm all of the important details in subsequent e-mails.</p>

<p>So yadda yadda, lots of details, writing stuff down, oh there’s a joke, time to laugh. Now the recruiter is done talking and you’re done asking all of your questions.</p>

<p>Your recruiter will now say something along the lines of “<em>so what do you think?</em>“</p>

<p>This seems innocuous, but your reply here is critical, because there’s a lot you can say to weaken your position. This is your first decision point.</p>

<p>A decision point is a moment in the negotiation where your interlocutor wants to compel you to make a decision. If they succeed in tying you to a position, they will close the door on further negotiating. Of course “what do you think?” is a subtle prod. But it is the beginning of many attempts to get you to make a premature commitment.</p>

<p><strong>This leads to rule #2 of negotiating: always keep the door open.</strong> Never give up your negotiating power until you’re absolutely ready to make an informed, deliberate final decision.</p>

<p>This means your job is to traverse as many of these decision points as possible without giving up the power to continue negotiating. Very frequently, your interlocutor will try to trick you into making a decision, or tie you to a decision you didn’t commit to. You must keep verbally jiu-jitsu-ing out of these antics until you’re actually ready to make your final decision.</p>

<h2 id="protecting-information">Protecting information</h2>

<p>There’s an uncomfortable silence by now, and their “<em>what do you think?</em>” is hanging in the air.</p>

<p>If you say “<em>yes, that sounds amazing, when do I start?</em>” you implicitly accept the offer and completely close the door on the negotiation. This is your recruiter’s number one favorite thing to hear. It stands to reason you probably shouldn’t do this.</p>

<p>But their second favorite thing to hear you say is “<em>can you do 90K instead of 85K?</em>” This also closes the door, but for a different and more subtle reason. And it’s the number one reason why most people suck at negotiation.</p>

<p><strong>Rule #3 of negotiating: information is power.</strong> To protect your power in the negotiation, you must protect information as much as possible.</p>

<p>A company doesn’t give you insight into what it’s thinking. It doesn’t tell you its price range, how much it paid the previous candidate with your experience, or anything like that. It intentionally obfuscates those things. But it wants you not to do the same.</p>

<p>A company wants to be like a bidder in a secret auction. But unlike the other bidders, it wants to know exactly how high all of the other bids are. It then openly intends to exploit that knowledge, often by bidding one cent more than the second highest bid.</p>

<p>Yeah, no. Screw that. It’s a silent auction, and to keep it that way, you must protect information.</p>

<p>In many situations, the only reason why you have any negotiating power at all is because the employer doesn’t actually know what you’re thinking. They might not know how good your other offers are, or how much you were making in your last job, or how you weigh salary vs equity, or even how rational you are as a decision-maker. Bottom line, you want them to be uncertain on exactly what it would take to sign you.</p>

<p>When you say “<em>can you do 90K instead of 85K,</em>” you’ve told them exactly what it will take to make you sign. The sheet’s pulled back, the secret auction is up, and they’re going to bid 90K (or more likely, 87K). And they know there’s almost no risk in doing so, because you’ll probably accept.</p>

<p>What if you were the kind of person who wouldn’t even consider an offer below 110K? Or the kind of person who wouldn’t consider an offer below 120K? If you were, you wouldn’t ask for 90K, and if they offered it as conciliation, you’d tell them to stop wasting your time.</p>

<p>By staying silent, <em>they don’t actually know which of those kinds of people you are.</em> In their mind, you could be any of the three.</p>

<p>A corollary of this rule is that you should not reveal to companies what you’re currently making. There are some exceptions, but as a rule you should assume this. If you must divulge what you’re making, you should be liberal in noting the total value of your package (incorporate bonuses, unvested stock, nearness to promotion etc.), and always mention it in a context like “<em>[XYZ] is what I’m currently making, and I’m definitely looking for a step up in my career for my next role.</em>“</p>

<p>Companies will ask about your current compensation at different stages in the process—some before they ever interview you, some after they decide to make you an offer. But be mindful of this, and protect information.</p>

<p>So given this offer, don’t ask for more money or equity or anything of the sort. Don’t comment on any specific details of the offer except to clarify them.</p>

<p>Give away nothing. Retain your power.</p>

<p>Say instead: “<em>Yeah, [COMPANY_NAME] sounds great! I really thought this was a good fit, and I’m glad that you guys agree. Right now I’m talking with a few other companies so I can’t speak to the specific details of the offer until I’m done with the process and get closer to making a decision. But I’m sure we’ll be able to find a package that we’re both happy with, because I really would love to be a part of the team.</em>“</p>

<p>Think like the watermelon farmer. This offer is just is the first businessman who’s stopped by your watermelon patch, glanced over your crops, and announced “I’ll take all of these right now for $2 a melon.”</p>

<p>Cool. It’s a big market, and you’re patient—you’re a farmer after all. Just smile and tell them you’ll keep their offer in mind.</p>

<p>And this is super important: always be unequivocally positive.</p>

<h2 id="the-importance-of-positivity">The importance of positivity</h2>

<p><strong>Staying positive is rule #4 of negotiation</strong>. Even if the offer is shit, it’s extremely important to remain positive and excited about the company. This is because <em>your excitement is one of your most valuable assets in a negotiation.</em></p>

<p>A company is making you an offer because they think you’ll do hard work for them if they pay you. If you lose your excitement for the company during the interview process, then they’ll lose confidence that you’ll actually want to work hard or stay there for a long time. Each of those makes you less attractive as an investment. Remember, you are the product! If you become less excited, then the product you’re selling actually loses value.</p>

<p>Imagine you were negotiating with someone over buying your watermelons, but the negotiation took so long that by the time you’d reached an agreement, your watermelons had gone bad.</p>

<p>Companies are terrified of that. They don’t want their candidates to go bad during a negotiation. Hence why they hire professional recruiters to manage the process and make sure they remain amicable. You and the recruiter share the same interest in that regard. If a company feels like you’ve gone bad, suddenly they’re a lot less willing to pay for you.</p>

<p>So despite whatever is happening in the negotiation, give the company the impression that 1) you still like the company, and that 2) you’re still excited to work there, even if the numbers or the money or the timing is not working out. Generally the most convincing thing to signal this is to reiterate you love the mission, the team, or the problem they’re working on, and really want to see things work out.</p>

<h2 id="dont-be-the-decision-maker">Don’t be the decision-maker</h2>

<p>You can wrap up the conversation now by saying:</p>

<blockquote>
  <p>I’ll look over some of these details and discuss it with my [FAMILY/CLOSE_FRIENDS/SIGNIFICANT_OTHER]. I’ll reach out to you if I have any questions. Thanks so much for sharing the good news with me, and I’ll be in touch!</p>
</blockquote>

<p>So not only are you ending the conversation with the power all in your hands, but note there’s another important move here: you’re roping in other decision-makers.</p>

<p><strong>Rule #5 of negotiation: don’t be the decision-maker.</strong> Even if you don’t particularly care what your friends/family/husband/mother thinks, by mentioning them, you’re no longer the only person the recruiter needs to win over. There’s no point in them trying to bully and intimidate you; the “true decision-maker” is beyond their reach.</p>

<p>This is a classic technique in customer support and remediation. It’s never the person on the phone’s fault, they’re just some poor schmuck doing their job. It’s not their decision to make. This helps to defuse tension and give them more control of the situation.</p>

<p>It’s much harder to pressure someone if they’re not the final decision-maker. So take advantage of that.</p>

<p>Okay!</p>

<p>We have our first offer. Send a follow-up e-mail confirming all of the details you discussed with your recruiter so you have a paper trail. Just say “<em>just wanted to confirm I had all the details right.</em>“</p>

<p>Groovy. Next step is to leverage this to land other offers and find the best deal we can find in the job market.</p>

<h2 id="getting-other-offers">Getting other offers</h2>

<p>Turns out, it doesn’t matter that much where your first offer is from, or even how much they’re offering you. Just having an offer in hand will get the engine running.</p>

<p>If you’re already in the pipeline with other companies (which you should be if you’re doing it right), you should proactively reach out and let them know that you’ve just received an offer. Try to build a sense of urgency. Regardless of whether you know the expiration date, all offers expire at some point, so take advantage of that.</p>

<blockquote>
  <p>Hello [PERSON],</p>

  <p>I just wanted to update you on my own process. I’ve just received an offer from [COMPANY] which is quite strong. That said, I’m really excited about [YOUR AMAZING COMPANY] and really want to see if we can make it work. Since my timeline is now compressed, is there anything you can do to expedite the process?</p>
</blockquote>

<p>Should you specifically mention the company that gave you an offer? Depends. If it’s a well-known company or a competitor, then definitely mention it. If it’s a no-name or unsexy company, you should just say you received an offer. If it’s expiring soon, you should mention that as well.</p>

<p>Either way, send out a letter like this to every single company you’re talking to. No matter how hopeless or pointless you think your application is, you want to send this signal to everyone who is considering you in the market.</p>

<p>Second, if there are any other companies you are looking to apply to (whether through referral or cold application), or even companies at which you’ve already applied but haven’t heard back, I would also follow up with a similar e-mail.</p>

<p>So why do this? Isn’t this tacky, annoying, or even desperate?</p>

<p>None of the above. It is the oldest method in history to galvanize a marketplace—show that supplies are limited and build urgency. Demand breeds demand. Not every company will respond to this, but many will.</p>

<p>Isn’t it stupid that companies respond to this though?</p>

<h2 id="why-companies-care-about-other-offers">Why companies care about other offers</h2>

<p><a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">When I wrote about the story of my own job search</a>, I mentioned how having an offer from Google made companies turn around and expedite me through their funnels. Many commentators lamented at the capriciousness of these companies. If Uber or Twitch only talked to me because of Google and until then weren’t willing to look at me, what did that say about their hiring processes? What legitimately are they evaluating, if anything at all?</p>

<p>I think this response is totally backwards. The behavior of tech companies here is actually very rational, and you would do well to understand it.</p>

<p>First, you must realize what a company’s goal is. A company’s goal is to hire someone who will become an effective employee and produce more value than their cost. How do you figure out who will do that? Well, you can’t know for certain without actually hiring them, but there are a few proxies. Pedigree is the strongest signal; if they did it at other companies, they can probably do it at yours. And if someone trusted within the organization can vouch for them, that’s often a strong signal as well.</p>

<p>But turns out, almost everything else is a weak signal. Weak in the sense that it’s just not very reliable. Interviews, if you think about it, are long, sweaty, uncomfortable affairs that only glancingly resemble actual employment. They’re weird and can’t tell you that much about whether an individual will be a good at their job. There’s no way around this. There are a few stronger signals, like bringing someone in for a week or two on a contract-to-hire position, but strong candidates won’t consider this. So candidates as a whole have effectively forced companies to assume almost all of the risk in hiring.</p>

<p>The truth is, knowing that someone has passed your interview just doesn’t say <em>that much</em> about whether they’ll be a good employee. It’s as though you knew nothing about a student other than their SAT score. It’s just not a lot of data to go off.</p>

<p>Nobody has solved this problem. Not Google nor anyone else.</p>

<p>And this is precisely why it’s rational for companies to care that you’ve received other offers. They care because each company knows that their own process is noisy, and the processes of most other companies are also noisy. But a candidate having multiple offers means that they have multiple weak signals in their favor. Combined, these converge into a much stronger signal than any single interview. It’s like knowing that a student has a strong SAT score, and GPA, and won various scholarships. Sure, it’s still possible that they’re a dunce, but it’s much harder for that to be true.</p>

<p>This is not to say that companies respond proportionally to these signals, or that they don’t overvalue credentials and brands. They do. But caring about whether you have other offers and valuing you accordingly is completely rational.</p>

<p>So this is all to say—tell other companies that you’ve received offers. Give them more signal so that they know you’re a valued and compelling candidate. And understand why this changes their mind about whether to interview you.</p>

<p>As you continue interviewing, remember to keep practicing your interview skills. The single strongest determinant of your final offer will be the number and strength of offers that you receive.</p>

<h2 id="some-advice-on-timing">Some advice on timing</h2>

<p>You want to be strategic about the timing of your offers. Generally, you should try to start interviewing at larger companies earlier. Their processes are slower and their offer windows are wider (meaning they allow you more time to decide). Startups are the other way around.</p>

<p>Your goal should be to have as many offers overlapping at the same time as possible. This will maximize your window for negotiating.</p>

<p>When you receive an offer, often the first thing you should ask for is more time to make your decision. Especially in your first offer, more time is by far the most valuable thing you can ask for. It’s time that enables you to activate other companies and end up with the strongest possible offer. So be prepared to fight for time.</p>

<h2 id="how-to-approach-exploding-offers">How to approach exploding offers</h2>

<p>Hoo boy.</p>

<p>Exploding offers are offers that expire within 24-72 hours. You won’t see this much at big companies, but they’re becoming increasingly common among startups and mid-sized companies.</p>

<p>Exploding offers suck, and I share most people’s disdain for this practice. But I do understand it. Exploding offers are a natural weapon for employers to combat a strong hiring market for tech workers. Companies know exactly what they’re doing with exploding offers—they play on fear and limit your ability to seek out counteroffers.</p>

<p>In a sense, it’s unsurprising that if startups have more difficulty attracting and securing talent, they’d resort to this practice. What I don’t like is the dishonesty about it. Employers often justify this by saying “<em>If you need more time than this, then that’s a sign you’re not the kind of person we’re looking for.</em>“</p>

<p>Please don’t buy this crap or feel guilty over it. They’re simply doing this to improve their chance of closing candidates. Needing more than three days to make a life decision isn’t a sign of anything other than thoughtfulness.</p>

<p>So what should you do if you receive an exploding offer?</p>

<p>Exploding offers are anathema to your ability to effectively navigate the labor market. Thus, there is only one thing to do. Treat the offer as a non-offer unless the expiration window is widened.</p>

<p>In no uncertain terms, convey that if the offer is exploding, it’s useless to you.</p>

<p>Example conversation:</p>

<blockquote>
  <p>I have one big concern. You mentioned that this offer explodes in 48 hours. I’m afraid this doesn’t work at all for me. There’s no way that I can make a decision on this offer within a 48 hour window. I’m currently wrapping up my interview process at a few other companies, which is likely to take me another week or so. So I’m going to need more time to make an informed decision.</p>
</blockquote>

<p>If they push back and say this is the best they can do, then politely reply:</p>

<blockquote>
  <p>That’s really unfortunate. I like [YOUR COMPANY] and was really excited about the team, but like I said, there’s no way I can consider this offer. 48 hours just too unreasonable of a window. The next company I join will be a big life decision for me, and I take my commitments very seriously. I also need to consult with my [EXTERNAL_DECISION_MAKER]. There’s no way that I can make a decision I’m comfortable with in this short an amount of time.</p>
</blockquote>

<p>Pretty much any company will relent at this point. If they persist, don’t be afraid to walk away over it. (They probably won’t let that happen, and will come grab you as you’re walking out the door. But if they don’t, then honestly, screw ‘em.)</p>

<p>I was given several exploding offers during my job search. And every time, I did essentially this. Every single offer immediately widened to become more reasonable, sometimes by several weeks.</p>

<p>I want to emphasize, lest I be misunderstood here—what I’m saying is not to just silently let an exploding offer expire, and assume that everything will be fine and they’ll still hire you. They won’t. For exploding offers to be a credible weapon, a company has to have a reputation of enforcing them. I’m saying explicitly call this out as an issue when they make the offer.</p>

<p>Don’t let a company bully you into giving away your negotiating power.</p>

<h2 id="the-negotiating-mindset">The Negotiating Mindset</h2>

<p>Before we enter into the actual back-and-forth, I want to examine the mindset you should have as a negotiator. This applies not just to how you approach the conversation, but also to how you think about the company.</p>

<p>Do not fall into the trap of valuing companies solely along one dimension. That means don’t just value companies based on salary, equity, or even on prestige. Those are all important dimensions, but so are cultural fit, the challenge of the work, learning potential, later career options, quality of life, growth potential, and just overall happiness. None of these inherently trump any of the other. Anyone who tells you “just choose wherever you think you’ll be happiest” is being just as simplistic than someone who says “just choose the one that offers the most money.” All of these things matter, and your decision should be genuinely multi-dimensional.</p>

<p>Be open to being surprised as you explore different companies.</p>

<p>It’s also important to understand that companies don’t all value you along the same dimension either. That is, different companies are genuinely looking for different skills, and there are some companies at which you will be more and less valuable. Even at peer companies this is true, especially so if you have a specialized skill-set.</p>

<p>The more companies you talk to, the more likely you are to find a company to which you are significantly more valuable than the rest. Chances are this is where you’ll be able to negotiate your strongest offer. It might surprise you which company this turns out to be; keep an open mind, and remember that a job search is a 2-sided process.</p>

<p>One of the most valuable things you can do for yourself in this process is to really try to understand how employers think and what motivates them. Understanding your interlocutor is extremely important in negotiation, and we’ll be exploring that a lot in the next blog post.</p>

<p>But most of all I want to emphasize: be curious about the other side. Try to understand why employers think the way they do. Be sympathetic toward them. Care about what they want and help them try to get it. Adopting this mindset will make you a much stronger negotiator, and accordingly, a much better employee and team member.</p>

<p>Okay. That’s as far as we’re going for today. In the next blog post, I’m going to cover the last four rules of negotiation. I’ll also go over the actual back-and-forth process—how to ask for what you want, how to strengthen offers, and how to dismantle the tricks that companies will try to pull on you. Also a lot more on the theory of negotiation, which I really dig.</p>

<p>Do share this post if you found it useful! And <a href="https://twitter.com/intent/follow?original_referer=http%3A%2F%2Fhaseebq.com%2F%3Fp%3D2393%26preview%3Dtrue&amp;ref_src=twsrc%5Etfw&amp;region=follow_link&amp;screen_name=hosseeb&amp;tw_p=followbutton">follow me on Twitter</a>.</p>

<p><a href="https://haseebq.com/how-not-to-bomb-your-offer-negotiation/">You can read part 2 here!</a></p>

<p>Until next time,</p>

    <p>Haseeb</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 4 Now Live on Groq (106 pts)]]></title>
            <link>https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</link>
            <guid>43596470</guid>
            <pubDate>Sat, 05 Apr 2025 20:13:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/">https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</a>, See on <a href="https://news.ycombinator.com/item?id=43596470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="63e34e6" data-element_type="container" data-elementor-type="wp-post" data-elementor-id="6435" data-elementor-post-type="post" data-widget_type="theme-post-content.default">
				<div data-id="722ca0c" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Meta’s Llama 4 Scout and Maverick models are live today on GroqCloud™, giving developers and enterprises day-zero access to the most advanced open-source AI models available.<br></span></h4>								</p>
				</div>
				<div data-id="1ab7589" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Today, Meta released the first models in the Llama 4 herd, which will enable people to build more personalized multimodal experiences. With Llama 4 Scout and Llama 4 Maverick available on GroqCloud today to its free users and paid customers, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</p>
				</div>
				
				<div data-id="345d7c5" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Groq Performance &amp; Pricing<br></span></h4>								</p>
				</div>
				<div data-id="3568efc" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>Our vertically integrated GroqCloud and inference-first architecture deliver unmatched performance and price. With Llama 4 models, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</span></p>
<p><span>Llama 4 Scout is currently running at over 460</span><span>&nbsp;tokens/s</span><span> while Llama 4 Maverick is coming today</span><span>.&nbsp;</span><span>Stay tuned for official 3rd party benchmarks from Artificial Analysis.&nbsp;</span></p>
<p><span>Groq is offering the first of the Llama 4 model herd at the following pricing:</span></p>								</div>
				<div data-id="355d301" data-element_type="widget" data-widget_type="text-editor.default">
									<ul><li aria-level="1"><b>Llama 4 Scout: </b><span>$0.11 / M input tokens and $0.34 / M output tokens</span></li><li aria-level="1"><strong>Llama 4 Maverick:</strong> $0.50 / M input tokens and $0.77 / M output tokens</li></ul>								</div>
				
				<div data-id="1ee4919" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>About Llama 4 <br></span></h4>								</p>
				</div>
				<div data-id="f519fef" data-element_type="widget" data-widget_type="text-editor.default">
				<p>The new Llama 4 models are Meta’s first models that use a Mixture of Experts (MoE) architecture. In MoE models, a single token activates only a fraction of the total parameters. MoE architectures are more compute efficient for model training and inference and, given a fixed training FLOPs budget, deliver higher quality models compared to dense architectures.<br>Llama 4 models are designed with native multimodality, incorporating early fusion to seamlessly integrate text and vision tokens into a unified model backbone. <br>Meta aims to develop the most helpful, useful models for developers while protecting against and mitigating the most severe risks. This includes integrating mitigations at each layer of model development from pre-training to post training and tunable system-level mitigations that shield developers from adversarial users. In doing so, Meta is helping empower developers to create helpful, safe, and adaptable experiences for their Llama supported applications.</p>
				</div>
				
				<div data-id="e9fc04b" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Llama 4 Scout &amp; Maverick<br></span></h4>								</p>
				</div>
				<div data-id="9a49798" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>These latest Llama models from Meta include smaller and larger options to accommodate a range of use cases and developer needs.</span></p><p><span>Llama 4 Scout is a leading multimodal model and is more powerful than the Llama 3 models. It contains 17 billion active parameters, 16 experts, and 109 billion total parameters; it delivers state-of-the-art performance for its class.&nbsp;</span></p><p><span>Llama 4 Maverick contains 17 billion active parameters, 128 experts, and 400 billion total parameters, offering high quality at a lower price compared to Llama 3.3 70B. It offers unparalleled, industry-leading performance in image and text understanding with support for 12 languages, enabling the creation of sophisticated AI applications that bridge language barriers. As the workhorse model for general assistant and chat use cases, Llama 4 Maverick is great for precise image understanding and creative writing. For developers, it offers state-of-the-art intelligence with high speed, optimized for best response quality on tone, and refusals.</span></p>								</div>
				
				<div data-id="531d7d8" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Build Fast with Llama 4 on GroqCloud<br></span></h4>								</p>
				</div>
				
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama4 (1015 pts)]]></title>
            <link>https://www.llama.com/llama4/</link>
            <guid>43595585</guid>
            <pubDate>Sat, 05 Apr 2025 18:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.llama.com/llama4/">https://www.llama.com/llama4/</a>, See on <a href="https://news.ycombinator.com/item?id=43595585">Hacker News</a></p>
Couldn't get https://www.llama.com/llama4/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: iPhone 2005 weird "Blob Keyboard" simulator (123 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43595442</link>
            <guid>43595442</guid>
            <pubDate>Sat, 05 Apr 2025 18:20:49 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43595442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="43595442">
      <td><span></span></td>      <td><center><a id="up_43595442" href="https://news.ycombinator.com/vote?id=43595442&amp;how=up&amp;goto=item%3Fid%3D43595442"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=43595442">Show HN: iPhone 2005 weird "Blob Keyboard" simulator</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_43595442">101 points</span> by <a href="https://news.ycombinator.com/user?id=juliendorra">juliendorra</a> <span title="2025-04-05T18:20:49 1743877249"><a href="https://news.ycombinator.com/item?id=43595442">8 hours ago</a></span> <span id="unv_43595442"></span> | <a href="https://news.ycombinator.com/hide?id=43595442&amp;goto=item%3Fid%3D43595442">hide</a> | <a href="https://hn.algolia.com/?query=Show%20HN%3A%20iPhone%202005%20weird%20%22Blob%20Keyboard%22%20simulator&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=43595442&amp;auth=73eff720157eb1fabbb5a96d6d3aa1dc7ef9a0e8">favorite</a> | <a href="https://news.ycombinator.com/item?id=43595442">34&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi HN,</p><p>I teach tech design history, and one of the key stories I cover is the development of the original iPhone keyboard by Ken Kocienda. Reading about it in his book "Creative Selection" is great, but I wanted my students (and now you!) to actually <i>feel</i> this step in the process.</p><p>So, I built a web simulator of the "Blob Keyboard", Kocienda's very first attempt at a touchscreen keyboard that actually works, from September 2005:</p><p>Try the Blob Keyboard: <a href="https://juliendorra.github.io/blob-keyboard-simulator/blob-keyboard-simulator.html" rel="nofollow">https://juliendorra.github.io/blob-keyboard-simulator/blob-k...</a></p><p>- Tap for the middle letter</p><p>- Swipe left or right for the side letters</p><p>More on the github repo: <a href="https://github.com/juliendorra/blob-keyboard-simulator">https://github.com/juliendorra/blob-keyboard-simulator</a></p><p>The Blob Keyboard prototype emerged during a UX crisis for iPhone team (their software keyboard just didn't work at all, fingers being too big, and the Newton failure loomed over them), highlighting how innovation is rarely a straight path. It was developed on a tethered touchscreen display codenamed "Wallaby".</p><p>To make this simulator as authentic as possible, I referenced images from Kocienda's book and even got direct feedback and guidance from Ken Kocienda himself on Bluesky.</p><p>What to expect (or… what not to expect):</p><p>This is a reconstruction of a very early prototype with limitations reflecting that specific moment. The goal was to test first if typing with accuracy was even possible, as all the rest was moot if it failed!</p><p>It's NOT QWERTY: They were still hoping to get us out of QWERTY, but then familiarity won.</p><p>No Backspace: You can't delete.</p><p>No Cursor Movement: The text field is just a simple display.</p><p>No Caps or Numbers: Only lowercase letters.</p><p>No Smooth Animations: Keys just "pop" instantly when pressed. Kocienda noted that your eye fills in the gaps, giving a sense of movement.</p><p>Best Experience:</p><p>While it works with a mouse/trackpad on desktop, it's designed for touchscreens to better replicate the original Wallaby hardware interaction. Use it on your phone!</p><p>This project aims to provide a tangible glimpse into a turning point moment in iPhone development and the iterative nature of design. It's like stepping back in time and trying out that early demo on Kocienda's desk.</p><p>I would love to hear your reactions and thoughts on experiencing this piece of UI history! What other significant prototype do you wish you could experience?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA's Project Scientist Faces Painful Choices as Voyager Mission Nears Its End (104 pts)]]></title>
            <link>https://gizmodo.com/keeping-voyager-alive-nasas-project-scientist-faces-painful-choices-as-the-iconic-mission-nears-its-end-2000580634</link>
            <guid>43595293</guid>
            <pubDate>Sat, 05 Apr 2025 18:01:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/keeping-voyager-alive-nasas-project-scientist-faces-painful-choices-as-the-iconic-mission-nears-its-end-2000580634">https://gizmodo.com/keeping-voyager-alive-nasas-project-scientist-faces-painful-choices-as-the-iconic-mission-nears-its-end-2000580634</a>, See on <a href="https://news.ycombinator.com/item?id=43595293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              
              <p>In 1977, two probes launched less than a month apart on a mission to the great beyond. The twin Voyager spacecraft were to travel where no other mission had gone before, exploring what lies outside the vast bubble that surrounds our solar system, beyond the influence of our host star.</p> <p>Voyager 1 reached the beginning of interstellar space in 2012, while Voyager 2 reached the boundary in 2018, traveling beyond the protective bubble surrounding the solar system known as the heliosphere. The Voyager probes were the first spacecraft to cross into interstellar space and have been exploring the unfamiliar region for nearly 48 years. But all good things must come to an end, and the iconic mission is gradually losing steam as it approaches oblivion.</p> <p>The Voyagers are powered by heat from decaying plutonium, which is converted into electricity. Each year, the aging spacecraft lose about 4 watts of power. In an effort to conserve power, the <a href="https://gizmodo.com/nasa-shuts-off-voyager-science-instrument-more-power-cuts-ahead-to-keep-both-probes-going-2000572202">mission team has turned off any systems that were deemed unnecessary</a>, including a few science instruments. Each Voyager spacecraft began with 10 instruments, but now have just three each. The two spacecraft now have enough power to operate for another year or so before engineers are forced to turn off two more instruments.</p> <p>The Voyager team, some of whom have worked on the mission since it first began, are forced to make these tough decisions to keep the mission going, in addition to <a href="https://gizmodo.com/nasa-pulls-off-delicate-thruster-swap-keeping-voyager-1-mission-alive-2000497434">coming up with creative solutions to resolve menacing glitches</a> that affect the spacecraft as they weather the harsh space environment.</p> <p>Linda Spilker, the Voyager mission’s project scientist, spoke to Gizmodo about the challenges that come with operating the outdated spacecraft, and passing on the knowledge of the Voyagers to the newer generations of scientists and engineers who have joined the mission.</p>

 <p>This interview has been lightly edited for clarity and length.</p> <p><strong>Passant Rabie, Gizmodo: How long have you worked on the Voyager mission?</strong></p> <p><strong>Spilker:</strong> I started working on Voyager in 1977, it was my first job out of college, and I had a choice between the Viking extended mission or the Voyager mission. I, of course, hadn’t heard of Voyager. So I said, where’s Voyager going? And they said, well, Jupiter and Saturn and onto Uranus and Neptune with Voyager 2 if all goes well. And I thought, oh my goodness—I remember in third grade, I got a little telescope I used to use to look at the Moon and look at Jupiter and Saturn, and look for little moons around Jupiter and see if I could spot the rings around Saturn. So the thought of a chance to go visit these worlds that were really only tiny dots in my little telescope, I said, “sign me up.”</p> <p><strong>Gizmodo: How has the mission evolved over the years?</strong></p> <p><strong>Spilker:&nbsp;</strong>The number of people that are working on and flying Voyager is a whole lot smaller than it was in the planetary days. We’ve turned off a lot of instruments on Voyager. We had some pretty big teams with the remote sensing instruments, the cameras, the spectrometers, etc, that are out on a boom on the end of the spacecraft. As the instruments turned off, the mission got smaller.</p>

 <p>There really was the thinking after Neptune, that Voyager would probably only last a few more years and so they had a very small team, and they kind of were, in a sense, basically neatening up everything and putting Voyager in a mode that could operate longterm. A lot of the engineers, as well as the scientists, were rolling off the mission, leaving just a very small operations team for what we call the Voyager interstellar mission.</p> <p>The challenge was, can we reach the heliopause? We didn’t know where it was, we had no idea how far away it was. We got to Neptune, and then we thought, “well, maybe it’s just another 10 [astronomical units] or so, a little bit further, a little bit further.” And so every time we got a little bit further, the modelers would go back, scratch their heads and say, “ah, it could be a little bit more, a little bit farther away,” and so on and on that continued, until finally, Voyager 1 crossed the heliopause in 2012. If you think about that, that’s like 21 years after the start of the mission. And then, six years after that, Voyager 2 crossed the heliopause, and ever since then, they’ve been flying in interstellar space, making unique measurements about the particles in interstellar space, the cosmic ray abundance, the magnetic field. Basically, it’s a chance to explore—once you cross that boundary, there’s a whole new region, a whole new realm out there in interstellar space.</p> <p><strong>Gizmodo: Is it an emotional decision to turn off Voyager’s instruments?</strong></p> <p><strong>Spilker:&nbsp;</strong> I was talking to the cosmic ray instrument lead, and I said, “Wow, this must really be tough for you to see your instrument turned off.” He helped build the instrument in the early 1970s. This instrument that’s been sending you data, and that’s been part of your life for over 50 years now. And he said, it was hard to think about turning it off for the whole team. It’s kind of like losing a best friend, or someone that’s been a part of your life for so many years, and then suddenly, it’s silent.</p>

 <p>At the same time, there’s this pride that you were part of that, and your instrument got so much great data—so it’s a mix of emotions.</p> <p><strong>Gizmodo: What are the challenges that come with operating a mission for this long?</strong></p> <p><strong>Spilker:&nbsp;</strong> The spacecraft was built in the 1970s, and so that’s the technology that we had in those days. And we didn’t have very much computer memory, so we had to be very careful and think through what we could do with this tiny amount of computer memory.</p>

 <p>So the challenge with these aging components is, how long until a key piece fails? We’re well past the warranty of four years. We also have less power every year, about 4 watts less power so we have to find 4 watts per year to turn off on the spacecraft. The spacecraft had a lot of redundancy on it, so that means two of every computer and two of all the key components. We’ve been able to turn off those backup units, but we’re now at the point where, to really get a significant amount of power, all that’s left are some of the science instruments to turn off. So, that’s where we’re at.</p> <p>Then, of course, if you have less power, the temperature goes down inside. There’s something called a bus that has all the electronics inside, and that’s getting colder and colder. Along the outside of the bus are these tiny lines of hydrazine that go to the thrusters, so we started to worry about the thermal constraints. How cold can the lines get before they freeze? How cold can some of these other components get before they stop working? So that’s another challenge.</p>  <p>Then there are individual tiny thrusters that align the spacecraft and keep that antenna pointed at the Earth so we can send the data back, and they’re very slowly clogging up with little bits of silica, and so their puffs are getting weaker and weaker. That’s another challenge that we’re going through to balance.</p>

 <p>But we’re hopeful that we can get one, possibly two, spacecraft to the 50th anniversary in 2027. Voyager’s golden anniversary, and perhaps even into the early 2030s with one, maybe two, science instruments.</p> <p><strong>Gizmodo: What about the language that the spacecraft use?</strong></p> <p><strong>Spilker:&nbsp;</strong> They use something called machine language, and I think it’s a language that’s unique to Voyager’s program. There are three different computers, an attitude control computer, another computer for commands, and another computer that basically configures the data and sends it back to the ground.</p> <p>So you have to configure these very tiny memories, and it’s in a machine language that nobody really uses anymore. We got some experts to come back and help us solve some of the problems we’ve had on the spacecraft, or other engineers who have had to learn the machine language. We had a chip failure on one of the computers, so we had to reprogram that computer and so we brought in some experts, and they really enjoyed it, trying to troubleshoot and figure out what’s wrong. And it was like a detective story, you know, what can we do? And they figured it out, and it worked.</p> <p>With Voyager, what often happens is, everything looks really good and then something goes wrong on the spacecraft. And in this case, all of a sudden we went from data coming back every day to just a tone, a signal that said the spacecraft is still there.</p>

 <p>One good analogy is going from getting letters from Voyager—you open them up and read about what’s happening every day—to now getting a letter, opening it, and finding it blank. You have no information coming back from Voyager. Imagine your computer fails, and the screen is dark</p> <p>We were sending up commands and trying to figure out what happened, and ultimately got something called a memory readout, and we found that a chip had failed. We knew which parts of the computer programs were on that chip, and then it was a matter of taking those pieces and then finding enough free space on the rest of the computer to reprogram it and get it to work again. But in bringing in those people, where do you start? In the 70s, we didn’t have the computers we do today. A lot of Voyager material is in memos, and sometimes the memos are scanned in a PDF file. And so you have to go on, literally, a sort of a hunting, like, which would be the most useful for me to look at. Some of the engineers had a big diagram up on the wall of what the computer looked like and all the paths that it had to go through to figure it all out. And they just stuck sticky notes all over as they were figuring it out.</p>

 <p>It was a mix of bringing in people who really knew and understood that computer—one of the retirees really understands the flight data system computer—and subject matter experts, and we would get them up to speed and have them work with the Voyager team. Meanwhile, the scientists are patiently waiting for their data to come back.</p> <p><strong>Gizmodo: You&nbsp;</strong><b>mentioned that the team has gotten smaller over the years. Is it basically the same people that have been working on the mission all along or do you have to bring in new people and fill them in?</b></p>

 <p><strong>Spilker:</strong> As you can imagine, most of the people are new. There are really only a handful that helped build the instruments in the 1970s, and a few of the scientists that are left have worked on the mission from the beginning until now.</p> <p>We’ve actually brought back some people who retired, who were there in that time frame of building and coding Voyager, so they have come back and now work part time. Retirees are very happy to come back and help us. And then, of course, a lot of younger people that have come on and bring their own experiences, and so we’ve been training several new people recently into the roles that we need to operate.</p> <p>On the science side, there’s a series of guest investigators—basically modelers and theorists—who work with the scientists on the Voyager teams to help pass that knowledge forward. In other words, to mentor the next generation of scientists who might want to work with the data in the future.</p> <p><strong>Gizmodo: As a scientist, what have been the most important things that you’ve learned from the Voyager mission?</strong></p>

 <p><strong>Spilker:&nbsp;</strong>Voyager left breadcrumbs, clues for future missions to come. One of Voyager’s goals was to see through to the surface of Saturn’s Moon, Titan. We didn’t know if it could have liquid oceans on the surface, or what the surface looked like. During Voyager’s close flyby of Titan, we found that none of its instruments or camera filters could penetrate through the haze. It looked like a bad day in a smoggy city.</p> <p>It was Voyager’s discovery, or non-discovery, of not being able to see the surface of Titan, that led to the Cassini mission. After Voyager’s flyby, NASA and the European Space Agency got together and said, “we need to go back.”</p> <p>I had a chance to go work on Cassini. I got in very early, and helped formulate the mission concept. I spent around 30 years on Cassini, and then the mission ended in 2017. At that point, I was thinking of retiring but then I got the opportunity to go back to Voyager and work with Edward Stone [who served as project scientist for Voyager from 1972 to 2022] and the science team, and go back to the mission where I first started.</p> <p>I went home and I told my husband, “I don’t think I’m going to retire.”</p>

 <figure id="attachment_2000584812" aria-describedby="caption-attachment-2000584812"><img decoding="async" src="https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS.jpeg" alt="Luckypeanuts" width="1920" height="1280" srcset="https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS.jpeg 1920w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-300x200.jpeg 300w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-1024x683.jpeg 1024w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-768x512.jpeg 768w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-336x224.jpeg 336w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-1400x932.jpeg 1400w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-680x453.jpeg 680w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-896x597.jpeg 896w, https://gizmodo.com/app/uploads/2025/04/LUCKYPEANUTS-1792x1195.jpeg 1792w" sizes="(max-width: 1023px) calc(100vw - 2rem), (max-width: 1279px) calc(100vw - 26rem), 680px"><figcaption id="caption-attachment-2000584812">Spilker explains the tradition of lucky peanuts, which date back to the Ranger Project in the 1960’s, at a gathering in Von Karman Auditorium at NASA’s Jet Propulsion Laboratory in Pasadena, California. Credit: NASA/JPL-Caltech</figcaption></figure> <p><strong>Gizmodo: How does it feel now that the mission is approaching its end?</strong></p> <p><strong>Spilker:&nbsp;</strong>We’re hoping to get one or both spacecraft to Voyager’s golden anniversary, and that’s going to be in 2027. As we get closer to the end of the mission, for me personally, it’s kind of like wrapping up my career in a way—because I’ll probably retire once the Voyager mission ends. I’m just really, really happy to have been a part of it.</p> <p><strong>Gizmodo:</strong> <strong>There’s always this debate of whether we should launch another interstellar probe. I’m wondering how you feel about that?</strong></p> <p><strong>Spilker:&nbsp;</strong>I think it would be a great idea, it could even go further than Voyager.</p> <p>We know that material mostly comes from supernova explosions, and that those explosions create bubbles in space filled with material that came from the exploding star. Earth and the rest of the planets are inside this heliopause [the outer edge of the bubble that surrounds our solar system]. But there are other bubbles.</p>

 <p>You can imagine, every time you have a supernova, you get a new bubble, and those bubbles are all there in space. How far do you have to keep going to reach another bubble? And what is it like to get farther and farther away from the Sun? One of the questions of the Voyager mission is, how far does the Sun’s influence continue into interstellar space?</p> <p>We’re still working and thinking about an interstellar probe that would go much, much farther than Voyager. You’re talking about a multi-generation mission.</p> <p><strong>Gizmodo: Should we have already launched one?</strong></p> <p><strong>Spilker:&nbsp;</strong>There’s so many interesting places to go. Prior to Voyager, we had no idea what the heliopause was like. Then getting this sort of taste of interstellar space makes us want to go back.</p> <p>It’s like going to so many places, you get to answer all these questions and make tremendous discoveries, but you leave behind a list of questions that’s much longer than the ones you answered.</p>

 <p><strong>Gizmodo: Do you worry that we won’t be able to recreate a mission like Voyager again under the current circumstances at NASA?</strong></p> <p><strong>Spilker:&nbsp;</strong>We’re entering a new and interesting era. You have the private industry wanting to play a bigger role in getting us to space. In a certain sense, some of these bigger rockets could deliver a mission to Uranus or Neptune in a much shorter time.</p> <p>I see hopeful signs, but it’s always tough when you have budgets to balance and other things to look out for. But if you look at when I started at NASA’s Jet Propulsion Laboratory to now, the number of missions that are flying in space— whether they’re missions to planets or to study our Sun—there are so many more missions today. There’s just been sort of a blossoming of scientific missions and our understanding of our place in the universe.</p> <p>So I’m hopeful, there’s always tough times to weather. We’ve been through tough times before, and I think we’ll weather this one.</p>
                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Faster interpreters in Go: Catching up with C++ (149 pts)]]></title>
            <link>https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp</link>
            <guid>43595283</guid>
            <pubDate>Sat, 05 Apr 2025 17:59:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp">https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp</a>, See on <a href="https://news.ycombinator.com/item?id=43595283">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>By <!-- -->Vicent Martí<!-- --> | <time datetime="2025-03-20">March 20, 2025</time></p><p>The SQL evaluation engine that ships with Vitess, <a href="https://github.com/vitessio/vitess">the open-source database that powers PlanetScale</a>, was originally implemented as an AST evaluator that used to operate directly on the SQL AST generated by our parser. Over this past year, we've gradually replaced it with a Virtual Machine which, despite being written natively in Go, performs similarly to the original C++ evaluation code in MySQL. Most remarkably, the new Virtual Machine has repeatedly proven itself easier to maintain than the original Go interpreter, even though it's orders of magnitude faster. Let's review the implementation choices we've made to get these surprising results.</p><h2 id="whats-a-sql-evaluation-engine"><a href="#whats-a-sql-evaluation-engine">What's a SQL evaluation engine?</a></h2><p>Vitess has been designed for unlimited horizontal scaling. To accomplish this, all queries to a Vitess cluster must go through a <code>vtgate</code>. Since you can deploy as many <code>vtgate</code> instances as you want, because they’re essentially stateless, this allows you to grow the capacity of your cluster linearly.  The job of each gate is the most complex part of the whole distributed system. It parses the SQL of the incoming queries and creates a shard-aware query plan, which we evaluate in one or many of the shards of the cluster. Then, we aggregate the results of these evaluations, and return them to the user.</p><p>One of the reasons why Vitess works so well in practice (in both performance and in ease of adoption) is that every shard in a cluster is backed by a real MySQL instance. Even the more complex SQL queries can be decomposed into simpler statements that are evaluated in the underlying MySQL database. Hence, the results of these queries always match what you’d expect from querying MySQL directly.</p><p>However, SQL queries in the real world can get <em>really wild</em>. We need to support pretty much every kind of query that a normal MySQL instance supports, but we need to evaluate it across several MySQL instances. This means that sometimes, we don’t get to fall back to MySQL to evaluate all our SQL expressions.</p><p>Think of a rather simple query such as this:</p><pre data-language="sql">SELECT inventory.item_id, SUM(inventory.count), AVG(inventory.price) AS avg_price
FROM inventory
WHERE inventory.state = 'available' AND inventory.warehouse IN ? 
GROUP BY inventory.item_id
HAVING  avg_price &gt; 100;
</pre><p>Assuming this query is executed in a sharded Vitess cluster, the inventoried items can exist in any of the shards. Hence, our query planner will prepare a plan that queries all shards in parallel, <a href="https://planetscale.com/blog/grouping-and-aggregations-on-vitess">pushing down part of the aggregation to MySQL</a>, and then we'll perform the aggregations (<code>SUM</code> and <code>AVG</code>) locally in the <code>vtgate</code>. The <code>state</code> and <code>warehouse</code> checks in the <code>WHERE</code> clause can and will be executed directly on the MySQL instance that powers each shard. But the last expression, <code>avg_price &gt; 100</code>, applies to the result of the aggregation, which is only available inside Vitess. This is where the Vitess evaluation engine comes in.</p><p>Our evaluation engine is an interpreter that supports the majority of the scalar expressions in the SQL dialect used by MySQL. This does not include high level constructs such as performing a <code>JOIN</code>,  the grouping of a <code>GROUP BY</code>, etc (these are performed directly by the planner, as we’ve seen), but the actual sub-expressions that you’d see as the condition of a <code>WHERE</code> clause, or a <code>GROUP BY</code> clause. Any piece of SQL that cannot be lowered to be executed in MySQL by the planner is evaluated locally in Go by the engine.</p><p>Of course, these SQL sub-expressions are not arbitrarily complex. They are not even Turing complete (as they cannot loop!), so you may think that a statement like <code>avg_price &gt; ?</code> would be trivial to evaluate, but as in most engineering problems, there’s a wealth of nuance when doing these things in the real world.</p><p>SQL is an incredibly dynamic language full of quirks, and the SQL in MySQL, doubly so. We have spent an inordinate amount of time getting every single corner case of SQL evaluation to match exactly MySQL’s behavior. In fact, our <a href="https://github.com/vitessio/vitess/blob/main/go/vt/vtgate/evalengine/testcases/cases.go">test</a> <a href="https://github.com/vitessio/vitess/blob/main/go/vt/vtgate/evalengine/testcases/inputs.go">suite</a> and <a href="https://github.com/vitessio/vitess/tree/main/go/vt/vtgate/evalengine/integration">fuzzer</a> are so comprehensive that we routinely find bugs in the original MySQL evaluation engine, which we have to fix upstream (<a href="https://github.com/mysql/mysql-server/pull/602">like this collation bug</a>, <a href="https://github.com/mysql/mysql-server/pull/517">this issue in the <code>insert</code> SQL function</a> or <a href="https://github.com/mysql/mysql-server/pull/515">this bug when searching substrings</a>). Nonetheless, being fully accurate is not enough. For most queries, these expressions are evaluated once or even more than once <em>for every returned row</em>, so in order to not introduce additional overhead, evaluation needs to be as quick as possible.</p><p>As discussed earlier, the first version of the evaluation engine in Vitess was an AST-based interpreter, operating directly on top of the SQL AST generated by our parser. This was a very straightforward design that allowed us to focus on <em>accuracy</em>, at the expense of performance. Let's discuss our new design for replacing this interpreter with a fully fledged virtual machine which is both faster and easier to maintain. Starting with the basics.</p><h2 id="the-shapes-of-an-interpreter"><a href="#the-shapes-of-an-interpreter">The shapes of an interpreter</a></h2><p>For those new to programming language implementations, there are roughly 3 ways to execute a <em>dynamic</em> language at runtime. In increasing level of complexity <em>and</em> performance:</p><ol><li>An AST-based interpreter, where the syntax of the language is parsed into an AST and evaluation is performed by recursively walking each node of the AST and computing the results. <em>(this is the way the <code>evalengine</code> in Vitess used to work!)</em></li><li>A bytecode VM, where the AST is compiled into binary bytecode that can be evaluated by a virtual machine — a piece of code that simulates a CPU, but with higher-level instructions. <em>(this is what we've recently shipped!)</em></li><li>A JIT compiler, in which the bytecode is compiled directly into the host platform's native instructions, so it can be executed directly by the CPU without being interpreted by a Virtual Machine. <em>(we'll talk about this later!)</em></li></ol><p>The first thing to consider here is whether the upgrade from an AST interpreter to a virtual machine makes sense from a performance point of view. Here’s an intuition: SQL expressions are incredibly dynamic (when it comes to typing), very high level (when it comes to each primitive operation), and with very little control flow (when it comes to evaluation -- SQL expressions don't really loop, and conditionals are rare; their flow is always lineal!). This can lead us to believe that there's no performance to be squeezed from translating the AST-based evaluation engine into bytecode. The AST is already well suited for high level operations and type-switching!</p><p>This is only <em>superficially</em> true. Lots of programming languages are highly dynamic and they manage to run in bytecode VMs much more efficiently than with an AST interpreter. A clear example of this is the now ancient transition that Ruby did from its original AST interpreter in MRI to YARV, a bytecode VM. Python also did a similar switch very early on. And you can bet that literally no JavaScript engines are using AST evaluation: even though the goal of these engines is to start running JS as soon as possible, they still compile to (very efficient) bytecode interpreters before JIT compilation kicks in.</p><p>So where’s the advantage of a virtual machine versus an AST interpreter? A lot of it boils down to instruction dispatching, which can be made very fast (more on this later!). But it is true that for SQL expressions, we’re actually going to execute very few instructions. Hence, to squeeze performance out of the VM, we’re going to have to come up with new tricks.</p><p>The initial approach I had in mind for our SQL virtual machine was based on <a href="https://publications.sba-research.org/publications/dls10.pdf">Efficient Interpretation using Quickening</a> by Stefan Brunthaler. The idea behind this paper is that dynamic programming languages are very hard to execute efficiently because of the lack of information about types. A simple expression such as <code>a + 1</code> must be interpreted in a completely different way depending on whether <code>a</code> is an integer, a floating point number of even a string. To optimize these operations in practice, the paper suggests rewriting the bytecode from more generic instructions (e.g. the sum operator that needs to figure out the types of the two operands to know how to sum them) into specific static instructions which are specialized for the types they operate on at runtime (e.g. the sum operator that knows that both operands are integers and can sum them right away).</p><p>To do that, a quickening VM needs to figure out <em>at runtime</em> the types of the expressions being evaluated and incrementally rewrite the bytecode into instructions that operate on them. This is very hard to do in practice! But after implementing a good chunk of specialized instructions for the different types of operators in SQL and attempting to runtime rewrite them, I noticed an opportunity to take the idea even further by making it more efficient and, crucially, simpler.</p><p>It turns out that the semantic analysis we perform in Vitess is advanced enough that, through careful integration with the upstream MySQL server and its information schema, it can be used to <em>statically type the AST of the SQL expressions we were executing</em>. This took a lot of effort to implement, but resulted in a big win: since the planner knows the types of the actual inputs that will be used to evaluate each SQL expression, we can derive from those the types of all sub-expressions at compilation time, resulting in byte-code that is already specialized without requiring runtime rewriting.</p><p>Now we just need to implement a Virtual Machine to efficiently interpret the specialized bytecode!</p><h2 id="an-efficient-virtual-machine-in-go"><a href="#an-efficient-virtual-machine-in-go">An efficient Virtual Machine in Go</a></h2><p>Implementing a VM usually involves a lot of complexity. As we’ve explained, you have to write a compiler that processes the input expression AST and generates the corresponding binary instructions (you have to come up with an encoding even!) and <em>afterwards</em> you have to implement the actual VM, which decodes each instruction and performs the corresponding operation. And you have to constantly keep these in sync! Any mismatches between the compiler that emits the bytecode and the VM that executes it are often catastrophic and very hard to debug.</p><p>Historically, a bytecode VM has always been implemented the same way: a big-ass switch statement. You decode an instruction, and switch on its type to jump to the operation that needs to be performed. This is often a performance advantage against AST interpreters, because switching in practice is quite fast (particularly when implemented in C or C++ like most VMs are), and allows execution to happen linearly, without recursion.</p><p>This design, however, also has its fair share of shortcomings. Mike Pall, JIT-master extraordinaire and author of LuaJIT, gives a very insightful rundown of these issues on <a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html">this mailing list post from 2011</a>. Allow me to summarize for this blog: Besides the fact that the VM's instructions need to be kept in-sync with the compiler, the actual performance of the main VM loop in a language with many instructions is not great in practice because compilers usually struggle when compiling massive functions, and these functions <em>are</em> massive. They spill registers all over the place on each branch of the switch, because it's hard to tell which branches are hot and which ones are cold. With all the pushing and popping, the jump into the switch's branch often looks more like a function call, so a lot of the performance benefits of the virtual machine dissipate.</p><p>Mike was discussing C compilers in that post, but it's safe to assume that these problems are the same for a virtual machine implemented in Go. After a lot of testing, I can assure you that they are actually <em>much worse</em> because the Go compiler is not great at optimization. There’s always a trade-off between optimization and fast compile times, and the Go authors have historically opted for the latter.</p><p>One key issue for Go is that often the different branches of the switch statement are jumped to via <em>binary search</em> instead of a jump table. Switch jump table optimization was <a href="https://go-review.googlesource.com/c/go/+/357330">implemented surprisingly late on the compiler</a>, and in practice it is <em>very fiddly</em>, without any way to enforce it. You have to tweak the way the VM's instructions are encoded carefully to ensure that you're jumping in the VM's main loop, and you have no way to reliably check whether your virtual machine’s dispatch code has been properly optimized besides reviewing the generated assembly yourself.</p><p>Clearly, switch-based VM loops are not the state of the art for writing efficient interpreters, neither in Go nor in any other programming language. So what <em>is</em> the state of the art then? Well, when it comes to Go it turns out that there's nobody doing fast interpreters right now (at least nobody I can find). The people who are doing interesting work here, such as the <a href="https://github.com/tetratelabs/wazero"><code>wazero</code> WASM implementation</a> are focusing their performance efforts on JIT. So we’re going to have to innovate!</p><p>Outside of Go, the most interesting approach for interpreters implemented in C or C++ is <strong>continuation-style evaluation loops</strong>, as seen <a href="https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html">in this report from 2021 that implements this technique for parsing Protocol Buffers</a>. This involves implementing all the opcodes for the VM as freestanding functions that operate on the VM as an argument, with the return of the function being <em>a callback to the next step of the computation</em>. It does sound like something expensive and, huh, recursive, but the trick is that newer versions of LLVM allow us to mark functions as <em>forcefully</em> tail-called (see: https://en.wikipedia.org/wiki/Tail_call), so the resulting code is not recursively calling the VM loop but instead <em>jumping</em> between the operations and using the free-standing functions as an abstraction to control register placement and spillage. The most recent release of Python 3.14 actually <a href="https://docs.python.org/3.14/whatsnew/3.14.html#whatsnew314-tail-call">ships an interpreter based on this design</a>, boasting up to 30% improvement when executing Python code.</p><p>Unfortunately, this is not something we can do in Go because as we discussed earlier, the Go compiler is allergic to optimization. It <em>can</em> sometimes emit tail calls, but it needs to be tickled in just the right way, and this implementation simply does not work in practice unless the tail-calls are guaranteed at compilation time. But what if we keep the same design with free-standing functions for each instruction and instead of tail-calling, we forcefully return control to the evaluation loop after each one? This could be implemented very easily by not emitting our compiled program as “byte code”, but instead emitting <strong>a slice of function pointers to each instruction</strong>. The design may be a bit counter-intuitive, but it has a lot of very interesting properties.</p><p>First, the VM becomes trivial! It's just a few lines of code, and it doesn't have to worry about optimizing any large switch statements. It's just repeatedly calling functions one after the other! Here’s a simplified example, but if you check <a href="https://github.com/vitessio/vitess/blob/b05df12741adf1314839694e489e687e7ec6c6ea/go/vt/vtgate/evalengine/vm.go#L73-L98">the actual implementation in Vitess</a> you’ll see that a real virtual machine implementation is hardly more complicated than this.</p><pre data-language="go">func (vm *VirtualMachine) execute(p *Program) (eval, error) {
	code := p.code
	ip := 0

	for ip &lt; len(code) {
		ip += code[ip](vm)
		if vm.err != nil {
			return nil, vm.err
		}
	}
	if vm.sp == 0 {
		return nil, nil
	}
	return vm.stack[vm.sp-1], nil
}
</pre><p>All we need to return when executing each instruction is the offset for the instruction pointer <code>ip</code>. Most functions return <code>1</code>, which causes the next instruction to be executed, but by returning negative or positive values, you can implement all control flow, including loops and conditionals.</p><p>Besides the greatly simplified virtual machine, the second advantage of this approach is that the compiler <em>also</em> becomes trivial, because there is no bytecode! Instead, the compiler emits the individual instructions directly by pushing "callbacks" into a slice. There are no instruction opcodes to keep track off, no encoding to perform and nothing to keep in sync with the VM. <strong>Developing the compiler means developing the VM simultaneously</strong>, which greatly improves iteration speed and prevents a whole class of bugs that happen often when developing virtual machines.</p><pre data-language="go">func (c *compiler) emitPushNull() {
	c.emit(func(vm *VirtualMachine) int {
		vm.stack[vm.sp] = nil
		vm.sp++
		return 1
	})
}
</pre><p>As you may notice, there’s a bit of a hiccup here when it comes to modeling the instructions for a non-trivial language: if there's no instruction encoding, then we cannot have instructions with arguments.</p><p>This is a big problem in a language like C (traditionally used to implement most programming language interpreters), which is why this technique is never seen there. But it’s actually not a problem for us,  because the Go compiler actually supports <em>closures</em>! We can emit any instruction we want and the Go compiler will automatically capture its arguments inside the callback. We don't have to think about how to encode our arguments in the bytecode, and in fact, our arguments can be as complex as they need to be: the resulting callback will contain a copy of them created by the Go compiler. It's essentially a poor man's JIT, aided by the compiler, and it works amazingly well in practice, both performance-wise and for ergonomics.</p><p>Check out this compiler method that generates an instruction to push a <code>TEXT</code> SQL object from the input rows into the stack:</p><pre data-language="go">func (c *compiler) emitPushColumn_text(offset int, col collations.TypedCollation) {
	c.emit(func(vm *VirtualMachine) int {
		vm.stack[vm.sp] = newEvalText(vm.row[offset].Raw(), col)
		vm.sp++
		return 1
	})
}
</pre><p>Both the offset in the input <code>rows</code> array <em>and</em> the collation for the text are statically baked into the generated instruction!</p><h2 id="almost-statically-typed"><a href="#almost-statically-typed">Almost statically typed</a></h2><p>With the fully static typing for SQL expressions (derived from the type information in the planner) we get to design an extremely efficient virtual machine where every single instruction is specialized for the type of the operands it executes on. This is both the optimal and the simplest design for a VM because we never have to do type switching during evaluation. But we’re dealing with SQL here (or, more accurately, the SQL dialect of MySQL), so not everything is rainbows and unicorns. Very often it’s quite the opposite.</p><p>Let’s consider this wildly complex SQL expression: <code>-inventory.price</code>. That is, the negation of each of the values in the <code>inventory.price</code> column of our query. We know (thanks to our semantic analysis, and the schema tracker) that the type of the <code>inventory.price</code> column is <code>BIGINT</code>. So what could be the type of <code>-inventory.price</code>? Naive readers without experience in the magical world of SQL may believe the resulting type is <code>BIGINT</code>, but that’s not the case in practice!</p><p>The vast majority of the time, the negation of a <code>BIGINT</code> yields indeed another <code>BIGINT</code> value. But when the actual value of the <code>BIGINT</code> is -9223372036854775808 (i.e. the smallest value that can be represented in 64 bits), negating it promotes the value into a <code>DECIMAL</code>, instead of silently truncating it, or returning an error. You can see how this can easily throw a wrench in our statically compiled instructions for our virtual machine. Suddenly the static type checking we’ve computed is no longer valid because the types of the expression no longer depend on the types of the inputs, but on the actual <em>values</em> of the inputs. In order to continue evaluating the result of this negation, we’d always have to type-check again at runtime, defeating the whole point of static typing to begin with.</p><p>To work around this issue, we’re <em>not</em> introducing more type switches at runtime. We’re using a classic trick which can be seen all the time in JIT compiled code and very rarely, if ever, in virtual machines: <strong>de-optimization</strong>. There’s a small list of expressions where corner cases (e.g. overflow) can result in dynamic typing at runtime. Whenever this happens, we simply bail out of executing in our virtual machine and fall back to executing on the old AST evaluator, which has always performed type switching at runtime. This is very similar to what JIT compilers do when they detect that the runtime type of a value no longer matches the generated code they’ve emitted; they fall back from the native code to the virtual machine. In our case, we’re one step behind, falling back from the virtual machine to the AST interpreter, but the performance implications are the same. This design allows us to keep our interpreter executing statically typed code without any type switches at runtime. Here's an example of what integer negation looks like when compiled:</p><pre data-language="go">func (c *compiler) emitNeg_i() {
	c.emit(func(vm *VirtualMachine) int {
		arg := vm.stack[env.vm.sp-1].(*evalInt64)
		if arg.i == math.MinInt64 {
			vm.err = errDeoptimize
		} else {
			arg.i = -arg.i
		}
		return 1
	})
}
</pre><p>There is one significant drawback with this approach, however: the code for the AST interpreter can never be removed from Vitess. But this is, overall, not a bad thing. Just like most advanced language runtimes keep their virtual machine interpreter despite having a JIT compiler, having access to our classic AST interpreter gives us versatility. It can be used when we detect that an expression will be evaluated just <em>once</em> (e.g. when we use the evaluation engine to perform constant folding on a SQL expression). In those cases, the overhead of compiling and then executing on the VM trumps a single-pass evaluation on the AST. Lastly, when it comes to accuracy, being able to fuzz both the AST interpreter and the VM against each other has resulted in an invaluable tool for detecting bugs and corner cases.</p><h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2><p>This technique for virtual machine implementation is not fully novel (I’ve seen it used before for a rules-based authorization engine in the wild!), but as far as I can tell it has never been used in Go. Given the constraints of the language and the compiler, the technique yields spectacular results: the new SQL interpreter in Vitess is just <em>faster</em>. Faster to write, faster to maintain and faster to execute. The benchmarks speak for themselves:</p><h3 id="evalengine-performance-in-vitess-over-time"><a href="#evalengine-performance-in-vitess-over-time">Evalengine performance in Vitess over time</a></h3><p><picture><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-D588Aj2C.png?auto=compress%2Cformat" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-darkmode-BmvxW3Md.png?auto=compress%2Cformat" media="(prefers-color-scheme: dark)"><img alt="Benchmark results" height="1295" loading="lazy" src="https://planetscale-images.imgix.net/assets/benchmark-results-D588Aj2C.png?auto=compress%2Cformat" width="2361"></picture></p><p>Here we have a performance comparison of 5 different queries (ranging from very complex to very simple) between three implementations:</p><ol><li><strong>old</strong>, which is the original AST-based dynamic implementation of the <code>evalengine</code>.</li><li><strong>ast</strong>, which is the result of adding static type checking to the virtual machine and using them to partially optimize the AST evaluator.</li><li><strong>vm</strong>, which is the callback-based virtual machine implementation as discussed in this post.</li></ol><h3 id="recent-results-compared-with-mysql"><a href="#recent-results-compared-with-mysql">Recent results compared with MySQL</a></h3><p><picture><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-CvMaQMIM.png?auto=compress%2Cformat" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-darkmode-CDCX_2gs.png?auto=compress%2Cformat" media="(prefers-color-scheme: dark)"><img alt="Benchmark results With MySQL" height="1295" loading="lazy" src="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-CvMaQMIM.png?auto=compress%2Cformat" width="2361"></picture></p><p>This is the current performance of our evaluation engine pitted against the native C++ implementation in MySQL. Note that measuring the time that MySQL spends in evaluation is very tricky; these are not the total reponse times for a query, but the result of manual instrumentation in the <code>mysqld</code> server to ensure a fair comparison.</p><details><summary>Raw benchmark data</summary><div><pre>                                      │     ast      │                 vm                  │                  mysql                   │
                                      │    sec/op    │   sec/op     vs base                │    sec/op     vs base                    │
CompilerExpressions/complex_arith-32    162.75n ± 1%   50.77n ± 1%  -68.81% (p=0.000 n=10)   49.40n ±  5%  -69.64% (p=0.000 n=10+184)
CompilerExpressions/comparison_i64-32    30.30n ± 2%   16.95n ± 1%  -44.08% (p=0.000 n=10)   26.93n ± 22%  -11.12% (p=0.000 n=10+11)
CompilerExpressions/comparison_u64-32    30.57n ± 3%   17.49n ± 1%  -42.78% (p=0.000 n=10)   18.80n ±  9%  -38.53% (p=0.000 n=10+16)
CompilerExpressions/comparison_dec-32    70.75n ± 1%   52.58n ± 2%  -25.68% (p=0.000 n=10)   46.59n ±  5%  -34.14% (p=0.000 n=10+14)
CompilerExpressions/comparison_f-32      53.05n ± 1%   25.65n ± 1%  -51.64% (p=0.000 n=10)   27.75n ± 23%  -47.69% (p=0.000 n=10)
geomean                                  56.30n        28.94n       -48.60%                  31.76n        -43.58%

                                      │    ast     │                   vm                    │
                                      │    B/op    │    B/op     vs base                     │
CompilerExpressions/complex_arith-32    96.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_i64-32   16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_u64-32   16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_dec-32   64.00 ± 0%   40.00 ± 0%   -37.50% (p=0.000 n=10)
CompilerExpressions/comparison_f-32     16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)

                                      │    ast     │                   vm                    │
                                      │ allocs/op  │ allocs/op   vs base                     │
CompilerExpressions/complex_arith-32    9.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_i64-32   1.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_u64-32   1.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_dec-32   3.000 ± 0%   2.000 ± 0%   -33.33% (p=0.000 n=10)
CompilerExpressions/comparison_f-32     2.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
</pre></div></details><p>The results are stark: the pre-compiled SQL expressions when ran in the new VM are up to 20x times faster than the first implementation of SQL evaluation in Vitess, and for most cases, we've caught up with the performance of the C++ implementation in MySQL. One further detail which is not shown on the graphs, but can be seen on the raw benchmark data, is that the new virtual machine <strong>does not allocate memory</strong> to perform evaluation — a very nice side effect of the fully specialized instructions thanks to the static type checking.</p><p>Overall, we consider getting in the same performance ballpark as MySQL's C++ evaluation engine as a huge engineering success, particularly when the resulting implementation is so easy to maintain.<!-- --> <!-- -->There will always be a performance gap between Go and C++, arising from the trade-off of quality vs compilation speed in the Go compiler, and from the semantics of the language itself, but as we show here, this gap is not insurmountable. With expertise and careful design, it is possible to reap the many benefits of developing and deploying Go services without paying the performance penalty inherent in the language. In this specific case, we got there by having the capacity to perform semantic analysis and statically typing SQL expressions (something which MySQL does not do), and by choosing an efficient virtual machine design that uses the strengths of Go instead of fighting its limitations.</p><h3 id="addendum-so-why-not-jit"><a href="#addendum-so-why-not-jit">Addendum: So why not JIT?</a></h3><p>Inquiring minds may be wondering: what's next? Are we doing JIT compilation next? The answer is no. Although this design for a compiler and VM looks like an exceptional starting point for implementing a full JIT compiler <em>in theory</em>, in practice the trade-off between optimization and complexity doesn't make sense. JIT compilers are important for programming languages where their bytecode operations can be optimized into a very low level of abstraction (e.g. where an "add" operator only has to perform a native x64 <code>ADD</code>). In these cases, the overhead of dispatching instructions becomes so dominant that replacing the VM's loop with a block of JITted code makes a significant performance difference. However, for SQL expressions, and even after our specialization pass, most of the operations remain extremely high level (things like "match this JSON object with a path" or "add two fixed-width decimals together"). The overhead of instruction dispatch, as measured in our benchmarks, is less than 20% (and can possibly be optimized further in the VM's loop). 20% is not the number you're targetting before you start messing around with raw assembly for a JIT. So at this point my intuition is that JIT compilation would be a needlessly complex dead optimization.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What If We Made Advertising Illegal? (1049 pts)]]></title>
            <link>https://simone.org/advertising/</link>
            <guid>43595269</guid>
            <pubDate>Sat, 05 Apr 2025 17:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simone.org/advertising/">https://simone.org/advertising/</a>, See on <a href="https://news.ycombinator.com/item?id=43595269">Hacker News</a></p>
Couldn't get https://simone.org/advertising/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Register Allocation on AMD's RDNA 4 GPU Architecture (106 pts)]]></title>
            <link>https://chipsandcheese.com/p/dynamic-register-allocation-on-amds</link>
            <guid>43595223</guid>
            <pubDate>Sat, 05 Apr 2025 17:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/dynamic-register-allocation-on-amds">https://chipsandcheese.com/p/dynamic-register-allocation-on-amds</a>, See on <a href="https://news.ycombinator.com/item?id=43595223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Modern GPUs often make a difficult tradeoff between occupancy (active thread count) and register count available to each thread. Higher occupancy provides more thread level parallelism to hide latency with, just as more SMT threads help hide latency on a CPU. But while a CPU can use all of its SMT threads regardless of what code it's running, the same doesn't apply to GPUs. GPU ISAs offer a large number of very wide vector registers. Storing all registers for all thread slots would be impractical because register files must balance capacity with speed and die area usage.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp" width="824" height="545" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:545,&quot;width&quot;:824,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:17100,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39ad0e36-cde9-4af8-b104-5aeae0ae836e_824x545.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>For example, RDNA 4's ISA lets instructions address up to 256 vector general purpose registers (VGPRs). Each register is 1024 bits wide in wave32 mode, and each RDNA 4 SIMD has 16 thread slots. The SIMD would need a 512 KB register file to hold 256 registers for all 16 threads. In practice register requirements vary across different GPU workloads. RDNA 4, like many other GPUs, uses a smaller register file and allocates depending on what threads require. Code that needs a lot of registers can do so at the cost of less thread-level parallelism, while code that uses fewer registers can run more active threads and be less sensitive to latency. RDNA 4 desktop GPUs have a 192 KB register file per SIMD, so a GPU kernel can use all thread slots (achieve maximum occupancy) if it uses 96 or fewer vector registers.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp" width="1026" height="498" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:498,&quot;width&quot;:1026,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:8620,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702a8b22-ac95-4368-a706-3f4e3878e5a7_1026x498.webp 1456w" sizes="100vw"></picture></div></a></figure></div><p>A bigger register file obviously improves the occupancy and register usage tradeoff situation. RDNA increased SIMD register file capacity to 128 KB, up from 64 KB on GCN. RDNA 3 introduced a 192 KB register file configuration for high end GPUs, where die area is likely less of a concern. But that strategy isn’t efficient for raytracing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp" width="1456" height="969" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:969,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1253978,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F656c63e2-c55c-4c92-af1e-8f9d8bbf7a51_2163x1440.webp 1456w" sizes="100vw"></picture></div></a></figure></div><p>AMD notes that ray traversal and hit/miss handling have different VGPR requirements. AMD uses an inline raytracing model where all raytracing stages run within the same thread. A raytracing shader’s VGPR allocation has to be set to the maximum that any stage requires, because a thread’s register allocation remains static throughout its lifetime. Even if code that needs a lot of registers only accounts for a small part of execution time, that high VGPR allocation will limit active thread count for the duration of the workload. Raytracing is particularly latency sensitive, and AMD would like to run as many threads (rays) in parallel as possible to help absorb latency.</p><p><span>Therefore RDNA 4 introduces a new dynamic VGPR allocation mode. In this mode, a thread starts with a minimum VGPR allocation and changes it throughout it’s lifetime. Rather than specify how many VGPRs a shader will use, the driver tells GPU to launch it in dynamic VGPR mode. A chip-wide </span><code>SQ_DYN_VGPR</code><span> register directly sets active thread count per SIMD, or occupancy, rather than having that inferred from shader VGPR usage. </span><code>SQ_DYN_VGPR</code><span> also controls other dynamic VGPR mode parameters, like VGPR allocation block size and deadlock avoidance mode.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp" width="337" height="280" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:280,&quot;width&quot;:337,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4692,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8314d90c-5b1d-463f-9b3c-c854e48373f0_337x280.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>As defined in Linux kernel code. I couldn’t find references/usages in either Linux or LLVM, so I’m guessing what each field does</figcaption></figure></div><p><span>Each enabled thread slot gets a single reserved VGPR block, and a newly launched thread starts with just that VGPR block active. When the thread needs more registers, it requests a new VGPR count using a </span><code>s_alloc_vgpr</code><span> instruction. </span><code>s_alloc_vgpr</code><span> attempts to allocate more registers if called with a value higher than the current allocation, or frees registers if called with a lower value. Changing VGPR allocation affects the upper end of the usable VGPR range, just like with non-dynamic VGPR allocation. Hardware hands out VGPRs in blocks of 16 or 32, depending on how the driver sets up </span><code>SQ_DYN_VGPR</code><span>. A thread can allocate up to eight blocks, so the driver must select the larger block size and give up some allocation granularity if a thread needs to use more than 128 VGPRs.</span></p><p><span>Allocation requests don’t always succeed. </span><code>s_alloc_vgpr</code><span> sets the Scalar Condition Code (SCC) to indicate success, or clears it on failure. SCC is analogous to a flag register on CPUs, and is used for branching and add-with-carry. Shader code has to check SCC to determine if an allocation request succeeded. If an allocation request fails, a shader could in theory try to find other useful work to do while periodically retrying the allocation. But doing so would be quite complex, so in practice a shader will busy-wait until allocation succeeds.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp" width="1365" height="726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:726,&quot;width&quot;:1365,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:29748,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e369252-8055-4b9f-afb3-af9ba65b16d0_1365x726.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Example of dynamic register allocation used in the DirectX procedural geometry example</figcaption></figure></div><p>Therefore dynamic VGPR mode turns the occupancy question on its head. A SIMD can have as many active threads as the driver feels like, regardless of register allocation. But theoretical occupancy doesn’t tell the whole story. Threads can still get blocked waiting on VGPR allocation. A SIMD could have all thread slots filled, but some of those threads could be busy-waiting on VGPR allocation rather than making useful progress.</p><p>Busy-waiting can become more than a performance inconvenience. Dynamic VGPR allocation can lead to deadlock. AMD knows this, and describes how that can happen in RDNA 4’s ISA manual.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp" width="855" height="141" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:141,&quot;width&quot;:855,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18458,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa68b488d-2f6e-4362-bbd9-5a46bbff3236_855x141.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I think a deadlock case can be more general than what AMD describes. If every thread in a SIMD needs to allocate more registers, but hardware doesn’t have enough free registers to satisfy any request, every thread will get stuck forever. That’s a deadlock, even if there are technically registers available.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp" width="810" height="439" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:439,&quot;width&quot;:810,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6376,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bcbba48-90cc-48ef-a7c7-505eca11b196_810x439.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>AMD mitigates some deadlock scenarios with a deadlock avoidance mode. The ISA manual is light on details, only saying it reserves just enough VGPRs for one thread to reach maximum VGPR allocation at all times. Each thread can allocate up to eight VGPR blocks, and one block comes reserved with the thread slot, so deadlock avoidance mode would reserve 7 VGPR blocks. I believe deadlock avoidance mode works by only allowing one thread to allocate registers from the reserved pool at a time. In short:</p><ol><li><p>Base case: No reserved registers allocated. Any request can proceed</p></li><li><p>From (1), any combination of allocation requests from all threads will allow at least one thread (say thread A) to succeed</p></li><li><p>From (2), no other thread can allocate from the reserved pool, allowing thread A to increase its register allocation to the maximum should it need to.</p></li><li><p>Eventually A will leave its high register usage code section, or terminate completely, and thus free up registers for other threads to do the same.</p></li></ol><p>Needless to say, that situation isn’t great for performance because it can serialize useful work across threads. But getting to the finish line slowly is better than not getting there at all.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp" width="552" height="334" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:334,&quot;width&quot;:552,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6912,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F023a40ca-920e-4308-96dc-b4d78e7f60f5_552x334.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Deadlock avoidance mode isn’t foolproof. If the programmer manages to meet three conditions:</p><ol><li><p>Two threads need to allocate registers</p></li><li><p>The high register usage sections of both threads depend on each other, for example in a producer consumer model</p></li><li><p>No other thread can give up their registers until the two threads above make progress</p></li></ol><p>Then they can run into a deadlock even with deadlock avoidance mode enabled. Programmers should probably avoid cross-thread dependencies in dynamic VGPR mode, unless they’re confident threads only wait on each other in low VGPR usage sections.</p><p>As with many new features, dynamic VGPR mode isn’t a one-size-fits-all solution. It’s narrowly targeted to start, and can only be used with wave32 compute shaders. Graphics shaders like pixel and vertex shaders can only use the regular non-dynamic launch mode. The same goes for wave64 shaders of any type.</p><p>A workgroup of threads launched in dynamic VGPR mode will “take over” the equivalent of a GPU core. That would be a Workgroup Processor (WGP) in WGP mode, or a Compute Unit (CU) in CU mode. Thus dynamic and non-dynamic threads can’t coexist on the same GPU core.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp" width="325" height="240" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:240,&quot;width&quot;:325,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6238,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5a1bb28-cde0-43c1-b1f0-0858498cb05e_325x240.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Registers used to specify various compute program launch parameters</figcaption></figure></div><p><span>Dynamic VGPR mode may be less efficient at using register file capacity. Each enabled thread slot gets a reserved VGPR block, regardless of whether a thread is actually running in that slot. A workload that doesn’t have enough parallelism to fill all enabled thread slots would waste those reserved registers. Deadlock avoidance mode would set aside more registers that could have been easily allocated in non-dynamic mode. Drivers can reduce reserved register count by disabling deadlock avoidance mode or reducing thread slot count. Both of those options come with obvious downsides. In wave32 mode, non-dynamic register mode can allocate up to 256 registers in 24 entry blocks</span><sup>a</sup><span> on current RDNA 4 GPUs. That offers finer granularity than the 32 entry blocks needed to give a thread 256 registers in dynamic VGPR mode.</span></p><p><span>AMD isn’t the only GPU maker that lets a thread adjust register allocation mid-execution. Nvidia introduced a </span><code>setmaxnreg</code><span> PTX instruction in Hopper, and that’s carried forward to Blackwell consumer GPUs. </span><code>setmaxnreg</code><span> superficially acts like AMD’s </span><code>s_alloc_vgpr</code><span>, letting the calling thread request a different register allocation. However Nvidia’s dynamic register allocation works very differently from AMD’s, and is probably better called register reassignment. Nvidia for their part never gave this mechanism a name.</span></p><p><span>Nvidia doesn’t use a separate launch mode. Kernels always launch the regular way, with a specified register allocation that also determines how many threads they can run concurrently. For example a compute shader that uses 96 registers on Blackwell will only be able to run 5 concurrent threads in each SM sub-partition. After threads launch, they can call </span><code>setmaxnreg</code><span> to shift registers between threads in the same workgroup. Unlike </span><code>s_alloc_vgpr</code><span>, </span><code>setmaxnreg</code><span>‘s register pool is whatever the workgroup started out with. If every thread calls </span><code>setmaxnreg</code><span> and requested register count across threads is greater than what the workgroup started with, they will deadlock regardless of how much free space the register file may have.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp" width="724" height="274" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:274,&quot;width&quot;:724,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5532,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59c69e9a-d8ed-4e8e-ad9b-c8331939f2ad_724x274.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>As an aside, </span><code>setmaxnreg</code><span> is a PTX instruction. PTX in an intermediate level programming language for Nvidia GPUs with an assembly-like syntax. It isn’t assembly, which Nvidia calls SASS. However PTX is meant to give more control over emitted instructions than a C-like high level language. Therefore PTX instructions often have similarities with SASS instructions, and can offer hints about the underlying ISA.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png" width="1062" height="382" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:382,&quot;width&quot;:1062,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:60623,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42e6374a-f9cc-4617-af23-729cb6be2bbd_1062x382.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The semantics around </span><code>setmaxnreg</code><span> suggest Nvidia’s mechanism is geared towards tightly orchestrated register swapping between threads. It’s not like AMD’s free-flowing dynamic allocation behavior where different threads can be out-of-phase with each other, so to speak. Nvidia’s “warpgroup” likely refers to threads sharing the same SM sub-partition, and thus the same register file.</span></p><blockquote><p><span>The same </span><code>setmaxnreg</code><span> instruction must be executed by all warps in a warpgroup. After executing a </span><code>setmaxnreg</code><span> instruction, all warps in the warpgroup must synchronize explicitly before executing subsequent setmaxnreg instructions. If a </span><code>setmaxnreg</code><span> instruction is not executed by all warps in the warpgroup, then the behavior is undefined</span></p><p><a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#miscellaneous-instructions-setmaxnreg" rel="">Miscallenous Instructions, Parallel Thread Execution ISA Version 8.7</a></p></blockquote><p><span>A determined developer could emulate AMD’s initial dynamic VGPR state on Nvidia by with a workgroup that allocates all register file capacity in a SM, then immediately has every thread trim its allocation down to the minimum. But after that, synchronization requirements on Nvidia would make it difficult to emulate AMD’s independent allocation behavior. </span><code>setmaxnreg</code><span>‘s scalar-only input makes it harder to look up a desired allocation value from memory. Of course difficult doesn’t mean impossible. A register input can be emulated with a sufficient application of conditional branches, but let’s not think about that too much.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp" width="1456" height="969" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:969,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:825958,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbab9e37-ba96-4cfb-b7e8-17571e981aec_2163x1440.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Not Hopper or Blackwell, but have a Nvidia related image to spice things up. I’m sick of seeing AI generated images everywhere, so I’m going to start taking more pictures with my DSLR and post them</figcaption></figure></div><p>In exchange for less flexibility, Nvidia should have no problem mixing “dynamic” and regular threads on the same SM. Nvidia can also adjust register allocation with finer granularity than AMD. The latter can be especially important because Nvidia has smaller 64 KB register files, and waste from “slack” register file usage can be even more painful.</p><p>Nvidia’s register reassignment mechanism isn’t well suited for AMD’s raytracing use case. However, Nvidia’s raytracing design likely doesn’t need it. Nvidia hardware uses a DXR 1.0 raytracing model. If it works like Intel, raytracing stages execute as separate thread launches on the SMs. Regular vector register allocation that happens at each thread launch would already solve the problem AMD faces with all-in-one raytracing shaders.</p><p>Intel’s documentation explicitly states that raytracing stages execute as separate thread launches. But even if they didn’t, Intel would benefit less from dynamic register allocation than AMD. Intel GPUs used fixed register allocation until very recently. Each thread gets 128 registers whether it needs them or not. More recent GPUs like Battlemage add a “large GRF” mode that cuts occupancy in half to give each thread 256 registers. There’s no option in between.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp" width="1456" height="969" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:969,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:153496,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faec9a9ca-4273-4bbb-8ddb-00d2dc91d8e4_2163x1440.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Intel’s Arc B580</figcaption></figure></div><p>Therefore Intel can maintain full occupancy with a higher per-thread register count than either AMD or Nvidia. Dynamic VGPR allocation is only useful if it helps increase occupancy in the first place – that is, the GPU can’t achieve full occupancy with non-dynamic VGPR allocation. If Intel were to dynamically allocate registers, the very coarse register allocation granularity may result in a more threads getting blocked than on AMD.</p><p>AMD’s dynamic VGPR allocation mode is an exciting new feature. It addresses a drawback with AMD’s inline raytracing technique, letting AMD keep more threads in flight without increasing register file capacity. That in turn makes RDNA 4 less latency sensitive in raytracing workloads, likely with minimal power and area cost. Raytracing shaders that use more than 96 VGPRs are attractive targets for the dynamic VGPR feature.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp" width="1456" height="789" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:789,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:95692,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92ba099a-d6c3-4b1f-98b8-7a5dd1e43cb5_1920x1040.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Profiling Quake 2 RTX under Radeon Graphics Profiler. AMD chose to use fully inlined raytracing shaders, and no dynamic VGPR allocation, despite the shader being limited to 9 threads (out of 16 slots) due to VGPR usage.</figcaption></figure></div><p>Raytracing shaders on AMD can either inline all raytracing stages, or use an “indirect” mode where different stages are executed in separate function calls. So far, I’ve only seen AMD use dynamic VGPR allocation in indirect mode. Raytracing stages all take place within the same thread in both modes, but perhaps function call sites provide a convenient place to adjust VGPR allocation. After all, a function has clearly defined entry and exit points. AMD often prefers to inline raytracing stages to avoid function call overhead. I have not seen dynamic VGPR mode used when raytracing stages are inlined, even when raytracing shader occupancy is VGPR limited.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp" width="1456" height="358" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:358,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:40152,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e20d08-8e9b-417c-8622-f0ab5860bb52_2000x492.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The RX 9070 provided by AMD</figcaption></figure></div><p><span>Certainly </span><code>s_alloc_vgpr</code><span> isn’t limited to function call sites, so I wonder if future AMD drivers will be more trigger-happy with dynamic VGPR mode. Conversely, AMD uses dynamic VGPR allocation in indirect mode even when non-dynamic allocation could have achieved full occupancy. Doing so shouldn’t hurt performance, but it does suggest driver decisions aren’t so fine grained at the moment.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp" width="933" height="873" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:873,&quot;width&quot;:933,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:27596,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/160652329?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd581fedf-9944-4276-b294-03fdde3e6d2f_933x873.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Setting “Disable raytracing shader inlining” using AMD’s tools makes the driver use raytracing shaders with function calls, which also use dynamic register allocation. Done here to illustrate effect on occupancy</figcaption></figure></div><p><span>Generic compute workloads could benefit from dynamic VGPR mode too, assuming AMD does work to expose the feature through various toolchains. </span><a href="https://github.com/NVIDIA/cutlass/issues/2007" rel="">Some </a><span>of Nvidia’s GPGPU libraries take advantage of </span><code>setmaxnreg</code><span>, so there’s probably compute applications for AMD’s dynamic VGPR feature too.</span></p><p><span>At a higher level, features like dynamic VGPR allocation paint a picture where AMD’s GPU efforts are progressing at a brisk pace. It doesn’t feel like an easy feature to implement. Thread register allocation could be non-contiguous in the physical register file, complicating register addressing under the hood. Features like deadlock avoidance would demand additional work. With regards to raytracing, dynamic VGPR allocation shows there’s plenty of progress to be made within AMD’s single-shader raytracing model. Along with </span><a href="https://chipsandcheese.com/p/rdna-4s-out-of-order-memory-accesses" rel="">breaking false cross-wave memory dependencies</a><span>, AMD seems determined to keep stamping out performance limiters with each generation.</span></p><p><span>If you like the content then consider heading over to the </span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span> or </span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span> if you want to toss a few bucks to Chips and Cheese. Also consider joining the </span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p><ol><li><p><a href="https://www.amd.com/content/dam/amd/en/documents/radeon-tech-docs/instruction-set-architectures/rdna4-instruction-set-architecture.pdf" rel="">“RDNA 4” Instruction Set Architecture Reference Guide</a></p></li><li><p><a href="https://docs.nvidia.com/cuda/parallel-thread-execution/#miscellaneous-instructions-setmaxnreg" rel="">Nvidia setmaxreg</a></p></li></ol><p>a. RDNA 4’s ISA manual indicates the 24 register allocation granularity only applies to devices with 1536 VGPRs per SIMD, or 192 KB register files. Other RDNA 4 devices allocate VGPRs in blocks of 16 registers, and likely have a 128 KB register file. RDNA 3 used smaller 128 KB register files in lower end devices, reserving 192 KB register files for the highest end SKUs. As RDNA 4 SKUs with non-192 KB register files do not exist at the time of writing, there is no need to discuss them in the article proper. However, such devices may launch in the future and it’s something to be aware of.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exeter's unassuming co-op worker leads double life as 'Lord of the Logos' (142 pts)]]></title>
            <link>https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</link>
            <guid>43594396</guid>
            <pubDate>Sat, 05 Apr 2025 15:54:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941">https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</a>, See on <a href="https://news.ycombinator.com/item?id=43594396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><!-- Article Start--><p>The famous saying 'never judge a book by its cover' couldn't be more fitting for part-time Exeter Co-op worker <a data-content-type="news" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/news/devon-news/meet-christophe-szpajdel-exeter-co-410444" rel="Follow" target="_self">Christophe Szpajdel.</a> Behind the nondescript uniform and happy and warm welcoming smile lies a hidden talent that has seen the 54-year-old award-winning artist produce outstanding work for the likes of pop star Rihanna alongside renowned names in the world of the heavy metal scene, as well as fashion and films.</p> <p>The common thread between them all is striking logos which Belgium-born Christophe produces using the old school method of just a piece of paper and a pencil. You'll be more likely to find him sitting in the outdoors as that's where he feels most at ease and creative.</p> <p>My first encounter with Christophe - nickname Lord of the Logos i is at Heavitree Pleasure Ground in Exeter. The <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/weather">weather</a> is unusually warm for a March day, so Christophe has found himself a sunny spot outside the front of the Parklife Cafe.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044178" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>As I approach, he is busy working on a new logo called Exe'uber'ances which is the title of an exhibition he is participating in Exeter this summer.</p> <p>Knowing that his speciality is heavy metal, I expect to see him dressed in a black t-shirt brandishing a fearsome gothic inspired design. To my surprise, he is wearing a bright blue t-shirt emblazoned with yellow lettering. On closer inspection, it becomes apparent that Christophe is turning his talents to political protest t-shirts as the front reads 'make Russia small again', with an anti-Trump and vice-president JD Vance.</p> <p>He explains it was created in a 'moment of anger' and that he has Ukrainian heritage in his family. For his own personal satisfaction creates controversial drawings of American president Donald Trump that can only ever be kept under wraps to limit any damage to his career that has earned him the nickname 'Lord of the Logos'.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044199" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's life-long passion for art started when he was a schoolboy drawing wildlife. His art then turned in a new direction when he discovered English rock band Motörhead, much to the disapproval of his mum whose favourite artist was Barbara Streisand and his dad's being Elvis.</p> <p>It led to a love of heavy metal, particularly the black and death metal sub-genres. His two passions have since taken him all over the world. His work first came to wider international attention in the mid '90s off of the back of logos for the likes of Emperor, Old Man's Child and Enthroned. </p> <p>Since then he has continued to make a significant contribution to the extreme metal scene having drawn logos for hundreds of bands including Melechesh, Falkenbach, Aborted, Abigail Williams and Bloodshot Dawn. For 'fun', he has designed unofficial logos for the likes of Ed Sheeran and Bruno Mars.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044203" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos, on stage" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos, on stage</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe created his first logo at the tender age of 17 for a Polish band called Totustus back in 1987. Unfortunately, the band never achieved fame. </p> <p>The first 'important' logo he says he designed was in 1989 for Finland band Disgrace, but what he credits for getting his name out there was creating logos for Germany band Endseeker, a well-known death metal band, and Enthroned from Belgium.</p> <p>But his biggest claim to fame remains the global recognition he gained after designing a show-stopping logo for pop star Rihanna in 2016. One of his visually striking designs was projected onto a 100ft backdrop at the MTV VMA awards during a live performance of her single B*tch Better Have My Money.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="410479" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="411">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" alt="Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards</span>
</figcaption>
</figure> <p>Nothing can be more grounding than the fact he designed it at <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/sidmouth">Sidmouth</a> Library in between shifts at the Co-op in the town. The opportunity came following a chance encounter with a member of Rihanna's management team on the tube between Canada Water and London Paddington.</p> <p>But it isn't the logo he is the most proud of. Instead he says it is the one he designed for Norwegian black metal band Emperor, simply because it is 'readable and iconic'.</p> <p>"If I could create a logo for anyone it would be Muse. I would also like to do ones for Ed Sheeran, Calvin Harris and also Elbow who are one of my favourite bands.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044201" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="435">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" alt="The Emperor logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Emperor logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Explaining how to make the perfect logo, Christophe, who lives in the Stoke Hill area of Exeter, said: "They have to be fluid to the eye. You need harmony, flow, symmetry and for it to be pleasant to the eye and very stylish.</p> <p>"If something is off centre it looks distracting; I'm a bit of a perfectionist! I love the aesthetics of an arched logo.</p> <p>"I prefer my logos to be simple, but have a kick. They also need to have a certain readability. Using a calligraphy style means the letters blend together rather than letters in existing fonts."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044202" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="642">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" alt="The Exe'uber'ances logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Exe'uber'ances logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's reputation for designing logos means he receives commissions from all over the world. His finalised sketches are then digitised by graphic designer Faye Burn to speed up the process for clients. </p> <p>However, the industry is fiercely competitive which is a constant struggle for Christophe to battle against.</p> <p>He said: "Within the past 10 years, the industry has been ruined by cheap designers using a computer and changing existing logos into a different name. Stealing intellectual property is something I have experienced extremely frequently.</p> <p>"You can tell when all the detail has been done by hand rather than by a computer, and those 'designers' charge a much cheaper price which makes people more inclined to use them."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044200" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="820">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" alt="Christophe Szpajdel in his Co-op uniform" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel in his Co-op uniform</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>It means that Christophe relies on the steady income of his job at the Co-op serving customers. He is contracted to do 12 to 20 hours a week, currently at its store in Queen Street, but also can occasionally be seen doing shifts in Heavitree.</p> <p>He said: "The reason I will never be able to fulfil my dream to be living exclusively off my art is because of the competition there now is so I have to have two sources of income.</p> <p>"Working at the Co-op also helps me maintain contact with the outside world as otherwise you can be immersed in your own art world. As long as my tummy is full and I have a roof over my head, that is the most important thing."</p> <p>Being part-time at the Co-op enables Christophe to spend as much time as he can abroad exhibiting his work and also attending events and award ceremonies. In January, he was awarded the prestigious Artist of the Year 2025 International Prize at the Palazzo Pucci in Italy. </p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044179" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, with his latest award" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, with his latest award</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>The award is presented to a select group of artists who have distinguished themselves through their aesthetic research and the stylistic values of their artwork. Additionally, he has been nominated as one of the top 60 masters by the internationally renowned ArtTour International Magazine which will be a red carpet event.</p> <p>Significant clients Christophe have worked with recently include producing a logo for short film Framed in Blood by Chris Sheeran, an alternative logo design for band The Pretty Wild, a logo for Italian alternative model and designer Amigdala, and a t-shirt design to be a potentially worn at the film premiere of Turkish movie Pavlonya by Kadir Uzun. In May, Christophe will be hosting his first exhibition in Chile during the Metal Fest at the Movistar Arena.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044222" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" alt="Christophe Szpajdel presenting a logo to death metal band Heksen" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel presenting a logo to death metal band Heksen</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>However, he also remains true to his long-established Devon roots. From June 9 to 15, he will be among three artists taking part in an exhibition at Tabac Taphouse in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/exeter">Exeter</a>, as part of Art Week Exeter. He will also be participating in annual art event Devon Open Studios.</p> <p>Again with other local artists, he will be showcasing his work at Café Momus, located within Manor Street Galleries in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/plymouth">Plymouth</a>, from September 1 to 30. Christophe has also written books about his work, the first titled under his nickname Lord of the Logos with limited copies now available. His work has also featured in other books among other prestigious artists.rtists.</p><!-- Article End--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a word game. My mom thinks it's great. What do you think? (389 pts)]]></title>
            <link>https://www.whatsit.today/</link>
            <guid>43593789</guid>
            <pubDate>Sat, 05 Apr 2025 14:26:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whatsit.today/">https://www.whatsit.today/</a>, See on <a href="https://news.ycombinator.com/item?id=43593789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Loading daily challenge...</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Vision for WebAssembly Support in Swift (180 pts)]]></title>
            <link>https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</link>
            <guid>43593596</guid>
            <pubDate>Sat, 05 Apr 2025 13:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060">https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</a>, See on <a href="https://news.ycombinator.com/item?id=43593596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>As WebAssembly support has been developed by the Swift community and significantly improved over the years, I would like to put up a pitch for a vision describing WebAssembly support in Swift. Your feedback would be highly appreciated! Full vision text is included below, while <a href="https://github.com/swiftlang/swift-evolution/pull/2590">the corresponding PR is also available on GitHub</a>.</p>
<h2><a name="p-362448-introduction-1" href="#p-362448-introduction-1"></a>Introduction</h2>
<p>WebAssembly (abbreviated <a href="https://webassembly.github.io/spec/core/intro/introduction.html#wasm">Wasm</a>) is a virtual machine instruction set focused on portability, security, and high performance. It is vendor-neutral, designed and developed by <a href="https://w3.org/">W3C</a>. An implementation of a WebAssembly virtual machine is usually called a <strong>WebAssembly runtime</strong>.</p>
<p>One prominent spec-compliant implementation of a Wasm runtime in Swift is <a href="https://github.com/swiftwasm/WasmKit">WasmKit</a>. It is available as a Swift package, supports multiple host platforms, and has a simple API for interaction with guest Wasm modules.</p>
<p>An application compiled to a Wasm module can run on any platform that has a Wasm runtime available. Despite its origins in the browser, it is a general-purpose technology that has use cases in client-side and server-side applications and services. WebAssembly support in Swift makes the language more appealing in those settings, and also brings it to the browser where it previously wasn't available at all<sup><a href="#footnote-362448-1" id="footnote-ref-362448-1">[1]</a></sup>. It facilitates a broader adoption of Swift in more environments and contexts.</p>
<p>The WebAssembly instruction set has useful properties from a security perspective, as it has no interrupts or peripheral access instructions. Access to the underlying system is always done by calling explicitly imported functions, implementations for which are provided by an imported WebAssembly module or a WebAssembly runtime itself. The runtime has full control over interactions of the virtual machine with the outside world.</p>
<p>WebAssembly code and data live in completely separate address spaces, with all executable code in a given module loaded and validated by the runtime upfront. Combined with the lack of "jump to address" and a limited set of control flow instructions that require explicit labels in the same function body, this makes a certain class of attacks impossible to execute in a correctly implemented spec-compliant WebAssembly runtime.</p>
<h3><a name="p-362448-webassembly-system-interface-and-the-component-model-2" href="#p-362448-webassembly-system-interface-and-the-component-model-2"></a>WebAssembly System Interface and the Component Model</h3>
<p>The WebAssembly virtual machine has no in-built support for I/O; instead, a Wasm module's access to I/O is dependent entirely upon the runtime that executes it.</p>
<p>A standardized set of APIs implemented by a Wasm runtime for interaction with the host operating system is called <a href="https://wasi.dev/">WebAssembly System Interface (WASI)</a>. <a href="https://github.com/WebAssembly/wasi-libc">WASI libc</a> is a layer on top of WASI that Swift apps compiled to Wasm can already use thanks to C interop. The current implementation of Swift stdlib and runtime for <code>wasm32-unknown-wasi</code> triple is based on this C library. It is important for WASI support in Swift to be as complete as possible to ensure portability of Swift code in the broader Wasm ecosystem.</p>
<p>In the last few years, the W3C WebAssembly Working Group considered multiple proposals for improving the WebAssembly <a href="https://github.com/webassembly/interface-types">type system</a> and <a href="https://github.com/webassembly/module-linking">module linking</a>. These were later subsumed into a combined <a href="https://component-model.bytecodealliance.org/">Component Model</a> proposal thanks to the ongoing work on <a href="https://github.com/WebAssembly/WASI/blob/main/wasip2/README.md">WASI Preview 2</a>, which served as playground for the new design.</p>
<p>The Component Model defines these core concepts:</p>
<ul>
<li>
<p>A <strong>component</strong> is a composable container for one or more WebAssembly modules that have a predefined interface;</p>
</li>
<li>
<p><strong>WebAssembly Interface Types (WIT) language</strong> allows defining contracts between components;</p>
</li>
<li>
<p><strong>Canonical ABI</strong> is an ABI for types defined by WIT and used by component interfaces in the Component Model.</p>
</li>
</ul>
<p>Preliminary support for WIT has been implemented in <a href="https://github.com/swiftwasm/WasmKit/blob/0.0.3/Sources/WITTool/WITTool.swift">the <code>wit-tool</code> subcommand</a> of the WasmKit CLI. Users of this tool can generate <code>.wit</code> files from Swift declarations, and vice versa: Swift bindings from <code>.wit</code> files.</p>
<h2><a name="p-362448-use-cases-3" href="#p-362448-use-cases-3"></a>Use Cases</h2>
<p>We can't anticipate every possible application Swift developers are going to create with Wasm, but we can provide a few examples of its possible adoption in the Swift toolchain itself. To quote <a href="https://www.swift.org/gsoc2024/#building-swift-macros-with-webassembly">a GSoC 2024 idea</a>:</p>
<blockquote>
<p>WebAssembly could provide a way to build Swift macros into binaries that can be distributed and run anywhere, eliminating the need to rebuild them continually.</p>
</blockquote>
<p>This can be applicable not only to Swift macros, but also for the evaluation of SwiftPM manifests and plugins.</p>
<p>In the context of Swift developer tools, arbitrary code execution during build time can be virtualized with Wasm. While Swift macros, SwiftPM manifests, and plugins are sandboxed on Darwin platforms, with Wasm we can provide stronger security guarantees on other platforms that have a compatible Wasm runtime available.</p>
<p>The WebAssembly instruction set is designed with performance in mind. A WebAssembly module can be JIT-compiled or compiled on a client machine to an optimized native binary ahead of time. With recently accepted proposals to the Wasm specification it now supports features such as SIMD, atomics, multi-threading, and more. A WebAssembly runtime can generate a restricted subset of native binary code that implements these features with little performance overhead.</p>
<p>Adoption of Wasm in developer tools does not imply unavoidable performance overhead. With security guarantees that virtualization brings, there's no longer a need to spawn a separate process for each Swift compiler and SwiftPM plugin/manifest invocation. Virtualized Wasm binaries can run in the host process of a Wasm runtime, removing the overhead of new process setup and IPC infrastructure.</p>
<h2><a name="p-362448-goals-4" href="#p-362448-goals-4"></a>Goals</h2>
<p>As of March 2024 all patches necessary for basic Wasm and WASI Preview 1 support have been merged to the Swift toolchain and core libraries. Based on this, we propose a high-level roadmap for WebAssembly support and adoption in the Swift ecosystem:</p>
<ol>
<li>
<p>Make it easier to evaluate and adopt Wasm with increased API coverage for this platform in the Swift core libraries. Main prerequisite for that is setting up CI jobs for those libraries that run tests for WASI and also Embedded Wasm, where possible. As a virtualized embeddable platform, not all system APIs are always available or easy to port to WASI. For example, multi-threading, file system access, networking and localization need special support in Wasm runtimes and a certain amount of consideration from a developer adopting these APIs.</p>
</li>
<li>
<p>Improve support for cross-compilation in Swift and SwiftPM. We can simplify versioning, installation, and overall management of Swift SDKs for cross-compilation in general, which is beneficial not only for WebAssembly, but for all platforms.</p>
</li>
<li>
<p>Continue work on Wasm Component Model support in Swift as the Component Model proposal is stabilized. Ensure that future versions of WASI are available to Swift developers targeting Wasm.</p>
</li>
<li>
<p>Make interoperability with Wasm components as smooth as C and C++ interop already is for Swift. With a formal specification for Canonical ABI progressing, this will become more achievable with time. This includes consuming components from, and building components with Swift.</p>
</li>
<li>
<p>Improve debugging experience of Swift code compiled to Wasm. While rudimentary support for debugging exists in some Wasm runtimes, we aim to improve it and, where possible, make it as good as debugging Swift code compiled to other platforms.</p>
</li>
</ol>
<h3><a name="p-362448-proposed-language-features-5" href="#p-362448-proposed-language-features-5"></a>Proposed Language Features</h3>
<p>In our work on Wasm support in Swift, we experimented with a few function attributes that could be considered as pitches and eventually Swift Evolution proposals, if the community is interested in their wider adoption. These attributes allow easier interoperation between Swift code and other Wasm modules linked with it by a Wasm runtime.</p>
<h2><a name="p-362448-platform-specific-considerations-6" href="#p-362448-platform-specific-considerations-6"></a>Platform-specific Considerations</h2>
<h3><a name="p-362448-debugging-7" href="#p-362448-debugging-7"></a>Debugging</h3>
<p>Debugging Wasm modules is challenging because Wasm does not expose ways to introspect and control the execution of a Wasm module instance, so a debugger cannot be built on top of Wasm itself. Special support from the Wasm execution engine is necessary for debugging.</p>
<p>The current state of debugging tools in the Wasm ecosystem is not as mature as other platforms, but there are two main directions:</p>
<ol>
<li>
<p><a href="https://github.com/llvm/llvm-project/pull/77949">LLDB debugger with Wasm runtime</a> supporting GDB Remote Serial Protocol;</p>
</li>
<li>
<p><a href="https://book.swiftwasm.org/getting-started/debugging.html#enhanced-dwarf-extension-for-swift">Wasm runtime with a built-in debugger</a>.</p>
</li>
</ol>
<p>The first approach provides an almost equivalent experience to existing debugging workflows on other platforms. It can utilize LLDB's Swift support, remote metadata inspection, and serialized Swift module information. However, since Wasm is a Harvard architecture and has no way to allocate executable memory space at runtime, implementing expression evaluation with JIT in user space is challenging. In other words, GDB stub in Wasm engines need tricky implementations or need to extend the GDB Remote Serial Protocol.</p>
<p>The second approach embeds the debugger within the Wasm engine. In scenarios where the Wasm engine is embedded as a guest in another host engine (e.g. within a Web Browser), this approach allows seamless debugging experiences with the host language by integrating with the host debugger. For example, in cases where JavaScript and Wasm call frames are interleaved, the debugger works well in both contexts without switching tools. Debugging tools like Chrome DevTools can use DWARF information embedded in Wasm file to provide debugging support. However, supporting Swift-specific metadata information and JIT-based expression evaluation will require integrating LLDB's Swift plugin with these debuggers in some way.</p>
<p>In summary, debugging in the browser and outside of the browser context are sufficiently different activities to require separate implementation approaches.</p>
<h3><a name="p-362448-multi-threading-and-concurrency-8" href="#p-362448-multi-threading-and-concurrency-8"></a>Multi-threading and Concurrency</h3>
<p>WebAssembly has <a href="https://github.com/WebAssembly/threads">atomic operations in the instruction set</a> (only sequential consistency is supported), but it does not have a built-in way to create threads. Instead, it relies on the host environment to provide multi-threading support. This means that multi-threading in Wasm is dependent on the Wasm runtime that executes a module. There are two proposals to standardize ways to create threads in Wasm:</p>
<p>(1) <a href="https://github.com/WebAssembly/wasi-threads">wasi-threads</a>, which is already supported by some toolchains, runtimes, and libraries but has been superseded;</p>
<p>(2) The new <a href="https://github.com/WebAssembly/shared-everything-threads">shared-everything-threads</a> proposal is still in the early stages, but is expected to be the future of multi-threading in Wasm.</p>
<p>Swift currently supports two threading models in Wasm: single-threaded (<code>wasm32-unknown-wasi</code>) and multi-threaded using wasi-threads (<code>wasm32-unknown-wasip1-threads</code>). Despite the latter supporting multi-threading, Swift Concurrency defaults to a cooperative single-threaded executor due to the lack of wasi-threads support in libdispatch. Preparing for the shared-everything-threads proposal is crucial to ensure that Swift Concurrency can adapt to future multi-threading standards in Wasm.</p>
<h3><a name="p-362448-h-64-bit-address-space-9" href="#p-362448-h-64-bit-address-space-9"></a>64-bit address space</h3>
<p>WebAssembly currently uses a 32-bit address space, but <a href="https://github.com/WebAssembly/memory64/">64-bit address space</a> proposal is already in the implementation phase.</p>
<p>Swift supports 64-bit pointers on other platforms where available, however WebAssembly is the first platform where relative reference from data to code is not allowed. Alternative solutions like image-base relative addressing or "small code model" for fitting 64-bit pointer in 32-bit are unavailable, at least for now. This means that we need cooperation from the WebAssembly toolchain side or different memory layout in Swift metadata to support 64-bit linear memory support in WebAssembly.</p>
<h3><a name="p-362448-shared-libraries-10" href="#p-362448-shared-libraries-10"></a>Shared libraries</h3>
<p>There are two approaches to using shared libraries in the WebAssembly ecosystem:</p>
<ol>
<li>
<p><a href="https://emscripten.org/docs/compiling/Dynamic-Linking.html">Emscripten-style dynamic linking</a></p>
</li>
<li>
<p><a href="https://github.com/WebAssembly/component-model/blob/main/design/mvp/Linking.md">Component Model-based "ahead-of-time" linking</a></p>
</li>
</ol>
<p>Emscripten-style dynamic linking is a traditional way to use shared libraries in WebAssembly, where the host environment provides non-standard dynamic loading capabilities.</p>
<p>The latter approach cannot fully replace the former, as it is unable to handle dynamic loading of shared libraries at runtime, but it is more portable way to distribute programs linked with shared libraries, as it does not require the host environment to provide any special capabilities except for Component Model support.</p>
<p>Support for shared libraries in Swift means ensuring that Swift programs can be compiled in position-independent code mode and linked with shared libraries by following the corresponding dynamic linking ABI.</p>
<hr>

<ol>
<li id="footnote-362448-1"><p>Browser-specific use cases remain to be addressed in a separate document. <a href="#footnote-ref-362448-1">↩︎</a></p>
</li>
</ol>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compilers: Incrementally and Extensibly (2024) (120 pts)]]></title>
            <link>https://okmij.org/ftp/tagless-final/Compiler/index.html</link>
            <guid>43593088</guid>
            <pubDate>Sat, 05 Apr 2025 12:55:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://okmij.org/ftp/tagless-final/Compiler/index.html">https://okmij.org/ftp/tagless-final/Compiler/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43593088">Hacker News</a></p>
Couldn't get https://okmij.org/ftp/tagless-final/Compiler/index.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Earth's clouds are shrinking, boosting global warming (154 pts)]]></title>
            <link>https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</link>
            <guid>43592756</guid>
            <pubDate>Sat, 05 Apr 2025 12:08:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming">https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</a>, See on <a href="https://news.ycombinator.com/item?id=43592756">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Europe needs its own social media platforms to safeguard sovereignty (105 pts)]]></title>
            <link>https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</link>
            <guid>43592454</guid>
            <pubDate>Sat, 05 Apr 2025 11:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/">https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</a>, See on <a href="https://news.ycombinator.com/item?id=43592454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Social media has emerged as the central nervous system of global communication, shaping politics, culture, and identity. Yet, Europe’s digital public square is not its own. Over 80% of the continent’s social media activity flows through platforms headquartered in the United States—Meta (Facebook, Instagram), Alphabet (YouTube), and X (Twitter)—creating a dependency that undermines Europe’s autonomy.</p>



<p>Recently, it has become increasingly clear that European companies urgently need to build Europe’s own sovereign social media ecosystem to counter disinformation, protect democratic integrity, preserve cultural diversity, and reclaim control from US corporate and geopolitical interests. Europe’s sovereignty in the 21st century is at stake.</p>



<h2>The threat of US interference: Disinformation as a geopolitical weapon</h2>



<p>The 2016 Brexit referendum exposed how US-based actors exploited European vulnerabilities. For example, Cambridge Analytica harvested data from 87 million Facebook users—including millions of Europeans—to micro-target voters with divisive ads. Leaked documents revealed campaigns designed to inflame anti-EU sentiment, demonstrating how US corporate tools can destabilize European unity.</p>



<p>Moreover, false narratives about voter fraud propagated by US politicians on Twitter and Facebook flooded European networks, bolstering extreme movements. In Germany, the “Querdenker” movement leveraged these claims to protest COVID-19 measures, while in other countries, several disinformation groups backed by US billionaires amplified baseless accusations about election rigging.</p>



<p>It is important to understand that US platforms optimize for engagement and their owners interests, not truth. During France’s 2022 presidential race, YouTube’s algorithm disproportionately recommended far-right candidate Éric Zemmour, boosting his visibility despite his marginal polling. Researchers found that 60% of French-language election content on YouTube contained misinformation, much of it algorithmically amplified.</p>



<h2>US billionaire oligarchy problem</h2>



<p>American billionaires, including tech billionaires, wield outsized influence over European discourse. Elon Musk’s acquisition of Twitter (rebranded as X) led to the reinstatement of 62,000 banned accounts, including extremists, far-right figures like Germany’s Nikolai Nerling, who had spread anti-vaccine conspiracies, persons who committed several serious crimes in Europe, and persons who promote illegal activities such as rape and dehumanization of others. Meanwhile, Meta’s content moderation policies routinely ignore EU directives; in 2023, the European Commission accused Meta of failing to curb disinformation campaigns. Recently, several disinformation campaigns linked to US billionaires attacked EU officials on social media platforms, spreading false narratives and encouraging committing crimes (e.g., murdering officials or overthrowing governments in the EU). It has become clear that these platforms operate as extensions of US corporate power and the new US administration, prioritizing profit and political gains over Europe’s stability and safety.</p>



<h2>Data colonialism: US platforms exploit Europe</h2>



<h3><strong>GDPR vs the US surveillance state</strong></h3>



<p>While the EU’s <a href="https://mediascope.group/what-is-the-general-data-protection-regulation-gdpr/" title="GDPR. What is the General Data Protection Regulation?">General Data Protection Regulation (GDPR)</a> enshrines privacy as a fundamental right, US platforms remain bound by laws like the <a href="https://mediascope.group/the-us-cloud-act-and-risks-for-european-asian-and-african-companies/" title="The US CLOUD Act and risks for European, Asian and African companies">CLOUD Act</a>, which grants American authorities access to data stored anywhere in the world. In 2022, the European Data Protection Board fined Meta for transferring EU user data to US servers, citing risks of NSA surveillance. Despite the EU-US Data Privacy Framework, experts warn that European data remains vulnerable to US intelligence overreach.</p>



<h3><strong>Economic extraction</strong></h3>



<p>US platforms siphon billions from Europe’s digital economy. In 2022, Meta reported €4.3 billion in EU revenue but paid an effective tax rate of 8.5% through Irish loopholes—€2.5 billion less than standard EU corporate rates. Google and Apple similarly route profits through tax havens, depriving European governments of funds needed for tech innovation. This financial drain perpetuates Europe’s dependency, stifling homegrown competitors.</p>



<h3><strong>Erasing Europe’s diversity</strong></h3>



<p>US platforms homogenize culture by privileging English-language content aligning with the worldview of the current US presidential administration and US billionaires. More than 70% of trends on social media originate in the US, overshadowing local creators. European journalists and influencers struggle to compete with US influencers, while platforms like Instagram algorithmically promote American beauty standards, marginalizing Europe’s diverse cultural identities. The shrinking visibility of local users and their regional languages also threatens linguistic heritage of Europe.</p>



<h2>Europe is facing digital sovereignty crisis</h2>



<p>The US tech cold war has turned data into a strategic asset, yet Europe remains a digital colony. US platforms dominate critical infrastructure: 92% of European governments use Facebook for public communication, while Google’s search monopoly shapes access to information. This dependency leaves Europe exposed to geopolitical coercion. For instance, US platforms are involved in limiting and censoring pro-European content but promoting anti-European narratives that are aligned with US interests. Developing sovereign European platforms, including social media platforms and search engines, would ensure the sovereignty in technology, economy, information space, security and defense.</p>



<h2>Building on European strengths: The fediverse and beyond</h2>



<p>European companies and communities already host decentralized alternatives like Mastodon, a federated network powered by the homegrown Mastodon software. These GDPR-compliant tools allow users to control data and interconnect across servers—a model echoing the EU’s federalist values. However, fragmentation, lack of user-friendly UI and underfunding limit their reach. A unified EU initiative could fund these projects while the alliance of European companies and communities could merge these projects into a public-private platform.</p>



<p>It is in the best interest of the European Union to provide funding for European-owned social media platforms to ensure their development and European digital sovereignty.</p>



<h2>Network effects and innovation</h2>



<p>Critics often argue that Silicon Valley’s dominance is insurmountable, citing global statistics of Meta-owned platforms (Facebook, Instagram, Threads) and X. Yet Europe’s 450 million affluent users offer a critical mass. Moreover, Europe attracts people from other regions such as Asia, Africa and South America. Case studies from China (WeChat, Weibo, Xiaohongshu) show that sovereign platforms can thrive and expand globally.</p>



<p>Moreover, the EU is a regulatory superpower which can use legislation to support homegrown social media platforms. For example, the EU can mandate US “gatekeeper” platforms (per the Digital Markets Act) to interconnect with European alternatives, allowing cross-platform interactions. In addition, the EU could introduce EU-wide tax breaks for creators using European platforms in the form of “cultural exceptions”.</p>



<h2>Europe’s digital destiny</h2>



<p>The choice is stark: continue as a digital colony of US tech giants or forge a sovereign future. European social media platforms are not just a tool—they shield against disinformation, act as guardian of cultural diversity, and a pillar of strategic autonomy. By combining support and strategic interests with cutting-edge innovation, the EU can support the development of the homegrown social media ecosystem. The time to act is now, before the algorithms of Meta and X platforms write Europe’s next chapter for it.</p>



<hr>



<p>You can read more writings of Dawid Wiktor on his&nbsp;<a href="https://mediascope.group/?page_id=2567">Exec Profile</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emulating an iPhone in QEMU (217 pts)]]></title>
            <link>https://eshard.com/posts/emulating-ios-14-with-qemu</link>
            <guid>43592409</guid>
            <pubDate>Sat, 05 Apr 2025 10:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshard.com/posts/emulating-ios-14-with-qemu">https://eshard.com/posts/emulating-ios-14-with-qemu</a>, See on <a href="https://news.ycombinator.com/item?id=43592409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Start of the journey</h2>
<p>We started our journey with iOS emulation by looking at existing open-source solutions. We had successfully run <a href="https://github.com/alephsecurity/xnu-qemu-arm64">alephsecurity/xnu-qemu-arm64</a> before, but the project being read-only was concerning.</p>
<p>Then we tried <a href="https://github.com/TrungNguyen1909/qemu-t8030">TrungNguyen1909/qemu-t8030</a> and it had quite a few interesting features:</p>
<ul>
<li>the ability to actually restore iOS (using a second "companion" QEMU for USB connectivity)</li>
<li>running iOS 14</li>
<li>a more recent version of QEMU</li>
<li>a nice wiki on how to bring up the emulator</li>
</ul>
<p>With that project, we quickly managed to get a shell and ssh by modifying <code>System/Library/xpc/launchd.plist</code> so it was a great starting point.</p>
<p><img src="https://cms.eshard.com/uploads/image_16_ff7341d07a.png" alt="image (16).png"></p>
<p>We set our long term objective on getting a functional iOS emulated, with UI and at least the ability to execute some apps.</p>
<p>The first thing that bothered us with the <code>t8030</code> project was the fact that they added code in QEMU itself to patch the xnu kernel. We knew we were going to probably need more patching and wanted a cleaner way to do this.
As we had some experience with a jailbroken real iPhone, we looked into using <a href="https://github.com/palera1n/PongoOS">Pongo</a> to apply checkra1n patches, as this would allow us to remove any patching done in QEMU.</p>
<p>In a jailbreaking scenario, after getting pwned by checkmate, PongoOS is injected in SRAM and the checkra1n-kpf module is sent through USB.
Rather than bothering with early USB we chose to increase the SRAM on our emulated phone, and use PongoOS with checkra1n’s KPF module.</p>
<p>Executing PongoOS, first, was not without its issues, any boot code usually done by the bootrom or iboot would be missing, such as setting up the FPU before performing any double/float instructions. Skimming through <a href="https://developer.arm.com/documentation/dai0527/latest/">ARM documentation (section 5.4)</a> and a some <a href="https://github.com/citruz/pongoOS-QEMU/commit/033413bfaa6ebc4e1b8680b7548a3505fabe808b#diff-94255394208544c1bce0ef3fc2b955262dc6f5e8ed391005a521f28a0440a042L109-R117">Googling</a> helped.</p>
<p>Features introduced with A13 and later devices, not supported by Pongo, broke the pattern-matching of some patches. For example Pointer Authentication (PAC) instructions added <code>autda</code> / <code>xpacd</code> and Apple used a different slide.</p>
<p>Example with the infamous <a href="https://theapplewiki.com/wiki/Tfp0_patch">task_for_pid (tfp0)</a></p>
<pre><p><code><span>% ipsw macho info kernelcache.release.iphone10b.decompressed
</span>000: LC_SEGMENT_64 sz=0x006d8000 off=0x00000000-0x006d8000 addr=0xfffffff007004000-0xfffffff0076dc000 r-x/r-x   __TEXT
<!-- -->
<!-- -->Previous version (iphone-X (14.0_18A373_GM))
<!-- --> - tfp0 address 0xfffffff0076e9e70
<!-- -->   0xfffffff0076e9e70 - 0ffffffff007004000 = 0x6e5e70
<!-- --> - binary
<!-- -->   % hexdump -s 0x6e5e70 -n 8 kernelcache.release.iphone10b.decompressed
<!-- -->   06e5e70 7f70 07ec fff0 0017
<!-- -->
<!-- --> 	Raw: 	0x0017_fff0_07ec_7f70
<!-- --> 	Ghidra:  0xffff_fff0_70ec_7f70
<!-- -->
<!-- -->Later version (iphone-11 (14.0_18A5351d))
<!-- --> - tfp0 address 0x0xfffffff0076c9e40
<!-- -->   0xfffffff0076c9e40 - 0ffffffff007004000 = 0x6c5e40
<!-- --> - binary
<!-- -->   % hexdump -s 0x6c5e40 -n 8 kernelcache.research.iphone12b.decompressed
<!-- -->   06c5e40 1d70 00f0 307a 8010
<!-- -->	 
<!-- -->	Raw:	0x8010_307a_00f0_1d70
<!-- -->	Ghidra: 0xffff_fff0_07f0_5d70
</code></p></pre>
<p><img src="https://cms.eshard.com/uploads/unnamed2_cb01bfe271.png" alt="unnamed2.png"></p>

<p>Pongo allowed us to get access to existing checkra1n patches for multiple iOS versions, and although the dynamic application was interesting, it wasn't easy to read, modify or share. We wanted a more declarative approach, just like actual code patches.</p>
<p>So we made tools allowing us to diff between two <code>Mach-O</code>, and generate a text patch file with the assembly differences. The other program would take this patch file and simply apply to a binary.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250224_174126_cde0ed3bb5.png" alt="Screenshot_20250224_174126.png"></p>

<p>We then booted with Pongo, and used QEMU monitor to dump the memory sections patched by Pongo, then reassembled a patched kernel and finally generated a patch file with all the modifications.
The big patch was then split and commented properly, allowing us to review and control exactly what was patched in the kernel.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed_e4a4ff90f0.png" alt="unnamed.png"></p>

<h2>It’s dark in there</h2>
<p>We knew that on modern iPhones every graphical rendering ends up going through their <a href="https://developer.apple.com/documentation/metal"><code>Metal</code></a> API, which then needs an actual GPU. We believed emulating the Apple Silicon GPU would be way too complex and so we had two solutions in mind:</p>
<ul>
<li>Use software rendering: it seemed it was possible in older versions of iOS (using the gpu=0 bootarg)</li>
<li>Forwarding the Metal calls to a device capable of doing the rendering such as real iPhone or maybe a Mac with OSX</li>
</ul>
<p><img src="https://cms.eshard.com/uploads/graphic_architecture_8d6484c452.png" alt="graphic_architecture.png"></p>

<p>The software rendering seemed much easier, so we first looked into that. Unfortunately, the <code>XNU</code> kernel bootarg option was gone in iOS 14. After looking at the <code>QuartzCore</code> framework with Ghidra it seemed that the software rendering would only be called as a fallback if no <code>Metal</code> renderer was available.</p>
<p>In order to confirm that software rendering was indeed usable we worked on a real jailbroken iPhone, and patched <code>Quartzcore</code> to use software rendering. And indeed we confirmed it was possible! With these modifications, the UI was much slower, and had artifacts on parts which probably directly required <code>Metal</code> for rendering.</p>
<p><img src="https://cms.eshard.com/uploads/iphonex_sw_rendering_fae74d73b1.png" alt="iphonex_sw_rendering.png"></p>

<p>After these experiments, we knew we could get software rendering on QEMU, for anything not using <code>Metal</code> or <code>OpenGL</code> directly (so basically all <code>UIKit</code> apps).</p>
<p>We also explored the alternative of proxying the metal calls, working with 2 physical iPhones. What we did was:</p>
<ul>
<li>Parse all iOS headers with LLVM</li>
<li>All pointers to objective C object on the server is a stub pointer on the client</li>
<li>Generate automatic code to exchange structs and pointers</li>
<li>Hook all functions and methods</li>
<li>Forward every call to a server, executing them and returning the result</li>
</ul>
<p>We got some basic calls to go back and forth for Metal initialization, but we realized the road was still very long to get something to actually work. The Objetive C language and the <code>Metal</code> API are quite complex and have many features making this endeavor very complex.</p>
<p><img src="https://cms.eshard.com/uploads/metal_hook_da83384ee9.png" alt="metal_hook.png"></p>

<p>We ended up postponing this solution for a later time and thought starting with software rendering, even though it’s more restrictive, would help us advance with other problems faster.</p>
<p>Furthermore, we found out, iOS frameworks actually expose private APIs not present in the public headers. Although there are some ways to parse these and generate headers, they are most of the time not usable directly and complicate things further.</p>

<h2>IOSurface hunting</h2>
<p>After trying to make software rendering work, we decided we still needed at least a framebuffer device and the original t8030 QEMU didn’t implement one. However, we found <a href="https://github.com/ChefKissInc/QEMUAppleSilicon">a fork of the project</a> which was apparently working on IOMFB support, and decided to try debugging the display with it.</p>
<p><img src="https://cms.eshard.com/uploads/image_2_2c83473f84.png" alt="image (2).png"></p>

<p>And indeed while restoring iOS with that version, we could see the Apple logo and progress bar. However on normal boot the display would remain completely black so it was time for debugging!</p>
<p>Looking at the IOMFB kext in Ghidra and the framebuffer implementation in QEMU, it seemed that two modes were possible:</p>
<ul>
<li>A raw framebuffer at fixed hardware address was available (we guessed for early display)</li>
<li>A more complex API using registers to configure multiple planes and using dma to write surfaces data</li>
</ul>
<p>We first started experimenting with the raw framebuffer (which we later found out was how <code>Pongo</code> displayed stuff). Using it, we could display arbitrary ARGB surfaces, but when booting, that framebuffer was never written to by the system.</p>
<p>Therefore, we started looking into the second display mode. By enabling traces in the framebuffer implementation in QEMU, we could see that the kernel would set up graphical planes using registers but then nothing happened.</p>
<p>At this point we needed to debug why nothing was displayed after boot, even though the framebuffer seemed implemented and detected by the kernel.</p>

<h2>Address randomization</h2>
<p>Even though we had SSH access, we quickly got limited on what we could observe on the running system. We needed to be able to debug the kernel and userspace components with GDB.</p>
<p>For the kernel randomization, it was actually set up in the t8030 board initialization and allowed to turn it off entirely, so it was easy enough.</p>
<p>For userland we had two cases, randomization for executables and for dynamic libraries inside the dyld cache. For executables, simply patching the _load_machfile kernel function was enough to disable it.</p>
<p><img src="https://cms.eshard.com/uploads/image_20_ec79b11511.png" alt="image (20).png"></p>

<p>For the dynamic libraries we ended up handling it a bit differently.  The first thing to know is that every library is contained in a big binary blob called the dyld cache (located at <code>/System/Library/Caches/com.apple.dyld/dyld_shared_cache_arm64e</code>).</p>
<p>All libraries from this cache (called frameworks) are loaded once at boot and then mapped into processes memory space, even though dlopen is called with a path on the filesystem (like <code>/System/Library/Frameworks/QuartzCore</code>).</p>
<p>We noticed that address randomization actually happened only once at boot, and then a library was always loaded by every executable at the same address later on.</p>
<p>So all we had to do was to write some C tool which would dlopen every framework library and then use the <code>_dyld*</code> functions to list the loaded images and get their offset.</p>
<p>Using this solution (and also the reverse process while debugging with addresses coming from GDB), we could easily debug any library from the dyld cache. We were particularly interested with the <code>IOMFB</code> kext, the <code>backboardd</code> and <code>SpringBoard</code> daemons and the <code>QuartzCore</code> framework.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed5_ad1129e037.png" alt="unnamed5.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed4_1148ce717f.png" alt="unnamed4.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed3_6dc57084e9.png" alt="unnamed3.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed6_1acb33616d.png" alt="unnamed6.png"></p>

<pre><p><code><span>debugserver localhost:1111 –attach backboardd
</span>iproxy 1111:1111
<!-- -->gdb-multiarch -x "set architecture arch" -x "target remote localhost:1111"
</code></p></pre>
<p><strong>Note2:</strong> we later found out how to disable the dyld  cache by patching the kernel. Doing so allows to get look for virtual address directly in the dyld cache on the host (which we did using the great <a href="https://github.com/gimli-rs/object">object</a> Rust library from the Gimli project).</p>
<p><strong>Note1:</strong> to debug userspace you need to have a gdb server on the guest (see the debugserver package from <a href="https://github.com/ProcursusTeam">Procursus</a> for example). We started using gdb on the host but it’s somehow limited or bugged, and lldb seemed better.</p>

<h2>Please talk to me</h2>
<p>Armed with a working GDB we could see that  <code>backboardd</code> appeared to be starting properly, but we realized system logs would be a great help to know what was or wasn’t happening.</p>
<p>On a real iPhone, you can get the system logs (after pairing with you computer in USB) with the tool <code>idevicesyslog</code>. This pairing process involves the generation of key pair with the private key being stored on the phone. <code>lockdownd</code> uses this to verify the identity of the computer (after the user has authorized it once in the UI).</p>
<p>In our case, although we could interact with the phone through USB, <code>lockdownd</code> would not work properly. After some Ghidra sessions we realized that <code>lockdownd</code> was trying to use the <code>keybag</code> to store the private key, which would require the SEP we are lacking.</p>
<p>In order to go further, we created a shellcode injected in place of some presumably useless existing function. The code reads a pre-generated pair of private/public keys from the filesystem, and basically loads them every time <code>lockdownd</code> tries to get them from the <code>keybag</code>.</p>
<p>After much debugging (and some more patching to simulate the user trusting the computer and the phone being unlocked), we finally got it to work, and could pair with the emulated iPhone from our companion QEMU.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed7_d7cd518551.png" alt="unnamed7.png"></p>
<p>We found out later on you can also use a tool called oslog on the iphone directly to show the logs (didn’t seem to work at the time), although having the ability would give us much more than just the logs afterwards.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed8_a1c58cc9ab.png" alt="unnamed8.png"></p>
<p>Unfortunately, the logs revealed that <code>QuartzCore</code> seemed to be initializing properly, detecting the size of the display. It also showed that software rendering was being used as a fallback. So everything was working properly but still no display!</p>
<p>Note:  a single error about pixel format was showing and we worked around it by forcing RGBA (we’ll talk later about patching userspace), although this was removed later on.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed9_675d25af99.png" alt="unnamed9.png"></p>

<h2>PAC or not PAC</h2>
<p>Modifying <code>backboardd</code> to fix a pixel format error showed us we were going to have issues with multiple aspects of iOS security.</p>
<p>The signature check at load and runtime were fixed with kernel patches, however we still had issues with pointer authentication failure interrupting our modified <code>backboardd</code> execution.</p>
<p>Pointer authentication is a feature added with ARM8.3 which is used on the <code>t8030</code> board we were emulating and not on t8015 which we used before, so this was new to us.</p>
<p>Since we had foreseen a lot more patching in the future, we decided to tackle that issue at that moment, and try to find a way to bypass this to make our life easier.</p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_2e382a4e6a.png" alt="esr_pac.png"></p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_decoded_8ec8ba3ab6.png" alt="esr_pac_decoded.png"></p>
<p>At the time, we first thought we could just replace all the PAC instructions with either NOP or equivalent non PAC instructions.</p>
<p>Although this would have probably worked, it was a bit invasive and we later found out that you can build an ARM64 PAC binary two ways:</p>
<ul>
<li>Either use a dedicated PAC instruction set, which can only be executed on ARM8.3+ CPU</li>
<li>Or an “unused” instruction set which will be interpreted as PAC on ARM8.3+ or non and non PAC equivalent on earlier ARM versions</li>
</ul>
<p>After running some tests with buildroot and an ARM64 linux system, we verified this to be true and also verified that the binaries compiled for our t8030, used the backward compatible instruction set (architecture called arm64e).</p>
<p>So basically, all we had to do was to disable PAC enforcing in QEMU, and it would just run like non PAC code. Unfortunately this didn’t work, and at the time we were using QEMU 7, and found out that QEMU 8 didn’t have the same behavior.</p>
<p>So we did the natural thing, and started porting the current code base to QEMU 8.2.1. This was painful as a lot of code modified QEMU generic code, particularly the code handling the apple specific instructions <code>genter</code>/<code>gexit</code> and the GL exception levels.</p>
<p>After countless xnu panics, gdb attaching to the kernel, gdb attaching to qemu itself, and a desperate git bisect to find our last bug, we finally got iOS booting again on QEMU 8!
And with it, the ability to disable PAC, and modify any executable code, anywhere as we want it.</p>

<h2>The light at the end of the tunnel</h2>
<p>Since <code>backboardd</code> appeared to be working properly in the system logs, we had no choice but to dig further into backboard behavior to try and understand why it still wasn’t displaying anything.</p>
<p>Writing raw ARGB frames on these addresses allowed us to actually modify the display and write on the different graphical planes, so we knew that the display part was actually working properly.</p>
<p>We were left with a few possibilities, either:</p>
<ul>
<li><code>backboardd</code> was not writing anything for some reason</li>
<li>or it wasn’t writing at the proper addresses</li>
<li>or what was written was not valid</li>
</ul>
<p>To investigate, we started by trying to dump physical DMA memory, where <code>backboardd</code> was supposed to write, maybe it was written to but not displayed properly.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092231_cf2b7f405a.png" alt="Screenshot_20250225_092231.png"></p>

<p>To do this, we used a QEMU monitor to get the non contiguous addresses, and then a crude script to dump the physical memory and merge it all in a single file.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092657_bec571344d.png" alt="Screenshot_20250225_092657.png"></p>

<p>Finally using ffplay we tried interpreting that data as an ARGB frame but unfortunately we didn’t get anything interesting.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed10_1e6630e287.png" alt="unnamed10.png"></p>

<p>The second idea was to play with the surfaces allocated by iOS, getting the mapped address in <code>backboardd</code> memory with GDB (by breaking in iosurface_lock).</p>
<p>Searching for all these addresses for some clue, even though we had no idea what was being displayed or if something was even supposed to be displayed. We sometimes found strange things shaped apple an logo, but clearly something was wrong about the way the frames were being written.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed11_5f113d14b2.png" alt="unnamed11.png"></p>

<p>We did the same thing on a real iPhone 10, and we easily dumped perfect raw ARGB frames of the current display. It turned out that with iPhone 11 (so t8030) and later, surfaces appear to be passed compressed to the GPU which knows how to handle it.</p>
<p>But since this doesn’t happen on iPhone X (t8015), we tried modifying the DTB in the QEMU to pass 8015 as <code>chip-id</code> instead of 8030. And finally, we got some apple logo showing on screen after the boot!</p>
<p><img src="https://cms.eshard.com/uploads/unnamed12_7806fbaf2d.png" alt="unnamed12.png"></p>

<h2>Some progress…bar</h2>
<p>At this point, we were happy to finally get a logo displayed but that’s all it did, and the system logs were quite verbose with many system daemons and different libraries we didn’t know about.</p>
<p>All we could do at this point is guess which of the many errors shown in the logs were related to the current issue and fix them one by one until the behavior of the UI changed.</p>
<p>We noticed issues about user authentication and found the errors originated from the daemon <code>mobileactivationd</code> and the framework <code>SpringBoardFoundation</code>.</p>
<p>After patching these, the UI started to display a white progress bar similar to what is shown during the restore phase. The bar seemed to progress indeed but seemed stuck at 90% even after waiting for hours :\</p>

<h2>Patching them all</h2>
<p>Patching the userspace and the framework of the dyld cache was made possible by disabling address randomization. The same way we patched the kernel, we created textual patch files split for each binary / library that we applied with our internal tools.</p>
<p>However, we quickly realized we were going to patch the dyld cache quite often, and while trying modifications it was very painful to handle the 2GB binary file.</p>
<p>Patching it directly was not realistic, we all work on Linux so we cannot modify the nvme directly, and copying the 2GB back and forth through SSH would take forever.</p>
<p>So what we did was to update our internal diffing/patching tool to work with dyld, search the offset of the framework in the dyld cache blob.</p>
<p>Furthermore, we added an option to allow generating simple “dd” commands (and their revert), which can be applied directly on the iPhone (after remounting the fs in rw).</p>
<p>This method allowed us to test many iterations of modifications, and only required a reboot of iOS to have modifications of the dyld cache taken into account.</p>
<p><strong>Note:</strong> a few extra modifications of signature checks in the kernel were necessary for these to work.</p>

<h2>It’s alive!</h2>
<p>Before finding out how to fix the stuck progress bar, we had a little experiment with a system process called <code>PreBoard</code>. It appears to be normally only shown to the user if something goes wrong (like an update interrupting).</p>
<p>Because it’s a system application which draws directly using <code>backboardd</code> (just like <code>SpringBoard</code> would do), it can be started directly from the command line. And with it we get a white screen asking us to swipe to upgrade!</p>

<p><img src="https://cms.eshard.com/uploads/unnamed13_35a54c70e0.png" alt="unnamed13.png"></p>

<p>Armed with knowledge of a past project about using a VNC server on a physical iPhone, we tried adding it, and after quite a few failed attempts, managed to actually unlock that white screen (not by swiping but with a keyboard key).</p>
<p>Right after unlocking, QEMU would stop the execution because iOS was apparently using an illegal instruction. After some digging into <code>backboardd</code>, we found out that it uses the <code>vImage</code> framework to do some hardware accelerated graphical operations (like _vHorizontal_Scale_ARGB_8888_Accelerate).</p>
<p>These operations rely on AMX (Apple Matrix Coprocessor) which have a set of proprietary instructions which are not implemented in the emulated ARM CPU running in QEMU. Fortunately, the <code>vImage</code> framework provides alternative software versions for these calls which only use generic ARM instructions, so we did yet again some patching.</p>
<p>The result is a new screen with an actual <code>IOKit</code> window asking us to enter the passcod and working textbox, in which we can type with the VNC injected keyboard events.</p>

<p><img src="https://cms.eshard.com/uploads/unnamed14_9319700bbb.png" alt="unnamed14.png"></p>

<p>At this point we knew everything was ready for <code>SpringBoard</code> to display properly and it was only a matter of time before we got it to start.</p></div></div>]]></description>
        </item>
    </channel>
</rss>