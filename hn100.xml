<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 13 Jan 2026 10:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google removes AI health summaries after investigation finds dangerous flaws (186 pts)]]></title>
            <link>https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/</link>
            <guid>46595419</guid>
            <pubDate>Mon, 12 Jan 2026 23:05:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/">https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/</a>, See on <a href="https://news.ycombinator.com/item?id=46595419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Why AI Overviews produces errors</h2>
<p>The recurring problems with AI Overviews stem from a design flaw in how the system works. As we <a href="https://arstechnica.com/information-technology/2024/05/googles-ai-overview-is-flawed-by-design-and-a-new-company-blog-post-hints-at-why/">reported</a> in May 2024, Google built AI Overviews to show information backed up by top web results from its page ranking system. The company designed the feature this way based on the assumption that highly ranked pages contain accurate information.</p>
<p>However, Google’s page ranking algorithm has long struggled with SEO-gamed content and spam. The system now feeds these unreliable results to its AI model, which then summarizes them with an authoritative tone that can mislead users. Even when the AI draws from accurate sources, the language model can still <a href="https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/">draw incorrect conclusions</a> from the data, producing flawed summaries of otherwise reliable information.</p>
<p>The technology does not inherently provide factual accuracy. Instead, it reflects whatever inaccuracies exist on the websites Google’s algorithm ranks highly, presenting the facts with an authority that makes errors appear trustworthy.</p>
<h2>Other examples remain active</h2>
<p>The Guardian found that typing slight variations of the original queries into Google, such as “lft reference range” or “lft test reference range,” still prompted AI Overviews. Hebditch said this was a big worry and that the AI Overviews present a list of tests in bold, making it very easy for readers to miss that these numbers might not even be the right ones for their test.</p>
<p>AI Overviews still appear for other examples that The Guardian originally highlighted to Google. When asked why these AI Overviews had not also been removed, Google said they linked to well-known&nbsp;and reputable sources and informed people when it was important to seek out expert advice.</p>
<p>Google said AI Overviews only appear for queries where it has high confidence in the quality of the responses. The company constantly measures and reviews the quality of its summaries across many different categories of information, it added.</p>
<p>This is not the first controversy for AI Overviews. The feature has previously <a href="https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/">told</a> people to put glue on pizza and eat rocks. It has proven unpopular enough that users have <a href="https://arstechnica.com/google/2025/01/just-give-me-the-fing-links-cursing-disables-googles-ai-overviews/">discovered</a> that inserting curse words into search queries disables AI Overviews entirely.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fabrice Bellard's TS Zip (2024) (163 pts)]]></title>
            <link>https://www.bellard.org/ts_zip/</link>
            <guid>46593802</guid>
            <pubDate>Mon, 12 Jan 2026 20:26:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bellard.org/ts_zip/">https://www.bellard.org/ts_zip/</a>, See on <a href="https://news.ycombinator.com/item?id=46593802">Hacker News</a></p>
<div id="readability-page-1" class="page">


The <code>ts_zip</code> utility can
compress (and hopefully decompress) text files using a Large Language
Model. The compression ratio is much higher than with other
compression tools. There are some caveats of course:
<ul>
  <li>A GPU is necessary to get a reasonable speed. 4 GB of RAM is
    required. </li>
  <li>It is slower than conventional compressors (compression and
    decompression speed: up to 1 MB/s on a RTX 4090).</li>
  <li>Only text files are supported. Binary files won't be compressed
  much. The currently used language model (RWKV 169M v4) was trained
  mostly on English texts. Other languages are supported including
  source code.</li>
  <li>It is experimental so no backward compability should be expected
    between the various versions.</li>
  <li>See also <a href="https://www.bellard.org/ts_sms">ts_sms</a> which is optimized for the
    compression of small messages.</li>
</ul>

<h2>Compression Ratio</h2>
<p>
The compression ratio is given in bits per byte (bpb).
</p>
<table>
  <thead>
    <tr>
      <th aria-sort="ascending">File
      </th><th>Original size<br>(bytes)
      </th><th colspan="2"><a href="https://en.wikipedia.org/wiki/XZ_Utils">xz</a><br>(bytes) (bpb)
      </th><th colspan="2">ts_zip<br>(bytes) (bpb)
    </th></tr>
  </thead>
  <tbody>
    <tr><td><a href="https://en.wikipedia.org/wiki/Canterbury_corpus">alice29.txt</a>
      </td><td>152089
      </td><td>48492
      </td><td>2.551
      </td><td>21713
      </td><td>1.142
    </td></tr>
    <tr><td><a href="https://en.wikipedia.org/wiki/Calgary_corpus">book1</a>
      </td><td>768771
      </td><td>261116
      </td><td>2.717
      </td><td>137477
      </td><td>1.431
    </td></tr>
    <tr><td><a href="http://mattmahoney.net/dc/text.html">enwik8</a>
      </td><td>100000000
      </td><td>24865244
      </td><td>1.989
      </td><td>13825741
      </td><td>1.106
    </td></tr>
    <tr><td><a href="http://mattmahoney.net/dc/text.html">enwik9</a>
      </td><td>1000000000
      </td><td>213370900
      </td><td>1.707
      </td><td>135443237
      </td><td>1.084
    </td></tr>
    <tr><td><a href="https://mirrors.edge.kernel.org/pub/linux/kernel/v1.2/linux-1.2.13.tar.xz">linux-1.2.13.tar</a>
      </td><td>9379840
      </td><td>1689468
      </td><td>1.441
      </td><td>1196859
      </td><td>1.021
    </td></tr>
  </tbody>
</table>
<p>
Results and speed for other programs on enwik8 and enwik9 are
available at the <a href="http://www.mattmahoney.net/dc/text.html">Large
Text Compression Benchmark</a>.
</p>

<h2>Download</h2>

<ul>
  <li>Linux version: <a href="https://www.bellard.org/ts_zip/ts_zip-2024-03-02.tar.gz">ts_zip-2024-03-02.tar.gz</a>.</li>
  <li>Windows version: <a href="https://www.bellard.org/ts_zip/ts_zip-2024-03-02-win64.zip">ts_zip-2024-03-02-win64.zip</a>.</li>
</ul>

<h2>Technical information</h2>
<ul>
  <li><code>ts_zip</code> uses
  the <a href="https://github.com/BlinkDL/RWKV-LM">RWKV 169M v4</a>
  language model which is a good compromise between speed and
  compression ratio. The model is quantized to 8 bits per parameter
    and evaluated using BF16 floating point numbers.</li>
  <li>The language model predicts the probabilities of the next token. An
    arithmetic coder then encodes the next token according to the
    probabilities.</li>
  <li>The model is evaluated in a deterministic and reproducible
    way. Hence the result does not depend on the exact GPU or CPU
    model nor on the number of configured threads. This key point
    ensures that a compressed file can be decompressed using a
    different hardware or software configuration.</li>
</ul>

<hr>
Fabrice Bellard - <a href="https://bellard.org/">https://bellard.org/</a>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The chess bot on Delta Air Lines will destroy you (2024) [video] (235 pts)]]></title>
            <link>https://www.youtube.com/watch?v=c0mLhHDcY3I</link>
            <guid>46593395</guid>
            <pubDate>Mon, 12 Jan 2026 19:57:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=c0mLhHDcY3I">https://www.youtube.com/watch?v=c0mLhHDcY3I</a>, See on <a href="https://news.ycombinator.com/item?id=46593395">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Cowork: Claude Code for the rest of your work (958 pts)]]></title>
            <link>https://claude.com/blog/cowork-research-preview</link>
            <guid>46593022</guid>
            <pubDate>Mon, 12 Jan 2026 19:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://claude.com/blog/cowork-research-preview">https://claude.com/blog/cowork-research-preview</a>, See on <a href="https://news.ycombinator.com/item?id=46593022">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When we released Claude Code, we expected developers to use it for coding. They did—and then quickly began using it for <a href="https://x.com/claudeai/status/2009666254815269313" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e170" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e170">almost everything else</a>. This prompted us to build Cowork: a simpler way for anyone—<a href="https://www.lennysnewsletter.com/p/everyone-should-be-using-claude-code" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e173" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e173">not just developers</a>—to work with Claude in the very same way. Cowork is available today as a research preview for Claude Max subscribers on our <a href="https://claude.com/download" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e176" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e176">macOS app</a>, and we will improve it rapidly from here.</p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/UAmKyyZ-b9E" title="Introducing Cowork: Claude Code for the rest of your work"></iframe></p></figure><p>How is using Cowork different from a regular conversation? In Cowork, you give Claude access to a folder of your choosing on your computer. Claude can then read, edit, or create files in that folder. It can, for example, re-organize your downloads by sorting and renaming each file, create a new spreadsheet with a list of expenses from a pile of screenshots, or produce a first draft of a report from your scattered notes.&nbsp;</p><p>In Cowork, Claude completes work like this with much more agency than you’d see in a regular conversation. Once you’ve set it a task, Claude will make a plan and steadily complete it, while looping you in on what it’s up to. If you’ve used Claude Code, this will feel familiar—Cowork is built on the very <a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk" target="_blank" data-wf-native-id-path="638a9647-f7be-7484-3d32-f34fa167b82a" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="638a9647-f7be-7484-3d32-f34fa167b82a">same foundations</a>. This means Cowork can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&nbsp;&nbsp;</p><p>When you’ve mastered the basics, you can make Cowork more powerful still. Claude can use your existing <a href="https://claude.com/connectors" target="_blank" data-wf-native-id-path="638a9647-f7be-7484-3d32-f34fa167b82f" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="638a9647-f7be-7484-3d32-f34fa167b82f">connectors</a>, which link Claude to external information, and in Cowork we’ve added an initial set of <a href="https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview" target="_blank" data-wf-native-id-path="638a9647-f7be-7484-3d32-f34fa167b832" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="638a9647-f7be-7484-3d32-f34fa167b832">skills</a> that improve Claude’s ability to create documents, presentations, and other files. If you pair Cowork with <a href="https://claude.com/chrome" target="_blank" data-wf-native-id-path="638a9647-f7be-7484-3d32-f34fa167b835" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="638a9647-f7be-7484-3d32-f34fa167b835">Claude in Chrome</a>, Claude can complete tasks that require browser access, too.</p><p>Cowork is designed to make using Claude for new work as simple as possible. You don’t need to keep manually providing context or converting Claude’s outputs into the right format. Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel. It feels much less like a back-and-forth and much more like leaving messages for a coworker.&nbsp;</p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/WBNZpAWhw5E" title="Organize your desktop files with Cowork"></iframe></p></figure><h2>Stay in control</h2><p>In Cowork, you can choose which folders and connectors Claude can see: Claude can’t read or edit anything you don’t give it explicit access to. Claude will also ask before taking any significant actions, so you can steer or course-correct it as you need.&nbsp;</p><p>That said, there are still things to be aware of before you give Claude control. By default, the main thing to know is that Claude can take potentially destructive actions (such as deleting local files) if it’s instructed to. Since there’s always some chance that Claude might misinterpret your instructions, you should give Claude very clear guidance around things like this.&nbsp;</p><p>You should also be aware of the risk of “<a href="https://www.anthropic.com/research/prompt-injection-defenses" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e19c" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e19c">prompt injections</a>”: attempts by attackers to alter Claude’s plans through content it might encounter on the internet. We’ve built sophisticated defenses against prompt injections, but agent safety—that is, the task of securing Claude’s real-world actions—is still an active area of development in the industry.&nbsp;</p><p>These risks aren’t new with Cowork, but it might be the first time you’re using a more advanced tool that moves beyond a simple conversation. We recommend taking precautions, particularly while you learn how it works. We provide more detail in our <a href="https://support.claude.com/en/articles/13364135-using-cowork-safely" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e1a2" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e1a2">Help Center</a>.&nbsp;</p><h2>Looking forward</h2><p>This is a research preview. We’re releasing Cowork early because we want to learn what people use it for, and how they think it could be better. We encourage you to experiment with what Cowork can do for you, and to try things you don’t expect to work: you might be surprised! As we learn more from this preview, we plan to make lots of improvements (including by adding cross-device sync and bringing it to Windows), and we’ll identify further ways to make it safer.&nbsp;</p><p>Claude Max subscribers can try Cowork now by downloading the <a href="https://claude.com/download" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e1aa" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e1aa">macOS app</a>, then clicking on “Cowork” in the sidebar. If you're on another plan, you can <a href="https://forms.gle/mtoJrd8kfYny29jQ9" target="_blank" data-wf-native-id-path="d7e2b4a8-bd30-6427-2c54-02a35d22e1ad" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d7e2b4a8-bd30-6427-2c54-02a35d22e1ad">join the waitlist</a> for future access.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X Didn't Fix Grok's 'Undressing' Problem. It Just Makes People Pay for It (200 pts)]]></title>
            <link>https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/</link>
            <guid>46592827</guid>
            <pubDate>Mon, 12 Jan 2026 19:11:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/">https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/</a>, See on <a href="https://news.ycombinator.com/item?id=46592827">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>After creating thousands</span> of <a href="https://www.wired.com/story/grok-is-pushing-ai-undressing-mainstream/#intcid=_wired-verso-hp-trending_e6f38b98-522c-48d8-be73-d982c8e641e2_popular4-2">“undressing” pictures of women</a> and sexualized imagery of apparent minors, Elon Musk’s X has apparently limited who can generate images with Grok. However, despite the changes, the chatbot is still being used to create “undressing” sexualized images on the platform.</p><p>On Friday morning, the Grok account on X started responding to some users’ requests with a message saying that image generation and editing are “currently limited to paying subscribers.” The message also includes a link pushing people toward the social media platform’s $395 annual subscription tier. In one test of the system requesting Grok create an image of a tree, the system returned the same message.</p><p>The apparent change comes after days of growing outrage against and <a href="https://www.wired.com/story/x-grok-app-store-nudify-csam-apple-google-content-moderation/">scrutiny</a> of Musk’s X and xAI, the company behind the Grok chatbot. The companies face an increasing number of investigations from regulators around the world over the creation of nonconsensual explicit imagery and alleged sexual images of children. British prime minister Keir Starmer <a href="https://www.bbc.com/news/articles/ckgjzknepvzo">has not ruled out</a> banning X in the country and said the actions have been “unlawful.”</p><p>Neither X nor xAI, the Musk-owned company behind Grok, has confirmed that it has made image generation and editing a paid-only feature. An X spokesperson acknowledged WIRED’s inquiry but did not provide comment ahead of publication. X has previously <a data-offer-url="https://x.com/Safety/status/2007648212421587223" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://x.com/Safety/status/2007648212421587223&quot;}" href="https://x.com/Safety/status/2007648212421587223" rel="nofollow noopener" target="_blank">said</a> it takes “action against illegal content on X,” including instances of child sexual abuse material. While Apple and Google have previously banned apps with similar “nudify” features, <a href="https://www.wired.com/story/x-grok-app-store-nudify-csam-apple-google-content-moderation/">X and Grok remain available</a> in their respective app stores. xAI did not immediately respond to WIRED's request for comment.</p><p>For more than a week, users on X have been asking the chatbot to edit images of women to remove their clothes—often asking for the image to contain a “string” or “transparent” bikini. While a public feed of images created by Grok contained far fewer results of these “undressing” images on Friday, it still created sexualized images when prompted to by X users with paid for “verified” accounts.</p><p>“We observe the same kind of prompt, we observe the same kind of outcome, just fewer than before,” Paul Bouchaud, lead researcher at Paris-based nonprofit AI Forensics, tells WIRED. “The model can continue to generate bikini [images],” they say.</p><p>A WIRED review of some Grok posts on Friday morning identified Grok generating images in response to user requests for images that “put her in latex lingerie” and “put her in a plastic bikini and cover her in donut white glaze.” The images appear behind a “content warning” box saying that adult material is displayed.</p><p>On Wednesday, WIRED revealed that Grok’s stand-alone website and app, which is separate from the version on X, has also been used in recent months to create <a href="https://www.wired.com/story/grok-is-generating-sexual-content-far-more-graphic-than-whats-on-x/#intcid=_wired-verso-hp-trending_e6f38b98-522c-48d8-be73-d982c8e641e2_popular4-2">highly graphic and sometimes violent sexual videos</a>, including celebrities and other real people. Bouchaud says it is still possible to use Grok to make these videos. “I was able to generate a video with sexually explicit content without any restriction from an unverified account,” they say.</p><p>While WIRED’s test of image generation using Grok on X using a free account did not allow any images to be created, using a free account on Grok’s app and website still generated images.</p><p>The change on X could immediately limit the amount of sexually explicit and harmful material the platform is creating, experts say. But it has also been criticized as a minimal step that acts as a band-aid to the real harms <a href="https://www.wired.com/story/deepfake-survivor-breeze-liu-microsoft/">caused by nonconsensual intimate imagery</a>.</p><p>“The recent decision to restrict access to paying subscribers is not only inadequate—it represents the monetization of abuse,” Emma Pickering, head of technology-facilitated abuse at UK domestic abuse charity Refuge, said in a statement. “While limiting AI image generation to paid users may marginally reduce volume and improve traceability, the abuse has not been stopped. It has simply been placed behind a paywall, allowing X to profit from harm.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Iran has now been offline for 96 hours (155 pts)]]></title>
            <link>https://twitter.com/netblocks/status/2010750871274160361</link>
            <guid>46591974</guid>
            <pubDate>Mon, 12 Jan 2026 18:03:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/netblocks/status/2010750871274160361">https://twitter.com/netblocks/status/2010750871274160361</a>, See on <a href="https://news.ycombinator.com/item?id=46591974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Postal Arbitrage (403 pts)]]></title>
            <link>https://walzr.com/postal-arbitrage</link>
            <guid>46591708</guid>
            <pubDate>Mon, 12 Jan 2026 17:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://walzr.com/postal-arbitrage">https://walzr.com/postal-arbitrage</a>, See on <a href="https://news.ycombinator.com/item?id=46591708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://walzr.com/stamp.png"><img src="https://walzr.com/postmark.webp"></p><div><p>As of 2025, a stamp for a letter costs $0.78 in the United States. Amazon Prime sells items for less than that... <b>with free shipping!</b> Why send a postcard when you can send actual stuff? </p><p>I found all items under $0.78 with free Prime shipping — screws, cans, pasta, whatever. Add a free gift note. It arrives in 1 or 2 days. Done.</p><p>You're not only saving money. It's about sending something real. Your friend gets a random can of tomato sauce with your birthday note attached. They laugh. They remember you. They might even use it!</p><p>Prices updated 10 minutes ago</p></div><table><tbody><tr onclick="window.open('https://www.amazon.com/dp/B000NSFQIU', '_blank')"><td>$0.25</td><td><img src="https://m.media-amazon.com/images/I/81KoXfeCD1L._AC_UL320_.jpg" alt="Lime"></td><td>Lime</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B0010XRUV8', '_blank')"><td>$0.42</td><td><img src="https://m.media-amazon.com/images/I/81PYxHg5ehL._AC_UL320_.jpg" alt="Kool-Aid Unsweetened Tropical Punch Powdered Drink Mix, 0.16 oz. Packet"></td><td>Kool-Aid Unsweetened Tropical Punch Powdered Drink Mix, 0.16 oz. Packet</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B08KZ3LQX1', '_blank')"><td>$0.45</td><td><img src="https://m.media-amazon.com/images/I/71mXWAS5a2L._AC_UL320_.jpg" alt="Amazon Grocery, Brown Gravy Mix, 0.87 Oz (Previously Happy Belly, Packaging May Vary)"></td><td>Amazon Grocery, Brown Gravy Mix, 0.87 Oz (Previously Happy Belly, Packaging May Vary)</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B0000EXX14', '_blank')"><td>$0.47</td><td><img src="https://m.media-amazon.com/images/I/612TH8f2GqL._AC_UL320_.jpg" alt="Maruchan Ramen Noodle Soup, Beef, 3 oz"></td><td>Maruchan Ramen Noodle Soup, Beef, 3 oz</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B001L1KRNC', '_blank')"><td>$0.49</td><td><img src="https://m.media-amazon.com/images/I/71MckCseqVL._AC_UL320_.jpg" alt="Lemon"></td><td>Lemon</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B0014E2OF0', '_blank')"><td>$0.50</td><td><img src="https://m.media-amazon.com/images/I/71zHXHlEnJL._AC_UL320_.jpg" alt="LA MODERNA, Vermicelli Pasta, 7 oz (Pack of 1) | Enriched Durum Wheat Semolina | Kosher, Non-GMO, Iron and Vitamin-Fortified | Thin Vermicelli Noodles for Soups, Broths, and Quick Meals"></td><td>LA MODERNA, Vermicelli Pasta, 7 oz (Pack of 1) | Enriched Durum Wheat Semolina | Kosher, Non-GMO, Iron and Vitamin-Fortified | Thin Vermicelli Noodles for Soups, Broths, and Quick Meals</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B001AXCY46', '_blank')"><td>$0.51</td><td><img src="https://m.media-amazon.com/images/I/4178dp3xHEL._AC_UL320_.jpg" alt="Simpson Strong-Tie H2.5A H2.5A 18-Gauge Galvanized Hurricane Tie"></td><td>Simpson Strong-Tie H2.5A H2.5A 18-Gauge Galvanized Hurricane Tie</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B000NSKB7Q', '_blank')"><td>$0.56</td><td><img src="https://m.media-amazon.com/images/I/818y42pc78L._AC_UL320_.jpg" alt="Russet Potato, 1 Each"></td><td>Russet Potato, 1 Each</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B0012JQD5Y', '_blank')"><td>$0.58</td><td><img src="https://m.media-amazon.com/images/I/617GgGMY8+L._AC_UL320_.jpg" alt="Apple Barrel Acrylic Paint in Assorted Colors (2 Ounce), 20504 Black"></td><td>Apple Barrel Acrylic Paint in Assorted Colors (2 Ounce), 20504 Black</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B07TSCWN1P', '_blank')"><td>$0.70</td><td><img src="https://m.media-amazon.com/images/I/71KDBIQe0OL._AC_UL320_.jpg" alt="Amazon Grocery, Tomato Sauce, 8 Oz (Previously Amazon Fresh, Packaging May Vary)"></td><td>Amazon Grocery, Tomato Sauce, 8 Oz (Previously Amazon Fresh, Packaging May Vary)</td></tr><tr onclick="window.open('https://www.amazon.com/dp/B000R4B6GQ', '_blank')"><td>$0.77</td><td><img src="https://m.media-amazon.com/images/I/71oeILLx2CL._AC_UL320_.jpg" alt="Yoplait Original Low Fat Strawberry Yogurt Cup, Made with Real Fruit, 6 oz"></td><td>Yoplait Original Low Fat Strawberry Yogurt Cup, Made with Real Fruit, 6 oz</td></tr></tbody></table><div><p>In 2023, I ordered $1 cans of beans to a bunch of extended family members. It ignited our family group chat for a few weeks and everyone was super into it. Pictures of beans started rolling in. Then <i>they</i> started sending random stuff to each other. An asbestos warning label, cookies, a tin of sardines. Someone even sent a pregnancy test to my grandmother. </p><p><img src="https://walzr.com/grandma.webp"></p></div><p>This site is not affiliated with or endorsed by Amazon, obviously! </p><p><a href="https://walzr.com/"><img src="https://walzr.com/atoz.png"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AI in SolidWorks (163 pts)]]></title>
            <link>https://www.trylad.com</link>
            <guid>46591100</guid>
            <pubDate>Mon, 12 Jan 2026 16:56:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trylad.com">https://www.trylad.com</a>, See on <a href="https://news.ycombinator.com/item?id=46591100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><div><div><p><span>LAD (Language-Aided Designer)</span></p><p>A SolidWorks add-in to design with natural language using AI</p></div><p><img src="https://www.trylad.com/Tan.png" alt="Backed by Y Combinator"></p></div><div><p>Describe your design in plain language and LAD will translate it into SolidWorks operations, creating sketches, features, and assemblies all through natural conversation. LAD uses screenshots and the feature tree to understand your model's current state, verifying operations were completed correctly and correcting mistakes.</p></div><div><div><div><p><img src="https://www.trylad.com/screenshots/ESP.png" alt="LAD visual context with screenshots and feature tree analysis"></p></div><div><p>Design from Documentation and Images</p><p>Provide documentation files, images, or examples of previous parts and assemblies, and LAD will intelligently read and use them.</p></div></div><div><div><p><img src="https://www.trylad.com/images/macro.png" alt="LAD macro writing and execution"></p></div><div><p>Write and Run Macros</p><p>LAD can write and run VBA macros for reproducibility and niche functionality not covered by standard LAD tools. When writing macros, LAD searches SolidWorks documentation and examples to better understand the API.</p></div></div><div><div><p><img src="https://www.trylad.com/screenshots/NEMA.png" alt="LAD complete SolidWorks API integration"></p></div><div><p>Permissioning and Versioning</p><p>LAD stores checkpoints so you can revert unwanted changes, lets you control which commands run automatically, and uses rules you provide to guide the AI as it works.</p></div></div></div><div><p><h2>Questions &amp; Answers</h2></p><div><ul><li><p>LAD (Language-Aided Designer) is a system that integrates directly into SolidWorks as an Add-in and can create sketches, features, macros, and other CAD objects.</p></li><li></li><li></li><li></li><li></li></ul></div></div><section><h2>LAD Changelog</h2></section></div><section><p>Try LAD now.</p></section></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TimeCapsuleLLM: LLM trained only on data from 1800-1875 (611 pts)]]></title>
            <link>https://github.com/haykgrigo3/TimeCapsuleLLM</link>
            <guid>46590280</guid>
            <pubDate>Mon, 12 Jan 2026 16:04:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/haykgrigo3/TimeCapsuleLLM">https://github.com/haykgrigo3/TimeCapsuleLLM</a>, See on <a href="https://news.ycombinator.com/item?id=46590280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">TimeCapsule LLM</h2><a id="user-content-timecapsule-llm" aria-label="Permalink: TimeCapsule LLM" href="#timecapsule-llm"></a></p>
<p dir="auto"><em>A language model trained <strong>from scratch</strong> exclusively on data from certain places and time periods to reduce modern bias and emulate the voice, vocabulary, and worldview of the era.</em></p>
<p dir="auto">Imagine if an AI model didnt just pretend to be historical but actually was.</p>
<p dir="auto">v0 and v0.5 built on <a href="https://github.com/karpathy/nanoGPT">nanoGPT by Andrej Karpathy</a> Core training scripts and model architecture are his work.</p>
<p dir="auto">v1 built on <a href="https://huggingface.co/microsoft/phi-1_5" rel="nofollow">Phi 1.5 by Microsoft</a></p>
<p dir="auto"><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" rel="nofollow">Hugging Face Link</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Behavior &amp; Limitations</h2><a id="user-content-model-behavior--limitations" aria-label="Permalink: Model Behavior &amp; Limitations" href="#model-behavior--limitations"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v0</strong></h3><a id="user-content-v0" aria-label="Permalink: v0" href="#v0"></a></p>
<p dir="auto">Early prompts show the model responding with 1800's language and behavior.
Example: Prompt: "Who art Henry?" and it replied "I know that man, I have did not a black, the storm."</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Sample Output"></a></p>
<ul dir="auto">
<li>No mention of modern concepts</li>
<li>Mostly era-accurate vocabulary</li>
<li>Sentences are mostly incoherent (expected for ~187MB training data)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v0.5</strong></h3><a id="user-content-v05" aria-label="Permalink: v0.5" href="#v05"></a></p>
<p dir="auto">A significant improvement over v0.</p>
<ul dir="auto">
<li>Victorian writing style, proper punctuation, mostly grammatical sentences</li>
<li>Still high factual hallucination rate</li>
<li>OCR noise (“Digitized by Google”) still present in outputs</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v1</strong></h3><a id="user-content-v1" aria-label="Permalink: v1" href="#v1"></a></p>
<p dir="auto">First model to recall and connect a real historical event with an actual figure from the dataset.</p>
<p dir="auto">Example: Prompt: "It was the year of our Lord 1834"</p>
<p dir="auto">The output: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity"</p>
<p dir="auto">At first I assumed that a protest might have coincidentally taken place the same year but take a look at this: <a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/1834protest.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/1834protest.png" alt="1834protest"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2mini-eval1</strong></h3><a id="user-content-v2mini-eval1" aria-label="Permalink: v2mini-eval1" href="#v2mini-eval1"></a></p>
<p dir="auto">Trained using a 15GB sample from v2's 90GB dataset.
Model trained to 10K steps only.</p>
<p dir="auto">There was an issue with tokenization that causes output to look like this:</p>
<p dir="auto">PROMPT:
Who is Charles Dickens?</p>
<p dir="auto">W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht</p>
<p dir="auto">Corrected:</p>
<p dir="auto">"Who is Charles Dickens? Does that work more of his excellent stirring, in his plays, in the Great Company's farm? What I have yet to quote from Jack Pickett? Do you not know that they were a species of galloping, or sawing of their breasts, or what was to be done about the time when Jackson was looking on the window? What is the success of an Englishman, and which his son has not been discovering to me, whereby to accomplish such a weight? Did you ever make a passage into the old roadway, or to an anchor-breeze at the foot of our boat, which you must leave us? The fact is, that whether the wind would rise up from the plain on Saturday night or noontide, or till the north, or otherwise, we shall be compelled to describe a formidable barrier, with the same effects as the present. In this situation, at least, it is not too much to say that we have left that room. I believe there are three copies in the 'Five Hundred-fold,' to be referred to, as the first number of our readers who wish t[o]...”</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2mini-eval2</strong></h3><a id="user-content-v2mini-eval2" aria-label="Permalink: v2mini-eval2" href="#v2mini-eval2"></a></p>
<p dir="auto">Trained using the same 15GB sample used for training eval1.
Model is again trained to 10K steps only.</p>
<p dir="auto">PROMPT:Charles Darwin</p>
<p dir="auto">Charles DarwinECCEMACY. Sir, — The following case is interesting to me : — I was in London a fortnight, and was much affected with an attack of rheumatism. The first attack of rheumatism was a week before I saw you, and the second when I saw you, and the third when I saw you, and the third in the same time. The second attack of gout, however, was not accompanied by any febrile symptoms, but was accompanied with an increased flow of urine, and with a more copious discharge of urine. The third attack was an hour after I saw you, and was succeeded by a return of a paroxysm of gout, and a more rapid return of the gout. The fourth attack was also accompanied by a fever, but was not always accompanied by any febrile symptoms. The third attack of gout was a fortnight after you had been ill, and the fourth was followed by a paroxysm of gout. The fourth attack was a fortnight after you were attacked, and was accompanied by a sense</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Datasets</h2><a id="user-content-datasets" aria-label="Permalink: Datasets" href="#datasets"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2</strong></h3><a id="user-content-v2" aria-label="Permalink: v2" href="#v2"></a></p>
<ul dir="auto">
<li>90GB of 1800-1875 London texts</li>
<li>136,344 documents</li>
<li>The full 90GB is not avalaible yet as it hasn't been tokenized but you can find a 15GB sample here: <a href="https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB" rel="nofollow">https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bias Stats</h3><a id="user-content-bias-stats" aria-label="Permalink: Bias Stats" href="#bias-stats"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Pronoun bias"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Geographic bias"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Temporal bias"></a></p>
<p dir="auto">Refer to <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json">v2 bias report</a> for more info.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to Use" href="#how-to-use"></a></p>
<p dir="auto">This project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 1: Gather and Prepare Historical Texts</h3><a id="user-content-step-1-gather-and-prepare-historical-texts" aria-label="Permalink: Step 1: Gather and Prepare Historical Texts" href="#step-1-gather-and-prepare-historical-texts"></a></p>
<ul dir="auto">
<li>Collect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850)</li>
<li>Keep them within your chosen time/place window</li>
<li>Clean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 2: Build a Custom Tokenizer</h3><a id="user-content-step-2-build-a-custom-tokenizer" aria-label="Permalink: Step 2: Build a Custom Tokenizer" href="#step-2-build-a-custom-tokenizer"></a></p>
<ul dir="auto">
<li>Run train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.</li>
<li>This will give you vocab.json and merges.txt</li>
<li>Thes files define vocab and merge rules for your model</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 3: Train Your Model</h3><a id="user-content-step-3-train-your-model" aria-label="Permalink: Step 3: Train Your Model" href="#step-3-train-your-model"></a></p>
<ul dir="auto">
<li>Refer to <a href="https://github.com/karpathy/nanoGPT">nanoGPT by Andrej Karpathy</a> for the training process or your chosen architecture’s docs.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Selective Temporal Training ?</h2><a id="user-content-what-is-selective-temporal-training-" aria-label="Permalink: What is Selective Temporal Training ?" href="#what-is-selective-temporal-training-"></a></p>
<p dir="auto">Selective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why not just use fine-tuning or LoRA?</h2><a id="user-content-why-not-just-use-fine-tuning-or-lora" aria-label="Permalink: Why not just use fine-tuning or LoRA?" href="#why-not-just-use-fine-tuning-or-lora"></a></p>
<p dir="auto">For this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1875.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What kind of data did you use for training?</h2><a id="user-content-what-kind-of-data-did-you-use-for-training" aria-label="Permalink: What kind of data did you use for training?" href="#what-kind-of-data-did-you-use-for-training"></a></p>
<p dir="auto">I'm using books, legal documents, newspapers, and other writings from 1800–1875 London. The list I linked (for v0) has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents:
<a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt">https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</a></p>
<p dir="auto">Dataset sizes:</p>
<ul dir="auto">
<li>v0: ~187MB</li>
<li>v0.5: ~435MB</li>
<li>v1: ~6.25GB</li>
<li>v2mini-eval1: 15GB</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How large are the models ?</h2><a id="user-content-how-large-are-the-models-" aria-label="Permalink: How large are the models ?" href="#how-large-are-the-models-"></a></p>
<p dir="auto">v0: 16M Parameters</p>
<p dir="auto">v0.5 123M Parameters</p>
<p dir="auto">v1: 700M Parameters</p>
<p dir="auto">v2mini-eval1: 300M Parameters</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Training Specs ?</h2><a id="user-content-training-specs-" aria-label="Permalink: Training Specs ?" href="#training-specs-"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v0/v0.5</h2><a id="user-content-v0v05" aria-label="Permalink: v0/v0.5" href="#v0v05"></a></p>
<p dir="auto">GPU: Geforce rtx 4060
CPU: i5-13400F
Ram: 16GB DDR5.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v1</h2><a id="user-content-v1-1" aria-label="Permalink: v1" href="#v1-1"></a></p>
<p dir="auto">GPU: A100 SXM rented</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v2mini-eval1</h2><a id="user-content-v2mini-eval1-1" aria-label="Permalink: v2mini-eval1" href="#v2mini-eval1-1"></a></p>
<p dir="auto">GPU: A100 SXM rented</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple picks Google's Gemini to power Siri (840 pts)]]></title>
            <link>https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html</link>
            <guid>46589675</guid>
            <pubDate>Mon, 12 Jan 2026 15:22:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html">https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html</a>, See on <a href="https://news.ycombinator.com/item?id=46589675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="Placeholder-ArticleBody-Video-108251160" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000400554" aria-labelledby="Placeholder-ArticleBody-Video-108251160"><p><img src="https://image.cnbcfm.com/api/v1/image/108251161-17682301881768230186-43459552421-1080pnbcnews.jpg?v=1768230188&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Cramer’s Stop Trading: Apple"><span></span><span></span></p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> is joining forces with <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/GOOGL/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> to power its <a href="https://www.cnbc.com/ai-effect/">artificial intelligence</a> features, including a major <a href="https://www.cnbc.com/2025/12/30/apple-intelligence-ai-siri-iphone.html">Siri</a> upgrade expected later this year. </p><p>The multi-year partnership will lean on Google's <a href="https://www.cnbc.com/2026/01/08/google-adds-gemini-features-to-gmail-message-summaries-proofreading-.html">Gemini</a> and cloud technology for future Apple foundational models, according to a statement obtained by CNBC's Jim Cramer.</p><p>"After careful evaluation, we determined that Google's technology provides the most capable foundation for Apple Foundation Models and we're excited about the innovative new experiences it will unlock for our users," the tech giants said in a <a href="https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/" target="_blank">joint statement</a> on Monday.</p><p>The models will continue to run on Apple devices and the company's private cloud compute, they added. </p><p>Apple declined to comment on the terms of the deal. Google referred CNBC to the joint statement. </p><p>In August, <a href="https://www.bloomberg.com/news/articles/2025-08-22/apple-explores-using-google-gemini-ai-to-power-revamped-siri?srnd=undefined" target="_blank">Bloomberg</a> had reported that Apple was in <a href="https://www.cnbc.com/2025/08/22/google-shares-rise-on-report-of-apple-using-gemini-for-siri.html">early talks with Google</a> to use a custom Gemini model to power a new iteration of Siri. The news outlet later <a href="https://www.bloomberg.com/news/articles/2025-11-05/apple-plans-to-use-1-2-trillion-parameter-google-gemini-model-to-power-new-siri" target="_blank">reported</a> that Apple was planning to pay about $1 billion a year to utilize Google AI.</p><p>The deal is another major indicator of growing trust in Google's <a href="https://www.cnbc.com/2025/11/27/how-google-put-together-the-pieces-for-its-ai-comeback.html">accelerating AI agenda</a> and comeback against OpenAI. In 2025, the search giant logged its <a href="https://www.cnbc.com/2025/12/31/google-stock-wraps-best-year-since-2009-as-ai-excites-wall-street-.html">best year since 2009</a> and surpassed Apple in market capitalization last week for the <a href="https://www.cnbc.com/2026/01/07/alphabets-market-cap-surpasses-apples-for-first-time-since-2019.html">first time since 2019</a>. </p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC tech news</h2><div><ul><li><a href="https://www.cnbc.com/2026/01/08/china-investigate-meta-acquisition-manus-export.html">Meta faces China probe over acquisition of AI agent startup Manus</a></li><li><a href="https://www.cnbc.com/2026/01/07/microsoft-behind-controversial-data-center-in-michigan-township.html">Microsoft revealed as company behind controversial data center proposal in Michigan township</a></li><li><a href="https://www.cnbc.com/2026/01/07/alphabets-market-cap-surpasses-apples-for-first-time-since-2019.html">Alphabet's market cap surpasses Apple's for first time since 2019</a></li><li><a href="https://www.cnbc.com/2026/01/07/google-characterai-to-settle-suits-involving-suicides-ai-chatbots.html">Google, Character.AI to settle suits involving minor suicides and AI chatbots</a></li></ul></div></div><div><p>Shares were slightly lower following the news. Google briefly touched above a <a href="https://www.cnbc.com/2026/01/12/alphabet-4-trillion-market-cap.html">$4 trillion market value</a>.</p><p>Apple has mostly stood on the sidelines of the AI frenzy that's swept up Wall Street since the launch of<a href="https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html"> OpenAI'</a>s <a href="https://www.cnbc.com/2026/01/07/openai-chatgpt-health-medical-records.html">ChatGPT</a> at the end of 2022. </p><p>Hyperscalers <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-16"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-17"><a href="https://www.cnbc.com/quotes/META/">Meta Platforms</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-18"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> have <a href="https://www.cnbc.com/2025/10/31/tech-ai-google-meta-amazon-microsoft-spend.html">shelled out billions</a> on AI products, tools and infrastructure for their customers.</p><p>That's amped up the pressure on the <a href="https://www.cnbc.com/2025/12/17/apple-ai-delay-siri.html">iPhone maker to deliver</a> an impressive Siri AI voice upgrade, which it delayed last year <a href="https://www.cnbc.com/2025/03/07/apple-delays-siri-ai-improvements-to-2026.html">until 2026</a>, despite <a href="https://www.cnbc.com/2025/04/23/apple-ai-ads-went-too-far-watchdog-says.html">running ads</a> for the product.</p><p>"It's going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year," the company said in a statement at the time.</p><p>Apple currently <a href="https://openai.com/index/openai-and-apple-announce-partnership/" target="_blank">partners with OpenAI</a> to integrate ChatGPT into Siri and Apple Intelligence, specifically for complicated queries that can tap into the AI model's world knowledge. It's unclear what the Google partnership means for the ChatGPT integration in the future.</p><p>The devices giant told CNBC said that they aren't making any changes to the agreement. OpenAI did not immediately respond to a request for comment. </p><p>Meanwhile, Google has made steady progress on its AI agenda, introducing its <a href="https://www.cnbc.com/2025/11/18/google-announces-gemini-3-as-battle-with-openai-intensifies.html">upgraded Gemini 3 model</a> late last year. </p><p>In October, Google CEO <a href="https://www.cnbc.com/sundar-pichai/">Sundar Pichai</a> <a href="https://blog.google/company-news/inside-google/message-ceo/alphabet-earnings-q3-2025/#google-cloud" target="_blank">said</a> the company's cloud segment signed more deals worth more than $1 billion through the third quarter of 2025 than the previous two years combined. </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Alphabet and Apple one-day stock chart.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Date is out, Temporal is in (382 pts)]]></title>
            <link>https://piccalil.li/blog/date-is-out-and-temporal-is-in/</link>
            <guid>46589658</guid>
            <pubDate>Mon, 12 Jan 2026 15:20:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://piccalil.li/blog/date-is-out-and-temporal-is-in/">https://piccalil.li/blog/date-is-out-and-temporal-is-in/</a>, See on <a href="https://news.ycombinator.com/item?id=46589658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en-US">
  <p>Time makes fools of us all, and JavaScript is no slouch in that department either. Honestly, I’ve never minded the latter much — in fact, if you’ve taken <a href="https://piccalil.li/javascript-for-everyone">JavaScript for Everyone</a> or tuned into the <a href="https://wil.to/posts#js4e">newsletter</a>, you already know that I largely <em>enjoy</em> JavaScript’s little quirks, believe it or not.</p>
<p>I like when you can see the seams; I like how, for as formal and iron-clad as the ES-262 specification might seem, you can still see all the good <em>and</em> bad decisions made by the hundreds of people who’ve been building the language in mid-flight, if you know where to look. JavaScript has <em>character</em>. Sure, it doesn’t necessarily do everything <em>exactly</em> the way one might expect, but y’know, if you ask me, JavaScript has a real charm once you get to know it!</p>
<p>There’s one part of the language where that immediately falls apart for me, though.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z1i1Ud4" prefix="r18" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,762308]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="762308"><pre id="code-block-762308" tabindex="0"><astro-slot>
<code is:raw=""><span>// Numeric months are zero-indexed, but years and days are not:</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span><span>2026</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Sun Feb 01 2026 00:00:00 GMT-0500 (Eastern Standard Time)</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>The <code>Date</code> constructor.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="14XpUs" prefix="r19" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,649157]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="649157"><pre id="code-block-649157" tabindex="0"><astro-slot>
<code is:raw=""><span>// A numeric string between 32 and 49 is assumed to be in the 2000s:</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"49"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Fri Jan 01 2049 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// A numeric string between 33 and 99 is assumed to be in the 1900s:</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"99"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Fri Jan 01 1999 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// ...But 100 and up start from year zero:</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"100"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Fri Jan 01 0100 00:00:00 GMT-0456 (Eastern Standard Time)</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>I dislike <code>Date</code> <em>immensely</em>.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="nX61C" prefix="r20" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,143868]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="143868"><pre id="code-block-143868" tabindex="0"><astro-slot>
<code is:raw=""><span>// A string-based date works the way you might expect:</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"2026/1/2"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Fri Jan 02 2026 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// A leading zero on the month? No problem; one is one, right?</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"2026/02/2"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Mon Feb 02 2026 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// Slightly different formatting? Sure!</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> <span>"2026-02-2"</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Mon Feb 02 2026 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// A leading zero on the day? Of course; why wouldn't it work?</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span><span>'2026/01/02'</span><span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Fri Jan 02 2026 00:00:00 GMT-0500 (Eastern Standard Time)</span>

<span>// Unless, of course, you separate the year, month, and date with hyphens.</span>
<span>// Then it gets the _day_ wrong.</span>
console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span><span>'2026-01-02'</span><span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Thu Jan 01 2026 19:00:00 GMT-0500 (Eastern Standard Time)</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p><code>Date</code> sucks. It was hastily and shamelessly copied off of Java’s homework in the car on the way to school and it got all the same answers wrong, right down to the name at the top of the page: <code>Date</code> doesn’t represent a <em>date</em>, it represents a <em>time</em>. Internally, dates are stored as number values called <strong>time values</strong>: Unix timestamps, divided into 1,000 milliseconds — which, okay, yes, a Unix time does also necessarily imply a date, sure, but <em>still</em>: Date represents a time, from which you can infer a date. Gross.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="nQpnS" prefix="r21" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,152131]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="152131"><pre id="code-block-152131" tabindex="0"><astro-slot>
<code is:raw=""><span>// Unix timestamp for Monday, December 4, 1995 12:00:00 AM GMT-05 (the day JavaScript was announced):</span>
<span>const</span> timestamp <span>=</span> <span>818053200</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> <span>new</span> <span>Date</span><span>(</span> timestamp <span>*</span> <span>1000</span> <span>)</span> <span>)</span><span>;</span>
<span>// Result: Date Mon Dec 04 1995 00:00:00 GMT-0500 (Eastern Standard Time)</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p>Words like “date” and “time” mean things, but, sure — <em>whatever, JavaScript</em>.</p></div>
<p>Java deprecated <em>their</em> <code>Date</code> way back in 1997, only a few years after JavaScript’s <code>Date</code> was turned loose on the unsuspecting world; meanwhile, we’ve been saddled with this mess ever since. It’s wildly inconsistent when it comes to parsing dates, as you’ve seen so far here. It has no sense of time zones beyond the local one and GMT, which is not ideal where “world-wide” is <em>right there in the web’s name</em> — and speaking-of, <code>Date</code> <em>only</em> respects the Gregorian calendar model. It wholesale does not understand the concept of daylight savings time, which— I mean, okay, yeah, samesies, but I’m not <em>made of computers</em>. All these shortcomings make it exceptionally common to use a third-party library dedicated to working around it all, some of which are absolutely <em>massive</em>; a performance drain that has done real and measurable damage to the web.</p>
<p>None of these are my major issue with <code>Date</code>. My complaint is about more than parsing or syntax or “developer ergonomics” or the web-wide performance impact of wholly necessary workarounds or even the definition of the word “date.” My issue with <code>Date</code> is soul-deep. My problem with <code>Date</code> is that using it means <em>deviating from the fundamental nature of time itself</em>.</p>
<a href="https://piccalil.li/courses"><span data-variant="dark">Advert</span><picture><source media="(width <= 600px)" srcset="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-portrait.png?auto=format"><img src="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-landscape.png?format=webp" alt="Save 15% on All courses! Use code WINTER15 at checkout" loading="lazy"></picture></a>
<p>All JavaScript’s primitives values are <strong>immutable</strong>, meaning that the values themselves cannot be changed. The number value <code>3</code> can never represent anything but the concept of “three” — you can’t make <code>true</code> mean anything other than “true.” These are values with concrete, iron-clad, real-world meanings. We know what three is. It can’t be some other non-three thing. These immutable data types are stored <strong>by value</strong>, meaning that a variable that represents the number value <code>3</code> effectively “contains” — and thus behaves as — the number value <code>3</code>.</p>
<p>When an immutable value is assigned to a variable, the JavaScript engine creates a copy of that value and stores the copy in memory:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="2fJOVq" prefix="r22" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,274196]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="274196"><pre id="code-block-274196" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theNumber <span>=</span> <span>3</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theNumber <span>)</span><span>;</span>
<span>// Result: 3</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>This fits the common mental model for “a variable” just fine: <code>theNumber</code> “contains” <code>3</code>.</p>
<p>When we initialize <code>theOtherNumber</code> with the value bound to <code>theNumber</code>, that mental model holds: once again a <code>3</code> is created and stored in memory. <code>theOtherNumber</code> can now be thought of as containing its own discrete <code>3</code>.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="QiQL8" prefix="r23" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,641110]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="641110"><pre id="code-block-641110" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theNumber <span>=</span> <span>3</span><span>;</span>
<span>const</span> theOtherNumber <span>=</span> theNumber<span>;</span>

console<span>.</span><span>log</span><span>(</span> theOtherNumber <span>)</span><span>;</span>
<span>// Result: 3;</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>The value of <code>theNumber</code> isn’t changed when we alter the value associated with <code>theOtherNumber</code>, of course — again, we’re working with two discrete instances of <code>3</code>.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Zz1Nux" prefix="r24" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,903409]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="903409"><pre id="code-block-903409" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theNumber <span>=</span> <span>3</span><span>;</span>
<span>let</span> theOtherNumber <span>=</span> theNumber<span>;</span>

theOtherNumber <span>=</span> <span>5</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theOtherNumber <span>)</span><span>;</span>
<span>// Result: 5;</span>

console<span>.</span><span>log</span><span>(</span> theNumber <span>)</span><span>;</span>
<span>// Result: 3</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>When you change the value bound to <code>theOtherNumber</code>, you’re not changing the <code>3</code>, you’re creating a new, immutable number value and binding that in its place. Hence an error when you try to tinker with a variable declared using <code>const</code>:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z2pnQoO" prefix="r25" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,230106]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="230106"><pre id="code-block-230106" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theNumber <span>=</span> <span>3</span><span>;</span>

theNumber <span>=</span> <span>5</span><span>;</span>
<span>// Result: Uncaught TypeError: invalid assignment to const 'theNumber'</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p>You can’t change the binding of a <code>const</code>, and you <em>definitely</em> can’t alter the meaning of <code>3</code>.</p></div>
<p>Data types that <em>can</em> be changed after they’re created are <strong>mutable</strong>, meaning that the data value <em>itself</em> can be altered. Object values — any non-primitive value, like an array, map, or set — are mutable.</p>
<p>Variables (and object properties, function parameters, and elements in an array, set, or map) can’t “contain” an object, the way we might think of <code>theNumber</code> in the example above as “containing” <code>3</code>. A variable can contain either a primitive value or a <strong>reference value</strong>, the latter of which is a pointer to that object’s stored location in memory. When you assign an object to a variable, instead of creating a copy of that object, the identifier represents a reference to the object’s stored position in memory. That’s why an object bound to a variable declared with <code>const</code> can still be altered: the <em>reference value</em> can’t be changed, but the values of the object can:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z286sWq" prefix="r26" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,581705]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="581705"><pre id="code-block-581705" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theObject <span>=</span> <span>{</span>
	<span>theValue</span> <span>:</span> <span>3</span>
<span>}</span><span>;</span>

theObject<span>.</span>theValue<span>++</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theObject<span>.</span>theValue <span>)</span><span>;</span>
<span>// Result: 4</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p>You still can’t change the binding of a <code>const</code>, but you <em>can</em> alter the object that binding references.</p></div>
<p>When a reference value is assigned from one variable to another, the JavaScript engine creates a copy of that reference value — not the object value itself, the way a discrete copy is made of a primitive value. Both identifiers point to the same object in memory — any changes made to that object by way of one reference will be reflected by the others, because they’re all referencing the same thing:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z11Apw6" prefix="r27" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,487210]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="487210"><pre id="code-block-487210" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theObject <span>=</span> <span>{</span>
	<span>theValue</span> <span>:</span> <span>3</span>
<span>}</span><span>;</span>

<span>const</span> theOtherObj <span>=</span> theObject<span>;</span>

theOtherObj<span>.</span>theValue<span>++</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theOtherObj<span>.</span>theValue <span>)</span><span>;</span>
<span>// Result: 4</span>

console<span>.</span><span>log</span><span>(</span> theObject<span>.</span>theValue <span>)</span><span>;</span>
<span>// Result: 4</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p><em>This</em> is what gets me about JavaScript’s date handling. Despite representing “point to it on a calendar” values, JavaScript’s date values are <em>mutable —</em> <code>Date</code> is a constructor, invoking a constructor with <code>new</code> necessarily results in an object, and all objects are inherently mutable:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z4jOBp" prefix="r28" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,72207]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="72207"><pre id="code-block-72207" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theDate <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> <span>typeof</span> theDate <span>)</span><span>;</span>
<span>// Result: object</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>Even though “January 1st, 2026” is as much an immutable real-world concept as “three” or “true,” the only way we have of representing that date is a with a mutable data structure.</p>
<p>This also means that any variable initialized with an instance of the <code>Date</code> constructor contains a reference value, pointing to a data value in memory that can be changed by way of any reference to that value:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="ZByBBI" prefix="r29" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,43758]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="43758"><pre id="code-block-43758" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> theDate <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theDate<span>.</span><span>toDateString</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>// Result: Tue Dec 30 2025</span>

theDate<span>.</span><span>setMonth</span><span>(</span> <span>10</span> <span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> theDate<span>.</span><span>toDateString</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>// Result: Sun Nov 30 2025</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p>Again, we’re going to breeze right over the fact that month <code>10</code> is <em>November</em>.</p></div>
<p>So despite real-world dates having set-in-stone <em>meanings</em>, the process of interacting with an instance of <code>Date</code> that represents that real-world value can mean altering that instance in ways we didn’t necessarily intend:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="2dYNwd" prefix="r39" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,550346]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="550346"><pre id="code-block-550346" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> today <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

<span>const</span> <span>addDay</span> <span>=</span> <span>theDate</span> <span>=&gt;</span> <span>{</span>
	theDate<span>.</span><span>setDate</span><span>(</span> theDate<span>.</span><span>getDate</span><span>(</span><span>)</span> <span>+</span> <span>1</span> <span>)</span><span>;</span>
	<span>return</span> theDate<span>;</span>
<span>}</span><span>;</span>

console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Today is </span><span><span>${</span> today<span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>, tomorrow is </span><span><span>${</span> <span>addDay</span><span>(</span> today <span>)</span><span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span>
<span>// Result: Today is 12/31/2025. Tomorrow is 1/1/2026.</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>Fine so far, right? Today is today, tomorrow is tomorrow; all is right in the world. You’d be forgiven for committing this to a codebase and moving on with your day. That is, unless we reordered the output slightly.</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="pL9sA" prefix="r40" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,721985]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="721985"><pre id="code-block-721985" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> today <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>addDay</span> <span>=</span> <span>theDate</span> <span>=&gt;</span> <span>{</span>
	theDate<span>.</span><span>setDate</span><span>(</span> theDate<span>.</span><span>getDate</span><span>(</span><span>)</span> <span>+</span> <span>1</span> <span>)</span><span>;</span>
	<span>return</span> theDate<span>;</span>
<span>}</span><span>;</span>

console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Tomorrow will be </span><span><span>${</span> <span>addDay</span><span>(</span> today <span>)</span><span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>. Today is </span><span><span>${</span> today<span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span>
<span>// Result: Tomorrow will be 1/1/2026. Today is 1/1/2026.</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>See what happened there? the variable <code>today</code> represents a reference to the object created by <code>new Date()</code>. When we provided <code>today</code> as an argument to the <code>addDay</code> function, the parameter <code>theDate</code> now represents a copy of the reference value — not a copy of the value, but a second reference to the object that represents today’s date. When we manipulate that value to determine the date of the following day, we’re manipulating the mutable object in memory, not an immutable copy — today becomes tomorrow, the falcon has a hard time hearing the falconer, the center starts to look a little iffy vis-a-vis “holding,” and so on.</p>
<p>Now, by this point you can probably tell that I’m not here to praise <code>Date</code>, but what you might not expect is that I’m here to <em>bury</em> it. That’s right: <code>Date</code> is soon to be over, done, gone, as “deprecated” as any part of the web platform can be — which is to say, “around forever, but you shouldn’t use it anymore, if you can avoid it.” Soon we will — at long last — have an object that replaces <code>Date</code> wholesale: <code>Temporal</code>.</p>
<a href="https://piccalil.li/courses"><span data-variant="dark">Advert</span><picture><source media="(width <= 600px)" srcset="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-portrait.png?auto=format"><img src="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-landscape.png?format=webp" alt="Save 15% on All courses! Use code WINTER15 at checkout -" loading="lazy"></picture></a>
<h2 id="temporal-is-not-a-constructor-its-a-namespace-object"><a href="#temporal-is-not-a-constructor-its-a-namespace-object">Temporal is not a constructor, it’s a namespace object</a></h2>
<p>The sharp-eyed among you may have noticed that I said “an <em>object</em> that replaces <code>Date</code>,” not “a constructor.” <code>Temporal</code> is not a constructor, and your browser’s developer console will tell you the same if you attempt to invoke it as one:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="2vGBAe" prefix="r30" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,794498]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="794498"><pre id="code-block-794498" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> today <span>=</span> <span>new</span> <span>Temporal</span><span>(</span><span>)</span><span>;</span>
<span>// Uncaught TypeError: Temporal is not a constructor</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p><code>Temporal</code> is a <em>way</em> better name for something that pertains to <em>time</em>, if you ask me.</p></div>
<p>Instead, <code>Temporal</code> is a <strong>namespace object</strong> — an ordinary object made up of static properties and methods, like the <code>Math</code> object:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Z129dhd" prefix="r31" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,335578]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="335578"><pre id="code-block-335578" tabindex="0"><astro-slot>
<code is:raw="">console<span>.</span><span>log</span><span>(</span> Temporal <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal { … }
	Duration: function Duration()
	Instant: function Instant()
	Now: Temporal.Now { … }
	PlainDate: function PlainDate()
	PlainDateTime: function PlainDateTime()
	PlainMonthDay: function PlainMonthDay()
	PlainTime: function PlainTime()
	PlainYearMonth: function PlainYearMonth()
	ZonedDateTime: function ZonedDateTime()
	Symbol(Symbol.toStringTag): "Temporal"
*/</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>I find this <em>immediately</em> understandable compared to <code>Date</code>.  The classes and namespaces objects that <code>Temporal</code> contains allow you to calculate durations between two points in time, represent a point in time <em>with or without time zone specificity</em>, or access the current moment in time via the <code>Now</code> property. <code>Temporal.Now</code> references a namespace object containing properties and methods of its own:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="DWUpQ" prefix="r32" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,111051]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="111051"><pre id="code-block-111051" tabindex="0"><astro-slot>
<code is:raw="">console<span>.</span><span>log</span><span>(</span> Temporal<span>.</span>Now <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.Now { … }
	instant: function instant()
	plainDateISO: function plainDateISO()
	plainDateTimeISO: function plainDateTimeISO()
	plainTimeISO: function plainTimeISO()
	timeZoneId: function timeZoneId()
	zonedDateTimeISO: function zonedDateTimeISO()
	Symbol(Symbol.toStringTag): "Temporal.Now"
	&lt;prototype&gt;: Object { … }
*/</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p><code>Temporal</code> gives us a sensible, plain-language way to grab today’s date, <em>a la</em> raggedy old  <code>Date</code>: the <code>Now</code> property contains a <code>plainDateISO()</code> method. Since we’re not specifying anything in the way of time zones (a thing we can do now, thanks to Temporal) that method gives us back today’s date in the current one — EST, in my case:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="1REqYW" prefix="r33" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,531367]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="531367"><pre id="code-block-531367" tabindex="0"><astro-slot>
<code is:raw="">console<span>.</span><span>log</span><span>(</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.PlainDate 2025-12-31
	&lt;prototype&gt;: Object { … }
*/</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<div><p>Notice how <code>plainDateISO</code> results in an already-formatted, date-only value? Stay tuned; that’ll come up again later.</p></div>
<p>—wait. That looks familiar:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="283pSX" prefix="r34" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,407693]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="407693"><pre id="code-block-407693" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> nowTemporal <span>=</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span><span>;</span>
<span>const</span> nowDate <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> nowTemporal <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.PlainDate 2025-12-31
	&lt;prototype&gt;: Object { … }
*/</span>

console<span>.</span><span>log</span><span>(</span> nowDate <span>)</span><span>;</span>
<span>/* Result (expanded):
Date Tue Dec 31 2025 11:05:52 GMT-0500 (Eastern Standard Time)
	&lt;prototype&gt;: Date.prototype { … }
*/</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>Could it be that—…</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="ZcGKpM" prefix="r35" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,689194]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="689194"><pre id="code-block-689194" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> rightNow <span>=</span> Temporal<span>.</span>Now<span>.</span><span>instant</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> <span>typeof</span> rightNow <span>)</span><span>;</span>
<span>// object</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p><em>Yes, we’re still working with a mutable object that represents the current date</em>, I say in my spookiest voice, flashlight squarely beneath my chin. At a glance, this might not seem like it addresses my big complaint with <code>Date</code> at all.</p>
<p>Well, we’re kind of at the mercy of the nature of the language, here: dates represent complex real-world values, complex data necessitates complex data structures, and for JavaScript, that means objects. The difference is in how we <em>interact</em> with these Temporal objects, as compared to instances of <code>Date</code>, and — as is so often the case — the magic is in the prototype chain:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="ZMz1AX" prefix="r36" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,231225]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="231225"><pre id="code-block-231225" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> nowTemporal <span>=</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span>__proto__ <span>)</span><span>;</span>
<span>/* Result (expanded):
Object { … }
	add: function add()
	calendarId: &gt;&gt;
	constructor: function PlainDate()
	day: &gt;&gt;
	dayOfWeek: &gt;&gt;
	dayOfYear: &gt;&gt;
	daysInMonth: &gt;&gt;
	daysInWeek: &gt;&gt;
	daysInYear: &gt;&gt;
	equals: function equals()
	era: &gt;&gt;
	eraYear: &gt;&gt;
	inLeapYear: &gt;&gt;
	month: &gt;&gt;
	monthCode: &gt;&gt;
	monthsInYear: &gt;&gt;
	since: function since()
	subtract: function subtract()
	toJSON: function toJSON()
	toLocaleString: function toLocaleString()
	toPlainDateTime: function toPlainDateTime()
	toPlainMonthDay: function toPlainMonthDay()
	toPlainYearMonth: function toPlainYearMonth()
	toString: function toString()
	toZonedDateTime: function toZonedDateTime()
	until: function until()
	valueOf: function valueOf()
	weekOfYear: &gt;&gt;
	with: function with()
	withCalendar: function withCalendar()
	year: &gt;&gt;
	yearOfWeek: &gt;&gt;
	Symbol(Symbol.toStringTag): "Temporal.PlainDate"
	&lt;get calendarId()&gt;: function calendarId()
	&lt;get day()&gt;: function day()
	&lt;get dayOfWeek()&gt;: function dayOfWeek()
	&lt;get dayOfYear()&gt;: function dayOfYear()
	&lt;get daysInMonth()&gt;: function daysInMonth()
	&lt;get daysInWeek()&gt;: function daysInWeek()
	&lt;get daysInYear()&gt;: function daysInYear()
	&lt;get era()&gt;: function era()
	&lt;get eraYear()&gt;: function eraYear()
	&lt;get inLeapYear()&gt;: function inLeapYear()
*/</span>

</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>Right away you’ll notice that there are a number of methods and properties devoted to accessing, formatting, and manipulating the details of the Temporal object we’re working with. No big surprises there — it means a little bit of a learning curve, sure, but nothing an occasional trip over to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Temporal">MDN</a> couldn’t solve, and they all more-or-less do what they say on their respective tins. The big difference from working with <code>Date</code> is <em>how</em> they do so, at a fundamental level:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="1rqmc1" prefix="r37" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,811942]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="811942"><pre id="code-block-811942" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> nowTemporal <span>=</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span><span>;</span>

<span>// Current local date:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.PlainDate 2025-12-30
	&lt;prototype&gt;: Object { … }
*/</span>

<span>// Current local year:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span>year <span>)</span><span>;</span>
<span>// Result: 2025</span>

<span>// Current local date and time:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span><span>toPlainDateTime</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.PlainDateTime 2025-12-30T00:00:00
	&lt;prototype&gt;: Object { … }
*/</span>

<span>// Specify that this date represents the Europe/London time zone:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span><span>toZonedDateTime</span><span>(</span> <span>"Europe/London"</span> <span>)</span> <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.ZonedDateTime 2025-12-30T00:00:00+00:00[Europe/London]
	&lt;prototype&gt;: Object { … }
*/</span>

<span>// Add a day to this date:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span><span>add</span><span>(</span><span>{</span> <span>days</span><span>:</span> <span>1</span> <span>}</span><span>)</span> <span>)</span><span>;</span>
<span>/*
Temporal.PlainDate 2025-12-31
	&lt;prototype&gt;: Object { … }
*/</span>

<span>// Add one month and one day to this date, and subtract two years:</span>
console<span>.</span><span>log</span><span>(</span> nowTemporal<span>.</span><span>add</span><span>(</span><span>{</span> <span>months</span><span>:</span> <span>1</span><span>,</span> <span>days</span><span>:</span> <span>1</span> <span>}</span><span>)</span><span>.</span><span>subtract</span><span>(</span><span>{</span> <span>years</span><span>:</span> <span>2</span> <span>}</span><span>)</span> <span>)</span><span>;</span>
<span>/*
Temporal.PlainDate 2024-01-31
	&lt;prototype&gt;: Object { … }
*/</span>

console<span>.</span><span>log</span><span>(</span> nowTemporal <span>)</span><span>;</span>
<span>/* Result (expanded):
Temporal.PlainDate 2025-12-30
	&lt;prototype&gt;: Object { … }
*/</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>Notice how none of these transformations required us to manually spin up any new objects, <em>and</em> that the value of the object referenced by <code>nowTemporal</code> remains unchanged? Unlike <code>Date</code>,  the methods we use to interact with a Temporal object result in <em>new</em> Temporal objects, rather than requiring us to use them in the context of a new instance or to modify the instance we’re working with — which is how we’re able to chain the <code>add</code> and <code>subtract</code> methods together in <code>nowTemporal.add({ months: 1, days: 1 }).subtract({ years: 2 })</code>.</p>
<p>Sure, we’re still working with objects, and that means we’re working with mutable data structures that represent real-world values:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="160dkF" prefix="r38" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,738180]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="738180"><pre id="code-block-738180" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> nowTemporal <span>=</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span><span>;</span>

nowTemporal<span>.</span>someProperty <span>=</span> <span>true</span><span>;</span>

console<span>.</span><span>log</span><span>(</span> nowTemporal <span>)</span><span>;</span>

<span>/* Result (expanded):
Temporal.PlainDate 2026-01-05
	someProperty: true
	&lt;prototype&gt;: Object { … }
</span></code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>
<p>…But the value represented by that Temporal object isn’t meant to be changed during the normal course of interacting with it — even though the object is still essentially mutable, we’re not stuck using that object in ways that could alter what it means in terms of real-world dates and times. I’ll take it.</p>
<p>So, let’s revisit that janky little “today is X, tomorrow is Y” script we wrote using <code>Date</code> earlier. First, we’ll fix it by making sure we’re working with two discrete instances of <code>Date</code> rather than modifying the instance that represents today’s date:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="Udgcv" prefix="r41" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,365513]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="365513"><pre id="code-block-365513" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> today <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

<span>const</span> <span>addDay</span> <span>=</span> <span>theDate</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> tomorrow <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>;</span>

	tomorrow<span>.</span><span>setDate</span><span>(</span> theDate<span>.</span><span>getDate</span><span>(</span><span>)</span> <span>+</span> <span>1</span> <span>)</span><span>;</span>
	<span>return</span> tomorrow<span>;</span>
<span>}</span><span>;</span>

console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Tomorrow will be </span><span><span>${</span> <span>addDay</span><span>(</span> today <span>)</span><span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>. Today is </span><span><span>${</span> today<span>.</span><span>toLocaleDateString</span><span>(</span><span>)</span> <span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span>
<span>// Result: Tomorrow will be 1/1/2026. Today is 12/31/2025.</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>

<p>Okay, fine. It gets the job done, just as it has since the day <code>Date</code> first bumbled its way onto the web. We’re not unwittingly altering the value of <code>today</code> since we’re spinning up a new instance of <code>Date</code> inside our <code>addDay</code> function — wordy, but it works, as it has for decades now. We add <code>1</code> to it, which we have to just kind of <em>know</em> means add one <em>day.</em> Then in our template literal we need to keep nudging JavaScript to give us the date in a format that doesn’t include the current time, as a string. It’s functional, but verbose.</p>
<p>Now, let’s redo it using <code>Temporal</code>:</p>
<div>
<!-- 
  IMPORTANT: Do not indent this slot content in Astro.
  Leading whitespace will be preserved and break code formatting.
-->
<astro-island uid="1my0FA" prefix="r42" component-url="/_astro/CodeBlock.chXmwTQ3.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;className&quot;:[0,&quot;language-js&quot;],&quot;id&quot;:[0,261058]}" ssr="" client="visible" opts="{&quot;name&quot;:&quot;CodeBlock&quot;,&quot;value&quot;:true}" await-children=""><div data-element="code-block" data-id="261058"><pre id="code-block-261058" tabindex="0"><astro-slot>
<code is:raw=""><span>const</span> today <span>=</span> Temporal<span>.</span>Now<span>.</span><span>plainDateISO</span><span>(</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Tomorrow will be </span><span><span>${</span> today<span>.</span><span>add</span><span>(</span><span>{</span> <span>days</span><span>:</span> <span>1</span> <span>}</span><span>)</span> <span>}</span></span><span>. Today is </span><span><span>${</span> today <span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span>
<span>// Result: Tomorrow will be 2026-01-01. Today is 2025-12-31.</span>
</code>
</astro-slot></pre></div><!--astro:end--></astro-island>
</div>

<p><em>So much better</em>. Leaner, meaner, and <em>way</em> less margin for error. We want today’s date without the time, and the object that results from invoking <code>plainDateISO</code> (and any new Temporal objects created from it) will retain that formatting <em>without</em> being coerced to a string. Formatting: <em>check</em>.</p>
<p>We want to output a value that represents today’s date plus one day, and we want to do so in a way where we are unmistakably saying “add one day to it” with no parsing guesswork: <em>check</em> and <em>check</em>.</p>
<p>Most importantly, we don’t want to run the risk of having our original <code>today</code> object altered unintentionally — because the result of calling the <code>add</code> method will always be a new Temporal object: <em>check</em>.</p>
<p><code>Temporal</code> is going to be a <em>massive</em> improvement over <code>Date</code>, and I only say “going to be” because it still isn’t quite ready for prime-time usage. <a href="https://tc39.es/proposal-temporal/">The draft specification for the proposed <code>Temporal</code> object</a> has reached stage three of the standardization process, meaning it is now officially “recommended for implementation” — not yet part of the standard that informs the ongoing development of JavaScript itself, but close enough that browsers can start tinkering with it. That means the results of that early experimentation may be used to further refine the specification, so nothing is set in stone just yet. Web standards are an iterative process, after all.</p>
<p>That’s where you and I come in. Now that <code>Temporal</code> has <a href="https://caniuse.com/?search=Temporal">landed in the latest versions of Chrome and Firefox</a> — and others, soon — it’s time for us to get in there and kick the tires a little bit. We may not have had any say in <code>Date</code>, but we get to experiment with <code>Temporal</code> before the final implementations land.</p>
<p>Soon, JavaScript will have sensible, modern date handling, and we’ll finally be able to cram <code>Date</code> way in the back of the junk drawer with the rubber bands, mismatched jar lids, mystery keys, and probably-half-empty AA batteries — still present, still an inexorable part of the web platform, but no longer our first, last, and only way of handling dates. And we only had to wait— well, hold on, let me just crunch the numbers real quick:</p>
<div>
  <astro-island uid="ZO0XPc" prefix="r9" component-url="/_astro/ConsoleLogger.67Rv-5VD.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;instruction&quot;:[0],&quot;code&quot;:[0,&quot;\nconst today = Temporal.Now.plainDateISO();\nconst jsShipped = Temporal.PlainDate.from( \&quot;1995-12-04\&quot; );\nconst sinceDate = today.since( jsShipped, { largestUnit: 'year' });\n\nconsole.log( `${ sinceDate.years } years, ${ sinceDate.months } months, and ${ sinceDate.days } days.` );\n&quot;],&quot;language&quot;:[0,&quot;js&quot;],&quot;outputType&quot;:[0,&quot;log&quot;],&quot;consoleOutput&quot;:[0,&quot;\n30 years, 0 months, and 27 days.\n&quot;],&quot;showLineNumbers&quot;:[0,false]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;ConsoleLogger&quot;,&quot;value&quot;:true}" await-children=""><div><p data-wrapper-type="inner"><h3>Try it out</h3></p><hr><div data-wrapper-type="inner"><pre tabindex="0"><code>const today = Temporal.Now.plainDateISO();
const jsShipped = Temporal.PlainDate.from( "1995-12-04" );
const sinceDate = today.since( jsShipped, { largestUnit: 'year' });

console.log( `${ sinceDate.years } years, ${ sinceDate.months } months, and ${ sinceDate.days } days.` );</code></pre></div></div><template data-astro-template="">
    
  </template><!--astro:end--></astro-island>
</div>
<p>Sure, the best time to replace <code>Date</code> would’ve been back in 1995, but hey: the second best time is <code>Temporal.Now</code>, right?</p>

    <div><p><strong>Enjoyed this article?</strong> <em>You can support us by <a href="https://opencollective.com/piccalilli/contribute/leave-a-tip-90508/checkout?interval=oneTime&amp;amount=3">leaving a tip</a> via Open Collective</em></p></div><a href="https://piccalil.li/courses"><span data-variant="dark">Advert</span><picture><source media="(width <= 600px)" srcset="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-portrait.png?auto=format"><img src="https://piccalil.b-cdn.net/images/ads/winter-discount-ad-landscape.png?format=webp" alt="Save 15% on All courses! Use code WINTER15 at checkout _" loading="lazy"></picture></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Statement from Federal Reserve Chair (176 pts)]]></title>
            <link>https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm?mod=ANLink</link>
            <guid>46589489</guid>
            <pubDate>Mon, 12 Jan 2026 15:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm?mod=ANLink">https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm?mod=ANLink</a>, See on <a href="https://news.ycombinator.com/item?id=46589489">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
        
        <div id="article">
                                        
                    <div>
            <p><strong>Accessible Keys for Video</strong></p>
            <p><strong>[Space Bar]</strong> toggles play/pause;</p>
            <p><strong>[Right/Left Arrows]</strong> seeks the video forwards and back (5 sec );</p>
            <p><strong>[Up/Down Arrows]</strong> increase/decrease volume;</p>
            <p><strong>[M]</strong> toggles mute on/off;</p>
            <p><strong>[F]</strong> toggles fullscreen on/off (Except IE 11);</p>
            <p>The <strong>[Tab]</strong> key may be used in combination with the <strong>[Enter/Return]</strong> key to navigate and activate control buttons, such as caption on/off.</p>
        </div>
                    
                    
                    <p>Good evening.</p>

<p>On Friday, the Department of Justice served the Federal Reserve with grand jury subpoenas, threatening a criminal indictment related to my testimony before the Senate Banking Committee last June. That testimony concerned in part a multi-year project to renovate historic Federal Reserve office buildings.</p>

<p>I have deep respect for the rule of law and for accountability in our democracy. No one—certainly not the chair of the Federal Reserve—is above the law. But this unprecedented action should be seen in the broader context of the administration's threats and ongoing pressure.</p>

<p>This new threat is not about my testimony last June or about the renovation of the Federal Reserve buildings. It is not about Congress's oversight role; the Fed through testimony and other public disclosures made every effort to keep Congress informed about the renovation project. Those are pretexts. The threat of criminal charges is a consequence of the Federal Reserve setting interest rates based on our best assessment of what will serve the public, rather than following the preferences of the President.</p>

<p>This is about whether the Fed will be able to continue to set interest rates based on evidence and economic conditions—or whether instead monetary policy will be directed by political pressure or intimidation.</p>

<p>I have served at the Federal Reserve under four administrations, Republicans and Democrats alike. In every case, I have carried out my duties without political fear or favor, focused solely on our mandate of price stability and maximum employment. Public service sometimes requires standing firm in the face of threats. I will continue to do the job the Senate confirmed me to do, with integrity and a commitment to serving the American people.</p>

<p>Thank you.</p>
                     
                </div>
        <div>
            <p>Last Update:
                
                            January 11, 2026
                        
            </p>
            
            
        </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLVM: The Bad Parts (337 pts)]]></title>
            <link>https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html</link>
            <guid>46588837</guid>
            <pubDate>Mon, 12 Jan 2026 14:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html">https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html</a>, See on <a href="https://news.ycombinator.com/item?id=46588837">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        
        <p>A few years ago, I wrote a blog post on <a href="https://www.npopov.com/2021/06/02/Design-issues-in-LLVM-IR.html">design issues in LLVM IR</a>. Since then, one of these issues has been fixed fully (opaque pointers migration), one has been mostly fixed (constant expression removal), and one is well on the way towards being fixed (ptradd migration).</p>

<p>This time I’m going to be more ambitious and not stop at three issues. Of course, not all of these issues are of equal importance, and how important they are depends on who you ask. In the interest of brevity, I will mostly just explain what the problem is, and not discuss what possible solutions would be.</p>

<p>Finally, I should probably point out that this is written from my perspective as the lead maintainer of the LLVM project: This is not a list of reasons to not use LLVM, it’s a list of opportunities to improve LLVM.</p>

<h2 id="high-level-issues">High level issues</h2>

<h3 id="review-capacity">Review capacity</h3>

<p>Unlike many other open-source projects, LLVM certainly <a href="https://insights.linuxfoundation.org/project/llvm-llvm-project">does not suffer</a> from a lack of contributors. There are <em>thousands</em> of contributors and the distribution is relatively flat (that is, it’s not the case that a small handful of people is responsible for the majority of contributions.)</p>

<p>What LLVM does suffer from is insufficient review capacity. There are a lot more people writing code than reviewing it. This is somewhat unsurprising, as code review requires more expertise than writing code, and may not provide immediate value<sup id="fnref:review_value" role="doc-noteref"><a href="#fn:review_value" rel="footnote">1</a></sup> to the person reviewing (or their employer).</p>

<p>Lack of review capacity makes for a bad contributor experience, and can also result in bad changes making their way into the codebase. The way this usually works out is that someone puts up a PR, then fails to get a qualified review for a long period of time, and then one of their coworkers (who is not a qualified reviewer for that area) ends up rubberstamping the PR.</p>

<p>A related problem is that LLVM has a somewhat peculiar contribution model where it’s the responsibility of the PR author to request reviewers. This is especially problematic for new contributors, who don’t know whom to request. Often relevant reviewers will become aware of the PR thanks to a label-based notification system, but this is not apparent from the UI, and it’s easy for PRs to fall through the cracks.</p>

<p>A potential improvement here would be a Rust-style <a href="https://forge.rust-lang.org/triagebot/pr-assignment.html">PR assignment system</a>.</p>

<h3 id="churn">Churn</h3>

<p>Both the LLVM C++ API and LLVM IR are not stable and undergo frequent changes. This is simultaneously a great strength and weakness of LLVM. It’s a strength because LLVM does not stagnate and is willing to address past mistakes even at significant cost. It’s a weakness because churn imposes costs on users of LLVM.</p>

<p>Frontends are <em>somewhat</em> insulated from this because they can use the largely stable C API. However, it does not cover everything, and most major frontends will have additional bindings that use the unstable C++ API.</p>

<p>Users that integrate with LLVM more tightly (for example downstream backends) don’t have that option, and have to keep up with all API changes.</p>

<p>This is part of LLVM’s general development philosophy, which I’ll express somewhat pointedly as “upstream or GTFO”. LLVM is liberally licensed and does not require you to contribute changes upstream. However, if you do not upstream your code, then it will also not factor into upstream decision-making.</p>

<p>This point is somewhat unlike the rest, in that I’m not sure it’s possible to make things “strictly better” here. It’s possible that LLVM’s current point on the stability scale is not optimal, but moving it somewhere else would come with significant externalities. Making major changes in LLVM is already extremely hard due to the sheer scale of the project, without adding additional stability constraints on top.</p>

<h3 id="build-time">Build time</h3>

<p>LLVM is a huge project. LLVM itself is &gt;2.5 million lines of C++ and the entire monorepo is something like 9 million. C++ is not exactly known for fast build times, and compiling all that code takes time. This is bearable if you either have fast hardware or access to a build farm, but trying to build LLVM on a low-spec laptop is not going to be fun.</p>

<p>An additional complication is building with debug info (which I always recommend against), in which case you’ll add the extra gotchas of slow link times, high risk of OOM and massive disk usage. There are ways to avoid that (using shared libs or dylib build, using split dwarf, using lld), but it takes some expertise.</p>

<p>Promising changes in this area are the <a href="https://discourse.llvm.org/t/rfc-use-pre-compiled-headers-to-speed-up-llvm-build-by-1-5-2x/89345?u=nikic">use of pre-compiled headers</a> (which significantly improves build time), and changing to use a <a href="https://discourse.llvm.org/t/rfc-llvm-link-llvm-dylib-should-default-to-on-on-posix-platforms/85908?u=nikic">dylib build by default</a> (which reduces disk usage and link time, esp. for debuginfo builds). Another is to <a href="https://discourse.llvm.org/t/rfc-reducing-process-creation-overhead-in-llvm-regression-tests/88612?u=nikic">reduce test overhead</a> using daemonization (not strictly part of the “build time”, but relevant for the development cycle).</p>

<h3 id="ci-stability">CI stability</h3>

<p>LLVM CI consists of over 200 post-commit buildbots that test LLVM in lots of different configurations on lots of different hardware. Commits that turn a buildbot from green to red result in an email to the commit author.</p>

<p>Unfortunately, this CI is never fully green, and flaky on top. This is in part due to flaky tests (typically in lldb or openmp), but can also be due to buildbot-specific issues. The end result is that it’s “normal” to get buildbot failure notifications for any given commit, even if it is perfectly harmless. This dilutes the signal, and makes it easier to miss the real failures.</p>

<p>The introduction of pre-merge testing on PRs did significantly improve the overall CI situation, but not the buildbot problem as such. I think we need to start taking flaky tests/buildbots more seriously before we can really make progress here.</p>

<p>Because someone is definitely going to mention how this <a href="https://graydon2.dreamwidth.org/1597.html">is not rocket science</a>, and we just need to start using bors / merge queues to guarantee an always-green build: It’s a problem of scale. There are &gt;150 commits on a typical workday, which would be more than one commit every 10 minutes even if they were uniformly distributed. Many buildbots have multi-hour runs. This is hard to reconcile.<sup id="fnref:bors" role="doc-noteref"><a href="#fn:bors" rel="footnote">2</a></sup></p>

<h3 id="end-to-end-testing">End-to-end testing</h3>

<p>In some respects, LLVM has very thorough test coverage. We’re quite pedantic about making sure that new optimizations have good coverage of both positive and negative tests. However, these tests are essentially unit tests for a single optimization pass or analysis.</p>

<p>We have only a small amount of coverage for the entire optimization pipeline (phase ordering tests), so optimizations sometimes regress due to pass interactions. Tests for the combination of the middle-end and backend pipelines are essentially nonexistent. There is likely room for improvement here, though it comes with tradeoffs.</p>

<p>However, what actually concerns me are end-to-end executable tests. LLVM’s test suite proper does not feature these at all. Executable tests are located in a separate <a href="https://github.com/llvm/llvm-test-suite">llvm-test-suite</a> repo, which is typically not used during routine development, but run by buildbots. It contains a lot of different code ranging from benchmarks to unit tests.</p>

<p>However, llvm-test-suite has quite few tests (compared to LLVM lit tests) and does not comprehensively cover basic operations. Things like testing operations on different float formats, on integers of different sizes, vectors of different sizes and element types, etc.</p>

<p>In part this is because of limitations of testing through C/C++, which is very heterogeneous in type support (C compilers don’t like exposing types that don’t have a defined psABI for the target). But that’s no excuse to delegate this testing to Zig instead (which exposes everything, everywhere, and has the corresponding test coverage).</p>

<h3 id="backend-divergence">Backend divergence</h3>

<p>While LLVM’s middle-end is very unified, backend implementations are very heterogeneous, and there is a tendency to fix issues (usually performance, but sometimes even correctness) only for the backend you’re interested in.</p>

<p>This takes many forms, like implementing target-specific DAG combines instead of generic ones. Though my definite favorite is to introduce lots of target hooks for optimizations – not because the optimization is actually only beneficial for one target, but because the person introducing it just doesn’t want to deal with the fallout on other targets.</p>

<p>This is understandable – after all, they may lack the knowledge to evaluate a change for other targets, so it may require working with many other maintainers, which can slow progress a lot. But the end result is still increasing divergence and duplication.</p>

<p>Lack of end-to-end testing compounds this issue, because that would act as something of a forcing function that at least all operations compile without crashing and produce correct results for all tested targets.</p>

<h3 id="compilation-time">Compilation time</h3>

<p>Because I’ve <a href="https://www.npopov.com/2020/05/10/Make-LLVM-fast-again.html">complained</a> about this enough in the past, I’ll keep it short: LLVM is slow, which is an issue both for JIT use cases, and anything that tends to produce huge amounts of IR (like Rust or C++).</p>

<p>Since I’ve started <a href="https://llvm-compile-time-tracker.com/">tracking compile-times</a>, the situation has significantly improved, both through targeted improvements and avoidance of regressions. However, there is still a lot of room for improvement: LLVM still isn’t fast, it’s just less slow.</p>

<p>One thing that LLVM is particularly bad at are <code>-O0</code> compile-times. The architecture is optimized for optimization, and lots of costs remain even if no optimization takes place. The <a href="https://discourse.llvm.org/t/tpde-llvm-10-20x-faster-llvm-o0-back-end/86664?u=nikic">LLVM TPDE</a> alternative backend shows that it’s possible to do better by an order of magnitude.</p>

<h3 id="performance-tracking">Performance tracking</h3>

<p>The flip side of the compile-time coin is runtime performance. This is something that LLVM obviously cares a lot about. Which is why I find it rather surprising that LLVM does not have any “official” performance tracking infrastructure.</p>

<p>Of course, there are lots of organizations which track performance of LLVM downstream, on their own workloads. In some ways this is good, because it means there is more focus on real-world workloads than on synthetic benchmarks like SPEC. However, not having readily accessible, public performance tracking also makes it hard for contributors to evaluate changes.</p>

<p>To be fair, LLVM does have an <a href="https://lnt.llvm.org/">LNT</a> instance, but a) it’s currently broken, b) LNT is one of the worst UX crimes ever committed, c) little data gets submitted there, and d) it’s not possible to request a test run for a PR, or something like that.</p>

<p>This point is frankly just baffling to me. I don’t personally care about SPEC scores, but I know plenty of people do, so why there is no first-class tracking for this is a mystery to me.</p>

<h2 id="ir-design">IR design</h2>

<h3 id="undef-values">Undef values</h3>

<p><a href="https://llvm.org/docs/UndefinedBehavior.html#undef-values">Undef values</a> take an arbitrary value from a certain set. They are used to model uninitialized values, and have historically been used to model deferred undefined behavior. The latter role has been replaced by poison values, which have much simpler propagation rules and are more amenable to optimization. However, undef is still used for uninitialized memory to this day.</p>

<p>There are two main problems with undef values. The first is the multi-use problem: An undef value can take a different value at each use. This means that transforms that increase the use count are generally invalid, and care has to be taken when optimizing based on value equality. The mere existence of undef values prevents us from performing optimizations we want to do, or greatly increases their complexity.</p>

<p>The second issue is that undef is very hard to reason about. Humans have trouble understanding it, and for proof-checkers it is computationally expensive.</p>

<p>Most likely, uninitialized memory will be represented using poison values instead in the future, but this runs into the problem that LLVM currently is not capable of correctly treating poison in memory. Proper support for poison in memory requires additional IR features, like the <a href="https://blog.llvm.org/posts/2025-08-29-gsoc-byte-type/">byte type</a>.</p>

<h3 id="unsoundness-and-specification-incompleteness">Unsoundness and specification incompleteness</h3>

<p>While most miscompilations (that is, correctness bugs) in LLVM are resolved quickly, there are quite a few that remain unfixed despite having been known for a long time. These issues usually combine the qualities of being largely theoretical (that is, appearing only in artificially constructed examples rather than real-world code) and running up against issues in LLVM’s IR design.</p>

<p>Some of them are cases where we have a good idea of how the IR design needs to change to address the issue, but these changes are complex and often require a lot of work to recover optimization parity. There is often a complexity cliff where you can do something that’s simple and <em>nearly</em> correct, or you can do something very complex that is fully correct.</p>

<p>Then there are other cases, where just deciding on how things <em>should</em> work is a hard problem. The provenance model is a prime example of this. The interaction of provenance with integer casts and type punning is a difficult problem with complex tradeoffs.</p>

<p>However, at some point these issues do need to be resolved. The recently formed <a href="https://discourse.llvm.org/t/rfc-forming-a-working-group-on-formal-specification-for-llvm/89056?u=nikic">formal specification working group</a> aims to tackle these problems.</p>

<h3 id="constraint-encoding">Constraint encoding</h3>

<p>A key challenge for optimizing compilers is encoding of constraints (like “this value is non-negative” or “this add will not overflow”). This includes both frontend-provided constraints (based on language undefined behavior rules), but also compiler-generated ones.</p>

<p>In particular, there are many different analyses that can infer facts about the program, but keeping these up-to-date throughout optimization is challenging. One good way to handle this is to encode facts directly in the IR. Correctly updating or discarding these annotations then becomes part of transform correctness.</p>

<p>LLVM has many different ways to encode additional constraints (poison flags, metadata, attributes, assumes), and these all come with tradeoffs in terms of how much information can be encoded, how reliably it is retained during optimization and to what degree it can <em>negatively</em> affect optimization. Information from metadata is lost too often, while information from assumes is not lost often enough.</p>

<h3 id="floating-point-semantics">Floating-point semantics</h3>

<p>There are various issues with floating-point (FP) semantics once we move outside the nice world of “strictly conforming IEEE 754 floats in the default environment”. A few that come to mind are:</p>

<ul>
  <li>Handling of signaling NaN and FP exceptions, and non-default FP environment in general. LLVM represents this using constrained FP intrinsics. This is not ideal, as all the FP handling is split into two parallel universes.</li>
  <li>Handling of denormals. LLVM has a function attribute to not assume IEEE denormal behavior, but this is only suitable for cases where flush to zero (FTZ) is used globally. It does not help with modeling cases like ARM, where scalar ops are IEEE, while vector ops use FTZ.</li>
  <li>Handling of excess precision, in particular when using the x87 FPU.</li>
</ul>

<!--### Type-based representation

This is something I've written about enough in the past, so I'll keep it brief: For historical reasons, LLVM IR encodes unnecessary type information that no longer carries any semantic meaning in various places. The biggest offender here were pointer element types, which were removed by the [opaque pointers migration][opaque_pointers].-->

<h2 id="other-technical-issues">Other technical issues</h2>

<h3 id="partial-migrations">Partial migrations</h3>

<p>LLVM is a very large project, and making any significant changes to it is hard and time consuming. Migrations often span years, where two different implementations of something coexist, until all code has been migrated. The two prime examples of this are:</p>

<p><strong>New pass manager:</strong> The “new” pass manager was first introduced more than a decade ago. Then about five years ago, we started using it for the middle-end optimization pipeline by default, and support for the legacy PM was dropped.</p>

<p>However, the back-end is still using the legacy pass manager. There is ongoing work to support the new pass manager in codegen, and we’re pretty close to the point where it can be used end-to-end for a single target. However, I expect it will still take quite a while for all targets to be ported and the legacy pass manager to be completely retired.</p>

<p><strong>GlobalISel:</strong> This is an even more extreme case. GlobalISel is the “new” instruction selector that is intended to replace SelectionDAG (and FastISel). It was introduced approximately one decade ago, and to this day, none of the targets that originally used SelectionDAG have been fully migrated to GlobalISel. There is one new target that’s GlobalISel-only, and there is one that uses GlobalISel by default for unoptimized builds. But otherwise, SelectionDAG is still the default everywhere.</p>

<p>There are two backends (AMDGPU and AArch64) that have somewhat complete GlobalISel support, but it’s not clear when/if they’ll be able to switch to using it by default. A big problem here is that new optimizations are continually being implemented on the SDAG side, so it’s hard to keep parity.</p>

<h3 id="abi--calling-convention-handling">ABI / calling convention handling</h3>

<p>Essentially everything about the handling of calling conventions in LLVM is a mess.</p>

<p>The responsibility for handling calling conventions is split between the frontend and the backend. There are good reasons why LLVM can’t do this by itself (LLVM IR sits at a too low level of abstraction to satisfy the extremely arcane ABI rules).</p>

<p>This is not a problem in itself – however, there is zero documentation of what the calling convention contract between the frontend and LLVM is, and the proper way to implement C FFI is essentially to look at what Clang does and copy that (invariably with errors, because the rules can be very subtle).</p>

<p>I’ve proposed to fix this by introducing an <a href="https://discourse.llvm.org/t/rfc-an-abi-lowering-library-for-llvm/84495?u=nikic">ABI lowering library</a> and vortex73 has <a href="https://blog.llvm.org/posts/2025-08-25-abi-library/">implemented a prototype</a> for it as part of GSoC. So we’re well on the way to resolving this side of the problem.</p>

<p>There are more problems though. One that Rust has struggled with a lot is the interaction of target features with the calling convention. Enabling additional target features can change the call ABI, because additional float/vector registers start getting used for argument/return passing. This means that calls between functions with a feature enabled and disabled may be incompatible, because they assume different ABIs.</p>

<p>Ideally, ABI and target features would be orthogonal, and only coupled in that some ABIs require certain target features (e.g. you can’t have a hard float ABI without enabling FP registers). Target features are a per-function choice, while the ABI should be per-module.</p>

<p>Some of the newer architectures like Loongarch and RISC-V actually have proper ABI design, but most of the older ones don’t. For example, it’s currently not possible to target AArch64 with a soft float ABI but hard float implementation.</p>

<h3 id="builtins--libcalls">Builtins / libcalls</h3>

<p>Somewhat related to this is the handling of compiler builtins/libcalls, which are auxiliary functions that the compiler may emit for operations that are not natively supported by the target. This covers both libcalls provided by libc (or libm), and builtins provided by compiler runtime libraries like libgcc, compiler-rt or compiler-builtins.</p>

<p>There are two sources of truth for this, TargetLibraryInfo (TLI) and RuntimeLibcalls. The former is used by the middle-end, primarily to recognize and optimize C library calls (this mostly covers only libc, but not libgcc). The latter is used by the backend, primarily to determine which libcalls may be emitted by the compiler and how they are spelled (this covers libgcc, and the subset of libc covered by LLVM intrinsics).</p>

<p>A problem with RuntimeLibcalls is that it currently largely works off only the target triple, which means that we have to make “lowest common denominator” assumptions about which libcalls are available, where the lowest common denominator is usually libgcc. If <code>--rtlib=compiler-rt</code> is used, LLVM does not actually know about that, and cannot make use of functions that are in compiler-rt but not libgcc.</p>

<p>This also means that we’re missing a customization point for other runtime libraries. For example, there is no way for Rust to say that it provides f128 suffix libcalls via compiler-builtins, overriding target-specific naming and availability assumptions based on which type <code>long double</code> in C maps to.</p>

<p>There is a lot of ongoing work in this area (by arsenm), so the situation here will hopefully improve in the near-ish future.</p>

<h3 id="context--module-dichotomy">Context / module dichotomy</h3>

<p>LLVM has two high-level data holders. A module corresponds to a compilation unit (e.g. pre-LTO, a single file in C/C++). The LLVM context holds various “global” data. There’s usually one context per thread, and multiple modules can (in principle) use a single context.</p>

<p>Things like functions and globals go into the module, while constants and types go into the context. The module also contains a data layout, which provides important type layout information like “how wide is a pointer”.</p>

<p>The fact that constants and types do not have access to the data layout is a constant source of friction. If you have a type, you cannot reliably tell its size without threading an extra parameter through everything. We have subsystems (like ConstantFold vs. ConstantFolding) that are separated entirely by whether data layout is available or not.</p>

<p>At the same time, I feel like this split is not actually buying us a lot. Having shared types and constants is somewhat convenient when it comes to module linking, because they can be directly shared, but I think performing explicit remapping in that one place would be better than having complexity everywhere else. Additionally, this would also allow cross-context linking, which is currently only possible by going through a bitcode roundtrip. In theory, the context could also allow some memory reuse when compiling multiple modules, but I think in practice there is usually a one-to-one correspondence between those.</p>

<h3 id="licm-register-pressure">LICM register pressure</h3>

<p>This is getting a bit down in the weeds, but I’ll mention it anyway due to how often I’ve run across this in recent times.</p>

<p>LLVM considers loop invariant code motion (LICM) to be a canonicalization transform. This means that we always hoist instructions out of loops, without any target specific cost modelling. However, LICM can increase the live ranges of values, which can increase register pressure, which can lead to a large amount of spills and reloads.</p>

<p>The general philosophy behind this is that LICM hoists everything, all middle-end transforms can work with nicely loop invariant instructions, and then instructions will get sunk back into the loop by the backend, which can precisely model register pressure.</p>

<p>Except… that second part doesn’t actually happen. I believe that (for non-PGO builds) instructions only get sunk back into loops either through rematerialization in the register allocator, or specialized sinking (typically of addressing modes), but for anything not falling into those buckets, no attempt to sink into loops in order to reduce register pressure is made.</p>

<h2 id="other">Other</h2>

<p>This list is not exhaustive. There’s more I could mention, but we’d get into increasingly narrow territory. I hope I covered most of the more important things – please do let me know what I missed!</p>



        
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reproducing DeepSeek's MHC: When Residual Connections Explode (107 pts)]]></title>
            <link>https://taylorkolasinski.com/notes/mhc-reproduction/</link>
            <guid>46588572</guid>
            <pubDate>Mon, 12 Jan 2026 13:57:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taylorkolasinski.com/notes/mhc-reproduction/">https://taylorkolasinski.com/notes/mhc-reproduction/</a>, See on <a href="https://news.ycombinator.com/item?id=46588572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <article>  <p>January 11, 2026</p> <p><strong>Every transformer you’ve ever used has the same residual connection design from 2016.</strong></p>
<p>GPT-5, Claude, Llama, Gemini. Under the hood, they all do the same thing: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>+</mo><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x + F(x)</annotation></semantics></math></span></span>. One stream of information flowing through the network, with each layer adding to it.</p>
<p>DeepSeek asked: what if it was wider?</p>
<figure data-astro-cid-bj3fsypb=""> <img src="https://taylorkolasinski.com/figures/v5_publication_summary.png" alt="mHC reproduction results" data-astro-cid-bj3fsypb="">  </figure> 

<h2 id="the-setup">The Setup</h2>
<p><strong>Standard residual connections</strong> are the backbone of every modern transformer. The idea is simple:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>l</mi></msub><mo>+</mo><mi>F</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_{l+1} = x_l + F(x_l)</annotation></semantics></math></span></span></span>
<p>The input flows through unchanged, plus the layer’s output. One stream of information. What goes in comes out, plus a learned update. This is why transformers can be hundreds of layers deep: the gradient has a clean path backward. Simple. Stable. Unchanged since 2016.</p>
<p><strong>Hyper-Connections</strong> take a different approach. Instead of one stream, expand to <strong>n parallel streams</strong> with learnable mixing matrices:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msubsup><mi>H</mi><mi>l</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi></mrow></msubsup><msub><mi>x</mi><mi>l</mi></msub><mo>+</mo><msubsup><mi>H</mi><mi>l</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo separator="true">,</mo><mi>T</mi></mrow></msubsup><mi>F</mi><mo stretchy="false">(</mo><msubsup><mi>H</mi><mi>l</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msubsup><msub><mi>x</mi><mi>l</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_{l+1} = H^{res}_l x_l + H^{post,T}_l F(H^{pre}_l x_l, W_l)</annotation></semantics></math></span></span></span>
<p>Compared to standard residual:</p>
<div data-astro-cid-y5xpyeus=""> <p id="hc-flow" data-astro-cid-y5xpyeus=""> <svg viewBox="0 0 700 200" xmlns="http://www.w3.org/2000/svg" data-astro-cid-y5xpyeus=""> <defs data-astro-cid-y5xpyeus=""> <!-- Glow filters --> <filter id="glow-gray" x="-50%" y="-50%" width="200%" height="200%" data-astro-cid-y5xpyeus=""> <feGaussianBlur stdDeviation="2" result="blur" data-astro-cid-y5xpyeus=""></feGaussianBlur> <feMerge data-astro-cid-y5xpyeus=""> <feMergeNode in="blur" data-astro-cid-y5xpyeus=""></feMergeNode> <feMergeNode in="SourceGraphic" data-astro-cid-y5xpyeus=""></feMergeNode> </feMerge> </filter> <filter id="glow-red" x="-50%" y="-50%" width="200%" height="200%" data-astro-cid-y5xpyeus=""> <feGaussianBlur stdDeviation="3" result="blur" data-astro-cid-y5xpyeus=""></feGaussianBlur> <feMerge data-astro-cid-y5xpyeus=""> <feMergeNode in="blur" data-astro-cid-y5xpyeus=""></feMergeNode> <feMergeNode in="SourceGraphic" data-astro-cid-y5xpyeus=""></feMergeNode> </feMerge> </filter> <filter id="glow-teal" x="-50%" y="-50%" width="200%" height="200%" data-astro-cid-y5xpyeus=""> <feGaussianBlur stdDeviation="2" result="blur" data-astro-cid-y5xpyeus=""></feGaussianBlur> <feMerge data-astro-cid-y5xpyeus=""> <feMergeNode in="blur" data-astro-cid-y5xpyeus=""></feMergeNode> <feMergeNode in="SourceGraphic" data-astro-cid-y5xpyeus=""></feMergeNode> </feMerge> </filter> </defs> <!-- LEFT SIDE: Standard Residual --> <g data-astro-cid-y5xpyeus=""> <!-- Title --> <text x="150" y="20" text-anchor="middle" fill="var(--color-residual)" data-astro-cid-y5xpyeus="">Standard Residual</text> <!-- Main stream line --> <line x1="30" y1="110" x2="270" y2="110" stroke="var(--color-residual)" stroke-width="2" opacity="0.4" data-astro-cid-y5xpyeus=""></line> <!-- Branch up to F --> <path d="M 100 110 L 100 70" stroke="var(--color-residual)" stroke-width="2" opacity="0.4" fill="none" data-astro-cid-y5xpyeus=""></path> <!-- F box --> <rect x="80" y="45" width="40" height="30" rx="4" fill="var(--color-bg)" stroke="var(--color-residual)" stroke-width="2" data-astro-cid-y5xpyeus=""></rect> <text x="100" y="65" text-anchor="middle" fill="var(--color-residual)" data-astro-cid-y5xpyeus="">F</text> <!-- Branch down from F --> <path d="M 120 60 L 180 60 L 180 110" stroke="var(--color-residual)" stroke-width="2" opacity="0.4" fill="none" data-astro-cid-y5xpyeus=""></path> <!-- Plus symbol --> <circle cx="180" cy="110" r="10" fill="var(--color-bg)" stroke="var(--color-residual)" stroke-width="2" data-astro-cid-y5xpyeus=""></circle> <line x1="175" y1="110" x2="185" y2="110" stroke="var(--color-residual)" stroke-width="2" data-astro-cid-y5xpyeus=""></line> <line x1="180" y1="105" x2="180" y2="115" stroke="var(--color-residual)" stroke-width="2" data-astro-cid-y5xpyeus=""></line> <!-- Animated dot on main path --> <circle cx="30" cy="110" r="4" fill="var(--color-residual)" filter="url(#glow-gray)" data-astro-cid-y5xpyeus=""></circle> <!-- Animated dot on F path --> <circle cx="100" cy="110" r="3" fill="var(--color-residual)" filter="url(#glow-gray)" opacity="0" data-astro-cid-y5xpyeus=""></circle> <circle cx="120" cy="60" r="3" fill="var(--color-residual)" filter="url(#glow-gray)" opacity="0" data-astro-cid-y5xpyeus=""></circle> <circle cx="180" cy="60" r="3" fill="var(--color-residual)" filter="url(#glow-gray)" opacity="0" data-astro-cid-y5xpyeus=""></circle> </g> <!-- RIGHT SIDE: Hyper-Connection --> <g transform="translate(350, 0)" data-astro-cid-y5xpyeus=""> <!-- Title --> <text x="160" y="20" text-anchor="middle" fill="var(--color-text)" data-astro-cid-y5xpyeus="">Hyper-Connection</text> <!-- Stream lines --> <line x1="30" y1="55" x2="310" y2="55" stroke="var(--color-text)" stroke-width="2" opacity="0.3" data-astro-cid-y5xpyeus=""></line> <line x1="30" y1="85" x2="310" y2="85" stroke="var(--color-text)" stroke-width="2" opacity="0.3" data-astro-cid-y5xpyeus=""></line> <line x1="30" y1="115" x2="310" y2="115" stroke="var(--color-text)" stroke-width="2" opacity="0.3" data-astro-cid-y5xpyeus=""></line> <line x1="30" y1="145" x2="310" y2="145" stroke="var(--color-text)" stroke-width="2" opacity="0.3" data-astro-cid-y5xpyeus=""></line> <!-- H_res mixing zone background --> <rect x="70" y="45" width="50" height="110" fill="var(--color-hc)" opacity="0" rx="4" data-astro-cid-y5xpyeus=""></rect> <!-- H_res crossing lines (faint) --> <g opacity="0.15" data-astro-cid-y5xpyeus=""> <line x1="75" y1="55" x2="115" y2="85" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="55" x2="115" y2="115" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="85" x2="115" y2="55" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="85" x2="115" y2="145" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="115" x2="115" y2="85" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="115" x2="115" y2="145" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="145" x2="115" y2="115" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="75" y1="145" x2="115" y2="55" stroke="var(--color-hc)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> </g> <!-- Labels --> <text x="95" y="170" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-y5xpyeus="">H_res</text> <text x="155" y="42" text-anchor="middle" fill="var(--color-muted)" data-astro-cid-y5xpyeus="">H_pre</text> <text x="215" y="42" text-anchor="middle" fill="var(--color-muted)" data-astro-cid-y5xpyeus="">H_post</text> <!-- H_pre aggregation lines --> <g opacity="0.2" data-astro-cid-y5xpyeus=""> <line x1="140" y1="55" x2="165" y2="85" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="140" y1="85" x2="165" y2="85" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="140" y1="115" x2="165" y2="115" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="140" y1="145" x2="165" y2="115" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> </g> <!-- F box --> <rect x="165" y="75" width="40" height="50" rx="4" fill="var(--color-bg)" stroke="var(--color-text)" stroke-width="2" data-astro-cid-y5xpyeus=""></rect> <text x="185" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-y5xpyeus="">F</text> <!-- H_post distribution lines --> <g opacity="0.2" data-astro-cid-y5xpyeus=""> <line x1="205" y1="85" x2="230" y2="55" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="205" y1="85" x2="230" y2="85" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="205" y1="115" x2="230" y2="115" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> <line x1="205" y1="115" x2="230" y2="145" stroke="var(--color-text)" stroke-width="1" data-astro-cid-y5xpyeus=""></line> </g> <!-- Stream dots --> <circle cx="30" cy="55" r="4" fill="var(--color-text)" filter="url(#glow-teal)" data-astro-cid-y5xpyeus=""></circle> <circle cx="30" cy="85" r="4" fill="var(--color-text)" filter="url(#glow-teal)" data-astro-cid-y5xpyeus=""></circle> <circle cx="30" cy="115" r="4" fill="var(--color-text)" filter="url(#glow-teal)" data-astro-cid-y5xpyeus=""></circle> <circle cx="30" cy="145" r="4" fill="var(--color-text)" filter="url(#glow-teal)" data-astro-cid-y5xpyeus=""></circle> <!-- Mixing flash dots (hidden by default) --> <circle cx="95" cy="70" r="6" fill="var(--color-hc)" filter="url(#glow-red)" opacity="0" data-astro-cid-y5xpyeus=""></circle> <circle cx="95" cy="100" r="6" fill="var(--color-hc)" filter="url(#glow-red)" opacity="0" data-astro-cid-y5xpyeus=""></circle> <circle cx="95" cy="130" r="6" fill="var(--color-hc)" filter="url(#glow-red)" opacity="0" data-astro-cid-y5xpyeus=""></circle> </g> </svg> </p> </div>  
<p>Three matrices control how information flows:</p>
<ul>
<li><strong>H_res</strong>: How streams mix in the residual path (the red crossings)</li>
<li><strong>H_pre</strong>: How streams combine before entering the layer</li>
<li><strong>H_post</strong>: How the layer’s output distributes back to streams</li>
</ul>
<p>More expressive. More parameters with negligible computational overhead. Better performance, in theory.</p>
<p>The problem? Those mixing matrices are <strong>unconstrained</strong>. They can amplify signals, not just route them.</p>
<hr>
<h2 id="the-explosion">The Explosion</h2>
<p>Under aggressive learning rates, Hyper-Connection (HC) signal amplification in my reproduction hit 7x before eventually collapsing. Amax (the maximum of row and column absolute sums) measures how much a matrix can amplify signals.</p>
<p data-astro-cid-2v76jlwr=""> <svg viewBox="0 0 600 180" xmlns="http://www.w3.org/2000/svg" data-astro-cid-2v76jlwr=""> <!-- TOP ROW: Unconstrained (HC) --> <g transform="translate(0, 0)" data-astro-cid-2v76jlwr=""> <!-- Label --> <text x="10" y="20" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">Unconstrained (HC)</text> <!-- Layer boxes with multipliers --> <g transform="translate(20, 35)" data-astro-cid-2v76jlwr=""> <!-- Layer 1 --> <circle cx="30" cy="20" r="18" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="30" y="25" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.1x</text> <text x="30" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.1</text> <!-- Arrow --> <line x1="52" y1="20" x2="78" y2="20" stroke="var(--color-hc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="80,20 74,17 74,23" fill="var(--color-hc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 2 --> <circle cx="110" cy="20" r="18" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="110" y="25" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.2x</text> <text x="110" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.32</text> <!-- Arrow --> <line x1="132" y1="20" x2="158" y2="20" stroke="var(--color-hc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="160,20 154,17 154,23" fill="var(--color-hc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 3 --> <circle cx="190" cy="20" r="18" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="190" y="25" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.15x</text> <text x="190" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.52</text> <!-- Arrow --> <line x1="212" y1="20" x2="238" y2="20" stroke="var(--color-hc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="240,20 234,17 234,23" fill="var(--color-hc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 4 --> <circle cx="270" cy="20" r="18" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="270" y="25" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.1x</text> <text x="270" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.67</text> <!-- Arrow --> <line x1="292" y1="20" x2="318" y2="20" stroke="var(--color-hc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="320,20 314,17 314,23" fill="var(--color-hc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 5 --> <circle cx="350" cy="20" r="18" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="350" y="25" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">1.2x</text> <text x="350" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">2.0</text> <!-- Ellipsis --> <text x="400" y="25" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">...</text> </g> <!-- Final annotation --> <text x="480" y="55" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">After 60 layers:</text> <text x="480" y="75" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-2v76jlwr="">304x</text> </g> <!-- BOTTOM ROW: Constrained (mHC) --> <g transform="translate(0, 90)" data-astro-cid-2v76jlwr=""> <!-- Label --> <text x="10" y="20" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">Constrained (mHC)</text> <!-- Layer boxes with multipliers --> <g transform="translate(20, 35)" data-astro-cid-2v76jlwr=""> <!-- Layer 1 --> <circle cx="30" cy="20" r="18" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="30" y="25" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> <text x="30" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0</text> <!-- Arrow --> <line x1="52" y1="20" x2="78" y2="20" stroke="var(--color-mhc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="80,20 74,17 74,23" fill="var(--color-mhc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 2 --> <circle cx="110" cy="20" r="18" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="110" y="25" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> <text x="110" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0</text> <!-- Arrow --> <line x1="132" y1="20" x2="158" y2="20" stroke="var(--color-mhc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="160,20 154,17 154,23" fill="var(--color-mhc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 3 --> <circle cx="190" cy="20" r="18" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="190" y="25" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> <text x="190" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0</text> <!-- Arrow --> <line x1="212" y1="20" x2="238" y2="20" stroke="var(--color-mhc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="240,20 234,17 234,23" fill="var(--color-mhc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 4 --> <circle cx="270" cy="20" r="18" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="270" y="25" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> <text x="270" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0</text> <!-- Arrow --> <line x1="292" y1="20" x2="318" y2="20" stroke="var(--color-mhc)" stroke-width="1.5" data-astro-cid-2v76jlwr=""></line> <polygon points="320,20 314,17 314,23" fill="var(--color-mhc)" data-astro-cid-2v76jlwr=""></polygon> <!-- Layer 5 --> <circle cx="350" cy="20" r="18" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-2v76jlwr=""></circle> <text x="350" y="25" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> <text x="350" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0</text> <!-- Ellipsis --> <text x="400" y="25" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">...</text> </g> <!-- Final annotation --> <text x="480" y="55" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">After 60 layers:</text> <text x="480" y="75" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-2v76jlwr="">1.0x</text> </g> </svg> </p> 
<p>At my 10M parameter scale, this is survivable. But DeepSeek saw this at 27B:</p>
<blockquote data-astro-cid-7q4cr32f=""> <p>“The Amax Gain Magnitude yields extreme values with peaks of 3000”</p> </blockquote> 
<p>That’s not a typo. Three thousand times amplification. At 27B parameters, unconstrained HC didn’t just drift. It exploded. My 10M reproduction hitting 9.2x is the early warning sign of this exponential failure.</p>
<p>This is why unconstrained mixing matrices break at scale. Small amplifications compound exponentially.</p>
<figure data-astro-cid-bj3fsypb=""> <img src="https://taylorkolasinski.com/figures/v5_stress_lr.png" alt="Stress test under aggressive learning rate" data-astro-cid-bj3fsypb=""> <figcaption data-astro-cid-bj3fsypb="">Under aggressive learning rates, HC signal amplification hit 7x before collapsing. mHC stayed flat at 1.0.</figcaption> </figure> 
<hr>
<h2 id="the-fix-constrain-the-manifold">The Fix: Constrain the Manifold</h2>
<p>DeepSeek’s fix is clean: constrain the mixing matrices to be <em>doubly stochastic</em>.</p>
<p>A doubly stochastic matrix has:</p>
<ul>
<li>All non-negative entries</li>
<li>Rows sum to 1</li>
<li>Columns sum to 1</li>
</ul>
<p data-astro-cid-mmd5ea5f=""> <svg viewBox="0 0 520 245" xmlns="http://www.w3.org/2000/svg" data-astro-cid-mmd5ea5f=""> <!-- LEFT: Unconstrained Matrix --> <g transform="translate(10, 30)" data-astro-cid-mmd5ea5f=""> <!-- Title --> <text x="80" y="-10" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">Unconstrained</text> <!-- Grid border --> <rect x="0" y="0" width="160" height="160" fill="none" stroke="var(--color-hc)" stroke-width="2" data-astro-cid-mmd5ea5f=""></rect> <!-- Grid lines --> <line x1="40" y1="0" x2="40" y2="160" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="80" y1="0" x2="80" y2="160" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="120" y1="0" x2="120" y2="160" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="40" x2="160" y2="40" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="80" x2="160" y2="80" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="120" x2="160" y2="120" stroke="var(--color-hc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <!-- Cell backgrounds (color by value) --> <rect x="0" y="0" width="40" height="40" fill="var(--color-hc)" opacity="0.4" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="0" width="40" height="40" fill="#4a90d9" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="0" width="40" height="40" fill="var(--color-hc)" opacity="0.25" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="0" width="40" height="40" fill="var(--color-hc)" opacity="0.15" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="40" width="40" height="40" fill="var(--color-hc)" opacity="0.05" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="40" width="40" height="40" fill="var(--color-hc)" opacity="0.28" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="40" width="40" height="40" fill="#4a90d9" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="40" width="40" height="40" fill="var(--color-hc)" opacity="0.05" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="80" width="40" height="40" fill="var(--color-hc)" opacity="0.18" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="80" width="40" height="40" fill="var(--color-hc)" opacity="0.12" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="80" width="40" height="40" fill="var(--color-hc)" opacity="0.22" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="80" width="40" height="40" fill="var(--color-hc)" opacity="0.06" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="120" width="40" height="40" fill="#4a90d9" opacity="0.15" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="120" width="40" height="40" fill="var(--color-hc)" opacity="0.06" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="120" width="40" height="40" fill="var(--color-hc)" opacity="0.05" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="120" width="40" height="40" fill="var(--color-hc)" opacity="0.05" data-astro-cid-mmd5ea5f=""></rect> <!-- Row 1 values --> <text x="20" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">1.3</text> <text x="60" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">-0.2</text> <text x="100" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.8</text> <text x="140" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.5</text> <!-- Row 2 values --> <text x="20" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <text x="60" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.9</text> <text x="100" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">-0.3</text> <text x="140" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <!-- Row 3 values --> <text x="20" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.6</text> <text x="60" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.4</text> <text x="100" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.7</text> <text x="140" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <!-- Row 4 values --> <text x="20" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">-0.1</text> <text x="60" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <text x="100" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <text x="140" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <!-- Row sums --> <text x="175" y="25" text-anchor="start" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">2.4</text> <text x="175" y="65" text-anchor="start" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">0.8</text> <text x="175" y="105" text-anchor="start" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">1.9</text> <text x="175" y="145" text-anchor="start" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">0.3</text> <!-- Column sums --> <text x="20" y="178" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">1.9</text> <text x="60" y="178" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">1.3</text> <text x="100" y="178" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">1.3</text> <text x="140" y="178" text-anchor="middle" fill="var(--color-hc)" data-astro-cid-mmd5ea5f="">0.9</text> </g> <!-- RIGHT: Doubly Stochastic Matrix --> <g transform="translate(270, 30)" data-astro-cid-mmd5ea5f=""> <!-- Title --> <text x="80" y="-10" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">Doubly Stochastic</text> <!-- Grid border --> <rect x="0" y="0" width="160" height="160" fill="none" stroke="var(--color-mhc)" stroke-width="2" data-astro-cid-mmd5ea5f=""></rect> <!-- Grid lines --> <line x1="40" y1="0" x2="40" y2="160" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="80" y1="0" x2="80" y2="160" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="120" y1="0" x2="120" y2="160" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="40" x2="160" y2="40" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="80" x2="160" y2="80" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <line x1="0" y1="120" x2="160" y2="120" stroke="var(--color-mhc)" stroke-width="1" opacity="0.3" data-astro-cid-mmd5ea5f=""></line> <!-- Cell backgrounds (intensity by value) --> <rect x="0" y="0" width="40" height="40" fill="var(--color-mhc)" opacity="0.4" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="0" width="40" height="40" fill="var(--color-mhc)" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="0" width="40" height="40" fill="var(--color-mhc)" opacity="0.3" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="0" width="40" height="40" fill="var(--color-mhc)" opacity="0.1" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="40" width="40" height="40" fill="var(--color-mhc)" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="40" width="40" height="40" fill="var(--color-mhc)" opacity="0.3" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="40" width="40" height="40" fill="var(--color-mhc)" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="40" width="40" height="40" fill="var(--color-mhc)" opacity="0.3" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="80" width="40" height="40" fill="var(--color-mhc)" opacity="0.3" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="80" width="40" height="40" fill="var(--color-mhc)" opacity="0.2" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="80" width="40" height="40" fill="var(--color-mhc)" opacity="0.4" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="80" width="40" height="40" fill="var(--color-mhc)" opacity="0.1" data-astro-cid-mmd5ea5f=""></rect> <rect x="0" y="120" width="40" height="40" fill="var(--color-mhc)" opacity="0.1" data-astro-cid-mmd5ea5f=""></rect> <rect x="40" y="120" width="40" height="40" fill="var(--color-mhc)" opacity="0.3" data-astro-cid-mmd5ea5f=""></rect> <rect x="80" y="120" width="40" height="40" fill="var(--color-mhc)" opacity="0.1" data-astro-cid-mmd5ea5f=""></rect> <rect x="120" y="120" width="40" height="40" fill="var(--color-mhc)" opacity="0.5" data-astro-cid-mmd5ea5f=""></rect> <!-- Row 1 values --> <text x="20" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.4</text> <text x="60" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <text x="100" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.3</text> <text x="140" y="25" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <!-- Row 2 values --> <text x="20" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <text x="60" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.3</text> <text x="100" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <text x="140" y="65" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.3</text> <!-- Row 3 values --> <text x="20" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.3</text> <text x="60" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.2</text> <text x="100" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.4</text> <text x="140" y="105" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <!-- Row 4 values --> <text x="20" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <text x="60" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.3</text> <text x="100" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.1</text> <text x="140" y="145" text-anchor="middle" fill="var(--color-text)" data-astro-cid-mmd5ea5f="">0.5</text> <!-- Row sums --> <text x="175" y="25" text-anchor="start" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="175" y="65" text-anchor="start" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="175" y="105" text-anchor="start" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="175" y="145" text-anchor="start" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <!-- Column sums --> <text x="20" y="178" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="60" y="178" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="100" y="178" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> <text x="140" y="178" text-anchor="middle" fill="var(--color-mhc)" data-astro-cid-mmd5ea5f="">1.0</text> </g> <!-- Bottom annotation --> <text x="230" y="238" text-anchor="middle" fill="var(--color-muted)" data-astro-cid-mmd5ea5f="">Rows sum to 1, columns sum to 1</text> </svg> </p> 
<p>This means the mixing operation can only take <em>weighted averages</em> of streams. It can route information, shuffle it, blend it. But it cannot amplify.</p>
<p><strong>How?</strong> The Sinkhorn-Knopp algorithm.</p>
<div id="sinkhorn" data-astro-cid-tgptfnc5=""> <svg viewBox="0 0 280 240" xmlns="http://www.w3.org/2000/svg" data-astro-cid-tgptfnc5=""> <!-- Matrix border --> <rect x="40" y="30" width="160" height="160" fill="none" stroke-width="2" data-astro-cid-tgptfnc5=""></rect> <!-- Grid lines --> <g data-astro-cid-tgptfnc5=""> <line x1="80" y1="30" x2="80" y2="190" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> <line x1="120" y1="30" x2="120" y2="190" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> <line x1="160" y1="30" x2="160" y2="190" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> <line x1="40" y1="70" x2="200" y2="70" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> <line x1="40" y1="110" x2="200" y2="110" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> <line x1="40" y1="150" x2="200" y2="150" stroke-width="1" opacity="0.3" data-astro-cid-tgptfnc5=""></line> </g> <!-- Cell backgrounds --> <g data-astro-cid-tgptfnc5=""> <rect data-row="0" data-col="0" x="40" y="30" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="0" data-col="1" x="80" y="30" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="0" data-col="2" x="120" y="30" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="0" data-col="3" x="160" y="30" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="1" data-col="0" x="40" y="70" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="1" data-col="1" x="80" y="70" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="1" data-col="2" x="120" y="70" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="1" data-col="3" x="160" y="70" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="2" data-col="0" x="40" y="110" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="2" data-col="1" x="80" y="110" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="2" data-col="2" x="120" y="110" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="2" data-col="3" x="160" y="110" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="3" data-col="0" x="40" y="150" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="3" data-col="1" x="80" y="150" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="3" data-col="2" x="120" y="150" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> <rect data-row="3" data-col="3" x="160" y="150" width="40" height="40" data-astro-cid-tgptfnc5=""></rect> </g> <!-- Cell values --> <g data-astro-cid-tgptfnc5=""> <text data-row="0" data-col="0" x="60" y="55" text-anchor="middle" data-astro-cid-tgptfnc5="">0.40</text> <text data-row="0" data-col="1" x="100" y="55" text-anchor="middle" data-astro-cid-tgptfnc5="">0.20</text> <text data-row="0" data-col="2" x="140" y="55" text-anchor="middle" data-astro-cid-tgptfnc5="">0.30</text> <text data-row="0" data-col="3" x="180" y="55" text-anchor="middle" data-astro-cid-tgptfnc5="">0.10</text> <text data-row="1" data-col="0" x="60" y="95" text-anchor="middle" data-astro-cid-tgptfnc5="">0.20</text> <text data-row="1" data-col="1" x="100" y="95" text-anchor="middle" data-astro-cid-tgptfnc5="">0.30</text> <text data-row="1" data-col="2" x="140" y="95" text-anchor="middle" data-astro-cid-tgptfnc5="">0.20</text> <text data-row="1" data-col="3" x="180" y="95" text-anchor="middle" data-astro-cid-tgptfnc5="">0.30</text> <text data-row="2" data-col="0" x="60" y="135" text-anchor="middle" data-astro-cid-tgptfnc5="">0.30</text> <text data-row="2" data-col="1" x="100" y="135" text-anchor="middle" data-astro-cid-tgptfnc5="">0.20</text> <text data-row="2" data-col="2" x="140" y="135" text-anchor="middle" data-astro-cid-tgptfnc5="">0.40</text> <text data-row="2" data-col="3" x="180" y="135" text-anchor="middle" data-astro-cid-tgptfnc5="">0.10</text> <text data-row="3" data-col="0" x="60" y="175" text-anchor="middle" data-astro-cid-tgptfnc5="">0.10</text> <text data-row="3" data-col="1" x="100" y="175" text-anchor="middle" data-astro-cid-tgptfnc5="">0.30</text> <text data-row="3" data-col="2" x="140" y="175" text-anchor="middle" data-astro-cid-tgptfnc5="">0.10</text> <text data-row="3" data-col="3" x="180" y="175" text-anchor="middle" data-astro-cid-tgptfnc5="">0.50</text> </g> <!-- Row sums --> <g data-astro-cid-tgptfnc5=""> <text data-row="0" x="215" y="55" text-anchor="start" data-astro-cid-tgptfnc5="">1.0</text> <text data-row="1" x="215" y="95" text-anchor="start" data-astro-cid-tgptfnc5="">1.0</text> <text data-row="2" x="215" y="135" text-anchor="start" data-astro-cid-tgptfnc5="">1.0</text> <text data-row="3" x="215" y="175" text-anchor="start" data-astro-cid-tgptfnc5="">1.0</text> </g> <!-- Column sums --> <g data-astro-cid-tgptfnc5=""> <text data-col="0" x="60" y="208" text-anchor="middle" data-astro-cid-tgptfnc5="">1.0</text> <text data-col="1" x="100" y="208" text-anchor="middle" data-astro-cid-tgptfnc5="">1.0</text> <text data-col="2" x="140" y="208" text-anchor="middle" data-astro-cid-tgptfnc5="">1.0</text> <text data-col="3" x="180" y="208" text-anchor="middle" data-astro-cid-tgptfnc5="">1.0</text> </g> <!-- Sum labels --> <text x="215" y="15" text-anchor="start" fill="var(--color-muted)" data-astro-cid-tgptfnc5="">row</text> <text x="20" y="208" text-anchor="end" fill="var(--color-muted)" data-astro-cid-tgptfnc5="">col</text> </svg>  </div>  
<p>The algorithm is dead simple:</p>
<ol>
<li><strong>Start with any matrix</strong> (the raw learned weights)</li>
<li><strong>Exponentiate</strong> to make all entries positive: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><msup><mi>e</mi><mi>H</mi></msup></mrow><annotation encoding="application/x-tex">P = e^H</annotation></semantics></math></span></span></li>
<li><strong>Normalize rows</strong> so each row sums to 1</li>
<li><strong>Normalize columns</strong> so each column sums to 1</li>
<li><strong>Repeat steps 3-4</strong> until convergence</li>
</ol>
<p>That’s it. Alternate row and column normalization. Twenty iterations is enough.</p>
<p>This procedure is <em>differentiable</em>. Gradients flow back through all twenty iterations. The network learns the raw weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span></span>, and Sinkhorn ensures the actual mixing matrix is always doubly stochastic.</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>P</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mtext>ColNorm</mtext><mo stretchy="false">(</mo><mtext>RowNorm</mtext><mo stretchy="false">(</mo><msup><mi>P</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P^{(t+1)} = \text{ColNorm}(\text{RowNorm}(P^{(t)}))</annotation></semantics></math></span></span></span>
<p>When I first saw this, it felt like cheating. You’re not learning stability. You’re forcing it. But some properties shouldn’t be learned; they should be guaranteed.</p>
<p>Technical note: Strictly speaking, only the recursive matrix H_res needs the full Sinkhorn doubly-stochastic treatment. It’s the one compounding errors layer-over-layer. The input/output mixers (H_pre, H_post) are just bounded via sigmoid. The Sinkhorn compute cost is paid only where it matters most.</p>
<hr>
<h2 id="the-results">The Results</h2>
<figure data-astro-cid-bj3fsypb=""> <img src="https://taylorkolasinski.com/figures/v5_seed_variation.png" alt="Seed variation showing HC instability vs mHC stability" data-astro-cid-bj3fsypb=""> <figcaption data-astro-cid-bj3fsypb="">Across 3 seeds at depth 24: HC (red) varies wildly, mHC (teal) is perfectly consistent.</figcaption> </figure> 
<h3 id="seed-variation-results-depth-24-3-seeds">Seed Variation Results (Depth 24, 3 seeds)</h3>




















<table><thead><tr><th>Model</th><th>Val Loss (mean ± std)</th><th>Max Amax (mean ± std)</th></tr></thead><tbody><tr><td>HC</td><td>0.884 ± 0.033</td><td>6.77 ± 0.60</td></tr><tr><td>mHC</td><td>1.116 ± 0.012</td><td>1.00 ± 0.00</td></tr></tbody></table>
<p>HC wins on raw performance: 0.88 vs 1.12 validation loss. At 10M parameters, the mHC constraint acts like a stability tax; you pay in expressivity. But at 27B parameters, that tax is the only thing preventing your model from exploding to NaN.</p>
<p>But look at the variance. HC’s loss varies 3x more across seeds (±0.033 vs ±0.012). And Amax? HC swings from 6.1 to 7.6 depending on the seed. mHC is 1.00. Every seed. Every run. Zero variance.</p>
<p>At 10M parameters, the instability is survivable. HC still wins. But at 27B parameters, that 6-7x amplification becomes 3000x. You can’t gamble at that scale.</p>
<h3 id="depth-scaling">Depth Scaling</h3>
<figure data-astro-cid-bj3fsypb=""> <img src="https://taylorkolasinski.com/figures/v5_depth_sweep.png" alt="How HC behaves across depths" data-astro-cid-bj3fsypb=""> <figcaption data-astro-cid-bj3fsypb="">Deeper models learn better but amplify more erratically.</figcaption> </figure> 
<p>I also swept depths from 6 to 24 layers (constant ~11M parameter budget):</p>
<ul>
<li><strong>Loss improves with depth</strong>, until it doesn’t. Depth 20 hit the sweet spot (0.85 val loss). Depth 24 regressed slightly (0.93) due to the width bottleneck from shrinking dim to 192.</li>
<li><strong>Amax is unpredictable.</strong> Depth 20 spiked to 9.2x. Depth 12 hit 6.6x. Depth 8 stayed at 4.3x. There’s no clean relationship; HC is chaotic.</li>
</ul>
<h3 id="experiment-details">Experiment Details</h3>
<p><strong>Dataset:</strong> TinyShakespeare (~1M chars, character-level)
<strong>Model:</strong> GPT-2 architecture, ~10M parameters
<strong>Training:</strong> 5000 steps, AdamW (β1=0.9, β2=0.95), weight decay 0.1, cosine LR decay
<strong>Hardware:</strong> Apple M-series (MPS)</p>
<p><strong>Depth sweep:</strong> 8 configurations (6-24 layers), width adjusted to maintain ~11M params
<strong>Seed variation:</strong> 3 seeds (42, 123, 456) at depth 24</p>
<hr>
<h2 id="why-this-matters">Why This Matters</h2>
<p>Residual connections are more than a trick to help gradients flow. They’re a conservation law.</p>
<p>In physics, conservation laws constrain what’s possible but enable prediction. You can’t build a perpetual motion machine, but you can calculate exactly where a ball will land.</p>
<p>The identity mapping in residual connections is similar. It constrains the network by preventing arbitrary transformations, but it guarantees stability. Signal magnitude is preserved.</p>
<p>HC breaks conservation; mHC restores it, not by returning to identity, but by finding a richer manifold that still conserves signal.</p>
<p>In 2016, He et al. introduced ResNets to solve the vanishing gradient problem, ensuring signals didn’t die. Ten years later, the opposite problem emerged: exploding signals from hyper-connectivity. The identity mapping solved the first by being passive. mHC solves the second by enforcing conservation.</p>
<blockquote data-astro-cid-7q4cr32f=""> <p>Every residual connection is a conservation law. mHC enforces it.</p> </blockquote> 
<p>Not a hack, not a trick. A principled constraint that makes the architecture work at scale.</p>
<hr>
<h2 id="takeaways">Takeaways</h2>
<ol>
<li>
<p><strong>The stream persistence bug humbled me.</strong> My first implementation looked right. The equations matched the paper. The code ran. But I was projecting the output back to a single stream and re-expanding it at each layer, killing the parallel architecture. The “hyper” part of Hyper-Connections wasn’t actually doing anything. Three separate audits said “looks correct.” The bug was architectural, not mathematical. I only caught it by asking: “Wait, what shape is actually flowing between layers?”</p>
</li>
<li>
<p><strong>Constraints aren’t limitations; they’re guarantees.</strong> The doubly stochastic projection forces stability. You’re not learning good behavior. You’re making bad behavior impossible. My first reaction: “That’s not elegant. That’s a straitjacket.” Then I saw HC hit 7x amplification. Oh. That’s the point.</p>
</li>
<li>
<p><strong>The boring choice scales.</strong> Standard residual connections have survived since 2016 not because they’re optimal, but because they’re stable. HC is more expressive but fragile. mHC finds a middle ground: more expressive than standard residuals, with stability guarantees.</p>
</li>
</ol>
<hr>
<h2 id="whats-next">What’s Next</h2>
<p>This is <strong>Part 1</strong> of a two-part series.</p>
<p><strong>Part 1 (this post):</strong> Reproduce mHC at small scale to understand the mechanics.</p>
<ul>
<li>10M parameters, TinyShakespeare dataset</li>
<li>Constant parameter budget across depths</li>
<li>Goal: Validate the core claim: HC explodes, mHC doesn’t</li>
</ul>
<p><strong>Part 2 (Thursday):</strong> Scale up to see real instability.</p>
<ul>
<li>1B parameters on A100s</li>
<li>C4 dataset, fixed width (no bottleneck)</li>
<li>Goal: Push toward the 3000x Amax regime</li>
</ul>
<p>At 10M params, HC peaked at 9.2x amplification, chaotic but survivable. The paper saw 3000x at 27B. Part 2 will show where things break.</p>
<hr>
<h2 id="resources">Resources</h2>
<p><strong>Paper:</strong> <a href="https://arxiv.org/abs/2512.24880">Manifold-Constrained Hyper-Connections</a> (arXiv 2512.24880)</p>
<p><strong>Related:</strong> <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning</a> (He et al., 2016)</p>
<p><strong>Code:</strong> Coming with Part 2.</p>
<hr>
<p><em>Part 2 comes Thursday. Follow <a href="https://x.com/TayKolasinski">@TayKolasinski</a> to catch it.</em></p> </article>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ireland fast tracks Bill to criminalise harmful voice or image misuse (143 pts)]]></title>
            <link>https://www.irishtimes.com/ireland/2026/01/07/call-to-fast-track-bill-targeting-ai-deepfakes-and-identity-hijacking/</link>
            <guid>46588319</guid>
            <pubDate>Mon, 12 Jan 2026 13:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.irishtimes.com/ireland/2026/01/07/call-to-fast-track-bill-targeting-ai-deepfakes-and-identity-hijacking/">https://www.irishtimes.com/ireland/2026/01/07/call-to-fast-track-bill-targeting-ai-deepfakes-and-identity-hijacking/</a>, See on <a href="https://news.ycombinator.com/item?id=46588319">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>The head of the Oireachtas committee on <a href="https://www.irishtimes.com/tags/artificial-intelligence/" target="_self" rel="" title="https://www.irishtimes.com/tags/artificial-intelligence/">artificial intelligence (AI)</a> has called on the Government to fast track a Bill that would criminalise the harmful misuse of someone’s voice or image. </p><p>Fianna Fáil TD <a href="https://www.irishtimes.com/tags/malcolm-byrne/" target="_self" rel="" title="https://www.irishtimes.com/tags/malcolm-byrne/">Malcolm Byrne</a> introduced the Protection of Voice and Image Bill in April, which would criminalise what are colloquially known as “deepfakes” - when someone’s voice or image is used to generate a false photo or video with AI. </p><p>It follows concerns over <a href="https://www.irishtimes.com/tags/elon-musk/" rel="" title="https://www.irishtimes.com/tags/elon-musk/">Elon Musk</a>’s AI tool Grok being <a href="https://www.irishtimes.com/crime-law/2026/01/06/non-consensual-ai-images-on-social-media-illegal-content-irish-regulator-says/" target="_self" rel="" title="https://www.irishtimes.com/crime-law/2026/01/06/non-consensual-ai-images-on-social-media-illegal-content-irish-regulator-says/">used to digitally undress women and children</a> for distribution on his social media channel <a href="https://www.irishtimes.com/tags/x/" target="_self" rel="" title="https://www.irishtimes.com/tags/x/">X</a>.</p><p>The strength of laws in Ireland to criminalise AI-generated non-consensual intimate images and child sex abuse images are being examined by the Attorney General.</p><div><h2>READ MORE</h2></div><p>Mr Byrne said while generating child sex abuse imagery and sharing intimate images without consent are already criminal offences, this Bill would create a new standalone criminal offence for those who “knowingly exploit another person’s name, image, voice or likeness without consent”, especially when it is done to harm to deceive. </p><p>“The deliberate misuse of someone’s image or voice without their consent for malign purposes should be a criminal offence. This Bill is a useful baseline and we need to move quickly to address this problem,” Mr Byrne said </p><p>Ireland’s child protection rapporteur, Caoilfhionn Gallagher, has said the harms from deep fake sexual abuse for the individuals depicted are “equivalent” to those from authentic images “because for victims the videos feel real”.</p><p>Ms Gallagher also questioned whether Ireland’s protections holding social media platforms to account were sufficient.</p><p><span>[&nbsp;</span><a aria-label="Open related story" href="https://www.irishtimes.com/ireland/2026/01/05/watchdog-raises-concerns-with-eu-over-x-sexually-explicit-images-created-by-grok-ai/" rel="noreferrer" target="_blank">Watchdog raises concerns with EU over X sexually explicit images created by Grok AI<span>Opens in new window</span></a><span>&nbsp;]</span></p><p>The special rapporteur on child protection was speaking on RTÉ radio’s Morning Ireland about concerns over the X platform’s Grok AI tool which includes the facility to “nudify” images.</p><p>“Given how realistic they are, victims know that they might be perceived as real by others,” she said.</p><p>“Generating these images is often part of a pattern of abuse or harassment. And I’m acutely conscious of the horrendous case of Nicole Coco Fox from Clondalkin, who died by suicide due to online abuse. So we know how devastating online abuse of any kind can be. We have to see this in that perspective.”</p><p>Ms Gallagher also raised the issue of other nudification apps being trained on vast data sets of mostly female images “because they tend to work most effectively on women’s bodies”.</p><p>“As a result, 99 per cent of sexually explicit deepfakes accessible online are estimated to be of women and girls. So this is also a gender-based violence issue.”</p><p>Ms Gallagher added that there was concern internationally about whether the protections in place were sufficient, because most of the protections from a legal and policy perspective internationally were very focused on the users themselves who may generate the images rather than the platforms and the products which facilitate the creation of these images.</p><p>“To take the platforms themselves, in this case X AI has its own acceptable use policy and which prohibits depicting likenesses of persons in a pornographic manner, but plainly that’s completely insufficient.” </p><p>Ms Gallagher said Ireland’s relevant laws, including section five of the Child Trafficking and Pornography Act 1998 and Coco’s Law, were “quite focused on the individual users”.</p><p>“The issue here is Ireland’s not alone and internationally there is a concern about the adequacy of the mechanisms for holding the platforms to account. Ultimately, this is in part a product safety issue and about whether the product itself which allows the images to be generated should be illegal or should be regulated more tightly rather than simply the individual users who take action using it,” she said.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 8 Desktop Environment for Linux (191 pts)]]></title>
            <link>https://github.com/er-bharat/Win8DE</link>
            <guid>46588132</guid>
            <pubDate>Mon, 12 Jan 2026 13:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/er-bharat/Win8DE">https://github.com/er-bharat/Win8DE</a>, See on <a href="https://news.ycombinator.com/item?id=46588132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Windows 8 revival on Linux.</h2><a id="user-content-windows-8-revival-on-linux" aria-label="Permalink: Windows 8 revival on Linux." href="#windows-8-revival-on-linux"></a></p>
<p dir="auto">If you are one of who enjoyed the windows 8 and miss its fluid animations but have since moved to linux.
And cant go back to windows 8, because all apps are non functional there. And if you can bear that you
cant install it on the newer hardware.
This is for you it is a shell for wayland window managers like Labwc hyprland etc. It gives a
wallpaper utility, a lock screen, a start menu, an OSD for volume and brightness a settins app for wall.
it dosent provide charms menu because i always thought its useless.
<a href="https://github.com/user-attachments/assets/8b0269a7-01d3-404d-b637-948cd9f767c7">Win8De.webm</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534447660-2dd5a13d-bda3-40ef-9a3e-b093bd3907df.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3NjYwLTJkZDVhMTNkLWJkYTMtNDBlZi05YTNlLWIwOTNiZDM5MDdkZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01M2I3YThiNTQ4ZWE2NTdkMzhjYmE2NTAwMmNiMGU0NDZkOTY0MWNlMDI3NjZlZTJjNjBkYzQxMDdkMjI5NzNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.wDie5OE6tP9awLpPoR3F-b0-kDnbJuM2RoIrkllW4HA"><img width="1920" height="1080" alt="start" src="https://private-user-images.githubusercontent.com/146621598/534447660-2dd5a13d-bda3-40ef-9a3e-b093bd3907df.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3NjYwLTJkZDVhMTNkLWJkYTMtNDBlZi05YTNlLWIwOTNiZDM5MDdkZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01M2I3YThiNTQ4ZWE2NTdkMzhjYmE2NTAwMmNiMGU0NDZkOTY0MWNlMDI3NjZlZTJjNjBkYzQxMDdkMjI5NzNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.wDie5OE6tP9awLpPoR3F-b0-kDnbJuM2RoIrkllW4HA"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531155931-77e450a7-e43e-43dd-9a3f-789c0eb6e52b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTMxLTc3ZTQ1MGE3LWU0M2UtNDNkZC05YTNmLTc4OWMwZWI2ZTUyYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kMzU5ZjU4NDFjZTE2MTNhZjQyYjgyYTQwNmQyZDE2OWI1MjBhYWJkNWU4ZjI2MTI4ODA0ZTgwZTI5MzAzN2QzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.QdvdYVmHl786RwEXA-UUTwQPrw6RvNrrdJRVEaNgJR4"><img width="1920" height="1080" alt="allapp" src="https://private-user-images.githubusercontent.com/146621598/531155931-77e450a7-e43e-43dd-9a3f-789c0eb6e52b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTMxLTc3ZTQ1MGE3LWU0M2UtNDNkZC05YTNmLTc4OWMwZWI2ZTUyYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kMzU5ZjU4NDFjZTE2MTNhZjQyYjgyYTQwNmQyZDE2OWI1MjBhYWJkNWU4ZjI2MTI4ODA0ZTgwZTI5MzAzN2QzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.QdvdYVmHl786RwEXA-UUTwQPrw6RvNrrdJRVEaNgJR4"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534447821-e3d62c68-5ef4-4128-9192-8854f9a8c07d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3ODIxLWUzZDYyYzY4LTVlZjQtNDEyOC05MTkyLTg4NTRmOWE4YzA3ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jM2JjZmIzYzYzODM0MDY5MDJkMjMyMzVlYTRkOGYzODc1MTRjNTRhYzQ1OWMyZTlhMjJjOTJiMTg5NDcwZTZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.XEuH8rkSGGinaKxqhB446_g6sAMpYzMDekUngOfkWHA"><img width="1920" height="1080" alt="lock-dialog" src="https://private-user-images.githubusercontent.com/146621598/534447821-e3d62c68-5ef4-4128-9192-8854f9a8c07d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3ODIxLWUzZDYyYzY4LTVlZjQtNDEyOC05MTkyLTg4NTRmOWE4YzA3ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jM2JjZmIzYzYzODM0MDY5MDJkMjMyMzVlYTRkOGYzODc1MTRjNTRhYzQ1OWMyZTlhMjJjOTJiMTg5NDcwZTZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.XEuH8rkSGGinaKxqhB446_g6sAMpYzMDekUngOfkWHA"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534448024-6f06bfd1-01dc-4195-8169-0506e238b32c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ4MDI0LTZmMDZiZmQxLTAxZGMtNDE5NS04MTY5LTA1MDZlMjM4YjMyYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NDg2OWYwMDVmMjdiZGQzYThkM2RlN2U3MGI4OTg1ODQ0MjdmYmYzMjE1NWZjMzJlOTNmNGFmZGMwYTEwN2FkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rLHkuFX7xb9-JC-aryDWIFwjkzN_Vl-Tc2x-ISjuIOo"><img width="1920" height="1080" alt="lock-vkey" src="https://private-user-images.githubusercontent.com/146621598/534448024-6f06bfd1-01dc-4195-8169-0506e238b32c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ4MDI0LTZmMDZiZmQxLTAxZGMtNDE5NS04MTY5LTA1MDZlMjM4YjMyYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NDg2OWYwMDVmMjdiZGQzYThkM2RlN2U3MGI4OTg1ODQ0MjdmYmYzMjE1NWZjMzJlOTNmNGFmZGMwYTEwN2FkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rLHkuFX7xb9-JC-aryDWIFwjkzN_Vl-Tc2x-ISjuIOo"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531155943-83ae8072-b697-4b3e-a1f9-b220b58e0424.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTQzLTgzYWU4MDcyLWI2OTctNGIzZS1hMWY5LWIyMjBiNThlMDQyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmFmMmRhNjNkZmVkNzkzMTAyYzUzYjY0MTdkZDE1ZGNjMzI5ZTZlOGJjNWZmZDNhYThjZDI5MDAxMWZmNzg5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ibe9ZaGZr4GyN5W4Bd67b0ghNP1zLZmk2YCrZC_6H1Y"><img width="1920" height="1080" alt="runningapps" src="https://private-user-images.githubusercontent.com/146621598/531155943-83ae8072-b697-4b3e-a1f9-b220b58e0424.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTQzLTgzYWU4MDcyLWI2OTctNGIzZS1hMWY5LWIyMjBiNThlMDQyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmFmMmRhNjNkZmVkNzkzMTAyYzUzYjY0MTdkZDE1ZGNjMzI5ZTZlOGJjNWZmZDNhYThjZDI5MDAxMWZmNzg5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ibe9ZaGZr4GyN5W4Bd67b0ghNP1zLZmk2YCrZC_6H1Y"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531156662-2afc4a9e-00e1-4baf-aea3-be8021915862.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU2NjYyLTJhZmM0YTllLTAwZTEtNGJhZi1hZWEzLWJlODAyMTkxNTg2Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NTdhYzg1YmYyMTkxNGNkY2MzZGRhOWMxMDcxYWQzMTk1ODY5MGU2YmQ2MWM3ODc2Yjg4NjIyOGI1ZDM3ZTE0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.a8tZp72G2uZJLglyRGO9oLTNFD6JBemuTTIUyAy4VtY"><img width="1920" height="1080" alt="lock" src="https://private-user-images.githubusercontent.com/146621598/531156662-2afc4a9e-00e1-4baf-aea3-be8021915862.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU2NjYyLTJhZmM0YTllLTAwZTEtNGJhZi1hZWEzLWJlODAyMTkxNTg2Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NTdhYzg1YmYyMTkxNGNkY2MzZGRhOWMxMDcxYWQzMTk1ODY5MGU2YmQ2MWM3ODc2Yjg4NjIyOGI1ZDM3ZTE0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.a8tZp72G2uZJLglyRGO9oLTNFD6JBemuTTIUyAy4VtY"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start</h3><a id="user-content-start" aria-label="Permalink: Start" href="#start"></a></p>
<ol dir="auto">
<li>one command Win8Start to show hide start menu can be bound to super of compositor.</li>
<li>full drag and drop support of start tiles and sizes small medium large xlarge gui way right click.</li>
<li>can drag from all apps to tiles.</li>
<li>search of apps functional.</li>
<li>drag app from all apps to botom to hide start screen and put icon any where that supports like desktop.</li>
<li>get power menu by clicking user icon.</li>
<li>have battery osd in it.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">OSD</h3><a id="user-content-osd" aria-label="Permalink: OSD" href="#osd"></a></p>
<ol dir="auto">
<li>Volume up down mute</li>
<li>brightness up down.</li>
<li>two part Win8OSD-server and Win8OSD-client server should be autostarted</li>
<li>Win8OSD-client --volup voldown mute dispup dispdown</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wall</h3><a id="user-content-wall" aria-label="Permalink: Wall" href="#wall"></a></p>
<ol dir="auto">
<li>simple image wallpaper</li>
<li>settable through settins</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lockscreen</h3><a id="user-content-lockscreen" aria-label="Permalink: Lockscreen" href="#lockscreen"></a></p>
<ol dir="auto">
<li>windows 8 style</li>
<li>wallpaper changable by settings app</li>
<li>have nice slide down and up of lockscreen</li>
<li>dont need click and drag just click is enough unlike original</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">settings</h3><a id="user-content-settings" aria-label="Permalink: settings" href="#settings"></a></p>
<ol dir="auto">
<li>can change wallpaper of all 3 graphically start wall lock</li>
<li>can change accent colors and background colors of start lockscreen etc.</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">for local binary use run</h3><a id="user-content-for-local-binary-use-run" aria-label="Permalink: for local binary use run" href="#for-local-binary-use-run"></a></p>
<p dir="auto"><code>./build.sh</code></p>
<p dir="auto">it will build all binaries and put it in "build/bin" folder you can use it in config files to autostart
and bind to system keys for brightness and volume with local location.
you can't run settings from start screen bc it uses system location so you will have to run it from binary built.
bind win/super key to Win8Start</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">for system install</h3><a id="user-content-for-system-install" aria-label="Permalink: for system install" href="#for-system-install"></a></p>
<p dir="auto"><code>./install.sh</code></p>
<p dir="auto">it will automatically run build.sh and move the binaries to "/usr/bin/" and will be available systemwide,
so it will be easier to put in configs and autostart</p>
<p dir="auto"><code>./uninstall.sh</code></p>
<p dir="auto">it will remove binaries from <code>/usr/bin/</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use It Like seperate DE</h2><a id="user-content-use-it-like-seperate-de" aria-label="Permalink: Use It Like seperate DE" href="#use-it-like-seperate-de"></a></p>
<p dir="auto">it will use different config file so that your current config is not affected.
create a copy of config folder and paste it with diff name like labwc2 hypr2 etc.</p>
<p dir="auto">find your compositors config loading command and make a .desktop file like this <strong>example</strong>.</p>
<p dir="auto"><code>[Desktop Entry]</code><br>
<code>Name=labwc-win8</code><br>
<code>Comment=A wayland stacking compositor</code><br>
<code>Exec=labwc -C /home/user1/.config/labwc3</code><br>
<code>Icon=labwc</code><br>
<code>Type=Application</code><br>
<code>DesktopNames=labwc;wlroots</code></p>
<p dir="auto">and <strong>paste</strong> it in <code>/usr/share/wayland-sessions/</code></p>
<p dir="auto">and at <em><strong>login choose this session.</strong></em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floppy disks turn out to be the greatest TV remote for kids (617 pts)]]></title>
            <link>https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/</link>
            <guid>46587934</guid>
            <pubDate>Mon, 12 Jan 2026 13:07:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/">https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/</a>, See on <a href="https://news.ycombinator.com/item?id=46587934">Hacker News</a></p>
Couldn't get https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Zen-C: Write like a high-level language, run like C (193 pts)]]></title>
            <link>https://github.com/z-libs/Zen-C</link>
            <guid>46587804</guid>
            <pubDate>Mon, 12 Jan 2026 12:57:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/z-libs/Zen-C">https://github.com/z-libs/Zen-C</a>, See on <a href="https://news.ycombinator.com/item?id=46587804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">Zen C</h2><a id="user-content-zen-c" aria-label="Permalink: Zen C" href="#zen-c"></a></p>
<p dir="auto"><strong>Modern Ergonomics. Zero Overhead. Pure C.</strong></p>
<p dir="auto"><a href="https://github.com/z-libs/Zen-C/blob/main"><img src="https://camo.githubusercontent.com/b0c6c6845a74cb65a7f0a32bdcfd8fbf80eeb40026c4029af424ab371c94b8bd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c642d70617373696e672d627269676874677265656e" alt="Build Status" data-canonical-src="https://img.shields.io/badge/build-passing-brightgreen"></a>
<a href="https://github.com/z-libs/Zen-C/blob/main"><img src="https://camo.githubusercontent.com/b8cadaa967891081f8f165695470689986c028821dd8a040132f6e661795dc0d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c7565" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT-blue"></a>
<a href="https://github.com/z-libs/Zen-C/blob/main"><img src="https://camo.githubusercontent.com/380c38421a611d29ae9f8182f8f5a008e641e8ba8c2b8e45f6a1b7f7cd29d14d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d302e312e302d6f72616e6765" alt="Version" data-canonical-src="https://img.shields.io/badge/version-0.1.0-orange"></a>
<a href="https://github.com/z-libs/Zen-C/blob/main"><img src="https://camo.githubusercontent.com/ec3ffbe89f8d1f152dec06cd451833acef4ded894b500c724cb70033418ec0be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6c696e75782d6c6967687467726579" alt="Platform" data-canonical-src="https://img.shields.io/badge/platform-linux-lightgrey"></a></p>
<p dir="auto"><em>Write like a high-level language, run like C.</em></p>
</div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto"><strong>Zen C</strong> is a modern systems programming language that compiles to human-readable <code>GNU C</code>/<code>C11</code>. It provides a rich feature set including type inference, pattern matching, generics, traits, async/await, and manual memory management with RAII capabilities, all while maintaining 100% C ABI compatibility.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/z-libs/Zen-C.git
cd Zen-C
make
sudo make install"><pre>git clone https://github.com/z-libs/Zen-C.git
<span>cd</span> Zen-C
make
sudo make install</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Compile and run
zc run hello.zc

# Build executable
zc build hello.zc -o hello

# Interactive Shell
zc repl"><pre><span><span>#</span> Compile and run</span>
zc run hello.zc

<span><span>#</span> Build executable</span>
zc build hello.zc -o hello

<span><span>#</span> Interactive Shell</span>
zc repl</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Language Reference</h2><a id="user-content-language-reference" aria-label="Permalink: Language Reference" href="#language-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Variables and Constants</h3><a id="user-content-1-variables-and-constants" aria-label="Permalink: 1. Variables and Constants" href="#1-variables-and-constants"></a></p>
<p dir="auto">Zen C uses type inference by default.</p>
<div data-snippet-clipboard-copy-content="var x = 42;                 // Inferred as int
const PI = 3.14159;         // Compile-time constant
var explicit: float = 1.0;  // Explicit type"><pre lang="zc"><code>var x = 42;                 // Inferred as int
const PI = 3.14159;         // Compile-time constant
var explicit: float = 1.0;  // Explicit type
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mutability</h4><a id="user-content-mutability" aria-label="Permalink: Mutability" href="#mutability"></a></p>
<p dir="auto">By default, variables are mutable. You can enable <strong>Immutable by Default</strong> mode using a directive.</p>
<div data-snippet-clipboard-copy-content="//> immutable-by-default

var x = 10;
// x = 20; // Error: x is immutable

var mut y = 10;
y = 20;    // OK"><pre lang="zc"><code>//&gt; immutable-by-default

var x = 10;
// x = 20; // Error: x is immutable

var mut y = 10;
y = 20;    // OK
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Primitive Types</h3><a id="user-content-2-primitive-types" aria-label="Permalink: 2. Primitive Types" href="#2-primitive-types"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Type</th>
<th>C Equivalent</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>int</code>, <code>uint</code></td>
<td><code>int</code>, <code>unsigned int</code></td>
<td>Platform standard integer</td>
</tr>
<tr>
<td><code>I8</code> .. <code>I128</code></td>
<td><code>int8_t</code> .. <code>__int128_t</code></td>
<td>Signed fixed-width integers</td>
</tr>
<tr>
<td><code>U8</code> .. <code>U128</code></td>
<td><code>uint8_t</code> .. <code>__uint128_t</code></td>
<td>Unsigned fixed-width integers</td>
</tr>
<tr>
<td><code>isize</code>, <code>usize</code></td>
<td><code>ptrdiff_t</code>, <code>size_t</code></td>
<td>Pointer-sized integers</td>
</tr>
<tr>
<td><code>byte</code></td>
<td><code>uint8_t</code></td>
<td>Alias for U8</td>
</tr>
<tr>
<td><code>F32</code>, <code>F64</code></td>
<td><code>float</code>, <code>double</code></td>
<td>Floating point numbers</td>
</tr>
<tr>
<td><code>bool</code></td>
<td><code>bool</code></td>
<td><code>true</code> or <code>false</code></td>
</tr>
<tr>
<td><code>char</code></td>
<td><code>char</code></td>
<td>Single character</td>
</tr>
<tr>
<td><code>string</code></td>
<td><code>char*</code></td>
<td>C-string (null-terminated)</td>
</tr>
<tr>
<td><code>U0</code>, <code>void</code></td>
<td><code>void</code></td>
<td>Empty type</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Aggregate Types</h3><a id="user-content-3-aggregate-types" aria-label="Permalink: 3. Aggregate Types" href="#3-aggregate-types"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arrays</h4><a id="user-content-arrays" aria-label="Permalink: Arrays" href="#arrays"></a></p>
<p dir="auto">Fixed-size arrays with value semantics.</p>
<div data-snippet-clipboard-copy-content="var ints: int[5] = {1, 2, 3, 4, 5};
var zeros: [int; 5]; // Zero-initialized"><pre lang="zc"><code>var ints: int[5] = {1, 2, 3, 4, 5};
var zeros: [int; 5]; // Zero-initialized
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Tuples</h4><a id="user-content-tuples" aria-label="Permalink: Tuples" href="#tuples"></a></p>
<p dir="auto">Group multiple values together.</p>
<div data-snippet-clipboard-copy-content="var pair = (1, &quot;Hello&quot;);
var x = pair.0;
var s = pair.1;"><pre lang="zc"><code>var pair = (1, "Hello");
var x = pair.0;
var s = pair.1;
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Structs</h4><a id="user-content-structs" aria-label="Permalink: Structs" href="#structs"></a></p>
<p dir="auto">Data structures with optional bitfields.</p>
<div data-snippet-clipboard-copy-content="struct Point {
    x: int;
    y: int;
}

// Struct initialization
var p = Point { x: 10, y: 20 };

// Bitfields
struct Flags {
    valid: U8 : 1;
    mode:  U8 : 3;
}"><pre lang="zc"><code>struct Point {
    x: int;
    y: int;
}

// Struct initialization
var p = Point { x: 10, y: 20 };

// Bitfields
struct Flags {
    valid: U8 : 1;
    mode:  U8 : 3;
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Enums</h4><a id="user-content-enums" aria-label="Permalink: Enums" href="#enums"></a></p>
<p dir="auto">Tagged unions (Sum types) capable of holding data.</p>
<div data-snippet-clipboard-copy-content="enum Shape {
    Circle(float),      // Holds radius
    Rect(float, float), // Holds width, height
    Point               // No data
}"><pre lang="zc"><code>enum Shape {
    Circle(float),      // Holds radius
    Rect(float, float), // Holds width, height
    Point               // No data
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Unions</h4><a id="user-content-unions" aria-label="Permalink: Unions" href="#unions"></a></p>
<p dir="auto">Standard C unions (unsafe access).</p>
<div data-snippet-clipboard-copy-content="union Data {
    i: int;
    f: float;
}"><pre lang="zc"><code>union Data {
    i: int;
    f: float;
}
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Functions &amp; Lambdas</h3><a id="user-content-4-functions--lambdas" aria-label="Permalink: 4. Functions &amp; Lambdas" href="#4-functions--lambdas"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Functions</h4><a id="user-content-functions" aria-label="Permalink: Functions" href="#functions"></a></p>
<div data-snippet-clipboard-copy-content="fn add(a: int, b: int) -> int {
    return a + b;
}

// Named arguments supported in calls
add(a: 10, b: 20);"><pre lang="zc"><code>fn add(a: int, b: int) -&gt; int {
    return a + b;
}

// Named arguments supported in calls
add(a: 10, b: 20);
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Lambdas (Closures)</h4><a id="user-content-lambdas-closures" aria-label="Permalink: Lambdas (Closures)" href="#lambdas-closures"></a></p>
<p dir="auto">Anonymous functions that can capture their environment.</p>
<div data-snippet-clipboard-copy-content="var factor = 2;
var double = x -> x * factor;  // Arrow syntax
var full = fn(x: int) -> int { return x * factor; }; // Block syntax"><pre lang="zc"><code>var factor = 2;
var double = x -&gt; x * factor;  // Arrow syntax
var full = fn(x: int) -&gt; int { return x * factor; }; // Block syntax
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. Control Flow</h3><a id="user-content-5-control-flow" aria-label="Permalink: 5. Control Flow" href="#5-control-flow"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Conditionals</h4><a id="user-content-conditionals" aria-label="Permalink: Conditionals" href="#conditionals"></a></p>
<div data-snippet-clipboard-copy-content="if x > 10 {
    print(&quot;Large&quot;);
} else if x > 5 {
    print(&quot;Medium&quot;);
} else {
    print(&quot;Small&quot;);
}

// Ternary
var y = if x > 10 ? 1 : 0;"><pre lang="zc"><code>if x &gt; 10 {
    print("Large");
} else if x &gt; 5 {
    print("Medium");
} else {
    print("Small");
}

// Ternary
var y = if x &gt; 10 ? 1 : 0;
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pattern Matching</h4><a id="user-content-pattern-matching" aria-label="Permalink: Pattern Matching" href="#pattern-matching"></a></p>
<p dir="auto">Powerful alternative to <code>switch</code>.</p>
<div data-snippet-clipboard-copy-content="match val {
    1 => print(&quot;One&quot;),
    2 | 3 => print(&quot;Two or Three&quot;),
    4..10 => print(&quot;Range&quot;),
    _ => print(&quot;Other&quot;)
}

// Destructuring Enums
match shape {
    Circle(r) => print(f&quot;Radius: {r}&quot;),
    Rect(w, h) => print(f&quot;Area: {w*h}&quot;),
    Point => print(&quot;Point&quot;)
}"><pre lang="zc"><code>match val {
    1 =&gt; print("One"),
    2 | 3 =&gt; print("Two or Three"),
    4..10 =&gt; print("Range"),
    _ =&gt; print("Other")
}

// Destructuring Enums
match shape {
    Circle(r) =&gt; print(f"Radius: {r}"),
    Rect(w, h) =&gt; print(f"Area: {w*h}"),
    Point =&gt; print("Point")
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Loops</h4><a id="user-content-loops" aria-label="Permalink: Loops" href="#loops"></a></p>
<div data-snippet-clipboard-copy-content="// Range
for i in 0..10 { ... }
for i in 0..10 step 2 { ... }

// Iterator/Collection
for item in vec { ... }

// While
while x < 10 { ... }

// Infinite with label
outer: loop {
    if done { break outer; }
}

// Repeat
repeat 5 { ... }"><pre lang="zc"><code>// Range
for i in 0..10 { ... }
for i in 0..10 step 2 { ... }

// Iterator/Collection
for item in vec { ... }

// While
while x &lt; 10 { ... }

// Infinite with label
outer: loop {
    if done { break outer; }
}

// Repeat
repeat 5 { ... }
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Advanced Control</h4><a id="user-content-advanced-control" aria-label="Permalink: Advanced Control" href="#advanced-control"></a></p>
<div data-snippet-clipboard-copy-content="// Guard: Execute else and return if condition is false
guard ptr != NULL else { return; }

// Unless: If not true
unless is_valid { return; }"><pre lang="zc"><code>// Guard: Execute else and return if condition is false
guard ptr != NULL else { return; }

// Unless: If not true
unless is_valid { return; }
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">6. Operators</h3><a id="user-content-6-operators" aria-label="Permalink: 6. Operators" href="#6-operators"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operator</th>
<th>Description</th>
<th>Function Mapping</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code></td>
<td>Arithmetic</td>
<td><code>add</code>, <code>sub</code>, <code>mul</code>, <code>div</code>, <code>rem</code></td>
</tr>
<tr>
<td><code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code></td>
<td>Comparison</td>
<td><code>eq</code>, <code>neq</code>, <code>lt</code>, <code>gt</code></td>
</tr>
<tr>
<td><code>[]</code></td>
<td>Indexing</td>
<td><code>get</code>, <code>set</code></td>
</tr>
<tr>
<td><code>??</code></td>
<td>Null Coalescing (<code>val ?? default</code>)</td>
<td>-</td>
</tr>
<tr>
<td><code>??=</code></td>
<td>Null Assignment (<code>val ??= init</code>)</td>
<td>-</td>
</tr>
<tr>
<td><code>?.</code></td>
<td>Safe Navigation (<code>ptr?.field</code>)</td>
<td>-</td>
</tr>
<tr>
<td><code>?</code></td>
<td>Try Operator (<code>res?</code> returns error if present)</td>
<td>-</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">7. Memory Management</h3><a id="user-content-7-memory-management" aria-label="Permalink: 7. Memory Management" href="#7-memory-management"></a></p>
<p dir="auto">Zen C allows manual memory management with ergonomic aids.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Defer</h4><a id="user-content-defer" aria-label="Permalink: Defer" href="#defer"></a></p>
<p dir="auto">Execute code when the current scope exits.</p>
<div data-snippet-clipboard-copy-content="var f = fopen(&quot;file.txt&quot;, &quot;r&quot;);
defer fclose(f);"><pre lang="zc"><code>var f = fopen("file.txt", "r");
defer fclose(f);
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Autofree</h4><a id="user-content-autofree" aria-label="Permalink: Autofree" href="#autofree"></a></p>
<p dir="auto">Automatically free the variable when scope exits.</p>
<div data-snippet-clipboard-copy-content="autofree var types = malloc(1024);"><pre lang="zc"><code>autofree var types = malloc(1024);
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">RAII / Drop Trait</h4><a id="user-content-raii--drop-trait" aria-label="Permalink: RAII / Drop Trait" href="#raii--drop-trait"></a></p>
<p dir="auto">Implement <code>Drop</code> to run cleanup logic automatically.</p>
<div data-snippet-clipboard-copy-content="impl Drop for MyStruct {
    fn drop(mut self) {
        free(self.data);
    }
}"><pre lang="zc"><code>impl Drop for MyStruct {
    fn drop(mut self) {
        free(self.data);
    }
}
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">8. Object Oriented Programming</h3><a id="user-content-8-object-oriented-programming" aria-label="Permalink: 8. Object Oriented Programming" href="#8-object-oriented-programming"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Methods</h4><a id="user-content-methods" aria-label="Permalink: Methods" href="#methods"></a></p>
<p dir="auto">Define methods on types using <code>impl</code>.</p>
<div data-snippet-clipboard-copy-content="impl Point {
    // Static method (constructor convention)
    fn new(x: int, y: int) -> Point {
        return Point{x: x, y: y};
    }

    // Instance method
    fn dist(self) -> float {
        return sqrt(self.x * self.x + self.y * self.y);
    }
}"><pre lang="zc"><code>impl Point {
    // Static method (constructor convention)
    fn new(x: int, y: int) -&gt; Point {
        return Point{x: x, y: y};
    }

    // Instance method
    fn dist(self) -&gt; float {
        return sqrt(self.x * self.x + self.y * self.y);
    }
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Traits</h4><a id="user-content-traits" aria-label="Permalink: Traits" href="#traits"></a></p>
<p dir="auto">Define shared behavior.</p>
<div data-snippet-clipboard-copy-content="trait Drawable {
    fn draw(self);
}

impl Drawable for Circle {
    fn draw(self) { ... }
}"><pre lang="zc"><code>trait Drawable {
    fn draw(self);
}

impl Drawable for Circle {
    fn draw(self) { ... }
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Composition</h4><a id="user-content-composition" aria-label="Permalink: Composition" href="#composition"></a></p>
<p dir="auto">Use <code>use</code> to mixin fields from another struct.</p>
<div data-snippet-clipboard-copy-content="struct Entity { id: int; }
struct Player {
    use Entity; // Adds 'id' field
    name: string;
}"><pre lang="zc"><code>struct Entity { id: int; }
struct Player {
    use Entity; // Adds 'id' field
    name: string;
}
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">9. Generics</h3><a id="user-content-9-generics" aria-label="Permalink: 9. Generics" href="#9-generics"></a></p>
<p dir="auto">Type-safe templates for Structs and Functions.</p>
<div data-snippet-clipboard-copy-content="// Generic Struct
struct Box<T> {
    item: T;
}

// Generic Function
fn identity<T>(val: T) -> T {
    return val;
}"><pre lang="zc"><code>// Generic Struct
struct Box&lt;T&gt; {
    item: T;
}

// Generic Function
fn identity&lt;T&gt;(val: T) -&gt; T {
    return val;
}
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">10. Concurrency (Async/Await)</h3><a id="user-content-10-concurrency-asyncawait" aria-label="Permalink: 10. Concurrency (Async/Await)" href="#10-concurrency-asyncawait"></a></p>
<p dir="auto">Built on pthreads.</p>
<div data-snippet-clipboard-copy-content="async fn fetch_data() -> string {
    // Runs in background
    return &quot;Data&quot;;
}

fn main() {
    var future = fetch_data();
    var result = await future;
}"><pre lang="zc"><code>async fn fetch_data() -&gt; string {
    // Runs in background
    return "Data";
}

fn main() {
    var future = fetch_data();
    var result = await future;
}
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">11. Metaprogramming</h3><a id="user-content-11-metaprogramming" aria-label="Permalink: 11. Metaprogramming" href="#11-metaprogramming"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Comptime</h4><a id="user-content-comptime" aria-label="Permalink: Comptime" href="#comptime"></a></p>
<p dir="auto">Run code at compile-time to generate source or print messages.</p>
<div data-snippet-clipboard-copy-content="comptime {
    print(&quot;Compiling...&quot;);
}"><pre lang="zc"><code>comptime {
    print("Compiling...");
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Embed</h4><a id="user-content-embed" aria-label="Permalink: Embed" href="#embed"></a></p>
<p dir="auto">Embed files as byte arrays.</p>
<div data-snippet-clipboard-copy-content="var png = embed &quot;assets/logo.png&quot;;"><pre lang="zc"><code>var png = embed "assets/logo.png";
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Plugins</h4><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto">Import compiler plugins to extend syntax.</p>
<div data-snippet-clipboard-copy-content="import plugin &quot;regex&quot;
var re = regex! { ^[a-z]+$ };"><pre lang="zc"><code>import plugin "regex"
var re = regex! { ^[a-z]+$ };
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Generic C Macros</h4><a id="user-content-generic-c-macros" aria-label="Permalink: Generic C Macros" href="#generic-c-macros"></a></p>
<p dir="auto">Pass preprocessor macros through to C.</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">12. Attributes</h3><a id="user-content-12-attributes" aria-label="Permalink: 12. Attributes" href="#12-attributes"></a></p>
<p dir="auto">Decorate functions and structs to modify compiler behavior.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Attribute</th>
<th>Scope</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>@must_use</code></td>
<td>Fn</td>
<td>Warn if return value is ignored.</td>
</tr>
<tr>
<td><code>@deprecated("msg")</code></td>
<td>Fn/Struct</td>
<td>Warn on usage with message.</td>
</tr>
<tr>
<td><code>@inline</code></td>
<td>Fn</td>
<td>Hint compiler to inline.</td>
</tr>
<tr>
<td><code>@noinline</code></td>
<td>Fn</td>
<td>Prevent inlining.</td>
</tr>
<tr>
<td><code>@packed</code></td>
<td>Struct</td>
<td>Remove padding between fields.</td>
</tr>
<tr>
<td><code>@align(N)</code></td>
<td>Struct</td>
<td>Force alignment to N bytes.</td>
</tr>
<tr>
<td><code>@constructor</code></td>
<td>Fn</td>
<td>Run before main.</td>
</tr>
<tr>
<td><code>@destructor</code></td>
<td>Fn</td>
<td>Run after main exits.</td>
</tr>
<tr>
<td><code>@unused</code></td>
<td>Fn/Var</td>
<td>Suppress unused variable warnings.</td>
</tr>
<tr>
<td><code>@weak</code></td>
<td>Fn</td>
<td>Weak symbol linkage.</td>
</tr>
<tr>
<td><code>@section("name")</code></td>
<td>Fn</td>
<td>Place code in specific section.</td>
</tr>
<tr>
<td><code>@noreturn</code></td>
<td>Fn</td>
<td>Function does not return (e.g. exit).</td>
</tr>
<tr>
<td><code>@derived(...)</code></td>
<td>Struct</td>
<td>Auto-implement traits (e.g. <code>Debug</code>).</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">13. Inline Assembly</h3><a id="user-content-13-inline-assembly" aria-label="Permalink: 13. Inline Assembly" href="#13-inline-assembly"></a></p>
<p dir="auto">Zen C provides first-class support for inline assembly, transpiling directly to GCC-style extended <code>asm</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Basic Usage</h4><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<p dir="auto">Write raw assembly within <code>asm</code> blocks. Strings are concatenated automatically.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Volatile</h4><a id="user-content-volatile" aria-label="Permalink: Volatile" href="#volatile"></a></p>
<p dir="auto">Prevent the compiler from optimizing away assembly that has side effects.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Named Constraints</h4><a id="user-content-named-constraints" aria-label="Permalink: Named Constraints" href="#named-constraints"></a></p>
<p dir="auto">Zen C simplifies the complex GCC constraint syntax with named bindings.</p>
<div data-snippet-clipboard-copy-content="// Syntax: : out(var) : in(var) : clobber(reg)
// Uses {var} placeholder syntax for readability

fn add(a: int, b: int) -> int {
    var result: int;
    asm {
        &quot;add {result}, {a}, {b}&quot;
        : out(result)
        : in(a), in(b)
        : clobber(&quot;cc&quot;)
    }
    return result;
}"><pre lang="zc"><code>// Syntax: : out(var) : in(var) : clobber(reg)
// Uses {var} placeholder syntax for readability

fn add(a: int, b: int) -&gt; int {
    var result: int;
    asm {
        "add {result}, {a}, {b}"
        : out(result)
        : in(a), in(b)
        : clobber("cc")
    }
    return result;
}
</code></pre></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Type</th>
<th>Syntax</th>
<th>GCC Equivalent</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Output</strong></td>
<td><code>: out(var)</code></td>
<td><code>"=r"(var)</code></td>
</tr>
<tr>
<td><strong>Input</strong></td>
<td><code>: in(var)</code></td>
<td><code>"r"(var)</code></td>
</tr>
<tr>
<td><strong>Clobber</strong></td>
<td><code>: clobber("rax")</code></td>
<td><code>"rax"</code></td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td><code>: clobber("memory")</code></td>
<td><code>"memory"</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><strong>Note:</strong> When using Intel syntax (via <code>-masm=intel</code>), you must ensure your build is configured correctly (for example, <code>//&gt; cflags: -masm=intel</code>). TCC does not support Intel syntax assembly.</p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiler Support &amp; Compatibility</h2><a id="user-content-compiler-support--compatibility" aria-label="Permalink: Compiler Support &amp; Compatibility" href="#compiler-support--compatibility"></a></p>
<p dir="auto">Zen C is designed to work with most C11 compilers. Some features rely on GNU C extensions, but these often work in other compilers. Use the <code>--cc</code> flag to switch backends.</p>
<div dir="auto" data-snippet-clipboard-copy-content="zc run app.zc --cc clang
zc run app.zc --cc zig"><pre>zc run app.zc --cc clang
zc run app.zc --cc zig</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test Suite Status</h3><a id="user-content-test-suite-status" aria-label="Permalink: Test Suite Status" href="#test-suite-status"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Compiler</th>
<th>Pass Rate</th>
<th>Supported Features</th>
<th>Known Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GCC</strong></td>
<td><strong>100%</strong></td>
<td>All Features</td>
<td>None.</td>
</tr>
<tr>
<td><strong>Clang</strong></td>
<td><strong>100%</strong></td>
<td>All Features</td>
<td>None.</td>
</tr>
<tr>
<td><strong>Zig</strong></td>
<td><strong>100%</strong></td>
<td>All Features</td>
<td>None. Uses <code>zig cc</code> as a drop-in C compiler.</td>
</tr>
<tr>
<td><strong>TCC</strong></td>
<td><strong>~70%</strong></td>
<td>Basic Syntax, Generics, Traits</td>
<td>No <code>__auto_type</code>, No Intel ASM, No Nested Functions.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><strong>Recommendation:</strong> Use <strong>GCC</strong>, <strong>Clang</strong>, or <strong>Zig</strong> for production builds. TCC is excellent for rapid prototyping due to its compilation speed but misses some advanced C extensions Zen C relies on for full feature support.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building with Zig</h3><a id="user-content-building-with-zig" aria-label="Permalink: Building with Zig" href="#building-with-zig"></a></p>
<p dir="auto">Zig's <code>zig cc</code> command provides a drop-in replacement for GCC/Clang with excellent cross-compilation support. To use Zig:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Compile and run a Zen C program with Zig
zc run app.zc --cc zig

# Build the Zen C compiler itself with Zig
make zig"><pre><span><span>#</span> Compile and run a Zen C program with Zig</span>
zc run app.zc --cc zig

<span><span>#</span> Build the Zen C compiler itself with Zig</span>
make zig</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions! Whether it's fixing bugs, adding documentation, or proposing new features.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to Contribute</h3><a id="user-content-how-to-contribute" aria-label="Permalink: How to Contribute" href="#how-to-contribute"></a></p>
<ol dir="auto">
<li><strong>Fork the Repository</strong>: standard GitHub workflow.</li>
<li><strong>Create a Feature Branch</strong>: <code>git checkout -b feature/NewThing</code>.</li>
<li><strong>Code Guidelines</strong>:
<ul dir="auto">
<li>Follow the existing C style.</li>
<li>Ensure all tests pass: <code>make test</code>.</li>
<li>Add new tests for your feature in <code>tests/</code>.</li>
</ul>
</li>
<li><strong>Submit a Pull Request</strong>: Describe your changes clearly.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running Tests</h3><a id="user-content-running-tests" aria-label="Permalink: Running Tests" href="#running-tests"></a></p>
<p dir="auto">The test suite is your best friend.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run all tests (GCC)
make test

# Run specific test
./zc run tests/test_match.zc

# Run with different compiler
./tests/run_tests.sh --cc clang
./tests/run_tests.sh --cc zig
./tests/run_tests.sh --cc tcc"><pre><span><span>#</span> Run all tests (GCC)</span>
make <span>test</span>

<span><span>#</span> Run specific test</span>
./zc run tests/test_match.zc

<span><span>#</span> Run with different compiler</span>
./tests/run_tests.sh --cc clang
./tests/run_tests.sh --cc zig
./tests/run_tests.sh --cc tcc</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Extending the Compiler</h3><a id="user-content-extending-the-compiler" aria-label="Permalink: Extending the Compiler" href="#extending-the-compiler"></a></p>
<ul dir="auto">
<li><strong>Parser</strong>: <code>src/parser/</code> - Recursive descent parser.</li>
<li><strong>Codegen</strong>: <code>src/codegen/</code> - Transpiler logic (Zen C -&gt; GNU C/C11).</li>
<li><strong>Standard Library</strong>: <code>std/</code> - Written in Zen C itself.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ozempic reduced grocery spending by an average of 5.3% in the US (402 pts)]]></title>
            <link>https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy</link>
            <guid>46587536</guid>
            <pubDate>Mon, 12 Jan 2026 12:29:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy">https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy</a>, See on <a href="https://news.ycombinator.com/item?id=46587536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>When Americans begin taking appetite-suppressing drugs like Ozempic and Wegovy, the changes extend well beyond the bathroom scale. According to new research, the medications are associated with meaningful reductions in how much households spend on food, both at the grocery store and at restaurants.</span></p><p><span>The study,&nbsp;</span><a href="https://journals.sagepub.com/doi/10.1177/00222437251412834"><span>published Dec. 18</span></a><span> in the&nbsp;Journal of Marketing Research, links survey data on GLP-1 receptor agonist use – a class of drugs originally developed for diabetes and now widely prescribed for weight loss – with detailed transaction records from tens of thousands of U.S. households. The result is one of the most comprehensive looks yet at how GLP-1 adoption is associated with changes in everyday food purchasing in the real world.</span></p><p><span>The headline finding is striking: Within six months of starting a GLP-1 medication, households reduce grocery spending by an average of 5.3%. Among higher-income households, the drop is even steeper, at more than 8%. Spending at fast-food restaurants, coffee shops and other limited-service eateries falls by about 8%.</span></p><p><span>Among households who continue using the medication, lower food spending persists at least a year, though the magnitude of the reduction becomes smaller over time, say co-authors, assistant professor&nbsp;</span><a href="https://business.cornell.edu/faculty-research/faculty/sh2596/"><span>Sylvia Hristakeva</span></a><span> and professor&nbsp;</span><a href="https://business.cornell.edu/faculty-research/faculty/jl2545/"><span>Jura Liaukonyte</span></a><span>,&nbsp;both in the Charles H. Dyson School of Applied Economics and Management in the Cornell SC Johnson College of Business.&nbsp;</span></p><p><span>“The data show clear changes in food spending following adoption,” Hristakeva said. “After discontinuation, the effects become smaller and harder to distinguish from pre-adoption spending patterns.”</span></p><p><span>Unlike previous studies that relied on self-reported eating habits, the new analysis draws on purchase data collected by Numerator, a market research firm that tracks grocery and restaurant transactions for a nationally representative panel of about 150,000 households. The researchers matched those records with repeated surveys asking whether household members were taking GLP-1 drugs, when they started and why.</span></p><p><span>That combination allowed the team to compare adopters with similar households that did not use the drugs, isolating changes that occurred after medication began.</span></p><p><span>The reductions were not evenly distributed across the grocery store.</span></p><p><span>Ultra-processed, calorie-dense foods – the kinds most closely associated with cravings – saw the sharpest declines. Spending on savory snacks dropped by about 10%, with similarly large decreases in sweets, baked goods and cookies. Even staples like bread, meat and eggs declined.</span></p><p><span>Only a handful of categories showed increases. Yogurt rose the most, followed by fresh fruit, nutrition bars and meat snacks.</span></p><p><span>“The main pattern is a reduction in overall food purchases. Only a small number of categories show increases, and those increases are modest relative to the overall decline,” Hristakeva said.&nbsp;</span></p><p><span>The effects extended beyond the supermarket. Spending at limited-service restaurants such as fast-food chains and coffee shops fell sharply as well.</span></p><p><span>The study also sheds light on who is taking GLP-1 medications. The share of U.S. households reporting at least one user rose from about 11% in late 2023 to more than 16% by mid-2024. Weight-loss users skew younger and wealthier, while those taking the drugs for diabetes are older and more evenly distributed across income groups.</span></p><p><span>Notably, about one-third of users stopped taking the medication during the study period. When they did, their food spending reverted to pre-adoption levels – and their grocery baskets became slightly less healthy than before they started, driven in part by increased spending on categories such as candy and chocolate.</span></p><p><span>That movement underscores an important limitation, the authors caution. The study cannot fully separate the biological effects of the drugs from other lifestyle changes users may make at the same time. However, evidence from clinical trials, combined with the observed reversion in spending after discontinuation, suggests appetite suppression is likely a key mechanism behind the spending changes.</span></p><p><span>The findings carry implications far beyond individual households.</span></p><p><span>For food manufacturers, restaurants and retailers, widespread GLP-1 adoption could mean long-term shifts in demand, particularly for snack foods and fast food. Package sizes, product formulations and marketing strategies may need to change. For policymakers and public-health experts, the results add context to ongoing debates about the role of medical treatments in shaping dietary behavior – and whether biologically driven appetite changes succeed where taxes and labels have struggled.</span></p><p><span>“At current adoption rates, even relatively modest changes at the household level can have meaningful aggregate effects,” Hristakeva said. “Understanding these demand shifts is therefore important for assessing food markets and consumer spending.”&nbsp;</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch a Debugging Terminal into GitHub Actions (142 pts)]]></title>
            <link>https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/</link>
            <guid>46587498</guid>
            <pubDate>Mon, 12 Jan 2026 12:25:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/">https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/</a>, See on <a href="https://news.ycombinator.com/item?id=46587498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <main aria-label="Content">
        <article>
            
            
            <div>
                <p><strong>Spoiler:</strong> I made a free and open-source way to get an interactive web terminal to your GitHub Action when it fails. Try it out here: <a href="https://actions-term.gripdev.xyz/">https://actions-term.gripdev.xyz/</a> (<a href="https://github.com/lawrencegripper/actions-term-on-fail">code 🔗</a>) <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<video preload="metadata" controls="">
    <source src="https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/termdemo.mp4" type="video/mp4">
    Your browser does not support the video element.
  </video>
<h2 id="building-it">Building it</h2>
<p>I think we’ve all been there, <strong>your build fails in Actions, but the script works fine locally.</strong> You now settle into a slow loop of:</p>
<ol>
<li>Push speculative change</li>
<li>See if it worked</li>
</ol>
<p>It was in the middle of one of these when I started thinking about how to make it better.</p>
<p>A Terminal would be great, that’s obvious, but how to make it happen? How could I make it free, and open to anyone, without costing me lots of money?</p>
<p>Operating a service that forward traffic between a user and the Actions VM would stack up data transfer costs and take some work to scale.</p>
<p>What about a Peer-to-Peer connection? I’d recently been going deeper on how <a href="https://tailscale.com/blog/how-tailscale-works">Tailscale</a>, <a href="https://github.com/n0-computer/iroh">iroh</a> and <a href="https://webrtc.org/">WebRTC</a> use <a href="https://tailscale.com/blog/how-nat-traversal-works">UDP Hole Punching to create Peer-to-Peer (P2P) connections</a> between nodes without relaying traffic. <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>If that worked then my server would only need to exchange a tiny bit of information per session and hopefully cost me very little 🤞</p>
<p>Could I use P2P and funnel a terminal session over it? Well the Actions VM is on the internet and allows UDP outbound, so it should work!</p>
<p>A simple bit of scripting proved it did 🥳 With WebRTC, if the Actions VM and my local machine exchange information about their connectivity (<a href="https://webrtc.org/getting-started/peer-connections#ice_candidates">ICE Candidates</a>), then I could form a connection.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h2 id="security-and-identities">Security and Identities</h2>
<p>The next problem is, <strong>how do you prove each end of the P2P connection is who they say they are?</strong></p>
<p>It’s important. I want to ensure that <code>lawrencegripper</code> can only access terminals for Actions triggered by <code>lawrencegripper</code>.</p>
<p>The browser side is relatively easy, we can use OAuth to login via GitHub and get a verified username ✅</p>
<p>On the Actions VM <a href="https://docs.github.com/en/actions/concepts/security/openid-connect">we have OIDC</a>, commonly used to auth from Actions to cloud providers.</p>
<p>Anyone can use it though, it gives us the ability to issue a signed OIDC token from within our Action which proves:</p>
<ol>
<li>The repo it’s running on</li>
<li>The user account that triggered it</li>
<li>The audience it is intended for</li>
</ol>
<p>To enable this feature you set the following permissions in the workflow</p>

<div><pre tabindex="0"><code data-lang="yaml"><span><span><span>    </span><span>permissions</span><span>:</span><span>
</span></span></span><span><span><span>      </span><span>id-token</span><span>:</span><span> </span><span>write</span></span></span></code></pre></div>

<p>You request a token via a REST request in the action, for example:</p>

<div><pre tabindex="0"><code data-lang="typescript"><span><span>    <span>const</span> <span>requestURL</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ACTIONS_ID_TOKEN_REQUEST_URL</span><span>;</span>
</span></span><span><span>    <span>const</span> <span>requestToken</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ACTIONS_ID_TOKEN_REQUEST_TOKEN</span><span>;</span>
</span></span><span><span>    <span>const</span> <span>SERVER_URL</span> <span>=</span> <span>'https://actions-term.gripdev.xyz'</span><span>;</span>
</span></span><span><span>    <span>const</span> <span>url</span> <span>=</span> <span>new</span> <span>URL</span><span>(</span><span>requestURL</span><span>);</span>
</span></span><span><span>    <span>url</span><span>.</span><span>searchParams</span><span>.</span><span>set</span><span>(</span><span>'audience'</span><span>,</span> <span>SERVER_URL</span><span>);</span>
</span></span><span><span>
</span></span><span><span>    <span>const</span> <span>resp</span> <span>=</span> <span>await</span> <span>fetch</span><span>(</span><span>url</span><span>.</span><span>toString</span><span>(),</span> <span>{</span>
</span></span><span><span>        <span>headers</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>Authorization</span><span>:</span> <span>`Bearer </span><span>${</span><span>requestToken</span><span>}</span><span>`</span><span>,</span>
</span></span><span><span>        <span>Accept</span><span>:</span> <span>'application/json'</span><span>,</span>
</span></span><span><span>        <span>},</span>
</span></span><span><span>    <span>});</span></span></span></code></pre></div>

<blockquote>
<p><a href="https://github.com/lawrencegripper/actions-term-on-fail/blob/21c8350bc33a4bf4451473eabecc9d7b2eedc716/client/src/index.ts#L35-L70">🔗 code</a></p>
</blockquote>
<p>Then, when the Action calls our server, it can include this token. We can then validate it cryptographically via JWKS:</p>

<div><pre tabindex="0"><code data-lang="golang"><span><span><span>    </span><span>const</span><span> </span><span>githubOIDCIssuer</span><span> </span><span>=</span><span> </span><span>"https://token.actions.githubusercontent.com"</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>githubJWKSURL</span><span> </span><span>=</span><span> </span><span>"https://token.actions.githubusercontent.com/.well-known/jwks"</span><span>
</span></span></span><span><span><span>    </span><span>// Fetch JWKS</span><span>
</span></span></span><span><span><span>	</span><span>keySet</span><span>,</span><span> </span><span>err</span><span> </span><span>:=</span><span> </span><span>jwkCache</span><span>.</span><span>Get</span><span>(</span><span>ctx</span><span>,</span><span> </span><span>githubJWKSURL</span><span>)</span><span>
</span></span></span><span><span><span>	</span><span>if</span><span> </span><span>err</span><span> </span><span>!=</span><span> </span><span>nil</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>		</span><span>return</span><span> </span><span>""</span><span>,</span><span> </span><span>""</span><span>,</span><span> </span><span>""</span><span>,</span><span> </span><span>fmt</span><span>.</span><span>Errorf</span><span>(</span><span>"failed to fetch JWKS: %w"</span><span>,</span><span> </span><span>err</span><span>)</span><span>
</span></span></span><span><span><span>	</span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>	</span><span>// Parse and validate token with clock skew tolerance</span><span>
</span></span></span><span><span><span>	</span><span>parseOpts</span><span> </span><span>:=</span><span> </span><span>[]</span><span>jwtx</span><span>.</span><span>ParseOption</span><span>{</span><span>
</span></span></span><span><span><span>		</span><span>jwtx</span><span>.</span><span>WithKeySet</span><span>(</span><span>keySet</span><span>),</span><span>
</span></span></span><span><span><span>		</span><span>jwtx</span><span>.</span><span>WithIssuer</span><span>(</span><span>githubOIDCIssuer</span><span>),</span><span>
</span></span></span><span><span><span>		</span><span>jwtx</span><span>.</span><span>WithValidate</span><span>(</span><span>true</span><span>),</span><span>
</span></span></span><span><span><span>		</span><span>jwtx</span><span>.</span><span>WithAcceptableSkew</span><span>(</span><span>2</span><span> </span><span>*</span><span> </span><span>time</span><span>.</span><span>Minute</span><span>),</span><span>
</span></span></span><span><span><span>		</span><span>jwtx</span><span>.</span><span>WithAudience</span><span>(</span><span>oidcExpectedAudience</span><span>),</span><span>
</span></span></span><span><span><span>	</span><span>}</span><span>
</span></span></span><span><span><span>	</span><span>token</span><span>,</span><span> </span><span>err</span><span> </span><span>:=</span><span> </span><span>jwtx</span><span>.</span><span>Parse</span><span>([]</span><span>byte</span><span>(</span><span>tokenStr</span><span>),</span><span> </span><span>parseOpts</span><span>...</span><span>)</span><span>
</span></span></span><span><span><span>	</span><span>if</span><span> </span><span>err</span><span> </span><span>!=</span><span> </span><span>nil</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>		</span><span>return</span><span> </span><span>""</span><span>,</span><span> </span><span>""</span><span>,</span><span> </span><span>""</span><span>,</span><span> </span><span>fmt</span><span>.</span><span>Errorf</span><span>(</span><span>"token validation failed: %w"</span><span>,</span><span> </span><span>err</span><span>)</span><span>
</span></span></span><span><span><span>	</span><span>}</span></span></span></code></pre></div>

<blockquote>
<p><a href="https://github.com/lawrencegripper/actions-term-on-fail/blob/main/server/main.go#L173-L221">🔗 code</a></p>
</blockquote>
<h2 id="connecting-the-peers-ie-signaling-server">Connecting the Peers (ie. <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Connectivity#signaling">Signaling Server</a>)</h2>
<p>At this point we know:</p>
<ol>
<li>We can create a connection between two peers (Actions VM &lt;-&gt; Users Browser) with WebRTC</li>
<li>We have a way to validate the identity of both ends of the connection (OAuth and OIDC)</li>
</ol>
<p>What’s left is the server to introduce the two peers 🤝 Let’s build a server to do that.</p>
<p>The server doesn’t need to handle the terminal data, that goes between the two peers directly, it’s only doing introductions.</p>
<p>When the VM and Browser are connected to the server it should send each one the connection details for the other.</p>
<p>To do this, the browser and the VM both create <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events">Server-sent events (SSE)</a> connections, allowing the signaling server to push events to them. They prove their identities by providing their OAuth credentials or OIDC to prove their identity.</p>
<p>The server then stores:</p>

<div><pre tabindex="0"><code data-lang="golang"><span><span><span>	</span><span>runIdToSessions</span><span>            </span><span>=</span><span> </span><span>make</span><span>(</span><span>map</span><span>[</span><span>string</span><span>]</span><span>*</span><span>Session</span><span>)</span><span> </span><span>// runId -&gt; session</span><span>
</span></span></span><span><span><span>	</span><span>runIdToSessionsMu</span><span>          </span><span>sync</span><span>.</span><span>RWMutex</span><span>
</span></span></span><span><span><span>	</span><span>runIdRunnerSseClient</span><span>       </span><span>=</span><span> </span><span>make</span><span>(</span><span>map</span><span>[</span><span>string</span><span>]</span><span>*</span><span>SSEClient</span><span>)</span><span> </span><span>// runId -&gt; SSE client (Actions VM)</span><span>
</span></span></span><span><span><span>	</span><span>runIdRunnerSseClientsMu</span><span>    </span><span>sync</span><span>.</span><span>RWMutex</span><span>
</span></span></span><span><span><span>	</span><span>actorToBrowserSseClients</span><span>   </span><span>=</span><span> </span><span>make</span><span>(</span><span>map</span><span>[</span><span>string</span><span>][]</span><span>*</span><span>SSEClient</span><span>)</span><span> </span><span>// actor -&gt; list of browser SSE clients</span><span>
</span></span></span><span><span><span>	</span><span>actorToBrowserSseClientsMu</span><span> </span><span>sync</span><span>.</span><span>RWMutex</span></span></span></code></pre></div>

<p>The server then, via SSE, sends the Actions VM connectivity details to the browser and the Browser’s connectivity details to the Actions VM.</p>
<p>At this point they establish the Peer-to-Peer connection 🥳</p>
<p>For bonus points, when a new Actions VM connects, I can see if a browser is open waiting and send them a notification.</p>

<div><pre tabindex="0"><code data-lang="golang"><span><span><span>	</span><span>runIdRunnerSseClientsMu</span><span>.</span><span>Lock</span><span>()</span><span>
</span></span></span><span><span><span>	</span><span>runIdRunnerSseClient</span><span>[</span><span>runId</span><span>]</span><span> </span><span>=</span><span> </span><span>client</span><span>
</span></span></span><span><span><span>	</span><span>log</span><span>.</span><span>Printf</span><span>(</span><span>"SSE: Runner connected for actor %s (total clients: %d)"</span><span>,</span><span> </span><span>actor</span><span>,</span><span> </span><span>len</span><span>(</span><span>runIdRunnerSseClient</span><span>))</span><span>
</span></span></span><span><span><span>	</span><span>runIdRunnerSseClientsMu</span><span>.</span><span>Unlock</span><span>()</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>	</span><span>// Notify browser subscribers about new session</span><span>
</span></span></span><span><span><span>	</span><span>sess</span><span>,</span><span> </span><span>ok</span><span> </span><span>:=</span><span> </span><span>runIdToSessions</span><span>[</span><span>runId</span><span>]</span><span>
</span></span></span><span><span><span>	</span><span>if</span><span> </span><span>ok</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>		</span><span>notifyNewSession</span><span>(</span><span>sess</span><span>)</span><span>
</span></span></span><span><span><span>	</span><span>}</span></span></span></code></pre></div>

<blockquote>
<p><a href="https://github.com/lawrencegripper/actions-term-on-fail/blob/255c79feee7d2cbb854144409a93bdd3a03fcdb4/server/main.go#L262-L271">🔗 Code</a></p>
</blockquote>
<h2 id="displaying-the-terminal">Displaying the Terminal</h2>
<p>Ok, we’re close now. We have the signaling server to exchange details and then the peers have a p2p connection.</p>
<p>What about creating a terminal and streaming the data?</p>
<p>WebRTC has a <code>datachannel</code> which you push arbitrary data through.</p>
<p>On the Actions VM side we create a <code>pty.Shell</code> and stream that data over our <code>datachannel (dc)</code></p>

<div><pre tabindex="0"><code data-lang="javascript"><span><span>    <span>shell</span> <span>=</span> <span>pty</span><span>.</span><span>spawn</span><span>(</span><span>SHELL</span><span>,</span> <span>[],</span> <span>{</span>
</span></span><span><span>        <span>name</span><span>:</span> <span>'xterm-256color'</span><span>,</span>
</span></span><span><span>        <span>cwd</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>GITHUB_WORKSPACE</span> <span>||</span> <span>process</span><span>.</span><span>cwd</span><span>(),</span>
</span></span><span><span>        <span>env</span><span>:</span> <span>process</span><span>.</span><span>env</span> <span>as</span> <span>Record</span><span>&lt;</span><span>string</span><span>,</span> <span>string</span><span>&gt;</span><span>,</span>
</span></span><span><span>    <span>});</span>
</span></span><span><span>
</span></span><span><span>    <span>shell</span><span>.</span><span>onData</span><span>((</span><span>shellData</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span></span><span><span>        <span>dc</span><span>.</span><span>sendMessage</span><span>(</span><span>shellData</span><span>);</span>
</span></span><span><span>    <span>});</span></span></span></code></pre></div>

<blockquote>
<p><a href="https://github.com/lawrencegripper/actions-term-on-fail/blob/6f46d09ac86757f72e74fe070bb4c7f745ea09c6/client/src/index.ts#L417-L423">code 🔗</a></p>
</blockquote>
<p>In the browser we then need to display an interactive terminal.</p>
<p>Reading around, I found the this awesome <a href="https://github.com/coder/ghostty-web">Ghostty library</a>. It has an xterm.js compatible implementation, I hooked this up and it worked first time 🥰</p>
<p>Well it did.. and it didn’t, the Terminal spawned via PTY doesn’t have any idea how big our terminal in the browser (Lines and Columns) so we get some horrible rendering in the terminal.</p>
<p>With a bit of poking, googling and some Opus 4.5, I created a method which estimates the size of terminal, via font sizing, and converts this to a rough column / rows. Then, on establishing the P2P connection I can send a <code>setup</code> JSON message which the Actions VM uses to start <code>pty.spawn</code> with the right sizing for the terminal.</p>
<h2 id="were-done-right">We’re done, right?</h2>
<p>Not quite, at this point we have 👇</p>

<pre tabindex="0"><code>┌─────────────────┐                              ┌─────────────────┐
│  GitHub Runner  │◄────────────────────────────►│    Browser      │
│  (TypeScript)   │      Direct P2P (WebRTC)     │  (ghostty-web)  │
│                 │                              │                 │
└────────┬────────┘                              └────────┬────────┘
         │                                                │
         │ Register session                               │ Get sessions
         │ (OIDC Token Auth)                              │ (GitHub OAuth)
         ▼                                                ▼
         └──────────────►┌─────────────────┐◄─────────────┘
                         │     Server      │
                         │   (Go - Auth    │
                         │   &amp; Discovery)  │
                         └─────────────────┘</code></pre>

<p>There is a lot of trust placed in the signaling server. It has to do the right thing, or it could provide access to someone else’s Actions VM.</p>
<p>Let’s do better.</p>
<h2 id="trust-vs-zero-trust">Trust vs Zero-Trust</h2>
<p>I’ve mentioned already <strong>the signaling server should only connect up users with actions they’ve started</strong>.</p>
<p>That relies on explicit trust, from users, that I’m going to do the right thing.</p>
<p>What if I’ve got a bug? What if someone compromises the signaling server? What if they steal the domain and run their own server on it?</p>
<p>Well, then they could hook up peers that shouldn’t be connected and … do mean things.</p>
<p>That sounds bad, lets work out how to fix that.</p>
<p>What if the <code>user</code> provided the Actions VM with a secret, that only they know?</p>
<p>When the P2P connection is made, the Actions VM could refuse to talk to the browser until it provides the right secret.</p>
<p>Secrets are cool and everything but if they’re intercepted they’re reusable, could we use a One-Time-Password (OTP) commonly used for 2FA on sites? Sure thing! Even better tools like 1Password will autofill it for you.</p>
<p>What does this flow look like? Roughly it’s 👇</p>

<div><pre tabindex="0"><code data-lang="text"><span><span>┌─────────────────┐                              ┌─────────────────┐
</span></span><span><span>│  GitHub Runner  │◄────────────────────────────►│    Browser      │
</span></span><span><span>│  (TypeScript)   │      Direct P2P (WebRTC)     │  (ghostty-web)  │
</span></span><span><span>└────────┬────────┘                              └────────┬────────┘
</span></span><span><span>         │                                                │
</span></span><span><span>         │◄───── 1. WebRTC Connection Established ───────►│
</span></span><span><span>         │                                                │
</span></span><span><span>         │◄─────────── 2. Browser sends OTP ────── ───────│
</span></span><span><span>         │                                                │
</span></span><span><span>         │  3. Runner validates OTP against secret        │
</span></span><span><span>         │                                                │
</span></span><span><span>         │              ┌──────────────────┐              │
</span></span><span><span>         │              │  If OTP Valid:   │              │
</span></span><span><span>         │──────────────│  4. Terminal     │─────────────►│
</span></span><span><span>                        │     access       │
</span></span><span><span>                        │     granted      │
</span></span><span><span>                        └──────────────────┘</span></span></code></pre></div>

<p>Even if the signaling server is manipulated, to hook up two peers which shouldn’t be connected, the user won’t be able to execute commands unless they can provide a valid OTP.</p>
<p>Better still the Signaling server (which I run) is never sent either the OTP or the OTP Secret used to validate each OTP.</p>
<p>This validation happens between two peers you own (Actions VM and your Browser).</p>
<h2 id="so-now-were-done">So now we’re done?</h2>
<p>One last thing… make the signaling server cheap to host.</p>
<p>I want to offer this for free for anyone to use. It’s a simple <code>go</code> binary in a docker image (to make it easy to self-hosting and test locally) but it needs to live on the internet.</p>
<p>A while ago I’d started poking at <a href="https://railway.com/">railway.com</a>, it’s cloud with a big billing twist, <strong>you only pay for the CPU and Memory you actually use</strong>. This felt like a great time to try it out.</p>
<p>How is the billing different, well…</p>
<ul>
<li>In Azure/AWS I have to say “I want 2 CPUs and 8GB” and I pay for that regardless of what I use.</li>
<li>On <a href="https://railway.com/">railway.com</a> I say “Use <strong>up to</strong> x CPUs and y GB” then you only pay for what the service actually consumes.</li>
</ul>
<blockquote>
<p>Note: In either Azure/AWS or Railway you still pay network egress.</p>
</blockquote>
<p>How does this work out for the signaling server?</p>
<p><strong>Really well</strong> it’s peak memory usage so far is 20MB, racking up a mean $0.00000… you get the point. It’s not costing much, as I’m not reserving a small machine with GBs of mem to run a service needing 20MB</p>
<p><img src="https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/memory-usage.png" alt="Graph showing 20mb of memory"></p>
<p>Even then it feels a bit wasteful running it all the time. There will be chunks of time when folks aren’t using it.</p>
<p>This was where I found a platform feature called <a href="https://docs.railway.com/reference/app-sleeping">sleeping</a>, it’s serverless but without the pain of moving away from the docker model to some proprietary runtime.</p>
<p>When the service isn’t doing anything, Railway spin down the service. If someone turns up, they hold the connection for a moment while restoring the container, then send the request through.</p>
<p>What does a cold start look like on our simple signalling server? It’s hardly recognizable.</p>
<p>Here is a recording, on the left you see the server is sleeping and on the right I hit the domain, there is a slight pause before the page renders ✨</p>
<video preload="metadata" controls="">
    <source src="https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/sleep.mp4" type="video/mp4">
    Your browser does not support the video element.
  </video>
<h3 id="footnotes">Footnotes</h3>


            </div>
        </article></main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic made a mistake in cutting off third-party clients (218 pts)]]></title>
            <link>https://archaeologist.dev/artifacts/anthropic</link>
            <guid>46586766</guid>
            <pubDate>Mon, 12 Jan 2026 10:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologist.dev/artifacts/anthropic">https://archaeologist.dev/artifacts/anthropic</a>, See on <a href="https://news.ycombinator.com/item?id=46586766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Anthropic may have just committed the biggest business blunder of 2026 -- and we're less than two weeks in. To understand why, let's briefly rewind to 2025, the year when agentic AI went mainstream.</p>
<p>On 3 February 2025, Andrej Karpathy <a href="https://x.com/karpathy/status/1886192184808149383?s=20">coined the term "vibe coding"</a> to describe the new paradigm.</p>
<p>Less than three weeks later, Anthropic <a href="https://www.anthropic.com/news/claude-3-7-sonnet">released the first research preview of Claude Code</a>, bringing large language models directly into developers' native habitat: the terminal.</p>
<p>OpenAI <a href="https://techcrunch.com/2025/04/16/openai-debuts-codex-cli-an-open-source-coding-tool-for-terminals/">followed with Codex CLI</a> in April, and Google released <a href="https://blog.google/innovation-and-ai/technology/developers-tools/introducing-gemini-cli-open-source-ai-agent/">Gemini CLI</a> in June.</p>
<p>All of these terminal-based coding agents follow the same principle:</p>
<ol>
<li>you type a prompt</li>
<li>the agent sends it to a large language model</li>
<li>the LLM responds and may instruct the agent to carry out actions like editing files or running commands</li>
<li>the agent carries out the actions and appends the results to the prompt</li>
</ol>
<p>These steps are repeated in a loop, but with a twist: the agent can continue working through the loop until the LLM decides that it requires user input.</p>
<p>The principle is so simple that it immediately gave rise to a bunch of alternative coding agents, including OpenCode, Roo, and Amp Code (to name but a few).
Each brought its own unique philosophy and approach to the table, but what they all have in common is that they ultimately rely on large language models for intelligence.
Their job is purely to collect user input, execute tool calls, and pass those to the model, over and over again.
Therefore, they tend to provide a way to select from a predefined set of models and a means of authenticating with the relevant providers (such as Anthropic or OpenAI),
generally using an API key.</p>
<p>When Claude Code launched for real in June 2025, usage of the Anthropic models was <a href="https://www.zdnet.com/article/anthropics-popular-claude-code-ai-tool-now-included-with-its-20month-pro-plan/">included</a> in the Pro and Max plans, for a flat monthly or annual subscription.
These plans quickly became very popular when users realised that the effective cost per token was much lower compared to Anthropic's API pricing.
So popular, in fact, that it <a href="https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone">reached $1 billion in annualised revenue</a> after only six months.</p>
<p>Meanwhile, OpenCode rapidly gained popularity, <a href="http://archive.today/OftjM">amassing</a> over 50,000 GitHub stars and more than 650,000 monthly active users in the same short timeframe.
One of its key selling points was the ability to "Log in with Anthropic to use your Claude Pro or Max account", thus enabling developers to benefit from the attractive Claude subscription pricing.
In contrast, other coding agents such as Amp only provided the ability to connect to Claude models via the much more expensive pay-per-token API.</p>
<p>It turns out that logging into third-party coding agents with an Anthropic OAuth token was a bit of a loophole. This was evident from the fact that it would only work if the client-supplied system prompt contained a specific phrase <a href="https://github.com/anomalyco/opencode/issues/417">identifying itself as Claude Code</a>. Nevertheless, many (presumably) unsuspecting Anthropic customers used OpenCode in this way; from their perspective, they were simply using the same service that they were already paying for, just in the comfort of their preferred coding harness.</p>
<p>However, Anthropic clearly didn't see it this way. On 9 January 2026, Anthropic unceremoniously closed the loophole, changing their API to detect and reject requests from third-party clients. The renowned vibe-coder Peter Steinberger soon <a href="https://x.com/steipete">posted</a> about it on the website formerly known as Twitter, and disgruntled Anthropic customers <a href="https://github.com/anthropics/claude-code/issues/17118">expressed their discontent</a> in a GitHub issue, requesting the decision to be reversed, many threatening to cancel their Claude subscription otherwise.</p>
<p>It's notable that Anthropic has not formally announced this change in ToS enforcement, neither ahead of time nor after the fact. The only quasi-announcement of this change was <a href="https://x.com/trq212/status/2009689809875591565">this thread</a>, posted by an Anthropic employee on their personal account the day after the changes took effect, presumably in response to customer complaints. The stated motivation for the change was the allegation that "third-party harnesses using Claude subscriptions create problems for users and generate unusual traffic patterns [...] making it really hard for us to help debug when they have questions about rate limit usage or account bans and they don’t have any other avenue for this support."</p>
<p>I will leave it to the reader to decide for themselves whether they consider this a credible explanation or not; frankly, it doesn't matter. The truth is that Anthropic is free to put whatever they want into their ToS, and customers have to abide by it or leave. It appears quite a few have opted for the latter. However, what does matter is what Anthropic has implicitly revealed through its actions last Friday:</p>
<ol>
<li>Anthropic is willing to go to war with their paying customers over a trivial ToS violation, and</li>
<li>they really, really want to own the entire value chain rather than being relegated to becoming just another "model provider", and</li>
<li>they utterly failed to consider the second-order effects of this business decision.</li>
</ol>
<p>The first point has received ample discussion already, so I want to focus on the second and third points.</p>
<p>It was <a href="https://www.theguardian.com/technology/2026/jan/07/ai-anthropic-funding-valuation">reported</a> just a few days earlier that Anthropic has signed a term sheet to raise $10bn at a humongous $350bn valuation. Related or not, the incentives are clear. Model-agnostic harnesses such as OpenCode present a real threat to Anthropic. Whilst its models are incredibly popular in the software developer community and it has made big inroads in enterprise LLM usage, the Claude chatbot itself reportedly commands a market share of... wait for it... <a href="https://gs.statcounter.com/ai-chatbot-market-share">1.07%</a>. So it's no surprise that they are trying to avoid being commoditized in their core market.</p>
<p>Which brings us to the final point: without anticipating it, Anthropic just found itself in a classic <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">prisoner's dilemma</a> with OpenAI -- and OpenAI just <a href="https://x.com/thsottiaux/status/2009742187484065881?s=20">defected</a>. Not only are they officially supporting OpenCode users to use their Codex subscriptions and usage limits in OpenCode, they are <a href="https://x.com/thsottiaux/status/2010064438033104966">extending the same support</a> to other open-source coding harnesses such as OpenHands, RooCode, and Pi. And it's not just a theoretical announcement either: support for connecting ChatGPT Pro/Plus subscriptions with OpenCode has already <a href="https://x.com/thdxr/status/2009803906461905202?s=20">shipped</a>.</p>
<p>What are we to take away from all this?</p>
<p>For me personally, I have decided I will never be an Anthropic customer, because I refuse to do business with a company that takes its customers for granted. Beyond my personal choices, though, I predict that the folks at Anthropic will come to regret their actions last week. By cracking down on their own customers in a vain attempt to quash healthy competition, they have destroyed a lot of goodwill and <a href="https://x.com/archeologistdev/status/2009763760748278110?s=20">gave their main rival an opening that was ripe for the picking</a>. Whilst they have plenty of cash in the bank for now, they will eventually need to learn to treat their customers with respect if they are to survive in the ever-more-competitive LLM provider landscape.</p>
<p><em>The views expressed here are my own. While the analysis is based on publicly available information, I welcome any factual corrections -- please feel free to <a href="https://x.com/archeologistdev">reach out</a>.</em></p>
</div></div>]]></description>
        </item>
    </channel>
</rss>