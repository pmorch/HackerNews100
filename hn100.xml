<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 22 Jun 2025 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Mechanical Watch: Exploded View (355 pts)]]></title>
            <link>https://fellerts.no/projects/epoch.html</link>
            <guid>44347425</guid>
            <pubDate>Sun, 22 Jun 2025 14:56:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fellerts.no/projects/epoch.html">https://fellerts.no/projects/epoch.html</a>, See on <a href="https://news.ycombinator.com/item?id=44347425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div><p>
        In May 2022, someone posted to Hacker News <a href="https://ciechanow.ski/mechanical-watch/">Bartosz
          Ciechanowski's
          blog post</a>
        explaining how mechanical watch movements work. Since then, his blog has
        been my absolute favorite corner of the Internet. His posts are not just
        well written and easy to follow, the accompanying interactive
        illustrations are magnificent.
        </p><p>
        The first illustration in his blog post about mechanical watch movements
        allows you to "explode" a ticking mechanical movement and rotate it to
        inspect its every component from any angle. I owe my foray into the
        hobby of watchmaking to Bartosz, but that's not what this blog post is
        about. Instead, I want to scratch an itch I've had for years now: How
        cool would it be to hold an exploded view of a <i>real</i> mechanical
        watch in your hand?
      </p></div>

    

    <h2>Apparently, nobody builds such models</h2>
    <div>
      <p>
        I figured that surely, someone has had this idea and built it before. On
        eBay you'll find cubes of resin embedding various random components from
        mechanical watches, but they are typically sold as "steampunk art" and
        bear little resemblance to the proper assembly of a mechanical watch
        movement. Sometimes, you'll find resin castings showing every component
        of a movement spread out in a plane like a buffet---very cool, but not
        what I'm looking for. Despite my best efforts, I haven't found anyone
        who makes what I'm after, and I have a sneaking suspicion as to why that
        is.
      </p>
      <div>
        <p><a href="https://fellerts.no/img/epoch/watch-buffet.jpg">
          <img src="https://fellerts.no/img/epoch/watch-buffet.jpg">
        </a></p><p>
          Every component making up the movement of a beautiful 1960's Longines
          Flagship wristwatch I worked on recently, laid out "buffet style".
        </p>
      </div>
      <p>
        Building an exploded view of a mechanical watch movement is undoubtedly
        very fiddly work and requires working knowledge about how a mechanical
        watch is assembled. People with that skillset are called watchmakers.
        <i>Maker</i>, not "destroyer for the sake of art". I guess it falls to
        me, then, to give this project an honest shot.
      </p>
    </div>

    <h2>...how do you build such a model?</h2>
    <div><p>
        Here comes my favorite part: jumping head-first into a project requiring
        a set of skills I don't even know exist, let alone possess, following a
        process that develops as the project evolves. So how would one go
        about building a real-life exploded view of a mechanical watch movement?
        </p><p>
        The first thing to consider is what type of mechanical watch movement to
        "explode". Although he doesn't explicitly say, I think Bartosz
        Ciechanowski's blog post is based on the <a href="https://calibercorner.com/eta-caliber-2824-2/">ETA caliber
          2824-2</a> mechanical watch movement (or one of its many clones, such as
        the Chinese PT5000). This is a very robust and popular automatic
        (self-winding) mechanical wristwatch movement found in many watches.
        It's considered one of the all-time "workhorse" movements of the
        industry. I highly encourage the curious reader to check out <a href="https://www.youtube.com/watch?v=Utzdcc-XJ5g">this YouTube video</a>
        of a very skilled and equally witty watchmaker servicing a Hamilton
        watch featuring this exact movement. The video will also reveal how many
        absolutely miniscule components make up the ETA-2824, making it less
        than ideal for my initial prototyping. A larger and simpler movement
        would be much better.
        </p><p>
        Luckily, in the late 1800's to early 1900's, many people carried a
        pocketwatch about their person. However, as smaller wristwatches gained
        popularity among men, beginning around the first world war with trench
        watches, pocket watches lost their value as timepieces. Many were melted
        down to reclaim the gold used to case the movement. Today, you can find
        gorgeous, hand-engraved movements from the turn of the 20th century on
        <a href="https://www.ebay.com/sch/i.html?_nkw=vintage+pocket+watch+movement">eBay</a>
        for next to nothing.
        </p><p>
        Pocketwatches are the simplest mechanical watch movements out there:
        they typically don't have any date complications, aren't self-winding,
        and usually don't even have a central seconds hand---that's a
        relatively modern feature. There's a reason budding watchmakers start
        out practicing on pocketwatch movements.
        </p><p>
        Now for the hard part: How do you suspend 50-100 tiny components to form
        an exploded view of the assembly?
      </p></div>

    <div>
      <!-- <a
        href="https://calibercorner.com/wp-content/uploads/2019/01/sellita-caliber-sw200-1-wide.jpg">
        <img
        src="https://calibercorner.com/wp-content/uploads/2019/01/sellita-caliber-sw200-1-wide.jpg">
        </a>
      <p>
        The Selita caliber SW200, one of the many ETA-2824 clones out there.
      </p> -->
      <p><a href="https://fellerts.no/img/epoch/pocketwatch.jpg">
        <img src="https://fellerts.no/img/epoch/pocketwatch.jpg">
      </a></p><p>
        A beautiful early 1900's pocketwatch movement from eBay. $20 for a piece
        of horological art.
      </p>
    </div>

    <h2>Layered resin casting</h2>
    <div>
      <p>
        The model I'm planning to build must stand up to being handled, which
        means it must be solid. In turn, that probably means that I need to cast
        my components in clear epoxy resin. My first idea was to build the
        exploded model up, layer by layer, letting the resin cure between each
        layer. To save time, I experimented with clear resin that cures when
        exposed to UV light. There are several reasons why this did not work:
      </p>
      <ol>
        <li>
            <p>The resin I purchased ended up with a heavy yellow tint after
              curing.
            </p>
          </li>
          <li>
            <p>My puny UV flashlight took forever to cure a pour even 1 mm
              deep.</p>
          </li>
          <li>
            <p>The seams between layers are very visible.</p>
          </li>
        
      </ol>
      <div><p>
        The first two problems can probably be solved by throwing money at the
        problem, but the last issue seems to be a problem with varying indices
        of refraction throughout my casting. The resin art community is
        well-aware of this problem, and the suggested solution is to pour the
        next layer of resin before the previous layer has fully cured. This
        supposedly helps the two layers fuse, and should make the transition
        between layers much less pronounced. Unfortunately, UV resin seems to
        cure from the outside in, meaning I needed to use "regular" two-part
        epoxy instead.
        </p><p>
        To achieve the effect I want, I need around 20 layers for a regular
        pocket watch movement. If I were to cast each layer in a transparent
        container, adding components and epoxy as the previous layer was
        half-cured, I would be doing nothing else for a solid week. Instead, I
        figured my best bet was to cast all 20-or-so layers at once, and stack
        them together once the epoxy was semi-cured. So, my next project was to
        order some casting silicone and cast myself a mold suited to casting
        thin disks of clear epoxy. A baking tray studded with poker chips formed
        the ideal mold for casting the silicone.
        </p><p>
        My resin disks solved problems 1 and 2 above, but problem 3 is still
        unsolved. In addition, this was a very messy and challenging way to
        cast resin: the half-cured disks are floppy, resin runs everywhere and
        bubbles get stuck between the layers. I bought a small vacuum chamber to
        combat the bubble issue, but escaping gas weaked havoc on the disks of
        resin. I learned enough about resin castings to finally realize that
        layered casting is not the way to go.
      </p></div>
    </div>
    <div>
      <p><a href="https://fellerts.no/img/epoch/uv-resin.jpg">
        <img src="https://fellerts.no/img/epoch/uv-resin.jpg">
      </a></p><p>
        1st attempt: embedding some nails in layers of UV resin.
      </p>
      <p><a href="https://fellerts.no/img/epoch/silicone-mold.jpg">
        <img src="https://fellerts.no/img/epoch/silicone-mold.jpg">
      </a></p><p>
        2nd attempt: Embedding more nails in disks of clear resin in a silicone
        mold...
      </p>
      <p><a href="https://fellerts.no/img/epoch/silicone-mold-result.jpg">
        <img src="https://fellerts.no/img/epoch/silicone-mold-result.jpg">
      </a></p><p>
        yeah, no.
      </p>
    </div>

    <h2>Suspending each component with fishing line</h2>
    <div><p>
        It took a while to accept that the only hope I had was to cast the
        entire model at once. This is difficult because I need to somehow
        suspend each tiny component in a way that is robust enough for me to
        pour resin all over it and then pull out any air bubbles.
        </p><p>
        Scarred and burnt by resin's index of refraction, I went looking for
        very thin rods of plastic or acrylic that I could cut to length and glue
        my components to. Fishing line fits the bill. Specifically, monofilament
        nylon leader used in fly fishing. It comes in many thicknesses, has an
        index of refraction very similar to epoxy resin, and is cheap. The only
        major challenge with using fishing line is that it "remembers" its
        spooled shape, so every segment I cut off has a slight bend to it. I was
        able to remedy this somewhat by stringing it repeatedly across the grill
        pan in my oven and baking it at 150°C (300°F) for an hour or so. When done,
        the middle segments are reasonably straight and significantly stiffer
        than what I started with.
        </p><p>
        The assembly process actually resembles "proper" watchmaking a lot. Of
        course, tweezer control and steady hands are important. But applying
        tiny drops of CA glue to components with a pinhead is a lot like
        applying oil to bearing surfaces and jewels. I just find it amusing to
        do it with glue instead of oil---CA glue being the <i>complete
          opposite</i> of a lubricant.
        </p><p>
        Armed with a pair of helping hands and a set of self-closing tweezers, I
        found the process of building up the exploded model of a scrap watch
        movement to be very satisfying.
      </p></div>
    <div>
      <p><a href="https://fellerts.no/img/epoch/fishing-line-screws.jpg">
        <img src="https://fellerts.no/img/epoch/fishing-line-screws.jpg">
      </a></p><p>
        0.7 mm monofilament fishing line attached to bridge screws.
      </p>
      <p><a href="https://fellerts.no/img/epoch/crown-wheel-assy.jpg">
        <img src="https://fellerts.no/img/epoch/crown-wheel-assy.jpg">
      </a></p><p>
        Monofilament fishing line maintains the distance betwen components. A
        jig holds everything still while the CA glue hardens.
      </p>
    </div>

    <h2>Resin casting at home</h2>
    <div><p>
        At this point I've tried a number of different epoxy resins claiming to
        cure crystal clear. As far as I can tell, they all turn out appreciably
        clear. Their main differences are viscosity, cure time and how much air
        they trap when mixing. Some resins claim to expel bubbles when curing.
        They manage this to some extent, but to get completely clear castings
        you either need a vacuum chamber to pull out all the air from your cast,
        or a pressure chamber to completely squash any pockets of air. I went
        for a vacuum pump because it's a fun thing to have around (boiling water
        at room temperature doesn't get old). Another benefit of the vacuum pump
        is that you don't need to leave your cast in the chamber for the entire
        cure time. My castings have a lot of voids that love to trap air, and
        the vacuum chamber does a good job of pulling out the trapped air.
        </p><p>
        My casting method goes like this: Mix enough of part A and B of your
        resin to fill the mold plus 10–15 %. Mix thoroughly for 3 minutes. Pour
        the resin into another mixing container to ensure that no unmixed resin
        is stuck to the walls of your container. Use a fresh stirring stick, and
        mix for another 3 minutes. Pull the whole container under vacuum (I
        manage around -0.96 bar) and leave it there for 30 minutes. Depending on
        your resin, the froth may very well overflow your mixing container:
        cycle between pulling a vacuum and letting air back in a couple times to
        pop most of the bubbles.
        </p><p>
        Now pour the resin into the mold and go through the vacuum process
        again. This time, most of the bubbles you're pulling out come from
        around the embedment, not from air trapped in the resin, which helps
        keep the frothing down.
      </p></div>
    <div>
      <p><a href="https://fellerts.no/img/epoch/froth.jpg">
        <img src="https://fellerts.no/img/epoch/froth.jpg">
      </a></p><p>
        Some resins froth up to several times the liquid volume under vacuum!
        Make sure there's enough room to accomodate this.
      </p>
    </div>

    <h2>Prototype #1: lessons learned</h2>
    <div>
      <p>
        My first somewhat promising cast was in a borosilicate class cylinder. I
        won't dwell on the looks of this, because I mostly wanted to experiment
        and answer a few burning questions with this prototype:
      </p><dl>
        <dt><b>Q:</b> How visible is the fishing line in the final result?</dt>
        <dd><b>A:</b> Not very! It's visible in the right light, but I don't
          think I'm able to do any better.
        </dd>
        <dt><b>Q:</b> Does CA glue interfere with the resin in any way?</dt>
        <dd>
          <b>A:</b> Most resin datasheets say that CA glue can interfere with
          the resin's curing process, but I can't tell from this test.
        </dd>
        <dt><b>Q:</b> Does casting in a cylinder make sense?</dt>
        <dd>
          <b>A:</b> Definitely not. Light refracts on the curved cylinder
          surface making it difficult to understand the geometry inside,
          defeating the purpose of the model. Cast in a cube.
        </dd>
      </dl><p>
      A week or so later, the cylinder shattered. Resin shrinks as it cures. On
      to the next prototype!
      </p>
    </div>

    <div>
      <p><a href="https://fellerts.no/img/epoch/first-cast.jpg">
        <img src="https://fellerts.no/img/epoch/first-cast.jpg">
      </a></p><p>
        First prototype cast. Fishing line all but disappears in the resin.
      </p>
    </div>

    <h2>Prototype #2: promising results</h2>
    <div>
      <p>
        At this point I have settled on a somewhat structured process.

      </p><h3>Disassemble and clean</h3><p>
      Start with a clean, disassembled movement. For instructions on how to
      properly disassemble and clean a watch movement, I highly recomment <a href="https://www.watchfix.com/">Mark
        Lovick's Watch Repair Course</a>.
      Assemble the train of wheels with their bridges and seize them by
      depositing small amounts of CA glue on the pinions. Just like with the
      watchmaker's oil, a sewing needle with a flat spot is perfect for
      picking up a small droplet of CA glue and depositing it where it's
      needed. Capillary action wicks it between the components. Less is more
      when it comes to CA glue: the bond between surfaces is stronger when no
      excess is used, and the cure time is around 30 seconds even without the
      use of an activator.
      </p><p>
      I made a small jig for cutting pieces of fishing line accurately and
      squarely out of a janky hand press tool.
      </p><h3>Assemble trainwheel side</h3><p>
      Work starts on the train wheel side of the movement (often called the
      watchmaker's side) because that's where most of the complexity lies.
      While working here, the movement can rest in a movement holder. I attach
      long strands of fishing line to the end of each of the bridge screws.
      Self-closing tweezers hold the bridges in place above where they seat on
      the mainplate, and the screw/fishing line combo is threaded through the
      screw hole in the bridge into the corresponding holes in the mainplate.
      More glue binds the bridges to the fishing line.
      </p><p>
      Subassemblies such as of the keyless works, motion works, balance
      assembly, etc. can be constructed separately and fastened as a unit.
      Small, flat components such as cover plates, intermediate wheels and cap
      jewels each get their own short studs of fishing line. I dip the studs
      in CA glue and place it near the center of mass of the component I'm
      working on: the fishing line's flat ends allows it to stand upright.
      </p><h3>Flip and assemble the dial side</h3><p>
      Before starting work on the dial side of the movement, it must be flipped
      over. I transfer the assembly into the jaws of some tweezers and apply
      closing force with a rubber band. The tweezers are clamped by "helping
      hands" glued to a piece of cardboard which allows me to spin my work
      around. Work continues similarly on the dial side. Finally, some thin
      transparent nylon sewing thread attaches the mainplate to a pegwood stick
      that allows me to suspend the whole assembly over a mold, ready for
      casting resin.
      </p><h3>Make the mold, prepare and pour resin</h3><p>
      Speaking of the mold: I bought some 2 mm thick 20x30 cm acrylic sheets.
      Foamcore or wood could work as well, but I don't want the vacuum pump to
      pull air from the mold into the casting. I cut them into 7x10 cm
      rectangles and lined them with "epoxy mold tape" (fancy packing tape
      that epoxy resin does not bond to). Then I used some Tec7 construction
      adhesive to form a cube.
      </p><p>
      Prototype #2 shows a lot of promise! It's far from perfect, though. Here
      are some of the things I'll improve for prototype #3 in no particular
      order:
      </p><ul>
        <li>
            <p>I struggled with attaching subassemblies to the mainplate because
              I need to precisely control the distance between the subassembly and
              the target surface: too snug and the assembly ends up crooked, too
              far away and the glue doesn't adhere properly. A proper lab jack
              (tiny scissor lift) might solve this, so one is on the way.
            </p>
          </li>
          <li>
            <p>The resin shrunk a lot while curing, most likely because it
              overheated. I'll focus on proper airflow for my next cast.
            </p>
          </li>
          <li>
            <p>
              People noted that it's difficult to see between the components, so
              I'll "explode" the next model even more.
            </p>
          </li>
          <li>
            <p>
              The hands are set to an invalid time. 10:10 is the way to go.
            </p>
          </li>
        
      </ul>
      <!-- shrinkage lab jack 2 -->
      
    </div>
    <p><a href="https://fellerts.no/img/epoch/prototype-2-top.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-2-top.jpg">
      </a>
      <br>
      <a href="https://fellerts.no/img/epoch/prototype-2-side-1.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-2-side-1.jpg">
      </a>
      <br>
      <a href="https://fellerts.no/img/epoch/prototype-2-side-2.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-2-side-2.jpg">
      </a>
      <br>
      <a href="https://fellerts.no/img/epoch/prototype-2-bottom.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-2-bottom.jpg">
      </a>
      <br>
    </p>

    <h2>Protoype #3: nailing the technique</h2>
    <div>
      <div><p>
        The third iteration incorporated the scissor lift lab jack into the
        process which, together with helping hands, allowed for much greater
        precision in bringing components together true and square. I'm also
        committing another watchmaking sin by placing a small magnet in the jaws
        of my self-closing tweezers to gently hold tiny screws. This allows me
        to lower a screw into its target drop of CA glue and simply lift the
        tweezers once the glue has set. This is a much more reliable method than
        trying to hold onto a sub-millimeter screw with self-closing tweezers
        whose gripping force I have little control over. Magnets are sinful in
        this case because magnetism can cause all sorts of timing issues in
        mechanical watch movements, but that's obviously not an issue in my
        case.
        </p><p>
        I also started using a CA accelerator to speed up the assembly, because
        waiting for glue to cure is painful. Spraying the accelerator onto my
        work would create a huge mess, so instead I spray some into a lidded
        container and use tweezers to pick up droplets of the stuff to deposit
        accurately onto the glue joints. This stuff is too volatile and runny to
        be picked up by a needle. For me, the most effective use of the CA
        accelerant is to first place a drop of CA glue on one of the two mating
        surfaces, then dip the other surface in accelerant and quickly bringing
        them into contact. I believe this works well because the joint cures
        along the interface instead of curing from the outside-in as is the case
        when spraying accelerant after the joint has glue in it.
        </p><p>
        You may see that the balance wheel is hanging from the hairspring in
        this casting. The balance wheel marks the end of the train of wheels and
        releases tiny amounts of energy from the mainspring 18,000 times per
        hour. The balance assembly is the heart of the movement and is also the
        most delicate component, and I want to highlight that by stretching the
        hairspring to show its form. These components are not glued in place,
        and the balance wheel hangs freely from its spring, meaning I have to
        cast the whole assembly upside-down to achieve this effect.
      </p></div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/prototype-3-side-1.jpg">
            <img src="https://fellerts.no/img/epoch/prototype-3-side-1.jpg">
          </a>
        </p>
        <p><a href="https://fellerts.no/img/epoch/prototype-3-side-2.jpg">
            <img src="https://fellerts.no/img/epoch/prototype-3-side-2.jpg">
          </a>
        </p>
      </div>
    </div>
    <p><a href="https://fellerts.no/img/epoch/prototype-3-top.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-3-top.jpg">
      </a>
      <br>
      <a href="https://fellerts.no/img/epoch/prototype-3-bottom.jpg">
        <img src="https://fellerts.no/img/epoch/prototype-3-bottom.jpg">
      </a>
    </p>

    <h2>Protype #4: ETA-2824</h2>
    <div>
      <p>
        At this point I figured I was ready to tackle the final boss of this
        project: the ETA 2824 wristwatch movement that we've all seen in <a href="https://ciechanow.ski/mechanical-watch/">Bartosz Ciechanowski's
        blog post</a>. Well, I'll tackle the Chinese PT5000 clone movement
        instead, because I can't justify spending €300 on a genuine movement
        only to ensure it will never run again.
      </p>
      <div>
        <p><a href="https://fellerts.no/img/epoch/pt5000-vs-render.jpg">
          <img src="https://fellerts.no/img/epoch/pt5000-vs-render.jpg">
        </a></p><p>
          Comparing my PT5000 to Bartosz's render.
        </p>
      </div>
      <div><p>
        This movement arrived from China in good working order---I was actually
        suprised at its performance out of the box. It ran with good amplitude
        and little positional variance between horizontal and vertical
        positions. I became less and less impressed as I disassembled the
        movement prior to cleaning, though, because it was absolutely drenched
        in oil. Many of the bridges had sharp burrs that broke off during
        cleaning. Nothing was broken though. All in all, these movements really
        need a proper service before putting them to service. That's not an
        issue here though.
        </p><p>
        I was worried that the much smaller components would be challenging to
        work with, but I found the process to be essentially the same as for
        larger pocket watch movements. My 0.7 mm nylon fishing wire still fits
        through most of the screw holes and the lab jack makes alignment a
        breeze.
        </p><p>
        Some components needed special care, in particular the balance shock
        springs that protect the delicate pivots of the balance staff from
        shocks. These aren't normally found on older pocket watch movements
        which is why a broken balance staff is one of the most common failure
        modes of pocketwatches. Shock springs are fragile and are, in my
        opinion, among the most difficult components to handle when servicing a
        watch. Of course, I want to also explode the balance assembly, so I
        needed a way to suspend the shock springs above the capstone jewel. By
        laying the spring down flat on silicone and placing a drop of CA glue on
        it, the surface tension of the glue fills in the inner disk. Once cured,
        the spring with its hard and transparent interior can be lifted off the
        silicone. This is how the luminous material (lume) is applied to the
        hands of a watch---another watchmaker's trick.
        </p><p>
        The assembly process was luckily uneventful, and I finished the build
        off with a black dial and a random set of hands from eBay.
        Unfortunately, the casting process went completely south. Only after I
        had created a mold, mixed, degassed, and poured resin, did I realize
        that my mold was just barely too tall to fit comfortably in the vacuum
        chamber. With some hasty modifications to the scaffolding that supported
        the exploded model, I was able to pull a reasonable vacuum on it, but it
        left the exploded model crooked. To add insult to injury, the resin
        seems to have dissolved the paint on the date indicator ring, which left
        milky streaks throughout the casting.
        </p><p>
        All in all, I spent roughly 18 hours stripping, cleaning and assembling
        the exploded view of the PT5000. With improved technique I might get
        this down below 15 hours, but it's <i>very</i> tedious work, and rushing
        means I'll knock something off and have to redo work. Good to know,
        because I will be doing this again until I get it right.
        </p></div>
    </div>
    <div>
      <p><a href="https://fellerts.no/img/epoch/pt5000-whale.jpg">
        <img src="https://fellerts.no/img/epoch/pt5000-whale.jpg">
      </a></p><p>The PT5000 disassembles nicely into a steampunk whale.</p>
      <p><a href="https://fellerts.no/img/epoch/pt5000-assy-1.jpg">
        <img src="https://fellerts.no/img/epoch/pt5000-assy-1.jpg">
      </a></p><p>Installing the barrel bridge assembly.</p>
      
      <p><a href="https://fellerts.no/img/epoch/pt5000-assy-4.jpg">
        <img src="https://fellerts.no/img/epoch/pt5000-assy-4.jpg">
      </a></p><p>Assembly complete!</p>
      
      <p><a href="https://fellerts.no/img/epoch/pt5000-final.jpg">
        <img src="https://fellerts.no/img/epoch/pt5000-final.jpg">
      </a></p><p>Final casting. The paint on the date ring, dial and hands dissolved. Also, the model is crooked.</p>
      <br>
    </div>

    <h2>End game: the wristwatch</h2>
    <div>
      <p>
        Prototype #4 has a couple flaws which I'd like to fix before calling
        this project done. The process of assembling the model is more or less
        nailed down: I just need to find a way to seal any painted surface
        before casting, as well as try to remember that my vacuum chamber has
        limited volume. I bought another PT5000, this time in a complete watch
        with case and a metal band, and started experimenting with sealing the
        painted surfaces. Here's what didn't work:
      </p><ul>
        <li>CA glue dissolves paint just as readily as epoxy resin. It might
          work on simple paint-jobs like the chapter indices and the hands, but
          the date ring has crisp lines (the numbers) which I need to
          preserve.</li>
        <li>UV curable CA glue didn't cure on top of the paint. No idea why.</li>
        <li>Same with UV curable epoxy resin.</li>
      </ul><p>
      Clear spray lacquer from the hardware store worked well and didn't
      dissolve the paint. It did turn yellow as you'll see in the final casting,
      but I'm okay with that. I also built a better jig to cut the fishing line
      into equal lengths with square ends. It's a bit janky but worked very
      well.
      </p><p>
      There's not much more to say. I'll stop blabbering and make way for an
      image series.
      </p>
    </div>
    <div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/fishing-line-jig.jpg">
          <img src="https://fellerts.no/img/epoch/fishing-line-jig.jpg">
        </a></p><p>Janky but effective cutting jig for fishing line.</p>
      </div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/painting.jpg">
          <img src="https://fellerts.no/img/epoch/painting.jpg">
        </a></p><p>Painting the dial, hands and calendar ring...</p>
      </div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/ww-assy-1.jpg">
          <img src="https://fellerts.no/img/epoch/ww-assy-1.jpg">
        </a></p><p>
          The watchmaker's side of the movement is assembled and fastened to the case.
        </p>
      </div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/ww-assy-2.jpg">
          <img src="https://fellerts.no/img/epoch/ww-assy-2.jpg">
        </a></p><p>
          Our watch is held by a stiff cardboard tube (okay, a toilet roll core)
          to keep the finished half suspended mid-air while work continues on
          the dial-side.
        </p>
      </div>

      <div>
        <p><a href="https://fellerts.no/img/epoch/ww-assy-3.jpg">
          <img src="https://fellerts.no/img/epoch/ww-assy-3.jpg">
        </a></p><p>
          Aligning the date ring...
        </p>
      </div>
      <div>
        <p><a href="https://fellerts.no/img/epoch/ww-assy-6.jpg">
          <img src="https://fellerts.no/img/epoch/ww-assy-6.jpg">
        </a></p><p>
          Done! I wish I could keep it in this form, but it's too
          fragile.
        </p>
      </div>
    </div>
    <h2>Final result</h2>
    <div>
      
      <p>
        I don't have the tools or knowledge required to sand this down to a
        perfect mirror finish, but that's okay. After 2.5 years of noodling
        around with this, I've achieved what I set out to do, and I'm pretty
        happy with the result, even if it is difficult to photograph. Figured
        I'd write this post to get some honest feedback, maybe even some tips,
        in case I decide to continue working on this... I mean, more <a href="https://en.wikipedia.org/wiki/Chronograph#/media/File:ST19_chronograph_movement_(Venus_175).jpg">interesting</a>
        wristwatch movements do exist!
      </p>
      <p>
        Bartosz, if you are reading this, <a href="https://fellerts.no/contact.html" tabindex="0" target="_self">contact</a> me and I'll send you the final casting. This
        project would never have happened without your blog post.
      </p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Denmark Is Switching to Linux (107 pts)]]></title>
            <link>https://www.pcgamer.com/software/operating-systems/denmark-is-switching-to-linux/</link>
            <guid>44346120</guid>
            <pubDate>Sun, 22 Jun 2025 11:52:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/software/operating-systems/denmark-is-switching-to-linux/">https://www.pcgamer.com/software/operating-systems/denmark-is-switching-to-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=44346120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<div id="slice-container-freeText-5ULdUh9LGMaJwzpL7gRfR5-Q4BbKbh3qDdHdpdHQ0564qv7jAfXQ41j"><p><strong>Update 6/22/25: </strong>Politiken has amended its original story to report that the Danish Ministry of Digital Affairs is only phasing out Microsoft Office—Windows is here to stay, for the time being.</p></div><p>Denmark's Ministry of Digital Affairs is trading Microsoft Office for the open source alternative, LibreOffice</p><p>It'll migrate about half of the Ministry of Digital Affairs away from Office this summer, reports Danish newspaper <a data-analytics-id="inline-link" href="https://politiken.dk/viden/tech/art10437680/Caroline-Stage-udfaser-Microsoft-i-Digitaliseringsministeriet" target="_blank" data-url="https://politiken.dk/viden/tech/art10437680/Caroline-Stage-udfaser-Microsoft-i-Digitaliseringsministeriet" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Politiken</a>. The move was attributed to a desire for greater digital sovereignty.</p><p>"It is not about isolation or digital nationalism ... But we must never make ourselves so dependent on so few that we can no longer act freely. Too much public digital infrastructure is currently tied up with very few foreign suppliers. This makes us vulnerable," said Danish Minister for Digital Affairs Caroline Stage Olsen in a LinkedIn Message translated by <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/its-the-year-of-linux-at-least-for-denmark-heres-why-the-countrys-government-is-dumping-windows-and-office-365" target="_blank" data-url="https://www.windowscentral.com/software-apps/windows-11/its-the-year-of-linux-at-least-for-denmark-heres-why-the-countrys-government-is-dumping-windows-and-office-365" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Windows Central</a>.</p><p>Though Politiken's original report that the government was moving away from Windows entirely was apparently made in error, this could be a sign of things to come for Denmark.</p><p>Governments have shifted away from Windows as a default in the past, but this is a pretty high profile one. Denmark is a pretty big economic player in Europe, and often ranks as a top ten nation worldwide when it comes to purchasing power and domestic product per capita.</p><p>This is certainly an ontologically good and/or bad thing if you're part of some kind of Operating System Wars cult. To me, it seems inevitable that the world will move on. In the distant past of computers moving between operating system families was pretty routine, and although it's true that Windows was so dominant for a time that Linux proponents were frequently laughed off, the tides always change eventually.</p><p>One day you'll probably ditch Windows for some uses, or scenarios, or maybe entirely—heck, if you've made the Steam Deck jump you already have done it in part, which might be something you didn't even think about when you did it.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-5ULdUh9LGMaJwzpL7gRfR5"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git Notes: Git's coolest, most unloved­ feature (2022) (286 pts)]]></title>
            <link>https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/</link>
            <guid>44345334</guid>
            <pubDate>Sun, 22 Jun 2025 09:14:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/">https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/</a>, See on <a href="https://news.ycombinator.com/item?id=44345334">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">







<section id="pagebody" role="main">
<blockquote>
<p>the short of it is: they’re cool for appending notes from automated
systems (like ticket or build systems) but not really for having
interactive conversations with other developers (at least not yet)</p>
<p>– Scott Chacon, <a href="https://github.blog/2010-08-25-git-notes-display/">GitHub.blog</a>,
Aug.&nbsp;2010</p>
</blockquote>
<p>Git notes are almost a secret.</p>
<p>They’re buried by their own distressing usability.</p>
<p>But git notes are continually rediscovered by engineers trying to
stash metadata inside git.</p>
<figure>
<img src="https://photos.tylercipriani.com/2022-10-30_simonw-git-notes.png" alt="Sun, 30 Oct 2022 11:05 @simonw">

</figure>
<p><strong>Git notes are powerful tools.</strong> And they could solve
so many problems—if only they were better known and easier to use.</p>
<section id="what-are-git-notes">
<h2><span>🧐</span> What are git notes?</h2>
<p>A common use of git notes is tacking metadata onto commits.</p>
<p>Once a commit cements itself in git’s history—that’s it. It’s
impossible to amend a commit message buried deep in a repo’s log<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>But git notes enable you to amend new information about old commits
in a special namespace. And they’re capable of so much more.</p>
<p><strong>Notes stow metadata about anything tracked by
git</strong>—any object: commits, blobs, and trees. All without futzing
with the object itself.</p>
<p>You add notes to the latest commit in a repo like this:</p>
<pre><code>git notes add -m 'Acked-by: &lt;tyler@tylercipriani.com&gt;'</code></pre>
<p>And then it shows up in <code>git log</code>:</p>
<pre><code>commit 1ef8b30ab7fc218ccc85c9a6411b1d2dd2925a16
Author: Tyler Cipriani &lt;thcipriani@gmail.com&gt;
Date:   Thu Nov 17 16:51:43 2022 -0700

    Initial commit

    Notes:
        Acked-by: &lt;tyler@tylercipriani.com&gt;</code></pre>
</section>
<section id="git-notes-in-the-wild">
<h2><span>🥾</span> Git notes in the wild</h2>
<p>The git project itself offers an example of git notes in the wild.
They link each commit to its discussion on their mailing list.</p>
<p>For example:</p>
<pre><code>commit 00f09d0e4b1826ee0519ea64e919515032966450
Author: &lt;redacted&gt;
Date:   Thu Jan 28 02:05:55 2010 +0100

    bash: support 'git notes' and its subcommands
    ...

Notes (amlog):
    Message-Id: &lt;1264640755-22447-1-git-send-email-szeder@ira.uka.de&gt;</code></pre>
<p>This commit’s notes point intrepid users to the <a href="https://lore.kernel.org/git/1264640755-22447-1-git-send-email-szeder@ira.uka.de/">thread
where this patch was discussed</a>.</p>
<p>Other folks are using notes for things like:</p>
<ul>
<li>Tracking time spent per commit or branch</li>
<li>Adding review and testing information to git log</li>
<li>And even fully distributed code review</li>
</ul>
</section>
<section id="storing-code-reviews-and-test-results-in-git-notes">
<h2><span>📦</span> Storing code reviews and test results in git
notes</h2>
<p>Here is a plea for all forges: make code review metadata available
offline, inside git.</p>
<p>The <a href="https://gerrit.googlesource.com/plugins/reviewnotes/+/refs/heads/master/src/main/resources/Documentation/refs-notes-review.md">reviewnotes</a>
plugin for Gerrit<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> is an example of how to do this
well. It makes it easy to see who reviewed code in git log:</p>
<pre><code>git fetch origin refs/notes/review:refs/notes/review
git log --show-notes=review</code></pre>
<p>The command above shows me all the standard git log info alongside
information about what tests ran and who reviewed the code. All without
forcing me into my browser.</p>
<pre><code>commit d1d17908d2a97f057887a4afbd99f6c40be56849
Author: User &lt;user@example.com&gt;
Date:   Sun Mar 27 18:10:51 2022 +0200

    Change the thing

Notes (review):
    Verified+1: SonarQube Bot
    Verified+2: jenkins-bot
    Code-Review+2: Reviewer Human &lt;reviewerhuman@wikimedia.org&gt;
    Submitted-by: jenkins-bot
    Submitted-at: Tue, 14 Jun 2022 21:59:58 +0000
    Reviewed-on: https://gerrit.wikimedia.org/r/c/mediawiki/core/+/774005
    Project: mediawiki/core
    Branch: refs/heads/master</code></pre>
</section>
<section id="distributed-code-review-inside-git-notes">
<h2><span>💠</span> Distributed code review <u>inside</u> git notes</h2>
<p>Motivated hackers can knead and extend git notes. Using them as
distributed storage for any madcap idea.</p>
<p>Someone at Google cobbled together a full-on code review system
teetering atop git notes called <a href="https://github.com/google/git-appraise">git-appraise</a>.</p>
<p>Its authors have declared it a “fully distributed code
review”—independent of GitHub, GitLab, or any other code forge.</p>
<p>This system lets you:</p>
<ul>
<li>Request review of a change</li>
<li>Comment on a change</li>
<li>Review and merge a change</li>
</ul>
<p>And you can do all this from your local computer, even if GitHub is
down.</p>
<p>Plus, it’s equipped with an affectedly unaesthetic web interface, if
that’s your thing.</p>
<figure>
<img src="https://photos.tylercipriani.com/2022-11-27_git-appraise-web.png" alt="The git-appraise web interface, in all its NaN-line-numbering glory.">

</figure>
</section>
<section id="no-one-uses-git-notes">
<h2><span>😭</span> No one uses git notes</h2>
<p>Git notes are a pain to use.</p>
<p>And GitHub <a href="https://github.blog/2010-08-25-git-notes-display/">opted to stop
displaying commit notes in 2014</a> without much explanation.</p>
<p>For commits, you can make viewing and adding notes easier using fancy
options in your gitconfig<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>. But for storing notes about blobs
or trees? Forget it. You’d need to be comfortable rooting around in
git’s <a href="https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain">plumbing</a>
first.</p>
<p>So, for now: <strong>git notes are relegated to obscurity</strong>.
Forever hamstrung by an obscure and clunky interface and limited
adoption—I often forget they’re there.</p>
</section>
<section id="forge-independence">
<h2><span>🗽</span> Forge independence</h2>
<p>Git is a distributed code review system. But much of the value of git
repos ends up locked into forges, like GitHub.</p>
<p>Git notes are a path toward an alternative.</p>
<p>Git distributes the history of a piece of code. <strong>Git notes
could make it possible to distribute the history of an entire
project.</strong></p>
</section>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Without having to endure the <a href="https://groups.google.com/g/jenkinsci-dev/c/-myjRIPcVwU/m/mrwn8VkyXagJ">perils
of a force push</a>, anyway.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The code review system used for <a href="https://gerrit.wikimedia.org/r/">a</a> <a href="https://go-review.googlesource.com/">couple</a> of <a href="https://android-review.googlesource.com/">bigish</a> <a href="https://chromium-review.googlesource.com/">projects</a>.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Noteably by automagically fetching
notes and displaying them in <code>git log</code> via:</p>
<pre><code>$ git config --add \
remote.origin.fetch \
'+refs/notes/*:refs/notes/*'
$ git config \
notes.displayRef \
'refs/notes/*'</code></pre>
<a href="#fnref3" role="doc-backlink">↩︎</a></li>
</ol>
</section>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How fast are Linux pipes anyway? (107 pts)]]></title>
            <link>https://mazzo.li/posts/fast-pipes.html</link>
            <guid>44344708</guid>
            <pubDate>Sun, 22 Jun 2025 07:27:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mazzo.li/posts/fast-pipes.html">https://mazzo.li/posts/fast-pipes.html</a>, See on <a href="https://news.ycombinator.com/item?id=44344708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">



<div>
<p>In this post, we will explore how Unix pipes are implemented in Linux by iteratively optimizing a test program that writes and reads data through a pipe.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>We will begin with a simple program with a throughput of around 3.5GiB/s, and improve its performance twentyfold. The improvements will be informed by profiling the program using Linux’s <a href="https://en.wikipedia.org/wiki/Perf_(Linux)"><code>perf</code> tooling</a>.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> The code <a href="https://github.com/bitonic/pipes-speed-test">is available on GitHub</a>.</p>
<div>
<figure>
<img src="https://mazzo.li/assets/images/fast-pipe-chart.svg" alt="Chart showing the performance of our pipe test programs.">

</figure>
</div>
<!--
This exercise won't be of much practical use --- we shouldn't be using pipes for high-performance inter-process communication anyway. However, it will shed some light on common themes when dealing with IO and the kernel, and on how one can go about identifying what's slow.
-->
<p>The post was inspired by reading <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">a highly optimized FizzBuzz program</a>, which pushes output to a pipe at a rate of ~35GiB/s on my laptop.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> Our first goal will be to match that speed, explaining every step as we go along. We’ll also add an additional performance-improving measure, which is not needed in FizzBuzz since the bottleneck is actually computing the output, not IO, at least on my machine.</p>
<p>We will proceed as follows:</p>
<ol type="1">
<li><a href="#first-version">A first slow version of our pipe test bench;</a></li>
<li><a href="#trouble-with-write">How pipes are implemented internally, and why writing and reading from them is slow;</a></li>
<li><a href="#splicing">How the <code>vmsplice</code> and <code>splice</code> syscalls let us get around some (but not all!) of the slowness;</a></li>
<li><a href="#paging">A description of Linux paging, leading up to a faster version using huge pages;</a></li>
<li><a href="#busy-loop">The final optimization, replacing polling with busy looping;</a></li>
<li><a href="#closing-thoughts">Some closing thoughts.</a></li>
</ol>
<p>Section 4 is the heaviest on Linux kernel internals, so it might be interesting even if you’re familiar with the other topics treated in the post. For readers not familiar with the topics treated, only basic knowledge of C is assumed.</p>
<p>Let’s begin!</p>
</div>

<h2 id="first-version">The challenge, and a slow first version <a href="#first-version">#</a></h2>
<div>
<p>First of all, let’s start with measuring the performance of <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">the fabled FizzBuzz program</a>, following the rules laid down by the StackOverflow post:</p>
<pre><code>% ./fizzbuzz | pv &gt;/dev/null
 422GiB 0:00:16 [36.2GiB/s]</code></pre>
<p><code>pv</code> is “pipe viewer”, <a href="http://www.ivarch.com/programs/pv.shtml">a handy utility</a> to measure the throughput of data flowing through a pipe. So <code>fizzbuzz</code> is producing output at a rate of 36GiB/s.</p>
<p><code>fizzbuzz</code> writes the output in blocks as big as the L2 cache, to strike a good balance between cheap access to memory and minimizing IO overhead.</p>
</div>
<div>
<p>On my machine, the L2 cache is 256KiB. Throughout this post, we’ll also output blocks of 256KiB, but without “computing” anything. Essentially, we’ll try to measure the upper bound for programs writing to a pipe with a reasonable buffer size.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>While <code>fizzbuzz</code> uses <code>pv</code> to measure speed, our setup will be slightly different: we’ll implement the programs on both ends of the pipe. This is so that we fully control the code involved in pushing and pulling data from the pipe.</p>
</div>

<div>
<p>The code is available <a href="https://github.com/bitonic/pipes-speed-test">in my <code>pipes-speed-test</code> repo</a>. <code>write.cpp</code> implements the writing, and <code>read.cpp</code> the reading. <code>write</code> repeatedly writes the same 256KiB forever. <code>read</code> reads through 10GiB of data and terminates, printing the throughput in GiB/s. Both executables accept a variety of command line options to change their behavior.</p>
<p>The first attempt at reading and writing from pipes will be using the <a href="https://linux.die.net/man/2/write"><code>write</code></a> and <a href="https://linux.die.net/man/2/read"><code>read</code></a> syscalls, using the same buffer size as <code>fizzbuzz</code>. Here’s a view of the writing end:</p>
</div>
<div id="cb2"><pre><code><span id="cb2-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb2-2">  <span>size_t</span> buf_size <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>18</span><span>;</span> <span>// 256KiB</span></span>
<span id="cb2-3">  <span>char</span><span>*</span> buf <span>=</span> <span>(</span><span>char</span><span>*)</span> malloc<span>(</span>buf_size<span>);</span></span>
<span id="cb2-4">  memset<span>((</span><span>void</span><span>*)</span>buf<span>,</span> <span>'X'</span><span>,</span> buf_size<span>);</span> <span>// output Xs</span></span>
<span id="cb2-5">  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span></span>
<span id="cb2-6">    <span>size_t</span> remaining <span>=</span> buf_size<span>;</span></span>
<span id="cb2-7">    <span>while</span> <span>(</span>remaining <span>&gt;</span> <span>0</span><span>)</span> <span>{</span></span>
<span id="cb2-8">      <span>// Keep invoking `write` until we've written the entirety</span></span>
<span id="cb2-9">      <span>// of the buffer. Remember that write returns how much</span></span>
<span id="cb2-10">      <span>// it could write into the destination -- in this case,</span></span>
<span id="cb2-11">      <span>// our pipe.</span></span>
<span id="cb2-12">      <span>ssize_t</span> written <span>=</span> write<span>(</span></span>
<span id="cb2-13">        STDOUT_FILENO<span>,</span> buf <span>+</span> <span>(</span>buf_size <span>-</span> remaining<span>),</span> remaining</span>
<span id="cb2-14">      <span>);</span></span>
<span id="cb2-15">      remaining <span>-=</span> written<span>;</span></span>
<span id="cb2-16">    <span>}</span></span>
<span id="cb2-17">  <span>}</span></span>
<span id="cb2-18"><span>}</span></span></code></pre></div>
<div>
<p>This snippet and following ones omit all error checking for brevity.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> The <code>memset</code> ensures that the output will be printable, but also plays another role, as we’ll discuss later.</p>
<p>The work is all done by the <code>write</code> call, the rest is making sure that the whole buffer is written. The read end is very similar, but <code>read</code>ing data into <code>buf</code>, and terminating when enough has been read.</p>
<p>After building, the code from the repo can be run as follows:</p>
</div>

<pre><code>% ./write | ./read
3.7GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>We’re writing the same 256KiB buffer filled with <code>'X'</code>s 40960 times, and measuring the throughput. What’s worrying is that we’re 10 times slower than <code>fizzbuzz</code>! And we’re not doing any work, just writing bytes to the pipe.</p>
<p>It turns out that we can’t get much faster than this by using <code>write</code> and <code>read</code>.</p>
<h2 id="trouble-with-write">The trouble with <code>write</code> <a href="#trouble-with-write">#</a></h2>
<div>
<p>To find out what our program is spending time on, we can use <a href="https://en.wikipedia.org/wiki/Perf_(Linux)"><code>perf</code></a>:<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> <a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<pre><code>% perf record -g sh -c './write | ./read'
3.2GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)
[ perf record: Woken up 6 times to write data ]
[ perf record: Captured and wrote 2.851 MB perf.data (21201 samples) ]</code></pre>
<p>The <code>-g</code> instructs perf to record call graphs: this will allow us to take a top-down look at where time is being spent.</p>
<p>We can take a look at where time is spent using <code>perf report</code>. Here is a lightly redacted excerpt, breaking down where <code>write</code> spends its time:<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<pre><code>% perf report -g --symbol-filter=write
-   48.05%     0.05%  write    libc-2.33.so       [.] __GI___libc_write
   - 48.04% __GI___libc_write
      - 47.69% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 47.54% ksys_write
               - 47.40% vfs_write
                  - 47.23% new_sync_write
                     - pipe_write
                        + 24.08% copy_page_from_iter
                        + 11.76% __alloc_pages
                        + 4.32% schedule
                        + 2.98% __wake_up_common_lock
                          0.95% _raw_spin_lock_irq
                          0.74% alloc_pages
                          0.66% prepare_to_wait_event
</code></pre>
<p>47% of the time is spent in <code>pipe_write</code>, which is what <code>write</code> resolves to if we’re writing to a pipe. This is not surprising — we’re spending roughly half of the time writing, and the other half reading.</p>
<p>Within <code>pipe_write</code>, 3/4 of the time is spent copying or allocating pages (<code>copy_page_from_iter</code> and <code>__alloc_pages</code>). If we already have an idea of how communication between the kernel and userspace works this might make some sense. Regardless, to fully understand what’s happening we must first understand how pipes work.</p>
</div>

<h3 id="what-are-pipes-made-of">What are pipes made of? <a href="#what-are-pipes-made-of">#</a></h3>
<p>The data structure holding a pipe can be found in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/pipe_fs_i.h#L34"><code>include/linux/pipe_fs_i.h</code></a>, and the operations on it in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c"><code>fs/pipe.c</code></a>.</p>
<p>A Linux pipe is a <a href="https://en.wikipedia.org/wiki/Circular_buffer">ring buffer</a> holding references to pages where the data is written to and read from:</p>
<p><img src="https://mazzo.li/assets/images/fast-pipes-pipe-ring.png"></p>
<p>In the image above the ring buffer has 8 slots, but we might have more or less, the default being 16. Each page is 4KiB on x86-64, but might be of different sizes on other architectures. In total, this pipe can hold at most 32KiB of data. This is a key point: every pipe has an upper bound on the total amount of data it can hold before it’s full.</p>
<p>The shaded part of the diagram represents the current pipe data, the non-shaded part the empty space in the pipe.</p>
<p>Somewhat counterintuitively, <code>head</code> stores the write-end of the pipe. That is, writers will write into the buffer pointed at by <code>head</code>, and increase <code>head</code> accordingly if they need to move onto the next buffer. Within the write buffer, <code>len</code> stores how much we’ve written in it.</p>
<p>Conversely, <code>tail</code> stores the read-end of the pipe: readers will start consuming the pipe from there. <code>offset</code> indicates where to start reading from.</p>
<p>Note that <code>tail</code> can appear <em>after</em> <code>head</code>, like in the picture, since we’re working with a circular/ring buffer. Also note that some slots might be unused when we haven’t filled the pipe completely — the <code>NULL</code> cells in the middle. If the pipe is full (no <code>NULL</code>s and no free space in the pages), <code>write</code> will block. If the pipe is empty (all <code>NULL</code>s), <code>read</code> will block.</p>
<p>Here’s an abridged version of the C data structures in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/pipe_fs_i.h#L34"><code>pipe_fs_i.h</code></a>:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>struct</span> pipe_inode_info <span>{</span></span>
<span id="cb7-2">  <span>unsigned</span> <span>int</span> head<span>;</span></span>
<span id="cb7-3">  <span>unsigned</span> <span>int</span> tail<span>;</span></span>
<span id="cb7-4">  <span>struct</span> pipe_buffer <span>*</span>bufs<span>;</span></span>
<span id="cb7-5"><span>};</span></span>
<span id="cb7-6"></span>
<span id="cb7-7"><span>struct</span> pipe_buffer <span>{</span></span>
<span id="cb7-8">  <span>struct</span> page <span>*</span>page<span>;</span></span>
<span id="cb7-9">  <span>unsigned</span> <span>int</span> offset<span>,</span> len<span>;</span></span>
<span id="cb7-10"><span>};</span></span></code></pre></div>
<p>We’re omitting many fields here, and we’re not explainining what <code>struct page</code> contains yet, but this is the key data structure to understanding how reading and writing from a pipe happens.</p>
<h3 id="reading-and-writing-to-pipes">Reading and writing to pipes <a href="#reading-and-writing-to-pipes">#</a></h3>
<p>Let’s now go to <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L416">the definition of <code>pipe_write</code></a>, to try and make sense of the <code>perf</code> output shown before.</p>
<p>Here is a simplified explanation of how <code>pipe_write</code> works:</p>
<ol type="1">
<li>If the pipe is already full, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L561">wait for space</a> and restart;</li>
<li>If the buffer currently pointed at by <code>head</code> has space, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L457">fill that space first</a>;</li>
<li><a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L577">While there’s free slots</a>, and <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L542">there are remaining bytes to write</a>, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L496">allocate new pages</a> and <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L532">fill them</a>, updating <code>head</code>.</li>
</ol>
<div>
<figure>
<img src="https://mazzo.li/assets/images/write-to-pipe.svg" alt="What happens to a pipe when we write to it.">

</figure>
</div>
<div>
<p>The operations described above are protected by a lock, which <code>pipe_write</code> <a href="https://github.com/torvalds/linux/blob/2c85ebc57b3e1817b6ce1a6b703928e113a90442/fs/pipe.c#L416">acquires</a> and releases as necessary.</p>
<p><code>pipe_read</code> is the mirror image of <code>pipe_write</code>, except that we consume pages, free them when we’ve fully read them, and update <code>tail</code>.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>So, we now have a quite unpleasant picture of what is going on:</p>
<ul>
<li>We copy each page twice, once from user memory to the kernel, and back again from the kernel to user memory;</li>
<li>The copying is done one 4KiB page at a time, interspersed with other activity, such as the synchronization between read and write, and page allocation and freeing;</li>
<li>We are working with memory that might not be contiguous, since we’re constantly allocating new pages;</li>
<li>We’re acquiring and releasing the pipe lock.</li>
</ul>
<p>On this machine, sequential RAM reading clocks at around 16GiB/s:</p>
</div>

<pre><code>% sysbench memory --memory-block-size=1G --memory-oper=read --threads=1 run
...
102400.00 MiB transferred (15921.22 MiB/sec)</code></pre>
<p>Given all the fiddliness listed above, a 4x slowdown compared to single-threaded sequential RAM speed is not that surprising.</p>
<p>Tweaking the buffer size or the pipe size to reduce the amount of syscall and synchronization overhead, or tuning other parameters will not get us very far. Luckily, there is a way to get around the slowness of <code>write</code> and of <code>read</code> altogether.</p>
<h2 id="splicing">Splicing to the rescue <a href="#splicing">#</a></h2>
<p>This copying of buffers from user memory to the kernel and back is a frequent thorn in the side of people needing to do fast IO. One common solution is to just cut the kernel out of the picture and perform IO operations directly. For example we might interact directly with a network card and bypass the kernel for low-latency networking.</p>
<p>In general when we write to a socket, or a file, or in our case a pipe, we’re first writing to a buffer somewhere in the kernel, and then let the kernel do its work. In the case of pipes, the pipe <em>is</em> a series of buffers in the kernel. All this copying is undesirable if we’re in the business of performance.</p>
<div>
<p>Luckily, Linux includes system calls to speed things up when we want to move data to and from pipes, without copying. Specifically:</p>
<ul>
<li><a href="https://man7.org/linux/man-pages/man2/splice.2.html"><code>splice</code></a> moves data from a pipe to a file descriptor, and vice-versa.</li>
<li><a href="https://man7.org/linux/man-pages/man2/vmsplice.2.html"><code>vmsplice</code></a> moves data from user memory into a pipe.<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
</ul>
<p>Crucially, both operations work without copying anything.</p>
<p>Now that we know how pipes work, we can already vaguely imagine how the two operations function: they just “grab” an existing buffer from somewhere and put it into the pipe ring buffer, or the reverse, rather than allocating new pages as needed:</p>
<p><img src="https://mazzo.li/assets/images/vmsplice-intuition.svg"></p>
</div>

<p>We’ll soon see exactly how this works.</p>
<h3 id="splicing-in-practice">Splicing in practice <a href="#splicing-in-practice">#</a></h3>
<p>Let’s replace <code>write</code> with <code>vmsplice</code>. This is the signature for <code>vmsplice</code>:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>struct</span> iovec <span>{</span></span>
<span id="cb9-2">  <span>void</span>  <span>*</span>iov_base<span>;</span> <span>// Starting address</span></span>
<span id="cb9-3">  <span>size_t</span> iov_len<span>;</span>  <span>// Number of bytes</span></span>
<span id="cb9-4"><span>};</span></span>
<span id="cb9-5"></span>
<span id="cb9-6"><span>// Returns how much we've spliced into the pipe</span></span>
<span id="cb9-7"><span>ssize_t</span> vmsplice<span>(</span></span>
<span id="cb9-8">  <span>int</span> fd<span>,</span> <span>const</span> <span>struct</span> iovec <span>*</span>iov<span>,</span> <span>size_t</span> nr_segs<span>,</span> <span>unsigned</span> <span>int</span> flags</span>
<span id="cb9-9"><span>);</span></span></code></pre></div>
<div>
<p><code>fd</code> is the target pipe, <code>struct iovec *iov</code> is an array of buffers we’ll be moving to the pipe. Note that <code>vmsplice</code> returns how much was “spliced” into the pipe, which might not be the full amount, much like how <code>write</code> returns how much was written. Remember that pipes are bounded by how many slots they have in the ring buffer, and <code>vmsplice</code> is not exempt from this restriction.</p>
<p>We also need to be a bit careful when using <code>vmsplice</code>. Since the user memory is moved to the pipe without copying, we must ensure that the read-end consumes it before we can reuse the spliced buffer.</p>
<p>For this reason <code>fizzbuzz</code> uses a double buffering scheme, which works as follows:</p>
<ol type="1">
<li>Split the 256KiB buffer in two;</li>
<li>Set the pipe size to 128KiB, this will have the effect of setting the pipe ring buffer to have 128KiB/4KiB = 32 slots;</li>
<li>Alternate between writing to the first half-buffer and using <code>vmsplice</code> to move it to the pipe and doing the same with the other half.</li>
</ol>
<p>The fact that the pipe size is set to 128KiB, and that we wait for <code>vmsplice</code> to fully output one 128KiB buffer, ensures that by the time we’re done with one iteration of <code>vmsplice</code> we <em>know</em> that the the previous buffer has been fully read — otherwise we would not have been able to fully <code>vmsplice</code> the new 128KiB buffer into the 128KiB pipe.</p>
<p>Now, we’re not actually writing anything to the buffers, but we’ll keep the double buffering scheme since a similar scheme would be required for any program actually writing content.<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<p>Our write loop now looks something like this:</p>
</div>

<div id="cb10"><pre><code><span id="cb10-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb10-2">  <span>size_t</span> buf_size <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>18</span><span>;</span> <span>// 256KiB</span></span>
<span id="cb10-3">  <span>char</span><span>*</span> buf <span>=</span> malloc<span>(</span>buf_size<span>);</span></span>
<span id="cb10-4">  memset<span>((</span><span>void</span><span>*)</span>buf<span>,</span> <span>'X'</span><span>,</span> buf_size<span>);</span> <span>// output Xs</span></span>
<span id="cb10-5">  <span>char</span><span>*</span> bufs<span>[</span><span>2</span><span>]</span> <span>=</span> <span>{</span> buf<span>,</span> buf <span>+</span> buf_size<span>/</span><span>2</span> <span>};</span></span>
<span id="cb10-6">  <span>int</span> buf_ix <span>=</span> <span>0</span><span>;</span></span>
<span id="cb10-7">  <span>// Flip between the two buffers, splicing until we're done.</span></span>
<span id="cb10-8">  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span></span>
<span id="cb10-9">    <span>struct</span> iovec bufvec <span>=</span> <span>{</span></span>
<span id="cb10-10">      <span>.</span>iov_base <span>=</span> bufs<span>[</span>buf_ix<span>],</span></span>
<span id="cb10-11">      <span>.</span>iov_len <span>=</span> buf_size<span>/</span><span>2</span></span>
<span id="cb10-12">    <span>};</span></span>
<span id="cb10-13">    buf_ix <span>=</span> <span>(</span>buf_ix <span>+</span> <span>1</span><span>)</span> <span>%</span> <span>2</span><span>;</span></span>
<span id="cb10-14">    <span>while</span> <span>(</span>bufvec<span>.</span>iov_len <span>&gt;</span> <span>0</span><span>)</span> <span>{</span></span>
<span id="cb10-15">      <span>ssize_t</span> ret <span>=</span> vmsplice<span>(</span>STDOUT_FILENO<span>,</span> <span>&amp;</span>bufvec<span>,</span> <span>1</span><span>,</span> <span>0</span><span>);</span></span>
<span id="cb10-16">      bufvec<span>.</span>iov_base <span>=</span> <span>(</span><span>void</span><span>*)</span> <span>(((</span><span>char</span><span>*)</span> bufvec<span>.</span>iov_base<span>)</span> <span>+</span> ret<span>);</span></span>
<span id="cb10-17">      bufvec<span>.</span>iov_len <span>-=</span> ret<span>;</span></span>
<span id="cb10-18">    <span>}</span></span>
<span id="cb10-19">  <span>}</span></span>
<span id="cb10-20"><span>}</span></span></code></pre></div>
<p>Here are the results writing with <code>vmsplice</code>, rather than <code>write</code>:</p>
<pre><code>% ./write --write_with_vmsplice | ./read
12.7GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>This reduces by half the amount of copying we need to do, and already improves our througput more than threefold — to 12.7GiB/s. Changing the read end to use <code>splice</code>, we eliminate all copying, and get another 2.5x speedup:</p>
<pre><code>% ./write --write_with_vmsplice | ./read --read_with_splice
32.8GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<h2 id="paging">Fishing for pages <a href="#paging">#</a></h2>
<p>What next? Let’s ask <code>perf</code>:</p>
<pre><code>% perf record -g sh -c './write --write_with_vmsplice | ./read --read_with_splice'
33.4GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.305 MB perf.data (2413 samples) ]
% perf report --symbol-filter=vmsplice
-   49.59%     0.38%  write    libc-2.33.so       [.] vmsplice
   - 49.46% vmsplice
      - 45.17% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 44.30% __do_sys_vmsplice
               + 17.88% iov_iter_get_pages
               + 16.57% __mutex_lock.constprop.0
                 3.89% add_to_pipe
                 1.17% iov_iter_advance
                 0.82% mutex_unlock
                 0.75% pipe_lock
        2.01% __entry_text_start
        1.45% syscall_return_via_sysret</code></pre>
<div>
<p>The lion’s share of the time is taken by locking the pipe for writing (<code>__mutex_lock.constprop.0</code>), and by moving the pages into the pipe (<code>iov_iter_get_pages</code>). There isn’t so much we can do about the locking, but we <em>can</em> improve the performance of <code>iov_iter_get_pages</code>.</p>
<p>As the name suggests, <code>iov_iter_get_pages</code> turns the <code>struct iovec</code>s we feed into <code>vmsplice</code> into <code>struct page</code>s to put into the pipe. To understand what this function actually does, and how to speed it up, we must first take a detour into how the CPU and Linux organize pages.</p>
</div>
<h3 id="a-whirlwind-tour-of-paging">A whirlwind tour of paging <a href="#a-whirlwind-tour-of-paging">#</a></h3>
<div>
<p>As you might be aware of, processes do not refer to locations in RAM directly: instead, the are assigned <em>virtual</em> memory addresses, which get resolved to <em>physical</em> addresses. This abstraction is known as <a href="https://en.wikipedia.org/wiki/Virtual_memory"><em>virtual memory</em></a>, and has all sorts of advantages we won’t cover here — the most obvious being that it significantly simplifies running multiple processes competing for the same physical memory.</p>
<p>In any case, whenever we execute a program and we load/store from/to memory, the CPU needs to convert our virtual address to a physical address. Storing a mapping from every virtual address to every corresponding physical address would be impratical. Therefore memory is split up in uniformly sized chunks, called <em>pages</em>, and virtual pages are mapped to physical pages:<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p><img src="https://mazzo.li/assets/images/virtual-phsyical.svg"></p>
<p>There’s nothing special about 4KiB: each architecture picks a size, based on various tradeoffs — some of which we’ll soon explore.</p>
<p>To make this a bit more precise, let’s imagine allocating 10000 bytes using <code>malloc</code>:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>void</span><span>*</span> buf <span>=</span> malloc<span>(</span><span>10000</span><span>);</span></span>
<span id="cb14-2">printf<span>(</span><span>"</span><span>%p\n</span><span>"</span><span>,</span> buf<span>);</span>          <span>// 0x6f42430</span></span></code></pre></div>
</div>

<div>
<p>As we use them, our 10k bytes will look contiguous in virtual memory, but will be mapped to 3 not necessarily contiguous physical pages:<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p><img src="https://mazzo.li/assets/images/example-allocation.svg"></p>
</div>

<div>
<p>One of the tasks of the kernel is to manage this mapping, which is embodied in a data structure called the <em>page table</em>. The CPU specifies how the page table looks (since it needs to understand it), and the kernel manipulates it as needed. On x86-64 the page table is a 4-level, 512-way tree, which itself lives in memory.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a> Each node of this tree is (you guessed it!) 4KiB wide, with each entry within the node leading to the next level being 8 bytes (4KiB/8bytes = 512). The entries contain the address of the next node, along with other metadata.</p>
<p>We have one page table per process — or in other words, each process has a reserved virtual address space. When the kernel context-switches to a process, it sets the special register CR3 to the <em>physical</em> address of the root of this tree.<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a> Then whenever a virtual address needs to be converted to a physical address, the CPU splits up the address in sections, and uses them to walk this tree and compute the physical address.</p>
<p>To make these concepts less abstract, here’s a visual depiction of how the virtual address <code>0x0000f2705af953c0</code> might be resolved to a physical address:</p>
<p><img src="https://mazzo.li/assets/images/virtual-address-resolution.svg"></p>
</div>

<div>
<p>The search starts from the first level, called the “page global directory”, or PGD, the physical location of which is stored in CR3. The first 16 bits of the address are unused.<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a> We use the next 9 bits the PGD entry, and traverse down to the second level, “page upper directory”, or PUD. The next 9 bits are used to select an entry from the PUD. The process repeats for the next two levels, PMD (“page middle directory”), and PTE (“page table entry”). The PTE tells where the actual physical page we’re looking for is, and then we use the last 12 bits to find the offset inside the page.</p>
<p>The sparse structure of the page table allows the mapping to be gradually built up as new pages are needed. Whenever a process needs memory, the page table will be updated with a new entry by the kernel.</p>
</div>

<h3 id="the-role-of-struct-page">The role of <code>struct page</code> <a href="#the-role-of-struct-page">#</a></h3>
<div>
<p>The <code>struct page</code> data structure is a key piece of this machinery: it is what the kernel uses to refer to a single <em>physical</em> page, storing its physical address and all sorts of other metadata about it.<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a> For instance we can get a <code>struct page</code> from the information contained in the PTE (the last level of the page table described above). In general it is used pervasively in all code handling page-related matters.</p>
<p>In the case of pipes, <code>struct page</code> is used to hold their data in the ring buffer, as we’re already seen:</p>
<div id="cb15"><pre><code><span id="cb15-1"><span>struct</span> pipe_inode_info <span>{</span></span>
<span id="cb15-2">  <span>unsigned</span> <span>int</span> head<span>;</span></span>
<span id="cb15-3">  <span>unsigned</span> <span>int</span> tail<span>;</span></span>
<span id="cb15-4">  <span>struct</span> pipe_buffer <span>*</span>bufs<span>;</span></span>
<span id="cb15-5"><span>};</span></span>
<span id="cb15-6"></span>
<span id="cb15-7"><span>struct</span> pipe_buffer <span>{</span></span>
<span id="cb15-8">  <span>struct</span> page <span>*</span>page<span>;</span></span>
<span id="cb15-9">  <span>unsigned</span> <span>int</span> offset<span>,</span> len<span>;</span></span>
<span id="cb15-10"><span>};</span></span></code></pre></div>
</div>

<p>However, <code>vmsplice</code> accepts <em>virtual</em> memory as input, while <code>struct page</code> refers to <em>physical</em> memory directly.</p>
<p>Therefore we need turn arbitrary chunks of virtual memory into a bunch of <code>struct page</code>s. This is exactly what <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/lib/iov_iter.c#L1518"><code>iov_iter_get_pages</code></a> does, and where we’re spending half of our time:</p>
<div id="cb16"><pre><code><span id="cb16-1"><span>ssize_t</span> iov_iter_get_pages<span>(</span></span>
<span id="cb16-2">  <span>struct</span> iov_iter <span>*</span>i<span>,</span>  <span>// input: a sized buffer in virtual memory</span></span>
<span id="cb16-3">  <span>struct</span> page <span>**</span>pages<span>,</span> <span>// output: the list of pages which back the input buffers</span></span>
<span id="cb16-4">  <span>size_t</span> maxsize<span>,</span>      <span>// maximum number of bytes to get</span></span>
<span id="cb16-5">  <span>unsigned</span> maxpages<span>,</span>   <span>// maximum number of pages to get</span></span>
<span id="cb16-6">  <span>size_t</span> <span>*</span>start        <span>// offset into first page, if the input buffer wasn't page-aligned</span></span>
<span id="cb16-7"><span>);</span></span></code></pre></div>
<p><code>struct iov_iter</code> is a Linux kernel data structure representing various ways of walking through chunks of memory, including <code>struct iovec</code>. In our case, it will point to a 128KiB buffer. <code>vmsplice</code> will use <code>iov_iter_get_pages</code> to turn the input buffer into a bunch of <code>struct page</code>s, and hold on to them. Now that you know how paging works, you might vaguely imagine how <code>iov_iter_get_pages</code> works as well, but we’ll explain it in detail in the next section.</p>
<p>We’ve rapidly gone through a lot of new concepts, so to recap:</p>
<ul>
<li>Modern CPUs use virtual memory for their processes;</li>
<li>Memory is organized in regularly-sized pages;</li>
<li>The CPU translates virtual addresses into physical addresses using a page table mapping virtual pages to physical pages;</li>
<li>The kernel adds and removes entries to the page table as necessary;</li>
<li>Pipes are made out of references to physical pages, so <code>vmsplice</code> must convert virtual memory ranges into physical pages, and hold on to them.</li>
</ul>
<h3 id="the-cost-of-getting-pages">The cost of getting pages <a href="#the-cost-of-getting-pages">#</a></h3>
<div>
<p>The time spent in <code>iov_iter_get_pages</code> is really entirely spent in another function, <code>get_user_pages_fast</code>:</p>
<pre><code>% perf report -g --symbol-filter=iov_iter_get_pages
-   17.08%     0.17%  write    [kernel.kallsyms]  [k] iov_iter_get_pages
   - 16.91% iov_iter_get_pages
      - 16.88% internal_get_user_pages_fast
           11.22% try_grab_compound_head
</code></pre>
<p><a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/mm/gup.c#L2944"><code>get_user_pages_fast</code></a> is a more bare-bones version of <code>iov_iter_get_pages</code>:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>int</span> get_user_pages_fast<span>(</span></span>
<span id="cb18-2">  <span>// virtual address, page aligned</span></span>
<span id="cb18-3">  <span>unsigned</span> <span>long</span> start<span>,</span></span>
<span id="cb18-4">  <span>// number of pages to retrieve</span></span>
<span id="cb18-5">  <span>int</span> nr_pages<span>,</span></span>
<span id="cb18-6">  <span>// flags, the meaning of which we won't get into</span></span>
<span id="cb18-7">  <span>unsigned</span> <span>int</span> gup_flags<span>,</span></span>
<span id="cb18-8">  <span>// output physical pages</span></span>
<span id="cb18-9">  <span>struct</span> page <span>**</span>pages</span>
<span id="cb18-10"><span>)</span></span></code></pre></div>
<p>Here “user” (as opposed to “kernel”) refers to the fact that we’re turning virtual pages into references to physical pages.</p>
<p>To get our <code>struct page</code>s, <code>get_user_pages_fast</code> does exactly what the CPU would do, but in software: it walks the page table to collect all the physical pages, storing the results in <code>struct page</code>s. In our case, we have a 128KiB buffer, and 4KiB pages, so we’ll have <code>nr_pages = 32</code>.<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a> <code>get_user_pages_fast</code> will need to walk the page table tree collecting 32 leaves, and storing the result in 32 <code>struct page</code>s.</p>
<p><code>get_user_pages_fast</code> also needs to make sure that the physical page is not repurposed until the caller doesn’t need it anymore. This is achieved in the kernel using a reference count <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/mm_types.h#L187">stored in <code>struct page</code></a>, which is used to know when a physical page can be released and repurposed in the future. The caller of <code>get_user_pages_fast</code> must, at some point, release the pages again with <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/mm.h#L1222"><code>put_page</code></a>, which will decrease the reference count.</p>
<p>Finally, <code>get_user_pages_fast</code> behaves differently depending on whether virtual addresses are already in the page table. This is where the <code>_fast</code> suffix comes from: the kernel will first try to get an already existing page table entry and corresponding <code>struct page</code> by just walking the page table, which is relatively cheap, and fall back to producing a <code>struct page</code> by other, more expensive means otherwise. The fact that we <code>memset</code> the memory at the beginning will ensure that we never end up in the “slow” path of <code>get_user_pages_fast</code>, since the page table entries will be created as our buffer is filled with <code>'X'</code>s.<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p>Note that the <code>get_user_pages</code> family of functions is not only useful for pipes — in fact, it is central in many drivers. A typical use is related to the kernel bypass we mentioned: a driver for a network card might use it to turn some user memory region into a physical page, then communicate the physical page location to the network card, and have the network card interact directly with that memory region without kernel involvement.</p>
</div>

<h3 id="huge-pages">Huge pages <a href="#huge-pages">#</a></h3>
<div>
<p>Up to now we’ve presented pages as always being of the same size — 4KiB on x86-64. However, many CPU architectures, including x86-64, include larger page sizes. In the case of x86-64, we not only have 4KiB pages (the “standard” size), but also 2MiB and even 1GiB pages (“huge” pages). In the rest of the post we’ll only deal with 2MiB huge pages, since 1GiB pages are fairly uncommon, and overkill for our task anyway.</p>
<div>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Smallest page size</th>
<th>Larger page sizes</th>
</tr>
</thead>
<tbody>
<tr>
<td>x86</td>
<td>4KiB</td>
<td>2MiB, 4MiB</td>
</tr>
<tr>
<td>x86-64</td>
<td>4KiB</td>
<td>2MiB, 1GiB<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a></td>
</tr>
<tr>
<td>ARMv7</td>
<td>4KiB</td>
<td>64KiB, 1MiB, 16MiB</td>
</tr>
<tr>
<td>ARMv8</td>
<td>4KiB</td>
<td>16KiB, 64KiB</td>
</tr>
<tr>
<td>RISCV32</td>
<td>4KiB</td>
<td>4MiB</td>
</tr>
<tr>
<td>RISCV64</td>
<td>4KiB</td>
<td>2MiB, 1GiB, 512GiB, 256 TiB</td>
</tr>
<tr>
<td>Power ISA</td>
<td>8KiB</td>
<td>64 KiB, 16 MiB, 16 GiB</td>
</tr>
</tbody>
</table>
<p><small>Page sizes available on architectures commonly used today, from <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)#Multiple_page_sizes">Wikipedia</a>.</small></p>
</div>
<p>The main advantage of huge pages is that bookkeeping is cheaper, since there’s fewer of them needed to cover the same amount of memory. Moreover other operations are cheaper too, such as resolving a virtual address to a physical address, since one level less of page table is needed: instead of having a 12-bit offset into the page, we’ll have a 21-bit offset, and one less page table level.</p>
</div>

<div>
<p>This relieves pressure on the parts of the CPUs that handle this conversion, leading to performance improvements in many circumstances.<a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> However, in our case, the pressure is not on the hardware that walks the page table, but on its software counterpart which runs in the kernel.</p>
<p>On Linux, we can allocate a 2MiB huge page <a href="https://mazzo.li/posts/check-huge-page.html">in a variety of ways</a>, such as by allocating memory aligned to 2MiB and then using <code>madvise</code> to tell the kernel to use huge pages for the provided buffer:</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>void</span><span>*</span> buf <span>=</span> aligned_alloc<span>(</span><span>1</span> <span>&lt;&lt;</span> <span>21</span><span>,</span> size<span>);</span></span>
<span id="cb20-2">madvise<span>(</span>buf<span>,</span> size<span>,</span> MADV_HUGEPAGE<span>)</span></span></code></pre></div>
<p>Switching to huge pages in our program yields another ~50% improvement:</p>
<pre><code>% ./write --write_with_vmsplice --huge_page | ./read --read_with_splice
51.0GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
</div>

<div>
<p>However, the reason for the improvements is not totally obvious. Naively, we might think that by using huge pages <code>struct page</code> will just refer to a 2MiB page, rather than 4KiB.</p>
<p>Sadly this is <em>not</em> the case: the kernel code assumes everywhere that a <code>struct page</code> refers to a page of the “standard” size for the current architecture. The way this works for huge pages (and in general for what Linux calls “compound pages”) is that a “head” <code>struct page</code> contains the actual information about the backing physical page, with successive “tail” pages just containing a pointer to the head page.</p>
<p>So to represent 2MiB huge page we’ll have 1 “head” <code>struct page</code>, and up to 511 “tail” <code>struct page</code>s. Or in the case of our 128KiB buffer, 31 tail <code>struct page</code>s:<a href="#fn22" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<p><img src="https://mazzo.li/assets/images/head-tail-pages.svg"></p>
<p>Even if we need all these <code>struct page</code>s, the code generating it ends up significantly faster. Instead of traversing the page table multiple times, once the first entry is found, the following <code>struct page</code>s can be <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/mm/gup.c#L2457">generated in a simple loop</a>. Hence the performance improvement!</p>
</div>

<h2 id="busy-loop">Busy looping <a href="#busy-loop">#</a></h2>
<p>We’re almost done, I promise! Let’s look at <code>perf</code> output once again:</p>
<pre><code>-   46.91%     0.38%  write    libc-2.33.so       [.] vmsplice
   - 46.84% vmsplice
      - 43.15% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 41.80% __do_sys_vmsplice
               + 14.90% wait_for_space
               + 8.27% __wake_up_common_lock
                 4.40% add_to_pipe
               + 4.24% iov_iter_get_pages
               + 3.92% __mutex_lock.constprop.0
                 1.81% iov_iter_advance
               + 0.55% import_iovec
            + 0.76% syscall_exit_to_user_mode
        1.54% syscall_return_via_sysret
        1.49% __entry_text_start
</code></pre>
<p>We’re now spending a significant amount of time waiting for the pipe to be writeable (<code>wait_for_space</code>), and waking up readers which were waiting for the pipe to have content (<code>__wake_up_common_lock</code>).</p>
<p>To sidestep these synchronization costs, we can ask <code>vmsplice</code> to return if the pipe cannot be written to, and busy loop until it is — and the same when reading with <code>splice</code>:</p>
<div id="cb23"><pre><code><span id="cb23-1"><span>...</span></span>
<span id="cb23-2"><span>// SPLICE_F_NONBLOCK will cause `vmsplice` to return immediately</span></span>
<span id="cb23-3"><span>// if we can't write to the pipe, returning EAGAIN</span></span>
<span id="cb23-4"><span>ssize_t</span> ret <span>=</span> vmsplice<span>(</span>STDOUT_FILENO<span>,</span> <span>&amp;</span>bufvec<span>,</span> <span>1</span><span>,</span> SPLICE_F_NONBLOCK<span>);</span></span>
<span id="cb23-5"><span>if</span> <span>(</span>ret <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> errno <span>==</span> EAGAIN<span>)</span> <span>{</span></span>
<span id="cb23-6">  <span>continue</span><span>;</span> <span>// busy loop if not ready to write</span></span>
<span id="cb23-7"><span>}</span></span>
<span id="cb23-8"><span>...</span></span></code></pre></div>
<p>By busy looping we get another 25% performance increase:</p>
<pre><code>% ./write --write_with_vmsplice --huge_page --busy_loop | ./read --read_with_splice --busy_loop
62.5GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>Obviously busy looping comes at the cost of fully occupying a CPU core waiting for <code>vmsplice</code> to be ready. But often this compromise is worth it, and in fact it is a common pattern for high-performance server applications: we trade off possibly wasteful CPU utilization for better latency and/or throughput.</p>
<p>In our case, this concludes our optimization journey for our little synthetic benchmark, from 3.5GiB/s to 65GiB/s.</p>
<h2 id="closing-thoughts">Closing thoughts <a href="#closing-thoughts">#</a></h2>
<p>We’ve systematically improved the performance of our program by looking at the <code>perf</code> output and the Linux source. Pipes and splicing in particular aren’t really hot topics when it comes to high-performance programming, but the themes we’ve touched upon are: zero-copy operations, ring buffers, paging &amp; virtual memory, synchronization overhead.</p>
<p>There are some details and interesting topics I left out, but this blog post was already spiraling out of control and becoming too long:</p>
<ul>
<li><p>In the actual code, the buffers are allocated separatedly, to reduce page table contention by placing them in different page table entries (something that the FizzBuzz program also does).</p>
<p>Remember that when a page table entry is taken with <code>get_user_pages</code>, its refcount is increased, and decreased on <code>put_page</code>. If we use two page table entries for the two buffers, rather than one page table entry for both of them, we have less contention when modifying the refcount.</p></li>
<li><p>The tests are ran by pinning the <code>./write</code> and <code>./read</code> processes to two cores with <code>taskset</code>.</p></li>
<li><p>The code in the repo contains many other options I played with, but did not end up talking about since they were irrelevant or not interesting enough.</p></li>
<li><p>The repo also contains <a href="https://github.com/bitonic/pipes-speed-test/blob/master/get-user-pages.cpp">a synthetic benchmark</a> for <code>get_user_pages_fast</code>, which can be used to measure exactly how much slower it runs with or without huge pages.</p></li>
<li><p>Splicing in general is a slightly dubious/<a href="https://dirtypipe.cm4all.com/">dangerous</a> concept, <a href="https://lwn.net/Articles/896267/">which continues to annoy</a> to kernel developers.</p></li>
</ul>
<p>Please let me know if this post was helpful, interesting, or unclear!</p>
<h2 id="acknowledgements">Acknowledgements <a href="#acknowledgements">#</a></h2>
<p>Many thanks to <a href="https://scvalex.net/">Alexandru Scvorţov</a>, Max Staudt, Alex Appetiti, Alex Sayers, Stephen Lavelle, Peter Cawley, and Niklas Hambüchen for reviewing drafts of this post. Max Staudt also helped me understand some subtleties of <code>get_user_pages</code>.</p>






</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LibRedirect – Redirects popular sites to alternative privacy-friendly frontends (313 pts)]]></title>
            <link>https://libredirect.github.io</link>
            <guid>44344246</guid>
            <pubDate>Sun, 22 Jun 2025 06:07:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://libredirect.github.io">https://libredirect.github.io</a>, See on <a href="https://news.ycombinator.com/item?id=44344246">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
    <div id="logo"> <p><img src="https://libredirect.github.io/img/icon.svg" width="160" height="160" alt="LibRedirect icon"></p>
    </div>
    
    <h3>A web extension that redirects YouTube, Instagram, Reddit, TikTok and other websites to
      alternative
      privacy-friendly frontends.</h3>
    <div id="description">
        <ul>
          <li>
            YouTube <span>→</span>
            <a href="https://invidious.io/">Invidious</a>,
            <a href="https://materialio.us/">Materialious</a>,
            <a href="https://github.com/TeamPiped/Piped">Piped</a>,
            <a href="https://github.com/mmjee/Piped-Material">Piped-Material</a>,
            <a href="https://codeberg.org/ashley/poke">Poke</a>,
            <a href="https://sr.ht/~cadence/tube">CloudTube</a>,
            <a href="https://github.com/lighttube-org/LightTube">LightTube</a>,
            <a href="https://github.com/migalmoreno/tubo">Tubo</a>,
            <a href="https://github.com/FreeTubeApp/FreeTube">FreeTube</a>,
            <a href="https://github.com/yattee/yattee">Yattee</a>,
            <a href="https://github.com/MarmadileManteater/FreeTubeCordova">FreeTube PWA</a>,
            <a href="https://github.com/ViewTube/viewtube">ViewTube</a>,
            <a href="https://github.com/n-ce/ytify/">ytify</a>
          </li>
          <li>
            YT Music <span>→</span>
            <a href="https://codeberg.org/Hyperpipe/Hyperpipe">Hyperpipe</a>,
            <a href="https://invidious.io/">Invidious</a>,
            <a href="https://github.com/FreeTubeApp/FreeTube">FreeTube</a>
          </li>
          <li>
            Twitter <span>→</span>
            <a href="https://github.com/zedeus/nitter">Nitter</a>
          </li>
          <li>
            ChatGPT <span>→</span>
            <a href="https://duckduckgo.com/duckduckgo-help-pages/aichat/">DuckDuckGo AI Chat</a>
          </li>
          <li>
            Bluesky <span>→</span>
            <a href="https://github.com/badlogic/skyview">Skyview</a>
          </li>
          <li>
            Reddit <span>→</span>
            <a href="https://github.com/spikecodes/libreddit">Libreddit</a>,
            <a href="https://github.com/redlib-org/redlib">Redlib</a>,
            <a href="https://codeberg.org/teddit/teddit">Teddit</a>,
            <a href="https://github.com/corenting/eddrit">Eddrit</a>,
            <a href="https://github.com/burhan-syed/troddit">Troddit</a>
          </li>
          <li>
            Tumblr <span>→</span>
            <a href="https://github.com/syeopite/priviblur">Priviblur</a>
          </li>
          <li>
            Twitch <span>→</span>
            <a href="https://codeberg.org/dragongoose/safetwitch">SafeTwitch</a>,
            <a href="https://codeberg.org/CloudyyUw/twineo">Twineo</a>
          </li>
          <li>
            TikTok <span>→</span>
            <a href="https://github.com/pablouser1/ProxiTok">ProxiTok</a>,
            <a href="https://github.com/MarsHeer/offtiktok">Offtiktok</a>
          </li>
          <li>
            Instagram <span>→</span>
            <a href="https://codeberg.org/ThePenguinDev/Proxigram">Proxigram</a>
          </li>
          <li>
            IMDb <span>→</span>
            <a href="https://github.com/zyachel/libremdb">libremdb</a>
          </li>
          <li>
            Bilibili <span>→</span>
            <a href="https://0xacab.org/johnxina/mikuinvidious">MikuInvidious</a>
          </li>
          <li>
            Pixiv <span>→</span>
            <a href="https://codeberg.org/VnPower/pixivfe">PixivFE</a>,
            <a href="https://codeberg.org/Peaksol/LiteXiv">LiteXiv</a>,
            <a href="https://codeberg.org/vixipy/Vixipy">Vixipy</a>
          </li>
          <li>
            Fandom <span>→</span>
            <a href="https://breezewiki.com/">BreezeWiki</a>
          </li>
          <li>
            Imgur <span>→</span>
            <a href="https://codeberg.org/video-prize-ranch/rimgo">rimgo</a>
          </li>
          <li>
            Pinterest <span>→</span>
            <a href="https://github.com/Ahwxorg/Binternet">Binternet</a>,
            <a href="https://codeberg.org/thirtysix/painterest">Painterest</a>
          </li>
          <li>
            SoundCloud <span>→</span>
            <a href="https://github.com/migalmoreno/tubo">Tubo</a>,
            <a href="https://git.maid.zone/stuff/soundcloak">soundcloak</a>
          </li>
          <li>
            Bandcamp <span>→</span>
            <a href="https://forgejo.sny.sh/sun/Tent">Tent</a>
          </li>
          <li>
            Tekstowo.pl <span>→</span>
            <a href="https://github.com/Davilarek/TekstoLibre">TekstoLibre</a>
          </li>
          <li>
            Genius <span>→</span>
            <a href="https://github.com/rramiachraf/dumb">Dumb</a>,
            <a href="https://github.com/Insprill/intellectual">Intellectual</a>
          </li>
          <li>
            Medium <span>→</span>
            <a href="https://sr.ht/~edwardloveall/Scribe">Scribe</a>,
            <a href="https://github.com/realaravinth/libmedium">LibMedium</a>,
            <a href="https://git.private.coffee/PrivateCoffee/small">Small</a>
          </li>
          <li>
            Quora <span>→</span>
            <a href="https://github.com/zyachel/quetre">Quetre</a>
          </li>
          <li>
            GitHub <span>→</span>
            <a href="https://codeberg.org/gothub/gothub">Gothub</a>
          </li>
          <li>
            GitLab <span>→</span>
            <a href="https://git.vitali64.duckdns.org/utils/laboratory.git/about/">Laboratory</a>
          </li>
          <li>
            Stack Overflow <span>→</span>
            <a href="https://github.com/httpjamesm/AnonymousOverflow">AnonymousOverflow</a>
          </li>
          <li>
            Reuters <span>→</span>
            <a href="https://github.com/HookedBehemoth/neuters">Neuters</a>
          </li>
          <li>
            Snopes <span>→</span>
            <a href="https://git.vern.cc/cobra/Suds">Suds</a>
          </li>
          <li>
            iFunny <span>→</span>
            <a href="https://git.vern.cc/cobra/UNfunny">UNfunny</a>
          </li>
          <li>
            Tenor <span>→</span>
            <a href="https://git.vern.cc/cobra/Soprano">Soprano</a>
          </li>
          <li>
            KnowYourMeme <span>→</span>
            <a href="https://git.vern.cc/cobra/MeMe">MeMe</a>
          </li>
          <li>
            Urban Dictionary <span>→</span>
            <a href="https://codeberg.org/zortazert/rural-dictionary">Rural Dictionary</a>
          </li>
          <li>
            Goodreads <span>→</span>
            <a href="https://github.com/nesaku/BiblioReads">BiblioReads</a>
          </li>
          <li>
            Wolfram Alpha <span>→</span>
            <a href="https://git.disroot.org/wolfree">WolfreeAlpha</a>
          </li>
          <li>
            Instructables <span>→</span>
            <a href="https://github.com/PrivateCoffee/structables">Structables</a>,
            <a href="https://git.vern.cc/cobra/Destructables">Destructables</a>,
            <a href="https://indestructables.codeberg.page/">Indestructables</a>
          </li>
          <li>
            Wikipedia <span>→</span>
            <a href="https://wikiless.org/">Wikiless</a>,
            <a href="https://git.private.coffee/privatecoffee/wikimore">Wikimore</a>
          </li>
          <li>
            Wayback Machine <span>→</span>
            <a href="https://github.com/ticky/wayback-classic">Wayback Classic</a>
          </li>
          <li>
            Pastebin <span>→</span>
            <a href="https://github.com/Dragynfruit/pasted">Pasted</a>
          </li>
          <li>
            Search <span>→</span>
            <a href="https://github.com/searxng/searxng">SearXNG</a>,
            <a href="https://searx.github.io/searx/">SearX</a>,
            <a href="https://benbusby.com/projects/whoogle-search/">Whoogle</a>,
            <a href="https://github.com/Ahwxorg/librey/">LibreY</a>,
            <a href="https://git.lolcat.ca/lolcat/4get">4get</a>
          </li>
          <li>
            Translate <span>→</span>
            <a href="https://codeberg.org/ManeraKai/simplytranslate">SimplyTranslate</a>,
            <a href="https://codeberg.org/aryak/mozhi">Mozhi</a>,
            <a href="https://github.com/LibreTranslate/LibreTranslate">LibreTranslate</a>,
            <a href="https://codeberg.org/gospodin/translite">Translite</a>
          </li>
          <li>
            Maps <span>→</span>
            <a href="https://www.openstreetmap.org/">OpenStreetMap</a>
          </li>
          <li>
            Meet <span>→</span>
            <a href="https://jitsi.org/">Jitsi</a>
          </li>
          <li>
            Send Files <span>→</span>
            <a href="https://gitlab.com/timvisee/send">Send</a>
          </li>
          <li>
            Paste Text <span>→</span>
            <a href="https://privatebin.info/">PrivateBin</a>,
            <a href="https://github.com/Dragynfruit/pasted">Pasted</a>,
            <a href="https://github.com/lus/pasty">Pasty</a>
          </li>
          <li>
            Ultimate Guitar <span>→</span>
            <a href="https://github.com/kmille/freetar">Freetar</a>,
            <a href="https://github.com/BenoitBellegarde/UltimateTab">Ultimate Tab</a>
          </li>
          <li>
            Baidu Tieba <span>→</span>
            <a href="https://0xacab.org/johnxina/rat">Rat Aint Tieba</a>
          </li>
          <li>
            Threads <span>→</span>
            <a href="https://git.sr.ht/~nixgoat/shoelace">Shoelace</a>
          </li>
          <li>
            DeviantArt <span>→</span>
            <a href="https://codeberg.org/skunky/skunkyart">SkunkyArt</a>
          </li>
          <li>
            GeeksforGeeks <span>→</span>
            <a href="https://git.vern.cc/cobra/NerdsforNerds">NerdsforNerds</a>,
            <a href="https://git.private.coffee/PrivateCoffee/ducksforducks">Ducks for Ducks</a>
          </li>
          <li>
            Coub <span>→</span>
            <a href="https://codeberg.org/gospodin/koub">Koub</a>
          </li>
          <li>
            Chefkoch <span>→</span>
            <a href="https://github.com/NoUmlautsAllowed/gocook">GoCook</a>
          </li>
        </ul>
      </div>

    <p><a rel="me" href="https://fosstodon.org/@libredirect">Mastodon</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TPU (Tensor Processing Unit) Deep Dive (320 pts)]]></title>
            <link>https://henryhmko.github.io/posts/tpu/tpu.html</link>
            <guid>44342977</guid>
            <pubDate>Sun, 22 Jun 2025 02:51:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://henryhmko.github.io/posts/tpu/tpu.html">https://henryhmko.github.io/posts/tpu/tpu.html</a>, See on <a href="https://news.ycombinator.com/item?id=44342977">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I've been working with TPUs a lot recently and it's fun to see how they had such different design philosophies compared to GPUs.</p>

        <p>The main strongpoint for TPUs is in their scalability. This is achieved through a co-design of both the hardware side (e.g. energy efficiency and modularity) and the software side (e.g. XLA compiler).</p>

        <br>
        <h2><span>Background</span></h2>
        <p>To give a brief tldr on TPUs, it's <mark>Google's ASIC that focuses on two factors: extreme matmul throughput + energy efficiency.</mark></p>

        <p>Their origins go back to Google in 2006, when they were first evaluating whether they should implement either GPUs, FPGAs, or custom ASICs. Back then there were only a few applications that necessitated specialized hardware and they decided those needs could be met by bringing in excess CPU compute from their large datacenters. But this changed in 2013 when Google's voice search feature ran on neural networks and internal projections speculated that they would need much more compute if it took off.</p>

        <p>Fast forward to today and TPUs power the majority of Google's AI services. Of course, that includes training and inference of Gemini or Veo, but also deploying their recommendation models (DLRMs).</p>

        <p>Let's dive in and look at TPU internals from the bottom up.</p>

        <br>
        <h2>TPU Single-Chip Level</h2>
        <p>I'll focus my diagrams to TPUv4, but this layout is more or less applicable to latest generation TPUs (e.g. TPUv6p "Trillium"; TPUv7 "Ironwood's details aren't released as of writing in June, 2025).</p>

        <p>Here's the layout of a single TPUv4 chip:</p>

        <!-- <figure style="text-align: center;">
            <img src="images/single_chip.png" alt="chip diagram" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">TPU Single Chip + TensorCore</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/single_chip.png" alt="chip diagram">
          <figcaption>TPU Single Chip + TensorCore</figcaption>
      </figure>
        


        <p>In each chip, there's two TPU TensorCores, which are responsible for our compute. (Note: inference-specialized TPUs have only one TensorCore). Both TensorCores have shared memory units: CMEM(128MiB) and HBM(32GiB).</p>

        <p>And within each TensorCore, there lies our compute units and smaller memory buffers:</p>

        <ol>
                <h3>1. Matrix Multiply Unit (MXU)</h3>
                <ul>
                  <li>&nbsp; &nbsp; &nbsp;- This is the key component of the TensorCore and is a 128x128 systolic array.</li>
                  <li>&nbsp; &nbsp; &nbsp;- We'll cover systolic arrays below.</li>
                </ul>

                <h3>2. Vector Unit (VPU)</h3>
                <ul>
                  <li>&nbsp; &nbsp; &nbsp;- General elementwise operations (e.g. ReLU, pointwise add/mul, reductions)</li>
                </ul>

                <h3>3. Vector Memory (VMEM; 32MiB)</h3>
                <ul>
                  <li>&nbsp; &nbsp; &nbsp;- Memory buffer. Data from HBM is copied into the VMEM before the TensorCore can do any computations.</li>
                </ul>

                <h3>4. Scalar Unit + Scalar Memory (SMEM; 10MiB)</h3>
                <ul>
                  <li>&nbsp; &nbsp; &nbsp;- Tell the VPU and MXU what to do.</li>
                  <li>&nbsp; &nbsp; &nbsp;- Manages control flow, scalar operations, and memory address generation.</li>
                </ul>
        </ol>

        
        <p>If you're coming from NVIDIA GPUs, there's some initial observations that might throw you off:</p>
        <ol>
            <li>On-chip memory units (CMEM, VMEM, SMEM) on TPUs are much larger than L1, L2 caches on GPUs.</li>
            <li>HBM on TPUs are also much smaller than HBM on GPUs.</li>
            <li>There seems to be a lot less "cores" responsible for the computation.</li>
        </ol>
        

        <p>This is the complete opposite of GPUs where they have smaller L1, L2 caches (256KB and 50MB, respectively for H100), larger HBM (80GB for H100), and tens of thousands of cores.</p>

        <p>Before we go any further, recall that TPUs are capable of extremely high throughput just like GPUs. TPU v5p can achieve 500 TFLOPs/sec per chip and with a full pod of 8960 chips we can achieve approximately 4.45 ExaFLOPs/sec. The newest "Ironwood" TPUv7 is said to reach up to 42.5 ExaFLOPS/sec per pod (9216 chips).</p>

        <p>To understand how TPUs achieve this, we need to understand their design philosophy.</p>

        <br>
        <h2>TPU Design Philosophy</h2>

        <p>TPUs achieve amazing throughput and energy efficiency by relying on two large pillars and a key assumption: systolic arrays + pipelining, Ahead-of-Time (AoT) compilation, and the assumption that most operations can be expressed in a way that maps well to systolic arrays. Fortunately, in our modern DL era, matmuls comprise the bulk of computation, which are fit for systolic arrays.</p>

        <br>
        <h2>TPU Design choice #1: Systolic Arrays + Pipelining</h2>

        <h3><span>Q. What is a Systolic Array?</span></h3>

        <p>Systolic array is a hardware design architecture consisting of a grid of interconnected processing elements (PE). Each PE performs a small computation (e.g. multiply and accumulate) and passes the results to neighboring PEs.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/systolic_arr.png" alt="systolic array diagram" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/systolic_arr.png" alt="systolic array diagram">
      </figure>
        

        <p>The benefit of such a design is that once data is passed into a systolic array, additional control logic on how data should be processed is not required. Also, when given a large enough systolic array, there's no memory read/writes other than the input and output.</p>

        <p>Due to their rigid organization, systolic arrays can only handle operations with fixed dataflow patterns, but fortunately matrix multiplication and convolutions fit perfectly in this regime.</p>

        <p>Moreover, there's clear opportunities for pipelining to overlap computation with data movements. Here's a diagram below for a pipelined pointwise operation on a TPU.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/pipeline_pointwise.gif" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Pipelined Pointwise Operation (from "How to Scale Your Model" <a href="#ref4">[4]</a>)</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/pipeline_pointwise.gif" alt="TPU data movement visualized">
          <figcaption>Pipelined Pointwise Operation (from "How to Scale Your Model" <a href="#ref4">[4]</a>)</figcaption>
      </figure>
        <h3><span>Aside: Downsides of Systolic Arrays - Sparsity</span></h3>

        <p>You can see how systolic arrays love dense matrices (i.e. When every PE is active nearly every cycle). However, the downside is that there's no performance improvements for sparse matrices of the same size: the same number of cycles will have to be performed where PEs are still doing work even for zero-valued elements.</p>

        <p><mark>Dealing with this systematic limitation of systolic arrays will become more important if the DL community favors more irregular sparsity (e.g. MoE).</mark></p>

        <h2>TPU Design choice #2: Ahead of Time (AoT) Compilation + Less Reliance on Caches</h2>

        <p>This section answers how TPUs achieve high energy efficiencies through avoiding caches through <mark>hardware-software codesign of TPUs + XLA compiler.</mark></p>

        <p>First, recall that traditional caches are designed to handle unpredictable memory access patterns. A program for one application can have vastly different memory access patterns with those from programs for other applications. In essence, caches allow hardware to be flexible and adapt to a wide range of applications. This is a large reason why GPUs are very flexible hardware (note: compared to TPUs).</p>

        <p>However, cache accesses (and memory accesses in general) cost significant energy. Below is a rough estimate of energy costs for operations on a chip (45nm, 0.9V; <a href="#ref18">[18]</a>). The key takeaway here is that memory access and control takes up most of our energy and that arithmetic takes up significantly less.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/patterson_breakdown.png" alt="TPU data movement visualized" width="auto" height="150" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/patterson_breakdown.png" alt="TPU data movement visualized">
      </figure>
        

        <p>But what if your application is very specific and its computation/memory access patterns are highly predictable?</p>

        <p>As an extreme example, if our compiler can figure out all the required memory accesses ahead of time, then our hardware can get by with just a scratchpad memory as a buffer with no caches.</p>

        <p>This is what the TPU philosophy aims for and exactly why TPUs were codesigned with the XLA compiler to achieve this. The XLA compiler generates optimized programs by analyzing computation graphs ahead of time.</p>

        <br>
        <h3><span>Q. But JAX also works well with TPUs, but they use <code>@jit</code>?</span></h3>

        <p>JAX+XLA on TPUs are in a hybrid space of JIT and AOT, thus the confusion. When we call a jitted function in JAX for the first time, JAX traces it to create a static computation graph. This is passed to the XLA compiler, where it is turned into a fully static binary for TPUs. It is during the last conversion stage where TPU-specific optimizations are done (e.g. minimize memory accesses) to tailor the process to TPUs.</p>

        <p>But there's one caution: jitted functions have to be compiled and cached again if they are run with different input shapes. That's why JAX does poorly with any dynamic padding or layers with for loops with different lengths that depend on the input.</p>

        <p>Of course, this approach sounds very good but there are also inconvenient downsides. There's the lack of flexibility and this heavy reliance on compilers is a double-edged sword.</p>

        <p>But why did Google still pursue this design philosophy?</p>

        <br>
        <h3><span>TPUs and Energy Efficiency (TPUv4)</span></h3>

        <p>The previous diagram for energy usage was not an accurate representation for TPUs, so here's the energy usage breakdown for TPUv4. Note that TPUv4 is 7nm and the 45nm is there for a comparison (<a href="#ref3">[3]</a>, <a href="#ref16">[16]</a>).</p>

        <br>
        <!-- <div style="display: flex; justify-content: center; gap: 20px; align-items: flex-end;">
          <figure style="text-align: center; margin: 0;">
              <img src="images/patterson_breakdown_1.png" alt="TPU data movement visualized" width="auto" height="300">
              <figcaption style="margin-top: 10px; font-style: italic;">Energy per Operation (TPUv4, 7 nm)</figcaption>
          </figure>
          <figure style="text-align: center; margin: 0;">
              <img src="images/tpuv4_energy_breakdown.png" alt="Second image description" width="auto" height="400">
          </figure>
      </div> -->
        
        

        <p>The bar plot on the left shows us the visualization of values, but one thing to note is that modern chips use HBM3, which uses much less energy than DDR3/4 DRAM shown over here. Nevertheless, this shows how memory operations consume a couple orders of magnitudes more energy.</p>

        <p>This is a good connection with <mark>modern scaling laws: we're very much happy to increase FLOPS in exchange for reduced memory operations.</mark> So reducing memory operations has double the optimization benefits since they not only make programs fast, but also consume much less energy.</p>

        <br>
        <h2>TPU Multi-Chip Level</h2>

        <p>Let's move up the ladder to look at how TPUs work in multi-chip settings.</p>

        <br>
        <h2><span>Tray Level (a.k.a "Board"; 4 chips)</span></h2>
        
        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/tray.png" alt="TPU data movement visualized" width="auto" height="300" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tray.png" alt="TPU data movement visualized">
      </figure>
        

        <p>A single TPU tray consists of 4 TPU chips or 8 TensorCores (referred to as just "cores"). And each tray gets its own CPU Host (Note: For inference TPUs, one host accesses 2 trays since they only have 1 core per chip).</p>

        <p>Host⇔Chip connection is PCIe, but Chip⇔Chip connection is Inter-Core Interconnect (ICI), which has a higher bandwidth.</p>

        <p>But ICI connections extend much further to multiple trays. And for this, we need to move up to the Rack level.</p>

        <br>
        <h2><span>Rack Level (4x4x4 chips)</span></h2>

        <p>The especially exciting part about TPUs is in their scalability, which we start to see from the Rack level.</p>

        <p>A TPU rack consists of 64 TPUs that are connected in a 4x4x4 3D torus. If you saw Google's promotion material for TPUs like below, this is an image of 8 TPU racks.</p>

        <br>
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tpu_racks.png" alt="TPU data movement visualized" width="auto" height="300">
          <figcaption>8 TPU Racks (TPUv4)</figcaption>
        </figure>
        

        <p>But before we dive into racks, we need to clarify some confusing terminology: racks vs pods vs slices.</p>

        <br>
        <h3><span>Q. What's the difference between a "TPU Rack" vs a "TPU Pod" vs "TPU Slice?</span></h3>

        <p>Different Google sources use them a bit differently and sometimes use "TPU Pods" and "TPU Slices" interchangeably. But for this article we'll stick with the definitions used in Google's TPU papers and in GCP's TPU documentation (<a href="#ref3">[3]</a>, <a href="#ref7">[7]</a>, <a href="#ref9">[9]</a>).</p>

        <ol>
            <li><span>TPU Rack:</span>
              <br> - Physical unit that contains 64 chips. Also known as a "cube".</li>
            <li><span>TPU Pod:</span>
              <br> - Maximum unit of TPUs that can be connected through ICI and optical fibers.
              <br> - Also known as a "Superpod" or "Full pod". For example, a TPU Pod for TPUv4 would consist of 4096 chips or 64 TPU Racks.</li>
            <li><span>TPU Slice:</span>
              <br> - Any configuration of TPUs that are in between 4 chips and the Superpod size.</li>
        </ol>


        <p><mark>The key difference is that a TPU Rack and a TPU Pod is a physical unit of measure whereas a TPU Slice is an abstract one.</mark> There's, of course, important physical properties for setting a TPU Slice but let's abstract this away for now.</p>

        <p>For now, we'll work with physical units of measure: TPU Racks and TPU Pods. This is because seeing how TPU systems are physically wired together allows us to understand TPU design philosophies better.</p>

        
        <p>Now back to TPU racks (for TPUv4):</p>

        <p>A single TPU Rack consists of 64 chips that are connected together through ICI and Optical Circuit Switching (OCS). In essence, we connect multiple trays together to emulate a system of 64 chips. This theme of putting together smaller parts to make a supercomputer continues to appear later.</p>

        <p>Below is a diagram for a single TPUv4 Rack. It's a 4x4x4 3D torus where each node is a chip, and the arrows in blue are ICI while the lines on the faces are OCS (redrawn from <a href="#ref7">[7]</a>).</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/rack_ocs.png" alt="Simple thread hierarchy" width="auto" height="400" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Single TPU Rack with OCS</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/rack_ocs.png" alt="Simple thread hierarchy">
          <figcaption>Single TPU Rack with OCS</figcaption>
      </figure>
        

        <p>This diagram, however, raises a couple questions. <em>Why is the OCS only used for the faces?</em> In other words, <em>what are the benefits of using OCS?</em> There's 3 large benefits and we'll cover the other two down below later.</p>

        <br>
        <h3><span>Benefits of OCS #1: Wraparound</span></h3>

        <p><mark>Faster communication between nodes through wraparound</mark></p>

        <p>The OCS also acts as a wraparound for a given TPU configuration. This reduces the worst case number of hops between two nodes from N-1 hops to (N-1)/2 per axis, as each axis becomes a ring (1D torus).</p>

        <p>This effect becomes more important as we scale up further since reducing chip-to-chip communication latency becomes crucial for high parallelization.</p>

        <br>
        <h3><span>Aside: Not all TPUs have 3D Torus Topologies</span></h3>

        <p>Note: older TPU generations (e.g. TPUv2, v3) and inference TPUs (e.g. TPUv5e, TPUv6e) have a 2D torus topology instead of a 3D torus like below. The TPUv7 "Ironwood", however, seems to be a 3D torus although it's promoted as an inference chip (Note: I'm only assuming from their promotional material).</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/torus_2d.png" alt="TPU data movement visualized" width="auto" height="300" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">2D Torus Topology</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/torus_2d.png" alt="TPU data movement visualized">
          <figcaption>2D Torus Topology</figcaption>
      </figure>
        <h2>Full Pod Level (aka "Superpod"; 4096 chips for TPUv4)</h2>

        <p>Just like how we connected multiple chips together to make a TPU Rack, we can connect multiple racks to make one large Superpod.</p>

        <p>A Superpod also refers to the largest configuration of interconnected chips (using only ICI and OCS) that TPUs can reach. There is a multi-pod level next, but this has to go through a slower interconnect and we'll cover this after this.</p>

        <p>This changes depending on the generation, but for TPUv4 is 4096 chips (i.e. 64 Racks of 4x4x4 chips). For the newest TPUv7 "Ironwood", this is 9216 chips.</p>

        <p>The diagram below shows one Superpod for TPUv4.</p>

        <br>
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/full_pod.png" alt="TPU data movement visualized">
          <figcaption>Superpod for TPUv4 (64 Racks)</figcaption>
      </figure>
        

        <p>Note how each cube (i.e. a TPU Rack) is connected with each other through OCS. This also allows us to take slices of TPUs in a pod.</p>

        <br>
        <h3><span>TPU Slices with OCS</span></h3>

        <p>We can request subsets of TPUs within the pod and these are TPU Slices. But there's multiple topologies to choose from even if you want N chips.</p>

        <p>For example, say you want a total of 512 chips. You can ask for a cube (8x8x8), a cigar shape (4x4x32), or a rectangle (4x8x16). Choosing the topology of the slice is a hyperparameter in itself.</p>

        <p><mark>The topology you choose will affect the communication bandwidth between nodes. And this directly affects the performance of different parallelism methods.</mark></p>

        <p>For example, a cube (ex. 8x8x8) would be preferred for all-to-all communications, such as data parallelism or tensor parallelism, because it has the highest bisection bandwidth. However, a cigar shape (ex. 4x4x32) would be better for pipeline parallelism as it can communicate with sequential layers faster (assuming one layer fits in a sub-slice of 4x4 chips).</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/diff_topo.png" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Example TPU Topologies</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/diff_topo.png" alt="TPU data movement visualized">
          <figcaption>Example TPU Topologies</figcaption>
      </figure>
        

        <p>But, of course, optimal topologies would depend on the model and finding this is a job in itself as well. The TPUv4 paper<a href="#ref9">[9]</a> also measured this to show how topology changes can accelerate throughput (Note: I'm not sure which LLM architecture the first row is referring to as it wasn't specified).</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/diff_topo_fig.png" alt="TPU data movement visualized" width="auto" height="300" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Improvements in Throughput with Different Topologies</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/diff_topo_fig.png" alt="TPU data movement visualized">
          <figcaption>Improvements in Throughput with Different Topologies</figcaption>
      </figure>
        

        <p>We covered TPU Slices, but there's one important feature that contributes to a high operational stability of TPUs.</p>

        <p>It's that these slices do not have to be contiguous racks thanks to OCS. This is the second benefit of using OCS–and probably the largest–that we didn't get to earlier.</p>

        <br>
        <h3><span>Benefits of OCS #2: (Reconfigurable) Noncontiguous Multi-Node Slices</span></h3>

        <p>Note that this is different from hard-wiring multiple nodes together to emulate noncontiguous slices. Since OCS is a switch instead of being hard-wired, there's much less physical wires across nodes, thus allowing for higher scalability (i.e. larger TPU Pod sizes).</p>

        <p><mark>This allows flexible node configuration as scale.</mark> For example, say there are three jobs we want to run on a single pod. Although naive scheduling would not allow this, OCS connections instead allow us to abstract away the position of nodes and view the entire pod as just a <mark>"bag of nodes"</mark> (redrawn from <a href="#ref6">[6]</a>).</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/multijob.png" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Individual Jobs Can Treat TPU Racks in a Pod as "Bag of Nodes"</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/multijob.png" alt="TPU data movement visualized">
          <figcaption>Individual Jobs Can Treat TPU Racks in a Pod as "Bag of Nodes"</figcaption>
      </figure>
        

        <p>This increases pod utilization and possibly much easier maintenance in case of failed nodes. Google described this as <em>"Dead nodes have small blast radius."</em> However, I'm not sure how its liquid cooling would be impacted when only certain nodes have to be shut down.</p>

        <p>Finally, there's an interesting extension of this flexible OCS: we can also change the topology of TPU Slices, such as from a regular torus to a twisted torus.</p>

        <br>
        <h3><span>Benefits of OCS #3: Twisted TPU Topologies</span></h3>

        <p>We previously saw how we could achieve different TPU Slice topologies by changing (x,y,z) dimensions for a fixed number of chips. This time, however, we'll be working with fixed (x,y,z) dimensions, but instead change how they are wired together to achieve different topologies.</p>

        <p>A notable example is going from a regular torus of a cigar shape into a twisted cigar torus as seen below.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/twisted_torus.png" alt="TPU data movement visualized" width="auto" height="400" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Regular vs Twisted Torus (Source: TPUv4 Paper <a href="#ref9">[9]</a>)</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/twisted_torus.png" alt="TPU data movement visualized">
          <figcaption>Regular vs Twisted Torus (Source: TPUv4 Paper <a href="#ref9">[9]</a>)</figcaption>
      </figure>
        

        <p>The twisted torus case allows for faster communication between chips across the twisted 2D plane. This is especially useful for accelerating all-to-all communications.</p>

        <p>Let's dive a little deeper and imagine a concrete scenario where this would help.</p>

        <br>
        <h3><span>Accelerated Training using Twisted Torus</span></h3>

        <p>Theoretically, twisting the torus will bring the largest benefit for tensor parallel (TP) since there are multiple all-gather and reduce-scatter operations per layer. It could bring moderate benefits for data parallel (DP) since there's an all-reduce per training step as well, but this would be less frequent.</p>

        <p>Imagine we're training a standard decoder-only transformer and we want to employ lots of parallelism to accelerate training. We'll see two scenarios below.</p>

        <br>
        <h4><span><mark>Scenario #1: 4x4x16 Topology (TP + PP; Total 256 chips)</mark></span></h4>
        <!-- <p><strong>Scenario #1: 4x4x16 Topology (TP + PP; Total 256 chips)</strong></p> -->

        <p>Our z axis will be our pipeline parallel(PP) dimension and our 2D TP dimension will be 4x4. In essence, assume each layer k lies at z=k and that each layer is sharded across 16 chips. Assume standard OCS connections (i.e. nearest-neighbor) if not explicitly drawn.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/twisted_scenario_1.png" alt="TPU data movement visualized" width="auto" height="600" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">4x4x16 Topology with TP + PP</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/twisted_scenario_1.png" alt="TPU data movement visualized">
          <figcaption>4x4x16 Topology with TP + PP</figcaption>
      </figure>
        

        <p>We'll twist the 2D torus at each z=k, which makes communication between chips in each TP layer faster. Twisting along our PP dimension is unnecessary as they rely mostly on point-to-point communication.</p>

        <p><strong>Note:</strong> In reality, twisting the torus brings benefits when the number of chips is larger than 4x4. We're using 4x4 only for visualization purposes.</p>

        <br>
        <h4><span><mark>Scenario #2: 16x4x16 Topology (DP + TP + PP; Total 1024 chips)</mark></span></h4>
        <!-- <p><strong>Scenario #2: 16x4x16 Topology (DP + TP + PP; Total 1024 chips)</strong></p> -->

        <p>As an extension, we'll be adding a DP dimension of 4 to our previous scenario. This means there's 4 of scenario #1 models along the x axis.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/twisted_scenario_2.png" alt="TPU data movement visualized" width="auto" height="600" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">16x4x16 Topology with DP + TP + PP</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/twisted_scenario_2.png" alt="TPU data movement visualized">
          <figcaption>16x4x16 Topology with DP + TP + PP</figcaption>
      </figure>
        

        <p>Notice how twisting the torus is limited to each TP dimension of each DP model (i.e. A 4x4 2D plane for each z=k given k=1…16). There is only a wraparound for the DP dimension so that each row becomes a horizontal ring of size 16.</p>

        <p>You might have noticed that there's an alternative topology of 8x8x16 instead (i.e. 2x2 DP dimension), but this becomes more complicated as we're mixing our DP and TP dimensions. Specifically, it's unclear how we should construct the OCS wraparounds for the y-axis while accommodating twisted toruses for each TP dimension.</p>

        <br>
        <h2>Multi-Pod Level (a.k.a "Multislice"; 4096+ chips for TPUv4)</h2>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/multipod.png" alt="TPU data movement visualized" width="auto" height="200" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/multipod.png" alt="TPU data movement visualized">
      </figure>
        

        <p>The final level of TPU hierarchy is the Multi-pod level. This is where you can treat multiple pods as one large machine. However, the communication between pods is done through Data-Center Network (DCN), which has a lower bandwidth than ICI.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/multipod_dcn.png" alt="TPU data movement visualized" width="auto" height="400" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">Two Pods Connected Over DCN <a href="#ref1">[1]</a></figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/multipod_dcn.png" alt="TPU data movement visualized">
          <figcaption>Two Pods Connected Over DCN <a href="#ref1">[1]</a></figcaption>
      </figure>
        

        <p>Diagram showing how Multi-pod training can be configured</p>

        <p>This was how PaLM was trained. It took 56 days to train over 6144 TPUv4s (2 pods). Below you can see the TPU job assignments over 6 pods: green is for PaLM, red is no assignment, and the rest are other jobs. Note that each square is a 4x4x4 cube of TPUs.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/palm_train.gif" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">TPU Pod Utilization for Training PaLM <a href="#ref6">[6]</a></figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/palm_train.gif" alt="TPU data movement visualized">
          <figcaption>TPU Pod Utilization for Training PaLM <a href="#ref6">[6]</a></figcaption>
      </figure>
        


        <p>Making this possible is difficult on its own, but what makes this more impressive is the focus on developer experience. Specifically, it's about focusing on the question of "How can we abstract the systems/HW part of model scaling as much as possible?".</p>

        <p>Google's answer is to make the XLA compiler responsible for coordinating communication between chips at large scales. With the right flags given by researchers (i.e. Parallelism dimensions for DP, FSDP, TP, num slices, etc), the XLA compiler inserts the right hierarchical collectives for the TPU topology at hand (Xu et al, 2021: GSPMD <a href="#ref2">[2]</a>). The goal is to make large scale training happen with as little code changes as possible.</p>

        <p>For example, here's a breakdown of an all-reduce operation across multiple slices from Google's blog <a href="#ref1">[1]</a>.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/xla_reduce.jpg" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">XLA Reduction of All-Reduce Across Pods</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/xla_reduce.jpg" alt="TPU data movement visualized">
          <figcaption>XLA Reduction of All-Reduce Across Pods</figcaption>
      </figure>
        

        <p>This is to show that the XLA compiler takes care of communication collectives both between slices and within slices.</p>

        <p>For a concrete example, there could be a TPU topology like below for training a model. The activation communication happens within a slice through ICI whereas gradient communications will happen across slices through DCN (i.e. across the DCN DP dim) <a href="#ref1">[1]</a>.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/multipod_many.png" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/multipod_many.png" alt="TPU data movement visualized">
      </figure>
        <h2>Putting diagrams to perspective in real-life</h2>

        <p>I find it helpful to put diagrams into perspective when you have actual photos of hardware. Here's a summary below.</p>

        <p>If you’ve seen pictures of Google’s promotion material for TPUs, you might have come across this image below.</p>

        <br>
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tpu_racks.png" alt="TPU data movement visualized" width="auto" height="300">
          <figcaption>8 TPU Racks (TPUv4)</figcaption>
        </figure>
        

        <p>This is 8xTPU Pods where each unit is a 4x4x4 3D torus we saw above. Each row in a pod has 2 trays, meaning there's 8 TPU chips per row.</p>

        <p>Here’s a single TPUv4 tray:</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/tpu_tray.png" alt="TPU data movement visualized" width="auto" height="300" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tpu_tray.png" alt="TPU data movement visualized">
      </figure>
        

        <p>Note that the diagram is simplified to just one PCIe port, but on the actual tray there’s 4 PCIe ports(on the left)--one for each TPU.</p>

        <p>And here’s a single chip below:</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/tpu_chip.png" alt="TPU data movement visualized" width="auto" height="300" style="margin-left:auto; margin-right: auto;">
            <figcaption style="margin-top: 10px; font-style: italic;">TPUv4 Chip with ASIC in center + 4 HBM Stacks</figcaption>
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tpu_chip.png" alt="TPU data movement visualized">
          <figcaption>TPUv4 Chip with ASIC in center + 4 HBM Stacks</figcaption>
      </figure>
        

        <p>The center piece is the ASIC and the surrounding 4 blocks are the HBM stacks. This is a TPU v4 we’re seeing, so it has 2 TensorCores inside, hence the total of 4 HBM stacks.</p>

        <p>I couldn’t find the chip floorplan for TPUv4, so here’s one for TPUv4i which is similar except that it only has 1 TensorCore since it’s an inference chip <a href="#ref3">[3]</a>.</p>

        <br>
        <!-- <figure style="text-align: center;">
            <img src="images/tpuv4i_layout.png" alt="TPU data movement visualized" width="auto" height="500" style="margin-left:auto; margin-right: auto;">
        </figure> -->
        <figure>
          <img src="https://henryhmko.github.io/posts/tpu/images/tpuv4i_layout.png" alt="TPU data movement visualized">
      </figure>
        

        <p>Notice how the CMEM takes up quite some space on the layout for TPUv4i.</p>

        <br>
        <h2>Acknowledgements</h2>
        <p>Thank you to the Google TPU Research Cloud(TRC) for the TPU support!</p>



        <br>
        <h2>References</h2>

        <p id="ref1">[1] <a href="https://cloud.google.com/blog/products/compute/using-cloud-tpu-multislice-to-scale-ai-workloads" target="_blank">Google Blog: TPU Multi-Slice Trainng</a></p>
        <p id="ref2">[2] <a href="https://arxiv.org/pdf/2105.04663" target="_blank">Xu, et al. "GSPMD: General and Scalable Parallelizaton for ML Computation Graphs"</a></p>
        <p id="ref3">[3] <a href="https://gwern.net/doc/ai/scaling/hardware/2021-jouppi.pdf" target="_blank">Jouppi et al. "Ten Lessons From Three Generations Shaped Google's TPUv4i"</a></p>
        <p id="ref4">[4] <a href="https://jax-ml.github.io/scaling-book/tpus/" target="_blank">How to Scale Your Model - TPUs</a></p>
        <p id="ref5">[5] <a href="https://fleetwood.dev/posts/domain-specific-architectures#google-tpu" target="_blank">Domain Specific Architectures for AI Inference - TPUs</a></p>
        <p id="ref6">[6] <a href="https://hc2023.hotchips.org/assets/program/conference/day2/ML%20training/HC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf" target="_blank">HotChips 2023: TPUv4</a></p>
        <p id="ref7">[7] <a href="https://cloud.google.com/tpu/docs/v4" target="_blank">Google Cloud Docs: TPUv4</a></p>
        <p id="ref8">[8] <a href="https://arxiv.org/abs/1704.04760" target="_blank">Jouppi et al. "In-Datacenter Performance Analysis of a Tensor Processing Unit" -- TPU origins paper</a></p>
        <p id="ref9">[9] <a href="https://arxiv.org/abs/2304.01433" target="_blank">Jouppi et al. "TPU v4"-- TPUv4 paper</a></p>
        <p id="ref10">[10] <a href="https://www.youtube.com/watch?v=0yPFBxkOKRY" target="_blank">PaLM training video</a></p>
        <p id="ref11">[11] <a href="https://hc33.hotchips.org/assets/program/tutorials/HC2021.Google.Sameer%20Kumar.pdf" target="_blank">HotChips 2021: "Challenges in large scale training of Giant Transformers on Google TPU machines"</a></p>
        <p id="ref12">[12] <a href="https://hc32.hotchips.org/assets/program/tutorials/HC2020.Google.SameerKumarDehaoChen.v02.pdf" target="_blank">HotChips 2020: "Exploring Limits of ML Training on Google TPUs"</a></p>
        <p id="ref13">[13] <a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/" target="_blank">Google Blog: Ironwood</a></p>
        <p id="ref14">[14] <a href="https://old.hotchips.org/hc31/HC31_T3_Cloud_TPU_Codesign.pdf" target="_blank">HotChips 2019: "Cloud TPU: Codesigning Architecture and Infrastructure"</a></p>
        <p id="ref15">[15] <a href="https://www.youtube.com/watch?v=XkgtANeDrm8" target="_blank">ETH Zurich's Comp Arch Lecture 28: Systolic Array Architectures</a></p>
        <p id="ref16">[16] <a href="https://www.cs.ucla.edu/wp-content/uploads/cs/PATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf" target="_blank">Patterson presentation: "A Decade of Machine Learning Accelerators: Lessons Learned and Carbon Footprint"</a></p>
        <p id="ref17">[17] <a href="https://personales.unican.es/vallejoe/Publications/C%C3%A1mara%20-%20TPDS'10%20-%20Twisted%20Torus%20Topologies%20for%20Enhanced%20Interconnection%20Networks.pdf" target="_blank">Camara et al. "Twisted Torus Topologies for Enhanced Interconnection Networks."</a></p>
        <p id="ref18">[18] <a href="https://gwern.net/doc/cs/hardware/2014-horowitz-2.pdf" target="_blank">Horowitz article: "Computing's Energy Problem(and what we can do about it)"</a></p>



<!--         
        <p id="ref1">[1] <a href="https://github.com/srush/GPU-Puzzles" target="_blank">Sasha Rush, GPU Puzzles Github Repo</a></p>
        <p id="ref2">[2] <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-gpu-background/index.html" target="_blank"> NVIDIA GPU Performance Guide</a></p>
        <p id="ref3">[3] <a href="https://developer.nvidia.com/cuda-gpus" target="_blank">NVIDIA CUDA Compute Capability Specs</a></p>
        <p id="ref4">[4] Programming Massively Parallel Processors(PMPP) Textbook, 4th ed. Hwu, Kirk, Hajj.</p> -->
    
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sound As Pure Form: Music Language Inspired by Supercollider, APL, and Forth (163 pts)]]></title>
            <link>https://github.com/lfnoise/sapf</link>
            <guid>44342731</guid>
            <pubDate>Sun, 22 Jun 2025 02:17:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lfnoise/sapf">https://github.com/lfnoise/sapf</a>, See on <a href="https://news.ycombinator.com/item?id=44342731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><pre>WHAT

This program is called:

"A tool for exploring sound as pure form." or "sound as pure form" or "sapf"

It is an interpreter for a language for creating and transforming sound. The
language is mostly functional, stack based and uses postfix notation similar to
FORTH. It represents audio and control events using lazy, possibly infinite
sequences. It intends to do for lazy sequences what APL does for arrays: provide
very high level functions with pervasive automatic mapping, scanning, and
reduction operators. This makes for a language where short programs can achieve
results out of proportion to their size. Because nearly all of the programmer
accessible data types are immutable, the language can easily run multiple
threads without deadlock or corruption.

WHY

Other languages that inspired this one:
    APL, Joy[1], Haskell, Piccola[2], Nyquist[3], SuperCollider[4].

APL and FORTH (from which Joy derives) are both widely derided for being
write-only languages. Nevertheless, there has yet to be a language of such
concise expressive power as APL or its descendants. APL is powerful not because
of its bizarre symbols or syntax, but due to the way it automatically maps
operations over arrays and allows iterations at depth within arrays. This means
one almost never needs to write a loop or think about operations one-at-a-time.
Instead one can think about operations on whole structures.

Here is a great quote from Alan Perlis[5] on APL, which that also reflects my
interest in this way of programming :

"What attracted me, then, to APL was a feeling that perhaps through APL one
might begin to acquire some of the dimensions in programming that we revere in
natural language — some of the pleasures of composition; of saying things
elegantly; of being brief, poetic, artistic, that makes our natural languages
so precious to us."

The Joy language introduced concatenative functional programming. This generally
means a stack based virtual machine, and a program consisting of words which are
functions taking an input stack and returning an output stack. The natural
syntax that results is postfix. Over a very long time I have come to feel that
syntax gets in between me and the power in a language. Postfix is the least
syntax possible.

There are several reasons I like the concatenative style of programming:
    Function composition is concatenation. 
    Pipelining values through functions to get new values is the most natural
        idiom.
    Functions are applied from left to right instead of inside out. 
    Support for multiple return values comes for free. 
    No need for operator precedence. 
    Fewer delimiters are required: 
        Parentheses are not needed to control operator precedence.
        Semicolons are not needed to separate statements.
        Commas are not needed to separate arguments.

(Note: Sapf is inspired by, but is not purely a concatenative language because it has lexical variables.)

When I am programming interactively, I most often find myself in the situation
where I have a value and I want to transform it to something else. The thing to
do is apply a function with some parameters. With concatenative programming this
is very natural. You string along several words and get a new value.


QUICK SET-UP

Put the sapf program into ~/bin or wherever you keep commands.
Since this binary is unsigned you will need to remove Apple's quarantine attribute:

xattr -r -d com.apple.quarantine &lt;path-to-sapf-binary&gt;

Set up the environment variables in Terminal or your shell profile. 
For example:

export SAPF_HISTORY="$HOME/sapf-files/sapf-history.txt"
export SAPF_LOG="$HOME/sapf-files/sapf-log.txt"
export SAPF_PRELUDE="$HOME/sapf-files/sapf-prelude.txt"
export SAPF_EXAMPLES="$HOME/sapf-files/sapf-examples.txt"
export SAPF_README="$HOME/sapf-files/README.txt"
export SAPF_RECORDINGS="$HOME/sapf-files/recordings"
export SAPF_SPECTROGRAMS="$HOME/sapf-files/spectrograms"

read this README. 

check out some examples:
    start sapf in Terminal.
    open sapf-examples.txt in a text editor
    copy an example onto the command line.


COMMAND LINE

sapf [-r sample-rate][-p prelude-file]

sapf [-h]
    print this help

OPTIONS
    -r sample-rate
        Sets the session sample rate. The default sample rate is 96000 Hz.
        
    -p prelude-file
        The path to a file of code to load before entering the read-eval-print
        loop. If this argument is not supplied, the prelude file is loaded from
        the path stored in the environment variable SAPF_PRELUDE.
        
    -h
        print help for the command line options.

ENVIRONMENT VARIABLES 
    
    SAPF_PRELUDE 
        the path for a code file to be loaded before entering the
        read-eval-print loop.
        
    SAPF_RECORDINGS
        the path where output sound files should be written.
        
    SAPF_SPECTROGRAMS
        the path where spectrogram images should be written.
        
    SAPF_HISTORY
        the path where the command line history is stored for recall at runtime.
        
    SAPF_LOG
        the path where a log of command line inputs are stored for posterity.
        
    SAPF_EXAMPLES
        the path to a file of examples. 

    SAPF_README
        the path to this README file.


BUILT IN FUNCTION HELP
    You can get a list of all defined functions by typing
        "helpall".
    You can get help for a particular built-in function by typing 
        "`someword help" (note the backquote).

A VERY FEW EXAMPLES

    ;; type 'stop' to stop sound playback

    ;; play a sine wave at 800 Hz and initial phase of zero.
    800 0 sinosc .3 * play   
    
    ;; the analog bubbles example from SuperCollider:
    .4 0 lfsaw 2 * [8 7.23] 0 lfsaw .25 * 5/3 + + ohz 0 sinosc .04 * .2 0 4 combn play

    See the "examples" file for more.

TYPES
    "It is better to have 100 functions operate on one data structure 
    than 10 functions on 10 data structures." -- Alan Perlis

    The language has a bare minimum of data types:
        Real - a 64 bit double precision floating point number for quantifying
            things.
        String - a string of characters for naming things.
        List - Ordered lists of values that function as both arrays and lazy
            potentially infinitely long sequences.
        Form - An object that maps symbolic names to values. A form is a
            dictionary with inheritance.
        Function - Functions are values that when applied take values from the
            stack and evaluate an expression.
        Ref - A mutable container for a value. This is the only mutable data
            type.
        
        
SYNTAX
    Expressions are sequences of words (or other syntactic elements) written in postfix 
    form. All words are are executed in left to right order as they are encountered. 
    When a word is executed it looks up the value bound to that word. If the value is a 
    function, then the function is applied and any arguments of the function are taken 
    from the stack. If the value is not a function then the value itself is pushed onto 
    the stack. 

    
    2 3 *  --&gt;  6
    
    "--&gt;" means "evaluates to" throughout this document.
    

COMMENTS
    Comments begin with a semicolon character and continue to the end of a line.
    
    ; this is a comment line

NUMBERS

    Numbers are written in the usual ways.
        1  2.3 .5 7.
        
    Scientific notation
        3.4e-3 1.7e4
        
    Suffixes. There are several suffixes that scale the value.
    
        pi - scales the number by 3.141592653589793238...
             pi can stand alone as well as being a suffix.
             pi  2pi  .5pi  .25pi
            
        M - mega. scales the number by one million 1000000.
            1M .5M
            
        k - kilo. scales the number by 1000.
            4k 1.5k
        
        h - hecto. scales the number by 100.
            8h
            
        c - centi. scales the number by .01
            386c 702c
            
        m - milli. scales the number by .001
            53m 125m
            
        u - micro. scales the number by .000001
            20u
    
    Infix fractions with no intervening spaces are interpreted as literal real 
    numbers. Both the numerator and denominator can be floating point as 
    described above.
    
        5/4  9/7  15/11  pi/4  7.5/4  1k/3
    


STRINGS
    Strings are enclosed in double quotes. 
    
    "This is a string"
    
    \\n is newline and \\t is tab.
    
    "\\tThis string begins with a tab and ends with a newline.\\n"

WORDS
    Words are sequences of characters delimited by spaces, square brackets,
    curly brackets, parentheses, or one of the quote characters described below 
    (except for the equals sign, which can occur in a word).
    
    these are words

    When a word is executed it looks up the value bound to that word. If the
    value is a function, then the function is applied and any arguments of the
    function are taken from the stack. If the value is not a function then the
    value itself is pushed onto the stack. 

QUOTES
    There are certain symbols that, when immediately preceding a word, change
    the normal evaluation behavior. Normally when a word occurs in an
    expression, the value bound to the word symbol is looked up and applied.
    For example, when a word appears by itself like this:
        sin 
    The interpreter looks up the value bound to the 'sin symbol, which is a
    function, and applies it.

    If a word is preceded by backquote, the interpreter looks up the value bound
    to the symbol without applying it.
        `sin
    The function bound to the 'sin symbol will be pushed onto the stack instead
    of being applied.
    
    If a word is preceded by single quote, the interpreter pushes the symbol
    itself onto the stack.
        'sin
    
    If a word is preceded by comma, the interpreter pops the object on top of the
    stack, looks up the value bound to the symbol in the object, and pushes that
    value onto the stack.
        ,name
    
    If a word is preceded by dot, the interpreter looks up the value bound to
    the symbol in the object on top of the stack, and applies it.
        .name
        
    If a word is preceded by the equals sign, the interpreter binds a value to a
    symbol in the current scope. The current scope extends to the next closing
    square bracket. There are no mutable local variables. Symbols once bound may
    not be changed except at the outer-most scope (the workspace). It is not
    possible to bind values to symbols outside the current scope.
        
        123 = x
 
	You can bind multiple values from the stack using parentheses after the = sign.
	This saves having to pop them off and bind them in reverse order.

		1 2 3 = (a b c)    ; is equivalent to:   1 2 3 = c = b = a
		a b c --&gt; 1 2 3

	You can bind values from lists using square brackets after the = sign.

		[1 2 3 4 5] = [a b c]
		a b c --&gt; 1 2 3
	
		#[1 2 3 4 5] = [a b c]  ; also works for signals. Don't use # on the right hand side.
		a b c --&gt; 1 2 3
	
	Don't get clever though:

	[1 2][3 4] = ([a b][c d])  ; syntax error. nested destructuring is not supported.
    
    
FUNCTIONS

    Functions are a backslash followed by a list of argument names, followed by
    a function body within square brackets.
    
    \a b [a b + a b *]
    
    When the interpreter encounters a function in the code, it creates an instance
    of the function that captures the free variables of the function and pushes that
    onto the stack. It does not apply the function.
    A function may be applied using the ! operator.
    
    3 4 \a b [a b + a b *] !  --&gt;  7 12
    
    The function may be assigned to a word.
    
    \a b [a b + a b *] = blub
    3 4 blub  --&gt;  7 12
    
    Optionally, a help string may follow the function arguments.
    
    \a b 
        "(a b --&gt; sum product) returns the sum and product of a and b." 
        [a b + a b *]
    
    Unlike other concatenative languages, the body of a function is executed on 
    an empty stack. Values from the calling stack are not accessible except via 
    the named arguments.
    
LISTS

    Lists are created by writing expressions within square brackets. The
    expressions are evaluated and the items left on the stack become the
    elements of the list.
    
    [1 2 3]
    
    [1 2 + 3 4 *]  --&gt;  [3 12]
    
    [2 aa 3 ba]  --&gt;  [2 3 2]

    There are two types of lists, value lists aka "streams" and numeric lists
    aka "signals". Signals are defined using an initial '#' character as follows.
    
    #[1 2 3]
    
    #[1 2 + 3 4 *]  --&gt;  #[3 12]

FORMS
    Also known as dictionary, map, or record, a Form is a set of bindings from keys 
    to values. Forms may inherit from other forms.
    Forms are enclosed in curly braces. Keys are preceeded by colons.
    
    { :a 1 :b 2 } = x    ; the value 1 is bound to the key a, and the value 2 is 
                         ; bound to the key b.
    
    { x :c 3 } = y       ; y inherits from x and binds the value 3 to the key c.
    
    The position of keys is actually completely arbitrary within the braces. It is 
    only required that the number of values pushed onto the stack equals, or in the 
    case of inheritance exceeds by one, the number of keys.
    
    So the following are completely equivalent to the above:
    
    {1 2 :a :b} = x
    {x 3 :c} = y

    {:a :b 1 2} = x
    {:c x 3} = y

    This can be useful when returning multiple values from functions and binding 
    them to multiple keys. In general, I would recommend the first syntax above for 
    most cases.
    
    Multiple inheritance is supported by specifying a list of parents.
    Multiple inheritance is an experimental feature and may be removed since it
    prevents certain optimizations that may prove more useful.
    Parent objects are ordered according to an algorithm defined for
    the Dylan programming language[6].

    {:a 1} = a
    {a :b 2} = b
    {a :c 3} = c
    {[b c] :d 4} = d        ; inherit first from b then from c.
    d --&gt; {{{{:a 1}  :c 3}  :b 2}  :d 4}   ; b is reached before c in traversal.
                                           ; a is inherited from only once.

AUTO-MAPPING

    Many built-in operators which take a scalar argument will automatically map
    over a signal or stream passed in that argument position. For example, the
    "to" operator returns a sequence from a starting number to an ending number:
    
        0 4 to  --&gt;  [0 1 2 3 4]
        
    If a list is passed as one of the arguments, then that list is auto-mapped
    and a list of lists is returned.
    
        [0 2] 4 to  --&gt;  [[0 1 2 3 4][2 3 4]]
        
        0 [2 3 4] to  --&gt;  [[0 1 2][0 1 2 3][0 1 2 3 4]]
        
    If lists are passed in for multiple arguments that are subject to
    auto-mapping, then they will be auto-mapped with successive values from each
    of the arguments.
    
        [0 7][2 9] to  --&gt;  [[0 1 2][7 8 9]]
        
    When multiple arguments are auto-mapped, the result will be of the same
    length as the shortest list.
    
        [0 1][5 4 3] to  --&gt;  [[0 1 2 3 4 5][1 2 3 4]]
        
    Auto-mapping may be performed over infinite lists. ord is a function which 
    returns an infinite list of integers starting with 1. 
        ord --&gt; [1 2 3 4 5 ...]
    
        0 ord to  --&gt;  [[0 1][0 1 2][0 1 2 3][0 1 2 3 4][0 1 2 3 4 5]...]

THE "EACH" OPERATOR

    Sometimes an operator needs to be applied at a deeper level than the top
    level. The @ sign, known as the "each" operator, tags the top value on the
    stack so that the next function that consumes it will operate over each of
    its values instead of the list as a whole.
    
    For example say we have the following nested list:
    
        [[1 2 3] [4 5 6]]
        
    If we reverse it we get the outer list reversed:
    
        [[1 2 3] [4 5 6]] reverse  --&gt;  [[4 5 6] [1 2 3]]
        
    What if we want to reverse each of the inner lists? We use the each
    operator:
    
        [[1 2 3] [4 5 6]] @ reverse  --&gt;  [[3 2 1] [6 5 4]]
    
    We can use the each operator to do outer products. Normally math operators
    proceed over lists element-wise like so:
    
        [1 2][10 20] +   --&gt;   [11 22]
    
    If we use the each operator we can apply + to each element of one list and
    the whole other list.
    
        [1 2] @ [10 20] +  --&gt;  [[11 21] [12 22]]
        
        [1 2] [10 20] @ +  --&gt;  [[11 12] [21 22]]
        
    This works because math operators auto-map over lists. 
    Other operators do not auto-map over lists, for example the 2ple operator.
    2ple creates a two item list from the two items on the top of the stack.
    
        [1 2] [10 20] 2ple  --&gt;  [[1 2] [10 20]] 

        [1 2] @ [10 20] 2ple  --&gt;  [[1 [10 20]] [2 [10 20]]]
        
        [1 2] [10 20] @ 2ple  --&gt;  [[[1 2] 10] [[1 2] 20]]
        
        [1 2] @ [10 20] @ 2ple --&gt; [[1 10] [2 20]]
        
    In order to do an outer product we need to use ordered each operators. These
    perform nested loops.
    
        [1 2] @1 [10 20] @2 2ple  --&gt;  [[[1 10] [1 20]] [[2 10] [2 20]]]
        
        [1 2] @2 [10 20] @1 2ple  --&gt;  [[[1 10] [2 10]] [[1 20] [2 20]]]
        
        
    You can do mapping two (or more) levels deep with @@ (or @@@, @@@@, etc) :
    
        [[[1 2 3] [4 5]] [[6 7] [8 9 10]]] @@ reverse  
            --&gt;  [[[3 2 1] [5 4]] [[7 6] [10 9 8]]]
    
    ord @1 ord @2 to   --&gt; an infinite list of infinite lists of finite lists:
        [
            [[1] [1 2] [1 2 3] [1 2 3 4] [1 2 3 4 5] ...] 
            [[2 1] [2] [2 3] [2 3 4] [2 3 4 5] ...] 
            [[3 2 1] [3 2] [3] [3 4] [3 4 5] ...] 
            [[4 3 2 1] [4 3 2] [4 3] [4] [4 5] ...] 
            [[5 4 3 2 1] [5 4 3 2] [5 4 3] [5 4] [5] ...] 
            ...
        ]

    Lists of Forms can be constructed using the each operator.
    
    {:a ord @ :b 0}  --&gt;  [{:a 1 :b 0} {:a 2 :b 0} {:a 3 :b 0} {:a 4 :b 0} ...]
    
    {:a 1 3 to @1  :b 1 4 to @2}  --&gt;          ; outer product
        [
            [{:a 1  :b 1} {:a 1  :b 2} {:a 1  :b 3} {:a 1  :b 4}]
            [{:a 2  :b 1} {:a 2  :b 2} {:a 2  :b 3} {:a 2  :b 4}]
            [{:a 3  :b 1} {:a 3  :b 2} {:a 3  :b 3} {:a 3  :b 4}]
        ]
        
    Lists of lists can be created using the each operator within the list
    constructor syntax:
    
    [[1 2 3] @ 4 5] --&gt; [[1 4 5] [2 4 5] [3 4 5]]
    
    [[1 2 3] @1 [4 5 6] @2] --&gt; 
            [[[1 4] [1 5] [1 6]] [[2 4] [2 5] [2 6]] [[3 4] [3 5] [3 6]]]

MULTI-CHANNEL EXPANSION

    Multi-channel expansion is a kind of auto-mapping for operators that process
    signals and not streams (for example, unit generators). These operators auto-map
    over streams, but not signals.
    
    ; the saw oscillator expands over the list [300 301] to produce stereo
    ; channels that beat with each other at 1 Hz.
    [300 301] 0 saw .3 * play
    
REDUCING AND SCANNING MATH OPERATORS

    For all two argument math operators, adding a forward slash after the
    operator turns it into a list reducing operator and adding a backward slash
    turns it into a list scanning operator.
    
    1 2 + --&gt; 3   normal addition
    [1 2 3 4] +/  --&gt; 10    sum
    [1 2 3 4] +\  --&gt; [1 3 6 10]   accumulation
    
    [1 2 3 4] */  --&gt; 24    product
    [1 2 3 4] *\  --&gt; [1 2 6 24]   scan of multiplication
    
    Adding a caret after the operator makes it work in pair-wise fashion. It
    outputs the first value, then outputs the operator applied to successive
    pairs.
    [1 2 3 4 5 6] +^     --&gt; [1 3 5 7 9 11]
    
    -^ and +\ are inverses of each other.
    [7 9 16 20 1 5] -^   --&gt; [7 2 7 4 -19 4]        pairwise difference
    [7 2 7 4 -19 4] +\   --&gt; [7 9 16 20 1 5]        accumulation


REFERENCES    

1. <a href="http://www.kevinalbrecht.com/code/joy-mirror/joy.html" rel="nofollow">http://www.kevinalbrecht.com/code/joy-mirror/joy.html</a>

2. <a href="http://scg.unibe.ch/research/piccola" rel="nofollow">http://scg.unibe.ch/research/piccola</a>

3. <a href="http://www.cs.cmu.edu/~music/nyquist/" rel="nofollow">http://www.cs.cmu.edu/~music/nyquist/</a>

4. <a href="http://supercollider.sourceforge.net/" rel="nofollow">http://supercollider.sourceforge.net</a>

5. <a href="http://www.jsoftware.com/papers/perlis78.htm" rel="nofollow">http://www.jsoftware.com/papers/perlis78.htm</a>

6. <a href="http://haahr.tempdomainname.com/dylan/linearization-oopsla96.html" rel="nofollow">http://haahr.tempdomainname.com/dylan/linearization-oopsla96.html</a>

</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. strikes Iran's nuclear facilities (276 pts)]]></title>
            <link>https://www.axios.com/2025/06/21/us-strike-iran-nuclear-israel-trump</link>
            <guid>44341678</guid>
            <pubDate>Sun, 22 Jun 2025 00:12:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2025/06/21/us-strike-iran-nuclear-israel-trump">https://www.axios.com/2025/06/21/us-strike-iran-nuclear-israel-trump</a>, See on <a href="https://news.ycombinator.com/item?id=44341678">Hacker News</a></p>
Couldn't get https://www.axios.com/2025/06/21/us-strike-iran-nuclear-israel-trump: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Trump says US has bombed Fordo nuclear plant in attack on Iran (1107 pts)]]></title>
            <link>https://www.bbc.co.uk/news/live/ckg3rzj8emjt</link>
            <guid>44341639</guid>
            <pubDate>Sun, 22 Jun 2025 00:00:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/live/ckg3rzj8emjt">https://www.bbc.co.uk/news/live/ckg3rzj8emjt</a>, See on <a href="https://news.ycombinator.com/item?id=44341639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="list" spacing="6" tabindex="0" data-testid="postList"><li><div><article data-testid="content-post" id="asset:ea41cffb-36ea-4459-9360-56e0992f5b5c"><header><span><img src="https://static.files.bbci.co.uk/core/website/assets/static/news/incident-types/analysis.77b314ef10.svg" alt="Analysis" draggable="false"><h3 type="normal"><span role="text"><span>Trump's message to Iran - negotiate or expect more strikes</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:23 British Summer Time</span></span></span></span></h3></span></header><p><span><span><img alt="" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/128/cpsprodpb//vivo/live/images/2023/1/6/a1462f87-b5c0-43b2-8a08-2f7c7a8f1bff.jpg.webp" width="64" height="64"></span></span><span><strong>Bernd Debusmann Jr</strong><br>Reporting from Washington DC</span></p>
      <p>Trump's message to the Iranian regime was short, simple and direct: come to the negotiating table, or more strikes will come. </p><p> "If they do not, future attacks will be far greater," he said. "And a lot easier." </p><p>In the lead-up to the attacks, Trump had repeatedly - at least publicly - left room for negotiations to continue. </p><p>Now, he continues to leave the path open, but with the threat of further American strikes looming over Iran's leadership. </p><p>"There will be either peace, or there will be tragedy for Iran far greater than we have witnessed over the last eight days," he said. </p><p>Notably, Trump did not explicitly mention the possibility of regime change in Tehran. Instead, he made it clear the US considers the operation largely over. But if - and only if - Iran comes to the table. </p><p>The US has moved considerable military assets to the region, which suggests, as Trump noted, that the US is ready to move extremely quickly if the president so chooses.</p><figure><p><span><img alt="Trump walks with U.S. Vice President JD Vance, U.S. Secretary of State Marco Rubio and U.S. Defense Secretary Pete Hegseth before his address to the nation" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/1c6c9f22-0008-4059-8e8f-b277ba29a4ce.jpg.webp 800w" width="1000" height="563"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure>
    </article></div></li><li><div><article data-testid="content-post" id="asset:7c44e0f1-cccf-42b4-b0be-1fa588d9df43"><header><span><h3 type="normal"><span role="text"><span>Israel and US worked as 'a team'</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:12 British Summer Time</span></span></span></span></h3></span></header>
      <p>Trump says thousands were killed by Iran's former military commander Qasem Soleimani.</p><p>"I decided a long time ago that I would not let this happen, it will not continue."</p><p>He also congratulates Benjamin Netanyahu, saying they worked as a "team" to erase this "horrible threat to Israel".</p><p>Trump remarks lasted for about four minutes. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:8dd5b99b-9b1e-4a60-acb5-61b739133bd7"><header><span><h3 type="normal"><span role="text"><span>Trump warns of more strikes if peace 'doesn't come quickly'</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:10 British Summer Time</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="Trump delivers an address to the nation at the White House" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/ec80caf5-5b22-4344-94f3-042dcb89ec57.jpg.webp 800w" width="1000" height="563"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>Trump is flanked by Vice President JD Vance, Secretary of State Marco Rubio and Secretary of Defence Pete Hegseth.</p></figcaption></figure><p>"There will be either peace or there will be tragedy for Iran far greater that we have witnessed over the last eight days," Trump warns.</p><p>"Remember, there are many targets left. Tonight was the most difficult of them all by far, and perhaps the most lethal. </p><p>"But if peace doesn't come quickly we will go to those other targets with precision, speed and skill," the US president says.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:1d1ab6f8-760b-41e0-9ca1-d0ff4dda646b"><header><span><h3 type="normal"><span role="text"><span>Strikes were 'a spectacular military success'</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:07 British Summer Time</span></span></span></span></h3></span></header>
      <p>Trump confirms the US struck Iran's nuclear facilities at Fordo, Natanz, and Isfahan a short while ago.</p><p>"Everyone heard those names for years as they built this horrible destructive enterprise," he says.</p><p>"Tonight I can report to the world that the strikes were a spectacular military success."</p><p>He goes on to say "Iran’s key nuclear enrichment facilities have been completely and totally obliterated".</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:d03a4187-a399-4167-937e-d4ec93eb1fc7"><header><span><h3 type="normal"><span role="text"><span>Iran must 'now make peace', Trump says</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:05 British Summer Time</span></span></span></span></h3></span></header>
      <p>Iran "must now make peace," says US President Donald Trump.</p><p>"If they do not, future attacks will be far greater and a lot easier," he says.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:86d41e00-d6ee-46f1-b815-a3356b39597c"><header><span><h3 type="normal"><span role="text"><span>Trump addresses nation</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 03:03 British Summer Time</span></span></span></span></h3></span></header>
      <p>Donald Trump has started his address. Follow more for the latest updates. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:335cb012-33d1-4c7f-a964-67d33c07c40d"><header><span><h3 type="normal"><span role="text"><span>Trump set for televised address</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:59 British Summer Time</span></span></span></span></h3></span></header>
      <p>Donald Trump is set to make a televised address any moment now after earlier using social media to announce the US strikes on Iran. </p><p>You can follow all the latest here and watch it by clicking 'Watch live' at the top of this page. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:597b724b-b055-4157-9190-f60dfa02bcb8"><header><span><h3 type="normal"><span role="text"><span>Democrats respond to US strikes on Iran</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:55 British Summer Time</span></span></span></span></h3></span></header>
      <p>US House Minority Leader Hakeem Jeffries says that US strikes on Iran has "dramatically increased" the risk of war.</p><p>In a post on X, Jeffries says: "President Trump misled the country about his intentions, failed to seek congressional authorisation for the use of military force and risks the entanglement in a potentially disastrous war in the Middle East."</p><p>He added that Trump "shoulders complete and total responsibility for any adverse consequences that flow from his unilateral military action". </p><p>Separately, Democratic US senator Bernie Sanders says that Trump's strikes are "grossly unconstitutional".</p><p>"The only entity that can take this country to war is the US Congress. The president does not have the right," Sanders added. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:f21b391c-fd1b-4ade-bf7f-332b539608af"><header><span><h3 type="normal"><span role="text"><span>'Trump and the US acted with a lot of strength,' Netanyahu says</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:52 British Summer Time</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="Israeli Prime Minister Benjamin Netanyahu attends a meeting with U.S. President Donald Trump in the Oval Office of the White House on April 7, 2025 in Washington, DC." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/9f560450-bf34-464a-8f3d-e1aea702c06a.jpg.webp 800w" width="1022" height="575"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>Israeli Prime Minister Benjamin Netanyahu has just issued a statement following the US strikes on Iran's nuclear facilities.</p><p>"President Trump and I often say: 'Peace through strength.' First comes strength, then comes peace," he says. </p><p>"And tonight, president Trump and the United States acted with a lot of strength," Netanyahu says.</p><p>As we've reported earlier, the US had given Israel a heads up ahead of the strikes. Netanayhu and Trump also spoke afterwards.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:318f6f11-bf58-4ce9-8849-f347aac2e313"><header><span><h3 type="normal"><span role="text"><span>Uncertainty dawns in the Middle East</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:50 British Summer Time</span></span></span></span></h3></span></header><p><span><span><img alt="" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/128/cpsprodpb//vivo/live/images/2024/4/5/f2dd10d2-6e87-4dc2-94d4-7768f306fec6.jpg.webp" width="64" height="64"></span></span><span><strong>Jo Floto</strong><br>Middle East bureau chief in Jerusalem</span></p>
      <p>Israel
has always maintained that it had the capacity to destroy Iran’s nuclear
programme on its own, but it is also no secret that only America possessed the
massive ordnance capable of dealing with the strongest levels of protection,
particularly at Fordo, built deep inside a mountain.</p><p>If
the sites are now indeed out of use, then there may be an opportunity for
Israel’s Prime Minister Benjamin Netanyahu to declare his main war aim
complete.  </p><p>But
this morning the Middle East will be holding its breath, waiting to see whether
this marks the beginning of the end of this conflict, or the beginning of an
even more deadly phase to the war.</p><p>Last
week Iran’s Supreme Leader Ali Khamenei had vowed to hit back at the US were it to enter the
war. “The Americans should know that any US military intervention will
undoubtedly be accompanied by irreparable damage,” he said.</p><p>Only
on Saturday the Houthi group in Yemen - staunch Iranian allies - had threatened
to attack US ships transiting through the Red Sea if America entered the war.</p><figure><p><span><img alt="Iran's Supreme Leader Ayatollah Ali Khamenei speaks in a televised message following the Israeli strikes, in Tehran, Iran, June 18" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/b88a9733-21a7-44b2-9ac0-eca661c26ad1.jpg.webp 800w" width="1000" height="563"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>Iran's Supreme Leader Ayatollah Ali Khamenei speaks in a televised message following the Israeli strikes in Tehran on June 18</p></figcaption></figure>
    </article></div></li><li><div><article data-testid="content-post" id="asset:8f4a8816-618b-445d-92ef-8aab54e795f0"><header><span><h3 type="normal"><span role="text"><span>The Fordo facility and US 'bunker busters' explained</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:41 British Summer Time</span></span></span></span></h3></span></header>
      <p>As we have reported, one of the main targets of the US strikes was the Fordo nuclear facility. </p><p>This is what the area looks like. </p><figure><p><span><img alt="Map of Fordo" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/2ece85a4-36b3-4799-9449-58256ca94caa.png.webp 800w" width="1280" height="1312"></span></p></figure><p>They were reported to have used 'bunker-buster' bombs.</p><figure><p><span><img alt="Graphic of bunker buster bomb" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/ca92f07d-2a14-4014-a5e9-aa41cf60908d.png.webp 800w" width="1280" height="2872"></span></p></figure><p>And the only planes that could carry such bombs are B-2 stealth bombers. </p><figure><p><span><img alt="Graphic about the bombers" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/36d742ae-316f-4b3b-b68d-a74f7b0efee9.jpg.webp 800w" width="1280" height="1686"></span></p></figure>
    </article></div></li><li><div><article data-testid="content-post" id="asset:b975965a-63c7-4c21-afcd-6f1830427d1c"><header><span><h3 type="normal"><span role="text"><span>Trump and Netanyahu spoke after the attack, senior White House source says</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:36 British Summer Time</span></span></span></span></h3></span></header>
      <p>US President Donald Trump and Israeli President Benjamin Netanyahu spoke after the US strikes on Iran's nuclear facilities, the BBC's US partner CBS News reported, citing a senior White House official.</p><p>The US gave Israel a heads up before the strikes, the source told CBS.</p><p>Senior Department of Defense officials also confirmed that the GBU-57A Massive Ordnance Penetrator, a "bunker buster" bomb, was used in the attack, with two being deployed for each of the nuclear targets.</p><p>As we have reported, the three sites targeted by the US tonight were Fordo, Natanz and Esfahan.</p><figure><p><span><img alt="Map of the nuclear sites in Iran" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/aa63395b-ee1b-49b7-97dd-74bf14f97daa.png.webp 800w" width="1280" height="1420"></span></p></figure>
    </article></div></li><li><div><article data-testid="content-post" id="asset:9f82c284-66c9-4b18-a92a-bc6dc1aa5b50"><header><span><h3 type="normal"><span role="text"><span>This is a seismic moment</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:22 British Summer Time</span></span></span></span></h3></span></header><p><span><strong>Mark Lowen</strong><br>Reporting from Tel Aviv</span></p>
      <p>The question following the US strikes on Iran is now what the reaction from Tehran will be.</p><p>This is a seismic moment in the war and the relationship between Iran and Israel.</p><p>It carries potentially huge implications for American security. There are around 40,000 American troops stationed in this region. They will be on extremely high alert. </p><p>Yesterday, the Iran-backed Houthis in Yemen threatened that they would resume attacks on American ships in the Red Sea if the US got militarily involved in Iran.</p><p>There will be now a huge fear of Iranian retaliation on American and military assets in the region, and of course of how Iran will retaliate towards Israel.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:2f0354d4-0739-4e26-836c-6380f4160028"><header><span><h3 type="normal"><span role="text"><span>US reached out to Iran before strikes, report says</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:18 British Summer Time</span></span></span></span></h3></span></header>
      <p>More details are emerging about the diplomacy leading up to the strikes. </p><p>The US reached out to Iran "diplomatically" on Saturday to say the strikes are all it plans to do and that "regime change efforts are not planned", according to the BBC's US partner CBS News.</p><p>Earlier this week, several US officials told CBS that Trump opposed a plan to kill Iran's supreme leader Ayatollah Ali Khamenei.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:80358e75-3e89-4496-93b5-dc1d01c2f030"><header><span><h3 type="normal"><span role="text"><span>US strikes set off mad scramble in Washington</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:08 British Summer Time</span></span></span></span></h3></span></header><p><span><span><img alt="" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/128/cpsprodpb//vivo/live/images/2023/1/6/a1462f87-b5c0-43b2-8a08-2f7c7a8f1bff.jpg.webp" width="64" height="64"></span></span><span><strong>Bernd Debusmann Jr</strong><br>Reporting from Washington DC</span></p>
      <p>Here in Washington, the news of the US strikes in Iran set off a mad scramble across the city to follow the news, with reactions coming in quickly.</p><p>US politicians quickly weighed in on the news.</p><p>"This is not constitutional," wrote Republican Thomas Massie of Kentucky - a noted isolationist who has for days been warning that he believes US military involvement runs counter to Trump's "America First" agenda. </p><p>John Fetterman, a Democratic Senator from Pennsylvania - and vocal backer of Israel - wrote on X that "as I've long maintained, this was the correct move by POTUS [President of the US]." </p><p>"Iran is the world's leading sponsor of terrorism and cannot have nuclear capabilities," he added.</p><figure><p><span><img alt="U.S. President Donald Trump salutes Col. Paul R. Pawluk, Vice Commander for the 89th Airlift Wing, before boarding Marine One at Joint Base Andrews" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/6/22/ef8a6966-296e-445d-9903-1125896b9d6f.jpg.webp 800w" width="1000" height="563"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure>
    </article></div></li><li><div><article data-testid="content-post" id="asset:e91a58c2-2c41-48bc-8262-2f9c3ff3b736"><header><span><h3 type="normal"><span role="text"><span>Israel heightens state of alert</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 02:04 British Summer Time</span></span></span></span></h3></span></header><p><span><span><img alt="" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/128/cpsprodpb//vivo/live/images/2024/4/5/f2dd10d2-6e87-4dc2-94d4-7768f306fec6.jpg.webp" width="64" height="64"></span></span><span><strong>Jo Floto</strong><br>Middle East bureau chief in Jerusalem</span></p>
      <p>The Israel Defense Forces has just issued a statement, stepping up the state of alert.</p><p>"With the approval of the Minister of Defense Israel Katz, and following the situational assessment, it was determined that as of today (Sunday), at 03:45am, (01:45am BST) immediate changes will be made to the Home Front Command instructions.</p><p>"As part of the changes, it was decided to shift all areas of the country from Partial and Limited Activity to Essential Activity. The instructions include: a prohibition on educational activities, gatherings, and workplaces, except for essential sectors."</p><p>The IDF adds that the public is required to follow the instructions published on the official Home Front Command channels.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:eb19cac9-52de-47fa-8163-c7b17f978584"><header><span><h3 type="normal"><span role="text"><span>US lawmakers react to Trump's decision to strike Iran</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 01:58 British Summer Time</span></span></span></span></h3></span></header>
      <p>We're now getting some initial reaction from US lawmakers on Trump's surprise announcement of strikes against Iran.</p><p>South Carolina Senator Lindsey Graham congratulates Trump and says he "made the right call".</p><p>He adds that Iran's "regime deserves it".</p><p>Republican Senator Roger Wicker echoes the praise, saying Trump made a "deliberate" and "correct" decision to eliminate the "existential threat" posed by Iran.</p><p>But there is also criticism from some, with Republican Senator Thomas Massie of Kentucky saying "this is not Constitutional".</p><p>Sara Jacobs, a Democratic representative of California, says the strikes are "an escalation that risks bringing the US into another endless and deadly war”.</p><p>Secretary of State Marco Rubio has reposted Trump's Truth Social announcement but has yet to publicly comment on the strikes.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:bd7bd500-e3b6-4d12-9334-330a8b60910d"><header><span><h3 type="normal"><span role="text"><span>Iran also confirms Natanz, Isfahan strikes</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 01:56 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p><span><strong>Ghoncheh Habibiazad</strong><br>BBC Persian, World Service reporter</span></p>
      <p>Akbar
Salehi, the security deputy governor of Isfahan, has just said: "Several explosions were
heard in Natanz and Isfahan, we saw attacks near the nuclear sites of Isfahan
and Natanz."</p><p>All three strike sites mentioned by Trump have now been confirmed by Iranian officials.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:69bd08b6-17f2-4833-b760-cd41590445bf"><header><span><h3 type="normal"><span role="text"><span>Danger of escalation still exists</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 01:55 British Summer Time</span></span></span></span></h3></span></header><p><span><strong>Jake Kwon</strong><br>North America Correspondent</span></p>
      <p>Iran has been vocal in its threat to strike US bases in the Middle East if it were to be attacked. </p><p>US stations around 40,000 troops in the region. Not only Iran, but one of its proxies in the region, the Houthi rebels in Yemen has said it will strike American ships that are passing through the Suez canal down the Red Sea. </p><p>Though President Trump had called on Iran to "end this war", this war might just be starting. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:bf9530ef-8a11-4cdb-9d7d-37f00b1ba769"><header><span><h3 type="normal"><span role="text"><span>Iran officially acknowledges Fordo bombing</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 01:52 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p><span><strong>Ghoncheh Habibiazad</strong><br>BBC Persian, World Service reporter</span></p>
      <p>We have just seen the first official acknowledgment of the Fordo bombing from an Iranian official.</p><p>Morteza
Heydari, spokesperson of the Qom Province Crisis Management, says "a part of the Fordo nuclear site area
came under an aerial attack", according to the Tasnim news agency.</p>
    </article></div></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Requiem for a Solar Plant (113 pts)]]></title>
            <link>https://7goldfish.com/articles/Requiem_for_a_solar_plant.php</link>
            <guid>44341281</guid>
            <pubDate>Sat, 21 Jun 2025 22:44:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://7goldfish.com/articles/Requiem_for_a_solar_plant.php">https://7goldfish.com/articles/Requiem_for_a_solar_plant.php</a>, See on <a href="https://news.ycombinator.com/item?id=44341281">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <section>
<h2>Requiem for a Solar Plant</h2>
<p>The email landed like a brick through a plate glass window.</p>
<blockquote><p>"...requiring reconductoring of 1.71 miles at a cost of $795,150...limiting output to 3MW..."</p></blockquote>
<p>I stared at my laptop screen, the blue light illuminating the shadows under my eyes in my darkened California living room. Outside, endless February rain tapped against the windows like impatient fingers. My gut churned, a familiar discomfort that had become my constant companion over the past year. This wasn't just bad news. This was a death sentence.</p>

<p><img src="https://7goldfish.com/img/requiemFASP.png" width="100%"></p>


<p>Three years of work. Over a million dollars spent. A team scattered across three continents. All of it now threatened by two pages of engineering assessments and a single number: 3MW. My solar plant, originally planned for 4.54MW, had just been slashed by a third. The economics that had barely made sense before now collapsed entirely.</p>
<p>I reached for my phone and typed out a message to Mr. R.</p>
<blockquote><p>Just saw the interconnection report. We need to talk.</p></blockquote>
<p>The reply came quickly, despite the eleven-hour time difference. Mr. R had an uncanny ability to be available whenever needed, as though he never slept.</p>
<blockquote><p>I've been reviewing the numbers. It doesn't work.</p></blockquote>
<p>I rubbed my temples, remembering the day years earlier when the Invictus Solar project had first crystallized in my mind—a perfect convergence of opportunity and purpose. I'd made a fortune by accident in cryptocurrency, more money than I'd ever dreamed of, and had been searching for something meaningful to do with it. Something that would generate sustainable returns while helping shift the world toward renewable energy.</p>
<p>The tax advantages alone had seemed almost too good to be true: stack the federal Investment Tax Credit for solar with the capital gains deferrals from the Qualified Opportunity Zone program, and you could turn marginal economics into attractive returns. It was financial alchemy—transforming crypto profits into clean energy infrastructure while minimizing tax exposure. <label for="sn-1"></label><span> <strong>Financial Projections (Pre-Interconnection Study)</strong>
<br> - Total Installed Cost: $8,723,136 ($1.37/Watt DC) 
<br>- Capacity: 6375 kW DC / 4540 kW AC 
<br>- Net Capacity Factor: 23.8% 
<br>- Pre-tax IRR: -0.92% 
<br>- After-tax Equity IRR: 2.56% 
<br>- NPV: ($1,499,388) at 6% discount rate 
<br>- QOZ Tax Benefits: Estimated to add 3.7% to IRR
<p>
 These projections relied on a $45/MWh PPA price and assumed 4.54MW AC capacity.
<br> The reduction to 3MW in the interconnection study would significantly worsen these already-marginal returns. </p></span></p>
<p>Now, eighteen months later, sitting in my living room staring at the brutal economics of my failed project, I wondered how something so promising had gone so terribly wrong.</p>
<p>My phone rang. Mr. R.</p>
<p>"The land was good. The solar analysis was good. The land was flat. The price was right. The goddamn opportunity zone lined up perfectly," Mr. R said, his Russian accent more pronounced than usual, betraying his frustration. "But Texas with it's insane mineral rights and the interconnection study…"</p>
<p>I smiled despite myself. There was something comforting about Mr. R's exasperation, as though his anger could somehow shield us both from the disappointment.</p>
<p>"Tell me again what they're saying," I said, reaching for a notepad. "The whole thing."</p>
<p>"They want to limit us to three megawatts instead of four point five. They want us to pay nearly eight hundred thousand just to upgrade their wires. Another hundred and forty thousand for two reclosers. Plus tax." Mr. R spoke with the precision of someone who had memorized every painful detail. "And even with all that, they still say there will be fault current violations. So they cut our capacity anyway."</p>
<p>"Because the substation is too far away."</p>
<img src="https://7goldfish.com/img/requiemFASP_3.png">
<p>"Four point six miles instead of the one or two we thought. The distribution circuit takes a winding path we couldn't see from the satellite images. It goes to an entirely different substation. It's not just the distance though, our neighbors on the line have 'noisy usage' "</p>
<p>I stared at the ceiling, my mind racing through alternatives. Could we negotiate with the power company? Find another interconnection point? Redesign the system to work with the reduced capacity?</p>
<p>But I already knew the answers. We had spent months on these problems already. There was no alternative interconnection point on the property. The reduced capacity made the economics impossible. The numbers simply didn't work anymore.</p>
<p>"So that's it then," I said softly. "We shut it down."</p>
<p>The line went quiet for a moment.</p>
<p>"Yes," Mr. R finally said. "We shut it down. But first, I calculate exactly how much money we have wasted."</p>
<h2>The Assembling</h2>
<p>It started with a whiteboard session in my Palo Alto home in the summer of 2022, my kid running about in his underwear as I scribbled numbers and scenarios. Cryptocurrency had been an unexpected windfall for me, but I was painfully aware of the ecological footprint of mining. Moreover I squirmed at the 32.3% capital gains tax. <label for="sn-2"></label><span> California has an extra 12.3% on top of the 20% for federal long term capital gains </span> There was a certain poetry in transforming those digital gains into physical infrastructure that would generate clean energy for decades.</p>
<p>"What's the tax treatment on crypto profits if I roll them into a Qualified Opportunity Zone investment?" I'd asked my accountant.
His eyes had lit up—the first clue I was onto something interesting.</p>
<blockquote><p>"If you structure this correctly, you could defer capital gains through 2026 and reduce the taxable amount by up to 10%. Then layer on the ITC for solar—that's another 30% off your capital investment. It's rarely this clean."</p></blockquote>
<p>I needed someone to help translate this concept into reality, someone I could trust with both technical expertise and independent judgment. The Astral Codex Ten community—a rationalist blog I frequented—provided the unexpected solution.</p>
<p>Mr. R's application stood out immediately. Not because his experience perfectly matched the role—it didn't—but because of what he'd done just weeks earlier. As Russian forces massed at the Ukrainian border, he had calmly assessed the probability of invasion, concluded it was imminent, and acted decisively. He'd quit his oil industry job and left Russia, a step ahead of what he correctly predicted would be a draft notice that would send him to the front lines. That kind of clear-eyed foresight couldn't be taught.</p>
<p>Our first Zoom call revealed a muscular man with a shaved head and a perpetually amused expression, as though life's absurdities were a private joke he alone understood.<label for="sn-9"></label><span> 
<strong>The Team</strong> 
<br>- Project Manager: Mr. R (Russian national, relocated to Argentina during project) 
<br>- Business Analyst: Mrs. A (Friend brought onto project later) 
<br>- Project Backer: Me (Managing from California, then Singapore, then California again) 
<p>
<strong>Key Contractors: </strong>
<br>- Interconnection Consulting: EPE ($14,500) 
<br>- Engineering: HOLT Renewables ($113,718.44) 
<br>- Legal: SSCF&amp;C ($18,684.39) - CPA: HCVT ($54,433.59)
</p><p>

Total staff and contractor costs before construction: $589,374.34</p></span> 
 He spoke precise, technical English with a light Russian accent that thickened when he grew excited.</p>
<blockquote><p>"You want to use cryptocurrency profits to build renewable energy infrastructure in a tax-advantaged zone," he summarized. "A transformation of digital wealth into physical electricity generation. It's elegant. When do we start?"</p></blockquote>
<p>Within days, he was writing Python scripts to scrape property listings across Texas, overlaying them with opportunity zone boundaries and proximity to electrical infrastructure. The maps he generated were beautiful—technicolor visualizations showing potential sites as bright dots against the sprawling Texas landscape.</p>

<p>Meanwhile, my own situation grew complicated. I had been wanting to live abroad for a variety of reasons, including lower taxes. My wife, born in India but long since accustomed to American life—had was enthusiastic about a move that would take us closer to her family. Singapore seemed the perfect fit: developed infrastructure, a fast and easy visa process, and direct flights to her hometown in India.</p>
<p>We shipped our belongings across the Pacific and signed a two-year lease on a small house in the Katong area, about a 15 minute walk to the beach. The city-state gleamed with efficiency and wealth, its immaculate streets and towering skyscrapers a stark contrast to the dusty Texas parcels I was evaluating from afar.</p>
<p>Three months in, Singapore's tropical climate had transformed me in unexpected ways. My gut microbiome rebelled against some unknown element—probably the food, maybe the mold, no one could say for certain. My hormones went haywire. I found myself bedridden for weeks at a time, sleeping thru days and nights in our perfectly climate-controlled apartment.</p>
<blockquote><p>"The Roby parcel is promising," he texted one especially bad afternoon. "Flat terrain, opportunity zone status confirmed, distribution line runs along the southern border. Initial interconnection assessment looks favorable."</p></blockquote>

<p>I couldn't muster the energy to reply, but Mr. R didn't need constant direction. He proceeded methodically, working with our growing network of contractors to assess the viability of what would become the Invictus Solar project.
By the time my family admitted defeat in Singapore and shipped our belongings back to California—another wrenching international move while I battled persistent illness—Mr. R had assembled all the pieces.</p>

<img src="https://7goldfish.com/img/requiemFASP_2.png">



<p>The Roby parcel. A year-long lease with an option to buy. An initial interconnection study showing 4.54MW of available capacity.<label for="sn-3"></label><span> We had been hoping and aiming to build a 9.9 MW facility. Texas allows an accelerated interconnection process for anything under 10MW, but the QOZ requirement severely filtered where we could build, and cranking down capacity was something I could live with</span> A preliminary engineering design for a 6.4MW DC / 4.5MW AC solar array using bifacial modules with fixed tilt.
It all looked perfect on paper.
Except for two issues we had overlooked.</p>
<p>We had measured the distance to the substation as the crow flies. But electricity doesn't flow as the crow flies. It follows the distribution circuit, winding its way through the rural Texas landscape like a river following the path of least resistance. The preliminary reports from the power company said it was a non-issue, but as it turns out those are, as Mr. R would say, "unreliable". 
The second issue was mineral rights.</p>
<h2>The Mineral Kingdom</h2>
<p>"In Texas, mineral rights supersede surface rights by law," she continued. "If someone owns the minerals beneath your solar plant and wants to extract them, they have the legal right to tear down your installation to access those minerals."
My mouth went dry. "But our surveys show there's nothing valuable underground. No oil, no gas, nothing worth extracting."</p>
<p>"Doesn't matter," she replied, leaning forward. "Your solar plant is worth millions. Your insurance company won't touch it without waivers from the mineral rights holders, saying they won't exercise that right of access. It's about risk, not reality."
I nodded, trying to look composed while my mind raced through implications. "So we just need to find who owns these rights and get them to sign a waiver. How hard can that be?"</p>
<blockquote><p>Usually it's not a problem, You just make an offer at the going rate</p></blockquote>

<p>Mineral rights in Texas, it turned out, were a bizarre subterranean world with byzantine laws and scattered fiefdoms.<label for="sn-4"></label>
<span> <b>Texas Mineral Rights: A Primer</b><br> In Texas, land ownership is often separated into surface rights and mineral rights. When these rights are "severed" (owned by different parties): Mineral rights legally dominate surface rights, the right of access to extract minerals Mineral rights can be subdivided among multiple owners, Often this is poorly recorded. When owners die without specifying mineral rights in wills, ownership fragments among heirs PPP Ownership can become extremely fragmented over generations. 
<p>None of these ownership changes are recorded by the state by default. An interested third party needs to find the obituaries, and then go from county clerk to county clerk requesting that each one be recorded in a strange mixture of genealogy and bureaucracy.  Insurance is typically unavailable for infrastructure without mineral rights waivers. Mortgages are unavailable without insurance.  For the Roby parcel, ownership had fragmented to 27 different parties, with two entities controlling ~40%. </p></span> Our parcel's mineral rights had been severed from the surface rights decades ago. Then repeatedly subdivided. Then inherited. Then subdivided again.
The Mineral Ownership Report arrived three weeks later—a dense document revealing the scope of our challenge. Twenty-seven different people owned portions of the mineral rights beneath our would-be solar array. Two major holders controlled about 40%, with the remainder scattered among twenty-five others, some owning fractions so small they amounted to mineral dust.</p>
<p>A waiverwaver from the single largest stakeholder would be enough to satisfy our insurers, we had our agent reach out about getting a waiver. 
</p><blockquote><p>Actually these mineral rights were left to me by my grandfather. I have quite a sentimental attachment to them. I'm not interested</p></blockquote>
<p>I thought this was just a polite way of saying that they wanted more money than the market rate, so we reached back out with a higher offer.</p>
<blockquote><p>I told you they were sentimental mineral rights. Please don't contact me again</p></blockquote>
<p>We hired Western Land Services, specialists in mineral rights acquisition, to deal with all of the records and to contact the array of rights holders and secure waivers. 
Meanwhile, I battled my own physical terrain. The gut issues from Singapore persisted back in California, though less severely. By keeping an extremely restricted diet<label for="sn-5"></label><span>I went on a very careful elimination diet, starting with potatoes and bone broth, and expanding to little else besides organic meat and dairy</span> I was able to feel almost normal, able to focus for hours on end. Other days, exhaustion descended, leaving me unable to accomplish much beyond feeding myself. Doctors prescribed various treatments, most didn't help, and I resisted the more dramatic interventions trying to manage things thru diet.</p>
<p>Through it all, Mr. R kept the project moving with relentless efficiency. His situation had its own complications. Having fled Russia, he'd settled temporarily in Argentina, working remotely while navigating visa issues. Our team calls sometimes featured background noise from Buenos Aires cafés, the clatter of espresso cups and rapid-fire Spanish creating a surreal backdrop to discussions of Texas mineral rights and solar panel configurations.</p>
<p>By October 2024, we'd spent over $100,000 just trying to resolve the mineral rights situation. Insurance companies offered creative solutions. Normally we needed to secure waivers from owners controlling 50% of the rights, for them to consider coverage. If we set aside dedicated drilling areas within our property, that apparently we could reduce that percentage. It looked ugly but solvable.</p>
<p>Our engineers redesigned the solar array, moving it from the southern boundary to the northern section of the property, closer to the distribution line that ran along the county road. The redesign cost $30,000—steep, but far less than the half-million dollars it would have cost to run cabling across the property.</p>
<p>The lease on the property was up, and it was time to either buy it or abandon the project. I decided to fly to Texas and have a physical look at the actual property. It would also be a great chance to meet some of the people we had been working with remotely. The property was beautiful and huge. I had known that on paper it was a large plot, about ten times what we needed for an already large solar facility, but walking across it drove home just how much land we were talking about. It also sported a lovely little cabin, and I harbored fantasies of spending time out there watching the actual construction happen.</p>
<p>The Texas trip, however, proved too much for my body. When I got back I crashed hard, nearly three weeks in bed except for meals. My wife began to contemplate what it would be like to be a widow. My doctor finally talked me into some of the more aggressive hormonal interventions. They worked well and I was able to return to a more or less normal life, though I continue to this day to be on a drastically restricted diet. 
In the mineral kingdom beneath our feet, twenty-seven strangers held the power to scuttle our dreams. But above ground, the true arbiter of our fate would be the distribution circuit capacity, hidden in plain sight along the northern boundary of our would-be solar farm.</p>
<h2>The Grid's Judgment</h2>
<p>February in Texas brings a particular quality of light—sharp and clear, lacking the hazy intensity of summer. It was in this crystalline light that our dreams finally shattered.
The full interconnection study arrived without ceremony. Just an email with a PDF attachment from AEP-Texas, appearing on a Tuesday morning. All of our concerns and focus were on resolving the mineral rights situation. We simply assumed the detailed interconnection study would match the preliminary one.
Mr. R had already seen it. He called before I'd finished reading the executive summary.
"It's worse than we expected," he said without preamble, bringing up the documents in a zoom window.</p>
<p>The study was dense with technical jargon, but its conclusion was brutally clear. To interconnect our solar plant, we would need to:
Reconductor 1.71 miles of distribution line at a cost of $795,150
Install two new reclosers for $137,984
And even after these upgrades, our capacity would be limited to 3MW—not the 4.54MW originally indicated, much less the 10MW we had set out to build.
<label for="sn-a"></label><span> <strong>Interconnection Report Details</strong>
<br>
The final study identified several violations that would occur if our 4MW project were connected:<br>
Over-voltage (&gt;126V)<br>
Fault current change at PCC exceeding 10%<br>
Rapid voltage change violations<p>


<strong>Required mitigations:</strong><br>
Reconductor 1.71 miles of 2/0 AL with 477 AL at 100C: $795,150<br>
Upgrade recloser at pole 42602576932621: $68,992<br>
Remove fuses and install Viper recloser at pole 42602516931052: $68,992<br>
Federal Gross-Up Tax: $96,392<br>
Total interconnection cost: $1,029,526</p></span></p>
<p>Even with these upgrades, output would be limited to 3MW instead of 4.54MW due to persistent fault current issues. 
 


I stared out my office window at the California sunshine, so similar yet so different from the Texas light falling on our empty parcel. A million dollar upgrade requirement. A 33% reduction in capacity. The financial model that had already been balanced on a knife edge now collapsed completely.</p>
<p>"Why didn't they tell us this in the preliminary assessment?" I asked, though I already knew the answer.
"The preliminary assessment is just that—preliminary," Mr. R replied. "They look at maps and theoretical capacities. The real study is when they measure the actual wires in the ground, test the equipment. I spoke with their engineer. He said they no longer even put cost estimates in preliminary reports because the discrepancies cause too many angry customers."</p>
<p>I laughed, a short bark devoid of humor. "Well, they were right about that."
The fundamental issue was quality. Those 4.6 circuit-miles between our point of interconnection and the substation meant power had to travel a long way. The existing wire should have been able to handle our plant's output without creating unacceptable voltage fluctuations, but it had degraded in the ground. Even with upgraded wire, the fault current, the surges of electricity introduced by other users on the line, would still exceed safety limits at 4MW.</p>
<p>"If we had known that the wires run in crazy directions to the substation, we would have filtered our property search differently," Mr. R said, his voice tinged with frustration. "We just followed the visible power lines on the map"
"Well, we know for next time" I replied, almost automatically. I tend to be stubborn.</p>
<p>Next time. The words hung in the air.
Was there going to be a next time? After eighteen months of work, over a million dollars spent, and nothing to show for it but a deeper understanding of Texas mineral rights and distribution circuit physics?
"Let me ask you something," I said after a moment. "If we were to try again, what would you do differently?"</p>
<p>Mr. R didn't hesitate. "Run five projects through the process simultaneously. Most will fail for reasons you cannot predict. With five, one might succeed. And switching to batteries instead of solar.  Or at least solar plus storage."
</p><blockquote><p>"Have you been following the political situation?"</p></blockquote>
<p>Donald Trump had won, and his administration was already announcing plans to impose massive tariffs on Chinese imports, including solar panels and battery cells. The regulatory environment that had made our project potentially viable was shifting beneath our feet like Texas sand. The Republican controlled House and Senate were not terribly keen on solar.</p>
<p>"The ITC might not survive," I said quietly. "And even if it does, the tariffs would kill us on equipment costs."</p>
<p>"Exactly." Mr. R's voice was matter-of-fact. "Also the QOZ program is expiring. We started at the right time, now it's the wrong time."
The irony wasn't lost on me. The political shift would likely kill more projects than all the technical challenges we'd faced. Wild swings and regulatory uncertainty meant no one could model a thirty-year return on investment when the rules might change completely next month.</p>
<p>The next steps were clear. Shut down the project. Close the company. Pay the final invoices. Put the land up for sale.</p>
<p>Write the post-mortem.</p>
<p>Help Mr. R find a new job.<label for="sn-6"></label><span>If you want to hire an amazing general manager, talented programmer, and generally capable and agentistic guy, please get in touch with me, I'll connect you</span></p>
<p>Write a blog post. 
I looked out at the California sun again, thinking of all that Texas light falling uselessly on our empty parcel. Light that would never be converted to electricity. Never flow through those reconductored wires. Never power a single home.</p>

  </section>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LaborBerlin: State-of-the-Art 16mm Projector (199 pts)]]></title>
            <link>https://www.filmlabs.org/wiki/en/meetings_projects/spectral/laborberlin16mmprojector/start</link>
            <guid>44340386</guid>
            <pubDate>Sat, 21 Jun 2025 20:08:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filmlabs.org/wiki/en/meetings_projects/spectral/laborberlin16mmprojector/start">https://www.filmlabs.org/wiki/en/meetings_projects/spectral/laborberlin16mmprojector/start</a>, See on <a href="https://news.ycombinator.com/item?id=44340386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
                                                            <!-- wikipage start -->
                    <!-- TOC START -->
<div id="dw__toc">
<h3>Table of Contents</h3>

</div>
<!-- TOC END -->

<h2 id="laborberlinstate-of-the-art_16mm_projector">LaborBerlin: State-of-the-Art 16mm Projector</h2>


<h2 id="background">Background</h2>
<div>

<p>
While artists all over the world continue to work with celluloid film, they are often confronted with precarious screening conditions due to increasingly old and hard to repair equipment. In particular, film projectors and their aging mechanical parts have become less dependable, contributing in many cases to the destruction of the film material instead of ensuring its optimal presentation. The last 16mm commercially available film projector was built in the 90’s but most artists, archivists and projectionists have to deal with much older equipment, sometimes going back to the 60’s and 50’s. At the same time, the traditional industrial manufacturers have disappeared or shifted to other fields, service personnel have retired and spare parts are rare and unreasonably priced. Designed mainly for standard film projections, vintage projectors also fail to cater to contemporary demands: While not offering enough flexibility for artists who work in expanded cinema, they also don’t usually meet the needs of archival projection. Along with the digital revolution, which has, in the last decade, already greatly reduced the opportunities for experiencing analogue film projection, the aging technology of vintage projection equipment has become an important factor in the disappearance of analogue film projection and the uniqueness of its experience.
</p>



</div>

<h2 id="introduction">Introduction</h2>
<div>

<p>
Our idea is to develop a state-of-the-art and modular 16mm film projector using only open-source technologies and non-proprietary/commonly available spare parts. We believe that especially the central mechanical elements of the old projectors – claw mechanism, shutter wheel and film transport - are in most cases so well engineered that a new development here would be a waste of time and energy. Instead, we want to build the projector on the basis of an existing - and easily available - projector mechanism. The same applies to the optics: lenses that are compatible with projectors made by Eiki, Bauer, Bell &amp; Howell and Hokushin are available worldwide in good condition. This projector should cater to the needs of contemporary film artists, archivists and projectionists alike.
</p>



</div>

<h2 id="technical_features_wish_list">Technical Features (Wish List)</h2>
<div>

<p>
<strong>Design</strong>
</p>
<ul>
<li><p> Modular design</p>
</li>
<li><p> Open source technologies</p>
</li>
<li><p> Non-proprietary &amp; commonly available spare parts (3D-printable)</p>
</li>
<li><p> Adjustable height &amp; tilt</p>
</li>
<li><p> Lightweight for travelling &amp; portability during projection</p>
</li>
<li><p> Option to project in vertical format (90° tilted or Prism system)</p>
</li>
</ul>

<p>
<strong>Power</strong>
</p>
<ul>
<li><p> 110V &amp; 220V</p>
</li>
<li><p> Optional: Battery for outdoor &amp; portability during projection</p>
</li>
</ul>

<p>
<strong>Light source</strong>
</p>
<ul>
<li><p> Super bright, dimmable LED</p>
</li>
<li><p> Color temperature adjustment for differently timed prints,Tungsten or Xenon or redshifted film prints</p>
</li>
<li><p> Digital shutter (flicker)</p>
</li>
</ul>

<p>
<strong>Film formats</strong>
</p>
<ul>
<li><p> 16mm – Super-16 – Ultra-16 – open gate<br>
(with switchable format masks)</p>
</li>
<li><p> Steady focus between print &amp; reversal stocks</p>
</li>
<li><p> Optional: interchangeable sprocket wheels for shrunk film</p>
</li>
</ul>

<p>
<strong>Optics</strong>
</p>
<ul>
<li><p> Wide zoom range lens 25mm – 150mm</p>
</li>
<li><p> Compatible with Bauer, Eiki &amp; B&amp;H lenses (adapter tubes)</p>
</li>
<li><p> Focus with Worm Gear</p>
</li>
<li><p> Anamorphic lens holder</p>
</li>
<li><p> Holder for Elmo Viewer Type 100 (viewing without screen)</p>
</li>
</ul>

<p>
<strong>Transport</strong>
</p>
<ul>
<li><p> Crystal sync speeds: 12 – 15 – 16,66 – 18 – 23,976 – 24 – 25 – 29,97 – 30 FPS</p>
</li>
<li><p> Manual vario-speed from &lt; 1 to 30 FPS</p>
</li>
<li><p> Vario shutter wheel independent from FPS</p>
</li>
<li><p> Digital frame counter</p>
</li>
<li><p> Memory counter for in- and out-point</p>
</li>
<li><p> Fast rewind in both directions</p>
</li>
</ul>

<p>
<strong>Audio</strong>
</p>
<ul>
<li><p> Optical &amp; magnetic audio (no built-in amplifier – just outputs)</p>
</li>
<li><p> Microphone input for live voice</p>
</li>
<li><p> Headphone jack</p>
</li>
<li><p> Integrated digital audio sync system</p>
</li>
</ul>

<p>
<strong>Connectivity</strong>
</p>
<ul>
<li><p> Sync with digital audio, video &amp; midi</p>
</li>
<li><p> Sync between several projectors</p>
</li>
<li><p> Switchable from master to slave</p>
</li>
<li><p> Sync with Elmo ESS system</p>
</li>
<li><p> Optional: ready for telecine</p>
</li>
<li><p> Remote control: IR / Cable / Bluetooth</p>
</li>
</ul>

<p>
<strong>Accessories</strong>
</p>
<ul>
<li><p> Development of a compatible looper device</p>
</li>
<li><p> Spool arm extensions</p>
</li>
</ul>



</div>

<h2 id="phase_i">PHASE I</h2>


<h2 id="state_of_the_project_march_2023">State of the Project – March 2023</h2>
<div>

<p>
Our project takes place over a period of two and a half years, and should be completed by September 2025 with the presentation of a prototype at the Back To The Future Festival in Rotterdam.
</p>

<p>
As a first step, in a team of two, we disassembled four film projector models, which we found offered a suitable mechanical system that could serve as the basis for further development. We have defined three fields of development, for which we will have to collaborate with different experts. These fields are light source, film transport mechanism and electronics.
</p>

<p>
But before we can take the next step, we also realised that we are at a junction where we first have to decide which path to take:
</p>

<p>
<strong>A. </strong>Develop a flexible upgrading system which suits various existing projector models. This would ensure that artists would be able to upgrade their own projector model, no matter where they live and what projector they own. Our concern is that it may be difficult to develop parts that can adapt with various existing mechanical parts.
</p>

<p>
<strong>B. </strong>Develop an upgrading system for only one widely available projector model. This would enable us to develop much more specific parts and create an integrated concept for that one type. The downside is that many projector models are not equally available in all parts of the world.
</p>

<p>
<strong>C. </strong>Develop a DIY-Kit, replicating mechanics from various existing models, using techniques like 3D-printing , CNC- and laser cutting. This would enable artists all over the world to build up their own, modular and state-of-the-art projector from scratch. Eventually we could provide and ship readymade parts that would be too difficult to produce individually.
</p>

<p>
Once this crucial decision has been made, we want to bring an expert in electromechanics on board to accompany the project through to the prototype. At the same time, we want to build an online community with whom we can share our ideas and who can also test and improve individual parts. We are already in contact with several people who are independently working on similar developments and who are waiting to finally share their knowledge and experiences with each other. In the end, we will hire an industrial designer to work with us in order to build a prototype.
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_6443-web.jpg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_6443-web.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_6443-web.jpg?w=800&amp;tok=937903" loading="lazy" title="img_6443-web.jpg" alt="img_6443-web.jpg" width="800"></a>
</p>



</div>

<h2 id="projector_disassemblies">Projector Disassemblies</h2>
<div>

<p>
In the following we show detail shots of various 16mm projector models that we have disassembled for better examination. For each model we list the advantages and disadvantages that we noticed during disassembly.
</p>



<p>
<strong>1. Siemens 2000</strong>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/siemens-combo.jpg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:siemens-combo.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/siemens-combo.jpg?w=800&amp;tok=caf998" loading="lazy" title="siemens-combo.jpg" alt="siemens-combo.jpg" width="800"></a>
</p>
<div><table>
	<tbody><tr>
		<td> + easy availability in Europe </td><td> – poor availability in USA and Asia </td>
	</tr>
	<tr>
		<td> + robust mechanics </td><td> – unusual claw mechanism </td>
	</tr>
	<tr>
		<td> + claw with 3 teeth </td><td> – no magnetic sound </td>
	</tr>
	<tr>
		<td> + very accurate focus mechanism </td><td> – bakelite gears </td>
	</tr>
	<tr>
		<td> + compatible with Eiki &amp; Bauer lenses </td><td> – 2 belts, 1 chain </td>
	</tr>
	<tr>
		<td> + 2 and 3 blade shuttter wheel </td><td> – unusual optical sound head </td>
	</tr>
	<tr>
		<td> + manual film threading </td><td> – gate difficult to access </td>
	</tr>
</tbody></table></div>



<p>
<strong>2. Kodak Pageant</strong>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/pageant-combo.jpg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:pageant-combo.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/pageant-combo.jpg?w=800&amp;tok=5157ad" loading="lazy" title="pageant-combo.jpg" alt="pageant-combo.jpg" width="800"></a>
</p>
<div><table>
	<tbody><tr>
		<td> + easy availability in USA </td><td> – poor availability in Europe </td>
	</tr>
	<tr>
		<td> + very simple mechanics </td><td> – gate difficult to access </td>
	</tr>
	<tr>
		<td> + only few plastic parts </td><td> – lower guide roller not well designed </td>
	</tr>
	<tr>
		<td> + only 1 belt, 1 chain </td><td> – 18/24 FPS via belt change </td>
	</tr>
	<tr>
		<td> + manual film threading </td><td> – primitive claw mechanism, 2 teeth </td>
	</tr>
	<tr>
		<td>   </td><td> – lens holder too small for Eiki &amp; Bauer lenses </td>
	</tr>
	<tr>
		<td>   </td><td> – no focusing mechanism </td>
	</tr>
	<tr>
		<td>   </td><td> – only limited &amp; fixed focal lengths available </td>
	</tr>
	<tr>
		<td>   </td><td> – no magnetic sound </td>
	</tr>
</tbody></table></div>



<p>
<strong>3. Hokushin SC-10</strong>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/hokushin-combo.jpg" title="en:meetings_projects:spectral:laborberlin16mmprojector:hokushin-combo.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/hokushin-combo.jpg?w=800&amp;h=347&amp;tok=b529bd" loading="lazy" title="hokushin-combo.jpg" alt="hokushin-combo.jpg" width="800" height="347"></a>
</p>
<div><table>
	<tbody><tr>
		<td> + easy availability in NL &amp; Japan </td><td> – poor availability in rest of the world </td>
	</tr>
	<tr>
		<td> + compatible with Eiki &amp; Bauer lenses </td><td> – many plastic parts </td>
	</tr>
	<tr>
		<td> + gate easily accessible </td><td> – many belts </td>
	</tr>
	<tr>
		<td> + shutter, gate &amp; claw in one unit </td><td> – little space in the housing </td>
	</tr>
	<tr>
		<td> + manual film threading </td><td> – threading arm useless </td>
	</tr>
</tbody></table></div>



<p>
<strong>4. nac Analysis Projector</strong>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/nac-combo.jpg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:nac-combo.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/nac-combo.jpg?w=800&amp;h=257&amp;tok=a34cd0" loading="lazy" title="nac-combo.jpg" alt="nac-combo.jpg" width="800" height="257"></a>
</p>
<div><table>
	<tbody><tr>
		<td> + vario FPS, still &amp; reverse projection </td><td> – poor availability worldwide </td>
	</tr>
	<tr>
		<td> + remote control </td><td> – no sound </td>
	</tr>
	<tr>
		<td> + frame counter </td><td> – spool size limitation </td>
	</tr>
	<tr>
		<td> + compatible with B&amp;H lenses </td><td> – reduced brightness (mirror) </td>
	</tr>
	<tr>
		<td> + open gate </td><td> – very noisy fan </td>
	</tr>
	<tr>
		<td> + gate easily accessible </td><td> – heavy weight </td>
	</tr>
	<tr>
		<td> + simple mechanical design </td><td>   </td>
	</tr>
	<tr>
		<td> + shutter, gate &amp; claw in one unit </td><td>   </td>
	</tr>
	<tr>
		<td> + manual film threading </td><td>   </td>
	</tr>
</tbody></table></div>



<p>
<strong>5. Eiki RT2</strong>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/eiki-combo.jpg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:eiki-combo.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/eiki-combo.jpg?w=800&amp;tok=f2be96" loading="lazy" title="eiki-combo.jpg" alt="eiki-combo.jpg" width="800"></a>
</p>
<div><table>
	<tbody><tr>
		<td> + good availability almost worldwide </td><td> – expensive </td>
	</tr>
	<tr>
		<td> + offers plenty of space for modifications </td><td> – not 100% open mechanics </td>
	</tr>
	<tr>
		<td> + offers plenty of space in the light house </td><td> – loop former is prone to jamming </td>
	</tr>
	<tr>
		<td> + compatible with Bauer &amp; Hokushin lenses </td><td> – unreliable focus mechanism </td>
	</tr>
	<tr>
		<td> + gate easily accessible </td><td>   </td>
	</tr>
	<tr>
		<td> + manual threading possible </td><td>   </td>
	</tr>
	<tr>
		<td> + good supply of spares </td><td>   </td>
	</tr>
	<tr>
		<td> + robust metal body </td><td>   </td>
	</tr>
</tbody></table></div>



</div>

<h2 id="state_of_the_project_february_2024">State of the Project – February 2024</h2>
<div>

<p>
In August 2023 we decided that before building a prototype, we first needed to find an LED light source that is capable of replacing the common 24V 250W halogen bulb. Chzech film artist Jan Kulka recommended high density LEDs from Chinese manufacturer <a href="https://www.getiangroup.com/specialty-white-cob-leds.html" title="https://www.getiangroup.com/specialty-white-cob-leds.html" rel="ugc nofollow">Getian</a>, which he has used for his <a href="https://www.pramitacka.cz/archeoscope.pdf" title="https://www.pramitacka.cz/archeoscope.pdf" rel="ugc nofollow">Archeoscope</a> expanded cinema machine. Over a period of 6 months we tested several LEDs with different Wattage, starting from 200W, then moving up to 400W, 600W and finally 800W. We based our decisions not only on the brightness but also on the size of the LED chips in relation to the 16mm projector gate.
</p>

<p>
In order to achieve comparable and realistic testing parameters, we took out a 16mm gate with lens holder from an old Bell &amp; Howell projector. We placed the LEDs as close as possible to the gate and step-by-step turned up the voltage in 0.5V increments. We then measured the temperature on the chip, and the brightness of the projection, using a lux meter.
</p>

<p>
After a few attempts we noticed that we were always reaching a critical temperature of 60°C (recommended by the manufacturer) even before the LEDs reached the rated power capacity and the highest brightness. We realised that we would have to find a more efficient cooling system then the computer processor heat sink with fan that we had started with. The next step to achieve more brightness was to try out water cooling. For our tests we chose a <a href="https://www.caseking.de/alphacool-eisbaer-aurora-360-cpu-complete-water-cooling-digital-rgb-360mm/WASE-452.html" title="https://www.caseking.de/alphacool-eisbaer-aurora-360-cpu-complete-water-cooling-digital-rgb-360mm/WASE-452.html" rel="ugc nofollow">water cooling system (AIO)</a> that is usually used for gaming computers. This actually allowed us to operate the LEDs with much higher voltage and up to their maximum capacities without over heating. Finally with an 800W LED we were able to reach close to twice the brightness of a 24V 250W halogen bulb.
</p>



</div>

<h2 id="phase_ii">PHASE II</h2>


<h2 id="high_density_led_tests">High Density LED Tests</h2>
<div>



<p>
<strong>Reference Brightness: </strong>Bell &amp; Howell 16mm Projector with 50mm f/1,4 lens at 24 FPS: 10,000 Lux
</p>

<p>
<strong>LED-Setup: </strong>	Lens: 50mm f/1,4, distance LED-gate:	2,3 cm, distance lens-wall:	155 cm
</p>

<p>
<br>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_7691.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_7691.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7691.jpeg?w=800&amp;tok=9bd2f4" loading="lazy" title="img_7691.jpeg" alt="img_7691.jpeg" width="800"></a>
</p>

<div>
<p><a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_7703.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_7703.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7703.jpeg?w=800&amp;tok=133edf" loading="lazy" title="img_7703.jpeg" alt="img_7703.jpeg" width="800"></a></p></div>

<p>
<strong>Test 1	07.08.2023	LED 200W</strong>	max. 13,6 A	12 - 16 V<strong>		with air cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 6,6 A </td><td> 12 V </td><td> 37°C </td><td> 4420 Lux </td><td> film slowly melts at 0fps </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 13,5 A </td><td> 13 V </td><td> 54,4°C </td><td> 7420 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 17,3 A </td><td> 13,5 V </td><td> 61°C </td><td> 8000 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> 13,6 A </td><td> 13 V </td><td> 55°C </td><td> 7480 Lux </td><td>   </td>
	</tr>
</tbody></table></div>



<p>
<strong>Test 2	14.10.2023	LED 400W</strong>	max. 10 A	42 - 48 V<strong>		with air cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td>   </td><td>   </td><td> 34 V </td><td>   </td><td>   </td><td> light emission begins </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 5,2 A </td><td> 42 V </td><td> 43°C </td><td> 9500 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 10 A </td><td> 44 V </td><td> 110°C </td><td>   </td><td> too hot </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 5,9 A </td><td> 42 V </td><td> 60°C </td><td> 9600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> – </td><td> – </td><td> – </td><td> – </td><td> LED blown </td>
	</tr>
</tbody></table></div>



<p>
<strong>Test 3	16.10.2023	LED 800W</strong>	max. 15 A	45 - 54 V<strong>		with air cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td>   </td><td>   </td><td> 40 V </td><td> 19 °C </td><td>   </td><td> light emission begins </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 1 A </td><td> 44 V </td><td> 23°C </td><td> 1500 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 2 A </td><td> 45 V </td><td> 28°C </td><td> 4300 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 2,7 A </td><td> 45,5 V </td><td> 30,3°C </td><td> 5600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> 3,5 A </td><td> 46 V </td><td> 34,3°C </td><td> 7100 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#5</strong> </td><td> 4,5 A </td><td> 46,5 V </td><td> 39,3°C </td><td> 8500 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#6</strong> </td><td> 6,2 A </td><td> 47 V </td><td> 50,1°C </td><td> 10600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#7</strong> </td><td> 7,5 A </td><td> 47,3 V </td><td> 62°C </td><td> 11800 Lux </td><td>   </td>
	</tr>
</tbody></table></div>



<p>
<strong>Test 4	29.10.2023	LED 800W</strong>	max. 15 A	45 - 54 V<strong>		with AIO water cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td>   </td><td>   </td><td> 40 V </td><td> 18 °C </td><td>   </td><td> light emission begins </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 1 A </td><td> 44 V </td><td> 20,6 °C </td><td> 2600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 1,5 A </td><td> 44,5 V </td><td> 21,6 °C </td><td> 3650 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 2 A </td><td> 45 V </td><td> 22,8 °C </td><td> 4800 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> 2,7 A </td><td> 45,5 V </td><td> 24,6 °C </td><td> 6100 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#5</strong> </td><td> 3,5 A </td><td> 46 V </td><td> 26,6 °C </td><td> 7600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#6</strong> </td><td> 4,3 A </td><td> 46,5 V </td><td> 29,1 °C </td><td> 9100 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#7</strong> </td><td> 5,3 A </td><td> 47 V </td><td> 31,3 °C </td><td> 10600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#8</strong> </td><td> 5,9 A </td><td> 47,3 V </td><td> 33,0 °C </td><td> 11600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#9</strong> </td><td> 6,4 A </td><td> 47,5 V </td><td> 34,8 °C </td><td> 12300 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#10</strong> </td><td> 7,5 A </td><td> 48 V </td><td> 37,3 °C </td><td> 13600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#11</strong> </td><td> 8,7 A </td><td> 48,5 V </td><td> 40,2 °C </td><td> 14900 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#12</strong> </td><td> 10 A </td><td> 49 V </td><td> 43 °C </td><td> 16300 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#13</strong> </td><td> 11,2 A </td><td> 49,5 V </td><td> 46,1 °C </td><td> 17400 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#14</strong> </td><td> 12,5 A </td><td> 50 V </td><td> 49,2 °C </td><td> 19500 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#15</strong> </td><td> 13,8 A </td><td> 50,5 V </td><td> 52,3 °C </td><td> <em>22000</em> Lux </td><td> Twice as bright as Halogen  </td>
	</tr>
	<tr>
		<td> <strong>#16</strong> </td><td> 15 A </td><td> 51 V </td><td> 55° C </td><td> 22000 Lux </td><td>   </td>
	</tr>
</tbody></table></div>



<p>
<strong>Test 5	16.12.2023	LED 600W</strong>	max. 17 A	36 - 42 V<strong>		with AIO water cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td>   </td><td>   </td><td> 31 V </td><td> 20,2 °C </td><td>   </td><td> light emission begins </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 0,5 A </td><td> 33 V </td><td> 21,3 °C </td><td> 1000 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 0,9 A </td><td> 33,5 V </td><td> 22,4 °C </td><td> 1680 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 1,5 A </td><td> 34 V </td><td> 23,7 °C </td><td> 2600 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> 2,3 A </td><td> 34,5 V </td><td> 25,5 °C </td><td> 3700 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#5</strong> </td><td> 3,4 A </td><td> 35 V </td><td> 28,7 °C </td><td> 5160 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#6</strong> </td><td> 4,7 A </td><td> 35,5 V </td><td> 31,9 °C </td><td> 6640 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#7</strong> </td><td> 6,5 A </td><td> 36 V </td><td> 36,1 °C </td><td> 8280 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#8</strong> </td><td> 8,4 A </td><td> 36,5 V </td><td> 39,8 °C </td><td> 9950 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#9</strong> </td><td> 10,7 A </td><td> 37 V </td><td> 45,4 °C </td><td> 11500 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#10</strong> </td><td> 13 A </td><td> 37,5 V </td><td> 49,3 °C </td><td> 12420 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#11</strong> </td><td> 15,4 A </td><td> 38 V </td><td> 54 °C </td><td> 12730 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#12</strong> </td><td> 17 A </td><td> 38,3 V </td><td> 56,4 °C </td><td> 12400 Lux </td><td>   </td>
	</tr>
</tbody></table></div>



<p>
<strong>Test 5	16.12.2023	LED 400W</strong>	max. 10 A	42 - 48 V<strong>		with AIO water cooling</strong>
</p>
<div><table>
	<tbody><tr>
		<td>   </td><td> <strong>Current</strong> </td><td> <strong>Voltage</strong> </td><td> <strong>Temp. LED Sensor</strong> </td><td> <strong>Lux</strong> </td><td> <strong>notes</strong> </td>
	</tr>
	<tr>
		<td>   </td><td>   </td><td> 36,5 V </td><td> 21,5 °C </td><td>   </td><td> light emission begins </td>
	</tr>
	<tr>
		<td> <strong>#1</strong> </td><td> 0,9 A </td><td> 39,5 V </td><td> 23,5 °C </td><td> 2000 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#2</strong> </td><td> 1,3 A </td><td> 40 V </td><td> 25,7 °C </td><td> 2750 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#3</strong> </td><td> 1,9 A </td><td> 40,5 V </td><td> 27,2 °C </td><td> 3740 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#4</strong> </td><td> 2,6 A </td><td> 41 V </td><td> 29,5 °C </td><td> 4740 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#5</strong> </td><td> 3,4 A </td><td> 41,5 V </td><td> 32 °C </td><td> 5900 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#6</strong> </td><td> 4,4 A </td><td> 42 V </td><td> 35,7 °C </td><td> 7120 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#7</strong> </td><td> 5,4 A </td><td> 42,5 V </td><td> 38,7 °C </td><td> 8130 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#8</strong> </td><td> 6,5 A </td><td> 43 V </td><td> 42,5 °C </td><td> 9150 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#9</strong> </td><td> 7,7 A </td><td> 43,5 V </td><td> 45,8 °C </td><td> 9850 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#10</strong> </td><td> 8,9 A </td><td> 44 V </td><td> 49 °C </td><td> 10150 Lux </td><td>   </td>
	</tr>
	<tr>
		<td> <strong>#11</strong> </td><td> 10 A </td><td> 44,5 V </td><td> 52 °C </td><td> 10300 Lux </td><td>   </td>
	</tr>
</tbody></table></div>

<p>
<br>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_4407.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_4407.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_4407.jpeg?w=800&amp;tok=af7fa5" loading="lazy" title="img_4407.jpeg" alt="img_4407.jpeg" width="800"></a>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_7707_kopie.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_7707_kopie.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7707_kopie.jpeg?w=800&amp;tok=bf9ac0" loading="lazy" title="img_7707_kopie.jpeg" alt="img_7707_kopie.jpeg" width="800"></a>
</p>

<p>
.
</p>

</div>

<h2 id="state_of_the_project_may_2024">State of the Project – May 2024</h2>
<div>

<p>
After coming to the conclusion that the 800W LED was the most appropriate for our project, we decided that the next step should be to test the LED with a projector that had a working transport mechanism which would allow us to run a test film through the projector and check the quality of the projection. This would mean that we would have to find a projector that we would need to modify in order to fit the LED and cooler. This brought us back to the question of which path to take with the project in general. It became clear that in the time frame that we have for the project, it was most important to be able to test a system where we had variable control over the light and the transport mechanism and that we should focus first on these two parameters. That meant focusing on replacing the lamp and motor in an already existing projector instead of trying to design an entirely new projector from scratch or instead of trying to engineer a hybrid model with the best features of various projectors. So we decided to modify the Eiki RT model because of its availability, robust construction and the amount of space that it offered in the housing for modifications. The simplicity of its transport mechanism was also the factor as well as the idea that the modifications we would make could be easily reproduced by others.
</p>

<p>
At this stage we decided to bring in somebody with more expertise with projector construction and modification. Based on his experience building his own custom projection devices we asked <strong>Jan Kulka</strong> from Prague to join our team and continue the development of the prototype with us. In April 2024 we met in Berlin and decided on the next steps to follow. Even though our wish list contains a vast number of possible functions, we decided to focus initially on replacing the motor and installing a flickering LED Lamp that would replace the mechanical shutter.
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/img_4680.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_4680.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_4680.jpeg?w=800&amp;tok=c42dc7" loading="lazy" title="img_4680.jpeg" alt="img_4680.jpeg" width="800"></a>
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_detail/en/meetings_projects/spectral/laborberlin16mmprojector/whatsapp_image_2024-06-13_at_13.50.27_1_.jpeg?id=en%3Ameetings_projects%3Aspectral%3Alaborberlin16mmprojector%3Astart" title="en:meetings_projects:spectral:laborberlin16mmprojector:whatsapp_image_2024-06-13_at_13.50.27_1_.jpeg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/whatsapp_image_2024-06-13_at_13.50.27_1_.jpeg?w=800&amp;tok=8d2cb3" loading="lazy" title="whatsapp_image_2024-06-13_at_13.50.27_1_.jpeg" alt="whatsapp_image_2024-06-13_at_13.50.27_1_.jpeg" width="800"></a><br>

</p>



</div>

<h2 id="phase_iii">PHASE III</h2>


<h2 id="st_prototype_with_800w_led_water_cooling_variable_fps_shutter_blades_angle">1st Prototype with 800W LED, water cooling, variable FPS, shutter blades &amp; angle</h2>
<div>

<p>
<br>
<strong>Jan Kulka </strong>took over the technical engineering of our first prototype. The aim was to modify an Eiki RT-2 projector and implement the following features:
</p>
<ul>
<li><p> The prototype should be capable of projecting 16mm film at variable frame rates from 0 - 30FPS</p>
</li>
<li><p> Our 800W high density LED should be installed, cooled by an AiO water cooling system to avoid blowing the LED or burning the film</p>
</li>
<li><p> The original shutter wheel should be replaced by an entire digital approach through flickering the LED</p>
</li>
<li><p> The prototype should be ready to be presented at ALUD festival in Barcelona by end of October 2024</p>
</li>
</ul>

<p>
At this point of time, we knew that our SPECTRAL project partners from Mire (Nantes) had already appointed experts for their “wandering devices project” to work out a modification of the same projector model, similar to what we had in mind. Their design, created by Zach Poff, Stefan Voglsinger, Guillermo Tellechea &amp; Loic Verdillon can be seen here: <a href="https://www.filmlabs.org/wiki/en/meetings_projects/spectral/mire-wandering/wandering-16mmprojection/start" title="https://www.filmlabs.org/wiki/en/meetings_projects/spectral/mire-wandering/wandering-16mmprojection/start" rel="ugc nofollow">Wandering 16mm projector retrofit</a>. Since all four devices projects within the SPECTRAL project are meant to be open source and to be replicated and improved by others, we decided to take over larger parts of their concept as a basis for our prototype. So we discussed with Jan that it would make sense to take over the code, the choice of the encoder, the motor model and the ‘virtual shutter’ system from their wandering devices project. This would give us more time and capacities to focus on the implementation of the 800W high density LED and the AiO water cooling system.
</p>

<p>
Jan decided to use only basic tools like a power drill, angle grinder and basic hand tools. Only in one case an ultrasonic saw had to be used. In order to make sure that anybody could do the same modification without the need for special machinery, no 3D printing or laser cutting were being used. Due to heat resistance reasons, most custom made parts were made of aluminum. Jan and the technicians he employed did a marvellous job as the following technical details and photos reveal:
</p>

<p>
<strong>1. Eiki RT-2 projector - original parts that have been removed</strong>
</p>
<ul>
<li><p> mechanical shutter &amp; sill image clutch &amp; dowser</p>
</li>
<li><p> power supply</p>
</li>
<li><p> motor</p>
</li>
<li><p> fan</p>
</li>
<li><p> all electronics</p>
</li>
<li><p> sound board</p>
</li>
<li><p> lower part of the body</p>
</li>
<li><p> to accommodate the hoses of the water cooler, some holes had to be drilled &amp; grinded into the inner part of the body</p>
</li>
</ul>

<p>
<strong>2. New light source</strong>
</p>
<ul>
<li>
</li>
<li><p> Mosfet – semiconductor for switching the 800W LED</p>
</li>
<li><p> three big resistors for safety &amp; better control of the LED</p>
</li>
<li><p> extra fan for cooling the resistors &amp; Mosfet</p>
</li>
<li><p> Condensor lens (probably taken from a Kodak Pageant 16mm projector)</p>
</li>
<li>
</li>
<li><p> yet to come: fan for gate, fan for space in between LED and condensor</p>
</li>
</ul>

<p>
<strong>3. Two new power supplies</strong>
</p>
<ul>
<li>
</li>
<li>
</li>
</ul>

<p>
<strong>4. New motor</strong>
</p>
<ul>
<li><p> Quicrun Fusion SE brushless system for Crawler 2-IN-1 with FOC (field oriented control) driver embedded within the motor itself, for accurate positioning &amp; control, big torque at slow &amp; fast speeds, compact size &amp; light weight</p>
</li>
<li><p> Motor pulley 16 teeth (GT2 type)</p>
</li>
<li><p> Main shaft pulley 100 teeth (GT2 type)</p>
</li>
<li><p> Timing belt (GT2 type)</p>
</li>
<li><p> Magnetic encoder / neodym magnet mounted on main shaft – detects angle of main shaft for precise motor control &amp; frame counting</p>
</li>
</ul>

<p>
<strong>5. New control electronics</strong>
</p>
<ul>
<li><p> Main circuit board accommodates:</p>
<ul>
<li><p> ESP - main controler</p>
</li>
<li><p> step down module to 5V</p>
</li>
<li><p> inputs &amp; outputs to control panel potentiometers &amp; buttons</p>
</li>
<li><p> Relay to switch optical sound LED</p>
</li>
<li><p> PWM signal output for the main LED power supply – to control the output voltage/current for the main LED chip (dimming)</p>
</li>
<li><p> PWM signal to the motor driver – to control the motor</p>
</li>
</ul>
</li>
<li><p> New soundboard (simple pre-amp for line out) for optical sound, using Eiki original light sensor &amp; small LED light source (replacing original exciter lamp)</p>
</li>
<li><p> Arduino Nano for resetting the ESP &amp; Motor driver when Machine gets switched on</p>
</li>
</ul>
<ul>
<li><p> The main LED Chip is  switched on &amp; off by Mosfet HY 4306 (mounted on new aluminium heatsink with a small fan), controlled by ESP-Wroom-32 - this serves as the electronic shutter </p>
</li>
<li><p> 800W LED is powered &amp; dimmed by Meanwell 1000W UHP-1000-48 power supply. The output voltage is controlled by an external VC (voltage control). This VC is generated by our custom made board, which is receiving the PWM signal from the ESP and translates it into 0-10V VC, which from there is being sent to the power supply's own output regulation system (no extra dimmer needed, dimming can be programmed digitally)</p>
</li>
</ul>

<p>
<strong>6. Buttons &amp; switches</strong>
</p>
<ul>
<li><p> Eiki main switch functions (from left to right)</p>
<ul>
<li><p> Reverse Play - Risk mode (playing at low fps may burn the film)</p>
</li>
<li><p> Reverse Play - Save mode (LED gets dimmed at low fps, no risk to burn the film)</p>
</li>
<li><p> Standby (electronics &amp; fans on) – projector is ready to run 5 secs after plugged in</p>
</li>
<li><p> Forward Play - Save mode (LED gets dimmed at low fps, no risk to burn the film)</p>
</li>
<li><p> Forward Play - Risk mode (playing at low fps may burn the film)</p>
</li>
</ul>
</li>
<li><p> Control panel buttons &amp; switches (from left to right)</p>
<ul>
<li><p> Potentiometer - motor speed (0-28 fps in save mode, 0-40 fps in risk mode)</p>
</li>
<li><p> Potentiometer - Ramp for motor speed (variable responsiveness (or delay) of speed poti, from instantaneous-15 secs)</p>
</li>
<li><p> Push button (red) - 1 frame backwards when motor is stopped, freeze frame while motor is running</p>
</li>
<li><p> Push button (black) - 1 frame forward when motor is stopped, freeze frame while motor is running</p>
</li>
<li><p> Potentiometer - LED brightness (off - maximum)</p>
</li>
<li><p> Potentiometer - ramp for LED brightness (responsiveness (or delay) of LED poti from instantaneous-15 secs)</p>
</li>
<li><p> Potentiometer - number of virtual shutter blades (or flashes per frame) - 1-2-3 blades</p>
</li>
<li><p> Potentiometer - virtual shutter angle (duration of each flash) –&nbsp;from closed to completely open</p>
</li>
<li><p> Switch (not yet in function)</p>
</li>
<li><p> later: 2 potentiometers for sound volume &amp; tone.</p>
</li>
</ul>
</li>
</ul>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7465.jpeg?w=800&amp;tok=084e9a" loading="lazy" title="img_7465.jpeg" alt="img_7465.jpeg" width="800">
</p>

<p>
water cooling system, 800W LED, copper plate for mounting, condenser lens (in the back)
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7569.jpeg?w=800&amp;tok=e33bac" loading="lazy" title="img_7569.jpeg" alt="img_7569.jpeg" width="800">
</p>

<p>
testing the condenser lens
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7666.jpeg?w=800&amp;tok=bd1167" loading="lazy" title="img_7666.jpeg" alt="img_7666.jpeg" width="800">
</p>

<p>
allocating space for the hoses of the water cooling system
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7686.jpeg?w=800&amp;tok=c2eca1" loading="lazy" title="grinded passage for the cooling hoses" alt="grinded passage for the cooling hoses" width="800">
</p>

<p>
grinding a passage for the hoses
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7701.jpeg?w=800&amp;tok=523a09" loading="lazy" title="the mounted radiator of the water cooling system" alt="the mounted radiator of the water cooling system" width="800">
</p>

<p>
the mounted radiator of the water cooling system
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7727.jpeg?w=800&amp;tok=f9be33" loading="lazy" title="img_7727.jpeg" alt="img_7727.jpeg" width="800">
</p>

<p>
the water cooling head
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7785.jpeg?w=800&amp;tok=e7de6b" loading="lazy" title="img_7785.jpeg" alt="img_7785.jpeg" width="800">
</p>

<p>
mounts for LED and condenser lens
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8030.jpeg?w=800&amp;tok=12577d" loading="lazy" title="img_8030.jpeg" alt="img_8030.jpeg" width="800">
</p>

<p>
all custom made parts for mounting LED and condenser lens
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8002.jpeg?w=800&amp;tok=ada73d" loading="lazy" title="img_8002.jpeg" alt="img_8002.jpeg" width="800">
</p>

<p>
all custom made parts for mounting LED and condenser lens
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7838.jpeg?w=800&amp;tok=95482a" loading="lazy" title="img_7838.jpeg" alt="img_7838.jpeg" width="800">
</p>

<p>
positioning the copper plate
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_7874.jpeg?w=800&amp;tok=983d8b" loading="lazy" title="img_7874.jpeg" alt="img_7874.jpeg" width="800">
</p>

<p>
the copperplate holds cooling head and condenser lens as well
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8074.jpeg?w=800&amp;tok=6d8282" loading="lazy" title="img_8074.jpeg" alt="img_8074.jpeg" width="800">
</p>

<p>
LED and condenser lens in action
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8841.jpeg?w=800&amp;tok=f2b6eb" loading="lazy" title="img_8841.jpeg" alt="img_8841.jpeg" width="800">
</p>

<p>
the new motor
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8908.jpeg?w=800&amp;tok=78c879" loading="lazy" title="img_8908.jpeg" alt="img_8908.jpeg" width="800">
</p>

<p>
mounts for the motor
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8928.jpeg?w=800&amp;tok=4dd21c" loading="lazy" title="img_8928.jpeg" alt="img_8928.jpeg" width="800">
</p>

<p>
mounts for the magnetic encoder
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8937.jpeg?w=800&amp;tok=f83e18" loading="lazy" title="img_8937.jpeg" alt="img_8937.jpeg" width="800">
</p>

<p>
magnetic encoder
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8940.jpeg?w=800&amp;tok=6e61f0" loading="lazy" title="img_8940.jpeg" alt="img_8940.jpeg" width="800">
</p>

<p>
magnetic encoder mounted
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8943.jpeg?w=800&amp;tok=df54ef" loading="lazy" title="img_8943.jpeg" alt="img_8943.jpeg" width="800">
</p>

<p>
magnetic encoder in position
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_8916.jpeg?w=800&amp;tok=9413f2" loading="lazy" title="img_8916.jpeg" alt="img_8916.jpeg" width="800">
</p>

<p>
the motor in position
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9461.jpeg?w=800&amp;tok=daa312" loading="lazy" title="img_9461.jpeg" alt="img_9461.jpeg" width="800">
</p>

<p>
aluminum frame to hold two power supplies
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9496.jpeg?w=800&amp;tok=f04b5f" loading="lazy" title="img_9496.jpeg" alt="img_9496.jpeg" width="800">
</p>

<p>
two power supplies mounted
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9534.jpeg?w=800&amp;tok=8613ee" loading="lazy" title="img_9534.jpeg" alt="img_9534.jpeg" width="800">
</p>

<p>
aluminum base with power supplies mounted, heat sink for mosfet &amp; resistors added
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9552.jpeg?w=800&amp;tok=eeb2fa" loading="lazy" title="img_9552.jpeg" alt="img_9552.jpeg" width="800">
</p>

<p>
aluminum base with power supplies mounted, button panel added
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9581.jpeg?w=800&amp;tok=a058cb" loading="lazy" title="img_9581.jpeg" alt="img_9581.jpeg" width="800">
</p>

<p>
aluminum base, heat sink, aluminum plate to hold electronic boards
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9632.jpeg?w=800&amp;tok=42cede" loading="lazy" title="img_9632.jpeg" alt="img_9632.jpeg" width="800">
</p>

<p>
button panel with potentiometers and push buttons
</p>

<p>
.
</p>

</div>

<h2 id="feedback_loop_ii_25nd_oct_2024_at_alud_festival_barcelona">Feedback Loop II – 25nd Oct 2024 at ALUD Festival, Barcelona</h2>
<div>

<p>
<br>
As part of<strong> <a href="https://crater-lab.org/alud-4/" title="https://crater-lab.org/alud-4/" rel="ugc nofollow">¡Alud! #4</a></strong>, a festival organised by our project partner Crater Lab, which is entirely dedicated to expanded cinema, we presented our first prototype at a so-called feedback loop, a public gathering where makers &amp; experts are having a detailed look at the various technical achievements during the Devices project. All four groups showed their latest version of their <a href="https://www.filmlabs.org/wiki/en/meetings_projects/spectral/start" title="https://www.filmlabs.org/wiki/en/meetings_projects/spectral/start" rel="ugc nofollow">various prototypes</a> in an exhibition kind of set-up. A few participants who could not attend in person, like Zach Poff and Matt McWilliams in the US, were joining the discussion via streaming. The open and hands-on character of the event allowed a direct exchange of feedbacks about technical features and solutions between all participants, on-site as well as online. Due to our logistic restrictions across countries, this was the first opportunity for our research team to see our prototype in a direct, side-by-side comparison with a similar, unmodified projector model with the original 250W halogen bulb, both projecting the same film. It was amazing to see the brightness and versatility of our projector, nevertheless we also observed a few flaws. This is what we found:
</p>
<ul>
<li><p><strong>Brightness: </strong>The projection of our prototype was much brighter compared to the 250W halogen projector</p>
</li>
<li><p><strong>Colours: </strong>Even though our 800W LED only has a CRI of 70, the colours looked saturated and vivid. The often debated importance of the CRI value doesn't seem to be as relevant in projection as it definitely is for scanning and colour grading in post production</p>
</li>
<li><p><strong>Features: </strong>All variable transport functionalities worked like a charm</p>
</li>
<li><p><strong>Optics: </strong>Since we are currently using an obscure condenser lens, we should work out a better optical system that can easily be replicated by anyone who wants to modify their own projector </p>
</li>
<li><p><strong>Mechanics: </strong>The projector seems to be very sensitive to tape splices, even though we took extra care to make sure they are accurate. Also Jan pointed out that he had come across one vintage film roll that didn't even get moved by the claw mechanism. Quick adjustments of the claw position did not solve the problem, we will have to do a complete CLA before we can go ahead. For the final release of our projector, we should also consider including sufficient information how to solve such problems</p>
</li>
<li><p><strong>Projection: </strong>Especially in the comparison with the original 250W halogen projector, we found the projected image flickering too much. In direct comparison, the much dimmer image of the halogen projector looks much smoother. This happens especially when the 800W LED is set to higher brightness. But the virtual number of shutter blades and the virtual shutter angle also play a big role in here</p>
</li>
</ul>

<p>
We discussed the possible reasons for the flicker:
</p>
<ul>
<li><p><strong>Electronics: </strong>Zach Poff suggested that there could be a problem with the output from mosfet. We will have to measure with an oscilloscope whether there are any flaws in the electronics</p>
</li>
<li><p><strong>Sync: </strong>It could be a sync problem between the pull of the claw and the flicker of the LED, especially after the prototype had been shipped in a van over a distance of 1700 kms from Prague to Barcelona. The neodym magnet that is attached to the main shaft, only holds by its own magnetic force. So a microscopic shift of its position on the shaft could have caused a slight jitter in the projection</p>
</li>
<li><p><strong>Human perception:</strong> It is possible that with the brightness of our LED, we may have reached a certain threshold, at which the image flicker appears more apparent to the human eye. Matt McWilliams pointed out that back in the days when drive-in theatres in the US increased the brightness of their projections, they also upgraded from two to three shutter blades to compensate for the occurring flicker</p>
</li>
<li><p> It could be possible that all three reasons may be adding up upon each other and that way cause more flicker</p>
</li>
</ul>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9148_2.jpeg?w=800&amp;tok=d24189" loading="lazy" title="img_9148_2.jpeg" alt="img_9148_2.jpeg" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9151_2.jpeg?w=800&amp;tok=b1355a" loading="lazy" title="img_9151_2.jpeg" alt="img_9151_2.jpeg" width="800">
</p>

<p>
.
</p>

</div>

<h2 id="addressing_flicker_issues_1st_march_2025">Addressing flicker issues – 1st March 2025</h2>
<div>

<p>
After the Feedback Loop in Barcelona we decided to first look into the flicker problems before going ahead with implementing more features in Phase IV. It turned out the the flicker was caused by several issues which were adding up upon each other. One major problem was the misalignment of the projector's pull-down claw mechanism. Due to poor reproduction quality, the service manual for Eiki RT series did not really help, but finally we found an online version of the <a href="http://www.k3camera.com/pdfs/eiki/2009-eiki-nt-nst-service-manual.pdf" title="http://www.k3camera.com/pdfs/eiki/2009-eiki-nt-nst-service-manual.pdf" rel="ugc nofollow">service manual for Eiki NT series</a> which gives very detailed instructions for cam tank adjustments (Page 27–31).
</p>

<p>
Another source for the flicker were minor fluctuations in the pulse output of the Mosfet HY 4306 semiconductor that switches the 800W LED. These fluctuations could be resolved by changing the code that is running the ESP-Wroom-32.
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/whatsapp_image_2025-02-12_at_09.26.37.jpeg?w=800&amp;tok=a36dea" loading="lazy" title="whatsapp_image_2025-02-12_at_09.26.37.jpeg" alt="whatsapp_image_2025-02-12_at_09.26.37.jpeg" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/whatsapp_image_2025-02-12_at_09.26.37_1_.jpeg?w=800&amp;tok=690ea6" loading="lazy" title="whatsapp_image_2025-02-12_at_09.26.37_1_.jpeg" alt="whatsapp_image_2025-02-12_at_09.26.37_1_.jpeg" width="800">
</p>

<p>
In order to get a real life impression of the projector's projection quality and capacities we decided that we need to see the projection in direct comparison with reference 16mm film projectors. We met at a screening room in Berlin and set up four projectors side-by-side. We fixed further minor mechanical issues and projected two (almost) equal film prints of a well preserved corporate film about land mapping and road construction.
</p>

<p>
Later we used a lux meter to measure the projection brightness at a distance of approx. 10 meter from the screen All projectors were running at their native 24 fps frame rate and equipped with an Isco Vario Kiptaron 1.3 / 35-65mm lens:
</p>
<ul>
<li><p><strong>State-of-the-Art 16mm Prototype</strong> – LED 800 W – 2 virtual blades                           530 Lux   (white with minimal pink tint?)</p>
</li>
<li><p><strong>Eiki EX-2000 N2</strong> – Xenon lamp 350 W – 2 shutter blades                                          480 Lux   (green tint)</p>
</li>
<li><p><strong>Eiki SSL-2 (Super Slim Slot Load)</strong> – halogen lamp 250 W – 2 shutter blades         410 Lux   (yellow tint)</p>
</li>
<li><p><strong>Eiki RT-2</strong> – halogen lamp 200 W – 2 shutter blades                                                   305 Lux   (orange tint)</p>
</li>
</ul>

<p>
Even though it helped using two (almost) equal film prints of the same film for comparison, it turned out that both prints were very different in colour tint and sharpness. Swapping prints and lenses systematically finally helped us understand that our prototype delivers a slightly brighter, sharper and much whiter image compared to the Eiki EX-2000 N2 Xenon Projector.
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/undefined/img_6144.jpg?w=800&amp;tok=86ae1a" loading="lazy" title="left: Prototype LED 800W - right: Eiki Xenon 350W" alt="left: Prototype LED 800W - right: Eiki Xenon 350W" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_6137.jpg?w=800&amp;tok=a1465f" loading="lazy" title="img_6137.jpg" alt="img_6137.jpg" width="800">
</p>

<p>
<a href="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9645.jpg" title="en:meetings_projects:spectral:laborberlin16mmprojector:img_9645.jpg"><img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9645.jpg?w=800&amp;tok=382864" loading="lazy" title="img_9645.jpg" alt="img_9645.jpg" width="800"></a>
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9646.jpg?w=800&amp;tok=c82a40" loading="lazy" title="img_9646.jpg" alt="img_9646.jpg" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9647.jpg?w=800&amp;tok=437b81" loading="lazy" title="img_9647.jpg" alt="img_9647.jpg" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_9654.jpg?w=800&amp;tok=d00dce" loading="lazy" title="img_9654.jpg" alt="img_9654.jpg" width="800">
</p>

<p>
<img src="https://www.filmlabs.org/wiki/_media/en/meetings_projects/spectral/laborberlin16mmprojector/img_6140.jpg?w=800&amp;tok=c9ac48" loading="lazy" title="img_6140.jpg" alt="img_6140.jpg" width="800">
</p>

<p>
Videos showing our projector in comparison with Eiki EX-2000 N2 Xenon:
</p>

<p>
<em> <a href="https://vimeo.com/1061820819" title="https://vimeo.com/1061820819" rel="ugc nofollow">State-of-the-Art 16mm Projector with LED 800W vs. Eiki EX-2000 N2 with 350W Xenon bulb</a></em>
</p>

<p>
<em> <a href="https://vimeo.com/1061820427" title="https://vimeo.com/1061820427" rel="ugc nofollow">Eiki EX-2000 N2 with 350W Xenon bulb vs. State-of-the-Art 16mm Projector with LED 800W</a> </em>
</p>

<p>
<em>.</em>
</p>

</div>




                    <!-- wikipage stop -->
                                    </div></div>]]></description>
        </item>
    </channel>
</rss>