<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 03 Sep 2024 16:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Steve Ballmer's incorrect binary search interview question (108 pts)]]></title>
            <link>https://blog.jgc.org/2024/09/steve-ballmers-binary-search-interview.html</link>
            <guid>41434637</guid>
            <pubDate>Tue, 03 Sep 2024 13:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jgc.org/2024/09/steve-ballmers-binary-search-interview.html">https://blog.jgc.org/2024/09/steve-ballmers-binary-search-interview.html</a>, See on <a href="https://news.ycombinator.com/item?id=41434637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-8452693863720025641" itemprop="description articleBody">
<p>In this short video <a href="https://en.wikipedia.org/wiki/Steve_Ballmer">Steve Ballmer</a> talks about a puzzle question he would ask candidates interviewing at Microsoft. Solving it is based on <a href="https://en.wikipedia.org/wiki/Binary_search">binary search</a> and the <a href="https://en.wikipedia.org/wiki/Expected_value">expected value</a>.</p><p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/svCYbkS0Sjk" width="320" youtube-src-id="svCYbkS0Sjk"></iframe></p><p>Here's what he says: "<i>I'm thinking of a number between 1 and 100. You can guess, after each guess I'll tell you whether high or low. You get it the first guess I'll give you five bucks. Four bucks, three, two, one, zero, you pay me a buck, you pay me two, you pay me three</i>".&nbsp;</p><p>The question is "<i>Should you accept to play this game?</i>". In the interview, Ballmer states that the answer is "No" for two reasons: firstly, because he can pick numbers that'll be the most difficult for you to determine, secondly because the expected value of the game (assuming Ballmer chooses randomly) is negative: you end up paying Ballmer.</p><p>He's right on the first count. If you follow a binary search strategy (which will be optimal if he's choosing randomly) and he chooses one of&nbsp;2, 5, 8, 11, 14, 17, 20, 22, 24, 27, 30, 33, 36, 39, 42, 45, 47, 49, 52, 55, 58, 61, 64, 67, 70, 72, 74, 77, 80, 83, 85, 87, 90, 93, 96, 98 or 100 then you owe him $1. For all other numbers you get $0 (if he chose&nbsp;1, 4, 7, 10, 13, 16, 19, 23, 26, 29, 32, 35, 38, 41, 44, 48, 51, 54, 57, 60, 63, 66, 69, 73, 76, 79, 82, 86, 89, 92, 95 or 99) or a positive outcome (some of his money!).</p><p>In the video above Ballmer chooses 59 which a binary search strategy would have found in 5 steps resulting in the interviewer, Emily Chang, winning $1. She was actually pretty close to doing that. The binary search steps would be 50, 75,&nbsp;62, 56, 59 and she guessed 50, 75, 60, 55, 57, 58, 59.&nbsp;</p><p>On the second count (Baller implies the expected value is negative), if he's choosing randomly, then he's wrong. The expected value is $0.20 (calculated discretely using the code below). The code calculates the number of guesses for each value and an overall expected value assuming Ballmer chooses randomly.</p><p><span>use strict;<br></span><span>use warnings;<br></span><span><br>my @v = (0, 5, 4, 3, 2, 1, 0, -1, -2);<br></span><span><br>my $ev = 0;<br></span><span>my $ec = 0;<br></span><span><br>my @range = (1..100);<br></span><span><br>foreach my $r (@range) {<br></span><span>&nbsp; &nbsp; my $l = $range[0];<br></span><span>&nbsp; &nbsp; my $h = $range[$#range];<br></span><span><br>&nbsp; &nbsp; my $s = 0;<br></span><span>&nbsp; &nbsp; while (1) {<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; $s += 1;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; my $g = int(($l + $h)/2);<br></span><span><br>&nbsp; &nbsp; &nbsp; &nbsp; if ($r == $g) {<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print "$r found in $s steps (" . dollar($v[$s]) . ")\n";<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $ev += $v[$s];<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $ec += 1;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; last;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; }<br></span><span><br>&nbsp; &nbsp; &nbsp; &nbsp; if ($g &lt; $r) {<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $l = $g + 1;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; next;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; }<br></span><span><br>&nbsp; &nbsp; &nbsp; &nbsp; if ($g &gt; $r) {<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $h = $g - 1;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; next;<br></span><span>&nbsp; &nbsp; &nbsp; &nbsp; }<br></span><span>&nbsp; &nbsp; }<br></span><span>}<br></span><span><br>$ev /= $ec;<br></span><span>print "Game expected value is " . dollar($ev) . "\n";<br></span><span><br>sub dollar {</span></p><p><span>&nbsp; &nbsp; my ($d) = @_;<br></span><span><br>&nbsp; &nbsp; my $f = (int($d) == $d)?'%d':'%.2f';<br></span><span>&nbsp; &nbsp; return sprintf("%s\$$f", ($d&lt;0)?'-':'', abs($d));<br></span><span>}</span></p><p><span>This chart shows the expected winnings (or loss) depending on the number Ballmer chooses. The shape of the binary search can be seen in the chart itself.</span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiElRkalAf71qPuh9a1t0yhsoAO5ZPQ-mR3NpSBwwuYpdsbkASynXT_JOwyrOkzWUNJ1ZWGnArmU4tKHEQpsMVxe9s5h7qdXgZRaMprV8dV2X_0-dXG195Dsi7S3hnJknshVyiRIgKUXCRcy4RZcDv0tI_bWQd6OwzkdEfNavHTm8HV4NH4ZP4itg/s1800/bs-1.png"><img data-original-height="702" data-original-width="1800" height="250" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiElRkalAf71qPuh9a1t0yhsoAO5ZPQ-mR3NpSBwwuYpdsbkASynXT_JOwyrOkzWUNJ1ZWGnArmU4tKHEQpsMVxe9s5h7qdXgZRaMprV8dV2X_0-dXG195Dsi7S3hnJknshVyiRIgKUXCRcy4RZcDv0tI_bWQd6OwzkdEfNavHTm8HV4NH4ZP4itg/w640-h250/bs-1.png" width="640"></a></p><p>A different way to think about the expected value and binary search is as follows:</p><p>1. On the first guess you choose 50 and win $5 with a probability of 1/100</p><p>2. On the second guess you choose 25 or 75 and win $4 with a probability of 2/100</p><p>3. On the third guess you choose 12, 37, 62 or 88 and win $3 with a probability of 4/100</p><p>4. On the fourth guess you choose 6, 18, 31, 43, 56, 68, 81 or 94 and win $2 with a probability of 8/100</p><p>5. And so on.</p><p>The gives the expected value as 5 * 1/100 + 4 * 2/100 + 3 * 4/100 + 2 * 8/100 + 1 * 16/100 + 0 * 32/100 + -1 * 37/100 (note the last term is the remaining possible numbers having reached the end of the binary search). That's 0.2.</p><p><i>Why was Ballmer wrong?</i></p><p>One possibility is that he didn't mean to have the $0 for 6 guesses. If he'd said "<i>I'm thinking of a number between 1 and 100. You can guess, after each guess I'll tell you whether high or low. You get it the first guess I'll give you five bucks. Four bucks, three, two, one, you pay me a buck, you pay me two, you pay me three</i>" then the expected value is -$0.49.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Economist Eugene Fama: 'Efficient markets is a hypothesis. It's not reality (143 pts)]]></title>
            <link>https://www.ft.com/content/ec06fe06-6150-4f39-8175-37b9b61a5520</link>
            <guid>41432086</guid>
            <pubDate>Tue, 03 Sep 2024 07:01:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/ec06fe06-6150-4f39-8175-37b9b61a5520">https://www.ft.com/content/ec06fe06-6150-4f39-8175-37b9b61a5520</a>, See on <a href="https://news.ycombinator.com/item?id=41432086">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offers-a4391590-87d1-4469-aff5-2bc724749a14" data-component="heroOffer" data-component-unique-name="Hero offers"><section data-o-grid-colspan="12 L6"><h2><blockquote>Economist Eugene Fama: ‘Efficient markets is a hypothesis. It’s not reality’</blockquote></h2></section><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Try unlimited access</span></h2><h2><strong><span>Only </span><span>CHF1</span><span> for 4 weeks</span></strong></h2></p><p><span>Then </span><span>CHF85</span><span> per month.
Complete digital access to quality FT journalism on any device. 
Cancel anytime during your trial.</span></p></div></div><div id="recommendedOffers-Recommended Offers-cabac25c-8e19-4227-afb6-39f063c82295" data-component="recommendedOffers" data-component-unique-name="Recommended Offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_standard.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Standard Digital</h3></p></div><p><span>CHF55</span><span> per month</span></p><p><span>Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF85</span><span> per month</span></p><p><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_bundle.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF379</span><span> for 3 months</span></p><p><span>Billed Yearly at </span><span>CHF1515</span><span>. Complete digital access plus the FT newspaper delivered Monday-Saturday.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription Options Offers API"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=ec06fe06-6150-4f39-8175-37b9b61a5520">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diffusion Is Spectral Autoregression (166 pts)]]></title>
            <link>https://sander.ai/2024/09/02/spectral-autoregression.html</link>
            <guid>41431293</guid>
            <pubDate>Tue, 03 Sep 2024 04:33:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sander.ai/2024/09/02/spectral-autoregression.html">https://sander.ai/2024/09/02/spectral-autoregression.html</a>, See on <a href="https://news.ycombinator.com/item?id=41431293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>A bit of signal processing swiftly reveals that diffusion models and autoregressive models aren’t all that different: <strong>diffusion models of images perform approximate autoregression in the frequency domain!</strong></p>

<p>
This blog post is also available as a <a href="https://colab.research.google.com/drive/1siywvhvl1OxI1UmqRrJHiFUK0M5SHlcx">Python notebook in Google Colab <img src="https://sander.ai/images/colab_logo.png"></a>, with the code used to produce all the plots and animations.</p>

<p>Last year, I wrote a blog post describing various different <a href="https://sander.ai/2023/07/20/perspectives.html">perspectives on diffusion</a>. The idea was to highlight a number of connections between diffusion models and other classes of models and concepts. In recent months, I have given a few talks where I discussed some of these perspectives. My talk at the <a href="https://www.eeml.eu/">EEML 2024 summer school</a> in Novi Sad, Serbia, was recorded and is <a href="https://www.youtube.com/watch?v=9BHQvQlsVdE">available on YouTube</a>. Based on the response I got from this talk, the link between diffusion models and <strong>autoregressive models</strong> seems to be particularly thought-provoking. That’s why I figured it could be useful to explore this a bit further.</p>

<p>In this blog post, I will unpack the above claim, and try to make it obvious that this is the case, at least for visual data. To make things more tangible, I decided to write this entire blog post in the form of <a href="https://colab.research.google.com/drive/1siywvhvl1OxI1UmqRrJHiFUK0M5SHlcx">a Python notebook</a> (using Google Colab). That way, <strong>you can easily reproduce the plots and analyses yourself</strong>, and modify them to observe what happens. I hope this format will also help drive home the point that this connection between diffusion models and autoregressive models is “real”, and not just a theoretical idealisation that doesn’t hold up in practice.</p>

<p>In what follows, I will assume a basic understanding of diffusion models and the core concepts behind them. If you’ve watched the talk I linked above, you should be able to follow along. Alternatively, the <a href="https://sander.ai/2023/07/20/perspectives.html">perspectives on diffusion</a> blog post should also suffice as preparatory reading. Some knowledge of the Fourier transform will also be helpful.</p>

<p>Below is an overview of the different sections of this post. Click to jump directly to a particular section.</p>

<ol>
  <li><em><a href="#iterative-refinement">Two forms of iterative refinement</a></em></li>
  <li><em><a href="#spectral-view">A spectral view of diffusion</a></em></li>
  <li><em><a href="#sound">What about sound?</a></em></li>
  <li><em><a href="#unstable-equilibrium">Unstable equilibrium</a></em></li>
  <li><em><a href="#closing-thoughts">Closing thoughts</a></em></li>
  <li><em><a href="#acknowledgements">Acknowledgements</a></em></li>
  <li><em><a href="#references">References</a></em></li>
</ol>

<h2 id="-two-forms-of-iterative-refinement"><a name="iterative-refinement"></a> Two forms of iterative refinement</h2>

<figure>
  <a href="https://sander.ai/images/jonction.jpg"><img src="https://sander.ai/images/jonction.jpg"></a>
</figure>

<p>Autoregression and diffusion are currently the two dominant generative modelling paradigms. There are many more ways to build generative models: <a href="https://en.wikipedia.org/wiki/Flow-based_generative_model">flow-based models</a> and <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">adversarial models</a> are just two possible alternatives (I discussed a few more in <a href="https://sander.ai/2020/03/24/audio-generation.html#generative-models">an earlier blog post</a>).</p>

<p>Both autoregression and diffusion differ from most of these alternatives, by splitting up the difficult task of generating data from complex distributions into smaller subtasks that are easier to learn. Autoregression does this by casting the data to be modelled into the shape of a sequence, and recursively predicting one sequence element at a time. Diffusion instead works by defining a corruption process that gradually destroys all structure in the data, and training a model to learn to invert this process step by step.</p>

<p>This <strong>iterative refinement</strong> approach to generative modelling is very powerful, because it allows us to construct very deep computational graphs for generation, without having to backpropagate through them during training. Indeed, both autoregressive models and diffusion models learn to perform a single step of refinement at a time – the generative process is not trained end-to-end. It is only when we try to sample from the model that we connect all these steps together, by sequentially performing the subtasks: predicting one sequence element after another in the case of autoregression, or gradually denoising the input step-by-step in the case of diffusion.</p>

<p>Because this underlying iterative approach is common to both paradigms, people have often sought to connect the two. One could frame autoregression as a special case of discrete diffusion, for example, with a corruption process that gradually replaces tokens by “mask tokens” from right to left, eventually ending up with a fully masked sequence. In the next few sections, we will do the opposite, framing diffusion as a special case of autoregression, albeit approximate.</p>

<p>Today, most language models are autoregressive, while most models of images and video are diffusion-based. In many other application domains (e.g. protein design, planning in reinforcement learning, …), diffusion models are also becoming more prevalent. I think this dichotomy, which can be summarised as “autoregression for language, and diffusion for everything else”, is quite interesting. I have <a href="https://sander.ai/2023/01/09/diffusion-language.html">written about it before</a>, and I will have more to say about it in a later section of this post.</p>

<h2 id="-a-spectral-view-of-diffusion"><a name="spectral-view"></a> A spectral view of diffusion</h2>

<figure>
  <a href="https://sander.ai/images/prism.jpg"><img src="https://sander.ai/images/prism.jpg"></a>
</figure>

<h3 id="-image-spectra"><a name="image-spectra"></a> Image spectra</h3>

<p>When diffusion models rose to prominence for image generation, people noticed quite quickly that they tend to produce images in a coarse-to-fine manner. The large-scale structure present in the image seems to be decided in earlier denoising steps, whereas later denoising steps add more and more fine-grained details.</p>

<p>To formalise this observation, we can use signal processing, and more specifically <strong>spectral analysis</strong>. By decomposing an image into its constituent <strong>spatial frequency</strong> components, we can more precisely tease apart its coarse- and fine-grained structure, which correspond to low and high frequencies respectively.</p>

<p>We can use the 2D <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a> to obtain a frequency representation of an image. This representation is invertible, i.e. it contains the same information as the pixel representation – it is just organised in a different way. Like the pixel representation, it is a 2D grid-structured object, with the same width and height as the original image, but the axes now correspond to horizontal and vertical spatial frequencies, rather than spatial positions.</p>

<p>To see what this looks like, let’s take some images and visualise their spectra.</p>

<figure>
  <a href="https://sander.ai/images/plot_image_spectra.png"><img src="https://sander.ai/images/plot_image_spectra.png" alt="Four images from the Imagenette dataset (top), along with their magnitude spectra (middle) and their phase spectra (bottom)."></a>
  <figcaption>Four images from the <a href="https://github.com/fastai/imagenette">Imagenette dataset</a> (top), along with their magnitude spectra (middle) and their phase spectra (bottom).</figcaption>
</figure>

<p>Shown above on the first row are four images from the <a href="https://github.com/fastai/imagenette">Imagenette dataset</a>, a subset of the ImageNet dataset (I picked it because it is relatively fast to load).</p>

<p>The Fourier transform is typically complex-valued, so the next two rows visualise the <em>magnitude</em> and the <em>phase</em> of the spectrum respectively. Because the magnitude varies greatly across different frequencies, its logarithm is shown. The phase is an angle, which varies between \(-\pi\) and \(\pi\). Note that we only calculate the spectrum for the green colour channel – we could calculate it for the other two channels as well, but they would look very similar.</p>

<p>The centre of the spectrum corresponds to the lowest spatial frequencies, and the frequencies increase as we move outward to the edges. This allows us to see where most of the energy in the input signal is concentrated. Note that by default, it is the other way around (low frequencies in the corner, high frequencies in the middle), but <code>np.fft.fftshift</code> allows us to swap these, which yields a much nicer looking visualisation that makes the structure of the spectrum more apparent.</p>

<p>A lot of interesting things can be said about the phase structure of natural images, but in what follows, we will primarily focus on the magnitude spectrum. The square of the magnitude is the <em>power</em>, so in practice we often look at the <em>power spectrum</em> instead. Note that the logarithm of the power spectrum is simply that of the magnitude spectrum, multiplied by two.</p>

<p>Looking at the spectra, we now have a more formal way to reason about different feature scales in images, but that still doesn’t explain why diffusion models exhibit this coarse-to-fine behaviour. To see why this happens, we need to examine what a typical image spectrum looks like. To do this, we will <strong>make abstraction of the directional nature of frequencies in 2D space</strong>, simply by slicing the spectrum along a certain angle, rotating that slice all around, and then averaging the slices across all rotations. This yields a one-dimensional curve: <strong>the <em>radially averaged power spectral density</em>, or RAPSD</strong>.</p>

<p>Below is an animation that shows individual directional slices of the 2D spectrum on a log-log plot, which are averaged to obtain the RAPSD.</p>

<figure>
  <a href="https://sander.ai/images/image_spectrum.gif"><img src="https://sander.ai/images/image_spectrum.gif" alt="Animation that shows individual directional slices of the 2D spectrum of an image on a log-log plot."></a>
  <figcaption>Animation that shows individual directional slices of the 2D spectrum of an image on a log-log plot.</figcaption>
</figure>

<p>Let’s see what that looks like for the four images above. We will use the <code>pysteps</code> library, which comes with a handy function to calculate the RAPSD in one go.</p>

<figure>
  <a href="https://sander.ai/images/plot_image_rapsd.png"><img src="https://sander.ai/images/plot_image_rapsd.png" alt="Four images from the Imagenette dataset (top), along with their radially averaged spectral power densities (RAPSDs, bottom)."></a>
  <figcaption>Four images from the Imagenette dataset (top), along with their radially averaged spectral power densities (RAPSDs, bottom).</figcaption>
</figure>

<p>The RAPSD is best visualised on a log-log plot, to account for the large variation in scale. We chop off the so-called DC component (with frequency 0) to avoid taking the logarithm of 0.</p>

<p>Another thing this visualisation makes apparent is that the curves are remarkably close to being straight lines. A straight line on a log-log plot implies that there might be a power law lurking behind all of this.</p>

<p>Indeed, this turns out to be the case: <strong>natural image spectra tend to approximately follow a power law</strong>, which means that the power \(P(f)\) of a particular frequency \(f\) is proportional to \(f^{-\alpha}\), where \(\alpha\) is a parameter<sup id="fnref:schaaf" role="doc-noteref"><a href="#fn:schaaf" rel="footnote">1</a></sup> <sup id="fnref:torralba" role="doc-noteref"><a href="#fn:torralba" rel="footnote">2</a></sup> <sup id="fnref:hyvarinen" role="doc-noteref"><a href="#fn:hyvarinen" rel="footnote">3</a></sup>. In practice, \(\alpha\) is often remarkably close to 2 (which corresponds to the spectrum of <a href="https://en.wikipedia.org/wiki/Pink_noise">pink noise</a> in two dimensions).</p>

<p>We can get closer to the “typical” RAPSD by taking the average across a bunch of images (in the log-domain).</p>

<figure>
  <a href="https://sander.ai/images/mean_log_rapsd.png"><img src="https://sander.ai/images/mean_log_rapsd.png" alt="The average of RAPSDs of a set of images in the log-domain."></a>
  <figcaption>The average of RAPSDs of a set of images in the log-domain.</figcaption>
</figure>

<p>As I’m sure you will agree, that is pretty unequivocally a power law!</p>

<p>To estimate the exponent \(\alpha\), we can simply use linear regression in log-log space. Before proceeding however, it is useful to resample our averaged RAPSD so the sample points are linearly spaced in log-log space – otherwise our fit will be dominated by the high frequencies, where we have many more sample points.</p>

<p>We obtain an estimate \(\hat{\alpha} = 2.454\), which is a bit higher than the typical value of 2. As far as I understand, this can be explained by the presence of man-made objects in many of the images we used, because they tend to have smooth surfaces and straight angles, which results in comparatively more low-frequency content and less high-frequency content compared to images of nature. Let’s see what our fit looks like.</p>

<figure>
  <a href="https://sander.ai/images/mean_log_rapsd_fit.png"><img src="https://sander.ai/images/mean_log_rapsd_fit.png" alt="The average of RAPSDs of a set of images in the log-domain (red line), along with a linear fit (dotted black line)."></a>
  <figcaption>The average of RAPSDs of a set of images in the log-domain (red line), along with a linear fit (dotted black line).</figcaption>
</figure>

<h3 id="-noisy-image-spectra"><a name="noisy-spectra"></a> Noisy image spectra</h3>

<p>A crucial aspect of diffusion models is the corruption process, which involves adding Gaussian noise. Let’s see what this does to the spectrum. The first question to ask is: what does the spectrum of noise look like? We can repeat the previous procedure, but replace the image input with standard Gaussian noise. For contrast, we will visualise the spectrum of the noise alongside that of the images from before.</p>

<figure>
  <a href="https://sander.ai/images/mean_log_rapsd_noise.png"><img src="https://sander.ai/images/mean_log_rapsd_noise.png" alt="The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of standard Gaussian noise (blue line)."></a>
  <figcaption>The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of standard Gaussian noise (blue line).</figcaption>
</figure>

<p>The RAPSD of Gaussian noise is also a straight line on a log-log plot; but a horizontal one, rather than one that slopes down. This reflects the fact that <strong>Gaussian noise contains all frequencies in equal measure</strong>. The Fourier transform of Gaussian noise is itself Gaussian noise, so its power must be equal across all frequencies in expectation.</p>

<p>When we add noise to the images and look at the spectrum of the resulting noisy images, we see a hinge shape:</p>

<figure>
  <a href="https://sander.ai/images/mean_log_rapsd_sum.png"><img src="https://sander.ai/images/mean_log_rapsd_sum.png" alt="The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of standard Gaussian noise (blue line) and the average of RAPSDs of their sum (green line)."></a>
  <figcaption>The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of standard Gaussian noise (blue line) and the average of RAPSDs of their sum (green line).</figcaption>
</figure>

<p>Why does this happen? Recall that the <strong>Fourier transform is linear</strong>: the Fourier transform of the sum of two things, is the sum of the Fourier transforms of those things. Because the power of the different frequencies varies across orders of magnitude, <strong>one of the terms in this sum tends to drown out the other</strong>. This is what happens at low frequencies, where the image spectrum dominates, and hence the green curve overlaps with the red curve. At high frequencies on the other hand, the noise spectrum dominates, and the green curve overlaps with the blue curve. In between, there is a transition zone where the power of both spectra is roughly matched.</p>

<p>If we increase the variance of the noise by scaling the noise term, we increase its power, and as a result, its RAPSD will shift upward (which is also a consequence of the linearity of the Fourier transform). This means a smaller part of the image spectrum now juts out above the waterline: <strong>the increasing power of the noise looks like the rising tide!</strong></p>

<figure>
  <a href="https://sander.ai/images/mean_log_rapsd_high_noise.png"><img src="https://sander.ai/images/mean_log_rapsd_high_noise.png" alt="The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of Gaussian noise with variance 16 (blue line) and the average of RAPSDs of their sum (green line)."></a>
  <figcaption>The average of RAPSDs of a set of images in the log-domain (red line), along with the average of RAPSDs of Gaussian noise with variance 16 (blue line) and the average of RAPSDs of their sum (green line).</figcaption>
</figure>

<p>At this point, I’d like to revisit a diagram from the <a href="https://sander.ai/2023/07/20/perspectives.html#autoregressive">perspectives on diffusion blog post</a>, where I originally drew the connection between diffusion and autoregression in frequency space, which is shown below.</p>

<figure>
  <a href="https://sander.ai/images/image_spectra.png"><img src="https://sander.ai/images/image_spectra.png" alt="Magnitude spectra of natural images, Gaussian noise, and noisy images."></a>
  <figcaption>Magnitude spectra of natural images, Gaussian noise, and noisy images.</figcaption>
</figure>

<p>These idealised plots of the spectra of images, noise, and their superposition match up pretty well with the real versions. When I originally drew this, I didn’t actually realise just how closely this reflects reality!</p>

<p>What these plots reveal is an approximate equivalence (in expectation) between adding noise to images, and <strong>low-pass filtering</strong> them. The noise will drown out some portion of the high frequencies, and leave the low frequencies untouched. The variance of the noise determines the <strong>cut-off frequency</strong> of the filter. Note that this is the case only because of the characteristic shape of natural image spectra.</p>

<p>The animation below shows how the spectrum changes as we gradually add more noise, until it eventually overpowers all frequency components, and all image content is gone.</p>

<figure>
  <a href="https://sander.ai/images/rising_tide.gif"><img src="https://sander.ai/images/rising_tide.gif" alt="Animation that shows the changing averaged RAPSD as more and more noise is added to a set of images."></a>
  <figcaption>Animation that shows the changing averaged RAPSD as more and more noise is added to a set of images.</figcaption>
</figure>

<h3 id="-diffusion"><a name="diffuion"></a> Diffusion</h3>

<p>With this in mind, it becomes apparent that the corruption process used in diffusion models is actually gradually filtering out more and more high-frequency information from the input image, and the different time steps of the process correspond to a frequency decomposition: basically an approximate version of the <strong>Fourier transform</strong>!</p>

<p>Since diffusion models themselves are tasked with reversing this corruption process step-by-step, they end up roughly predicting the next higher frequency component at each step of the generative process, given all preceding (lower) frequency components. This is a soft version of <strong>autoregression in frequency space</strong>, or if you want to make it sound fancier, <strong>approximate spectral autoregression</strong>.</p>

<p>To the best of my knowledge, <a href="https://arxiv.org/abs/2206.13397">Rissanen et al. (2022)</a><sup id="fnref:heat" role="doc-noteref"><a href="#fn:heat" rel="footnote">4</a></sup> were the first to apply this kind of analysis to diffusion in the context of generative modelling (see §2.2 in the paper). Their work directly inspired this blog post.</p>

<p>In many popular formulations of diffusion, the corruption process does not just involve adding noise, but also rescaling the input to keep the total variance within a reasonable range (or constant, in the case of variance-preserving diffusion). I have largely ignored this so far, because it doesn’t materially change anything about the intuitive interpretation. Scaling the input simply results in the RAPSD shifting up or down a bit.</p>

<h3 id="-which-frequencies-are-modelled-at-which-noise-levels"><a name="quantitative"></a> Which frequencies are modelled at which noise levels?</h3>

<p>There seems to be a monotonic relationship between noise levels and spatial frequencies (and hence feature scales). Can we characterise this quantitatively?</p>

<p>We can try, but it is important to emphasise that this relationship is only really valid in expectation, averaged across many images: <strong>for individual images, the spectrum will not be a perfectly straight line, and it will not typically be monotonically decreasing</strong>.</p>

<p>Even if we ignore all that, the “elbow” of the hinge-shaped spectrum of a noisy image is not very sharp, so it is clear that there is quite a large transition zone where we cannot unequivocally say that a particular frequency is dominated by either signal or noise. So this is, at best, a very smooth approximation to the “hard” autoregression used in e.g. large language models.</p>

<p>Keeping all of that in mind, let us construct a mapping from noise levels to frequencies for a particular diffusion process and a particular image distribution, by choosing a signal-to-noise ratio (SNR) threshold, below which we will consider the signal to be undetectable. This choice is quite arbitrary, and we will just have to choose a value and stick with it. We can choose 1 to keep things simple, which means that we consider the signal to be detectable if its power is equal to or greater than the power of the noise.</p>

<p>Consider a Gaussian diffusion process for which \(\mathbf{x}_t = \alpha(t)\mathbf{x}_0 + \sigma(t) \mathbf{\varepsilon}\), with \(\mathbf{x}_0\) an example from the data distribution, and \(\mathbf{\varepsilon}\) standard Gaussian noise.</p>

<p>Let us define \(\mathcal{R}[\mathbf{x}](f)\) as the RAPSD of an image \(\mathbf{x}\) evaluated at frequency \(f\). We will call the SNR threshold \(\tau\). If we consider a particular time step \(t\), then assuming the RAPSD is monotonically decreasing, we can define the <strong>maximal detectable frequency</strong> \(f_\max\) at this time step in the process as the maximal value of \(f\) for which:</p><p>

\[\mathcal{R}[\alpha(t)\mathbf{x}_0](f) &gt; \tau \cdot \mathcal{R}[\sigma(t)\mathbf{\varepsilon}](f).\]

</p><p>Recall that the Fourier transform is a linear operator, and \(\mathcal{R}\) is a radial average of the square of its magnitude. Therefore, scaling the input to \(\mathcal{R}\) by a real value means the output gets scaled by its square. We can use this to simplify things:</p><p>

\[\mathcal{R}[\mathbf{x}_0](f) &gt; \tau \cdot \frac{\sigma(t)^2}{\alpha(t)^2} \mathcal{R}[\mathbf{\varepsilon}](f).\]

</p><p>We can further simplify this by noting that \(\forall f: \mathcal{R}[\mathbf{\varepsilon}](f) = 1\):</p><p>

\[\mathcal{R}[\mathbf{x}_0](f) &gt; \tau \cdot \frac{\sigma(t)^2}{\alpha(t)^2}.\]

</p><p>To construct such a mapping in practice, we first have to choose a diffusion process, which gives us the functional form of \(\sigma(t)\) and \(\alpha(t)\). To keep things simple, we can use the rectified flow<sup id="fnref:rectifiedflow" role="doc-noteref"><a href="#fn:rectifiedflow" rel="footnote">5</a></sup> / flow matching<sup id="fnref:flowmatching" role="doc-noteref"><a href="#fn:flowmatching" rel="footnote">6</a></sup> process, as used in Stable Diffusion 3<sup id="fnref:sd3" role="doc-noteref"><a href="#fn:sd3" rel="footnote">7</a></sup>, for which \(\sigma(t) = t\) and \(\alpha(t) = 1 - t\). Combined with \(\tau = 1\), this yields:</p><p>

\[\mathcal{R}[\mathbf{x}_0](f) &gt; \left(\frac{t}{1 - t}\right)^2.\]

</p><p>With these choices, we can now determine the shape of \(f_\max(t)\) and visualise it.</p>

<figure>
  <a href="https://sander.ai/images/max_detectable_frequency.png"><img src="https://sander.ai/images/max_detectable_frequency.png" alt="Maximum detectable frequency as a function of diffusion time, for a given set of images and the diffusion process used in rectified flow and flow matching formalisms."></a>
  <figcaption>Maximum detectable frequency as a function of diffusion time, for a given set of images and the diffusion process used in rectified flow and flow matching formalisms.</figcaption>
</figure>

<p>The frequencies here are relative: if the bandwidth of the signal is 1, then 0.5 corresponds to the <a href="https://en.wikipedia.org/wiki/Nyquist_frequency">Nyquist frequency</a>, i.e. the maximal frequency that is representable with the given bandwidth.</p>

<p>Note that all representable frequencies are detectable at time steps near 0. As \(t\) increases, so does the noise level, and hence \(f_\max\) starts dropping, until it eventually reaches 0 (no detectable signal frequencies are left) close to \(t = 1\).</p>

<h2 id="-what-about-sound"><a name="sound"></a> What about sound?</h2>

<figure>
  <a href="https://sander.ai/images/mixer.jpg"><img src="https://sander.ai/images/mixer.jpg"></a>
</figure>

<p>All of the analysis above hinges on the fact that spectra of natural images typically follow a power law. Diffusion models have also been used to generate audio<sup id="fnref:wavegrad" role="doc-noteref"><a href="#fn:wavegrad" rel="footnote">8</a></sup> <sup id="fnref:diffwave" role="doc-noteref"><a href="#fn:diffwave" rel="footnote">9</a></sup>, which is the other main perceptual modality besides the visual. A very natural question to ask is whether the same interpretation makes sense in the audio domain as well.</p>

<p>To establish that, we will grab a dataset of typical audio recordings that we might want to build a generative model of: speech and music.</p>

<figure>
    <audio controls="" src="https://sander.ai/files/audio_clip1.wav"><a href="https://sander.ai/files/audio_clip1.wav">Audio clip 1</a></audio>
    <a href="https://sander.ai/images/spectrogram_clip1.png"><img src="https://sander.ai/images/spectrogram_clip1.png" alt="Magnitude spectrogram for audio clip 1."></a>
    <audio controls="" src="https://sander.ai/files/audio_clip2.wav"><a href="https://sander.ai/files/audio_clip2.wav">Audio clip 2</a></audio>
    <a href="https://sander.ai/images/spectrogram_clip2.png"><img src="https://sander.ai/images/spectrogram_clip2.png" alt="Magnitude spectrogram for audio clip 2."></a>
    <audio controls="" src="https://sander.ai/files/audio_clip3.wav"><a href="https://sander.ai/files/audio_clip3.wav">Audio clip 3</a></audio>
    <a href="https://sander.ai/images/spectrogram_clip3.png"><img src="https://sander.ai/images/spectrogram_clip3.png" alt="Magnitude spectrogram for audio clip 3."></a>
    <audio controls="" src="https://sander.ai/files/audio_clip4.wav"><a href="https://sander.ai/files/audio_clip4.wav">Audio clip 4</a></audio>
    <a href="https://sander.ai/images/spectrogram_clip4.png"><img src="https://sander.ai/images/spectrogram_clip4.png" alt="Magnitude spectrogram for audio clip 4."></a>
    <figcaption>Four audio clips from the <a href="https://www.kaggle.com/datasets/lnicalo/gtzan-musicspeech-collection">GTZAN music/speech dataset</a>, and their corresponding spectrograms.</figcaption>
</figure>

<p>Along with each audio player, a <em>spectrogram</em> is shown: this is a time-frequency representation of the sound, which is obtained by applying the Fourier transform to short overlapping windows of the waveform and stacking the resulting magnitude vectors together in a 2D matrix.</p>

<p>For the purpose of comparing the spectrum of sound with that of images, we will use the 1-dimensional analogue of the RAPSD, which is simply the squared magnitude of the 1D Fourier transform.</p>

<figure>
  <a href="https://sander.ai/images/plot_sound_spectra.png"><img src="https://sander.ai/images/plot_sound_spectra.png" alt="Magnitude spectra of four audio clips from the GTZAN music/speech dataset."></a>
  <figcaption>Magnitude spectra of four audio clips from the <a href="https://www.kaggle.com/datasets/lnicalo/gtzan-musicspeech-collection">GTZAN music/speech dataset</a>.</figcaption>
</figure>

<p>These are a lot noisier than the image spectra, which is not surprising as these are not averaged over directions, like the RAPSD is. But aside from that, they don’t really look like straight lines either – the power law shape is nowhere to be seen!</p>

<p>I won’t speculate about why images exhibit this behaviour and sound seemingly doesn’t, but it is certainly interesting (feel free to speculate away in the comments!). To get a cleaner view, we can again average the spectra of many clips in the log domain, as we did with the RAPSDs of images.</p>

<figure>
  <a href="https://sander.ai/images/mean_log_spec.png"><img src="https://sander.ai/images/mean_log_spec.png" alt="The average of magnitude spectra of a set of audio clips the log-domain."></a>
  <figcaption>The average of magnitude spectra of a set of audio clips the log-domain.</figcaption>
</figure>

<p>Definitely not a power law. More importantly, it is not monotonic, so adding progressively more Gaussian noise to this does not obfuscate frequencies in descending order: <strong>the “diffusion is just spectral autoregression” meme does not apply to audio waveforms!</strong></p>

<p>The average spectrum of our dataset exhibits a peak around 300-400 Hz. This is not too far off the typical spectrum of <a href="https://en.wikipedia.org/wiki/Colors_of_noise#Green_noise">green noise</a>, which has more energy in the region of 500 Hz. Green noise is supposed to sound like “the background noise of the world”.</p>

<figure>
  <a href="https://sander.ai/images/rising_tide_sound.gif"><img src="https://sander.ai/images/rising_tide_sound.gif" alt="Animation that shows the changing averaged magnitude spectrum as more and more noise is added to a set of audio clips."></a>
  <figcaption>Animation that shows the changing averaged magnitude spectrum as more and more noise is added to a set of audio clips.</figcaption>
</figure>

<p>As the animation above shows, the different frequencies present in audio signals still get filtered out gradually from least powerful to most powerful, because the spectrum of Gaussian noise is still flat, just like in the image domain. But as the audio spectrum does not monotonically decay with increasing frequency, the order is not monotonic in terms of the frequencies themselves.</p>

<p>What does this mean for diffusion in the waveform domain? That’s not entirely clear to me. It certainly makes the link with autoregressive models weaker, but I’m not sure if there are any negative implications for generative modelling performance.</p>

<p>One observation that does perhaps indicate that this is the case, is that a lot of diffusion models of audio described in the literature <strong>do not operate directly in the waveform domain</strong>. It is quite common to first extract some form of spectrogram (as we did earlier), and perform diffusion in that space, essentially treating it like an image<sup id="fnref:hawthorne" role="doc-noteref"><a href="#fn:hawthorne" rel="footnote">10</a></sup> <sup id="fnref:riffusion" role="doc-noteref"><a href="#fn:riffusion" rel="footnote">11</a></sup> <sup id="fnref:edmsound" role="doc-noteref"><a href="#fn:edmsound" rel="footnote">12</a></sup>. Note that spectrograms are a somewhat lossy representation of sound, because <a href="https://sander.ai/2020/03/24/audio-generation.html#why-waveforms">phase information is typically discarded</a>.</p>

<p>To understand the implications of this for diffusion models, we will extract <strong>log-scaled mel-spectrograms</strong> from the sound clips we have used before. The <a href="https://en.wikipedia.org/wiki/Mel_scale">mel scale</a> is a nonlinear frequency scale which is intended to be perceptually uniform, and which is very commonly used in spectral analysis of sound.</p>

<p>Next, we will interpret these spectrograms as images and look at their spectra. Taking the spectrum of a spectrum might seem odd – some of you might even suggest that it is pointless, because the Fourier transform is its own inverse! But note that there are a few nonlinear operations happening in between: taking the magnitude (discarding the phase information), mel-binning and log-scaling. As a result, this second Fourier transform doesn’t just undo the first one.</p>

<figure>
  <a href="https://sander.ai/images/plot_sound_melspec_rapsd.png"><img src="https://sander.ai/images/plot_sound_melspec_rapsd.png" alt="RAPSDs of mel-spectrograms of four audio clips from the GTZAN music/speech dataset."></a>
  <figcaption>RAPSDs of mel-spectrograms of four audio clips from the <a href="https://www.kaggle.com/datasets/lnicalo/gtzan-musicspeech-collection">GTZAN music/speech dataset</a>.</figcaption>
</figure>

<p>It seems like the power law has resurfaced! We can look at the average in the log-domain again to get a smoother curve.</p>

<figure>
  <a href="https://sander.ai/images/mean_log_melspec_rapsd.png"><img src="https://sander.ai/images/mean_log_melspec_rapsd.png" alt="The average of RAPSDs of mel-spectrograms of a set of sound clips in the log-domain (red line), along with a linear fit (dotted black line)."></a>
  <figcaption>The average of RAPSDs of mel-spectrograms of a set of sound clips in the log-domain (red line), along with a linear fit (dotted black line).</figcaption>
</figure>

<p>I found this pretty surprising. I actually used to object quite strongly to the idea of treating spectrograms as images, as in this tweet in response to <a href="https://en.wikipedia.org/wiki/Riffusion">Riffusion</a>, a variant of Stable Diffusion finetuned on spectrograms:</p>

<blockquote><div lang="en" dir="ltr"><p>Me: "NOOO, you can't just treat spectrograms as images, the frequency and time axes have completely different semantics, there is no locality in frequency and ..."</p><p>These guys: "Stable diffusion go brrr" <a href="https://t.co/Akv8aZl8Rv">https://t.co/Akv8aZl8Rv</a></p></div>— Sander Dieleman (@sedielem) <a href="https://twitter.com/sedielem/status/1603412454427574279?ref_src=twsrc%5Etfw">December 15, 2022</a></blockquote>


<p>… but I have always had to concede that it seems to work pretty well in practice, and perhaps the fact that spectrograms exhibit power-law spectra is one reason why.</p>

<p>There is also an interesting link with <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">mel-frequency cepstral coefficients (MFCCs)</a>, a popular feature representation for speech and music processing which predates the advent of deep learning. These features are constructed by taking the <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">discrete cosine transform (DCT)</a> of a mel-spectrogram. The resulting spectrum-of-a-spectrum is often referred to as the <strong>cepstrum</strong>.</p>

<p>So with this approach, perhaps the meme applies to sound after all, albeit with a slight adjustment: <strong>diffusion on spectrograms is just cepstral autoregression</strong>.</p>

<h2 id="-unstable-equilibrium"><a name="unstable-equilibrium"></a> Unstable equilibrium</h2>

<figure>
  <a href="https://sander.ai/images/spinningtop.jpg"><img src="https://sander.ai/images/spinningtop.jpg"></a>
</figure>

<p>So far, we have talked about a spectral perspective on diffusion, but we have not really discussed how it can be used to explain why diffusion works so well for images. The fact that this interpretation is possible for images, but not for some other domains, does not automatically imply that the method should also work better.</p>

<p>However, it does mean that the diffusion loss, which is a weighted average across all noise levels, is also implicitly a weighted average over all spatial frequencies in the image domain. Being able to individually weight these frequencies in the loss according to their relative importance is key, because the sensitivity of the human visual system to particular frequencies varies greatly. <strong>This effectively makes the diffusion training objective a kind of perceptual loss</strong>, and I believe it largely explains the success of diffusion models in the visual domain (together with <a href="https://sander.ai/2023/08/28/geometry.html">classifier-free guidance</a>).</p>

<p>Going beyond images, one could use the same line of reasoning to try and understand why diffusion models <em>haven’t</em> really caught on in the domain of language modelling so far (I wrote more about this <a href="https://sander.ai/2023/01/09/diffusion-language.html">last year</a>). The interpretation in terms of a frequency decomposition is not really applicable there, and hence being able to change the relative weighting of noise levels in the loss doesn’t quite have the same impact on the quality of generated outputs.</p>

<p>For language modelling, autoregression is currently the dominant modelling paradigm, and while diffusion-based approaches have been making inroads recently<sup id="fnref:ratios" role="doc-noteref"><a href="#fn:ratios" rel="footnote">13</a></sup> <sup id="fnref:sahoo" role="doc-noteref"><a href="#fn:sahoo" rel="footnote">14</a></sup> <sup id="fnref:shi" role="doc-noteref"><a href="#fn:shi" rel="footnote">15</a></sup>, a full-on takeover does not look like it is in the cards in the short term.</p>

<p>This results in the following status quo: <strong>we use autoregression for language, and we use diffusion for pretty much everything else</strong>. Of course, I realise that I have just been arguing that these two approaches are not all that different in spirit. But in practice, their implementations can look quite different, and a lot of knowledge and experience that practitioners have built up is specific to each paradigm.</p>

<p>To me, this feels like an <strong>unstable equilibrium, because the future is multimodal</strong>. We will ultimately want models that natively understand language, images, sound and other modalities mixed together. Grafting these two different modelling paradigms together to construct multimodal models is effective to some extent, and certainly interesting from a research perspective, but it brings with it an increased level of complexity (i.e. having to master two different modelling paradigms) which I don’t believe practitioners will tolerate in the long run.</p>

<p>So in the longer term, it seems plausible that we could go back to using autoregression across all modalities, perhaps borrowing some ideas from diffusion in the process<sup id="fnref:var" role="doc-noteref"><a href="#fn:var" rel="footnote">16</a></sup> <sup id="fnref:arnovq" role="doc-noteref"><a href="#fn:arnovq" rel="footnote">17</a></sup>. Alternatively, we might figure out how to build multimodal diffusion models for all modalities, including language. I don’t know which it is going to be, but both of those outcomes ultimately seem more likely than the current situation persisting.</p>

<p>One might ask, if diffusion is really just approximate autoregression in frequency space, why not just do exact autoregression in frequency space instead, and maybe that will work just as well? That would mean we can use autoregression across all modalities, and resolve the “instability” in one go. <a href="https://arxiv.org/abs/2103.03841">Nash et al. (2021)</a><sup id="fnref:dctransformer" role="doc-noteref"><a href="#fn:dctransformer" rel="footnote">18</a></sup>, <a href="https://arxiv.org/abs/2404.02905">Tian et al. (2024)</a><sup id="fnref:var:1" role="doc-noteref"><a href="#fn:var" rel="footnote">16</a></sup> and <a href="https://arxiv.org/abs/2406.19997">Mattar et al. (2024)</a><sup id="fnref:wavelets" role="doc-noteref"><a href="#fn:wavelets" rel="footnote">19</a></sup> explore this direction.</p>

<p>There is a good reason not to take this shortcut, however: the diffusion sampling procedure is exceptionally flexible, in ways that autoregressive sampling is not. For example, the number of sampling steps can be chosen at test time (this isn’t impossible for autoregressive models, but it is much less straightforward to achieve). This flexibility also enables <a href="https://sander.ai/2024/02/28/paradox.html">various distillation methods</a> to reduce the number of steps required, and <a href="https://sander.ai/2023/08/28/geometry.html">classifier-free guidance</a> to improve sample quality. Before we do anything rash and ditch diffusion altogether, we will probably want to figure out a way to avoid having to give up some of these benefits.</p>

<h2 id="-closing-thoughts"><a name="closing-thoughts"></a> Closing thoughts</h2>

<figure>
  <a href="https://sander.ai/images/lake_sunset.jpg"><img src="https://sander.ai/images/lake_sunset.jpg"></a>
</figure>

<p>When I first had a closer look at the spectra of real images myself, I realised that the link between diffusion models and autoregressive models is even stronger than I had originally thought – in the image domain, at least. This is ultimately why I decided to write this blog post in <a href="https://colab.research.google.com/drive/1siywvhvl1OxI1UmqRrJHiFUK0M5SHlcx">a notebook</a>, to make it easier for others to see this for themselves as well. More broadly speaking, I find that learning by “doing” has a much more lasting effect than learning by reading, and hopefully making this post interactive can help with that.</p>

<p>There are of course many other ways to connect the two modelling paradigms of diffusion and autoregression, which I won’t go into here, but it is becoming a rather popular topic of inquiry<sup id="fnref:rolling" role="doc-noteref"><a href="#fn:rolling" rel="footnote">20</a></sup> <sup id="fnref:fifo" role="doc-noteref"><a href="#fn:fifo" rel="footnote">21</a></sup> <sup id="fnref:forcing" role="doc-noteref"><a href="#fn:forcing" rel="footnote">22</a></sup>.</p>

<p>If you enjoyed this post, I strongly recommend also reading <a href="https://arxiv.org/abs/2206.13397">Rissanen et al. (2022)</a>’s paper on generative modelling with inverse heat dissipation<sup id="fnref:heat:1" role="doc-noteref"><a href="#fn:heat" rel="footnote">4</a></sup>, which inspired it.</p>

<p>This blog-post-in-a-notebook was an experiment, so any feedback on the format is very welcome! It’s a bit more work, but hopefully some readers will derive some benefit from it. If there are enough of you, perhaps I will do more of these in the future. <strong>Please share your thoughts in the comments!</strong></p>

<p>To wrap up, below are some low-effort memes I made when I should have been working on this blog post instead.</p>

<blockquote><p lang="en" dir="ltr">The interpretation of diffusion as autoregression in the frequency domain seems to be stirring up a lot of thought! (I may or may not have a new blog post in the works 🧐) <a href="https://t.co/XSxP27pKSt">pic.twitter.com/XSxP27pKSt</a></p>— Sander Dieleman (@sedielem) <a href="https://twitter.com/sedielem/status/1820233922287919263?ref_src=twsrc%5Etfw">August 4, 2024</a></blockquote>


<blockquote><p lang="en" dir="ltr">It's so much easier to tweet low-effort memes which assert that diffusion is just autoregression in frequency space, than it is to write a blog post about it 🤷 (but I'm doing both!) <a href="https://t.co/snLQavtZBf">pic.twitter.com/snLQavtZBf</a></p>— Sander Dieleman (@sedielem) <a href="https://twitter.com/sedielem/status/1826728256542052800?ref_src=twsrc%5Etfw">August 22, 2024</a></blockquote>




<p><em>If you would like to cite this post in an academic context, you can use this BibTeX snippet:</em></p>

<div><pre><code>@misc{dieleman2024spectral,
  author = {Dieleman, Sander},
  title = {Diffusion is spectral autoregression},
  url = {https://sander.ai/2024/09/02/spectral-autoregression.html},
  year = {2024}
}
</code></pre></div>

<h2 id="-acknowledgements"><a name="acknowledgements"></a> Acknowledgements</h2>

<p>Thanks to my colleagues at Google DeepMind for various discussions, which continue to shape my thoughts on this topic! In particular, thanks to Robert Riachi, Ruben Villegas and Daniel Zoran.</p>

<h2 id="-references"><a name="references"></a> References</h2>



      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IPMI (207 pts)]]></title>
            <link>https://computer.rip/2024-08-31-ipmi.html</link>
            <guid>41431244</guid>
            <pubDate>Tue, 03 Sep 2024 04:23:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computer.rip/2024-08-31-ipmi.html">https://computer.rip/2024-08-31-ipmi.html</a>, See on <a href="https://news.ycombinator.com/item?id=41431244">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>I am making steady progress towards moving the <em>Computers Are Bad</em> enterprise
cloud to its new home, here in New Mexico. One of the steps in this process is,
of course, purchasing a new server... the current Big Iron is getting rather
old (probably about a decade!)  and here in town I'll have the rack space for
more machines anyway.</p>
<p>In our modern, cloud-centric industry, it is rare that I find myself comparing
the specifications of a Dell PowerEdge against an HP ProLiant. Because the
non-hyperscale server market has increasingly consolidated around Intel
specifications and reference designs, it is even rarer that there is much of a
difference between the major options.</p>
<p>This brings back to mind one of those ancient questions that comes up among
computer novices and becomes a writing prompt for technology bloggers. What
<em>is</em> a server? Is it just, like, a big computer? Or is it actually special?</p>
<p>There's a lot of industrial history wrapped up in that question, and the answer
is often very context-specific. But there are some generalizations we can make
about the history of the server: client-server computing originated mostly as
an evolution of time-sharing computing using multiple terminals connected to a
single computer. There was no expectation that terminals had a similar
architecture to computers (and indeed they were usually vastly simpler
machines), and that attitude carried over to client-server systems. The PC
revolution instilled a WinTel monoculture in much of client-side computing by
the mid-'90s, but it remained common into the '00s for servers to run entirely
different operating systems and architectures.</p>
<p>The SPARC and Solaris combination was very common for servers, as were IBM's
minicomputer architectures and their numerous operating systems. Indeed, one of
the key commercial contributions of Java was the way it allowed enterprise
applications to be written for a Solaris/SPARC backend while enabling code
reuse for clients that ran on either stalwarts like Unix/RISC or "modern"
business computing environments like Windows/x86. This model was sometimes
referred to as client-server computing with "thick clients." It preserved the
differentiation between "server" and "client" as classes of machines, and the
universal adherance of serious business software to this model lead to an
association between server platforms and "enterprise computing."</p>
<p>Over time, things have changed, as they always do. Architectures that had been
relegated to servers became increasingly niche and struggled to compete with
the PC architecture on cost and performance. The general architecture of server
software shifted away from vertical scaling and high-uptime systems to
horizontal scaling with relaxed reliability requirements, taking away much of
the advantage of enterprise-class computers. For the most part, today, a server
is just a big computer. There are some distinguishing features: servers are far
more likely to be SMP or NUMA, with multiple processor sockets. While the days
of SAS and hardware RAID are increasingly behind us, servers continue to have
more complex storage controllers and topologies than clients. And servers,
almost by definition, offer some sort of out of band management.</p>
<p>Out-of-band management, sometimes also called lights-out management, identifies
a capability that is almost unheard of in clients. A separate, smaller
management computer allows for remote access to a server even when it is, say,
powered off. The terms out-of-band and in-band in this context emerge from
their customery uses in networking and telecom, meaning that out of band
management is performed without the use of the standard (we might say "data
plane") network connection to a machine. But in practice they have drifted in
meaning, and it is probably better to think of out-of-band management as
meaning that the <em>operating system and general-purpose components are not
required.</em> This might be made clearer by comparison: a very standard example of
in-band management would be SSH, a service provided by the software on a
computer that allows you to interact with it. Out-of-band management, by
contrast, is provided by a dedicated hardware and software stack and does not
require the operating system or, traditionally, even the CPU to cooperate.</p>
<p>You can imagine that this is a useful capability. Today, out-of-band management
is probably best exemplified by the remote console that most servers offer.
It's basically an embedded IP KVM, allowing you to interact with the machine as
if you were at a locally connected monitor and keyboard. A lot of OOB
management products also offer "virtual media," where you can upload an ISO
file to the management interface and then have it appear to the computer proper
as if it were a physical device. This is extremely useful for installing
operating systems.</p>
<p>OOB management is an interesting little corner of computer history. It's not a
new idea at all; in fact, similar capabilities can be found through pretty much
the entire history of business computing. If anything, it's gotten simpler and
more boring over time. A few evenings ago I was watching a <a href="https://www.youtube.com/watch?v=J1NxcgasTIU">clabretro
video</a> about an IBM p5 he's gotten
working. As is the case in most of his videos about servers, he has to give a
brief explanation of the multiple layers of lower-level management systems
present in the p5 and their various textmode and web interfaces.</p>
<p>If we constrain our discussion of "servers" to relatively modern machines,
starting say in the late '80s or early '90s, there are some common features:</p>
<ul>
<li>Some sort of local operator interface (this term itself being a very old
one), like an LCD matrix display or grid of LED indicators, providing low-level
information on hardware health.</li>
<li>A serial console with access to the early bootloader and a persistent
low-level management system.</li>
<li>A higher-level management system, with a variable position in the stack
depending on architecture, for remote management of the machine workload.</li>
</ul>
<p>A lot of this stuff still hangs around today. Most servers can tell you on the
front panel if a redundant component like a fan or power supply has failed,
although the number of components that are redundant and can be replaced online
has dwindled with time from "everything up to and including CPUs" on '90s
prestige architectures to sometimes little more than fans. Serial management is
still pretty common, mostly as a holdover of being a popular way to do OS
installation and maintenance on headless machines [1].</p>
<p>But for the most part, OOB management has consolidated in the exact same way as
processor architecture: onto Intel IPMI.</p>
<p>IPMI is confusing to some people for a couple of reasons. First, IPMI is a
specification, not an implementation. Most major vendors have their own
implementation of IPMI, often with features above and beyond the core IPMI
spec, and they call them weird acronyms like HP iLO and Dell DRAC. These
vendor-specific implementations often predate IPMI, too, so it's never quite
right to say they are "just IPMI." They're independent systems with IPMI
characteristics. On the other hand, more upstart manufacturers are more likely
to just call it IPMI, in which case it may just be the standard offering from
their firmware vendor.</p>
<p>Further confusing matters is a fair amount of terminological overlap. The IPMI
software runs on a processor conventionally called the baseboard management
controller or BMC, and the terms IPMI and BMC are sometimes used
interchangeably. Lights-out management or LOM is mostly an obsolete term but
sticks around because HP(E) is a fan of it and continues to call their IPMI
implementation Integrated Lights-Out. The BMC should not be confused with the
System Management Controller or SMC, which is one of a few terms used for a
component present in client computers to handle tasks like fan speed control.
These have an interrelated history and, indeed, the BMC handles those functions
in most servers.</p>
<p>IPMI also specifies two interfaces: an out-of-band interface available over the
network or a serial connection, and an in-band interface available to the
operating system via a driver (and, in practice, I believe communication
between the CPU and the baseboard management controller via the low-pin-count
or LPC bus, which is a weird little holdover of ISA present in most modern
computers). The result is that you can interact with the IPMI from a tool
running in the operating system, like ipmitool on Linux. That makes it a little
confusing what exactly is going on, if you don't understand that the IPMI is a
completely independent system that has a local interface to the running
operating system for convenience.</p>
<p>What does the IPMI actually <em>do?</em> Well, like most things, it's mostly become a
webapp. Web interfaces are just too convenient to turn down, so while a lot of
IPMI products do have dedicated client software, they're porting all the
features into an embedded web application. The quality of these web interfaces
varies widely but is mostly not very good. That raises a question, of course,
of how you <em>get</em> to the IPMI web interface.</p>
<p>Most servers on the market have a dedicated ethernet interface for the IPMI,
often labelled "IPMI" or "management" or something like that. Most people would
agree that the best way to use IPMI is to put the management network interface
onto a dedicated physical network, for reasons of both security and reliability
(IPMI should remain accessible even in case of performance or reliability
problems with your main network). A dedicated physical network costs time,
space, and money, though, so there are compromises. For one, your "management
network" is very likely to be a VLAN on your normal network equipment. That's
sort of like what AT&amp;T calls a common-carrier switching arrangement, meaning
that it behaves like an independent, private network but shares all of the
actual equipment with everything else, the isolation being implemented in
software. That was a weird comparison to make and I probably just need to write
a whole article on CCSAs like I've been meaning to.</p>
<p>Even that approach requires extra cabling, though, so IPMI offers "sideband"
networking. With sideband management, the BMC communicates directly with the
same NIC that the operating system uses. The implementation is a little bit
weird: the NIC will pretend to be two different interfaces, mixing IPMI traffic
into the same packet stream as host traffic but using a <em>different MAC
address.</em> This way, it appears to other network equipment as if there are two
different network interfaces in use, as usual. I will leave judgment as to how
good of an idea this is to you, but there are obvious security considerations
around reducing the segregation between IPMI and application traffic.</p>
<p>And yes, it should be said, a lot of IPMI implementations have proven to be
security nightmares. They should never be accessible to any untrusted person.</p>
<p>Details of network features vary between IPMI implementations, but there is a
standard interface on UDP 623 that can be used for discovery and basic
commands. There's often SSH and a web interface, and VNC is pretty common for
remote console.</p>
<p>There are some neat basic functions you can perform with the IPMI, either over
the network or locally using an in-band IPMI client. A useful one, if you are
forgetful and keep poor records like I do, is listing the hardware modules
making up the machine at an FRU or vendor part number level. You can also
interact with basic hardware functions like sensors, power state, fans, etc.
IPMI offers a standard watchdog timer, which can be combined with software
running on the operating system to ensure that the server will be reset if
the application gets into an unhealthy state. You should set a long enough
timeout to allow the system to boot and for you to connect and disable the
watchdog timer, ask me how I know.</p>
<p>One of the reasons I thought to write about IPMI is its strange relationship to
the world of everyday client computers. IPMI is very common in enterprise
servers but very rare elsewhere, much to the consternation of people like me
that don't have the space or noise tolerance for a 1U pizzabox in their homes.
If you are trying to stick to compact or low-power computers, you'll pretty
much have to go without.</p>
<p>But then, there's kind of a weird exception. What about Intel ME and AMD ST?
These are essentially OOB management controllers that are present in virtually
all Intel and AMD processors. This is kind of an odd story. Intel ME, the
Management Engine, is an enabling component of Intel Active Management
Technology (Intel AMT). AMT was pretty much an attempt at popularizing OOB
management for client machines, and offers most of the same capabilities as
IPMI. It has been considerably less successful. Most of that is probably due to
pricing, Intel has limited almost all AMT features to use with their very
costly enterprise management platforms. Perhaps there is some industry in which
these sell well, but I am apparently not in it. There are open-source AMT
clients, but the next problem you will run into is finding a machine where AMT
is actually usable.</p>
<p>The fact that Intel AMT has sideband management capability, and that therefore
the Intel ME component on which AMT runs has sideband management capability,
was the topic of quite some consternation in the security community. Here is a
mitigating factor: sideband management is only possible if the processor,
motherboard chipset, and NIC are all AMT-capable. Options for all three devices
are limited to Intel products with the vPro badge. The unpopularity of Intel
NICs in consumer devices alone means that sideband access is rarely possible.
vPro is also limited to relatively high-end processors and chipsets. The bad
news is that you will have a hard time using AMT in your homelab, although some
people certainly do. The upside is that the widely-reported "fact" that Intel
ME is accessible via sideband networking on consumer devices is typically
untrue, and for reasons beyond Intel software licensing.</p>
<p>That leaves an odd question around Intel ME itself, though, which is certainly
OOB management-like but doesn't really have any OOB management features without
AMT. So why do nearly all processors have it? Well, this is somewhat
speculative, but the impression I get is that Intel ME exists mostly as a
convenient way to host and manage trusted execution components that are used
for things like Secure Boot and DRM. These features all run on the same
processor as ME and share some common technology stack. The "management"
portion of Intel ME is thus largely vestigial, and it's part of the secure
computing infrastructure.</p>
<p>This is not to make excuses for Intel ME, which is entirely unauditable by
third parties and has harbored significant security vulnerabilities in the
past. But, remember, we all use one processor architecture from one of two
vendors, so Intel doesn't have a whole lot of motivation to do better. Lest
you respond that ARM is the way, remember that modern ARM SOCs used in
consumer devices have pretty much identical capabilities.</p>
<p>It is what it is.</p>
<p>[1] The definition of "headless" is sticky and we have to not get stuck on it
too much. People tend to say "headless" to mean no monitor and keyboard
attached, but keep in mind that slide-out rack consoles and IP KVMs have been
common for a long time and so in non-hyperscale environments truly headless
machines are rarer than you would think. Part of this is because using a serial
console is a monumental pain in the ass, so your typical computer operator will
do a lot to avoid dealing with it. Before LCD displays, this meant a CRT and
keyboard on an Anthro cart with wheels, but now that we are an enlightened
society, you can cram a whole monitor and keyboard into 1U and get a KVM
switching fabric that can cover the whole rack. Or swap cables. Mostly swap
cables.</p>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wizardry Co-Creator Andrew Greenberg Has Passed Away (114 pts)]]></title>
            <link>https://www.timeextension.com/news/2024/09/wizardry-co-creator-andrew-greenberg-has-passed-away</link>
            <guid>41431177</guid>
            <pubDate>Tue, 03 Sep 2024 04:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.timeextension.com/news/2024/09/wizardry-co-creator-andrew-greenberg-has-passed-away">https://www.timeextension.com/news/2024/09/wizardry-co-creator-andrew-greenberg-has-passed-away</a>, See on <a href="https://news.ycombinator.com/item?id=41431177">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="template">
<article id="article">
<header><section>
<p>1981 epic laid down the foundations of the genre</p>
</section></header><div><section>
<figure><a title="Wizardry Co-Creator Andrew Greenberg Has Passed Away 1" href="https://images.timeextension.com/f3705a0086f83/wizardry-co-creator-andrew-greenberg-has-passed-away-1.large.jpg"><img src="https://images.timeextension.com/f3705a0086f83/wizardry-co-creator-andrew-greenberg-has-passed-away-1.900x.jpg" width="900" height="484" alt="Wizardry Co-Creator Andrew Greenberg Has Passed Away 1"></a><figcaption><em><span></span> Image: Digital Eclipse</em></figcaption></figure><p>We're sad to report that Andrew Greenberg, who created the seminal RPG <strong>Wizardry</strong> alongside Robert Woodhead, has passed away.</p>
<p>Released in 1981, Wizardry was one of the first RPGs for personal computers and would prove to be a huge influence on the development of the genre. It was also a massive success in Japan and continues to receive new installments in that market.</p>
<p>More recently, the original game was <a href="https://www.timeextension.com/games/switch-eshop/wizardry_proving_grounds_of_the_mad_overlord">remastered</a> by Digital Eclipse for modern systems.</p>
<figure><a title="Wizardry Co-Creator Andrew Greenberg Has Passed Away 2" href="https://images.timeextension.com/112de465423ec/wizardry-co-creator-andrew-greenberg-has-passed-away-2.large.png"><img src="https://images.timeextension.com/112de465423ec/wizardry-co-creator-andrew-greenberg-has-passed-away-2.original.jpg" width="900" height="605" loading="lazy" alt="Wizardry Co-Creator Andrew Greenberg Has Passed Away 2"></a><figcaption><em><span></span> Image: <a href="https://www.facebook.com/madoverlord/posts/8270753369641433#?aeh">Robert Woodhead</a></em></figcaption></figure>
<p>Greenberg – who lent his name to the antagonist of the first Wizardry game (Werdna is Andrew spelt backwards) – would later work as a patent attorney and general counsel for a renewable energy company.</p>
<p>Our thoughts are with Greenberg's family and friends at this difficult time.</p>

<!-- cache: html:timeextension.com/ssl/related-articles:165716,169960,157548 @ 2024-09-03T17:13:27+01:00 --></section>
<p>[source <a title="External Link: https://x.com/David_Mullich/status/1829574742686548110" rel="noopener" href="https://x.com/David_Mullich/status/1829574742686548110">x.com</a>]</p>
<!-- cache: html:timeextension.com/ssl/related-info/2614662b348702ad5e871c5d4ac08bb8 @ 2024-09-03T17:13:27+01:00 --></div></article><!-- cache: html:timeextension.com/ssl/article-next-prev/news/2024/09/wizardry-co-creator-andrew-greenberg-has-passed-away @ 2024-09-03T17:29:43+01:00 --><section><nav><p><a title="Previous Article: This Tiny Piece Of Plastic Could Save Your N64's Analogue Stick" data-event-category="Suggestions" data-event-action="Article Previous" data-event-label="Image" href="https://www.timeextension.com/news/2024/08/this-tiny-piece-of-plastic-could-save-your-n64s-analogue-stick"><img src="https://images.timeextension.com/95d4b17a09c5e/300x150.jpg" width="300" height="150" loading="lazy" alt="Previous Article: This Tiny Piece Of Plastic Could Save Your N64's Analogue Stick"></a></p>
<h2><a title="Previous Article: This Tiny Piece Of Plastic Could Save Your N64's Analogue Stick" data-event-category="Suggestions" data-event-action="Article Previous" data-event-label="Title" href="https://www.timeextension.com/news/2024/08/this-tiny-piece-of-plastic-could-save-your-n64s-analogue-stick"><span>News</span> <span>This Tiny Piece Of Plastic Could Save Your N64's Analogue Stick</span></a></h2>
<p><a title="Previous Article: This Tiny Piece Of Plastic Could Save Your N64's Analogue Stick" data-event-category="Suggestions" data-event-action="Article Previous" data-event-label="Arrow" href="https://www.timeextension.com/news/2024/08/this-tiny-piece-of-plastic-could-save-your-n64s-analogue-stick"><span></span> <span>Prev</span></a></p>
</nav><nav><p><a title="Next Article: This Is Why You Should Never Store Your Retro Game Collection In A Shed" data-event-category="Suggestions" data-event-action="Article Next" data-event-label="Image" href="https://www.timeextension.com/news/2024/09/this-is-why-you-should-never-store-your-retro-game-collection-in-a-shed"><img src="https://images.timeextension.com/d96a5322f358b/300x150.jpg" width="300" height="150" loading="lazy" alt="Next Article: This Is Why You Should Never Store Your Retro Game Collection In A Shed"></a></p>
<h2><a title="Next Article: This Is Why You Should Never Store Your Retro Game Collection In A Shed" data-event-category="Suggestions" data-event-action="Article Next" data-event-label="Title" href="https://www.timeextension.com/news/2024/09/this-is-why-you-should-never-store-your-retro-game-collection-in-a-shed"><span>News</span> <span>This Is Why You Should Never Store Your Retro Game Collection In A Shed</span></a></h2>
<p><a title="Next Article: This Is Why You Should Never Store Your Retro Game Collection In A Shed" data-event-category="Suggestions" data-event-action="Article Next" data-event-label="Arrow" href="https://www.timeextension.com/news/2024/09/this-is-why-you-should-never-store-your-retro-game-collection-in-a-shed"><span>Next</span> <span></span></a></p>
</nav></section><div>
<p><img src="https://images.timeextension.com/users/794/avatar.jpg" width="80" height="80" loading="lazy" alt="Damien McFerran"></p>
<div><p>Damien has been writing professionally about tech and video games since 2007 and oversees all of Hookshot Media's sites from an editorial perspective. He's also the editor of <a href="https://www.timeextension.com/">Time Extension</a>, the network's newest site, which – paradoxically – is all about gaming's past glories.</p><ul><li><a href="https://www.timeextension.com/authors/Damo"><span></span> Author Profile</a></li><li><a onclick="return replyTo('Damo');" href="https://www.timeextension.com/#"><span></span> Reply</a></li></ul>
</div>
	</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Greppability is an underrated code metric (806 pts)]]></title>
            <link>https://morizbuesing.com/blog/greppability-code-metric/</link>
            <guid>41430772</guid>
            <pubDate>Tue, 03 Sep 2024 02:47:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://morizbuesing.com/blog/greppability-code-metric/">https://morizbuesing.com/blog/greppability-code-metric/</a>, See on <a href="https://news.ycombinator.com/item?id=41430772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>When I‘m working on maintaining an unfamiliar codebase, I will spend a lot of
time grepping the code base for strings. Even in projects exclusively written
by myself, I have to search a lot: function names, error messages,
class names, that kind of thing. If I can‘t find what I‘m looking for, it‘ll
be frustrating in the best case, or in the worst case lead to dangerous
situations where I‘ll assume a thing is not needed anymore, since I can‘t find
any references to it in the code base. From these situations, I‘ve derived some
rules you can apply to keep your code base greppable:</p>
<h2 id="dont-split-up-identifiers">Don‘t split up identifiers</h2>
<p>It turns out that splitting up, or dynamically constructing identifiers is a
bad idea.</p>
<p>Suppose you have two database tables <code>shipping_addresses</code>, <code>billing_addresses</code>,
it might seem like a perfectly good solution to construct the table name
dynamically from the order type.</p>
<pre tabindex="0"><code><span><span>const</span><span> getTableName</span><span> =</span><span> (addressType</span><span>:</span><span> 'shipping'</span><span> |</span><span> 'billing'</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>    return</span><span> `${</span><span>addressType</span><span>}_addresses`</span></span>
<span><span>}</span></span></code></pre>
<p>Though it looks nice and DRY, it‘s not great for maintainenance: someone will
inevitably search the code base for the table name <code>shipping_addresses</code> and
miss this occurence.</p>
<p>Refactored for greppability:</p>
<pre tabindex="0"><code><span><span>const</span><span> getTableName</span><span> =</span><span> (addressType</span><span>:</span><span> 'shipping'</span><span> |</span><span> 'billing'</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>    if</span><span> (</span><span>addressType</span><span> ===</span><span> 'shipping'</span><span>) {</span></span>
<span><span>        return</span><span> 'shipping_addresses'</span></span>
<span><span>    }</span></span>
<span><span>    if</span><span> (</span><span>addressType</span><span> ===</span><span> 'billing'</span><span>) {</span></span>
<span><span>        return</span><span> 'billing_addresses'</span></span>
<span><span>    }</span></span>
<span><span>    throw</span><span> new</span><span> TypeError</span><span>(</span><span>'addressType must be billing or shipping'</span><span>)</span></span>
<span><span>}</span></span></code></pre>
<p>The same goes for column names, object fields, and, god forbid, method/function
names (it‘s easily possible to dynamically construct method names with javascript).</p>
<h2 id="use-the-same-names-for-things-across-the-stack">Use the same names for things across the stack</h2>
<p>Don‘t rename fields at application boundaries to match naming schemes. An obvious
example is then importing postgres-style snake_case identifiers into
javascript, then converting them to camelCase. This makes it harder to
find—you now have to grep for two strings instead of one in order to find all
occurences!</p>
<pre tabindex="0"><code><span><span>const</span><span> getAddress</span><span> =</span><span> async</span><span> (id</span><span>:</span><span> string</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>    const</span><span> address</span><span> =</span><span> await</span><span> getAddressById</span><span>(</span><span>id</span><span>)</span></span>
<span><span>    return</span><span> {</span></span>
<span><span>        streetName: </span><span>address</span><span>.</span><span>street_name</span><span>,</span></span>
<span><span>        zipCode: </span><span>address</span><span>.</span><span>zip_code</span><span>,</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>You‘re better off biting the bullet and returning the object directly:</p>
<pre tabindex="0"><code><span><span>const</span><span> getAddress</span><span> =</span><span> async</span><span> (id</span><span>:</span><span> string</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>    return</span><span> await</span><span> getAddressById</span><span>(</span><span>id</span><span>)</span></span>
<span><span>}</span></span></code></pre>
<h2 id="flat-is-better-than-nested">Flat is better than nested</h2>
<p>Taking inspiration from the <a href="https://peps.python.org/pep-0020/">Zen of Python</a>,
when dealing with namespaces, flattening your folders/object structures is mostly better
than nesting.</p>
<p>For example if you have two choices to set up your translation files:</p>
<pre tabindex="0"><code><span><span>{</span></span>
<span><span>    "auth"</span><span>: {</span></span>
<span><span>        "login"</span><span>: {</span></span>
<span><span>            "title"</span><span>: </span><span>"Login"</span><span>,</span></span>
<span><span>            "emailLabel"</span><span>: </span><span>"Email"</span><span>,</span></span>
<span><span>            "passwordLabel"</span><span>: </span><span>"Password"</span><span>,</span></span>
<span><span>        },</span></span>
<span><span>        "register"</span><span>:</span></span>
<span><span>            "title"</span><span>: </span><span>"Register"</span><span>,</span></span>
<span><span>            "emailLabel"</span><span>: </span><span>"Email"</span><span>,</span></span>
<span><span>            "passwordLabel"</span><span>: </span><span>"Password"</span><span>,</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>and</p>
<pre tabindex="0"><code><span><span>{</span></span>
<span><span>    "auth.login.title"</span><span>: </span><span>"Login"</span><span>,</span></span>
<span><span>    "auth.login.emailLabel"</span><span>: </span><span>"Email"</span><span>,</span></span>
<span><span>    "auth.login.passwordLabel"</span><span>: </span><span>"Password"</span><span>,</span></span>
<span><span>    "auth.register.title"</span><span>: </span><span>"Login"</span><span>,</span></span>
<span><span>    "auth.register.emailLabel"</span><span>: </span><span>"Email"</span><span>,</span></span>
<span><span>    "auth.register.passwordLabel"</span><span>: </span><span>"Password"</span><span>,</span></span>
<span><span>}</span></span></code></pre>
<p>take the second option! You will be able to easily find your keys now, which
you are probably referring to as something like <code>t('auth.login.title')</code>.</p>
<p>Or consider React component structure: a component stucture like</p>
<pre tabindex="0"><code><span><span>./components/AttributeFilterCombobox.tsx</span></span>
<span><span>./components/AttributeFilterDialog.tsx</span></span>
<span><span>./components/AttributeFilterRating.tsx</span></span>
<span><span>./components/AttributeFilterSelect.tsx</span></span></code></pre>
<p>is preferable to</p>
<pre tabindex="0"><code><span><span>./components/attribute/filter/Combobox.tsx</span></span>
<span><span>./components/attribute/filter/Dialog.tsx</span></span>
<span><span>./components/attribute/filter/Rating.tsx</span></span>
<span><span>./components/attribute/filter/Select.tsx</span></span></code></pre>
<p>from a greppability perspective, since you‘ll be able to grep for the
whole namespaced component <code>AttributeFilterCombobox</code> just from the usage, as
opposed to just <code>Dialog</code>, which you might have multiple of accross your
application.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's 'Recall' feature can't be uninstalled after all (177 pts)]]></title>
            <link>https://mashable.com/article/microsoft-recall-feature-cant-be-uninstalled</link>
            <guid>41430757</guid>
            <pubDate>Tue, 03 Sep 2024 02:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/microsoft-recall-feature-cant-be-uninstalled">https://mashable.com/article/microsoft-recall-feature-cant-be-uninstalled</a>, See on <a href="https://news.ycombinator.com/item?id=41430757">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" data-autopogo="">
<p>It turns out <a href="https://mashable.com/article/control-panel-retiring-windows" target="_self" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body">Windows 11</a> users won't be able to uninstall Microsoft's controversial "Recall" feature after all. </p><p>Recall is a Copilot+ feature announced in May that essentially takes constant screenshots of your behavior while using operating system, ostensibly for users to easily find previous work. </p><p>A report by <a href="https://www.deskmodder.de/blog/2024/09/02/windows-11-recall-wird-sich-deinstallieren-lassen-einstellung-dafuer-wurde-hinzugefuegt/" target="_blank" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body" title="(opens in a new window)">Deskmodder </a>seemed to reveal recent Windows 11 update 24H2 allows users to completely uninstall the feature. But now, in a statement to <a href="https://www.theverge.com/2024/9/2/24233992/microsoft-recall-windows-11-uninstall-feature-bug" target="_blank" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body" title="(opens in a new window)">The Verge</a>, Microsoft clarified that that the uninstall option was just a bug. </p><p>"We are aware of an issue where Recall is incorrectly listed as an option under the 'Turn Windows features on or off' dialog in Control Panel," said Windows senior product manager Brandon LeBlanc to the outlet. "This will be fixed in an upcoming update."</p><p><a href="https://games.mashable.com/" target="_blank" data-ga-click="" data-ga-element="mashable_games_general" data-ga-action="mashable_games_general" data-ga-item="mashable_games_general" data-ga-label="In-Content General Games Module">
<img title="Mashable Games" src="https://mashable.com/images/mashable-games-mobile.png" alt="Mashable Games" width="600" height="600">
<img title="Mashable Games" src="https://mashable.com/images/mashable-games-desktop.png" alt="Mashable Games" width="768" height="180">
</a>
</p>
<p>When Microsoft announced Recall, it was intended to be baked into Windows 11's functions. The feature tracks everything you do on compatible Windows PCs and uses an on-device generative AI model to retrieve particular information a user is looking for, by filing through a library of screenshots saved on the device. Critics of the feature immediately pointed out that it is highly susceptible to cybersecurity flaws since it indiscriminately saves sensitive information like passwords, confidential work, and personal information. </p><section x-data="window.newsletter()" x-init="init()" data-ga-impression="" data-ga-category="newsletters" data-ga-module="incontent_nl_signup" data-ga-label="mashablelightspeed">
<p>
Mashable Light Speed
</p>


</section>
<p>Former Microsoft security expert Kevin Beaumont described it as a cybersecurity "<a href="https://mashable.com/article/microsoft-copilot-recall-cybersecurity-disaster" target="_self" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body">disaster.</a>"</p><p>"Stealing everything you’ve ever typed or viewed on your own Windows PC is now possible with two lines of code," said Beaumont. </p>
<p>The public backlash to the new feature led to Microsoft just days after its May announcement following up with a new statement that the Recall feature would be opt-in and therefore switched off by default.</p><p>It is also being <a href="https://mashable.com/article/microsoft-recall-ai-feature-uk-investigation" target="_self" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body">investigated</a> by the UK's Information Commissioner's Office (ICO) for violations of user privacy. But after all the outcry and potential legal ramifications, </p><p>Recall was initially slated for release in June, but was delayed as Microsoft scrambled to address security concerns. Now, it will <a href="https://mashable.com/article/microsoft-recall-copilot-relaunch-october" target="_self" data-ga-click="1" data-ga-element="offer" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body">launch in October</a> to Windows Insiders testers. </p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feds Kill Plan to Curb Medicare Advantage Overbilling After Industry Opposition (119 pts)]]></title>
            <link>https://kffhealthnews.org/news/article/medicare-advantage-overbilling-diagnostic-codes-cms-killed-rule/</link>
            <guid>41430310</guid>
            <pubDate>Tue, 03 Sep 2024 01:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kffhealthnews.org/news/article/medicare-advantage-overbilling-diagnostic-codes-cms-killed-rule/">https://kffhealthnews.org/news/article/medicare-advantage-overbilling-diagnostic-codes-cms-killed-rule/</a>, See on <a href="https://news.ycombinator.com/item?id=41430310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								
<p>A decade ago, federal officials drafted a plan to discourage Medicare Advantage health insurers from overcharging the government by billions of dollars — only to abruptly back off amid an “uproar” from the industry, newly released court filings show.</p>



<p>The Centers for Medicare &amp; Medicaid Services published the draft regulation in January 2014. The rule would have required health plans, when examining patient’s medical records, to identify overpayments by CMS and refund them to the government.</p>



<p>But in May 2014, CMS dropped the idea without any public explanation. Newly released court depositions show that agency officials repeatedly cited concern about pressure from the industry.</p>



<p>The 2014 decision by CMS, and events related to it, are at the center of a multibillion-dollar Justice Department civil fraud case against UnitedHealth Group pending in federal court in Los Angeles.</p>



<p>The Justice Department alleges the giant health insurer cheated Medicare out of more than $2 billion by reviewing patients’ records to find additional diagnoses, adding revenue while ignoring overcharges that might reduce bills. The company “buried its head in the sand and did nothing but keep the money,” DOJ said in a court filing.</p>



<p>Medicare pays health plans higher rates for sicker patients but requires that the plans bill only for conditions that are properly documented in a patient’s medical records.</p>



<p>In a court filing, UnitedHealth Group denies wrongdoing and argues it shouldn’t be penalized for “failing to follow a rule that CMS considered a decade ago but declined to adopt.”</p>



<p>This month, the parties in the court case made public thousands of pages of depositions and other records that offer a rare glimpse inside the Medicare agency’s long-running struggle to keep the private health plans from taking taxpayers for a multibillion-dollar ride.</p>



<p>“It’s easy to dump on Medicare Advantage plans, but CMS made a complete boondoggle out of this,” said Richard Lieberman, a Colorado health data analytics expert.</p>



<p>Spokespeople for the Justice Department and CMS declined to comment for this article. In an email, UnitedHealth Group spokesperson Heather Soule said the company’s “business practices have always been transparent, lawful and compliant with CMS regulations.”</p>


<div data-type="kaiser-health-news/newsletter" data-align="center">
	<h4>
		<a href="https://kffhealthnews.org/email/">
			Email Sign-Up		</a>
	</h4>
	<p>
		Subscribe to KFF Health News' free Morning Briefing.	</p>
	

</div>



<p><strong>Missed Diagnoses</strong></p>



<p>Medicare Advantage insurance plans have grown explosively in recent years and now <a href="https://www.kff.org/medicare/issue-brief/medicare-advantage-in-2024-enrollment-update-and-key-trends/">enroll about 33 million members</a>, more than half of people eligible for Medicare. Along the way, the industry has been the target of dozens of whistleblower lawsuits, <a href="https://kffhealthnews.org/news/article/audits-hidden-until-now-reveal-millions-in-medicare-advantage-overcharges/">government audits</a>, and other investigations alleging the health plans often exaggerate how sick patients are to rake in undeserved Medicare payments — including by doing what are called chart reviews, intended to find allegedly missed diagnosis codes.</p>



<p>By 2013, CMS officials knew some Medicare health plans were hiring medical coding and analytics consultants to aggressively mine patient files — but they doubted the agency’s authority to demand that health plans also look for and delete unsupported diagnoses.</p>



<p>The proposed January 2014 regulation mandated that chart reviews “cannot be designed only to identify diagnoses that would trigger additional payments” to health plans.</p>



<p>CMS officials backed down in May 2014 because of “stakeholder concern and pushback,” Cheri Rice, then director of the CMS Medicare plan payment group, testified in a 2022 deposition made public this month. A second CMS official, Anne Hornsby, described the industry’s reaction as an “uproar.”</p>



<p>Exactly who made the call to withdraw the chart review proposal isn’t clear from court filings so far.</p>



<p>“The direction that we received was that the rule, the final rule, needed to include only those provisions that had wide, you know, widespread stakeholder support,” Rice testified.</p>



<p>“So we did not move forward then,” she said. “Not because we didn’t think it was the right thing to do or the right policy, but because it had mixed reactions from stakeholders.”</p>



<p>The CMS press office declined to make Rice available for an interview. Hornsby, who has since left the agency, declined to comment.</p>



<p>But Erin Fuse Brown, a professor at the Brown University School of Public Health, said the decision reflects a pattern of timid CMS oversight of the popular health plans for seniors.</p>



<p>“CMS saving money for taxpayers isn’t enough of a reason to face the wrath of very powerful health plans,” Fuse Brown said.</p>



<p>“That is extremely alarming.”</p>



<p><strong>Invalid Codes</strong></p>



<p>The fraud case against UnitedHealth Group, which runs the nation’s largest Medicare Advantage plan, was filed in 2011 by a former company employee. The DOJ <a href="https://www.justice.gov/opa/pr/united-states-intervenes-false-claims-act-lawsuit-against-unitedhealth-group-inc-mischarging">took over</a> the whistleblower suit in 2017.</p>



<p>DOJ alleges Medicare paid the insurer more than $7.2 billion from 2009 through 2016 solely based on chart reviews; the company would have received $2.1 billion less if it had deleted unsupported billing codes, the government says.</p>



<p>The government argues that UnitedHealth Group knew that many conditions it had billed for were not supported by medical records but chose to pocket the overpayments. For instance, the insurer billed Medicare nearly $28,000 in 2011 to treat a patient for cancer, congestive heart failure, and other serious health problems that weren’t recorded in the person’s medical record, DOJ alleged in a 2017 filing.</p>



<p>In all, DOJ contends that UnitedHealth Group should have deleted more than 2 million invalid codes.</p>



<p>Instead, company executives signed annual statements attesting that the billing data submitted to CMS was “accurate, complete, and truthful.” Those actions violated the False Claims Act, a federal law that makes it illegal to submit bogus bills to the government, DOJ alleges.</p>



<p>The complex case has featured years of legal jockeying, even pitting the recollections of key CMS staff members — including several who have since departed government for jobs in the industry — against those of UnitedHealthcare executives.</p>



<p><strong>‘Red Herring’</strong></p>



<p>Court filings describe a 45-minute video conference arranged by then-CMS administrator Marilyn Tavenner on April 29, 2014. Tavenner testified she set up the meeting between UnitedHealth and CMS staff at the request of Larry Renfro, a senior UnitedHealth Group executive, to discuss implications of the draft rule. Neither Tavenner nor Renfro attended.</p>



<p>Two UnitedHealth Group executives on the call said in depositions that CMS staffers told them the company had no obligation at the time to uncover erroneous codes. One of the executives, Steve Nelson, called it a “very clear answer” to the question. Nelson has since left the company.</p>



<p>For their part, four of the five CMS staffers on the call said in depositions that they didn’t remember what was said. Unlike the company’s team, none of the government officials took detailed notes.</p>



<p>“All I can tell you is I remember feeling very uncomfortable in the meeting,” Rice said in her 2022 deposition.</p>



<p>Yet Rice and one other CMS staffer said they did recall reminding the executives that even without the chart review rule, the company was obligated to make a good-faith effort to bill only for verified codes — or face possible penalties under the False Claims Act. And CMS officials reinforced that view in follow-up emails, according to court filings.</p>



<p>DOJ called the flap over the ill-fated regulation a “red herring” in a court filing and alleges that when UnitedHealth asked for the April 2014 meeting, it knew its chart reviews had been under investigation for two years. In addition, the company was “grappling with a projected $500 million budget deficit,” according to DOJ.</p>



<p><strong>Data Miners</strong></p>



<p>Medicare Advantage plans defend chart reviews against criticism that they do little but artificially inflate the government’s costs.</p>



<p>“Chart reviews are one of many tools Medicare Advantage plans use to support patients, identify chronic conditions, and prevent those conditions from becoming more serious,” said Chris Bond, a spokesperson for AHIP, a health insurance trade group.</p>



<p>Whistleblowers have argued that the <a href="https://publicintegrity.org/health/home-is-where-the-money-is-for-medicare-advantage-plans/">cottage industry</a> of analytics firms and coders that sprang up to conduct these reviews pitched their services as a huge moneymaking exercise for health plans — and little else.</p>



<p>“It was never legitimate,” said William Hanagami, a California attorney who represented whistleblower James Swoben in a <a href="https://www.justice.gov/usao-cdca/pr/medicare-advantage-provider-pay-270-million-settle-false-claims-act-liabilities">2009 case</a> that alleged chart reviews improperly inflated Medicare payments. In a <a href="https://cdn.ca9.uscourts.gov/datastore/opinions/2016/08/10/13-56746.pdf">2016 decision</a>, the 9th Circuit Court of Appeals wrote that health plans must exercise “due diligence” to ensure they submit accurate data.</p>



<p>Since then, other insurers have settled DOJ allegations that they billed Medicare for unconfirmed diagnoses stemming from chart reviews. In July 2023, Martin’s Point Health Plan, a Portland, Maine, insurer, <a href="https://www.justice.gov/opa/pr/martins-point-health-care-inc-pay-22485000-resolve-false-claims-act-allegations">paid $22,485,000</a> to settle whistleblower allegations that it improperly billed for conditions ranging from diabetes with complications to morbid obesity. The plan denied any liability.</p>



<p>A <a href="https://oig.hhs.gov/oei/reports/oei-03-17-00470.pdf">December 2019 report</a> by the Health and Human Services Inspector General found that 99% of chart reviews added new medical diagnoses at a cost to Medicare of an estimated $6.7 billion for 2017 alone.</p>
	


							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is My Blue Your Blue? (946 pts)]]></title>
            <link>https://ismy.blue/</link>
            <guid>41430258</guid>
            <pubDate>Tue, 03 Sep 2024 01:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ismy.blue/">https://ismy.blue/</a>, See on <a href="https://news.ycombinator.com/item?id=41430258">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Open Mathematics Depository (130 pts)]]></title>
            <link>https://openmathdep.tuxfamily.org/</link>
            <guid>41429515</guid>
            <pubDate>Mon, 02 Sep 2024 23:06:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openmathdep.tuxfamily.org/">https://openmathdep.tuxfamily.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41429515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<hr>
<h3>Open Mathematics Depository</h3>
<hr>
<h4>Depository</h4>

<p>The primary intention of this project is to provide open access to mathematical texts in PDF format which individual mathematicians find particularly useful and which are clearly in the public domain or under open license. This provides a middle ground between large depositories like archive.org which host "everything" and subscription download services which often monopolize access to public domain texts. Please notify us, using the email below, if any of our PDF files are corrupted so that we can re-upload the readable file.

</p><p>The PDFs of our mathematical texts are <a href="http://downloads.tuxfamily.org/openmathdep/">here</a>.

</p><hr>

<h4>Share your mathematics PDFs</h4>

<p>Contributions of texts in PDF form, <b>which are in the public domain or under open license</b>, may be sent to our email below. Please only send texts that you personally find useful and helpful. If you have created interesting bookmarks or notes, feel free to leave them in. The purpose of this project is to be a <b>selective</b> depository, housing texts which people who practice mathematics find worthwhile. Until there are curators for other languages, <b>please send only English texts</b>. Anyone wishing to be the curator for another language is welcome to email us at the address below. The following donations would be greatly appreciated:
</p><ul>
<li>Klein's Elementary Mathematics from an Advanced Standpoint - Geometry
</li><li>Hilbert's Geometry and Imagination
</li><li>Any solid exposition of Grassmann Algebra/Spaces
</li></ul>

<hr>

<h4>Are we violating your copyright?</h4>

<p>If your property is on archive.org, have them remove it and we will
happily follow suit. Most of our pdfs come from there. Otherwise, just
follow these four steps and we'll pull the file.

</p><ol>
<li>Email us using the Project Email below.
</li><li>We will respond with our physical address.
</li><li>Send us a <b>trackable</b> letter establishing your claim.
</li><li>On receipt, we will delete the file and notify you by email.
</li></ol>

<hr>

<address>

<p>Contact info is <a href="http://tangshi.tuxfamily.org/author.html">here</a>

</p></address>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Iranian writer is sentenced to 12 years after tweeting a dot at supreme leader (141 pts)]]></title>
            <link>https://www.npr.org/2024/09/02/g-s1-20579/iran-sentenced-12-years-tweet-supreme-leader</link>
            <guid>41429245</guid>
            <pubDate>Mon, 02 Sep 2024 22:19:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/09/02/g-s1-20579/iran-sentenced-12-years-tweet-supreme-leader">https://www.npr.org/2024/09/02/g-s1-20579/iran-sentenced-12-years-tweet-supreme-leader</a>, See on <a href="https://news.ycombinator.com/item?id=41429245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-20586">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/1100/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" type="image/webp" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" data-format="webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/1100/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" type="image/jpeg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" data-format="jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/1100/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" alt="Supreme Leader Ayatollah Ali Khamenei attends a meeting with the President Masoud Pezeshkian's administration, in Tehran, Iran, Aug. 27." data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2200x1446+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F10%2F68%2F0a0da68c4bc083446dcbb94569c5%2Fap24240396996924.jpg" data-format="jpeg">
        </picture>
</div>
<div>
    <div>
        <p>
                Supreme Leader Ayatollah Ali Khamenei attends a meeting with the President Masoud Pezeshkian's administration, in Tehran, Iran, Aug. 27. 
                <b aria-label="Image credit">
                    
                    Office of the Iranian Supreme Leader/AP
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Office of the Iranian Supreme Leader/AP
        
    </span>
</p></div>
   </div>
   <p>An Iranian writer and activist has been sentenced to 12 years in prison after replying with a single dot, or period, in response to a post on the social platform X by Iran’s supreme leader Ayatollah Ali Khamenei. </p>   <p>Hossein Shanbehzadeh, a longtime critic of Iran’s leadership, was active on social media, supporting political prisoners and the removal of mandatory headscarves for women. He was sent to prison in 2019 for his online comments insulting Khamenei. He later wrote about the experience, including <a href="https://www.voanews.com/a/iran-s-judiciary-alleges-activist-has-ties-to-israeli-spy-agency/7648312.html">being flogged</a>, according to Voice of America.</p>   <p>In early June, 35-year-old Shanbehadeh was arrested in Ardabil, northwestern Iran. According to <a href="https://www.rferl.org/a/iran-blogger-detained-period-ayatollah/32980810.html">Radio Free Europe/Radio Liberty</a>, he told his family he wasn’t sure why he was arrested, but it came shortly after he posted the response to Khamenei’s tweet, which showed the Iranian leader with the country’s national volleyball team.</p>   
   <div id="res1798200454083473901" aria-label="Tweet">
            <blockquote><p lang="en" dir="ltr">The Islamic Republic's security forces on Tuesday arrested Iranian blogger, writer and proofreader Hossein Shanbehzadeh who, last month, posted a single dot in reply to Supreme Leader Ali Khamenei's tweet, and that comment was liked far more than Khamenei's original tweet.… <a href="https://t.co/P4Bram1nr6">pic.twitter.com/P4Bram1nr6</a></p>— Iran International English (@IranIntl_En) <a href="https://twitter.com/IranIntl_En/status/1798200454083473901?ref_src=twsrc%5Etfw">June 5, 2024</a></blockquote>


   </div>
   
<!-- END ID="RES1798200454083473901" CLASS="BUCKETWRAP TWITTER LARGE GRAPHIC" ARIA-LABEL="TWEET" -->
   <p>Shanbehzadeh’s post received far more “likes” than Khamenei’s original tweet, according to <a href="https://www.iranintl.com/en/202408311891">Iran International English</a>.</p>   
   
<!-- END ID="RESG-S1-20579-101" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Shanbehzadeh is just the latest activist to be caught up in the hard-line government’s crackdown on critics. Iran watchers say the leadership has felt insecure about the high level of dissent in the country for a while. Artists, playwrights, directors and others are also being swept up and given long prison sentences. In late April, Iranian rapper <a href="https://www.npr.org/2024/04/30/1248245576/iranian-rapper-receives-death-sentence-for-songs-criticizing-the-establishment" target="1248245576">Toomaj Salehi</a> was handed the death sentence for his antigovernment videos.</p>   <p>Shanbehzadeh was sentenced to five years for alleged pro-Israel propaganda activity, four years for insulting Islamic sanctities, two years for spreading lies online and an additional year for anti-regime propaganda.</p>   <p>His lawyer, Amir Raisian, told Shargh Network, a reformist newspaper in Iran, that he would appeal the verdict, especially the accusation of pro-Israel activity. The prosecutor’s office in Ardabil alleged that Shanbehzadeh had been in contact with Israeli intelligence officers and was arrested when trying to leave the country, according to Voice of America.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playdate Game Zero Zero: Perfect Stop (163 pts)]]></title>
            <link>https://play.date/games/zero-zero/</link>
            <guid>41429232</guid>
            <pubDate>Mon, 02 Sep 2024 22:16:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play.date/games/zero-zero/">https://play.date/games/zero-zero/</a>, See on <a href="https://news.ycombinator.com/item?id=41429232">Hacker News</a></p>
<div id="readability-page-1" class="page">



    
        <nav id="navbar">
    <ul>
        <li id="nav-home">
            <a href="https://play.date/">
                Playdate
            </a>
        </li>
        <li id="nav-buy">
            
                
                    <a href="https://play.date/shop/">
                        Buy Now<i>!!</i>
                    </a>
                
            
        </li>
        <label for="whopper">Show menu</label>
        
        
    </ul>
</nav>
    

    

    
    <main id="main" role="main">
        

        

        

    <header>
        
    
        
            <img src="https://media-cdn.play.date/media/games/340143/Web_feature_dQlGhEX.png" alt="Zero Zero: Perfect Stop">
        
    
    
        
            <nav id="breadcrumb">
                <ul>
                    <li>
                        <a href="https://play.date/games/">Catalog</a>
                    </li>
                    <li>
                        <a href="https://play.date/games/tags/racing/">Racing</a>
                    </li>
                    
                    <li>
                        <a href="https://play.date/games/tags/action/">Action</a>
                    </li>
                    
                </ul>
            </nav>
        
    
    </header>
    
    <div id="gameListing">
            <div id="gameListingTitle">
                <h2 id="game340143">
                    
                        <img src="https://media-cdn.play.date/media/games/340143/Web_title_RPFfLKk.png" alt="Zero Zero: Perfect Stop">
                    
                </h2>
            </div>
            
            
                
                <div id="gameListingAuthor">
                    <h2>Made by Hunter Bridges</h2>
                </div>
                
            
            
            
            <div id="gameListingDescription">
                
                
                
                <p>Challenge your skills as a train driver! Stop in the right place, at the right time. Maintain your timetable as you glide through scenic Yamanashi. Welcome aboard the Fuji Express!</p>

<p><i>Zero Zero: Perfect Stop</i> is a train driving game where you use the crank to control the train's throttle and brakes.</p>

<p>In <b>Driver's Mode</b>, navigate the course diagram, observe speed limits, and achieve target objectives as you try to stop at each station as punctually and precisely as possible. Challenge 1-stop, 3-stop, 5-stop, and Express diagrams along the Fuji Express as you approach Mt. Fuji.</p>

<p>Challenge your own high scores, or other drivers' across the globe on the online leaderboards.</p>

<p>Or, enjoy the sights with no stress in <b>Free Mode</b>! There is also a <b>Tutorial</b> for new players.</p>

<p>Enjoy the vast scenery, and a unique challenge of patience and precision!</p>

<p>(This game supports English and Japanese)<br>
(このゲームは日本語でもＯＫです)</p>
            </div>
            
                
            
            
                
                <section id="gameListingScoreboards">

                    <h3>Scoreboards</h3>

                    
                    <div>
                        <h4>09 - Mitsutouge to Mt. Fuji, Express</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>984,924</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>983,296</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>979,804</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Phiroth</dd>
                                    <dd>927,894</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>919,522</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>1655044158154447</dd>
                                    <dd>884,037</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>jontomato</dd>
                                    <dd>877,104</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>SpaceJace</dd>
                                    <dd>876,146</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>orkn</dd>
                                    <dd>871,456</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>858,876</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>01 - Mitsutouge to Mt. Fuji, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>Mamaluigi145</dd>
                                    <dd>977,402</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>971,680</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>956,436</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>942,069</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>915,910</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>912,742</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>hunty</dd>
                                    <dd>905,879</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>6229233127285014</dd>
                                    <dd>890,993</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>india</dd>
                                    <dd>874,529</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>Phiroth</dd>
                                    <dd>850,312</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>02 - Mitsutouge to Kotobuki, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>975,988</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>974,033</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>973,900</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Mamaluigi145</dd>
                                    <dd>968,333</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>962,333</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>945,754</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>stefb</dd>
                                    <dd>941,033</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>SpaceJace</dd>
                                    <dd>934,467</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>hunty</dd>
                                    <dd>920,933</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>6229233127285014</dd>
                                    <dd>909,197</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>03 - Kotobuki to Yoshiike Onsenmae, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>989,634</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>984,525</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>977,500</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>957,516</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>6229233127285014</dd>
                                    <dd>939,768</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>Phiroth</dd>
                                    <dd>938,947</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>9808599591265569</dd>
                                    <dd>932,714</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>929,315</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>0572717345646741</dd>
                                    <dd>927,569</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>3396169507696406</dd>
                                    <dd>927,334</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>04 - Yoshiike Onsenmae to Shimoyoshida, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>985,679</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>974,760</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>973,580</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>966,919</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>hunty</dd>
                                    <dd>962,436</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>SpaceJace</dd>
                                    <dd>961,683</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>7933707719207984</dd>
                                    <dd>947,405</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>stefb</dd>
                                    <dd>934,399</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>924,151</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>kohlrobi</dd>
                                    <dd>922,099</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>05 - Shimoyoshida to Gekkoji, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>981,338</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>979,709</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>hunty</dd>
                                    <dd>975,689</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>958,721</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>heyimludo</dd>
                                    <dd>958,283</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>3396169507696406</dd>
                                    <dd>952,002</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>951,178</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>marinebean</dd>
                                    <dd>938,452</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>stefb</dd>
                                    <dd>937,714</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>Saiklex</dd>
                                    <dd>934,937</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>06 - Gekkoji to Mt. Fuji, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>974,089</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>969,487</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>Mamaluigi145</dd>
                                    <dd>961,996</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>951,436</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>945,100</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>934,598</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>rae</dd>
                                    <dd>929,196</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>8667528259685510</dd>
                                    <dd>922,046</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>Saiklex</dd>
                                    <dd>917,554</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>SpaceJace</dd>
                                    <dd>909,992</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>07 - Mitsutouge to Shimoyoshida, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>973,102</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>961,250</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>945,504</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Mamaluigi145</dd>
                                    <dd>904,935</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>stefb</dd>
                                    <dd>902,617</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>876,920</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>873,654</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>idolminds</dd>
                                    <dd>865,841</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>Phiroth</dd>
                                    <dd>856,137</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>5924328230044621</dd>
                                    <dd>844,768</dd>
                                
                            
                        
                        </dl>
                    </div>
                    
                    <div>
                        <h4>08 - Yoshiike Onsenmae to Mt. Fuji, Local</h4>
                        <dl>
                        
                            
                                
                                    <dt>
                                        <span>1</span>
                                    </dt>
                                    <dd>SoinkstersChris</dd>
                                    <dd>971,502</dd>
                                
                                    <dt>
                                        <span>2</span>
                                    </dt>
                                    <dd>Glenjamin</dd>
                                    <dd>965,809</dd>
                                
                                    <dt>
                                        <span>3</span>
                                    </dt>
                                    <dd>Moppi</dd>
                                    <dd>949,659</dd>
                                
                                    <dt>
                                        <span>4</span>
                                    </dt>
                                    <dd>Mamaluigi145</dd>
                                    <dd>939,712</dd>
                                
                                    <dt>
                                        <span>5</span>
                                    </dt>
                                    <dd>zipmon</dd>
                                    <dd>936,016</dd>
                                
                                    <dt>
                                        <span>6</span>
                                    </dt>
                                    <dd>IvanJoukov</dd>
                                    <dd>895,580</dd>
                                
                                    <dt>
                                        <span>7</span>
                                    </dt>
                                    <dd>rae</dd>
                                    <dd>884,567</dd>
                                
                                    <dt>
                                        <span>8</span>
                                    </dt>
                                    <dd>6229233127285014</dd>
                                    <dd>878,793</dd>
                                
                                    <dt>
                                        <span>9</span>
                                    </dt>
                                    <dd>Saiklex</dd>
                                    <dd>866,749</dd>
                                
                                    <dt>
                                        <span>10</span>
                                    </dt>
                                    <dd>bechamel</dd>
                                    <dd>859,615</dd>
                                
                            
                        
                        </dl>
                    </div>
                    

                </section>
                
            
            
                <section id="gameListingMoreInfo">
                    <h3>More cool info</h3>
                    <ul>
                        
                        
                            
                                <li>
                                    <label for="link-1">
                                        <a name="link-1" href="https://hunterbridges.com/zerozero.html">Website</a>
                                    </label>
                                </li>
                            
                                <li>
                                    <label for="link-2">
                                        <a name="link-2" href="https://blog.hunterbridges.com/zerozero/guide/">Player's Guide</a>
                                    </label>
                                </li>
                            
                                <li>
                                    <label for="link-3">
                                        <a name="link-3" href="https://hunty.bandcamp.com/album/zero-zero-perfect-stop-original-soundtrack">Original Soundtrack</a>
                                    </label>
                                </li>
                            
                        
                        
                            <li>
                                <label for="link-support">
                                    <a href="mailto:support@hunterbridges.com">Game support</a>
                                </label>
                            </li>
                        
                    </ul>
                </section>
            
            
            
                
                <section id="gameListingFeaturedIn">
                    
                    <h3>Featured In…</h3>
                
                    
                    <ul>                    
                        <li>
                            <a href="https://play.date/games/tags/racing/">Racing</a>
                        </li>
                        
                        <li>
                            <a href="https://play.date/games/tags/action/">Action</a>
                        </li>
                        
                    </ul>
                    
                </section> 
                
            
            
            
            
                
            
        </div>
    

    

    

    
        


    

    </main>
    

    

    
    




    
    
    
    
    



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Long-term unemployment leads to disengagement and apathy (115 pts)]]></title>
            <link>https://www.psypost.org/long-term-unemployment-leads-to-disengagement-and-apathy-rather-than-efforts-to-regain-control/</link>
            <guid>41429156</guid>
            <pubDate>Mon, 02 Sep 2024 22:03:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/long-term-unemployment-leads-to-disengagement-and-apathy-rather-than-efforts-to-regain-control/">https://www.psypost.org/long-term-unemployment-leads-to-disengagement-and-apathy-rather-than-efforts-to-regain-control/</a>, See on <a href="https://news.ycombinator.com/item?id=41429156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="psypo-1426812380"><p><a href="https://news.google.com/publications/CAAqBwgKMLz2gwsw-5CAAw" aria-label="Follow PsyPost on Google News"><img decoding="async" src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" data-src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" alt="Follow PsyPost on Google News" data-srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w" data-sizes="(max-width: 510px) 100vw, 510px" width="250" height="85" srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w"></a></p></div><p>New research published in the <a href="https://doi.org/10.1111/jopy.12967"><em>Journal of Personality</em></a> reveals that prolonged unemployment is strongly correlated with loss of personal control and subsequent disengagement both psychologically and socially.</p><p>The need for control is a fundamental aspect of human motivation, and when this need is unmet, it can lead to significant psychological consequences. Past research has explored control loss through experimental manipulations, but questions remain about the ecological validity of these findings. This study, led by Wiktor Soral and colleagues, aimed to address these concerns by investigating the real-world implications of prolonged unemployment—a situation that severely threatens personal control.</p><p>Unemployment is a significant stressor with far-reaching impacts on mental health. It strips individuals of both the explicit benefits of employment, such as income, and the implicit ones, like structured time and social connections. Building on this understanding, Soral and colleagues focused on how prolonged unemployment might alter psychological functioning and social adaptation. Specifically, they explored whether these changes manifest as disengagement and helplessness, or if there are attempts to regain lost control.</p><p>The study involved a sample of 1,055 Polish participants, with 748 unemployed individuals and 307 employed individuals serving as a control group. The unemployed participants were categorized based on the length of their unemployment: short-term (0-3 months), medium-term (4-12 months), and long-term (over 12 months).</p><p>The survey collected demographic information, including age, gender, education level, and place of residence. Participants completed a variety of measures to assess well-being, self-esteem, perceived control (personal, political, and fatalistic), emotions, stress coping strategies, and social attitudes. The study also examined variables that could indicate control regaining efforts, such as active coping and collective action, as well as those suggesting disengagement, like withdrawal and anti-democratic beliefs. Data collection occurred in two parts, with participants completing the second part of the survey within two weeks of the first. Only participants who completed both parts were included in the final analysis, resulting in a total of 854 participants.</p><p>Soral and colleagues found that prolonged unemployment is strongly associated with a decline in well-being and self-esteem, alongside an increased perception of personal and fatalistic control loss. As unemployment duration lengthened, participants reported more negative emotions, particularly those related to low-approach and avoidance, such as feeling depressed or frightened.</p><p>They also exhibited fewer positive emotions, especially those linked to active engagement like enthusiasm. This emotional disengagement was accompanied by a significant reduction in active stress coping strategies and a decrease in the pursuit of personal projects and future-oriented goals. The findings suggest that long-term unemployment fosters a sense of learned helplessness, where individuals become increasingly demotivated and pessimistic about their ability to regain control over their lives.</p><p>Socially, the study revealed that long-term unemployed individuals are more likely to disengage from social and political activities. They reported lower levels of national identification and a reduced likelihood of participating in collective actions, such as protests. Additionally, these individuals exhibited higher levels of psychological defensiveness, including increased individual and collective narcissism, and a greater tendency to blame external entities, like governments or corporations, for their unemployment.</p><p>Interestingly, the study did not find evidence that these individuals turned to external sources of control, such as belief in an intervening God or system justification, suggesting that while they become more defensive and disengaged, they do not necessarily seek comfort or control through external systems.</p><p>One limitation noted by the authors is the cross-sectional nature of the study, which prevents establishing causality.</p><p>The study, “<a href="https://doi.org/10.1111/jopy.12967">Prolonged unemployment is associated with control loss and personal as well as social disengagement</a>”, was authored by Wiktor Soral, Marcin Bukowski, Michał Bilewicz, Aleksandra Cichocka, Karol Lewczuk, Marta Marchlewska, Aleksandra Rabinovitch, Anna Rędzio, Magdalena Skrodzka, and Mirosław Kofta.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Art of Finishing (567 pts)]]></title>
            <link>https://www.bytedrum.com/posts/art-of-finishing/</link>
            <guid>41428705</guid>
            <pubDate>Mon, 02 Sep 2024 20:51:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bytedrum.com/posts/art-of-finishing/">https://www.bytedrum.com/posts/art-of-finishing/</a>, See on <a href="https://news.ycombinator.com/item?id=41428705">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>It’s a quiet Saturday afternoon. I’ve carved out a few precious hours for coding, armed with a steaming cup of coffee and the familiar urge to dive into a project. As I settle into my chair and open my terminal, I’m confronted with a challenge that’s become all too familiar: deciding which of my many unfinished projects to tackle.</p>
<p>I navigate to my project directory, greeted by a graveyard of half-implemented ideas and stalled works-in-progress. Each one represents a different problem I’ve tried to solve, a different technology I’ve attempted to master. They’re all interesting, each with its own purpose and potential. But as I scan through them, I can already feel my enthusiasm waning. I know that whichever one I choose, I’ll be facing not just the original problem, but a hydra of new challenges that have sprouted since I last looked at the code.</p>
<p>After some deliberation, I make my choice and fire up my IDE. As I pull the latest changes and begin the archaeological dig through my commit history, I brace myself for what I know I’ll find. Sure enough, there it is: an unfinished frontend task, more wireframe than polished UI. Or perhaps it’s a library integration that’s hitting limitations I hadn’t anticipated. Or, in classic over-engineering fashion, I’ve built a complex architecture for a problem that could have been solved with a simple script.</p>
<p>I roll up my sleeves and dive in, determined to make progress. The next couple of hours fly by in a flurry of activity—refactoring code, debugging integration issues, or wrestling with CSS to get that one component to align just right. Before I know it, my allocated time is up.</p>
<p>As I prepare to step away from my desk, I can’t shake a feeling of frustration. I started the session full of optimism, ready to make significant headway. Now, I’m left with a nagging sense of inadequacy. Despite my efforts, it feels like I’ve barely moved the needle. The codebase is still a maze of TODO comments and half-implemented features. The Hydra of software development has grown two new heads for every one I managed to address.</p>
<p>This cycle of enthusiasm, struggle, and disappointment has become all too familiar. It’s the Hydra Project Effect: no matter how much progress I make, new challenges always seem to sprout in their place. But while this pattern may seem unbreakable, I’m determined to find a way to tame this beast. In this post, I’ll explore strategies for breaking out of this cycle of endless beginnings and unsatisfying middles. It’s time to learn the art of finishing, to slay this Hydra once and for all, and to finally experience the satisfaction of a completed project.</p>
<p><img src="https://www.bytedrum.com/_astro/project-hydra.DXkDZcWk_1DYUan.svg" alt="My Hydra looks amazing, I am fantastic at drawing" width="662" height="896" loading="lazy" decoding="async"></p>
<h2 id="the-allure-of-the-endless-project">The Allure of the Endless Project</h2>
<p>There’s a certain comfort in the realm of infinite possibility. When a project is ongoing, it can be anything. It’s Schrödinger’s<sup><a href="#user-content-fn-schrodinger" id="user-content-fnref-schrodinger" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> project—simultaneously perfect and flawed until you actually finish it and put it out into the world. The moment you declare a project “done,” you open it up to criticism, both external and internal. What if it’s not good enough? What if I missed something crucial?</p>
<p>This fear of finality, combined with the excitement of new ideas, creates an ideal environment for project procrastination. It’s always easier to start something new than to push through the final, often tedious stages of completion of a project. But there’s more to it than just fear.</p>
<p>An unfinished project is full of intoxicating <em>potential</em>. It could be the next big thing, a revolutionary idea, or your magnum opus. This potential often feels more exciting than the reality of a finished product. There’s also comfort in the familiar territory of an ongoing project. You know the codebase, you understand the problems, and you’re in your element. Starting something new means facing the unknown, which can be daunting.</p>
<p>The illusion of productivity plays a significant role too. As long as you’re working on something, you feel productive. Jumping from project to project gives you a constant stream of “new project energy,” which can feel more invigorating than the grind of finishing a single project. It’s a way of avoiding difficult decisions that come with completion. Do you cut that feature you spent weeks on but isn’t quite right? Do you release now or spend another month polishing? By keeping projects ongoing, you can sidestep these challenging choices.</p>
<p>The absence of deadlines in personal projects adds another layer to this complexity<sup><a href="#user-content-fn-parkinson-law" id="user-content-fnref-parkinson-law" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>. Without the external pressure of a due date, it’s all too easy to fall into the trap of perfectionism. We find ourselves endlessly tweaking and refining, always chasing that elusive “perfect” solution. The irony is that this pursuit of perfection often leads to imperfect results—or no results at all. In our professional lives, deadlines force us to prioritize and make pragmatic decisions. But in personal projects, the luxury of unlimited time can become a curse, allowing us to justify spending hours, days, or even weeks on minor details that, in reality, make little difference to the project’s overall success or usefulness. It’s a stark reminder that sometimes, “good enough” truly is perfect, especially when the alternative is never finishing at all.</p>
<p>Paradoxically, sometimes we fear success as much as failure. A successful project might lead to increased expectations, more responsibility, or a change in identity that we’re not quite ready for. The unfinished project becomes a safety net, protecting us from the unknown consequences of success.</p>
<p><img src="https://www.bytedrum.com/_astro/project-timeline.DMCtX1xG_ZKINeB.svg" alt="My typical project timeline graph" width="1017" height="1379" loading="lazy" decoding="async"></p>
<h2 id="the-cost-of-never-finishing">The Cost of Never Finishing</h2>
<p>But this cycle of endless beginnings comes at a steep price. There’s a unique satisfaction in seeing a project through to completion that no amount of starting can match. Moreover, unfinished projects carry a mental weight. They linger in the back of your mind, quietly draining your mental energy and enthusiasm.</p>
<p>Perhaps most importantly, we learn different lessons from finishing projects than we do from starting them. Starting teaches us about ideation and initial implementation. Finishing, on the other hand, teaches us about perseverance, attention to detail, and the art of knowing when to let go. These are invaluable skills that can only be honed through the act of completion.</p>
<p>The costs of never finishing extend far beyond just missed opportunities. While starting projects might expose you to new technologies or concepts, it’s in the act of finishing—of solving those last, trickiest problems—where real <em>skill growth</em> often occurs. Each unfinished project can chip away at your confidence. Over time, you might start to doubt your ability to complete anything substantial, creating a self-fulfilling prophecy of incompletion.</p>
<p>The end stages of a project often involve optimization, refactoring, and really understanding the intricacies of your code. By not finishing, you miss out on these valuable learning experiences. In professional settings, being known as someone who starts things but doesn’t finish them can be detrimental to your career. Employers and clients value those who can deliver completed projects, making the ability to finish a crucial professional skill.</p>
<p>Every unfinished project takes up mental space. It’s like having dozens of browser tabs open—each one uses a little bit of your mental RAM, leaving you with less capacity for new ideas and focused work. This mental clutter can be a significant drain on your creativity and productivity.</p>
<p>Perhaps most importantly, you deny yourself the incomparable feeling of satisfaction when you release a finished project into the world. There’s a <em>joy in shipping</em> that can’t be replicated by starting something new. Finished projects also invite feedback, and without shipping, you miss out on valuable insights from users or peers that could significantly improve your skills and future projects.</p>
<p>Understanding both the allure of endless projects and the cost of never finishing is crucial. It’s not about dismissing the excitement of new beginnings, but rather about finding a balance—learning to channel that initial enthusiasm into the equally important (if sometimes less glamorous) work of seeing things through to completion. By recognizing these patterns in ourselves, we can start to develop strategies to overcome them and finally slay the Project Hydra.</p>
<h2 id="strategies-for-taming-the-project-hydra">Strategies for Taming the Project Hydra</h2>
<p>So, how do I break this cycle? How do I learn to finish what I start? Here are some strategies I’m implementing to tame my own Project Hydra:</p>
<ol>
<li>
<p>✅ <strong>Define “Done” from the Start</strong>: Before diving into a project, I’ll clearly define what “finished” looks like. What are the core features that constitute a complete project? I’ll write them down and resist the urge to expand this list as I go. This clarity helps prevent scope creep and gives me a clear target to aim for.</p>
</li>
<li>
<p>🚀 <strong>Embrace MVP</strong>: Instead of aiming for perfection, I’ll aim for “good enough.” I’ll get a basic version working and out into the world. I can always iterate and improve later. This approach helps maintain momentum and provides early feedback opportunities.</p>
</li>
<li>
<p>⏳ <strong>Time-Box My Projects</strong>: I’ll give myself a deadline. It doesn’t have to be short, but it should be finite. Having an end date creates urgency and helps me prevent endless feature creep. I find that breaking larger projects into smaller, time-boxed phases helps maintain a sense of progress.</p>
</li>
<li>
<p>🧩 <strong>Practice Finishing Small Things</strong>: I’ll build my “finishing muscle” by completing small projects or tasks regularly. I recognize that the skill of finishing is like any other—it improves with practice. This could be as simple as finishing a blog post or completing a small coding challenge each week.</p>
</li>
<li>
<p>💡 <strong>Separate Ideation from Implementation</strong>: I’ll keep a separate idea log. When new features or project ideas pop up during implementation, I’ll jot them down for future consideration instead of immediately acting on them. This helps maintain focus on the current project while still capturing potentially valuable ideas.</p>
</li>
<li>
<p>🎉 <strong>Celebrate Completions</strong>: I’ll make finishing a big deal. I’ll celebrate when I complete a project, no matter how small. This positive reinforcement can help shift my mindset towards completion. Whether it’s treating myself to a nice dinner or simply sharing my accomplishment with friends, acknowledging these wins boosts motivation for future projects.</p>
</li>
<li>
<p>👥 <strong>Embrace Accountability</strong>: I’ll find ways to make myself accountable for finishing projects. This could involve finding an accountability partner, making public commitments about project milestones, or joining a group of fellow developers. External accountability adds motivation and support to the often solitary journey of personal projects.<sup><a href="#user-content-fn-accountability-study" id="user-content-fnref-accountability-study" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
</li>
</ol>
<p>These strategies provide my personal roadmap for overcoming the challenges of the Project Hydra. By implementing them consistently, I hope to develop better habits and increase my chances of seeing projects through to completion. It’s about creating a supportive structure around my work, balancing internal motivation with external accountability, and gradually building the skill of finishing.</p>
<p>Of course, strategies are just the beginning. The real challenge lies in consistently applying these approaches to my work. It’s a process of trial and error, of learning what works best for my personal style and the specific demands of each project. But with each small win, with each project pushed a little closer to completion, I’m building the habits and mindset needed to finally tame the Project Hydra.</p>
<h2 id="the-path-forward">The Path Forward</h2>
<p>The path ahead will be challenging. I know that changing ingrained habits and thought patterns will take time and consistent effort. There will likely be setbacks along the way – moments when the allure of a new project tempts me away from finishing the current one, or when the fear of imperfection makes me hesitate to declare something “done”. But I’m committed to pushing through these obstacles and building my “finishing muscle”.</p>
<p>This journey isn’t just about completing code; it’s about growing as a developer and creator. Each finished project, no matter how small, is a step towards becoming someone who not only starts with enthusiasm but finishes with satisfaction.</p>
<p>The Project Hydra has loomed over my work for too long. Armed with new strategies and determination, I’m ready to face this beast head-on. It’s time to stop planning and start doing.</p>
<p>Now, if you’ll excuse me, I have a project to finish – and this time, I intend to see it through.<sup><a href="#user-content-fn-final-note" id="user-content-fnref-final-note" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup></p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-schrodinger">
<p>Unlike the cat, however, most unfinished projects are neither alive nor dead - they’re just taking up space on our <del>hard</del> <del>SSD</del> NVMe drives. <a href="#user-content-fnref-schrodinger" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-parkinson-law">
<p>This phenomenon is closely related to <a href="https://en.wikipedia.org/wiki/Parkinson%27s_law#First_meaning">Parkinson’s Law</a>, which states that “work expands so as to fill the time available for its completion.” In personal projects, the available time is often infinite, leading to endless expansion. <a href="#user-content-fnref-parkinson-law" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-accountability-study">
<p>A study by the American Society of Training and Development found that people have a 65% chance of completing a goal if they commit to someone else. That chance increases to 95% when they have a specific accountability appointment with the person they’ve committed to. <a href="#user-content-fnref-accountability-study" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-final-note">
<p>I finished this article in one sitting, fueled by determination and an alarming amount of coffee. No Hydras were harmed in the making of this blog post. <a href="#user-content-fnref-final-note" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
</ol>
</section> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Light-based technique shows 90% accuracy in early prostate cancer detection (121 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-09-based-technique-accuracy-early-prostate.html</link>
            <guid>41428478</guid>
            <pubDate>Mon, 02 Sep 2024 20:18:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-09-based-technique-accuracy-early-prostate.html">https://medicalxpress.com/news/2024-09-based-technique-accuracy-early-prostate.html</a>, See on <a href="https://news.ycombinator.com/item?id=41428478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/researcher-uses-light.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/researcher-uses-light.jpg" data-sub-html="Microscopic and histological images of blood smears and prostate tissue biopsies—thin (2–5 µm) films, respectively: (a) and (d) show blood smears and prostate tissue at normal conditions; (b) and (e) depict high-differentiation adenocarcinoma conditions; (c) and (f) illustrate low-differentiation adenocarcinoma. Credit: <i>Scientific Reports</i> (2024). DOI: 10.1038/s41598-024-63816-z">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/researcher-uses-light.jpg" alt="Researcher uses light to develop quicker, cheaper and less painful technique to detect prostate cancer" title="Microscopic and histological images of blood smears and prostate tissue biopsies—thin (2–5 µm) films, respectively: (a) and (d) show blood smears and prostate tissue at normal conditions; (b) and (e) depict high-differentiation adenocarcinoma conditions; (c) and (f) illustrate low-differentiation adenocarcinoma. Credit: Scientific Reports (2024). DOI: 10.1038/s41598-024-63816-z" width="800" height="530">
             <figcaption>
                Microscopic and histological images of blood smears and prostate tissue biopsies—thin (2–5 µm) films, respectively: (a) and (d) show blood smears and prostate tissue at normal conditions; (b) and (e) depict high-differentiation adenocarcinoma conditions; (c) and (f) illustrate low-differentiation adenocarcinoma. Credit: <i>Scientific Reports</i> (2024). DOI: 10.1038/s41598-024-63816-z
            </figcaption>        </figure>
    </div><p>An Aston University researcher has used light to develop the first step towards a quicker, cheaper and less painful technique to detect cancer.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>Professor Igor Meglinski from the University's Aston Institute of Photonic Technologies led the team that has developed a new method of analyzing the crystals in dehydrated blood. Their paper "Insights into polycrystalline microstructure of blood films with 3D Mueller matrix imaging approach" has been <a href="https://www.nature.com/articles/s41598-024-63816-z" target="_blank">published</a> in the journal <i>Scientific Reports</i>.</p>
<p>Professor Meglinski used a new polarization-based image reconstruction technique to analyze polycrystalline structures in dried blood samples. The proteins in blood change their shape and how they fit together during the early stages of diseases like cancer. Professor Meglinski and his team used changes in the proteins' tertiary structure or unique 3D shape together with its quaternary structure—which is how multiple proteins join together—to detect and classify cells.</p>
<p>This technique enabled the researchers to conduct a detailed layer-by-layer analysis of dry blood smears, which is crucial for identifying significant differences between healthy and cancerous samples.</p>
<p>The researchers analyzed 108 blood film samples from three equal size groups: healthy volunteers, those who had <a href="https://medicalxpress.com/tags/prostate+cancer/" rel="tag">prostate cancer</a> and a third group who had the illness and had cells that were more likely to aggressively spread.</p>
<p>Professor Meglinski said, "Our study introduces a pioneering technique to the liquid biopsy domain, aligning with the ongoing quest for non-invasive, reliable and efficient diagnostic methods. A key advancement in our study is the characterization of the mean, variance, skewness, and kurtosis of distributions with the cells which is crucial for identifying significant differences between healthy and cancerous samples.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>"This breakthrough opens new avenues for cancer diagnosis and monitoring, representing a substantial leap forward in personalized medicine and oncology."</p>
<p>The study's findings had a 90% accuracy rate of both <a href="https://medicalxpress.com/tags/early+diagnosis/" rel="tag">early diagnosis</a> and classification of cancer which is much higher than existing screening methods. Also, as the technique relies on <a href="https://medicalxpress.com/tags/blood+samples/" rel="tag">blood samples</a> instead of tissue biopsies, it is less traumatic and risky for patients.</p>
<p>Professor Meglinski added, "This high level of precision, combined with the non-invasive nature of the technique, marks a significant advancement in liquid biopsy technology. It holds immense potential for revolutionizing <a href="https://medicalxpress.com/tags/cancer+diagnosis/" rel="tag">cancer diagnosis</a>, early detection, patient stratification and monitoring, thereby greatly enhancing <a href="https://medicalxpress.com/tags/patient+care/" rel="tag">patient care</a> and treatment outcomes.</p>
<p>"This study also presents a testament to the resilience and support of our Ukrainian colleagues involved in the research, especially in light of the ongoing conflict in Ukraine."</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Alexander G. Ushenko et al, Insights into polycrystalline microstructure of blood films with 3D Mueller matrix imaging approach, <i>Scientific Reports</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1038/s41598-024-63816-z" target="_blank">DOI: 10.1038/s41598-024-63816-z</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Novel light-based technique shows 90% accuracy in early prostate cancer detection (2024, September 2)
                                                 retrieved 3 September 2024
                                                 from https://medicalxpress.com/news/2024-09-based-technique-accuracy-early-prostate.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web scraping with GPT-4o: powerful but expensive (284 pts)]]></title>
            <link>https://blancas.io/blog/ai-web-scraper/</link>
            <guid>41428274</guid>
            <pubDate>Mon, 02 Sep 2024 19:50:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blancas.io/blog/ai-web-scraper/">https://blancas.io/blog/ai-web-scraper/</a>, See on <a href="https://news.ycombinator.com/item?id=41428274">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        
        <!-- <h1>Using GPT-4o for web scraping</h1> -->
<!-- <p>28 Aug 2024 - </p> -->

<p>tl;dr; show me the <a href="#conclusions-and-demo">demo and source code!</a></p>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/app.png" alt="app"></p>

<p>I’m pretty excited about the new <a href="https://platform.openai.com/docs/guides/structured-outputs">structured outputs</a>
feature in OpenAI’s API so I took it for a spin and developed an AI-assisted web scraper. This post summarizes my learnings.</p>

<h2 id="asking-gpt-4o-to-scrape-data">Asking GPT-4o to scrape data</h2>

<p>The first experiment was to straight ask GPT-4o to extract the data from an HTML
string, so I used the new structured outputs feature with the following <a href="https://docs.pydantic.dev/latest/">Pydantic</a> models:</p>

<div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Dict</span>

<span>class</span> <span>ParsedColumn</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>values</span><span>:</span> <span>List</span><span>[</span><span>str</span><span>]</span>


<span>class</span> <span>ParsedTable</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>columns</span><span>:</span> <span>List</span><span>[</span><span>ParsedColumn</span><span>]</span>
</code></pre></div>

<p>The system prompt is:</p>

<blockquote>
  <p>You’re an expert web scraper. You’re given the HTML contents of a table and you have to extract structured data from it.</p>
</blockquote>

<p>Here are some interesting things I found when parsing different tables.</p>

<p><em>Note:</em> I also tried GPT-4o mini but yielded significantly worse results so I just continued my experiments with GPT-4o.</p>

<h2 id="parsing-complex-tables">Parsing complex tables</h2>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/image.png" alt="alt text"></p>

<p>After experimenting with some simple tables, I wanted to see how the model would do with a more complex ones, so I passed a 10-day <a href="https://weather.com/">weather</a> forecast from Weather.com. The table
contains a big row for at the top and smaller rows for the other 9
days. Interestingly, GPT-4o was able to parse this correctly:</p>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/image-1.png" alt="alt text"></p>

<p>For the 9 remaining days, the table shows a day and a night forecast (see screenshot above). The model correctly parsed such data and added a <code>Day/Night</code> column. Here’s how it looks like in the browser (note that to display this, we need to click on the button to the right of each row):</p>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/image-2.png" alt="alt text"></p>

<p>At first, I thought that the parsed <code>Condition</code> column was a hallucination since I did not see that in the website, however, upon inspecting the source code, I realized that those tags exist but are invisible in the table.</p>

<h2 id="combined-rows-break-the-model">Combined rows break the model</h2>

<p>When thinking where to find <em>easy tables</em>, my first thought was <em>Wikipedia</em>. Turns out, a <em>simple</em> table from Wikipedia (<a href="https://en.wikipedia.org/wiki/Human_Development_Index">Human development index</a>) breaks the model because rows with repeated values are merged:</p>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/image-3.png" alt="alt text"></p>

<p>And while the model is able to retrieve individual columns (as instructed by the system prompt), they don’t have the same size, hence, I’m unable to represent the data as a table.</p>

<p>I tried modifying the system prompt with the following:</p>

<blockquote>
  <p>Tables might collapse rows into a single row. If that’s the case, extract the collapsed row as multiple JSON values to ensure all columns contain the same number of rows.</p>
</blockquote>

<p>But it didn’t work. I have yet to try modifying the system prompt
to tell the model to extract rows instead of columns.</p>

<h2 id="asking-gpt-4o-to-return-xpaths">Asking GPT-4o to return XPaths</h2>

<p>Running an OpenAI API call every time can become very expensive, so I figured I’d ask the model to return <a href="https://developer.mozilla.org/en-US/docs/Web/XPath">XPaths</a> instead of
the parsed data. This would allow me to scrape the same page (e.g., to fetch updated data) without breaking the bank.</p>

<p>After some tweaks, I came up with this prompt:</p>

<blockquote>
  <p>You’re an expert web scraper.</p>

  <p>The user will provide the HTML content and the column name.
Your job is to come up with an XPath that will return all elements of that column.</p>

  <p>The XPath should be a string that can be evaluated by Selenium’s
<code>driver.find_elements(By.XPATH, xpath)</code> method.</p>

  <p>Return the full matching element, not just the text.</p>
</blockquote>

<p>Unfortunately, this didn’t work well. Sometimes, the model would return invalid XPaths (although
this was alleviated with the sentence that mentions Selenium) or XPaths that would
return incorrect data or no data at all.</p>

<h2 id="combining-the-two-approaches">Combining the two approaches</h2>

<p>My next attempt was to combine both approaches: once the model extracted the data,
we could use it as a reference to ask the model for the XPath. <em>This worked much better than straight asking for XPaths!</em></p>

<p>I noticed that sometimes the generated XPath would return no data at all so I added
some dumb retry logic: if the XPath returns no results, try again. This did the trick for
the tables I tested.</p>

<p>However, I noticed a new issue: sometimes the first step (extract data) converted images into text (e.g. an arrow pointing upwards might appear in the
extracted data as “arrow-upwards”), this caused the second step to fail since it’d look for data that wasn’t there. I did not attempt to fix this problem.</p>

<h2 id="gpt-4o-is-very-expensive">GPT-4o is very expensive</h2>

<p><img src="https://blancas.io/assets/images/ai-web-scraper/image-4.png" alt="alt text"></p>

<p>Scraping with GPT-4o can become very expensive since even small HTML tables can contain lots of characters. I’ve been experimenting for two days and I’ve already spent $24!</p>

<p>To reduce the cost, I added some clean up logic to remove unnecessary data from the HTML string before passing it to the model. A simple function that removes all properties except <code>class</code>, <code>id</code>, and <code>data-testid</code> (which are the ones I noticed the generated XPaths were using) trimmed the number of characters in the table by half.</p>

<p>I didn’t see any performance degradations and my suspicion is that the results would actually improve extraction quality.</p>

<p>Currently, the second step (generate XPaths) makes one model call per column in
the table, another improvement could be to generate more than one XPath, I have yet
to try this approach and evaluate performance.</p>

<h2 id="conclusions-and-demo">Conclusions and demo</h2>

<p>I was surprised by the extraction quality of GPT-4o (but then sadly surprised when I looked at how much I’d have to pay OpenAI!). Nonetheless, this was a fun experiment and I definitely see potential for AI-assisted web scraping tools.</p>

<p>I did a quick demo using Streamlit, you can check it out here: <a href="https://orange-resonance-9766.ploomberapp.io/">https://orange-resonance-9766.ploomberapp.io</a>, the source code is on <a href="https://github.com/edublancas/posts/tree/main/ai-web-scraping">GitHub</a> (Spoiler: don’t expect anything polished).</p>

<p>Some stuff I’d like to try if I had more time:</p>

<ol>
  <li>Capture browser events: the current demo is a one-off process: users enter the URL and an initial XPath. This isn’t great UX as it’d be better to ask the user to click on the table they want to extract, and to provide some sample rows so the model can understand the structure a bit better.</li>
  <li>In complex tables, a single XPath might not be enough to extract a full column, I’d like to see if asking the LLM to return a program (e.g. Python) would work.</li>
  <li>More experimenting with the HTML clean up is needed. It’s very expensive to use GPT-4o and I feel like I’m passing a lot of unnecessary data to the model</li>
</ol>



 
        
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A modern way to type in African languages (173 pts)]]></title>
            <link>https://github.com/pythonbrad/afrim</link>
            <guid>41427563</guid>
            <pubDate>Mon, 02 Sep 2024 18:10:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pythonbrad/afrim">https://github.com/pythonbrad/afrim</a>, See on <a href="https://news.ycombinator.com/item?id=41427563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Afrim ⌨️</h2><a id="user-content-afrim-️" aria-label="Permalink: Afrim ⌨️" href="#afrim-️"></a></p>
<p dir="auto"><a href="https://github.com/pythonbrad/afrim/blob/main/CHANGELOG.md"><img src="https://camo.githubusercontent.com/1e22e80dbf708b90f7cf724ce9ea11c9137a32f601f4f4be8f4e2875afc1ee52/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4b656570253230612532304368616e67656c6f672d2d3535352e7376673f6c6f676f3d64617461253341696d616765253246737667253242786d6c25334262617365363425324350484e325a79423462577875637a30696148523063446f764c336433647935334d793576636d63764d6a41774d43397a646d636949475a706247773949694e6d4d54566b4d7a416949485a705a58644362336739496a41674d4341784f4463674d546731496a3438634746306143426b50534a4e4e6a49674e324d744d5455674d7930794f4341784d43307a4e7941794d6d45784d6a49674d544979494441674d4441744d5467674f5445674e7a51674e7a51674d4341774d44453249444d34597a59674f5341784e4341784e5341794e4341784f4745344f5341344f534177494441774d6a51674e4341304e5341304e534177494441774e69417762444d744d5341784d793078595445314f4341784e5467674d4341774d4455314c5445334944597a4944597a494441674d44417a4e5330314d69417a4e43417a4e434177494441774c5445744e574d744d7930784f4330354c544d7a4c5445354c5451334c5445794c5445334c5449304c5449344c544d344c544d335154673149446731494441674d4441324d694133656d307a4d434134597a4977494451674d7a67674d5451674e544d674d7a45674d5463674d5467674d6a59674d7a63674d6a6b674e5468324d544a6a4c544d674d5463744d544d674d7a41744d6a67674d7a68684d545531494445314e534177494441784c54557a49444532624330784d794179614330785954557849445578494441674d4445744d5449744d5777744d5463744d6d4d744d544d744e4330794d7930784d6930794f5330794e7930314c5445794c5467744d6a51744f43307a4f5745784d7a4d674d544d7a494441674d4445344c545577597a55744d544d674d5445744d6a59674d6a59744d7a4d674d5451744e7941794f533035494451314c545636545451774944513159546b3049446b30494441674d4441744d5463674e5451674e7a55674e7a55674d4341774d4459674d7a4a6a4f4341784f5341794d69417a4d5341304d69417a4d6941794d534179494451784c5449674e6a41744d5452684e6a41674e6a41674d4341774d4449784c5445354944557a4944557a494441674d4441354c544935597a41744d5459744f43307a4d7930794d7930314d5745304e7941304e794177494441774c5455744e574d744d6a4d744d6a41744e4455744d6a59744e6a63744d5467744d5449674e4330794d4341354c54493249444534656d30784d4467674e7a5a684e5441674e5441674d4341774d5330794d5341794d6d4d744d5463674f53307a4d6941784d7930304f4341784d7930784d5341774c5449784c544d744d7a41744f5330314c544d744f5330354c54457a4c5445325954677849446778494441674d4445744e69307a4d6941354e4341354e434177494441784f43307a4e5341354d4341354d434177494441784e6930784d6d77784c544a6a4e5330354944457a4c54457a4944497a4c544532494445324c5455674d7a49744d7941314d4341354944457a494467674d6a4d674d6a41674d7a41674d7a59674e7941784e53413349444935494441674e444a36625330304d7930334d324d744d5463744f43307a4d7930324c545132494455744d5441674f4330784e6941794d4330784f53417a4e3245314e4341314e434177494441774e53417a4e474d3349444531494449774944497a49444d3349444979494449794c5445674d7a67744f5341304f4330794e4745304d5341304d534177494441774f4330794e4341304d7941304d794177494441774c5445744d544a6a4c5459744d5467744d5459744d7a45744d7a49744d7a6836625330794d7941354d5767744d574d744e7941774c5445304c5449744d6a45744e3245794e7941794e794177494441784c5445774c54457a4944553349445533494441674d4445744e4330794d4341324d7941324d794177494441784e6930794e574d314c544579494445794c544535494449304c54497849446b744d7941784f43307949444933494449674d5451674e6941794d7941784f4341794e79417a4d334d744d69417a4d5330784e6941304d474d744d5445674f4330794d5341784d53307a4d6941784d5870744d53307a4e4859784e4767744f4659324f476734646a4934624445774c54457761444578624330784e4341784e5341784e7941784f4567354e6e6f694c7a34384c334e325a7a344b" alt="Changelog" data-canonical-src="https://img.shields.io/badge/Keep%20a%20Changelog--555.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9IiNmMTVkMzAiIHZpZXdCb3g9IjAgMCAxODcgMTg1Ij48cGF0aCBkPSJNNjIgN2MtMTUgMy0yOCAxMC0zNyAyMmExMjIgMTIyIDAgMDAtMTggOTEgNzQgNzQgMCAwMDE2IDM4YzYgOSAxNCAxNSAyNCAxOGE4OSA4OSAwIDAwMjQgNCA0NSA0NSAwIDAwNiAwbDMtMSAxMy0xYTE1OCAxNTggMCAwMDU1LTE3IDYzIDYzIDAgMDAzNS01MiAzNCAzNCAwIDAwLTEtNWMtMy0xOC05LTMzLTE5LTQ3LTEyLTE3LTI0LTI4LTM4LTM3QTg1IDg1IDAgMDA2MiA3em0zMCA4YzIwIDQgMzggMTQgNTMgMzEgMTcgMTggMjYgMzcgMjkgNTh2MTJjLTMgMTctMTMgMzAtMjggMzhhMTU1IDE1NSAwIDAxLTUzIDE2bC0xMyAyaC0xYTUxIDUxIDAgMDEtMTItMWwtMTctMmMtMTMtNC0yMy0xMi0yOS0yNy01LTEyLTgtMjQtOC0zOWExMzMgMTMzIDAgMDE4LTUwYzUtMTMgMTEtMjYgMjYtMzMgMTQtNyAyOS05IDQ1LTV6TTQwIDQ1YTk0IDk0IDAgMDAtMTcgNTQgNzUgNzUgMCAwMDYgMzJjOCAxOSAyMiAzMSA0MiAzMiAyMSAyIDQxLTIgNjAtMTRhNjAgNjAgMCAwMDIxLTE5IDUzIDUzIDAgMDA5LTI5YzAtMTYtOC0zMy0yMy01MWE0NyA0NyAwIDAwLTUtNWMtMjMtMjAtNDUtMjYtNjctMTgtMTIgNC0yMCA5LTI2IDE4em0xMDggNzZhNTAgNTAgMCAwMS0yMSAyMmMtMTcgOS0zMiAxMy00OCAxMy0xMSAwLTIxLTMtMzAtOS01LTMtOS05LTEzLTE2YTgxIDgxIDAgMDEtNi0zMiA5NCA5NCAwIDAxOC0zNSA5MCA5MCAwIDAxNi0xMmwxLTJjNS05IDEzLTEzIDIzLTE2IDE2LTUgMzItMyA1MCA5IDEzIDggMjMgMjAgMzAgMzYgNyAxNSA3IDI5IDAgNDJ6bS00My03M2MtMTctOC0zMy02LTQ2IDUtMTAgOC0xNiAyMC0xOSAzN2E1NCA1NCAwIDAwNSAzNGM3IDE1IDIwIDIzIDM3IDIyIDIyLTEgMzgtOSA0OC0yNGE0MSA0MSAwIDAwOC0yNCA0MyA0MyAwIDAwLTEtMTJjLTYtMTgtMTYtMzEtMzItMzh6bS0yMyA5MWgtMWMtNyAwLTE0LTItMjEtN2EyNyAyNyAwIDAxLTEwLTEzIDU3IDU3IDAgMDEtNC0yMCA2MyA2MyAwIDAxNi0yNWM1LTEyIDEyLTE5IDI0LTIxIDktMyAxOC0yIDI3IDIgMTQgNiAyMyAxOCAyNyAzM3MtMiAzMS0xNiA0MGMtMTEgOC0yMSAxMS0zMiAxMXptMS0zNHYxNGgtOFY2OGg4djI4bDEwLTEwaDExbC0xNCAxNSAxNyAxOEg5NnoiLz48L3N2Zz4K"></a>
<a href="https://crates.io/crates/afrim" rel="nofollow"><img src="https://camo.githubusercontent.com/3bee7b6f90edb1c637bbc080133054e77879ae3f8b4a49abb99c497b1332c2ed/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f616672696d2e737667" alt="crates.io" data-canonical-src="https://img.shields.io/crates/v/afrim.svg"></a>
<a href="https://github.com/pythonbrad/afrim/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/25e346d4cc0b7b63bac32a6c6f33c8ce86db85f13d606724f8e02fff79af4993/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f6c2f616672696d2e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/crates/l/afrim.svg"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/pythonbrad/afrim/workflows/Rust/badge.svg"><img src="https://github.com/pythonbrad/afrim/workflows/Rust/badge.svg" alt="Rust"></a>
<a href="https://docs.rs/afrim" rel="nofollow"><img src="https://camo.githubusercontent.com/ec15ca0f067cada14f8f5f8fd2600b5cc8916812c8f651851e015e3e322b3109/68747470733a2f2f646f63732e72732f616672696d2f62616467652e737667" alt="docs.rs" data-canonical-src="https://docs.rs/afrim/badge.svg"></a>
<a href="https://deps.rs/repo/github/pythonbrad/afrim" rel="nofollow"><img src="https://camo.githubusercontent.com/76cb188674070b4639c496d8a76094c671382da3365beb5c202096a68cbfc6c1/68747470733a2f2f646570732e72732f7265706f2f6769746875622f707974686f6e627261642f616672696d2f7374617475732e737667" alt="dependency status" data-canonical-src="https://deps.rs/repo/github/pythonbrad/afrim/status.svg"></a>
<a href="https://coveralls.io/github/pythonbrad/afrim?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/cf36e4720d4568353a8255d8bca627caa78e3740cf0dc6e7d6fbe24c5f52197b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f707974686f6e627261642f616672696d2f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/pythonbrad/afrim/badge.svg?branch=main"></a></p>
<p dir="auto">Afrim is an input method for African languages. It is designed to protect the native language of various local dialects of Africa and is a universal phonetic-based input method platform.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">AFRIM is the abbreviation of <em>AFRICA IME</em> or <em>Africa Input Method Engine</em>.</p>
<p dir="auto">From the beginning, AFRIM was written as a remake of <a href="https://github.com/H-Theking/clafrica">Clafrica IME</a>, and named <em>clafrica</em>.</p>
<p dir="auto">Then, we created an input method library with some improvements inspired from <a href="https://github.com/rime">RIME</a>. We renamed it to <em>Afrim Input Method Engine</em>.</p>
<p dir="auto">Later, it supports Amharic and Geez and other african phonetic input method, and we want support all african phonetic Input Method.</p>
<p dir="auto">Inspired from <a href="https://github.com/rime/librime">librime</a>, we want AFRIM aka <em>Afrim Input Method Engine</em> to be the top IME for african languages.</p>
<p dir="auto">For more details on the project name, confer the issue <a data-error-text="Failed to load title" data-id="1952485359" data-permission-text="Title is private" data-url="https://github.com/pythonbrad/afrim/issues/107" data-hovercard-type="issue" data-hovercard-url="/pythonbrad/afrim/issues/107/hovercard" href="https://github.com/pythonbrad/afrim/issues/107">#107</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul>
<li> 🌐 Support for all sequential codification codes.</li>
<li> 🎨 Easy to use CLI interface.</li>
<li> 📚 Customizable dictionary.</li>
<li> 💻 Support for both desktop and web platform.</li>
<li> 🤖 Support for the Rhai scripting language.</li>
<li> 📝 Auto-suggestion / Auto-correction / Auto-completion.</li>
<li> ☁️  Full immersion mode for non-latin languages. (🚧 Experimental 🚧)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build dependencies (Linux only)</h2><a id="user-content-build-dependencies-linux-only" aria-label="Permalink: Build dependencies (Linux only)" href="#build-dependencies-linux-only"></a></p>
<ul dir="auto">
<li>libxtst-dev</li>
<li>libevdev-dev</li>
<li>libxdo-dev</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Runtime dependencies (Linux only)</h2><a id="user-content-runtime-dependencies-linux-only" aria-label="Permalink: Runtime dependencies (Linux only)" href="#runtime-dependencies-linux-only"></a></p>
<ul dir="auto">
<li>libxtst-dev</li>
<li>libevdev-dev</li>
<li>libxdo-dev</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported keyboard layouts</h2><a id="user-content-supported-keyboard-layouts" aria-label="Permalink: Supported keyboard layouts" href="#supported-keyboard-layouts"></a></p>
<ul dir="auto">
<li>QWERTY (USA)</li>
<li>FRENCH (not AZERTY)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">In using cargo</h2><a id="user-content-in-using-cargo" aria-label="Permalink: In using cargo" href="#in-using-cargo"></a></p>
<p dir="auto"><code>cargo install afrim</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it in the console</h2><a id="user-content-try-it-in-the-console" aria-label="Permalink: Try it in the console" href="#try-it-in-the-console"></a></p>
<p dir="auto"><code>afrim</code> comes with a REPL application which can be used to test if his library is working.
To use the afrim, simply provide the path of the datafile that suit your needs.</p>
<p dir="auto">Eg. <code>afrim configfile.toml</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Dataset</h2><a id="user-content--dataset" aria-label="Permalink: 📚 Dataset" href="#-dataset"></a></p>
<p dir="auto">🏢 Official:</p>
<ul dir="auto">
<li><a href="https://github.com/pythonbrad/afrim-data">Afrim Supported Code</a>.</li>
</ul>
<p dir="auto">🧑🏿‍🤝‍🧑🏿 Community:</p>
<ul dir="auto">
<li>Feel free to propose your own.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎨 Frontends</h2><a id="user-content--frontends" aria-label="Permalink: 🎨 Frontends" href="#-frontends"></a></p>
<p dir="auto">🏢 Official:</p>
<ul dir="auto">
<li><a href="https://github.com/pythonbrad/afrim-wish">afrim-wish</a>: Frontend for desktop environment.</li>
<li><a href="https://github.com/pythonbrad/afrim-web">afrim-web</a>: Frontend for web environment.</li>
<li><a href="https://github.com/pythonbrad/afrim-keyboard">afrim-keyboard</a>: Frontend for android environment.</li>
</ul>
<p dir="auto">🧑🏿‍🤝‍🧑🏿 Community:</p>
<ul dir="auto">
<li>Feel free to propose your own.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licence</h2><a id="user-content-licence" aria-label="Permalink: Licence" href="#licence"></a></p>
<p dir="auto">All the code in this repository is released under the Mozilla Public License v2.0, for more information take a look at the <a href="https://github.com/pythonbrad/afrim/blob/main/LICENSE">LICENSE</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you would like to contribute to this project, please fork the repository and submit a pull request with your changes.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on Distributed Systems for Young Bloods (303 pts)]]></title>
            <link>https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/</link>
            <guid>41427185</guid>
            <pubDate>Mon, 02 Sep 2024 17:23:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/">https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/</a>, See on <a href="https://news.ycombinator.com/item?id=41427185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>I’ve been thinking about the lessons distributed systems engineers learn on
the job. A great deal of our instruction is through scars made by mistakes
made in production traffic. These scars are useful reminders, sure, but it’d
be better to have more engineers with the full count of their fingers.</p>
<p>New systems engineers will find the <a href="http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing">Fallacies of Distributed
Computing</a> and the <a href="http://codahale.com/you-cant-sacrifice-partition-tolerance/">CAP theorem</a> as part of their
self-education. But these are abstract pieces without the direct, actionable
advice the inexperienced engineer needs to start moving<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. It’s surprising
how little context new engineers are given when they start out.</p>
<p>Below is a list of some lessons I’ve learned as a distributed systems engineer
that are worth being told to a new engineer. Some are subtle, and some are
surprising, but none are controversial. This list is for the new distributed
systems engineer to guide their thinking about the field they are taking
on. It’s not comprehensive, but it’s a good beginning.</p>
<p>The worst characteristic of this list is that it focuses on technical problems
with little discussion of social problems an engineer may run into. Since
distributed systems require more machines and more capital, their engineers
tend to work with more teams and larger organizations. The social stuff is
usually the hardest part of any software developer’s job, and, perhaps,
especially so with distributed systems development.</p>
<p>Our background, education, and experience bias us towards a technical solution
even when a social solution would be more efficient, and more pleasing. Let’s
try to correct for that. People are less finicky than computers, even if their
interface is a little less standardized.</p>
<p>Alright, here we go.</p>
<p><a name="fail" href="#fail">#</a> <strong>Distributed systems are different because they fail often.</strong> When asked what
separates distributed systems from other fields of software engineering, the
new engineer often cites latency, believing that’s what makes distributed
computation hard.</p>
<p>But they’re wrong. What sets distributed systems engineering apart is the
probability of failure and, worse, the probability of partial failure. If a
well-formed mutex unlock fails with an error, we can assume the process is
unstable and crash it. But the failure of a distributed mutex’s unlock must be
built into the lock protocol.</p>
<p>Systems engineers that haven’t worked in distributed computation will come up
with ideas like “well, it’ll just send the write to both machines” or “it’ll
just keep retrying the write until it succeeds”. These engineers haven’t
completely accepted (though they usually intellectually recognize) that
networked systems fail more than systems that exist on only a single machine
and that failures tend to be partial instead of total. One of the writes may
succeed while the other fails, and so now how do we get a consistent view of
the data? These partial failures are much harder to reason about.</p>
<p>Switches go down, garbage collection pauses make leaders “disappear”,
socket writes seem to succeed but have actually failed on the other machine, a
slow disk drive on one machine causes a communication protocol in the whole
cluster to crawl, and so on. Reading from local memory is simply more stable
than reading across a few switches.</p>
<p>Design for failure. <a href="#fail">#</a></p>
<p><a name="robustdist" href="#robustdist">#</a> <strong>Writing robust distributed systems costs more than writing robust
single-machine systems.</strong> Creating a robust distributed solution requires more
money than a single-machine solution because there are failures that only
occur with many machines. Virtual machine and cloud technology make
distributed systems engineering cheaper but not as cheap as being able to
design, implement, and test on a computer you already own. And there are
failure conditions that are difficult to replicate on a single
machine. Whether it’s because they only occur on dataset sizes much larger
than can be fit on a shared machine, or in the network conditions found in
datacenters, distributed systems tend to need actual, not simulated,
distribution to flush out their bugs. Simulation is, of course, very useful. <a href="#robustdist">#</a></p>
<p><a name="robustoss" href="#robustoss">#</a> <strong>Robust, open source distributed systems are much less common than robust,
single-machine systems.</strong> The cost of running many machines for long periods
of time is a burden on open source communities. Hobbyists and dilettantes are
the engines of open source software and they do not have the financial
resources available to explore or fix many of the problems a distributed
system will have. Hobbyists write open source code for fun in their free time
and with machines they already own. It’s much harder to find open source
developers who are willing to spin up, maintain, and pay for a bunch of
machines.</p>
<p>Some of this slack has been taken up by engineers working for corporate
entities. However, the priorities of their organization may not be in line
with the priorities of your organization.</p>
<p>While some in the open source community are aware of this problem, it’s not
yet solved. This is hard. <a href="#robustoss">#</a></p>
<p><a name="coord" href="#coord">#</a> <strong>Coordination is very hard.</strong> Avoid coordinating machines wherever
possible. This is often described as “horizontal scalability”. The real trick
of horizontal scalability is independence – being able to get data to
machines such that communication and consensus between those machines is kept
to a minimum. Every time two machines have to agree on something, the service
becomes harder to implement. Information has an upper limit to the speed it can
travel, and networked communication is flakier than you think, and your idea
of what constitutes consensus is probably wrong. Learning about the <a href="http://en.wikipedia.org/wiki/Two_Generals%27_Problem">Two
Generals</a> and <a href="http://en.wikipedia.org/wiki/Byzantine_Generals%27_Problem">Byzantine Generals</a> problems is useful
here. (Oh, and Paxos really is <a href="http://research.google.com/pubs/pub33002.html">very hard to implement</a>; that’s not
grumpy old engineers thinking they know better than you.) <a href="#coord">#</a></p>
<p><a name="memory" href="#memory">#</a> <strong>If you can fit your problem in memory, it’s probably trivial.</strong> To a
distributed systems engineer, problems that are local to one machine are
easy. Figuring out how to process data quickly is harder when the data is a
few switches away instead of a few pointer dereferences away. In a distributed
system, the well-worn efficiency tricks documented since the beginning of
computer science no longer apply. Plenty of literature and implementations are
available for algorithms that run on a single machine because the majority of
computation has been done on singular, uncoordinated machines. Significantly
fewer exist for distributed systems. <a href="#memory">#</a></p>
<p><a name="slow" href="#slow">#</a> <strong>“It’s slow” is the hardest problem you’ll ever debug.</strong> “It’s slow” might
mean one or more of the number of systems involved in performing a user
request is slow. It might mean one or more of the parts of a pipeline of
transformations across many machines is slow. “It’s slow” is hard, in part,
because the problem statement doesn’t provide many clues to the location of the
flaw. Partial failures, ones that don’t show up on the graphs you usually look
up, are lurking in a dark corner. And, until the degradation becomes very
obvious, you won’t receive as many resources (time, money, and tooling) to
solve it. <a href="http://research.google.com/pubs/pub36356.html">Dapper</a> and <a href="http://engineering.twitter.com/2012/06/distributed-systems-tracing-with-zipkin.html">Zipkin</a> were built for a reason. <a href="#slow">#</a></p>
<p><a name="backpressure" href="#backpressure">#</a> <strong>Implement backpressure throughout your system.</strong> Backpressure is the
signaling of failure from a serving system to the requesting system and how
the requesting system handles those failures to prevent overloading itself and
the serving system. Designing for backpressure means bounding resource
use during times of overload and times of system failure. This is one
of the basic building blocks of creating a robust distributed system.</p>
<p>Implementations of backpressure usually involve either dropping new
messages on the floor, or shipping errors back to users (and incrementing
a metric in both cases) when a resource becomes limited or failures
occur. Timeouts and exponential back-offs on connections and requests to other
systems are also essential.</p>
<p>Without backpressure mechanisms in place, cascading failure or unintentional
message loss become likely. When a system is not able to handle the failures
of another, it tends to emit failures to another system that depends on it. <a href="#backpressure">#</a></p>
<p><a name="partial" href="#partial">#</a> <strong>Find ways to be partially available.</strong> Partial availability is being able to
return some results even when parts of your system is failing.</p>
<p>Search is an ideal case to explore here. Search systems trade-off between how
good their results are and how long they will keep a user waiting. A typical
search system sets a time limit on how long it will search its documents, and,
if that time limit expires before all of its documents are searched, it will
return whatever results it has gathered. This makes search easier to scale in
the face of intermittent slowdowns, and errors because those failures are
treated the same as not being able to search all of their documents. The
system allows for partial results to be returned to the user and its
resilience is increased.</p>
<p>And consider a private messaging feature in a web application. At some point, no
matter what you do, enough storage machines for private messaging will be down
at the same time that your users will notice. So what kind of partial failure do
we want in this system?</p>
<p>This takes some thought. People are generally more okay with private messaging
being down for them (and maybe some other users) than they are with all users
having some of their messages go missing. If the service is overloaded or one of
its machines are down, failing out just a small fraction of the userbase is
preferable to missing data for a larger fraction. And, on top of that choice, we
probably don’t want an unrelated feature, like public image upload, to be
affected just because private messaging is having a problem. How much work are
we willing to do to keep those failure domains separate?</p>
<p>Being able to recognize these kinds of trade-offs in partial availability is
good to have in your toolbox. <a href="#partial">#</a></p>
<p><a name="metrics" href="#metrics">#</a> <strong>Metrics are the only way to get your job done.</strong> Exposing metrics (such as
latency percentiles, increasing counters on certain actions, rates of change)
is the only way to cross the gap from what you believe your system does in
production and what it actually is doing. Knowing how the system’s behavior on
day 20 is different from its behavior on day 15 is the difference between
successful engineering and failed shamanism. Of course, metrics are necessary
to understand problems and behavior, but they are not sufficient to know what
to do next.</p>
<p>A diversion into logging. Log files are good to have, but they tend to
lie. For example, it’s very common for the logging of a few error classes to
take up a large proportion of a space in a log file but, in actuality, occur
in a very low proportion of requests. Because logging successes is redundant
in most cases (and would blow out the disk in most cases) and because
engineers often guess wrong on which kinds of error classes are useful to see,
log files get filled up with all sorts of odd bits and bobs. Prefer logging as
if someone who has not seen the code will be reading the logs.</p>
<p>I’ve seen a good number of outages extended by another engineer (or myself)
over-emphasizing something odd we saw in the log without first checking it
against the metrics. I’ve also seen another engineer (or myself)
Sherlock-Holmes’ing an entire set of failed behaviors from a handful of log
lines. But note: a) we remember those successes because they are so very rare
and b) you’re not Sherlock unless the metrics or the experiments back up the
story. <a href="#metrics">#</a></p>
<p><a name="percentiles" href="#percentiles">#</a> <strong>Use percentiles, not averages.</strong> Percentiles (50th, 99th, 99.9th, 99.99th)
are more accurate and informative than averages in the vast majority of
distributed systems. Using a mean assumes that the metric under evaluation
follows a bell curve but, in practice, this describes very few metrics an
engineer cares about. “Average latency” is a commonly reported metric, but
I’ve never once seen a distributed system whose latency followed a bell
curve. If the metric doesn’t follow a bell curve, the average is meaningless
and leads to incorrect decisions and understanding. Avoid the trap by talking
in percentiles. Default to percentiles, and you’ll better understand how users
really see your system. <a href="#percentiles">#</a></p>
<p><a name="capacity" href="#capacity">#</a> <strong>Learn to estimate your capacity.</strong> You’ll learn how many seconds are in a
day because of this. Knowing how many machines you need to perform a task is
the difference between a long-lasting system, and one that needs to be
replaced 3 months into its job. Or, worse, needs to be replaced before you
finish productionizing it.</p>
<p>Consider tweets. How many tweet ids can you fit in memory on a common machine?
Well, a typical machine at the end of 2012 has 24 GB of memory, you’ll need an
overhead of 4-5 GB for the OS, another couple, at least, to handle requests,
and a tweet id is 8 bytes. This is the kind of back of the envelope
calculation you’ll find yourself doing. Jeff Dean’s <a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf">Numbers Everyone Should
Know</a> slide is a good expectation-setter. <a href="#capacity">#</a></p>
<p><a name="flags" href="#flags">#</a> <strong>Feature flags are how infrastructure is rolled out.</strong> “Feature flags” are a
common way product engineers roll out new features in a system. Feature flags
are typically associated with frontend A/B testing where they are used to show
a new design or feature to only some of the userbase. But they are a powerful
way of replacing infrastructure as well.</p>
<p>Too many projects have failed because they went for the “big cutover” or a
series of “big cutovers” that were then forced into rollbacks by bugs found too
late. By using feature flags instead, you’ll gain confidence in your project and
mitigate the costs of failure.</p>
<p>Suppose you’re going from a single database to a service that hides the details
of a new storage solution. Using a feature flag, you can slowly ramp up writes
to the new service in parallel to the writes to the old database to make sure
its write path is correct and fast enough. After the write path is at 100% and
backfilling into the service’s datastore is complete, you can use a separate
feature flag to start reading from the service, without using the data in user
responses, to check for performance problems. Another feature flag can be used
to perform comparison checks on read of the data from the old system and the new
one. And one final flag can be used to slowly ramp up the “real” reads from the
new system.</p>
<p>By breaking up the deployment into multiple steps and affording yourself quick
and partial reactions with feature flags, you make it easier to find bugs and
performance problems as they occur during ramp up instead of at a “big bang”
release time. If an issue occurs, you can just tamp the feature flag setting
back down to a lower (perhaps, zero) setting immediately. Adjusting the rates
lets you debug and experiment at different amounts of traffic knowing that any
problem you hit isn’t a total disaster. With feature flags, you can also choose
other migration strategies, like moving requests over on a per-user basis, that
provide better insight into the new system. And when your new service is still
being prototyped, you can use flags at a low setting to have your new system
consume fewer resources.</p>
<p>Now, feature flags sound like a terrible mess of conditionals to a classically
trained developer or a new engineer with well-intentioned training. And the use
of feature flags means accepting that having multiple versions of infrastructure
and data is a norm, not an rarity. This is a deep lesson. What works well for
single-machine systems sometimes falters in the face of distributed problems.</p>
<p>Feature flags are best understood as a trade-off, trading local complexity (in
the code, in one system) for global simplicity and resilience. <a href="#flags">#</a></p>
<p><a name="idspace" href="#idspace">#</a> <strong>Choose id spaces wisely.</strong> The space of ids you choose for your system will
shape your system.</p>
<p>The more ids required to get to a piece of data, the more options you have in
partitioning the data. The fewer ids required to get a piece of data, the
easier it is to consume your system’s output.</p>
<p>Consider version 1 of the Twitter API. All operations to get, create, and
delete tweets were done with respect to a single numeric id for each
tweet. The tweet id is a simple 64-bit number that is not connected to any
other piece of data. As the number of tweets goes up, it becomes clear that
creating user tweet timelines and the timeline of other user’s subscriptions
may be efficiently constructed if all of the tweets by the same user were
stored on the same machine.</p>
<p>But the public API requires every tweet be addressable by just the tweet
id. To partition tweets by user, a lookup service would have to be
constructed. One that knows what user owns which tweet id. Doable, if
necessary, but with a non-trivial cost.</p>
<p>An alternative API could have required the user id in any tweet look up and,
initially, simply used the tweet id for storage until user-partitioned storage
came online. Another alternative would have included the user id in the tweet
id itself at the cost of tweet ids no longer being k-sortable and numeric.</p>
<p>Watch out for what kind of information you encode in your ids, explicitly and
implicitly. Clients may use the structure of your ids to de-anonymize private
data, crawl your system in unexpected ways (auto-incrementing ids are a
typical sore point), or perform a <a href="https://www.owasp.org/index.php/Top_10_2010-A4-Insecure_Direct_Object_References">host of other attacks</a>. <a href="#idspace">#</a></p>
<p><a name="dataloc" href="#dataloc">#</a> <strong>Exploit data-locality.</strong> The closer the processing and caching of your data
is kept to its persistent storage, the more efficient your processing, and the
easier it will be to keep your caching consistent and fast. Networks have more
failures and more latency than pointer dereferences and <code>fread(3)</code>.</p>
<p>Of course, data-locality means being nearby in space, but it also means nearby
in time.  If multiple users are making the same expensive request at nearly the
same time, perhaps their requests can be joined into one. If multiple instances
of requests for the same kind of data are made near to one another, they could
be joined into one larger request. Doing so often affords lower communication
overheard and easier fault management. <a href="#dataloc">#</a></p>
<p><a name="cached" href="#cached">#</a> <strong>Writing cached data back to persistent storage is bad.</strong> This happens in
more systems than you’d think. Especially ones originally designed by people
less experienced in distributed systems. Many systems you’ll inherit will have
this flaw. If the implementers talk about “Russian-doll caching”, you have a
large chance of hitting highly visible bugs. This entry could have been left
out of the list, but I have a special hate in my heart for it. A common
presentation of this flaw is user information (e.g. screennames, emails, and
hashed passwords) mysteriously reverting to a previous value. <a href="#cached">#</a></p>
<p><a name="domore" href="#domore">#</a> <strong>Computers can do more than you think they can.</strong> In the field today, there’s
plenty of misinformation about what a machine is capable of from practitioners
that do not have a great deal of experience.</p>
<p>At the end of 2012, a light web server had 6 or more processors, 24 GB of
memory and more disk space than you can use. A relatively complex <a href="http://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a>
application in a modern language runtime on a single machine is trivially
capable of doing thousands of requests per second within a few hundred
milliseconds. And that’s a deep lower bound. In terms of operational ability,
hundreds of requests per second per machine is not something to brag about in
most cases.</p>
<p>Greater performance is not hard to come by, especially if you are willing to
profile your application and introduce efficiencies based on your
measurements. <a href="#domore">#</a></p>
<p><a name="cap" href="#cap">#</a> <strong>Use the CAP theorem to critique systems.</strong> The CAP theorem isn’t something
you can build a system out of. It’s not a theorem you can take as a first
principle and derive a working system from. It’s much too general in its
purview, and the space of possible solutions too broad.</p>
<p>However, it is well-suited for critiquing a distributed system design, and
understanding what trade-offs need to be made. Taking a system design and
iterating through the constraints CAP puts on its subsystems will leave you
with a better design at the end. For homework, apply the CAP theorem’s
constraints to a real world implementation of Russian-doll caching.</p>
<p>One last note: Out of C, A, and P, you <a href="http://codahale.com/you-cant-sacrifice-partition-tolerance/">can’t choose CA</a>. <a href="#cap">#</a></p>
<p><a name="services" href="#services">#</a> <strong>Extract services.</strong> “Service” here means “a distributed system that
incorporates higher-level logic than a storage system and typically has a
request-response style API”. Be on the lookout for code changes that would be
easier to do if the code existed in a separate service instead of in your
system.</p>
<p>An extracted service provides the benefits of encapsulation typically
associated with creating libraries. However, extracting out a service improves
on creating libraries by allowing for changes to be deployed faster and easier
than upgrading the libraries in its client systems. (Of course, if the
extracted service is hard to deploy, the client systems are the ones that
become easier to deploy.) This ease is owed to the fewer code and operational
dependencies in the smaller, extracted service and the strict boundary it
creates makes it harder to “take shortcuts” that a library allows for. These
shortcuts almost always make it harder to migrate the internals or the client
systems to new versions.</p>
<p>The coordination costs of using a service is also much lower than a shared
library when there are multiple client systems. Upgrading a library, even with
no API changes needed, requires coordinating deploys of each client
system. This gets harder when data corruption is possible if the deploys are
performed out of order (and it’s harder to predict that it will
happen). Upgrading a library also has a higher social coordination cost than
deploying a service if the client systems have different maintainers. Getting
others aware of and willing to upgrade is surprisingly difficult because their
priorities may not align with yours.</p>
<p>The canonical service use case is to hide a storage layer that will be
undergoing changes. The extracted service has an API that is more convenient,
and reduced in surface area compared to the storage layer it fronts. By
extracting a service, the client systems don’t have to know about the
complexities of the slow migration to a new storage system or format and only
the new service has to be evaluated for bugs that will certainly be found with
the new storage layout.</p>
<p>There are a great deal of operational and social issues to consider when doing
this. I cannot do them justice here. Another article will have to be written. <a href="#services">#</a></p>
<p><em>Much love to my reviewers <a href="https://twitter.com/dehora">Bill de hÓra</a>, <a href="https://twitter.com/coda">Coda Hale</a>, <a href="https://twitter.com/jdmaturen">JD
Maturen</a>, <a href="https://twitter.com/nora">Micaela McDonald</a>, and <a href="https://twitter.com/tnm">Ted Nyman</a>. Your
insight and care was invaluable.</em></p>
<p><strong>Update</strong> (2016-08-15): I’ve added permalinks for each section and cleaned up
some text in the sections on coordination, data-locality, feature flags, and
backpressure.</p>


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Fortress (YC S24) – Database platform for multi-tenant SaaS (113 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41426998</link>
            <guid>41426998</guid>
            <pubDate>Mon, 02 Sep 2024 16:58:40 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41426998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="41426998">
      <td><span></span></td>      <td><center><a id="up_41426998" href="https://news.ycombinator.com/vote?id=41426998&amp;how=up&amp;goto=item%3Fid%3D41426998"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=41426998">Launch HN: Fortress (YC S24) – Database platform for multi-tenant SaaS</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_41426998">101 points</span> by <a href="https://news.ycombinator.com/user?id=dchu17">dchu17</a> <span title="2024-09-02T16:58:40"><a href="https://news.ycombinator.com/item?id=41426998">13 hours ago</a></span> <span id="unv_41426998"></span> | <a href="https://news.ycombinator.com/hide?id=41426998&amp;goto=item%3Fid%3D41426998">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Fortress%20(YC%20S24)%20%E2%80%93%20Database%20platform%20for%20multi-tenant%20SaaS&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=41426998&amp;auth=accc94fbf9a7e2c622a77547106a699bb5f9ec09">favorite</a> | <a href="https://news.ycombinator.com/item?id=41426998">62&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi HN! We're Will, John, and David from Fortress (<a href="https://fortress.build/">https://fortress.build</a>). We're building a Bring Your Own Cloud (BYOC) backend as a service for multi-tenant SaaS apps, simplifying tenant data isolation across both shared and dedicated database instances.</p><p>There’s a demo here: <a href="https://www.loom.com/share/761cac3090ba4db8b2ce9d713873333a?sid=d76b31bb-100c-483e-ba26-60915d98e61a" rel="nofollow">https://www.loom.com/share/761cac3090ba4db8b2ce9d713873333a?...</a>, as well as a walkthrough of our Python SDK: <a href="https://www.loom.com/share/c4b3f95235e24d99a7ea571c4564602b" rel="nofollow">https://www.loom.com/share/c4b3f95235e24d99a7ea571c4564602b</a></p><p>YC initially funded us for AI web-scraping, but early in the batch we realized we wanted to pivot to something in data privacy - in some ways the opposite of web-scraping…</p><p>From talking with SaaS developers, we learned tenant isolation (making sure one customer’s data is not shown to another) is often considered in development but rarely a core competency. Many developers struggled setting up Row-Level-Security (RLS) correctly on Postgres, some are enforcing application level access controls with none at the database-level at all, and many didn’t know which multi-tenant db architecture to start with and just decided to deal with it later. However, with increasing data sensitivity and compliance requirements, they’ve seen growing customer demand for stricter data requirements, including more demands for dedicated database instances or even databases deployed on the customer’s private cloud.</p><p>We also learned that SaaS developers prefer to have databases on their own cloud, and many who start on a 3rd party DBaaS eventually move infrastructure to their own cloud later. Having things on your own cloud makes it easier for SaaS to offer on-prem/full-siloed deployments and meet compliance requirements for larger customers. So we pivoted into being a BYOC platform and made Fortress integratable with cloud-native databases.</p><p>Our goal with Fortress is to give SaaS developers the ease of use of a managed DBaaS, native isolation for tenants, and the ability to programmatically provision and access database instances on any cloud.</p><p>Fortress provides SaaS developers an abstraction at the tenant level, allowing them to enforce tenant isolation through a function without having to set up RLS themselves or use WHERE statements in every query. Currently, on the Fortress platform, this is simple as every tenant in a shared database is given a logical db in a Postgres Cluster and we handle routing (We are currently working on a solution that provides native tenant isolation for tenants stored in shared tables).</p><p>Through our SDKs, developers only need to handle one connection to the Fortress client and we'll route requests and handle connection caching to ensure minimal latency to the right tenant’s data. We are working on creating more SDKs and simplifying existing ones. We currently support Postgres via AWS Aurora with plans to support other cloud-native databases and open-sourced databases via Kubernetes.</p><p>If you want to try it out, we’ve opened up self-serve to spin up new databases on your AWS cloud. You will need to create an account with Fortress (<a href="https://fortress.build/auth/sign-up">https://fortress.build/auth/sign-up</a>) to connect it to your own AWS account - that’s what BYOC (Bring Your Own Cloud) means! But if you are uncomfortable with granting us IAM permissions, we are offering a free db on the managed Fortress cloud for you to test out our SDKs (just cancel out of the Integrations page, create a database on the Database page, and select managed as the option, you will have a limit of 1). Note: AWS takes a while to spin up new clusters, adding tenants to existing clusters should be fairly instantaneous.</p><p>To provide you something basic to play with, we created a simple python flask application where you can easily test out our python SDK (<a href="https://github.com/fortress-build/python-example">https://github.com/fortress-build/python-example</a>). We created a video of us walking through the example with Fortress (<a href="https://www.loom.com/share/0245bec78d9d4dbeba8836c4112aa5da?sid=fd79eea1-d71a-4cb9-8a3d-a870dfb6f5d3" rel="nofollow">https://www.loom.com/share/0245bec78d9d4dbeba8836c4112aa5da?...</a>)</p><p>We hope you’ll test it out! We wanted to launch on HN to hear honest criticism, ideas, and pain points in this space. We are a super early stage database product and recognize that we have a ton of room for improvements. Looking forward to your input!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Owners of 1-Time Passcode Theft Service Plead Guilty (172 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/09/owners-of-1-time-passcode-theft-service-plead-guilty/</link>
            <guid>41426982</guid>
            <pubDate>Mon, 02 Sep 2024 16:56:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/09/owners-of-1-time-passcode-theft-service-plead-guilty/">https://krebsonsecurity.com/2024/09/owners-of-1-time-passcode-theft-service-plead-guilty/</a>, See on <a href="https://news.ycombinator.com/item?id=41426982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>Three men in the United Kingdom have pleaded guilty to operating <strong>otp[.]agency</strong>, a once popular online service that helped attackers intercept the one-time passcodes (OTPs) that many websites require as a second authentication factor in addition to passwords.</p>
<p>Launched in November 2019, OTP Agency was a service for intercepting one-time passcodes needed to log in to various websites. Scammers who had already stolen someone’s bank account credentials could enter the target’s phone number and name, and the service would initiate an automated phone call to the target that warned them about unauthorized activity on their account.</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/45GsKWyF63U?si=WcCChUe4gFLTpnxO" width="750" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>The call would prompt the target to enter a one-time passcode that was sent to the user via SMS when the thieves attempted to log in. Any codes shared by the target were then relayed to the scammer’s user panel at the OTP Agency website.</p>
<p>A <a href="https://www.nationalcrimeagency.gov.uk/news/website-operators-promised-fraudsters-profit-within-minutes-if-they-subscribed-to-illegal-service" target="_blank" rel="noopener">statement</a> published Aug. 30 by the U.K.’s <strong>National Crime Agency</strong> (NCA) said three men pleaded guilty to running OTP Agency: <strong>Callum Picari</strong>, 22, from Hornchurch, Essex; <strong>Vijayasidhurshan Vijayanathan</strong>, 21, from Aylesbury, Buckinghamshire; and <strong>Aza Siddeeque</strong>, 19, from Milton Keynes, Buckinghamshire.</p>
<p>KrebsOnSecurity profiled OTP Agency in <a href="https://krebsonsecurity.com/2021/02/u-k-arrest-in-sms-bandits-phishing-service/" target="_blank" rel="noopener">a February 2021 story</a> about arrests tied to another phishing-related service based in the U.K. Someone claiming to represent OTP Agency then posted several comments on the piece, wherein <a href="https://krebsonsecurity.com/wp-content/uploads/2024/09/otp-support.png" target="_blank" rel="noopener">they claimed</a> the story was libelous and that they were a legitimate anti-fraud service. However, the service’s Telegram channel clearly showed its proprietors had built OTP Agency with one purpose in mind: To help their customers take over online accounts.</p>
<p>Within hours of that publication, OTP Agency shuttered its website and announced it was closing up shop and purging its user database. The NCA said the February 2021 story prompted a panicked message exchange between Picari and Vijayanathan:</p>
<blockquote><p>Picari said: bro we are in big trouble… U will get me bagged… Bro delete the chat</p>
<p>Vijayanathan: Are you sure</p>
<p>Picari: So much evidence in there</p>
<p>Vijayanathan: Are you 100% sure</p>
<p>Picari: It’s so incriminating…Take a look and search ‘fraud’…Just think of all the evidence…that we cba to find…in the OTP chat…they will find</p>
<p>Vijayanathan: Exactly so if we just shut EVERYTHING down</p>
<p>Picari: They went to our first ever msg…We look incriminating…if we shut down…I say delete the chat…Our chat is Fraud 100%</p>
<p>Vijayanathan : Everyone with a brain will tell you stop it here and move on</p>
<p>Picari: Just because we close it doesn’t mean we didn’t do it…But deleting our chat…Will f*^k their investigations…There’s nothing fraudulent on the site</p></blockquote>
<p>Despite deleting its Telegram channel, OTP Agency evidently found it difficult to walk away from its customers (and/or the money). Instead of shutting down as Vijayanathan wisely advised, just a few days later OTP Agency was communicating with customers <a href="https://krebsonsecurity.com/wp-content/uploads/2024/09/otp-support.png" target="_blank" rel="noopener">on a new Telegram channel</a>, offering a new login page and assuring existing customers that their usernames, passwords and balances would remain the same.</p>
<div id="attachment_68562"><p><img aria-describedby="caption-attachment-68562" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/09/optagency-reborn.png" alt="" width="775" height="632" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/09/optagency-reborn.png 775w, https://krebsonsecurity.com/wp-content/uploads/2024/09/optagency-reborn-768x626.png 768w" sizes="(max-width: 775px) 100vw, 775px"></p><p id="caption-attachment-68562">OTP Agency, immediately after their initial shutdown, telling customers their existing logins will still work.</p></div>
<p><span id="more-68557"></span>But that revival would be short-lived. The NCA said the site was taken offline less than a month later when the trio were arrested. NCA investigators said more than 12,500 people were targeted by OTP Agency users during the 18 month the service was active.</p>
<p>Picari was the owner, developer and main beneficiary of the service, and his personal information and ownership of OTP Agency was revealed in February 2020 in a “dox” posted to the now-defunct English-language cybercrime forum <a href="https://krebsonsecurity.com/2022/04/raidforums-get-raided-alleged-admin-arrested/" target="_blank" rel="noopener">Raidforums</a>. The NCA said it began investigating the service in June 2020.</p>
<div id="attachment_68565"><p><img aria-describedby="caption-attachment-68565" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/09/otpa-mugshots.png" alt="" width="748" height="440" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/09/otpa-mugshots.png 775w, https://krebsonsecurity.com/wp-content/uploads/2024/09/otpa-mugshots-768x452.png 768w" sizes="(max-width: 748px) 100vw, 748px"></p><p id="caption-attachment-68565">The OTP Agency operators who pleaded guilty to running the service; Aza Siddeeque, Callum Picari, and Vijayasidhurshan Vijayanathan.</p></div>
<p>OTP Agency might be gone, but several other similar OTP interception services are still in operation and accepting new customers, including a long-running service <a href="https://krebsonsecurity.com/2021/09/the-rise-of-one-time-password-interception-bots/" target="_blank" rel="noopener">KrebsOnSecurity profiled in September 2021</a> called <strong>SMSRanger</strong>. More on SMSRanger in an upcoming post.</p>
<p>Text messages, emails and phone calls warning recipients about potential fraud are some of the most common scam lures. If someone (or something) calls saying they’re from your bank, or asks you to provide any personal or financial information, <em>do not respond</em>.&nbsp; Just hang up, full stop.</p>
<p>If the call has you worried about the security and integrity of your account, check the account status online, or call your financial institution — ideally using a phone number that came from the bank’s Web site or from the back of your payment card.</p>
<p>Further reading: <a href="https://krebsonsecurity.com/2020/04/when-in-doubt-hang-up-look-up-call-back/" target="_blank" rel="noopener">When in Doubt, Hang Up, Look Up, and Call Back</a></p>
											</div></div>]]></description>
        </item>
    </channel>
</rss>