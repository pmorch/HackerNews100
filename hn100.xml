<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 02 Jul 2024 17:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[With fifth busy beaver, researchers approach computation's limits (110 pts)]]></title>
            <link>https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/</link>
            <guid>40857041</guid>
            <pubDate>Tue, 02 Jul 2024 14:27:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/">https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/</a>, See on <a href="https://news.ycombinator.com/item?id=40857041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>One memorable encounter occurred while Ligocki was visiting Germany the summer after his sophomore year, when he took a side trip to Berlin to meet up with Marxen. “We got through the language barrier through the medium of busy beavers,” he said. The medium of beer also helped. Ligocki ended up having too many and missed his train back to Hamburg.</p>
<p>The busy beaver bug stuck with Ligocki throughout college, but when he graduated and found a job, life got in the way. He returned to the hunt from time to time, but never for long. In early 2022, he set up an <a href="https://groups.google.com/g/busy-beaver-discuss">online discussion group</a> to help researchers stay in touch. Then in May, Stérin discovered the mailing list and sent an invitation to join the Busy Beaver Challenge. Ligocki needed no convincing.</p>

<p>One of his first contributions to the project was reviving a technique invented by Marxen, which they’d discussed in that Berlin pub 16 years earlier. Called the “closed tape language method,” it was a new way to identify patterns on a Turing machine’s tape that indicate it will never halt. This is the basic strategy behind programs that identify loopers and many other species of non-halting machines, but the closed tape language method had the potential to identify a much broader class of patterns using a unified mathematical framework.</p>
<p>Ligocki wrote a <a href="https://www.sligocki.com/2022/06/10/ctl.html">blog post</a> introducing his new collaborators to the technique, but even though the theoretical idea was very general, he didn’t know how to write a program that would cover all the cases. Blanchard figured out how to do that shortly after joining the project in the fall, but his program was relatively slow. Then two other contributors found ways to make it run much faster. Within the span of a few months, the closed tape language technique had gone from a promising idea to one of their <a href="https://discuss.bbchallenge.org/t/decider-finite-automata-reduction/123">most powerful tools</a>. It could even handle 10 of Georgiev’s 43 holdouts, nicknamed <a href="https://bbchallenge.org/skelet">Skelet machines</a> in his honor.</p>
<p>“This thing would never have existed with any one person contributing,” Ligocki said.</p>
<h2><strong>A Monster Approaches</strong></h2>
<p>As the months passed, new contributors discovered the Busy Beaver Challenge and began chipping away at different parts of the problem. But many machines remained unsolved, and two developed especially fearsome reputations.</p>
<p>The first was <a href="https://bbchallenge.org/1LC1LE_---1LD_1RD0LD_1LA1RE_0LB0RC">Skelet #1</a>, which kept alternating between phases of predictable and chaotic behavior. Then in March 2023, Ligocki and Pavel Kropitz — a Slovakian contributor who doesn’t speak English and communicates with the rest of the team using Google Translate — developed a series of ideas that finally <a href="https://www.sligocki.com/2023/03/13/skelet-1-infinite.html">cracked it open</a>. Using a souped-up version of Marxen and Buntrock’s 30-year-old accelerated simulation technique, they discovered that the tug-of-war between order and chaos did end, but only after more than a trillion trillion steps. Then it finally settled into a repeating cycle that was itself unusually long. Practically all infinite loops begin repeating within 1,000 steps; Skelet #1’s was more than 8 billion steps long.</p>
<p>“Who ordered that?” Blanchard said. “Where did that come from? Why is it here?”</p>

<p>The machine’s behavior was so strange, and the proof combined so many different ideas, that for nearly five months Ligocki wasn’t sure of the result. That period of uncertainty was dispelled by a new contributor — a 21-year-old self-taught programmer named <a href="https://github.com/meithecatte">Maja Kądziołka</a>, who mostly goes by the single name mei.</p>
<p>Kądziołka grew up in Poland and attended the University of Warsaw for one semester in fall 2021 before dropping out — the rigidity of the curriculum and the move to remote instruction after a surge of Covid-19 cases didn’t fit well with their learning style. They worked at a software company for a little over a year but increasingly found the work draining, and began looking for something more intellectually stimulating. They found it in Coq, the software designed to encode and certify the validity of mathematical proofs.</p>

<p>The Busy Beaver Challenge contributors were already using computer programs in their proofs, but like paper-and-pencil proofs, computer programs are vulnerable to errors. In Coq proofs, the code won’t run unless every line logically follows from the preceding ones, making errors effectively impossible. To Kądziołka, figuring out how to craft these proofs began to feel like a game. “It’s almost addictive,” they said. “I started at a normal hour, and then it was night. Then it was morning.”</p>
<p>After learning Coq, Kądziołka began looking for an open problem to test it out. That’s when they found the Busy Beaver Challenge. A few weeks later, they’d <a href="https://github.com/meithecatte/busycoq">translated</a> several of the team’s proofs into Coq, including Ligocki and Kropitz’s proof that Skelet #1 never halts — Ligocki could finally be sure about it. Suddenly, an even higher standard of rigor than Stérin’s emphasis on reproducibility seemed possible. And it had all started with someone who had no formal training at all — an amateur mathematician.</p>
<p>“Let’s remember that means a lover of mathematics,” Moore said. “It is not a pejorative term.”</p>
<h2><strong>The Dam Breaks</strong></h2>
<p>Around the same time, a graduate student named <a href="http://chrisxudoesmath.com/">Chris Xu</a> made a breakthrough on the second monstrous machine — <a href="https://bbchallenge.org/1LB---_0RC1LE_0RD1RC_1LA1RB_0LB0LA">Skelet #17</a>. It was usually easy to summarize the behavior of even the most fiendish five-rule Turing machines once you figured out how they worked. “Then you encounter some bullshit like Skelet 17, and you go, ‘Nah, the universe is trolling us,’” Kądziołka said. Understanding Skelet #17 by studying the patterns on its tape was like deciphering a secret message wrapped in four layers of encryption: Cracking one code just revealed another totally unrelated code, and two more below that. Xu had to decipher all of them before he could finally prove that the machine never halted.</p>
<p><a href="http://chrisxudoesmath.com/papers/skelet17.pdf">Xu’s proof</a> was brilliant, but it involved some mathematical intuition that nobody knew how to formalize in the precise terms demanded by Coq. What’s more, the Busy Beaver Challenge’s work wasn’t done: While Skelet #1 and #17 were the two machines that had seemed most formidable, some others remained to be solved, and still more had only been solved using inefficient programs. That was no way to convince the world.</p>

<p>“We wanted to make sure that it was something reasonably reproducible,” Blanchard said, “and also not write a proof where we would say, ‘Step 63: Let this program run for six months.’”</p>
<p>Over the following months, the community slowly cobbled together proofs for the remaining machines, but most had yet to be translated into Coq. Then in April a <a href="https://discuss.bbchallenge.org/t/proving-bb-5-in-coq/225">mysterious new contributor</a> known only by the pseudonym mxdys came in to finish the job. Nobody on the team knows where mxdys is located or any other personal details about them. In a Discord direct message exchange, they mentioned a long-standing interest in mathematical games, but they declined to provide more information about their background.</p>
<p>On May 10, mxdys posted a characteristically succinct message to the Discord server: “The Coq proof of BB(5) is finished.” Stérin replied a minute later with a series of seven exclamation points. In a matter of weeks, mxdys had refined the community’s techniques and synthesized their results into a single <a href="https://github.com/ccz181078/Coq-BB5">40,000-line Coq proof</a>.</p>
<p>“This is not a thing that’s easy to formalize,” said <a href="https://yforster.de/">Yannick Forster</a>, a Coq expert at the French national research institute Inria who reviewed the proof. “I’m still positively shocked.”</p>
<p>The machine that Marxen and Buntrock had discovered over 30 years earlier, which halted after 47 million steps, really was the fifth busy beaver.</p>
<p>“These news are very exciting for me,” Georgiev wrote in an email. “I never expected that this problem would be solved in my time.”</p>
<p>But for another Busy Beaver pioneer, the news came too late. Allen Brady <a href="https://www.rgj.com/obituaries/pnvs0805561">died on April 21</a>, less than a month before the proof was finished. He was 90 years old.</p>
<h2><strong>Where Beavers Roam</strong></h2>
<p>The Busy Beaver Challenge contributors have begun to draft a formal academic paper describing their results, supplementing mxdys’ Coq proof with a human-readable one. That’ll take a while: Most machines were proved non-halting in multiple ways, and the team will need to decide how best to combine the results into a single proof.</p>

<p>Meanwhile, part of the team has moved on to the next beaver. But just four days ago, mxdys and another contributor known as Racheline discovered a barrier for BB(6) that seems insurmountable: a six-rule machine whose halting problem resembles a famously intractable math problem called the <a href="https://www.quantamagazine.org/computer-scientists-attempt-to-corner-the-collatz-conjecture-20200826/">Collatz conjecture</a>. Connections between Turing machines and the Collatz conjecture date back to a <a href="https://link.springer.com/article/10.1007/BF01409968">1993 paper</a> by the mathematician <a href="https://bbchallenge.org/~pascal.michel/index.html">Pascal Michel</a>, but the newly discovered machine, dubbed “<a href="https://bbchallenge.org/1RB1RA_0LC1LE_1LD1LC_1LA0LB_1LF1RE_---0RA&amp;status=undecided">Antihydra</a>,” is the smallest one that appears unsolvable without a conceptual breakthrough in mathematics. That adds an extra layer of significance to the BB(5) result.</p>
<p>“It’s conceivable that this is the last busy beaver number that we will ever know,” Aaronson said.</p>
<p>There are many variants of the original busy beaver problem, and some Busy Beaver Challenge contributors plan to keep working on these. But not everyone intends to continue this work. They each came to the project on their own, for their own reasons, and their journeys are beginning to diverge.</p>
<p>Stérin wants to develop software tools to facilitate collaborative online projects in other areas of mathematics. “The thing that BB challenge brought me is the deep, deep, deep conviction that it’s an extremely effective way of performing research,” he said. “It deserves to have a bigger stage.”</p>

<p>Kądziołka too is pulling back, after developing a fascination with the European international rail network. “I will probably come back to busy beaver things again at some point, but currently it’s not the thing on my mind,” they said. “I’m currently pursuing becoming a train driver.”</p>
<p>Ligocki thinks he’ll keep up his busy beaver hunting, but after 20 years of switching between bursts of intense activity and not thinking about beavers at all, he’s learned not to put too much stock in his predictions.</p>
<p>“It’s kind of like the halting problem,” he said. “You just never can quite tell what’s going to happen.”</p>
<p><em>Editor’s note: Scott Aaronson is a member of&nbsp;</em>Quanta Magazine<em>’s&nbsp;</em><a href="https://www.quantamagazine.org/about/"><em>advisory board</em></a><em>.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Is Chile So Long? (479 pts)]]></title>
            <link>https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long</link>
            <guid>40856030</guid>
            <pubDate>Tue, 02 Jul 2024 12:36:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long">https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long</a>, See on <a href="https://news.ycombinator.com/item?id=40856030">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Chile is so long, it's </span><strong>curved.</strong></p><p><span>How long is it?</span><br><span>Why </span><em>not longer</em><span>?</span><br><span>Why is no other country as thin?</span><br><span>How does that make Chileans incomprehensible?</span></p><p>All your answers in today’s article!</p><p><span>Chile is as long as the US and Canada </span><strong><span>combined.</span><br></strong><span>Chile is as long as all of Europe!</span><br><span>It can stretch from Norway to Morocco.</span><br><span>From London to Baghdad!</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>You can stack over a dozen European countries in Chile north to south.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png" width="472" height="819.0260047281324" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1468,&quot;width&quot;:846,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Of course, that means Chile has every possible climate.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png" width="1041" height="1438" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1438,&quot;width&quot;:1041,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Chile is so long because of the Andes. Here's a map of elevation in South America.</p><p>You can't easily pass these mountains, and the tiny sliver of land to their west is Chile.</p><p>The mountains exist because of the Nazca tectonic plate hitting the South American one:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png" width="1456" height="739" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:739,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Here's a superb (composite) image of a Chilean volcano :</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png" width="544" height="768" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:544,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>But why is Chile so long? Why not longer? You can get a sense by looking at a satellite map of the region. From it, can you guess where most Chileans live?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png" width="458" height="591.9224555735057" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1600,&quot;width&quot;:1238,&quot;resizeWidth&quot;:458,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You can see by comparing the satellite map and the map of night lights:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif" width="436" height="553.3254994124559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:851,&quot;resizeWidth&quot;:436,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Chileans live in the middle of the country, in the northern part of the green stripe.</p><p>What's happening?</p><p>Winds blow westward close to the Equator and eastward farther south.</p><p>The Andes stop all the moisture from the Atlantic near the Equator, and from the Pacific farther south.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png" width="1456" height="1484" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1484,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>That's why both Brazil </span><strong>and Chile</strong><span> have rainforests.&nbsp;</span></p><p><span>The Chilean one is a </span><strong>temperate</strong><span> rainforest—like in the Pacific Northwest in North America.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png" width="402" height="497.88990825688074" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:872,&quot;resizeWidth&quot;:402,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You can see that reflected in the map of South America’s forests:</p><p>So all of southern Chile is green, but only the northern half of that is warm enough for comfortable living (and close to other countries' centers of population). That's where most Chileans live.</p><p>What about the northern part then, the desert?</p><p>That area is so dry, it can't support a large population.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png" width="398" height="458.7118644067797" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:680,&quot;width&quot;:590,&quot;resizeWidth&quot;:398,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>These flowers in the Atacama Desert only bloom every few years, when rainfall is unusually high.</em></figcaption></figure></div><p>And since it's close to the center of South America, it has neighbors...</p><p>Few locals and lots of neighbors means this area was contested for a long time after the Spanish Empire collapsed.</p><p>This is a map of contested areas in South America, 1879:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png" width="465" height="768" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:465,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Peru &amp; Bolivia went to war with Chile for that region, but they lost in the War of the Pacific.</p><p>Why fight? Natural resources: guano and saltpeter.</p><p>Back then, guano was the world’s main fertilizer (and this area had most of the world's guano, thanks to the climate).</p><p>Saltpeter was useful for gunpowder.</p><p>So why is Chile so long, but not longer?</p><ul><li><p>A sliver between coast &amp; Andes</p></li><li><p>Far south: too cold for another country</p></li><li><p>Far north: competing neighbors</p></li><li><p>Natural border there: desert. Chile won the war to get the tip.</p></li></ul><p>That's also why most Chileans live in the middle of the country: too cold in the south, too hot and dry in the north.</p><p>You can see that effect in a map of South American roads:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png" width="460" height="738.2146439317954" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1600,&quot;width&quot;:997,&quot;resizeWidth&quot;:460,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Cold, heat, sea and mountains make Chile a country—an extremely isolated one:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png" width="1456" height="1299" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1299,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And that's also the main reason why Chileans are incomprehensible: So isolated from all other Spanish speakers!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png" width="562" height="562" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:1080,&quot;resizeWidth&quot;:562,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Here’s some more detail, from </span><em><a href="https://unchartedterritories.tomaspueyo.com/p/why-do-900-million-people-speak-spanish" rel="">Why Do 900 Million People Speak Spanish and Portuguese the Way They Do?</a><span>:</span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg" width="1456" height="1009" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1009,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This graph shows how much the Spanish from different countries resemble each other. The greener, the closer. The redder, the farther apart.</p><p>You can see some countries are very red:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg" width="1456" height="989" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:989,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You see how red Chilean Spanish is? It means it’s quite different. In the beginning of Grad School, I could understand all my Hispanic classmates, but I had a hard time understanding the Chileans!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg" width="598" height="246" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:246,&quot;width&quot;:598,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I couldn’t find any great analysis on this, so if you find it, please let me know. The best hypotheses I could find were:</p><ul><li><p>It’s the farthest region from Spain, so the least communicated to the rest of the empire, and hence the one that drifted the most from the homeland.</p></li><li><p>It’s extremely isolated by the Andes, the ocean in the west, the ice in the south, and the desert in the north, making its connection even to Argentina, Bolivia or Peru really hard.</p></li><li><p>It didn’t have silver mines, or a climate for sugar or tobacco farming, so it wasn’t a particularly valuable place to exploit, and remained secondary in the empire, getting fewer visitors from other parts of the empire, and drifting further apart.</p></li><li><p>It has strong influences from other regions, such as German, Italian, or even Basque.&nbsp;</p></li></ul><p>But why is no other country as long?</p><p>You need:</p><ul><li><p>A sandwich between sea and continent</p></li><li><p>Oriented north-south, so that it changes climates quickly&nbsp;</p></li><li><p>Far enough from the equator so that the north-south climate does change fast, and so that it’s not too densely populated.</p></li></ul><p>The sandwich requires an oceanic plate subducting under a continental plate, which only happens here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png" width="1456" height="993" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:993,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>From there, take out the areas that are equatorial or too cold:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png" width="1456" height="1007" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1007,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the western Pacific, that leaves islands, mainly Japan, New Zealand, and maybe the Philippines. But in this part of the world, the mountain chains start from deep under the sea, which generates archipelagos rather than a continental sliver.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png" width="1456" height="907" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:907,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the eastern Pacific, it leaves Chile and the US – Mexico – Canada west coast. An elevation map shows how a country could have been viable here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png" width="1456" height="1413" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1413,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>West of the mountain chain that runs through all of the American continent, you can see the green sliver that could have been a country.</em></figcaption></figure></div><p>So why don’t we have a Chile of the north?</p><p>Mexico was close to Spain, had silver mines interesting to Spain, smaller mountains than the Andes, and is much narrower from sea to sea. All of this made the country much better communicated east-west, so the western coast couldn’t evolve as a separate entity.</p><p>In the US and Canadian coast, the US conquered that area from the east extremely fast, making the independence of the West Coast impossible. We can imagine that, if these regions had been left to continue developing for a few thousand years, a distinct country (or set of countries) would have emerged in the west.</p><p>So that's why Chile is one of the longest—and the thinnest—countries in the world!</p><div data-attrs="{&quot;url&quot;:&quot;https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p><em>If you know somebody who’d enjoy this article, show you think about them and share it!</em></p><p data-attrs="{&quot;url&quot;:&quot;https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Welcome to Ladybird, a truly independent web browser (526 pts)]]></title>
            <link>https://ladybird.org/index.html</link>
            <guid>40854836</guid>
            <pubDate>Tue, 02 Jul 2024 09:14:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ladybird.org/index.html">https://ladybird.org/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=40854836">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      <div>
            <h2>
              Welcome to <span>Ladybird</span>,<br>a truly independent<br>web
              browser.
            </h2>
            <p>
              We are building a brand-new browser from scratch, backed by a
              non-profit.
            </p>
            <p><a href="#gi">Get Involved</a>
          </p></div>

      <div id="about">
            <p><img src="https://ladybird.org/assets/img/about-2x.webp" alt="">
            </p>
            <div>
              <h2>About <span>Ladybird</span></h2>
              <p>
                Ladybird is a brand-new browser &amp; web engine. Driven by a
                web standards first approach, Ladybird aims to render the
                modern web with good performance, stability and security.
              </p>
              <p>
                From its humble beginnings as an HTML viewer for the SerenityOS
                hobby operating system project, Ladybird has since grown into a
                cross-platform browser supporting Linux, macOS, and other
                Unix-like systems.
              </p>
              <p>
                Ladybird is currently in heavy development. We are targeting a
                first Alpha release for early adopters in 2026.
              </p>
            </div>
          </div>

      <div>
          <div>
            <p>
              <h2>What makes <span>Ladybird</span> unique</h2>
            </p>
          </div>

          <div>
            <div>
                <p><img src="https://ladybird.org/assets/img/truly-independent.svg">
                </p>
                <div>
                  <h4>Truly independent</h4>
                  <p>
                    No code from other browsers.
                    We're building a new engine, based on web standards.
                  </p>
                </div>
              </div>

            <div>
                <p><img src="https://ladybird.org/assets/img/single-focus.svg">
                </p>
                <div>
                  <h4>Singular focus</h4>
                  <p>We are focused on one thing: the web browser.
                </p></div>
              </div>

            <div>
                <p><img src="https://ladybird.org/assets/img/no-monetization.svg">
                </p>
                <div>
                  <h4>No monetization</h4>
                  <p>
                    No "default search deals", crypto tokens, or other forms of
                    user monetization, ever.
                  </p>
                </div>
              </div>
          </div>
        </div>

      <div id="news">
          <p>
            <h2>News &amp; Announcements</h2>
          </p>
          
        </div>

      <div id="gi">
            <h2>Get Involved</h2>
            <p>
              Ladybird is currently in heavy development, and there's work to be
              done in all areas of the browser.
            </p>
            <p>
              We're welcoming new developers every week. The main community hub
              is
              <a href="https://discord.gg/nvfjVJ4Svh">our Discord server</a>.
            </p>
            <p>
              All the code is hosted on
              <a href="https://github.com/LadybirdBrowser/ladybird">GitHub</a>. Clone it, build it, and join our Discord if you want to
              collaborate on it! We're looking forward to seeing you there.
            </p>
            <p><a href="https://discord.gg/nvfjVJ4Svh">Join Discord</a>
            <a href="https://github.com/LadybirdBrowser/ladybird">Get the code</a>
          </p></div>

      

      <div>
              <h2>Become a <span>Ladybird</span> supporter</h2>
              <p>
                Ladybird is funded entirely by sponsorships and donations from
                people and companies who care about the open web.
              </p><p>
                We accept one-time and recurring monthly donations via <a href="https://donorbox.org/ladybird">Donorbox</a>.
              </p><p>
                If you or your company would like to make a large donation, we would be happy to display your logo
                on this website! Please <a href="mailto:contact@ladybird.org">contact us</a> about becoming a sponsor.
            </p></div>

      <div>
          <p>
            <h2>Frequently Asked Questions</h2>
          </p>

          <div>
            <div>
                
                <p>
                  We are targeting Summer 2026 for a first Alpha version on
                  Linux and macOS. This will be aimed at developers and early
                  adopters.
                </p>
              </div>

            <div>
                
                <p>
                  We currently have 4 paid full-time engineers working on
                  Ladybird. There is also a large community of volunteer contributors.
                </p>
              </div>

            <div>
                
                <p>
                  We have 3 new full-time engineers starting soon. Going
                  forward, we would like to grow the team at a reasonable pace.
                  Building the right team is more important than building it
                  quickly.
                </p>
              </div>

            <div><p>
                  The focus of the Ladybird project is to build a new browser
                  engine from the ground up. We don't use code from Blink,
                  WebKit, Gecko, or any other browser engine.
                  </p><p>
                  For historical reasons, the browser uses various libraries
                  from the SerenityOS project, which has a strong culture of
                  writing <i>everything</i> from scratch.
                  Now that Ladybird has forked from SerenityOS, it is no longer
                  bound by this culture, and we will be making use of 3rd party
                  libraries for common functionality (e.g image/audio/video formats,
                  encryption, graphics, etc.)
                  </p><p>
                  We are already using some of the same 3rd party libraries
                  that other browsers use, but we will never adopt another
                  browser engine instead of building our own.
                </p></div>

            <div><p>
                  We don't have anyone actively working on Windows support, and
                  there are considerable changes required to make it work well
                  outside a Unix-like environment.
                  </p><p>
                  We would like to do Windows eventually, but it's not a priority
                  at the moment.
                </p></div>

            <div><p>
                  We don't have anyone actively working on an Android or iOS port.
                  More effort will be put into mobile once we have the desktop versions in a good state.
                  </p><p>
                  While there is the start of an Android port in the project repository,
                  mobile is not a priority at the moment.
                </p></div>

            <div>
                  
                  <p>
                  Sponsors will have their logos displayed on our website, and
                  will be thanked in updates / on social media.
                  </p><p>
                  Please <a href="mailto:contact@ladybird.org">contact us</a> if you are interested in sponsorship.
                </p></div>

            <div>
                
                <p>
                  All sponsorships are in the form of unrestricted donations.
                  Board seats and other forms of influence are not for sale.
                </p>
              </div>

            <div><p>
                  Ladybird started as a component of the SerenityOS hobby project, which only allows C++.
                  The choice of language was not so much a technical decision, but more one of personal convenience.
                  Andreas was most comfortable with C++ when creating SerenityOS, and now we have almost half
                  a million lines of modern C++ to maintain.
                  </p><p>
                  However, now that Ladybird has forked and become its own independent project,
                  all constraints previously imposed by SerenityOS are no longer in effect.
                  We are actively evaluating a number of alternatives and will
                  be adding a mature successor language to the project in the near future.
                  This process is already quite far along, and prototypes exist in
                  multiple languages.
                </p></div>

          </div>
        </div>

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diff-pdf: tool to visually compare two PDFs (325 pts)]]></title>
            <link>https://github.com/vslavik/diff-pdf</link>
            <guid>40854319</guid>
            <pubDate>Tue, 02 Jul 2024 07:26:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/vslavik/diff-pdf">https://github.com/vslavik/diff-pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40854319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><em>Note: this repository is provided <strong>as-is</strong> and the code is not being actively
developed. If you wish to improve it, that's greatly appreciated: please make
the changes and submit a pull request, I'll gladly merge it or help you out
with finishing it. However, please do not expect any kind of support, including
implementation of feature requests or fixes. If you're not a developer and/or
willing to get your hands dirty, this tool is probably not for you.</em></p>
<p dir="auto"><a href="https://github.com/vslavik/diff-pdf/actions/workflows/build.yml"><img src="https://github.com/vslavik/diff-pdf/actions/workflows/build.yml/badge.svg" alt="Build"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">diff-pdf is a tool for visually comparing two PDFs.</p>
<p dir="auto">It takes two PDF files as arguments. By default, its only output is its return
code, which is 0 if there are no differences and 1 if the two PDFs differ. If
given the <code>--output-diff</code> option, it produces a PDF file with visually
highlighted differences:</p>
<div data-snippet-clipboard-copy-content="$ diff-pdf --output-diff=diff.pdf a.pdf b.pdf"><pre><code>$ diff-pdf --output-diff=diff.pdf a.pdf b.pdf
</code></pre></div>
<p dir="auto">Another option is to compare the two files visually in a simple GUI, using
the <code>--view</code> argument:</p>
<div data-snippet-clipboard-copy-content="$ diff-pdf --view a.pdf b.pdf"><pre><code>$ diff-pdf --view a.pdf b.pdf
</code></pre></div>
<p dir="auto">This opens a window that lets you view the files' pages and zoom in on details.
It is also possible to shift the two pages relatively to each other using
Ctrl-arrows (Cmd-arrows on MacOS). This is useful for identifying translation-only differences.</p>
<p dir="auto">See the output of <code>$ diff-pdf --help</code> for complete list of options.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Obtaining the binaries</h2><a id="user-content-obtaining-the-binaries" aria-label="Permalink: Obtaining the binaries" href="#obtaining-the-binaries"></a></p>
<p dir="auto">Precompiled version of the tool for Windows is available as part of
<a href="https://github.com/vslavik/diff-pdf/releases/latest/">the latest release</a>
as a ZIP archive, which contains everything you need to run diff-pdf. It will
work from any place you unpack it to.</p>
<p dir="auto">Alternatively, if you use <a href="https://chocolatey.org/" rel="nofollow">Chocolatey</a>, you can install
diff-pdf on Windows with:</p>

<p dir="auto">On Mac, if you use <a href="https://brew.sh/" rel="nofollow">Homebrew</a>, you can use it to install diff-pdf with it:</p>

<p dir="auto">On Mac, if you use <a href="https://macports.org/" rel="nofollow">Macports</a>, you can install diff-pdf with:</p>

<p dir="auto">On  Fedora and CentOS 8:</p>
<div data-snippet-clipboard-copy-content="$ sudo dnf install diff-pdf"><pre><code>$ sudo dnf install diff-pdf
</code></pre></div>
<p dir="auto">Precompiled version for openSUSE can be downloaded from the
<a href="http://software.opensuse.org/" rel="nofollow">openSUSE build service</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling from sources</h2><a id="user-content-compiling-from-sources" aria-label="Permalink: Compiling from sources" href="#compiling-from-sources"></a></p>
<p dir="auto">The build system uses Automake and so a Unix or Unix-like environment (Cygwin
or MSYS) is required. Compilation is done in the usual way:</p>
<div data-snippet-clipboard-copy-content="$ ./bootstrap
$ ./configure
$ make
$ make install"><pre><code>$ ./bootstrap
$ ./configure
$ make
$ make install
</code></pre></div>
<p dir="auto">(Note that the first step, running the <code>./bootstrap</code> script, is only required
when building sources checked from version control system, i.e. when <code>configure</code>
and <code>Makefile.in</code> files are missing.)</p>
<p dir="auto">As for dependencies, diff-pdf requires the following libraries:</p>
<ul dir="auto">
<li>wxWidgets &gt;= 3.0</li>
<li>Cairo &gt;= 1.4</li>
<li>Poppler &gt;= 0.10</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">CentOS:</h4><a id="user-content-centos" aria-label="Permalink: CentOS:" href="#centos"></a></p>
<div data-snippet-clipboard-copy-content="$ sudo yum groupinstall &quot;Development Tools&quot;
$ sudo yum install wxGTK wxGTK-devel poppler-glib poppler-glib-devel"><pre><code>$ sudo yum groupinstall "Development Tools"
$ sudo yum install wxGTK wxGTK-devel poppler-glib poppler-glib-devel
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Ubuntu:</h4><a id="user-content-ubuntu" aria-label="Permalink: Ubuntu:" href="#ubuntu"></a></p>
<div data-snippet-clipboard-copy-content="$ sudo apt-get install make automake g++
$ sudo apt-get install libpoppler-glib-dev poppler-utils libwxgtk3.0-gtk3-dev"><pre><code>$ sudo apt-get install make automake g++
$ sudo apt-get install libpoppler-glib-dev poppler-utils libwxgtk3.0-gtk3-dev
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">macOS:</h4><a id="user-content-macos" aria-label="Permalink: macOS:" href="#macos"></a></p>
<p dir="auto">Install Command Line Tools for Xcode:</p>

<p dir="auto">and install <a href="https://brew.sh/" rel="nofollow">Homebrew</a> or <a href="https://www.macports.org/" rel="nofollow">MacPorts</a> to manage dependencies, then:</p>
<div data-snippet-clipboard-copy-content="$ brew install automake autoconf wxmac poppler cairo pkg-config"><pre><code>$ brew install automake autoconf wxmac poppler cairo pkg-config
</code></pre></div>
<p dir="auto">or</p>
<div data-snippet-clipboard-copy-content="$ sudo port install automake autoconf wxWidgets-3.0 poppler cairo pkgconfig"><pre><code>$ sudo port install automake autoconf wxWidgets-3.0 poppler cairo pkgconfig
</code></pre></div>
<p dir="auto">Note that many more libraries are required on Windows, where none of the
libraries Cairo and Poppler use are normally available. At the time of writing,
transitive cover of the above dependencies included fontconfig, freetype, glib,
libpng, pixman, gettext, libiconv, libjpeg and zlib.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Compiling on Windows using MSYS + MinGW</h3><a id="user-content-compiling-on-windows-using-msys--mingw" aria-label="Permalink: Compiling on Windows using MSYS + MinGW" href="#compiling-on-windows-using-msys--mingw"></a></p>
<ol dir="auto">
<li>
<p dir="auto">First of all, you will need working MinGW installation with MSYS2 environment
and C++ compiler. Install MSYS2 by following <a href="https://www.msys2.org/" rel="nofollow">their instructions</a>.</p>
</li>
<li>
<p dir="auto">Once installed, launch the MSYS2 MinGW shell. It will open a terminal window;
type <code>cd /c/directory/with/diff-pdf</code> to go to the directory with diff-pdf
sources.</p>
</li>
<li>
<p dir="auto">You will need to install additional MSYS components that are not normally
included with MSYS, using these commands:</p>
<div data-snippet-clipboard-copy-content="$ pacman -Syu
$ pacman -S automake autoconf pkg-config make zip pactoys
$ pacboy -S gcc:p poppler:p wxWidgets:p"><pre><code>$ pacman -Syu
$ pacman -S automake autoconf pkg-config make zip pactoys
$ pacboy -S gcc:p poppler:p wxWidgets:p
</code></pre></div>
</li>
<li>
<p dir="auto">Build diff-pdf in the same way as in the instructions for Unix above:</p>
<div data-snippet-clipboard-copy-content="$ ./bootstrap  # only if building from git repository
$ ./configure
$ make"><pre><code>$ ./bootstrap  # only if building from git repository
$ ./configure
$ make
</code></pre></div>
</li>
<li>
<p dir="auto">To build a ZIP archive will all DLLs, run</p>

</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing</h2><a id="user-content-installing" aria-label="Permalink: Installing" href="#installing"></a></p>
<p dir="auto">On Unix, the usual <code>make install</code> is sufficient.</p>
<p dir="auto">On Windows, installation is not necessary, just copy the files somewhere. If
you built it following the instructions above, all the necessary files will be
in the created ZIP archive.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mako – fast, production-grade web bundler based on Rust (199 pts)]]></title>
            <link>https://makojs.dev/blog/mako-open-sourced</link>
            <guid>40853845</guid>
            <pubDate>Tue, 02 Jul 2024 05:41:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://makojs.dev/blog/mako-open-sourced">https://makojs.dev/blog/mako-open-sourced</a>, See on <a href="https://news.ycombinator.com/item?id=40853845">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <h2 id="mako-is-now-open-source" tabindex="-1">Mako is Now Open Source <a href="#mako-is-now-open-source">
          
        </a></h2>
<p><em>2024-06-28 by <a href="https://github.com/sorrycc">sorrycc</a></em></p>
<p>中文版: <a href="https://makojs.dev/blog/mako-open-sourced_zh-CN">《Mako 开源了》</a>。</p>
<p><img src="https://img.alicdn.com/imgextra/i4/O1CN01CK3ElF1kFaFzFBUiA_!!6000000004654-0-tps-1200-662.jpg" alt=""></p>
<p>Hi, I am sorrycc, one of the main maintainers of Mako, and also the creator of Umi, Dva, Father, and other libraries. I am thrilled to announce that Mako is finally open source, the Github url is <a href="https://github.com/umijs/mako/">https://github.com/umijs/mako/</a> , and I’m excited to formally introduce it to you today.</p>
<h2 id="what-is-mako%3F" tabindex="-1">What is Mako? <a href="#what-is-mako%3F">
          
        </a></h2>
<img src="https://img.alicdn.com/imgextra/i4/O1CN01dvFN0j1e2rYBJpJGJ_!!6000000003814-2-tps-2048-2048.png_240x240.jpg" width="120" height="120">
<p>Mako is an “extremely fast” and “production-grade” front-end build tool, based on Rust.</p>
<p>The “extremely fast” aspect was our initial motivation for starting the Mako project. Without build speed issues, Mako would not have been necessary. Refer to the Benchmark section below for some data, and we are constantly exploring even faster build speed solutions. The “production-grade” label comes from the fact that since 2023.11.24, Mako has been officially released internally at Ant Group. It has been validated with engineering practices on thousands of projects and all used npm packages and their versions. It has been implemented in hundreds of projects, serving various platforms and business scenarios internally, including management backends, mini-programs, H5 mobile, low-code, marketing, component libraries, component packaging, Serverless Functions, etc., demonstrating fully production-grade capabilities.</p>
<p>You can visit <a href="https://makojs.dev/docs/features">https://makojs.dev/docs/features</a> to learn more about Mako’s features.</p>
<h2 id="how-did-mako-come-about%3F" tabindex="-1">How did Mako come about? <a href="#how-did-mako-come-about%3F">
          
        </a></h2>
<p>Last year (2023.3), our team launched 3 projects, Rust, SSR, and AIG, and we took on the Rust direction to tackle build performance issues. Our team has been exploring faster build speed solutions, including <a href="https://umijs.org/blog/mfsu-faster-than-vite">MFSU</a>, which optimizes build speed within Webpack. However, this had certain limitations. We sought a thorough solution through Rust.</p>
<p><img src="https://img.alicdn.com/imgextra/i2/O1CN01GDA0FY1mgixV0oGkA_!!6000000004984-2-tps-2772-1330.png_1200x1200.jpg" alt=""></p>
<p>You might wonder why we didn’t use existing Rust tools but decided to create one ourselves. The reasons are complex. For instance, 1) the maturity level of community libraries and their compatibility with Ant’s needs, we researched all the community Rust build solutions before starting, ultimately deciding on creating our own, 2) having control, due to business reasons, build tools at Ant require a lot of customization, and this proved true as we found many matching needs after internal release, 3) the modern meta-frameworks require compilation-time frameworks, in addition to build, they also have a lot of compilation needs, especially in SSR &amp; RSC scenarios, for example, RSC scenarios required 4 builds internally, 4) the need to learn Rust and for team growth, modern frontend tools are all written in Rust, and we would fall behind if we did not advance.</p>
<p><img src="https://img.alicdn.com/imgextra/i3/O1CN012T9Nlo1WVFBDT64dK_!!6000000002793-2-tps-2090-854.png" alt=""></p>
<p>The timeline above is for Mako. Mako kicked off in 2023.3, had its first usable version by 2023.7, was internally released at Ant in 2023.11, and was open-sourced by 2024.6. We initially had 3 members with zero Rust experience, with team members, especially the virtual team, coming and going, learning Rust while digesting build knowledge and working on Mako was challenging, but fortunately, we succeeded and learned a lot in the process. We would like to thank the pioneers in the build domain like Webpack, Farm, and Rspack, as well as ChatGPT.</p>
<h2 id="speed" tabindex="-1">Speed <a href="#speed">
          
        </a></h2>
<p>Mako has put a lot of effort into speed. Below is some Benchmark data.</p>
<p><img src="https://img.alicdn.com/imgextra/i1/O1CN01Ibymuk1xrDoNp2jBg_!!6000000006496-2-tps-2018-340.png" alt=""></p>
<p>The Benchmark ran on a project that Turbopack also tests, on a Mac Book Pro M2 Max. It includes dimensions such as dev cold start time, root node and leaf node HMR time, production Build build time, and JS bundle size. (Note: Farm was not tried successfully using API mode, so no HMR data was generated; RsBuild had some issues upgrading to 0.7, so it’s still on 0.6 for now. RsBuild 0.7 might be a bit faster.)</p>
<p>If you’re interested, feel free to clone the repository and try it out yourself.</p>
<pre tabindex="0"><code><span><span>$</span><span> git</span><span> clone</span><span> git@github.com:umijs/benchmark.git</span></span>
<span><span>$</span><span> cd</span><span> benchmark</span></span>
<span><span>$</span><span> pnpm</span><span> i</span></span>
<span><span>$</span><span> pnpm</span><span> run</span><span> setup</span></span>
<span><span>$</span><span> pnpm</span><span> benchmark</span></span>
<span></span></code></pre>
<p>Here’s how we compare to our previous selves.</p>
<p><img src="https://img.alicdn.com/imgextra/i4/O1CN01UkKwZd1nsv7biyZKf_!!6000000005146-1-tps-825-365.gif" alt=""></p>
<p>For Ant Design Pro full project build, Webpack takes 16s, Mako takes 3.9s, a 4x speed improvement.</p>
<p><img src="https://img.alicdn.com/imgextra/i3/O1CN0180np4N1oZyLr5911c_!!6000000005240-1-tps-1340-610.gif" alt=""></p>
<p>For Ant Design Pro full project build, Mako is almost always real-time hot updates.</p>
<p><img src="https://img.alicdn.com/imgextra/i2/O1CN01LpdES21tqWkFN9mCg_!!6000000005953-1-tps-960-540.gif" alt=""></p>
<p>Intranet Hybrid framework Smallfish project build, based on RSC (React Server Components), scaffold project, build time reduced from 36.7s to 1.2s. It looks a bit exaggerated, but these are real data.</p>
<p><img src="https://img.alicdn.com/imgextra/i3/O1CN01L1HteO1uPKqayzb0u_!!6000000006029-2-tps-1538-494.png" alt=""></p>
<p>These are more examples of speed improvements on such RSC projects.</p>
<p><img src="https://img.alicdn.com/imgextra/i2/O1CN01bzKzwO1gnEtk9Z8pN_!!6000000004186-2-tps-2198-852.png" alt=""></p>
<p>Additionally, Mako also has an experimental SSU feature, similar to the previous MFSU implementation, which does packaging and caching of dependencies. Depending on the ratio of source code to dependencies, it can achieve a 10-50x speed boost in Dev hot start-up. Currently, it can be enabled with the <code>SSU=true</code> environment variable.</p>
<h2 id="how-to-participate%3F" tabindex="-1">How to participate? <a href="#how-to-participate%3F">
          
        </a></h2>
<p>If you want to experience Mako, you can create a Mako + React project with a single command using the scaffolding tool.</p>
<pre tabindex="0"><code><span><span>$</span><span> npm</span><span> create</span><span> mako</span></span>
<span></span></code></pre>
<p>If you’re a Umi user, it’s very simple to experience Mako!</p>
<pre tabindex="0"><code><span><span># Make sure your version is 4.2.0 or above</span></span>
<span><span>$</span><span> npx</span><span> umi</span><span> -v</span></span>
<span><span>4.2.0</span></span>
<span><span># Enable Mako configuration</span></span>
<span><span>$</span><span> npx</span><span> umi</span><span> config</span><span> set</span><span> mako</span><span> {}</span></span>
<span><span># Run build or other commands</span></span>
<span><span>$</span><span> npx</span><span> umi</span><span> build</span></span>
<span></span></code></pre>
<p>If you want to discuss issues or suggestions about Mako, you can scan the QR code to join our WeChat group. (If it’s expired or the group is full, please go to <a href="https://makojs.dev/docs/feedback">https://makojs.dev/docs/feedback</a> for a new QR code.)</p>
<img src="https://img.alicdn.com/imgextra/i1/O1CN01kKspME1FdAZ4cQ1F5_!!6000000000509-0-tps-1050-1671.jpg_240x240.jpg" width="120">
<p>Or click the following link to join our Telegram group.</p>
<p><a href="https://t.me/+EN3fycCw3TI1NDA1">https://t.me/+EN3fycCw3TI1NDA1</a></p>
<p>Also, you’re welcome to subscribe to Mako updates via RSS. We’ll post the latest news about Mako and high-quality technical articles related to building.</p>
<p><a href="https://makojs.dev/rss.xml">https://makojs.dev/rss.xml</a></p>
<p>If you want to get involved in Mako’s open source, you can visit <a href="https://github.com/umijs/mako">https://github.com/umijs/mako</a> and <a href="https://makojs.dev/docs/contributing">CONTRIBUTING document</a> to learn more. Anyone who has submitted Bugfix or Feature PRs can choose to join Mako’s developer DingTalk group.</p>
<p>If you plan to deeply promote and apply Mako in your company, or develop based on Mako, you can contact us (<a href="mailto:sorrycc@gmail.com">mailto:sorrycc@gmail.com</a>) for discussion. We can provide the relevant training, consulting, and more timely support services.</p>
<img src="https://img.alicdn.com/imgextra/i4/O1CN01uWRI3O1Dy7RzGO3fy_!!6000000000284-1-tps-320-224.gif" width="160">
<h2 id="live-q%26a" tabindex="-1">Live Q&amp;A <a href="#live-q%26a">
          
        </a></h2>
<p>Tonight (June 28, 2024) at 9 PM, we’ll be hosting a live Q&amp;A on Bilibili, reservation link available at <a href="https://t.bilibili.com/947260122376175622">https://t.bilibili.com/947260122376175622</a>. We welcome everyone to participate, and you can ask anything about Mako. If you have questions about Mako, you can fill in the questionnaire in advance at <a href="https://docs.qq.com/form/page/DY2Z6VndTRXBpR1Nh">https://docs.qq.com/form/page/DY2Z6VndTRXBpR1Nh</a>.</p>
<h2 id="acknowledgements" tabindex="-1">Acknowledgements <a href="#acknowledgements">
          
        </a></h2>
<p>The release of Mako would not have been possible without each contributor, especially since most of them have participated in their spare time. Thank you!</p>
<ul>
<li>Those who have submitted code to Mako: <a href="https://github.com/hedeng9">hedeng</a>, <a href="https://github.com/jiesia">jiesia</a>, <a href="https://github.com/Maple0817">Maple0817</a>, <a href="https://github.com/vagusX">vagusX</a>, <a href="https://github.com/chessl">chessl</a>, <a href="https://github.com/HiLanXiao">HiLanXiao</a>, <a href="https://github.com/JackGuiYang12">JackGuiYang12</a>, <a href="https://github.com/zhangpanweb">zhangpanweb</a>, <a href="https://github.com/ctts">ctts</a>, <a href="https://github.com/goo-yyh">goo-yyh</a>, <a href="https://github.com/whyer11">whyer11</a></li>
<li>Those who are still actively participating in the development of Mako: <a href="https://github.com/PeachScript">PeachScript</a>, <a href="https://github.com/stormslowly">stormslowly</a>, <a href="https://github.com/xusd320">xusd320</a>, <a href="https://github.com/LovePlayCode">LovePlayCode</a>, <a href="https://github.com/Jinbao1001">Jinbao1001</a>, <a href="https://github.com/sorrycc">sorrycc</a></li>
<li>Community members who used Mako in the early stages and provided suggestions: <a href="https://github.com/xiaohuoni">xiaohuoni</a>, <a href="https://github.com/xierenyuan">xierenyuan</a></li>
<li>The initiator of the project: <a href="https://github.com/afc163">afc163</a></li>
<li>Logo designer: <a href="https://github.com/golevkadesign">golevkadesign</a></li>
<li>The stylish landing page’s PD, designers, and developers: <a href="https://github.com/bupthly">bupthly</a>, 亿元, <a href="https://github.com/Wu-kung">Wu-kung</a></li>
</ul>
<p>And many authors of the community’s dependencies libraries!</p>
<ul>
<li><a href="https://github.com/webpack/webpack">webpack</a>, which inspired lots of ideas of Mako.</li>
<li><a href="https://github.com/swc-project/swc">swc</a> by <a href="https://github.com/kdy1">@kdy1</a>, which powered the parsing, transforming and code generation of Mako.</li>
<li><a href="https://github.com/farm-fe/farm">farm</a> by <a href="https://github.com/wre232114">@brightwu</a>, which inspired the tree shaking, plugin system and others of Mako.</li>
<li><a href="https://github.com/web-infra-dev/rspack">rspack</a>, which inspired the tree shaking of Mako.</li>
<li><a href="https://github.com/oxc-project/oxc-resolver">oxc-resolver</a> by <a href="https://github.com/Boshen">@Boshen</a> which powered the resolver of Mako.</li>
<li><a href="https://github.com/oxc-project/oxc/">Oxc</a> by <a href="https://github.com/Boshen">@Boshen</a> from which We learned a lot about how to develop efficiently with Rust.</li>
<li><a href="https://github.com/biomejs/biome">biome</a> by <a href="https://github.com/ematipico">@ematipico</a> from which We learned a lot about how to develop efficiently with Rust.</li>
</ul>

      
      
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Booting Linux Off of Google Drive (293 pts)]]></title>
            <link>https://ersei.net/en/blog/fuse-root</link>
            <guid>40853770</guid>
            <pubDate>Tue, 02 Jul 2024 05:20:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ersei.net/en/blog/fuse-root">https://ersei.net/en/blog/fuse-root</a>, See on <a href="https://news.ycombinator.com/item?id=40853770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><article><p>Competitiveness is a vice of mine. When I heard that a friend got Linux to <a href="https://www.kernel.org/doc/html/latest/admin-guide/nfs/nfsroot.html">boot off of NFS</a>, I had to one-up her. I had to prove that I could create something <em>harder</em>, something <em>better</em>, <em>faster</em>, <em>stronger</em>.</p><p>Like all good projects, this began with an Idea.</p><p>My mind reached out and grabbed wispy tendrils from the æther, forcing the disparate concepts to coalesce. The Mass gained weight in my hands, and a dark, swirling colour promising doom to those who gazed into it for long.</p><p>On the brink of insanity, my tattered mind unable to comprehend the twisted interplay of millennia of arcane programmer-time and the ragged screech of madness, I reached into the Mass and steeled myself to the ground lest I be pulled in, and found my <em>magnum opus</em>.</p><p>Booting Linux off of a Google Drive root.</p><h2 id="but-how">But How?<a href="#but-how" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>I wanted this to remain self-contained, so I couldn't have a second machine act as a "helper". My mind went immediately to <a href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace">FUSE</a>—a program that acts as a filesystem driver in userspace (with cooperation from the kernel).</p><p>I just had to get FUSE programs installed in the Linux kernel <a href="https://www.kernel.org/doc/html/latest/filesystems/ramfs-rootfs-initramfs.html">initramfs</a> and configure networking. How bad could it be?</p><h2 id="the-linux-boot-process">The Linux Boot Process<a href="#the-linux-boot-process" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>The Linux boot process is, technically speaking, very funny. Allow me to pretend I understand for a moment<sup id="fnref1:1"><a href="#fn:1">1</a></sup>:</p><ol><li>The firmware (BIOS/UEFI) starts up and loads the bootloader</li><li>The bootloader loads the kernel</li><li>The kernel unpacks a temporary filesystem into RAM which has the tools to mount the real filesystem</li><li>The kernel mounts the real filesystem and switches the process to the init system running on the new filesystem</li></ol><p>As strange as the third step may seem, it's very helpful! We can mount a FUSE filesystem in that step and boot normally.</p><h2 id="a-proof-of-concept">A Proof of Concept<a href="#a-proof-of-concept" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>The initramfs needs to have both network support as well as the proper FUSE binaries. Thankfully, <a href="https://github.com/dracutdevs/dracut">Dracut</a> makes it easy enough to build a custom initramfs.</p><p>I decide to build this on top of Arch Linux because it's relatively lightweight and I'm familiar with how it works, as opposed to something like Alpine.</p><pre><code><span>$</span><span> git <span>clone</span> https://github.com/dracutdevs/dracut</span>
<span>$</span><span> podman run -it --name arch -v ./dracut:/dracut docker.io/archlinux:latest bash</span></code></pre><p>In the container, I installed some packages (including the <code>linux</code> package because I need a functioning kernel), compiled <code>dracut</code> from source, and wrote a simple module script in <code>modules.d/90fuse/module-setup.sh</code>:</p><pre><code><span>#!/bin/bash</span>
<span><span>check</span></span>() {
    require_binaries fusermount fuseiso mkisofs || <span>return</span> 1
    <span>return</span> 0
}

<span><span>depends</span></span>() {
    <span>return</span> 0
}

<span><span>install</span></span>() {
    inst_multiple fusermount fuseiso mkisofs
    <span>return</span> 0
}</code></pre><p>That's it. That's all the code I had to write. Buoyed by my newfound confidence, I powered ahead, building the EFI image.</p><pre><code><span>$</span><span> ./dracut.sh --kver 6.9.6-arch1-1 \</span>
    --uefi efi_firmware/EFI/BOOT/BOOTX64.efi \
    --force -l -N --no-hostonly-cmdline \
    --modules "base bash fuse shutdown network" \
    --add-drivers "target_core_mod target_core_file e1000" \
    --kernel-cmdline "ip=dhcp rd.shell=1 console=ttyS0"
<span>$</span><span> qemu-kvm -bios ./FV/OVMF.fd -m 4G \</span>
    -drive format=raw,file=fat:rw:./efi_firmware \
    -netdev user,id=network0 -device e1000,netdev=network0 -nographic
...
...
dracut Warning: dracut: FATAL: No or empty root= argument
dracut Warning: dracut: Refusing to continue

Generating "/run/initramfs/rdsosreport.txt"
You might want to save "/run/initramfs/rdsosreport.txt" to a USB stick or /boot
after mounting them and attach it to a bug report.

To get more debug information in the report,
reboot with "rd.debug" added to the kernel command line.

Dropping to debug shell.

dracut:/#</code></pre><p><em>Hacker voice</em> I'm in. Now to enable networking and mount a test root. I have already extracted an Arch Linux root into a S3 bucket running locally, so this should be pretty easy, right? I just have to manually set up networking routes and load the drivers.</p><pre><code>dracut:/# modprobe fuse
dracut:/# modprobe e1000
dracut:/# ip link set lo up
dracut:/# ip link set eth0 up
dracut:/# dhclient eth0
dhcp: PREINIT eth0 up
dhcp: BOUND setting up eth0
dracut:/# ip route add default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15
dracut:/# s3fs -o url=http://192.168.2.209:9000 -o use_path_request_style fuse /sysroot
dracut:/# ls /sysroot
bin   dev  home  lib64  opt   root  sbin  sys  usr
boot  etc  lib   mnt    proc  run   srv   tmp  var
dracut:/# switch_root /sysroot /sbin/init
switch_root: failed to execute /lib/systemd/systemd: Input/output error
dracut:/# ls
sh: ls: command not found</code></pre><p>Honestly, I don't know what I expected. Seems like everything is just... <em>gone</em>. Alas, not even tab completion can save me. At this point, I was stuck. I had no idea what to do. I spent days just looking around, poking at the <code>switch_root</code> source code, all for naught. Until I remembered a link <a href="https://a.exozy.me/">Anthony</a> had sent me: <a href="https://unix.stackexchange.com/questions/226872/how-to-shrink-root-filesystem-without-booting-a-livecd/227318#227318">How to shrink root filesystem without booting a livecd</a>. In there, there was a command called <code>pivot_root</code> that <code>switch_root</code> seems to call internally. Let's try that out.</p><pre><code>dracut:/# logout
...
[  430.817269] ---[ end Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000100 ]---
...
dracut:/# cd /sysroot
dracut:/sysroot# mkdir oldroot
dracut:/sysroot# pivot_root . oldroot
pivot_root: failed to change root from `.' to `oldroot': Invalid argument</code></pre><p>Apparently, <code>pivot_root</code> is <a href="https://unix.stackexchange.com/a/455224">not allowed</a> to pivot roots if the root being switched is in the initramfs. Unfortunate. The Stack Exchange answer tells me to use <code>switch_root</code>, which doesn't work either. However, part of that answer sticks out to me:</p><blockquote><p>initramfs is rootfs: you can neither pivot_root rootfs, nor unmount it. Instead delete everything out of rootfs to free up the space (find -xdev / -exec rm '{}' ';'), overmount rootfs with the new root (cd /newmount; mount --move . /; chroot .), attach stdin/stdout/stderr to the new /dev/console, and exec the new init.</p></blockquote><p>Would it be possible to manually switch the root <em>without</em> a specialized system call? What if I just chroot?</p><pre><code>...
dracut:/# mount --rbind /sys /sysroot/sys
dracut:/# mount --rbind /dev /sysroot/dev
dracut:/# mount -t proc /proc /sysroot/proc
dracut:/# chroot /sysroot /sbin/init
Explicit --user argument required to run as user manager.</code></pre><p>Oh, I need to run the <code>chroot</code> command as PID 1 so Systemd can start up properly. I can actually tweak the initramfs's init script and just put my startup commands in there, and replace the <code>switch_root</code> call with <code>exec chroot /sbin/init</code>.</p><p>I put this in <code>modules.d/99base/init.sh</code> in the Dracut source after the udev rules are loaded and bypassed the <code>root</code> variable checks earlier.</p><pre><code>modprobe fuse
modprobe e1000
ip link <span>set</span> lo up
ip link <span>set</span> eth0 up
dhclient eth0
ip route add default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15
s3fs -o url=http://192.168.2.209:9000 -o use_path_request_style fuse /sysroot
mount --rbind /sys /sysroot/sys
mount --rbind /dev /sysroot/dev
mount -t proc /proc /sysroot/proc</code></pre><p>I also added <code>exec chroot /sysroot /sbin/init</code> at the end instead of the <code>switch_root</code> command.</p><p>Rebuilding the EFI image and...</p><p><img alt="A screenshot of a Linux login screen" src="https://ersei.net/user/pages/03.blog/40.fuse-root/itworks.png"></p><p>I sit there, in front of my computer, staring. It can't have been that easy, can it? Surely, this is a profane act, and the spirit of Dennis Ritchie ought't've stopped me, right?</p><p>Nobody stopped me, so I kept going.</p><p>I log in with the very secure password <code>root</code> as <code>root</code>, and it unceremoniously drops me into a shell.</p><pre><code>[root@archlinux ~]# mount
s3fs on / type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0)
...
[root@archlinux ~]#</code></pre><p>At last, Linux booted off of an S3 bucket. I was compelled to share my achievement with others—all I needed was a fetch program to include in the screenshot:</p><pre><code>[root@archlinux ~]# pacman -Sy fastfetch
:: Synchronizing package databases...
 core.db failed to download
error: failed retrieving file 'core.db' from geo.mirror.pkgbuild.com : Could not resolve host: geo.mirror.pkgbuild.com
warning: fatal error from geo.mirror.pkgbuild.com, skipping for the remainder of this transaction
error: failed retrieving file 'core.db' from mirror.rackspace.com : Could not resolve host: mirror.rackspace.com
warning: fatal error from mirror.rackspace.com, skipping for the remainder of this transaction
error: failed retrieving file 'core.db' from mirror.leaseweb.net : Could not resolve host: mirror.leaseweb.net
warning: fatal error from mirror.leaseweb.net, skipping for the remainder of this transaction
error: failed to synchronize all databases (invalid url for server)
[root@archlinux ~]#</code></pre><p>Uh, seems like DNS isn't working, and I'm missing <code>dig</code> and other debugging tools.</p><p>Wait a minute! My root filesystem is on S3! I can just mount it somewhere else with functional networking, <code>chroot</code> in, and install all my utilities!</p><p>Some debugging later, it seems like systemd-resolved doesn't want to run because it <code>Failed to connect stdout to the journal socket, ignoring: Permission denied</code>. I'm not about to try to debug systemd because it's too complicated and I'm lazy, so instead I'll just use Cloudflare's.</p><pre><code>[root@archlinux ~]# echo "nameserver 1.1.1.1" &gt; /etc/resolv.conf
[root@archlinux ~]# pacman -Sy fastfetch
:: Synchronizing package databases...
 core is up to date
 extra is up to date
...
[root@archlinux ~]# fastfetch</code></pre><p><img alt="Fastfetch showing the system running in QEMU" src="https://ersei.net/user/pages/03.blog/40.fuse-root/fastfetch.png"></p><p>I look around, making sure that nobody had tried to stop me. My window was intact, my security system had not tripped, the various canaries I had set up around the house had not been touched. I was safe to continue.</p><p>I was ready to have it run on Google Drive.</p><h2 id="google-gets-involved">Google Gets Involved<a href="#google-gets-involved" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>There's a project already that does Google Drive over FUSE for me already: <a href="https://github.com/astrada/google-drive-ocamlfuse">google-drive-ocamlfuse</a>. Thankfully, I have a Google account lying around that I haven't touched in years ready to go! I follow the instructions, accept the terms of service I didn't read, create all the oauth2 secrets, enable the APIs, install <code>google-drive-ocamlfuse</code> from the AUR into my Arch Linux VM, patch some <code>PKGBUILD</code>s (it's been a while), and lo and behold! I have mounted Google Drive! Mounting Drive and a few <em>very long</em><code>rsync</code> runs later, I have Arch Linux on Google Drive.</p><p>Just kidding, it's never that easy. Here's a non-exhausive list of problems I ran into:</p><ol><li>Symlinks to symlinks don't work (very important for stuff in <code>/usr/lib</code>)</li><li>Hardlinks don't work</li><li>It's so slowwwww</li><li>Relative symlinks don't work at all</li><li>No dangling symlinks (important for stuff that links to <code>/proc</code> and isn't mounted, or stuff that just hasn't copied over yet)</li><li>Symlinks outside of Google Drive don't work</li><li>Permissions don't work (neither do attributes)</li><li>Did I mention it's SLOW</li></ol><p>With how many problems there are with symlinks, I have half a mind to change the FUSE driver code to just create a file that ends in <code>.internalsymlink</code> to fix all of that, Google Drive compatibility be damned.</p><p>But, I have challenged myself to do this without modifying anything important (no kernel tweaking, no FUSE driver tweaking), so I'll just have to live with it and manually create the symlinks that <code>rsync</code> fails to make with a hacky <code>sed</code> command to the <code>rsync</code> error logs.</p><p>In the meantime, I added the token files generated from my laptop into the initramfs, as well as the Google Drive FUSE binary and SSL certificates, and tweaked a few settings<sup id="fnref1:2"><a href="#fn:2">2</a></sup> to make my life slighty easier.</p><pre><code>...
inst ./gdfuse-config /.gdfuse/default/config
inst ./gdfuse-state /.gdfuse/default/state
find /etc/ssl -<span>type</span> f -or -<span>type</span> l | <span>while</span> <span>read</span> file; <span>do</span> inst <span>"<span>$file</span>"</span>; <span>done</span>
find /etc/ca-certificates -<span>type</span> f -or -<span>type</span> l | <span>while</span> <span>read</span> file; <span>do</span> inst <span>"<span>$file</span>"</span>; <span>done</span>
...</code></pre><p><img alt="A screenshot of Google Drive showing the root of a typical Linux filesystem" src="https://ersei.net/user/pages/03.blog/40.fuse-root/google-drive-root.png"></p><p>It's nice to see that timestamps kinda work, at least. Now all that's left is to wait for the agonizingly slow boot!</p><pre><code>chroot: /sbin/init: File not found</code></pre><p>Perhaps they did not bother to stop me because they knew I would fail. </p><p>I know the file exists since, well, it <em>exists</em>, so why is it not found? Simple: Linux is kinda weird and if the binary you call depends on a library that's not found, then you'll get "File not found".</p><pre><code>dracut:/# ldd /sysroot/bin/bash
    linux-vdso.so.1 (0x00007e122b196000)
    libreadline.so.8 =&gt; /usr/lib/libreadline.so.8 (0x00007e122b01a000)
    libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007e122ae2e000)
    libncursesw.so.6 =&gt; /usr/lib/libncursesw.so.6 (0x00007e122adbf000)
    /lib64/ld-linux-x86-64.so.2 =&gt; /usr/lib64/ld-linux-x86-64.so.2 (0x00007e122b198000)</code></pre><p>However, these symlinks don't actually exist! Remember how earlier we noted that relative symlinks don't work? Well, that's come back to bite me. The Kernel is looking for files in <code>/sysroot</code> inside <code>/sysroot/sysroot</code>. Luckily, this is an easy enough fix: we just need to have <code>/sysroot</code> linked to <code>/sysroot/sysroot</code> without links:</p><pre><code>dracut:/# mkdir /sysroot/sysroot
dracut:/# mount --rbind /sysroot /sysroot/sysroot</code></pre><p>Now time to boot!</p><p>It took five minutes for Arch to rebuild the dynamic linker cache, another minute per systemd unit, and then, nothing. The startup halted in its tracks.</p><pre><code>[ TIME ] Timed out waiting for device /dev/ttyS0.
[DEPEND] Dependency failed for Serial Getty on ttyS0.</code></pre><p>Guess I have to increase the timeout and reboot. In <code>/etc/systemd/system/dev-ttyS0.device</code>, I put:</p><pre><code>[Unit]
Description=Serial device ttyS0
DefaultDependencies=no
Before=sysinit.target
JobTimeoutSec=infinity</code></pre><p>Luckily, it did not take infinite time to boot.</p><p><img alt="A Linux login prompt" src="https://ersei.net/user/pages/03.blog/40.fuse-root/gdrive-booted.png"></p><p>I'm so close to victory I can <em>taste</em> it! I just have to increase <em>another</em> timeout. I set <code>LOGIN_TIMEOUT</code> to <code>0</code> in <code>/etc/login.defs</code> in Google Drive, and tried logging in again.</p><p>Thankfully, there's a cache, so subsequent file reads aren't nearly as slow.</p><p><img alt="Fastfetch in Google Drive root, showing that the root partition is mounted as fuse.google-drive-ocaml" src="https://ersei.net/user/pages/03.blog/40.fuse-root/gdrive-fastfetch.png"></p><p>Here I am, laurel crown perched upon my head, my chimera of Linux and Google Drive lurching around.</p><p>But I'm not satisfied yet. Nobody had stopped me because they <em>want</em> me to succeed. I have to take this further. I need this to work on <em>real hardware</em>.</p><h2 id="now-do-it-on-real-hardwar">Now Do It On Real Hardware<a href="#now-do-it-on-real-hardwar" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>Fortunately for me, I <a href="https://ersei.net/en/blog/updates-2024-02">switched servers</a> and now have an extra laptop with no storage just lying around! A wonderful victim<sup id="fnref1:3"><a href="#fn:3">3</a></sup> for my test!</p><p>There are a few changes I'll have to make:</p><ol><li>Use the right ethernet driver and not the default <code>e1000</code></li><li>Do not use a serial display</li><li>Change the network settings to match my house's network topology</li></ol><p>All I need is the <code>r8169</code> driver for my ethernet port, and let's throw in a <a href="https://en.wikipedia.org/wiki/Power-line_communication">Powerline</a> into the mix, because it's not going to impact the performance in any way that matters, and I don't have an ethernet cord that can reach my room.</p><p>I build the unified EFI file, throw it on a USB drive under <code>/BOOT/EFI</code>, and stick it in my old server. Despite my best attempts, I couldn't figure out what the modprobe directive is for the laptop's built-in keyboard, so I just modprobed <code>hid_usb</code> and used an external keyboard to set up networking.</p><p><img alt="A screenshot of fastfetch and mount on bare metal showing that we're booted off of Google Drive" src="https://ersei.net/user/pages/03.blog/40.fuse-root/bare-metal-gdrive.png"></p><p>This is my <em>magnum opus</em>. My Great Work. This is the mark I will leave on this planet long after I am gone: The Cloud Native Computer.</p><p>Nice thing is, I can just grab the screenshot<sup id="fnref1:screenshot"><a href="#fn:screenshot">4</a></sup> from Google Drive and put it here!</p><h2 id="woe-cloud-native-computer">Woe! Cloud Native Computer Be Upon Ye<a href="#woe-cloud-native-computer" data-anchor-icon="#" aria-label="Anchor"></a></h2><p>Despite how silly this project is, there are a few less-silly uses I can think of, like booting Linux off of <a href="https://github.com/libfuse/sshfs">SSH</a>, or perhaps booting Linux off of a Git repository and tracking every change in Git using <a href="https://wiki.archlinux.org/title/Gitfs">gitfs</a>. The possibilities are endless, despite the middling usefulness.</p><p>If there is anything I know about technology, it's that moving everything to The Cloud is the current trend. As such, I am prepared to commercialize this for any company wishing to leave their unreliable hardware storage behind and move entirely to The Cloud. Please <a href="https://ersei.net/en/contact-me">request a quote</a> if you are interested in True Cloud Native Computing.</p><p>Unfortunately, I don't know what to do next with this. Maybe I should install Nix?</p><hr><p>Thoughts? Comments? Opinions? Feel free to share (relevant) ones with me! <a href="https://ersei.net/en/contact-me">Contact me here if you want.</a></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Switzerland mandates software source code disclosure for public sector (122 pts)]]></title>
            <link>https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland</link>
            <guid>40852084</guid>
            <pubDate>Mon, 01 Jul 2024 23:48:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland">https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland</a>, See on <a href="https://news.ycombinator.com/item?id=40852084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p dir="ltr">Switzerland has enacted the&nbsp;<a href="https://www.fedlex.admin.ch/eli/cc/2023/682/de">"Federal Law on the Use of Electronic Means for the Fulfilment of Governmental Tasks" (EMBAG),</a> establishing a mandatory requirement for open source software within public sector bodies. This legislative shift, championed by key figures such as Professor Dr. Matthias Stürmer, head of the Institute for Public Sector Transformation at the Bern University of Applied Sciences, signifies a paradigm shift in how governmental software development and procurement are approached.</p>
<p dir="ltr"><em>"Switzerland's new 'public money public code' law is a great opportunity for government, the IT industry and society. All stakeholders benefit from this new regulation since the public sector can reduce vendor lock-in, companies can grow their digital business solutions, and taxpayers spend less on IT solutions and receive better services due to increased competition and innovation."&nbsp; </em>Professor Dr. Matthias Stürmer</p>
<p dir="ltr">Professor Dr. Matthias Stürmer has been a pivotal advocate for this change. With a background in digital sustainability and open source community building, Stürmer has long argued for the benefits of OSS in enhancing digital transparency and reducing dependency on proprietary software. His involvement in various capacities, including his role at the Research Center for Digital Sustainability and as president of the&nbsp;<a href="https://www.ch-open.ch/en/ueber-ch-open/">open source association CH Open</a>.</p>
<p dir="ltr">The EMBAG law stipulates that all public bodies must disclose the source code of software developed by or for them, unless precluded by third-party rights or security concerns. This mandate aims to ensure greater transparency, security, and efficiency in government operations by promoting the use of OSS, which allows for public scrutiny and contribution to the software code​​.</p>
<p dir="ltr">One of the critical aspects of this law is encapsulated in Article 9, which not only mandates the disclosure of source code but also allows public bodies to offer additional services related to support, integration, or IT security, provided these services align with public tasks and are offered at a cost-covering remuneration. This provision ensures that while fostering OSS, the government can also maintain a competitive balance and avoid market distortion​​.</p>
<p dir="ltr">The journey to this legislative milestone was not without its challenges. The concept of making OSS mandatory in the public sector was initially met with resistance. Key stakeholders, including members of the Swiss Parliament and various governmental bodies, engaged in extensive debates. Concerns ranged from potential intellectual property issues to fears of compromising security. However, through persistent lobbying and advocacy, notably by the&nbsp;<a href="https://www.parldigi.ch/de/">Parliamentarian Group for Digital Sustainability (Parldigi)</a>, a consensus was reached, leading to the final compromise that forms the current EMBAG law​​.</p>
<p dir="ltr">The implementation of EMBAG is expected to serve as a model for other countries considering similar measures. The law aims to promote digital sovereignty and encourage innovation and collaboration within the public sector. As Switzerland adopts this approach, the benefits of open source software—greater security, cost efficiency, and enhanced public trust—may become more apparent.</p>
<p dir="ltr">Source:&nbsp;<a href="https://www.ti8m.com/de/blog/open-source-gesetz-schweiz">https://www.ti8m.com/de/blog/open-source-gesetz-schweiz</a>&nbsp;</p>
<p dir="ltr">Photo by <a href="https://unsplash.com/@nadine3?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Nadine Marfurt</a> on <a href="https://unsplash.com/photos/green-trees-on-mountain-under-white-clouds-during-daytime-V5XWBdjVWKA?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></p>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting the World Record in Hatetris (2022) (225 pts)]]></title>
            <link>https://hallofdreams.org/posts/hatetris/</link>
            <guid>40851919</guid>
            <pubDate>Mon, 01 Jul 2024 23:26:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hallofdreams.org/posts/hatetris/">https://hallofdreams.org/posts/hatetris/</a>, See on <a href="https://news.ycombinator.com/item?id=40851919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Previous post: <a href="https://hallofdreams.org/posts/prologue-in-hatetris/">Prologue in HATETRIS</a></em></p><h2 id="tetris-that-hates-you">Tetris That Hates You</h2><p><img data-src="/assets/img/HATETRIS/Stickman_611.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_611.png"> <em><a href="https://stickman.qntm.org/comics.php?n=611">StickManStickMan #611</a>, by Sam Hughes.</em></p><p><a href="https://qntm.org/files/hatetris/hatetris.html">HATETRIS</a> is a version of Tetris written in 2010 by programmer and sci-fi author <a href="https://twitter.com/qntm">Sam Hughes</a>. According to his <a href="https://qntm.org/hatetris">initial description of the game</a>:</p><blockquote><p>This is bad Tetris. It’s hateful Tetris. It’s Tetris according to the evil AI from “I Have No Mouth And I Must Scream”.</p></blockquote><p>(And if you aren’t familiar with Tetris at all, and don’t know the rules or pieces, we recommend <a href="https://tetris.com/play-tetris/">trying out the original game</a> for yourself; Wikipedia has an article about how <a href="https://en.wikipedia.org/wiki/Tetris_effect">Tetris in particular can consume your life and enter your very dreams</a>, but we’re sure you’ll be fine.)</p><p>The hatred comes from the way pieces are selected. In most variants of Tetris, the piece selection is pseudorandom, with methods ranging from independently random selection to the more recent Bag Random Generator. In almost every variant that isn’t truly random, the changes to randomness are done to make the player less likely to get two pieces of the same type in a row, or to go too long without seeing a given piece.</p><p>HATETRIS selects pieces in almost precisely the opposite manner, with a one-move lookahead min-max algorithm:</p><ul><li>First, check every possible position for all seven pieces.</li><li>Second, among those positions, examine how ‘good’ each of these moves is for the player, by measuring how high the highest block in the well is.</li><li>Third, select the piece which has the worst best-case scenario for the player. If there is a tie, break the tie in the piece order <code>S, Z, O, I, L, J, T</code>.</li></ul><p>There’s no randomness involved: the first, second, and third pieces you get upon starting the game will always be the <code>S</code> piece, and so will most of the others throughout the game. There’s no <code>next piece</code> window, since the next piece isn’t decided until you finish your move. There’s no possibility at all of getting four lines at once with a well-placed <code>I</code> piece, since the game will never under any circumstances give you an <code>I</code>-piece that you could use to clear four lines. And, in general, if you’ve set up to clear a line and there’s any piece at all which denies you that line for at least a turn, that’s the piece you’re going to get.</p><p>It’s a common experience for players to try the game for the first time with a strategy perfectly sound for normal Tetris and score no points at all, simply because normal Tetris strategy amounts to setting up good situations and then waiting for the odds to be in your favor. With a deterministic algorithm like this one, the odds will <em>never</em> be in your favor.</p><h2 id="high-scores">High Scores</h2><p>The flip side of determinism is predictability. Because the algorithm will always return the same move given the same history of moves, it’s possible to plan ahead and come up with complex strategies that one could never use in a non-deterministic game - and it’s possible to share results. The first few records (Mr. Hughes’ initial game of 5 points, and commenter JeremyBowers’ and Kazanir’s claims at seven points) were lost to history, but once replay functionality was added the day after release, the comment section became a leaderboard, and anyone could take an existing replay and copy the moves to try to improve on the same strategy.</p><p>Commenter Atypical posted the first replay, an eleven-point run, and over the next month, the high score was pushed to 17, 20, 22, 28, and finally 30, all using the same opening sequence of moves to create wells where every piece can be used to clear a line, four or five times in a row. This sequence of moves was so successful, in fact, that every world record run for ten years after its discovery used it. The Atypical strategy consisted of stacking<code>S</code>-pieces to the left of the well, clearing as many lines as possible, building a flat ‘ceiling’ on top of the pieces currently in the well, and then effectively starting from scratch on top of that ceiling. By the time of the 30-point runs, the Atypical strategy was so successful that it was even done a third time, near the end of the game. So far as we know, there isn’t a term for this, so we call this a <strong>pseudoloop</strong>; you’re not getting back to the same well you had before, but you’re doing the same pattern over and over again.</p><center><video width="500" height="540" controls=""> <source src="https://hallofdreams.org/assets/img/HATETRIS/2022-08-05_30_Points_Compressed.mp4" type="video/mp4"> Your browser does not support the video tag. </video></center><p>This score of 30 points, set a month after release by the Japanese Slashdot poster Deasuke, held for the next seven years. When we started playing the game in 2013, we assumed that 30 points was as high as humans would ever get, and was probably as high as the game’s mechanics would allow. But around 2017, we started tinkering a bit with machine learning, and the question naturally came up: could a program be written to beat HATETRIS? We floated around a few ideas - including what would have been a very primitive version of a Monte-Carlo tree search - but never got around to implementation, even after commenter chromeyhex eked out another point a few months later and proved that 30 was not the maximum after all. It wasn’t until June of 2021, when commenter knewjade optimized the final few moves of the existing high score to get a score of 32, and then 34 points two days later, that we decided to start coding in earnest.</p><p>And then, a week after that, knewjade got 41 points…and did so with a somewhat different opening sequence than the one which had been used and improved upon for ten years. And a week later, he pushed it to 45. The Rust emulator was working by that point and the program could play around a hundred random games per second…but that was about all it could do, and we weren’t even close to using any machine learning yet. We breathed a slow sigh of relief as weeks went by and our own project made progress with no new world records being set, until knewjade in late August of 2021 posted a high score completely unlike any game known to exist for HATETRIS, totalling 66 points.</p><center><video width="500" height="540" controls=""> <source src="https://hallofdreams.org/assets/img/HATETRIS/2022-08-05_66_Points_Compressed.mp4" type="video/mp4"> Your browser does not support the video tag. </video></center><p><a href="https://twitter.com/1millim/status/1429774558379216907">This game is beautiful.</a> Pieces set up in clearly unclearable positions turn out to be vital to clearing a line ten moves later, and it isn’t until fifteen points in that knewjade is forced to allow even a single hole higher than the first line. There are no pseudoloops - the shape of the well is constantly changing, and the well is quite frequently piled up almost to the top of the well to then clear multiple lines one after the next. By this point, <a href="https://gist.github.com/knewjade/586c9d82bd53f13afa8bcb7a65f8bd5a">knewjade had posted an explanation of the code he used to find these new high scores</a> (and this explanation will be key to our success, later), but even without the explanation, it was very clear that there was machine search involved somewhere. The game was simply too novel, discovered too quickly, and optimized too well, to have been done by a human being unaided. So it was possible for a machine to learn HATETRIS - we just had to learn how to teach it.</p><p><img data-src="/assets/img/HATETRIS/WorldRecordGraph.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/WorldRecordGraph.png"></p><h2 id="choosing-a-language">Choosing a Language</h2><p>For starting the project, our shortlist came down to three languages: Mathematica, python, and Rust. Each had various pros and cons:</p><ul><li><strong><em>Mathematica</em></strong>: Pros: huge amount of personal experience, huge number of useful built-in functions for machine learning and general analysis, easy to make visualizations or monitor in a dynamic way. Cons: slower than molasses in January.</li><li><strong><em>Python</em></strong>: Pros: Lots of good built-in machine learning APIs, like Tensorflow, Keras, and PyTorch. Faster than Mathematica. Cons: Still slower than compiled languages.</li><li><strong><em>Rust</em></strong>: Pros: Extremely fast. Cons: Not much in the way of built-in machine learning tools.</li></ul><p>Everything ultimately came down to speed; no matter what the plan, or what variant of machine learning we were going to do, we’d need vast quantities of data, and we’d need to get that data with a single mid-range desktop computer. And calculating the legal HATETRIS moves was going to take time; the initial implementation of the game in Javascript mentioned that the algorithm is “quite time-consuming to execute, so please forgive me if your browser chugs a little after locking each piece”. So, to get as many games and as much data as we could, we’d need every advantage, starting with the fastest language we personally knew.</p><p>As a point of reference, the first speed test we did was playing random games with an unoptimized emulator in Mathematica, and the same unoptimized emulator in Rust. Mathematica took 4.3 seconds per game on average, and Rust took 0.035 seconds per game on average. This was such a big difference that we deemed that all of the hassle and aggravation of negotiating with Rust’s borrow checker would be worth it.</p><h2 id="the-story-so-far">The Story So Far</h2><p>When we first started on this project, we had a very clear idea of what we thought a winning strategy would be: A Monte Carlo simulation, powered by Machine Learning! Just like they do in AlphaGo and the more generalized AlphaZero. Surely someone had already written an implementation and all <em>we</em> had to do was write an emulator, hook it up to a nebulous AlphaZero implementation and emerge with a world record. How long could it take? Two weeks?</p><h3 id="mcts">MCTS</h3><p>MCTS (Monte-Carlo Tree Search) is a well-trod path in gameplay simulations. Without getting into details, since the methodology behind MCTS is much better explained elsewhere, the core conceit is to make each move in a game into a tree-like structure and then explore the tree.</p><p><img data-src="/assets/img/HATETRIS/Chaslot_MCTS.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Chaslot_MCTS.png"> <em><a href="https://dke.maastrichtuniversity.nl/m.winands/documents/multithreadedMCTS2.pdf">Chaslot et al., 2008</a></em></p><p>Implementing a tree structure for HATETRIS positions was achievable. It was only after the initial tree implementation that we considered that there would be a <em>lot</em> of repeated wells: after all, in this game you can reach the same position in a number of different ways. A lot of deliberation and a re-factored codebase later, we opted for a <em>directed acyclic graph</em> (DAG) instead, taking identical positions and merging them into the same entry in a graph, rather than making them distinct entries on a tree. This complicated things significantly, but reduced our memory needs by an order of magnitude, at least. Refactoring from tree searches to DAG searches was more work than we’d expected to put in to the project, but was yielding promising results. An early depth first search got us scores of up to 14, with a simple greedy search looking for easy scores. At the time, the record was sitting at 34, so we felt very confident that we were on the right track.</p><p>It was sobering to realize, also, that “Graph vs Tree” in MCTS was in fact a discussion happening in professional circles. For example, <a href="https://ojs.aaai.org/index.php/ICAPS/article/view/15952/15763">this paper</a>, which we read and didn’t fully comprehend, had a very succinct explanation of how DAGs were different from trees, and why it mattered:</p><p><img data-src="/assets/img/HATETRIS/Czech_DAG.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Czech_DAG.png"></p><p>We highlight that we fully failed to understand these, because there’s two things we learned from this:</p><ul><li>Reading the academic papers is important, because sometimes experts have the same problems you do.</li><li>You don’t have to understand the whole paper (or most of the paper) to derive useful insights. Sometimes looking at the pictures is enough.</li></ul><p>By this point we had a working emulator and a directed acyclic graph, and were ready to get rolling.</p><h3 id="mcts--alphazero">MCTS + AlphaZero</h3><p>As it turns out, there is no “AlphaZero generic game engine that magically gets you world records” in Rust. There might be one in Python. Regardless, we could not just plug our MCTS to a magic library and hope for things to happen. Oh no. Instead, we had to build a monstrosity of layers using <code>tch</code>, a Rust-Pytorch-C binding library to make a model to train. The details of this are interesting, but not ultra-relevant to our world record run. We plan on writing a more detailed post-mortem after this blog where we dissect that at length. The main takeaways:</p><ul><li>Training a model took a long time, in the order of weeks.</li><li>Mutating hyperparameters to improve results was difficult with long runtimes.</li><li>We only had a few tens of thousands of games to train on, which made the learning extremely poor.</li><li>Weeks and weeks of iteration produced worse and worse models, some overtrained, others just terrible.</li><li>We were likely doing several things that would get us summarily exiled by real machine learning engineers.</li></ul><p>Now, we are going to intentionally gloss over the giant, annoying mess that was multithreading our MCTS, a tangled web of <code>mutexes</code>, <code>arc(mutexes)</code> and locking paths that we still haven’t cleaned the bugs out of. We even had to make our own branch of <code>tch</code> to support mutexing the learning network. In summary: We tried multithreading. It improved performance. But our models were… awful, taking two full months to get back to where the simple, greedy MCTS search had gotten us in a couple of days. And they showed no signs of ever improving.</p><p>As a desperate last maneuver, we looked to knewjade’s new shiny record (66, at this point in time). Using knewjade’s heuristic, we generated ten thousand more MCTS games (the best of which scored 20 points), fed them to the model, and let it cook for two weeks. The resulting model was somehow <em>worse</em> than our training data, scoring at most 17. Which meant our poor model was just never going to rise above its training data. Not with the meager resources we could provide it.</p><p>AlphaHATETRIS was officially dead.</p><h2 id="the-emulator">The Emulator</h2><p>So, with AlphaHATETRIS dead, what did we have to work with? Well for starters, we’d written a pretty darn good emulator. Our best version is still not the best version that exists, but it worked well for our needs. How does this emulator work, anyway?</p><h3 id="well-well-well">Well, Well, Well</h3><p>Some quick terminology, since we’ll be using the word “well” and “move” until they lose all meaning:</p><ul><li>A <strong>well</strong> is the <code>20 x 10</code> area in which the game is played, and any blocks currently in it. In general, when we talk about a well, you can think of it as a snapshot of a game in progress.</li><li>A <strong>piece</strong> is the four-block shape being maneuvered around in the well. When the piece cannot move down any further, it merges with the well and stops moving. This generates a new well.</li><li>A <strong>position</strong> refers to a legal placement of a piece within the well, be it terminal or not.</li><li>A <strong>terminal position</strong> is a piece that has reached a position where it can no longer descend, that is, it is going to become part of the well, exactly where it is. It’s terminal because once this piece is placed, we have created a new well.</li><li>A <strong>move</strong> is a placement of a piece within a well, such that it is terminal, and generates a new well. We do not consider non-terminal motion inside the well to be a ‘move’.</li></ul><p><img data-src="/assets/img/HATETRIS/basic_movement.png" width="800" src="https://hallofdreams.org/assets/img/HATETRIS/basic_movement.png"> <em>(Left: A piece, in blue, at the beginning of its move. Center: a piece at the end of its move, in a terminal position. Right: a piece, in blue, at the beginning of the next move. The previous piece has merged with the rest of the well, indicated by the grey squares.)</em></p><h3 id="basic-state-management">Basic State Management</h3><p>Our first draft was the obvious approach, considering every possible position by every possible piece, and repeating until there are no new positions left.</p><p>Move generation in this context, refers to only generating the moves for a specific well. That is, each time you get a piece, what are the places the piece could go?</p><p>Our initial version of the emulator took a well, and considered all the possible positions for the piece inside the well:</p><ul><li>First, take the initial position, and calculate the positions that could result from going left, right, up or down.</li><li>Continue calculating the left, right, up, and down motions for each new position you encounter, and remove any illegal positions which intersect a filled square, or go outside the well. Merge any duplicate positions together.</li><li>When there are no more new positions, check to see which positions aren’t illegal, but which can’t go down. This gives you the possible terminal positions for the piece: the place where the piece can rest and merge with the well.</li><li>Repeat for all seven pieces.</li><li>When you’re done, determine which piece the HATETRIS algorithm would give you, pick from that piece’s terminal positions, and with this new well, start again from step 1.</li></ul><p>It’s a pretty straightforward approach to dealing with wells, and it was fast. It could get the moves for an empty well in 1.1 ms, which was very good compared to Mathematica’s 330 ms with the same algorithm, but we knew we could do better. And we would have to, since we needed several hundred million games to train our machine learning algorithm.</p><p>The first improvement we made was to cut out considering positions that would only traverse empty space. That is, in a well where the first row is filled, but no others, only really consider the space in lines 2-5.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/PotentialMovementsCombined.gif" alt=""> <em>Left: Considering all possible positions. Right: Considering only the positions in the non-empty part of the well.</em></p><p>The next logical improvement was to pre-generate the state graph. That is, instead of starting with the piece in the middle and generating positions for a left arrow, a right arrow, an up and a down, we pre-computed and cached <em>all</em> these states in the “blank” space above occupied rows, which meant we saved significant time trying to compute all these positions, at the expense of having to have a pretty large pre-cached data structure. Fortunately there are only a few thousand starting positions for pieces, which we generated programmatically. It wound up being exactly 2457 positions between all 7 pieces.</p><p><a href="#flamegraphs--attack-of-the-clones">In analyzing the performance of move detection</a>, we discovered that the majority of our time was now spent accessing the hash of positions, since whenever a new positions was explored, we had to check if it already existed. A bit of a further dig and we discovered that most of that time was spent running a hashing algorithm on the positions data for comparison. Which again, made sense…but we knew all our positions were unique among each other. We didn’t <em>need</em> to do any hashing, we could just use the position’s representation as a key directly, if we could find a reasonable way to encode it. So we replaced the hashing algorithm with our own custom version that encoded the position as a binary representation of position, rotation and piece type. This was much faster than having to hash a position, and we knew it guaranteed uniqueness. This <em>doubled</em> the speed of our move finder.</p><p>At this point, we had a speed of 300 <strong>microseconds</strong> per core. That’s a ~350% speedup over our initial speed in Rust and a 10,000% speedup over our initial speed in Mathematica. We were confident we’d optimized as much as we possibly could…and still, it wasn’t nearly fast enough. We needed something faster, since all our flamegraphs clearly showed that move calculation was a giant bottleneck in performance. So, we had to pivot.</p><h3 id="gpu-matrix-operations">GPU Matrix Operations</h3><p>The first idea we came up with was, fitting the theme of this project, a vague notion based on what we had read computers should be able to do. We could just do some matrix math in a GPU!</p><p>Our plan was to calculate the legal moves via matrix operations, and speed up those matrix operations dramatically by running them on the GPU. The idea is simple enough: there are a finite number of positions a piece can be in. So, we start with a vector <code>v</code> representing the starting position of a piece, and a matrix <code>M</code> representing all the ways a piece can move from one position to another. The vector <code>v*M</code> (the vector which is the product of multiplying <code>v</code> by <code>M</code>) will then be the vector consisting of all possible positions a piece can be in after one step. <code>v*M²</code> will be the vector consisting of all possible positions a piece can be in after two steps. Do this multiplication <code>n</code> times, and you get <code>v*M^n</code>, a vector consisting of all possible positions a piece can be in after <code>n</code> steps. Eventually, <code>v</code> will stop having new nonzero elements, and then, you’re done - the nonzero elements of <code>v</code> are the positions that the piece can reach in the given well.</p><pre><code>vCurrent = startingState
vReachable = vCurrent

while max(vCurrent) &gt; 0:
    vIntermediate = sign(v1.transitionMatrix)
    vCurrent = vIntermediate &amp; ~vReachable
    vReachable |= vIntermediate

return vReachable
</code></pre><p>There were various improvements and refinements we did with this idea. Instead of using multiplication, we used Boolean logic operators to keep all the numbers either 0 or 1; instead of a full matrix, we had four vectors representing left, right, down, and rotation movements. The math worked, and gave a modest tenfold speedup when tested in Mathematica, but we estimated that in Rust the speedup would be negligible, due to the large number of redundant operations the CPU would have to do. However, GPUs are specifically designed for a large number of simple redundant operations. If we could calculate the legal moves on a GPU, it might provide a substantial speedup.</p><pre><code>vCurrent = startingState
vReachable = vCurrent

while max(vCurrent) &gt; 0:
    vIntermediate = permute(vCurrent, leftPermutation)
    vIntermediate |= permute(vCurrent, rightPermutation)
    vIntermediate |= permute(vCurrent, upPermutation)
    vIntermediate |= permute(vCurrent, downPermutation)
    vIntermediate &amp;= vEmpty
    vCurrent = vIntermediate &amp; ~vReachable
    vReachable |= vIntermediate

return vReachable
</code></pre><p>This required us to get comfortable with difficult topics: writing code to be executed in the GPU via CUDA C and cross-compiling C code so it could run on the GPU. We’ll save the excruciating details of how that worked for the longer post, merely pointing out here that:</p><ul><li>It can be done.</li><li>Make sure you’re writing CUDA C and not C++ or plain C.</li><li>The linker is going to hate you, its not personal, you’ll just have to keep adjusting flags until it works.</li></ul><p>In the end, we decided not to go this route, since we came up with another emulator improvement which would provide roughly the same speedup without having to deal with the GPU, which to be honest, had proven quite daunting.</p><h3 id="let-me-count-the-waves">Let Me Count The Waves</h3><p>Our final approach begun by thinking of the problem differently:</p><p>First we considered this: given a specific height, there is a finite set of possible positions that fit within that height. (for example, the height 1-4). These positions are not independent of each other. That is to say, if one piece position is blocked due to a filled square, some other piece positions will be blocked as well. For a given four-line area in the grid, there is a limited subset of potential positions for a piece, considering all rotations and positions within that space. In fact, for every piece except the <code>O</code> piece, there are 34 possible positions (including rotations) in a <code>4 x 10</code> area.</p><p>A ‘wave’ can be represented as a binary number that is 34 bits, corresponding to the 34 potential positions available to a piece. The binary represents if the position is reachable for the given piece or not. That is to say, if a position is empty and reachable, the corresponding digit in the wave is 1, and if it isn’t, the corresponding digit is 0.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/waveform.gif" alt=""></p><p>You also have a surface. A surface is the reachable part of a well: That is, any point which has a clear path to the empty top of the well.</p><p><img data-src="/assets/img/HATETRIS/well-surface.png" width="500" src="https://hallofdreams.org/assets/img/HATETRIS/well-surface.png"></p><p>The key is that a wave and a four-line slice of a surface, together, form a unique transition: the same wave plus the same slice of a surface will always produce the same new wave one line further down. As a result, the number of possible waves and surfaces is finite, and as we calculate moves, we can store the wave-surface transitions that we encounter in a cache, and the next time we encounter that transition, simply look it up from the cache again, rather than calculating the positions from scratch.</p><p>The final result of all this? From an original time of 330 milliseconds per move on Mathematica, to 1.1 milliseconds per move per core in Rust, to an optimized state-based emulator time of 300 microseconds per move per core, we were now down to 48 microseconds per move per core, on average. And, more importantly, finding the positions that a given piece could reach in a given well was no longer the bottleneck; any further optimization would have to be elsewhere.</p><p>But why? AlphaHATETRIS was dead, and machine learning wasn’t going to get us there. But the most recent world record holder had some answers for us.</p><p><img data-src="/assets/img/HATETRIS/Stickman_017.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_017.png"> <em><a href="https://stickman.qntm.org/comics.php?n=17">StickManStickMan #17</a>, by Sam Hughes.</em></p><h2 id="the-era-of-knewjade">The Era of Knewjade</h2><h3 id="the-knewjade-heuristic">The Knewjade Heuristic</h3><p>We’ve talked a lot in the past few minutes about knewjade (<a href="https://twitter.com/1millim?lang=en">Twitter</a> / <a href="https://github.com/knewjade">GitHub</a>). His heuristic. His beam searches. That’s because his work redefined how we were thinking about and approaching the problem. If nothing else, we were sure we could improve upon what he had done. To understand what we did then, it is important to understand what knewjade did to get 66 points, the highest score ever achieved at that point. More than twice what we had once considered an unbeatable 31.</p><p>Fortunately, knewjade had published his work, <a href="https://gist.github.com/knewjade/586c9d82bd53f13afa8bcb7a65f8bd5a">here</a>. While we don’t speak Japanese, Google Translate and staring at pictures helped us understand what was going on.</p><p>The knewjade approach is also known as a ‘heuristic beam search’. What does that mean? A ‘beam search’ means that you take some number of positions, get all of their children, keep the best ones, and then repeat the process until you run out of positions. For instance, if you had a beam search with a width of twenty-five million, then at every step, you take the best twenty-five million children from all of your existing wells, and use them as your wells for the next step. The ‘heuristic’ part is how you sort the children from best to worst in order to keep the best twenty-five million of them.</p><p>Fundamentally, the knewjade heuristic is a weighted sum of a few different factors. First, holes (empty squares with at least one full square above), and enclosed holes (empty squares with no path reaching to the surface). Holes and enclosed holes are bad. It makes sense that enclosed holes would be problematic: you must clear lines to get to them, and as we know, clearing lines in HATETRIS is no mean feat. Non-enclosed holes are a little more difficult to reason about, but without getting too technical, the layout of a hole can make it impossible or at least extremely challenging to clear, contributing height to the well, without giving an easy means of clearing lines.</p><p><img data-src="/assets/img/HATETRIS/enclosed-holes-knewjade.png" width="400" src="https://hallofdreams.org/assets/img/HATETRIS/enclosed-holes-knewjade.png"> <em>(In red: holes. In teal: enclosed holes.)</em></p><p>Second, the number of lines containing enclosed holes. We’ve already covered that enclosed holes are bad for clearing lines, but not all enclosed holes are created equal. A line with more than one enclosed hole is about as bad as a line with any number of enclosed holes, since you will have to clear all the lines above it regardless of how many holes there are. Thus, we care more about how many <em>lines</em> have enclosed holes, than the number of overall enclosed holes. As an example, the two left wells in the picture below would score quite differently: the one on the top is much more “clearable” than the one on the bottom, since you only have to clear one line in order to be able to access the enclosed holes instead of three.</p><p><img data-src="/assets/img/HATETRIS/knewjade-enclosed-lines.png" width="700" src="https://hallofdreams.org/assets/img/HATETRIS/knewjade-enclosed-lines.png"> <em>(Left: two wells with two enclosed holes each; the bottom left well is clearly harder to clear than the top left well. Right, lines containing at least one enclosed hole.)</em></p><p>Third, the erasability. How many different pieces can be used to erase a line in this well? The easier it is to erase a line, the easier it is to score. Erasability is good. This well happens to have a very high erasability score, since any piece can clear a line. To demonstrate:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/gif-of-clearability.gif" alt=""> <em>(A well which can clear all seven pieces)</em></p><p>And fourth, the score. A higher score is good. After all, we want world records. No matter how nice we make a well, all that matters is the score when we inevitably lose.</p><p>Each of these factors was given a weight, which knewjade generated with a <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">real-valued genetic algorithm</a>, and the resulting sum was the heuristic: an algorithm to evaluate any well, the higher the heuristic, the better the move.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/optimized-heuristic-gif.gif" alt=""></p><p>Knewjade had several improvements on this basic concept. One improvement was realizing that, since the surface of a well can almost never move down once it’s moved up, it doesn’t matter how many holes or enclosed holes there are below the surface. All that needs to be considered is the part of the well above the lowest line of the surface. A recap: a surface is the “reachable” part of the well, that is any area that can still be reached from the top.</p><p><img data-src="/assets/img/HATETRIS/knewjade-ignore.png" width="400" src="https://hallofdreams.org/assets/img/HATETRIS/knewjade-ignore.png"></p><p>However, there is in general one exception to the ‘surfaces can never move down’ rule: when a line at the bottom of the surface can be cleared with an <code>S</code> or <code>Z</code> piece. So, knewjade’s heuristic doesn’t count holes or enclosed holes if an <code>S</code> or <code>Z</code> piece can free them.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/knewjade-s-lowers.gif" alt=""></p><p>Knewjade’s approach is brilliant, interesting, and innovative, and we were confident we could copy it.</p><h3 id="following-footsteps">Following Footsteps</h3><p>So, all we had to do was implement this on our own. And as it turns out, implementing this on our own had a whole host of problems. Our calculation of the surface height took a huge amount of time, and at first, before we discovered waveforms, our emulator was extremely slow, and so calculating the erasability of a given well by calculating all of the legal moves possible for that well was extremely time-consuming. For a while, we thought we could get by without the erasability, and this was a mistake: without the erasability, we could only get a score of 41. Our personal record, for sure, but hardly 66 points.</p><p>So, we implemented erasability - but the slowdown was still a huge problem, so we made a second and much larger mistake: we took a shortcut. Rather than computing the erasability for <code>S</code>, <code>Z</code>, <code>O</code>, <code>I</code>, <code>L</code>, <code>J</code>, and <code>T</code>, every single time, we checked if <code>S</code> could be cleared, and <em>only</em> if it could be cleared checked for <code>Z</code>, and then only if <code>Z</code> could be cleared checked for <code>O</code>, and so forth. This sped up the heuristic evaluation significantly (many positions can’t be cleared by all seven pieces), but even when we improved the emulator and no longer had to worry as much about speed, we kept this shortcut in the code. And the problem with that is simple to state: if you’re setting up a well so that you can clear a line, you need to be able to clear that line with all seven pieces, and it does not matter what order you set this up in. We were throwing out perfectly good setups because the setups weren’t in our arbitrary order, and <em>we had completely forgotten that this assumption was bad</em>.</p><p>We describe this as a critical mistake, even though it only takes a few sentences to describe, and only one line of code to fix, because it was by far our most time-consuming error, more than any of the tedious debugging for the GPU or multithreading sections. We lost roughly three months due to this, after all was said and done. Knewjade’s beam search had a width of 25 million, and though he could run his in two or three days, we did not have the waveform-based emulator yet, and so our beam search would take three weeks to run. And, with no way of knowing ahead of time how well a given set of heuristic parameters would scale, that’s precisely what we did. Twice. We also had to get the parameters in the first place to test out, which (as we’ll discuss below) also took weeks, and in general we wasted a lot of time looking to improve the wrong parts of the code and not realizing that it was erasability that was limiting us.</p><p>Perhaps it’s unfair to blame this one mistake for months of wasted time, because even after we fixed the mistake, our implementation of knewjade’s heuristic was not as good as the original. We know this because knewjade was kind enough to send us his original parameters, and when we ran those parameters - in theory, using exactly the same heuristic he did - the beam search returned a score of 53, instead of the 66 he got. We still don’t know why it was that our heuristic did worse, or what the difference between his implementation and ours was. But by then, we’d come up with an additional term of our own, one which would make replicating the world record of 66 a moot point.</p><h2 id="mumble-mumble-graph-theory"><em>Mumble Mumble</em> Graph Theory</h2><p>For some months, we’d had a very interesting idea. The idea consisted of the words “graph theory”, which we’d occasionally gravely recite to each other and nod knowingly, with some vague gesticulations, and not much else. Much to our surprise, this turned out to be a workable strategy. Kind of.</p><p>While writing and making the visuals for this section, we actually discovered that the graph theory heuristic made no difference at all when used on a sufficiently wide beam search, and that we would have gotten 86 points with or without it. This was in large part because the games we mined for data weren’t representative of the kinds of moves that end up setting world records, and because we didn’t mine enough games to have good sampling rates. However, we include this section anyway, since we suspect that a properly implemented version could be a significant improvement; this heuristic by itself gets 38 points on a 25 million beam search, so setting what would have been the world record before 2021 means that there’s <em>something</em> worthwhile going on.</p><p>John Brzutowski, in his <a href="https://open.library.ubc.ca/media/stream/pdf/831/1.0079748/1">1988 master’s thesis</a>, proved that for a specific sequence of <code>S</code> and <code>Z</code> pieces, it was impossible to win the game of Tetris, and in the process got the ball rolling on making evil versions of Tetris, since it was now a fact that Tetris could, in theory, be so difficult as to be unwinnable. Part of his analysis was looking at the life cycle of “flats” - the creatures occupying individual lines in a Tetris well. These ‘flats’ are composed of blocks and empty spaces, and one could track an individual ‘flat’ from birth when it is nothing more than an empty line in the well) all the way until death (when it is completely filled, and the line goes away).</p><p><img data-src="/assets/img/HATETRIS/FlatLifeCycle.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/FlatLifeCycle.png"></p><p>Brzutowski’s insight was that these ‘flats’ had a very limited number of behaviors each turn. On a given turn, a ‘flat’ can:</p><ul><li>Be born</li><li>Remain exactly the same.</li><li>Fall down a line if there was a cleared line below.</li><li>Grow (gain more full blocks in its line).</li><li>Die (become completely full, and vanish).</li></ul><p>So, we can take a full game, and tag each individual flat in the game, watching it as it moves through its life cycle from birth to death - or, move through its life cycle and then stop, permanently. Because, in a game of Tetris that ends, a given flat will at some point either die (get cleared) or reach a point where it never grows, falls down, or changes ever again. The key insight we had was that some line shapes are more likely to die and get cleared than others, and that graph theory could measure and predict this tendency. Essentially there are “good” lines that clear well, and “bad” lines that are really difficult to clear.</p><p>In a perfect world where we were furnished with $50,000 a day in AWS credits, we could thoroughly investigate these behaviors over four lines, but with commercial hardware, we could really only focus on one-line transitions. But how do you figure out what makes a line better than its competitors? The answer is where graph theory comes in:</p><p><img data-src="/assets/img/HATETRIS/LineTransitions.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/LineTransitions.png"></p><p>We have in this image a complete set of all transitions for all lines (of width 4; the width 10 transition graph was too big to properly visualize, and even this is pushing it). And, with the data from the tens of thousands of MCTS games we had, it was possible to get a frequency for every transition in this graph, ranging from “vanishingly rare” to “happens almost every game”. There is one starting point – the empty line – and two ending points, not shown in this graph: a flat dying to clear a line, or a flat becoming immortal and never changing again. We could model this.</p><p>Model it how? The <a href="https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm">Ford-Fulkerson method</a>. Imagine the empty well as a source of water, and the two possible end states are buckets. The “water” that travels through the graph all winds up either in a “immortal” bucket or a “cleared” bucket. The frequency of the transitions in the graph, then, represents how ‘wide’ the channel is. Any flat <em>can</em> eventually be cleared, and any flat <em>can</em> become immortal, but if you have a pipe a foot wide towards one bucket and a drinking straw towards the other bucket, the amount of water in each bucket at the end will be different. What we want is to rank how good different flats are based on how much of the ‘water’ flowing through them eventually goes towards the bucket labeled ‘cleared’. This is what Ford-Fulkerson does (in broad strokes, it doesn’t actually model water), and with Mathematica’s implementation of it, we had <strong>clearability</strong>, the first part of our graph theory heuristic.</p><p>The second part was based on similar reasoning. Imagine you have what is frequently an incredible flat when it’s at the top, but the flat is now buried so deep below the surface of the well that no piece will ever reach it. No matter how easy that flat might be to clear in theory, in practice, it’ll never happen. So, we added a second component to the heuristic, <strong>permeability</strong>. We went through the tens of thousands of MCTS games again and made a second graph, this time detailing which pairs of lines had pieces go from the upper to the lower, and which didn’t.</p><p><img data-src="/assets/img/HATETRIS/Permeability.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Permeability.png"> <em>(Left: a well which would have a high permeability score. Right: a well which would have a low permeability score.)</em></p><p>So, the graph theory heuristic was the sum of a pair of terms. At each line, the odds that the line would ever eventually be cleared was multiplied by the odds that a piece could get down far enough to get to that line to clear it, with the empty line being by definition the most clearable of all. The higher this heuristic, the better.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/gif-graph.gif" alt=""></p><h2 id="putting-it-together">Putting It Together</h2><p>What we didn’t explicitly say yet, is that these two approaches can be combined. In a very direct way, the knewjade heuristic assesses the quality of a particular well, looking at its shape, considering the piece, and generally calculating its “quality”. The graph theory heuristic, on the other hand, considers only specific lines two at a time, without any broader context of well shape. This joint approach, combining shape and line, gives a more nuanced assessment of the state of the well.</p><p>What we suspected (though it’s not something we could formally prove) is that the two pieces should balance each other out. The knewjade heuristic looks at the aggregate shapes in a well – the holes and enclosed holes, the height of the surface – but does so in a general way, with no way of (for instance) determining that this hole is less bad than that one. The graph theory heuristic is quite precise, with thousands of parameters determined from millions of positions, but only considers lines in isolation, or lines in neighboring pairs, with no ability to look at the broader context of the well. Together, ideally, they balance out each other’s weaknesses, and can find better games than either could individually.</p><p>(And as mentioned before, on a large enough scale, none of this matters; the additional effect of the graph theory heuristic term drops to zero as the beam search gets wider, and when doing a full 25 million width beam search, it does not matter if the graph theory term is there or not. But that’s not something we’d learn until many months later, and something that might be fixed by improving the data backing our graph theory approach.)</p><h3 id="parameter-optimization">Parameter Optimization</h3><p>So, with the two parts of the heuristic – knewjade’s, and ours – we were ready to go, and all we needed to know were the weights. By how much should a hole be penalized? By how much should a clearable line be rewarded? How important is score? This last question was especially difficult to answer with just intuition; on one hand, weighting score extremely highly means that the beam search will be very greedy and potentially miss better strategies that take more moves to set up, but <em>not</em> weighting scores highly leads to the algorithm putting off scoring indefinitely, always figuring “Eh, scoring would take away this nice clearable line I found!”. We needed some empirical method to figure out what all these weights should be.</p><p>What we found was a Rust library called <a href="https://github.com/nestordemeure/Simplers"><code>Simple(x)</code> Global Optimization</a>, a simpler version of the more well known <a href="https://en.wikipedia.org/wiki/Bayesian_optimization">Bayesian Optimization</a> method. This method, like all optimization methods, takes a set of variables (in our case the weights for the heuristic) and a function of that set of variables (in our case, the number of moves a beam search with those weights ran for), and attempts to find the combination of variables that results in the highest value of the function. The upside was that we didn’t have to use any intuition about which weight was more important than which other weight, because <code>Simple(x)</code> could do it all for us. The downside was that this optimization required hundreds of beam searches before we could be reasonably sure we’d tried a broad enough variety.</p><p>So, hundreds of beam searches is precisely what we did. With a beam width of 250,000, each search took somewhere between forty-five minutes to two hours, and we let this run for well over a week. Then, after the two failed 25 million width beam searches, and after we discovered <a href="#following-footsteps">the bug</a>, we did the same thing again. By the end, our 250,000 width beam searches had returned a cluster of parameter combinations which lasted for 46 points and 148 moves…and one lone parameter combination which lasted for 46 points and 147 moves, surrounded by very similar combinations of parameters which did much worse.</p><p>One of the failed 25 million beam searches had been stuck in a local maximum - the parameters had stumbled upon a game that was <em>good</em>, but that was very difficult to improve upon, like climbing to the top of K2 when you’re trying to climb to the top of Mount Everest. As such, we decided not to go for the cluster that lasted 148 moves, but go for the lone combination that lasted 147, on the hopes of not getting stuck in a local maximum once again.</p><p>And we should make explicit here that ‘hopes’ is what we were running on. We simply didn’t and don’t have the hardware to do many ultra-wide beam searches, and the optimum parameters probably change when you enlarge the width by two orders of magnitude. We both doubt very much that this set of parameters is the best possible. All we know is that it scaled up better than any other set of parameters we’d ever used.</p><div><table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>Holes</td><td>11.2106</td></tr><tr><td>Enclosed Holes</td><td>83.7646</td></tr><tr><td>Enclosed Hole Lines</td><td>83.7646</td></tr><tr><td>Surface Height</td><td>-83.7646</td></tr><tr><td>Erasability</td><td>-83.7646 (per piece)</td></tr><tr><td>Graph Heuristic</td><td>-2.1413</td></tr><tr><td>Score</td><td>-332.2211</td></tr></tbody></table></div><p>(The graph heuristic weight is included for completeness’ sake; do not try that one at home.)</p><h2 id="the-final-run">The Final Run</h2><p>It’s worth talking about what exactly we were using to run these beam searches and machine learning models and various other wild ideas, since to us it felt like every paper we read involved spending tens of thousands of dollars at your local cloud provider. We did <em>not</em> have tens of thousands of dollars to spend. We had about $150 on Azure credits, a machine we’d built a while ago with a slightly modern GPU, an i7 CPU, 16gb of RAM and a motherboard so old it wouldn’t accept any more RAM, and a couple laptops we were using for other things, and occasionally running long simulations on. No more than maybe $2,000 in hardware, being generous and counting the laptops.</p><p>Every few weeks as we’d work on the project, we’d read something about how AlphaZero was able to play 44 million games in nine hours and then run them all through neural network training powered by a fleet of thousands of TPUs, sigh wistfully, and look at our machine learning model, which needed another two weeks to finish training on a measly 10k games. Still, by the time we were running 25 million beam searches at the end it wasn’t <em>awful</em>; a beam search would take roughly four days, a vast improvement over the original 6 week runtime (the original beam searches took 3 weeks, but returned games half as long, so would have taken 6 with the better parameters). An agonizing four days, only to get scores like 53, which had once been impressive but were not exactly the world record. Finally, with our best heuristic ready, and all the graph theory <em>mumble mumble</em> was wired up, we decided we’d do it. We’d use a magical cloud machine and be done in a few hours.</p><p>We settled on a <code>c5d.18xlarge</code> instance on AWS for $3.50 an hour. The main draw was the 1800 GB SSD and the 72 available cores. With multithreading and some rough back of the napkin math it was slated to take 7 hours. A mere $24.50 for being done. And to be clear, this was our last hurrah. We were considering other ideas, but we knew this was our best shot and that if this failed, we’d likely lack the morale to go back to the drawing board and try again.</p><p>Things conspired to delay us. COVID. A stolen credit card. Random real life interrupts. Finally, the Friday of Memorial Day, we spun up the 72 core instance. We’d originally planned on running a few trials on a cheaper 16 core instance… but we opted to skip them. After all, we reasoned, if things would finish in 7 hours, we could reassess after that and see what needed to be changed. We installed Rust, copied files over, set up ssh keys… and then hit run. We’d be well within our budget, $24 being less than the $100 or so we’d budgeted for cloud computing.</p><p>An astute reader will probably guess that we did not leave and come back 7 hours later to a world record. Partially because we sat there, glued to the screen, watching games play out, and partially because something had gone terribly wrong. You see, it turns out our back of the napkin math hadn’t accounted for one thing: file reads and writes. Adding more cores made the threaded processes faster, but now the bottleneck was how quickly we could get in and out of the hard drive. And it was not encouragingly fast. 7 hours later we had achieved a score of 10 points at depth 33. Some more quick back of the napkin math suggested we needed probably another 150 moves in order to tie the world record, so another 35ish hours. 42 times $3.50 was only 147 dollars. Still within our mental budget of “no more than $200 of cloud computing”.</p><p>Over the next few hours we watched the score inch up, and the depth increase. Never getting as fast as we’d like. It was like watching water slowly, ever so slowly drip into a well, not knowing if it would ever tip over. 10. 25. 35. We still didn’t know if our heuristic could even generate a world record. Watching the score tick up and the cost do the same.</p><p>Us being us, we had no patience. Instead of watching it tick agonizingly forward, at around the 48 hour mark, when we were starting to see scores of around 63, we decided we’d cheat - we’d take one well, printed out with the output logs, and run a small 10k beam search on a laptop in order to get a lower bound for how good a game was possible. Like opening presents on Christmas Eve rather than Christmas morning, this did spoil a bit of the dramatic tension - but it also confirmed that we would, at bare minimum, get a score of 71 points, and that we would for a fact get the world record. Somehow this made the remaining ten hours of waiting worse, not better. At the 56 hour mark it finished. We’d done it. We’d discovered a 86 point game was possible, and we were only $196 in the hole. Considering the key-frame generation still had to run to give us the moves that the game had played, we might not even exceed our $250 cloud computing budget.</p><p><img data-src="/assets/img/HATETRIS/Stickman_021.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_021.png"> <em><a href="https://stickman.qntm.org/comics.php?n=21">StickManStickMan #21</a>, by Sam Hughes.</em></p><p>Key-frame generation? Didn’t we already have a winning game? Well, yes and no. We’d had the moves needed to play the winning game, but we also had billions of other moves that did <em>not</em> lead to the winning game. ‘Key-frame generation’ is how we reverse-engineer a game from a beam search. At each timestep, the beam search saves the top N wells (in this case, 25 million), and stores them all to disk. At the end, we take a well from the last available timestep, go through all of the wells in the previous timestep, and calculate all of their children (though we’ve since <a href="#reversing-the-polarity">figured out a better way</a>). When a well from the previous timestep has, as one of its children, the well we’re looking for, we stop, save that well, and go back another timestep to repeat the process. The process of finding each well reminded us a bit of rendering an animation by generating keyframes, hence the name.</p><p>An obvious question here: why didn’t we store the children of each well on disk, so that we wouldn’t have to recalculate the children again? The first answer is that the complete beam search already takes 225 GB of space, and storing the children would far exceed the available space on both the RAM and hard drive. The second answer is that, by the end, the emulator was fast enough that the extra time taken to read the data from disk would have been more than the time taken to recalculate the children.</p><p>56 hours in, we had a gorgeous score of 86, assuming there were no bugs in our emulator (an idea which at the time seemed dangerously possible), and all that was left was to wait for the fairly quick process of keyframe generation to finish. It was midnight, and we asked the fateful question “how long can it actually take? An hour?”. This didn’t seem unreasonable, since keyframe generation was usually by far the fastest part of the process. But, as before, we had not considered the issues of scale. The sheer amount of disk reads and the massive depth we’d reached meant that the 72 cores didn’t speed things up at all, since 90% of the time was spent on the single-core operation of reading the timestep files from disk. Some quick math showed that it was going to take us another 12 hours to finish the process. Another 42 dollars and more agonizing waiting. With nothing to be done about it, we went to bed, vowing to wake up in the morning and input the game.</p><p>We cannot emphasize enough the sheer frustration at waking up the next day, and seeing it still merrily chugging along, slowly, ever so slowly; the back of the envelope math we’d done had been based on reading files from the end of the search, which were much smaller and faster to read than the files in the bulk of the game. 68 hours in, and the accursed keyframe generator was still only gradually moving forward. Neither of us got to enjoy that Sunday at all, watching it inch forward, bit by bit. Tantalizingly close.</p><p><img data-src="/assets/img/HATETRIS/Stickman_019.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_019.png"> <em><a href="https://stickman.qntm.org/comics.php?n=19">StickManStickMan #19</a>, by Sam Hughes.</em></p><p>Finally, late that afternoon, it finished. We hopped on a voice call, and put the game in to the online Javascript HATETRIS game, move by move, wondering at each moment if <em>this</em> is where we’d discover a key emulator bug or bad edge case to make all our efforts be for naught. But as the well piled tall on either side, and we fumbled flips here and there, one thing became clear. It was real. The world record was ours. <a href="https://qntm.org/hatetris#komment6293f5024978c">86 points</a>.</p><center><video width="500" height="540" controls=""> <source src="https://hallofdreams.org/assets/img/HATETRIS/2022-08-05_86_Points_Compressed.mp4" type="video/mp4"> Your browser does not support the video tag. </video></center><p>We breathed a sigh of relief. It was done. It was finished. Countless hours of engineering time. Endless runs on our machines, 100 dollars over what we’d originally planned to spend on AWS. (It turned out to be $140 over after data transfer costs and such), but it was done.</p><p><img data-src="/assets/img/HATETRIS/HATETRIS_PRs.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/HATETRIS_PRs.png"></p><h2 id="lessons-learned">Lessons Learned</h2><p>Up until now, this has been something of a narrative. There’s been a plot, there’s been progress, there’s been a clear (if non-monotonic) improvement from A to B to C. But there’s more stuff we learned, and dead ends we went down, that don’t really fit the story. We’ve captured them here for two reasons. One, we think these are valuable lessons that anyone who dives into this type of problem can benefit from. Two: we did a <em>lot</em> of work, much of which was only tangentially related to getting the world record, and while we’ll save most of that for a future blog post, we want to show some of it off now. These headings will only be loosely coupled, and while we think there’s a few related conclusions, we leave grand sweeping paradigms as an exercise for the reader.</p><h3 id="flamegraphs--attack-of-the-clones">Flamegraphs &amp; Attack of the Clones</h3><p>One lesson that came up over and over again throughout this project is that profiling is <em>very</em> important, because we as developers are bad at estimating which parts of code are bottlenecks and which aren’t. In one of the earliest iterations of the emulator, we had an error-handling exception which would format and print a string with state information in the event of a panic, to make debugging easier. We quickly fixed the underlying bug which would cause that string to print, but kept the print statement in anyway. What harm could it do?</p><p>We had no idea what the relative time cost of any of our code was at that stage, and didn’t find out until later, when we started using <strong>flamegraphs</strong> (a visual aid showing the proportion of time spent on each function call in a program) to profile our code. We had certain functions we knew for a fact were bottlenecks, so some of the graph wasn’t a surprise. What was a surprise, however, was the mountain sticking up from the surrounding foothills, in the center of the graph:</p><p><em>(Click or hover for more details)</em></p><p>As it turned out, that string format statement was taking up 17% of the total runtime, all in the event of an error that literally never happened. And that was before all of our other optimizations; if we put this string format statement back into the current emulator, it would take up well over 95% of the runtime by itself. And without code profiling, we <em>still</em> would never have guessed this.</p><p>Reasoning about runtime is <em>extremely</em> tricky. For all the coding interviews that emphasize calculating the runtime complexity of your program, there is a lot of magic that happens in coding, and the only way to really know what’s going on is to use appropriate tools to detect it. Sure, you should avoid nested for loops inside for loops, but profiling your program can give you even better results.</p><p>And by the same token, profiling also revealed that we had no need to worry about some things that concerned us. We’d spent significant amounts of time discussing how we were going to fix our various issues with using <code>.clone()</code> to get around borrow issues, and do things properly… but when we looked at the flamegraphs it turns out our 70+ clones were not costing us any time, since they were being optimized away during compilation. What we had assumed was a major time-sink was nothing to worry about at all.</p><p><img data-src="/assets/img/HATETRIS/attackclones.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/attackclones.png"></p><h3 id="array-vs-btree">Array vs. BTree</h3><p>That said, you can’t just ignore runtime complexity, either. Our original version of the beam search took <code>N</code> wells, calculated all of the children of all of the <code>N</code> wells (typically around <code>15*N</code>), sorted the list, and then took the best <code>N</code> children in the list to use for the next step. This is all well and good for small values of <code>N</code>, but when scaling up, this quickly becomes untenable; storing all of the children at the same time (as opposed to just storing the top <code>N</code> children) wastes a tremendous amount of memory, making the beam search take up on average fifteen times more RAM than it properly should. We knew we had to change something there.</p><p>So, we took the obvious route. To summarize in pseudocode:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre>for well in current_wells:
    for child in children(well):
        if child is better than worst_child in new_wells:
            insert child into new_wells in appropriate_position
            remove worst_child from new_wells
            get new worst_child from new_wells
</pre></td></tr></tbody></table></code></p></div><p>And therein lay the problem, though we didn’t figure it out for another month and a half. Reading an arbitrary element from the vector is <code>O(1)</code>, but insertion into the middle of a dynamically-sized vector is not an <code>O(1)</code> operation - it’s <code>O(n)</code>, scaling with the number of elements in the vector. This caused a huge nonlinear increase in runtime with respect to the beam width; had we tried to do a full 25 million width beam search at this point (and we wouldn’t have tried), it would have taken literal years to finish even with Rust’s impressive compiler magic.</p><p>We briefly considered using linked lists, <a href="https://rust-unofficial.github.io/too-many-lists/">despite well-known warnings about how tedious and difficult they could get in Rust</a>, but linked lists presented a different problem. Insertion in between two elements is nice and fast at O(1), but reading through the linked list to find out <em>where</em> to insert is O(n). This was exactly the opposite of the situation with vectors, but it was no closer to being a solution.</p><p>Upon seeing that we had two data structures, one which could read quickly but insert slowly, and the other which could read slowly but insert quickly, we thought “surely there’s some sort of compromise data structure that does both pretty well”. And sure enough, there was. Rust’s <a href="https://doc.rust-lang.org/std/collections/struct.BTreeSet.html">BTreeSet</a> was a built-in data structure based on <a href="https://en.wikipedia.org/wiki/B-tree">B-trees</a>, which have logarithmic read times and logarithmic write times. Things were slow enough already that we were willing to accept almost any constant in front of those logarithms, so we switched, and went from insertion taking up more than 90% of the beam search runtime to less than 1% instantly.</p><div><table><thead><tr><th>Data Type</th><th>Insertion Time</th><th>Element Read Time</th></tr></thead><tbody><tr><td>Vector</td><td><code>O(n)</code></td><td><code>O(1)</code></td></tr><tr><td>Linked List</td><td><code>O(1)</code></td><td><code>O(n)</code></td></tr><tr><td>B-Tree</td><td><code>O(log(n))</code></td><td><code>O(log(n))</code></td></tr></tbody></table></div><p>Changing the datastructure was the key to unlocking larger beam searches, but this would have been futile without the improvements we got from the flamegraphs, and in turn wouldn’t have worked if we’d spent all our time cleaning up clones. Writing highly efficient code is more of an artform than a science (and we await a flurry of angry tweet from our many reader over this statement). It requires a mix of the right tooling, understanding your code, and figuring out what tradeoffs make sense.</p><h3 id="machine-learning-on-the-cheap">Machine Learning (on the cheap)</h3><p>There’s another lesson we learned as we optimized our code as best we could…no amount of optimal code will eliminate the need for absurd amounts of hardware for machine learning. It doesn’t matter how good your emulator is, how blazingly fast you can play games… the sheer amount of training data and training time needed makes trying to solve problems of more than trivial complexity on consumer hardware very very challenging.</p><p>We’re not machine learning engineers. We don’t have formal backgrounds in machine learning, or in anything remotely close. Mr. Hughes generously said that we “appear to be academic researchers”, but that appearance is purely surface level. It’s possible, as it always is, that we were just doing everything wrong, and someone with a PhD in applied machine learning will show up with a model far better than any beam search we’ve designed. We wish for nothing more. We <em>want</em> user friendly machine learning for amateurs like ourselves. In fact, when we set out on this project, one of the things we wanted to prove was that AlphaZero could be used for a practical purpose without a massive computing cluster. As far as we can tell, it cannot.</p><p>The cloud costs, in TPUs and GPUs and RAM, to really get this project off the ground would have been considerable. Our models, tiny and poor as they were, still took two plus weeks to train on a very low number of games, and one of the things we’ve realized is that machine learning <em>depends</em> on having vast reams of data. It’s not sufficient to have 100,000 good games; you need tens of millions. And you need to be able to take games generated by your models and train on them. With super slow hardware, its impossible to tweak hyperparameters to figure out the best learning approach. (Which is, as far as we can tell, how the big, successful projects figure out their hyperparameters, careful guessing, and a lot of tweaking.)</p><p>Its frustrating to learn that the incredible tools that are supposed to revolutionize problem solving are out of the reach of anyone not able to throw significant cash at it. There’s a whole possible blog post on this topic. We’re <a href="https://www.gwern.net/Scaling-hypothesis">hardly the first to realize it</a>, but we felt it extremely keenly.</p><h3 id="behaviors-at-different-well-heights">Behaviors at Different Well Heights</h3><p>Since we had an emulator handy, while we were waiting to get sufficiently good heuristic parameters for the full case, we thought to explore some smaller wells, and see if there was any obvious trend in maximum score and maximum game length we could extrapolate. The primary motivation behind this was simple: before embarking on programs which would take weeks or even months to run, we wanted to prove to ourselves that knewjade’s record of 66 was beatable, and that it wasn’t simply the maximum possible score attainable in HATETRIS. So, we did a series of breadth-first search runs, up until it exceeded the RAM available on a laptop, and wrote down the results.</p><h4 id="10-blocks-across">10 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>4</td><td>21</td></tr><tr><td>3</td><td>0</td><td>6</td><td>310</td></tr><tr><td>4</td><td>1</td><td>11</td><td>9095</td></tr><tr><td>5</td><td>4</td><td>19</td><td>174634</td></tr><tr><td>6</td><td>8</td><td>31</td><td>4848325</td></tr><tr><td>7</td><td>12</td><td>43</td><td>141514270</td></tr><tr><td>8</td><td>≥17</td><td>≥57</td><td>≥1.00e8</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr><tr><td>16</td><td>≥86</td><td>≥247</td><td>≥2.50e7</td></tr></tbody></table></div><p>This set of runs had some interesting results. Among other things, we had assumed (and we were <a href="https://twitter.com/qntm/status/1404880481657757700">not the only ones</a>) that since there were <code>10*16</code> squares in the grid, each one of which could be either filled or not filled, that there were roughly <code>2^(10*16) ≈ 10^48</code> possible HATETRIS wells. However, here, the results indicated that the number of possible wells was vastly less; the maximum width of the BFS search increased by a factor of ~30 with each additional line of height, so the maximum number of concurrent states would be somewhere around <code>10^20</code>:</p><p><img data-src="/assets/img/HATETRIS/BFS_Widths.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/BFS_Widths.png"></p><p>For a game lasting (say) a thousand moves, this would be at most 10^23 possible wells. This was twenty-five orders of magnitude less than we expected, though sadly it was still nine orders of magnitude or so beyond what we could do with commercial brute-force and commercial hardware.</p><p>For completeness’ sake, we also examined narrower wells, to get as much of a feel for the behavior of HATETRIS with respect to well dimensions as possible. Width 4 is a special case, since an infinite loop there is actually possible in our emulator (and not possible in the newest version of HATETRIS); there’d be no point going any further. Doing BFS for wider wells might be interesting too, but our emulator currently can’t go beyond 10 blocks across, so we left that as a problem for a future date.</p><p><strong>EDIT (May 22nd, 2024)</strong>: The original values here were incorrect; this version of the emulator had a bug that only occurred when the well height was reduced; in certain circumstances, a piece which filled a line while sticking out the top of said line would be counted as a clear, rather than ending the game. That has been fixed, and these should hopefully be the correct values.</p><h4 id="8-blocks-across">8 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>3</td><td>10</td></tr><tr><td>3</td><td>1</td><td>6</td><td>75</td></tr><tr><td>4</td><td>1</td><td>8</td><td>1172</td></tr><tr><td>5</td><td>5</td><td>17</td><td>12447</td></tr><tr><td>6</td><td>6</td><td>21</td><td>159942</td></tr><tr><td>7</td><td>9</td><td>28</td><td>2250610</td></tr><tr><td>8</td><td>11</td><td>34</td><td>31440780</td></tr></tbody></table></div><h4 id="6-blocks-across">6 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>2</td><td>4</td></tr><tr><td>3</td><td>0</td><td>3</td><td>21</td></tr><tr><td>4</td><td>1</td><td>6</td><td>142</td></tr><tr><td>5</td><td>2</td><td>8</td><td>682</td></tr><tr><td>6</td><td>5</td><td>13</td><td>3998</td></tr><tr><td>7</td><td>6</td><td>15</td><td>23337</td></tr><tr><td>8</td><td>8</td><td>19</td><td>149389</td></tr><tr><td>9</td><td>9</td><td>23</td><td>1017165</td></tr><tr><td>10</td><td>12</td><td>28</td><td>6995425</td></tr><tr><td>11</td><td>13</td><td>32</td><td>50825005</td></tr></tbody></table></div><h4 id="4-blocks-across">4 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>1</td><td>2</td></tr><tr><td>3</td><td>0</td><td>2</td><td>5</td></tr><tr><td>4</td><td>∞</td><td>∞</td><td>16</td></tr></tbody></table></div><h4 id="5-blocks-across">5 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>1</td><td>3</td></tr><tr><td>3</td><td>0</td><td>2</td><td>8</td></tr><tr><td>4</td><td>1</td><td>4</td><td>41</td></tr><tr><td>5</td><td>3</td><td>7</td><td>134</td></tr><tr><td>6</td><td>4</td><td>10</td><td>543</td></tr><tr><td>7</td><td>5</td><td>12</td><td>2150</td></tr><tr><td>8</td><td>6</td><td>14</td><td>8670</td></tr><tr><td>9</td><td>7</td><td>16</td><td>35017</td></tr><tr><td>10</td><td>8</td><td>19</td><td>148656</td></tr><tr><td>11</td><td>10</td><td>22</td><td>645397</td></tr><tr><td>12</td><td>11</td><td>24</td><td>2935961</td></tr><tr><td>13</td><td>12</td><td>26</td><td>13436407</td></tr><tr><td>14</td><td>13</td><td>29</td><td>61699120</td></tr><tr><td>15</td><td>15</td><td>32</td><td>285071640</td></tr></tbody></table></div><h4 id="6-blocks-across-1">6 Blocks Across</h4><div><table><thead><tr><th>Height</th><th>Score</th><th>Length</th><th>BFS Width</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>2</td><td>4</td></tr><tr><td>3</td><td>0</td><td>3</td><td>21</td></tr><tr><td>4</td><td>1</td><td>6</td><td>139</td></tr><tr><td>5</td><td>2</td><td>8</td><td>679</td></tr><tr><td>6</td><td>4</td><td>12</td><td>3973</td></tr><tr><td>7</td><td>6</td><td>15</td><td>23126</td></tr><tr><td>8</td><td>7</td><td>19</td><td>143175</td></tr><tr><td>9</td><td>8</td><td>22</td><td>979997</td></tr><tr><td>10</td><td>11</td><td>27</td><td>6771901</td></tr><tr><td>11</td><td>12</td><td>30</td><td>48488721</td></tr><tr><td>12</td><td>15</td><td>36</td><td>362642476</td></tr></tbody></table></div><h4 id="7-blocks-across">7 Blocks Across</h4><h3 id="finding-the-bug">Finding The Bug</h3><p>Along the way, trying to come up with optimizations for this state-based emulator, we encountered an interesting bug. ‘Interesting’ because the original implementation of HATETRIS briefly <a href="https://qntm.org/hatetris#komment2605">had exactly the same bug, and had it for exactly the same reason</a>:</p><blockquote><p>Start a new game and hit “rotate” four times. Note what happens to the piece. Unlike many Tetris games, the rotation process is actually mathematical; each new piece rotates around a “point of origin” which is at the junction point of four squares. The rotation is performed by fiddling with the actual coordinates of each of the four “bits” which make up the piece. Each piece actually has a point of rotation in addition to everything else.</p></blockquote><blockquote><p>The algorithm which tests all the possible positions, actions and final resting places of each possible new piece can do anything you can do: left, right, drop, rotate. The algorithm stores a list of all of these locations and applies all possible transforms to each location in turn in order to generate a complete list. Obviously, each new location thus generated has to be compared with the whole list to make sure it is new. One of my early attempts to make the algorithm faster made it so that it only checked the locations of the four bits, not the central point of rotation.</p></blockquote><blockquote><p>However, in the case of an <code>S</code> or <code>Z</code> piece, the point of rotation is significant. <strong>Hitting “rotate” will result in a different piece depending on which way up the piece is</strong>. In Tom’s 12-point run, the algorithm moved an <code>S</code> piece to the same location as he did, and hit “rotate”, but because the piece was the other way up, resistance was encountered and nothing happened. With the piece the other way up, which is what Tom did, the rotation is successful and a line is made.</p></blockquote><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/HATETRIS/s-rotation.gif" alt=""></p><p>In other words, an <code>S</code> or <code>Z</code> piece occupying the same space can in fact be different pieces with different available positions. This means that the optimization of only considering the space a piece is taking up, rather than storing properties like ‘rotation’ and ‘position’ separately, will end up failing in some edge cases. This wouldn’t have been a huge speedup, and it’s not that important, but it was a signal to us that we were slowly but surely following the same path.</p><h3 id="echoes-of-alphazero">Echoes of AlphaZero</h3><p>The core premise of the AlphaZero neural architecture is that it is dual-head: the neural network has a policy head, and a value head, and the formula for determining which moves to investigate uses both. The value head is the simpler of the two: it takes in a position and outputs a single number ranging from -1 (meaning a predicted 100% chance of defeat) and +1 (meaning a predicted 100% chance of victory). The value head is what allows the algorithm to decide how good a position is, without having to play the entire game through to the end.</p><p><img data-src="/assets/img/HATETRIS/Stickman_691.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_691.png"> <em><a href="https://stickman.qntm.org/comics.php?n=691">StickManStickMan #691</a>, by Sam Hughes.</em></p><p>The policy head can be thought of (in <em>very</em> broad strokes, don’t take this too literally) as the ‘gut feeling’. If you’re a chess grandmaster, you don’t play as well as you do by looking at every possible move and counter-move that could be made - the branching factor of chess is simply too high. Instead, your gut feeling tells you to look at moves X, Y, and Z, so you do, and you don’t consider (or only briefly consider) the dozens of other possible moves available. The policy head works something like that, biasing the algorithm so that it does not consider all moves and all branches equally.</p><p>What we did, combining the overall ‘board sense’ from the knewjade heuristic and the line-by-line precision from the graph theory heuristic is very, very far removed from the original AlphaZero algorithm. Nevertheless, we couldn’t help but be reminded of the balance that the policy head and the value head were supposed to bring to each other when combined.</p><p>(This section was written long before we discovered that the graph theory heuristic made no difference; our intuition is no more perfect than the policy head’s.)</p><h3 id="reversing-the-polarity">Reversing the Polarity</h3><p>Keyframe generation took quite a while on the world record run, due to the sheer amount of time needed to read hundreds of gigabytes from disk into memory. There’s a better way to do it that didn’t occur to us until afterwards: make the emulator run backwards. That way, rather than calculating every child of every well that’s saved, simply calculate all of the possible parents of the well directly, and see which of those parents is in the previous generation’s well list.</p><p>If we really needed to speed up the process even further, we would write to a disk database rather than writing each timestep as its own file, and then when calculating the keyframes we’d only have to search the disk database for the dozen or so possible parents of the current well, probably getting the complete game in a few seconds.</p><p>Unfortunately, the initial idea of taking this idea to the extreme and calculating the entire ‘reverse game tree’ didn’t work; looking further than ten or so moves is currently very impractical, since most possible parents of a well are not reachable HATETRIS states (going back to the earlier discovery about how few reachable HATETRIS states there actually are). It’s possible to filter out some of the unreachable states (for instance, any well that has a partially filled line above a completely empty line is definitely unreachable), but we couldn’t figure out a way to filter out all of the unreachable parents, or even most of them, and so the effective branching factor is too high. If a full reverse emulator is possible, it would potentially allow for diskless beam searches, but right now it’s a bridge too far.</p><h2 id="the-next-world-record">The Next World Record</h2><p>We never bothered writing a script to take a list of wells and turn it directly into a valid <a href="https://github.com/qntm/base2048">Base2048</a> replay; it wouldn’t have been <em>that</em> difficult, but it was never important enough to actually get done. Instead, we printed out the list of wells, went through them one by one, and manually hit the arrow keys on the Javascript version of the game to move each piece where it needed to go. And along the way, we noticed a trend, one that we noticed also in knewjade’s 66 point run.</p><p><img data-src="/assets/img/HATETRIS/WellHeight.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/WellHeight.png"></p><p>The winning game piled pieces up pretty high, and did so pretty early; it first had a piece touch the top of the well less than halfway through the game (move 120, for a game that lasted 247 moves). Looking at it, it makes sense that piling up pieces benefits the score; the HATETRIS algorithm is based on the height of the well, so maximizing the well height minimizes the amount of information the HATETRIS algorithm has at its disposal, and puts an upper bound on how evil its piece selection can be.</p><p>So by that logic, a perfect game should keep pieces piled all the way up to the top the whole time. Ours does not - our heuristic indirectly penalizes wells for being too high, because stacking pieces all the way up to the top takes time which could be used to score points and clear lines. And any well which goes too long without clearing any lines tends to get filtered out. The left-hand side of that graph is a land of opportunity, and a better heuristic than ours could probably get more than a hundred points by properly exploiting it.</p><p>Going back to the analysis on smaller wells, the length of the best possible games seems to increase approximately quadratically. Fitting a quadratic function to the results from well heights 2 through 7 and extrapolating out (and taking the result with a grain of salt), we’d expect the best possible game to last about 290 moves, which, like the previous estimate, would correspond to a best possible score of 102-103 - at the very least, indicating again that the current record is not the best possible game.</p><p><img data-src="/assets/img/HATETRIS/MaximumGameLengths.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/MaximumGameLengths.png"></p><p>86 points is not the end of this story. It is, however, the end of this blog post.</p><h2 id="specific-thanks">Specific Thanks</h2><ul><li><a href="https://ca.linkedin.com/in/arta-seify-67793a117">Arta Seify</a>, for writing <a href="https://era.library.ualberta.ca/items/d4a0e7f0-12c5-4a88-9e79-39538bff4ce4/view/2c7e669e-07b9-4fa0-a4cc-d03800e4a11b/Seify_Arta_202001_MSc.pdf">his thesis</a> on modifying AlphaZero for single-player games, and for helping us quite a bit with implementation details when we emailed him.</li><li><a href="https://a3nm.net/blog/adversarial_tetris.html">Dr. Antoine Amarilli</a> for inspiring the small well size experiments.</li><li><a href="https://kevingal.com/">Kevin P. Galligan</a>, for providing insight into what alternate routes there were besides beam searches and MCTS to making a HATETRIS solver, and how far those alternate routes can get.</li><li>David’s dad, for suggesting <a href="https://en.wikipedia.org/wiki/B-tree">B-Trees</a> rather than linked lists or dynamic-sized arrays.</li><li><a href="https://www.youtube.com/watch?v=hF2wWRC5X9Q"> えぬ・わん</a>, for making a video analyzing the strategy used in our world record; more analysis than we did ourselves.</li><li><a href="https://qntm.org/hatetris#komment2579">Aypical</a>, <a href="http://speeddemosarchive.com/forum/index.php?topic=11523.msg323956#msg323956">SDA Guest</a>, <a href="https://qntm.org/hatetris#komment2655">Ivernis</a>, <a href="http://slashdot.jp/comments.pl?sid=493607&amp;cid=1758529">Deasuke</a>, and <a href="https://qntm.org/hatetris#komment593722b6a1beb">chromeyhex</a>, for giving HATETRIS a proper leaderboard and for each setting the bar successively higher.</li><li><a href="https://twitter.com/1millim?lang=en">Knewjade</a>, for setting forth both a <a href="https://twitter.com/1millim/status/1429774558379216907">monumental challenge</a> and the tools needed to eventually overcome it.</li><li><a href="https://qntm.org/">Sam Hughes</a>, for getting us to waste fourteen months and fourteen thousand words on Tetris. So far.</li></ul><h2 id="ps">P.S.</h2><p>Ok, so we lied about that last part being the end. If you read this far, (which is, lets face it, unlikely) you’ve heard a lot of griping, seen some things that look semi-magical, and possibly left with the impression that the authors had some sort of incredible knowledge base, or are researchers deeply entwined with the topic.</p><p>We’re not. We’re not researchers at all. We’re just two people who became obsessed with a problem and put their meager knowledge to use, beating rocks against rocks in different configurations until something resembling a spearhead came out. Our experience with Rust was, up to this point, <a href="https://hallofdreams.org/categories/advent-of-code/">six blog posts done on introductory Advent of Code problems</a> over the course of six months. We didn’t know much at the start, but we learned. First, we Googled and clicked on the first result. Then we scoured Stack Overflow and papers, and when that failed, we reached out to specialist Discord servers and emailed experts. When existing Rust crates didn’t do what we needed, we made our own Rust crates. We now know a lot of very obscure information about HATETRIS, but you could still fill volumes with things about HATETRIS that we don’t know. Many of the breakthroughs we had were due to ignorance. We pulled out the concept of waveforms because we were <em>terrified</em> that the next thing we’d have to do to push things forward was do complex matrix operations on a GPU. Inventing a new way of thinking about the problem seemed easier.</p><p>You, too, can do something like this. Find a problem. Become obsessed with it. Learn everything you can about it. Fall down dead ends. Give up, and then keep thinking about the problem at night. Have Eureka moments that lead you down other dead ends. Find a friend willing to get as obsessed as you are. Underestimate the time commitment, and then refuse to back down. Embrace the sunk cost fallacy. As long as you keep thinking about the problem, even if its in short bursts every few years, you’re still making progress. And if you never finish? If all you find are side-paths and obstacles, and it turns out the entire mission was doomed from the outset? That’s okay too. Projects like this nourish us, because there’s a part of the human mind that wants nothing more than to climb the mountain, rappel into the cave, explore the unknown and grapple with it.</p><p>So, regardless if you’re here because you care about the technical details, or because you saw HATETRIS and said “I heard of that, I think”, if you only take one lesson away from this whole thing, we hope it’s this. You too can do the thing you think is impossible or difficult.</p><p>If you fail? Write about it anyway. The original title of this post was “How Not to Get the World Record in HATETRIS”.</p><p><img data-src="/assets/img/HATETRIS/Stickman_620.png" alt="" src="https://hallofdreams.org/assets/img/HATETRIS/Stickman_620.png"> <em><a href="https://stickman.qntm.org/comics.php?n=620">StickManStickMan #620</a>, by Sam Hughes.</em></p><p><em>Next post: <a href="https://hallofdreams.org/posts/hatetris-2/">Losing the World Record in HATETRIS</a></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Code reviews do find bugs (170 pts)]]></title>
            <link>https://two-wrongs.com/code-reviews-do-find-bugs.html</link>
            <guid>40851895</guid>
            <pubDate>Mon, 01 Jul 2024 23:23:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://two-wrongs.com/code-reviews-do-find-bugs.html">https://two-wrongs.com/code-reviews-do-find-bugs.html</a>, See on <a href="https://news.ycombinator.com/item?id=40851895">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
There’s some 2015 research out of Microsoft titled <i>Code Reviews Do Not Find
Bugs</i><label for="fn.1">1</label><span><sup>1</sup> <i>Code Reviews Do Not Find Bugs; How the Current Code Review Best
Practice Slows Us Down</i>; Czerwonka, Greiler, Tilford; IEEE International
Conference on Software Engineering; 2015.</span> which seems strangely named because
reviewers <i>do</i> find bugs.
</p>

<p>
Here’s what the authors say:
</p>

<blockquote>
<p>
Contrary to the often stated primary goal of code reviews, they often do not
find functionality defects that should block a code submission. Only about 15&nbsp;%
of comments provided by reviewers indicate a possible defect, much less a
blocking defect.
</p>
</blockquote>

<p>
This is a misleading statistic, because it says nothing about the defect
detection rate. Only about 15&nbsp;% of smokers get lung cancer, but that does not
mean we can ignore smoking as a cause – smoking is the cause of more than 80&nbsp;%
of lung cancer cases. The fact that 15&nbsp;% of code review comments are about
defects is not a statement about a lack of detected defects, but rather a
statement about how reviewers <i>also</i> write a lot of comments about other things
– and we will see more about that later.
</p>

<p>
This does just not support the idea that reviewers do not find defects. For
example, if the reviews in their data had an average of four comments each, then
more than half of the reviews did get comments about defects!
</p>

<p>
But we don’t need to speculate on how many comments there were in their data,
because there has been previous research on this. We have known for a while that
code review (as well as pair programming) finds an additional 60&nbsp;% of defects
for only a 15&nbsp;% increase in time investment.<label for="fn.2">2</label><span><sup>2</sup> <i>Balancing Agility and
Discipline</i>; Boehm, Turner, Booch, Cockburn, Pyster; Addison–Wesley
Professional; 2003</span>
</p>

<p>
At this point, we also have more detailed data on the effectiveness of code
review. During the first 60 minutes of code review of the day, the reviewer
finds roughly one defect per ten minutes of reviewing – as long as they review
less than about 50 lines of code per ten minutes.<label for="fn.3">3</label><span><sup>3</sup> <i>Making Software: What
Really Works, and Why We Believe It</i>; Oram &amp; Wilson; O’Reilly Media; 2010.</span> In
other words, reviews are most effective on small chunks at a time, and mustn’t
expand to cover large fractions of the workday.
</p>

<p>
What other activity can you imagine where a single developer can uncover a
defect every 10 minutes? Certainly not through manual testing – not even all
forms of automated testing beat this rate, given that the total cost of
automated testing of a component quickly exceeds 10 minutes of time investment.
Code review is ridiculously effective. Of all the quality measures we might have
in place, code review is the last one I’d get rid of.<label for="fn.4">4</label><span><sup>4</sup> But if we produce more
than about 300 lines of code per developer and day, I would be tempted to let
the excess lines of code go unreviewed, and focus reviewing on the most
important 300 lines per developer and day.</span>
</p>

<hr>

<p>
The Microsoft authors also report on how code review is remarkably effective for
learning the codebase.
</p>

<blockquote>
<p>
The usefulness of code review comments – as judged by the author of a code
change – is positively correlated with reviewers’ experience. Without prior
exposure to the part of code base being reviewed, on average only 33&nbsp;% of any
reviewer’s comments are deemed useful by the author of a change. However,
reviewers typically learn very fast. When reviewing the same part of code base
for the third time, the usefulness ratio increases to about 67&nbsp;% of their
comments. By the fourth time, it is equivalent to the project’s long-term
average.
</p>
</blockquote>

<p>
Granted, they don’t say enough to determine whether “the project’s long-term
average” is at a comparatively low or high familiarity level, but it sounds to
me like only <i>four</i> code reviews are enough to get people relatively familiar
with a completely new part of the codebase. Assuming a reasonably-sized change
(50–100 lines of code?) and a reasonable pace of reviewing for a beginner (10–50
lines of code per 10 minutes?) this would mean about 1–2 hours of code review is
enough to get familiar with a codebase.
</p>

<p>
That’s a cheat code. Exploration and exploitation are always in conflict; for
software engineering, this means knowledge sharing and speed are in conflict. If
we put someone experienced with a component on a task, they will finish quickly
but we won’t spread knowledge about that component. If we put someone
inexperienced on the task, the task is likely to take much longer but we do get
knowledge sharing. <i>Or</i>! We ask the inexperienced person to review the code of
the experienced person. This takes virtually no time (increases development time
by 15&nbsp;%) and they become familiar with the component as a side effect. We get
both knowledge sharing and speed.<label for="fn.5">5</label><span><sup>5</sup> Not to mention that sometimes we want to
share knowledge about a component which does not need changes made to it. We can
then have people review past changes and get feedback on their reviews from an
experienced member of the team.</span>
</p>

<hr>

<p>
The main thesis of the Microsoft paper seems to be that code review is not worth
the time spent on it. We have already seen that when the review load is properly
managed, code review is highly effective both in terms of finding defects and
learning the codebase.
</p>

<p>
The Microsoft paper goes on to say other things that appear to contradict their
thesis, like
</p>

<ul>
<li><b>Feedback on long-term code maintainability covers 50&nbsp;% of code review
comments.</b> Sure, but isn’t this a good thing? Long-term code maintainability
is in my experience a large problem in organisations that don’t do peer
review.</li>
<li><b>The review is an opportunity for both author and reviewer to prove
themselves.</b> This seems like a potential motivator, and not a problem.</li>
<li><b>Code review usefulness is negatively correlated with change size.</b> This is a
feature, not a bug. It is an incentive to keep changes small and atomic.</li>
<li><b>Developers spend six hours per week reviewing.</b> This is a bit too much
(remembering the “first hour of the day” rule from before) but it should only
result in a marginal decrease in productivity – code review ought to still
appear to be a clear win.</li>
</ul>

<p>
I suspect the real problem with code review in the authors’ experience is one of
the last points they raise:
</p>

<ul>
<li><b>The median review turnaround time is 24 hours.</b> The research on code review
has been mostly done in lab settings and not in integrated on-the-job
situations, so it has not emphasised turnaround time. But having half of the
reviews take more than 24 hours seems – in my experience – like way too much.
When I did the maths on this at a previous job, the median turnaround time was
6 hours, and that was borderline painful (which was why I ran the numbers in
the first place.)</li>
</ul>

<p>
In the end, I agree with the authors that we should not blindly copy best
practises (i.e. cargo cult practices) but the reported experience in this case
does not appear to follow best practices, so before judging best practices we
should first make sure we have followed them.
</p>

<p>
If they are impractical to follow in a large organisation, that would be <a href="https://two-wrongs.com/publish-your-observations.html">an
important observation worth publishing</a>, rather than claiming they don’t work
when followed.
</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A proof of proof by infinite descent (101 pts)]]></title>
            <link>http://relatedwork.blogspot.com/2024/07/a-proof-of-proof-by-infinite-descent.html</link>
            <guid>40851130</guid>
            <pubDate>Mon, 01 Jul 2024 21:49:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://relatedwork.blogspot.com/2024/07/a-proof-of-proof-by-infinite-descent.html">http://relatedwork.blogspot.com/2024/07/a-proof-of-proof-by-infinite-descent.html</a>, See on <a href="https://news.ycombinator.com/item?id=40851130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-3124261924762160653" itemprop="description articleBody">
<p>WARNING: the following contains a whole lot of pedantry about proving
theorems at a level of detail such that you could likely convince a
computer proof assistant of their correctness. I teach a course where
students learn to write such proofs without computer assistance, because
doing so can profoundly affect how one perceives the possibilities for
formal definition and proof. Sometimes the default reasoning principles
provided by a proof assistant can restrict one’s perspective of what
reasoning principles are acceptable, how and why they might be judged
acceptable, and how to devise and validate new ones.</p>
<p>More relevant to the present post is that even the literature and
pedagogy of writing paper proofs is rife with defaults. I spend a lot of
time teaching about proof by induction, and I find that my students,
most of whom have learned something about proving stuff in the past,
often arrive constrained by a very regimented approach to induction,
involving mandatory “base cases” and “induction cases” and these
nebulous “induction hypotheses” which seem to descend from the sky when
invoked by arcane ceremony. I have some strong feelings about this,
mostly due to my own struggles with gaining comfort with induction as a
student, so I try to help students evade those struggles.</p>
<p>Taken at face value, this post is about some other proof principle,
proof by infinite descent, but at its heart it’s really about induction.
Ideally by the end of this post, I will have challenged, but also shed
light on, the nature of inductive proof cases and induction hypotheses.
As a bonus, you might see how induction can be used to explain another
proof principle that intuitively seems valid, but for which it may not
be obvious how to justify it formally.</p>
<h2 id="two-proofs-that-sqrt2-is-not-rational">Two Proofs That <span>\(\sqrt{2}\)</span> is Not Rational</h2>
<p>In an excellent <a href="https://math.andrej.com/2010/03/29/proof-of-negation-and-proof-by-contradiction/">blog
post</a> about the difference between proof of negation and proof by
contradiction, Andrej Bauer gives as an example a proof that <span>\(\sqrt{2}\)</span> is not a rational number. The
article is worth a read, but I would note in particular that in a
technical sense, his proof is not a proof that it <em>is an irrational
number</em>, just that it is not a rational number. I imagine that one
could also prove that <span>\(\sqrt{-1}\)</span> is
not rational, but that had better not count as a proof that it is
irrational! However, if we also prove that <span>\(\sqrt{2}\)</span> is a real number, which could be
done using Dedekind cuts for instance, then we can deduce that <span>\(\sqrt{2}\)</span> is indeed irrational. And to no
one’s surprise, we can prove that <span>\(\sqrt{-1}\)</span> is not a real number.</p>
<blockquote>
<p><strong>Theorem:</strong><span>\(\sqrt{2}\)</span> is not rational.<br>
<em>Proof</em>. Suppose <span>\(\sqrt{2}\)</span>
were equal to a fraction <span>\(\frac{a}{b}\)</span> with <span>\(a\)</span> and <span>\(b\)</span> relatively prime. Then we would get
<span>\(a^2 = 2b^2\)</span>, hence <span>\(a^2\)</span> is even and so is <span>\(a\)</span>. Write <span>\(a =
2c\)</span> and plug it back in to get <span>\(2c^2
= b^2\)</span>, from which we conclude that <span>\(b\)</span> is even as well. This is a
contradiction since <span>\(a\)</span> and <span>\(b\)</span> were assumed to be relatively prime.
QED.</p>
</blockquote>
<p>This is a proof of the negation of some proposition, i.e., that
assuming the truth of the proposition implies a contradiction. Let’s
consider some of its details.</p>
<p>First, the proof assumes that <span>\(\sqrt{2}\)</span> is equal to a fraction <span>\(\frac{a}{b}\)</span>, which implicitly implies
that <span>\(a\)</span> and <span>\(b\)</span> are integers and that <span>\(b\)</span> is not 0. We <em>could</em> limit the
two numbers to be naturals, by which I mean non-negative integers,
applying the convention that <span>\(\sqrt{2}\)</span> denotes specifically the
positive root, but since there exists a negative number that when
squared equals 2, and since generalizing the claim plays into my overall
story, let’s make no commitment to whether <span>\(a\)</span> and <span>\(b\)</span> are positive or negative.</p>
<p>Next, the proof uses the fact that every rational number can be
represented by a fraction <span>\(\frac{a}{b}\)</span> such that <span>\(a\)</span> and <span>\(b\)</span> are relatively prime, in other words
that no positive integer other than 1 divides them evenly, which is a
precise way of saying that <span>\(\frac{a}{b}\)</span> is in reduced form. This is a
fact that needs to be proved separately and prior to this proof. We
could instead ntegrate this reasoning directly into the proof: omit the
relative primality assumption, and then let <span>\(a' = a/\gcd(a,b)\)</span> and <span>\(b' = b/\gcd(a,b)\)</span> where <span>\(gcd(a,b)\)</span> is the greatest common divisor
of both. It then follows from some proof effort that <span>\(a'\)</span> and <span>\(b'\)</span> are relatively prime and <span>\(\frac{a'}{b'} = \frac{a}{b}\)</span>, thus
completing the general proof. However, we’re still using an auxiliary
fact that can be proven by induction: that <span>\(a\)</span> and <span>\(b\)</span> have a unique greatest common divisor.
More on that below.</p>
<p>From these assumptions and facts, the proof deduces that both <span>\(a\)</span> and <span>\(b\)</span> are even, which means that <span>\(2\)</span> divides both of them, which contradicts
the assumption that among positive integers only 1 can do this. So
assuming that <span>\(\sqrt{2}\)</span> is rational
leads to contradiction.</p>
<p>Now to drive the topic of this post, here’s a more annoying proof of
the same fact:</p>
<blockquote>
<p><em>Proof.</em> Suppose <span>\(\sqrt{2}\)</span>
were equal to a fraction <span>\(\frac{a}{b}\)</span>. Then we would get <span>\(a^2 = 2b^2\)</span>, hence <span>\(a^2\)</span> is even and so is <span>\(a\)</span>. Write <span>\(a =
2c\)</span> and plug it back in to get <span>\(2c^2
= b^2\)</span>, from which we conclude that <span>\(b\)</span> is even as well. Write <span>\(b = 2d\)</span> and plug it back in to get <span>\(c^2 = 2d^2\)</span>. This yields a contradiction
because we could divide our integers by <span>\(2\)</span> forever, which is impossible. QED.</p>
</blockquote>
<p>On the upside, this proof gets to omit the assumption that <span>\(a\)</span> and <span>\(b\)</span> are relatively prime, which in turn
means we don’t need to consult Wikipedia to remind ourselves what the
heck “relatively prime” means anyway. But on the other hand...what just
happened?!? Intuitively this makes sense, but is this legit?</p>
<p>While Andrej’s proof is a direct proof of negation, this annoying one
is an example of <em>proof by infinite descent</em>, which according to
Wikipedia is a particular kind of proof by contradiction, and relies on
something called the <a href="https://en.wikipedia.org/wiki/Proof_by_infinite_descent">the
well-ordering principle</a>. By the end of this post, I hope to convince
you that: a) it is not a kind of proof by contradiction: rather it’s a
technique for proving negation, so this claim deserves some
finger-wagging from Andrej. b) it does not rely on the well-ordering
principle, and good thing that because if it did, then the annoying
proof would be broken, but it’s not.</p>
<p>We should be able to ascertain from a formal statement of the
principle that it is simply a proof of negation. Andrej’s post
elaborates on the source of confusion. And what is the problem with the
claim that proof by infinite descent relies on well-ordering, whatever
that is? To explain, let’s first pinpoint a more fundamental and general
property, called <em>well-foundedness</em>, and reasoning principle,
<em>well-founded induction</em>, that the principle of infinite descent
can be based upon and even generalized, and use that to explain the
confusion. Along the way, we’ll produce a different explanation of proof
by infinite descent in terms of induction: an explanation that suits my
induction-happy brain better. Also, we’ll get the opportunity to
investigate induction itself: in particular, I want to demonstrate that
the common “base case/induction case” recipe for induction is a useful
but limiting view of how induction can be applied.</p>
<h2 id="well-foundedness-and-well-ordering">Well-foundedness and
Well-ordering</h2>
<p>As you might guess from the above two proofs, they depend on some
notion of “getting smaller”, and in the case of natural numbers the
default notion is the less-than relation <span>\(&lt;\)</span>, but less-than-ness is just an
example of a more general phenomenon. So first, let’s isolate the
property of <span>\(&lt;\)</span> on natural numbers
that really powers induction. A binary relation <span>\(\sqsubset\)</span> is called <em>well-founded</em>
if all leftward chains of the form <span>\(\dots
\sqsubset x_3 \sqsubset x_2 \sqsubset x_1\)</span> must be finite in
length, so there cannot exist any <em>infinite descending chains</em>.
The <span>\(&lt;\)</span> relation on natural
numbers has this property, because starting from any <span>\(n\)</span> and producing smaller numbers and
stopping whenever you want, you will always have to stop, either
necessarily at <span>\(0\)</span> or earlier by
choice. On the other hand, <span>\(&lt;\)</span>
extended to integers does not have this property because you can go
forever down the negative numbers, e.g., <span>\(\dots -16 &lt; -8 &lt; -4 &lt; -2\)</span>.
Luckily, <span>\(&lt;\)</span> isn’t the only binary
relation on integers! Here’s a different one that <em>is</em>
well-founded: if <span>\(z_1,z_2 \in
\mathbb{Z}\)</span>, say <span>\(z_1
\mathbin{\mathbin{\lvert&lt;\rvert}}z_2\)</span> if and only if <span>\(\lvert z_1\rvert &lt; \lvert z_2\rvert\)</span>,
where <span>\(\lvert z\rvert\)</span> denotes the
absolute value of <span>\(z\)</span> and <span>\(&lt;\)</span> is restricted to natural numbers.
Then <span>\(2
\mathbin{\mathbin{\lvert&lt;\rvert}}3\)</span> but also <span>\(-2 \mathbin{\mathbin{\lvert&lt;\rvert}}3\)</span>,
<span>\(2
\mathbin{\mathbin{\lvert&lt;\rvert}}{-3}\)</span>, and <span>\(-2
\mathbin{\mathbin{\lvert&lt;\rvert}}-3\)</span>: the sign of the integer
is ignored! Notice, though, that <span>\(2\)</span>
and <span>\(-2\)</span> are not related by <span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span> in
either direction. Since every leftward chain of the <span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span>
relation works its way toward <span>\(0\)</span>,
the center of the number line, we can see that all such chains must be
finite.</p>
<p>Since “well-ordering” and “well-founded” both start with “well-”, you
might suspect that there’s a relationship between them, and you’d be
right. Well-orderedness is described a variety of ways in the
literature, but for our purposes the following is the most relevant
formulation: a well-founded relation <span>\(\sqsubset\)</span> is a well-ordering if and only
if it relates every distinct pair of elements, i.e. <span>\(x_1 \neq x_2\)</span> implies either <span>\(x_1 \sqsubset x_2\)</span> or <span>\(x_2 \sqsubset x_1\)</span>. So based on what we’ve
observed, <span>\(&lt;\)</span> is well-ordered, but
<span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span> is
not (remember <span>\(2\)</span> and <span>\(-2\)</span>?).</p>
<p>To tie up a loose terminological end, consider the “-ordering” and
“-founded” suffixes. Well-orderings must be transitive: if <span>\(x_1 \sqsubset x_2\)</span> and <span>\(x_2 \sqsubset x_3\)</span> then <span>\(x_1 \sqsubset x_3\)</span>. The consequent must
hold because if it didn’t, then totality would force <span>\(x_3 \sqsubset x_1\)</span>, but that would
introduce a three-element cycle <span>\(\dots
\sqsubset x_3 \sqsubset x_1 \sqsubset x_2 \sqsubset x_3\)</span> and
break well-foundedness. Then, given some well-ordering <span>\(\sqsubset\)</span>, extending it to the relation
<span>\(\sqsubseteq\)</span>, which extends <span>\(\sqsubset\)</span> to be reflexive, is a <em>total
order</em>, i.e., a partial order (reflexive, transitive, antisymmetric
relation) that is also total. On the other hand, a well-founded relation
does not have to be transitive, let alone total, so extending one in
this manner is not even guaranteed to get you a partial order, let alone
a total one. Hence the suffix “-founded”.</p>
<h2 id="proof-by-infinite-descent-generalized">Proof by Infinite
Descent, Generalized</h2>
<p>Now that we have some grasp of well-foundedness, and why
well-orderedness is a red herring, Let’s use it to state the Principle
of Proof by Infinite Descent precisely and generally.</p>
<blockquote>
<p><strong>Theorem: Principle of Infinite Descent</strong><br>
Let <span>\(X\)</span> be a set and <span>\(\sqsubset\)</span> a well-founded relation on
<span>\(X\)</span>. Furthermore let <span>\(\Phi(x)\)</span> be some property of elements
<span>\(x\)</span> of <span>\(X\)</span>. Then if for every <span>\(x\)</span> in <span>\(X\)</span>, <span>\(\Phi(x)\)</span> implies <span>\(\Phi(y)\)</span> for some <span>\(y \sqsubset x\)</span>, it follows that <span>\(\Phi(x)\)</span> does not hold for any <span>\(x\)</span> in <span>\(X\)</span>.</p>
<p>Stated in formal logical notation: <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \sqsubset x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span></p>
</blockquote>
<p>The premise of the principle formalizes the idea that “no matter
where you are (which x), you can still make a ’descending’ step.”, and
the conclusion is that “well, if so then your property can’t apply to
any x: it leads to contradiction.” Arguably a better name for the
principle would be Proof by <em>No</em> Infinite Descent (thanks to
Andrej for this observation!).</p>
<p>Our proof that <span>\(\sqrt{2}\)</span> is not
rational implicitly applies this principle: Let <span>\(X\)</span> be the integers <span>\(\mathbb{Z}\)</span>; for integers <span>\(a,b\)</span>, let <span>\(a
\sqsubset b\)</span> be <span>\(a
\mathbin{\mathbin{\lvert&lt;\rvert}}b\)</span>; and let the property
<span>\(\Phi(a)\)</span> be “<span>\(a^2 = 2b^2\)</span> for some integer <span>\(b\)</span>” (formally, <span>\(\exists b\in \mathbb{Z}.\,a^2 = 2b^2\)</span>).
Assuming <span>\(a\)</span> and taking <span>\(b\)</span>, the proof uses division by <span>\(2\)</span> to produce a <span>\(c \mathbin{\mathbin{\lvert&lt;\rvert}}a\)</span>
for which some <span>\(d\)</span> satisfies the
equation. Having satisfied the premises of the principle, we use it to
deduce that no <span>\(a\)</span> satisfies the
property (though admittedly the prose proof shrouds this use of the
principle in squishy “forever is impossible” terminology).</p>
<p>The intuition for the principle is pretty straightforward: if the
premises hold, then in principle we can build an infinite descending
<span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span>-sequence
of integers that satisfy the property. But there are no such infinite
sequences, because we assumed that all of them must be finite, so a
contradiction must follow.</p>
<p>But let’s buttress this intuition with rigour. We can <em>prove</em>
this principle as a consequence of:</p>
<blockquote>
<p><strong>The Principle of Well-founded Induction</strong>: Let <span>\(X\)</span> be a set and <span>\(\sqsubset\)</span> a <em>well-founded
relation</em> on <span>\(X\)</span>. Then let <span>\(\Psi(x)\)</span> be some property of elements
<span>\(x\)</span> of <span>\(X\)</span>. Then if for every <span>\(x\)</span> in <span>\(X\)</span>, <span>\(\Psi(y)\)</span> holding for every <span>\(y \sqsubset x\)</span> suffices to prove <span>\(\Psi(x)\)</span>, it follows that <span>\(\Psi(x)\)</span> holds for every <span>\(x\)</span> in <span>\(X\)</span>.</p>
<p>Stated in formal logical notation: <span>\[(\forall x\in X.\, (\forall y \in X.\, y
\sqsubset x \implies \Psi(y)) \implies \Psi(x)) \implies  \forall x\in
X.\, \Psi(x).\]</span></p>
</blockquote>
<p>This principle is quite abstract, since it’s stated in terms of a
general principle. To clarify, let’s instantiate it with particular
well-founded relations that lead to principles with which we are
familiar. We already observed that <span>\(&lt;\)</span> is a well-founded relation on
natural numbers (because all well-orderings are also well-founded), we
can specialize well-founded induction to get what is often called
<em>strong mathematical induction</em> or <em>course-of-values
induction</em> on natural numbers: <span>\[(\forall
n\in \mathbb{N}.\, ((\forall m \in \mathbb{N}.\, m &lt;  n \implies
\Psi(m)) \implies \Psi(n)) \implies  \forall n\in \mathbb{N}.\,
\Psi(n).\]</span></p>
<p>The general structure of a proof by course-of-values induction is to
assume some natural number <span>\(n\)</span>, then
prove that assuming that <span>\(\Psi(m)\)</span>
holds for every number less than <span>\(n\)</span>
suffices to prove <span>\(\Psi(n)\)</span>.
Achieving that suffices to prove that <span>\(\Psi\)</span> holds for every natural number <span>\(n\)</span>. Observe that the assumption “<span>\(\Psi(m)\)</span> holds for every number less than
<span>\(n\)</span>” is what gets called an
“induction hypothesis”. In the common style of prose proofs, the
“induction hypothesis” often gets evoked in the middle of an argument,
and for a specific value, rather than explicitly assumed at the
beginning of the argument in full generality. To me this always seemed
to me to be some magical thing that got pulled out of the air in the
middle of the proof, leaving me unsure and about what kind of thing
induction even was. But in fact the induction hypothesis is just an
assumption that you make as you attempt to prove <span>\(\Psi(n)\)</span>, and its justification is hidden
in the proof of the principle of well-founded induction. Surprise: you
can prove induction principles correct, and devise and prove correct new
ones: they need not be taken as axioms!</p>
<p>Though students have often seen strong mathematical induction, they
are more familiar with plain ole’ mathematical induction, where the
“induction hypothesis” is to assume that a property holds for a natural
number one less than the current one. We can get this by using the
well-founded relation <span>\(n_1 &lt;_1
n_2\)</span> which holds if and only if <span>\(n_2
= n_1 + 1\)</span>. This relation is neither total nor an order since it
only ever relates abutting natural numbers. But, curiously enough, we
can still plug it into the Principle of Proof by Infinite Descent if we
want, and get something meaningful, albeit more restrictive, than using
<span>\(&lt;\)</span>.</p>
<p>Advertisement: I first learned about this perspective on induction
from Glynn Winskel’s excellent textbook, The Formal Semantics of
Programming Languages. I highly recommend it.</p>
<h2 id="what-even-is-a-base-case">What even is a “base case”?</h2>
<p>A common structure used in proofs that proceed by either mathematical
induction or course-of-values induction, or at least in teaching such
proofs, is to assume <span>\(n\)</span>, assume the
induction hypothesis, and then proceed by cases on whether <span>\(n = 0\)</span> or whether <span>\(n &gt; 0\)</span>. The first case gets called the
“base case” and is proven outright, and the second case gets called the
“inductive case” which exploits “the induction hypothesis” to complete
that case. When using induction more generally, as is common in PL
theory, this notion of base cases and induction cases gets emphasized as
well. However, it’s worth looking back at the principle of well-founded
induction and observing that nothing about that theorem forces a
particular case analysis, or restricts the availability of the premise
that gets called “the induction hypothesis”. The funny thing is that the
“base case” also has a perfectly fine induction hypothesis, but
typically it is useless because most of the time the proof in question
is not equipped to conjure an <span>\(m &lt;
n\)</span> with which to exploit it.</p>
<p>This template for applying the proof by course-of-values induction is
so common that often the split into base case vs. inductive case, where
the base case does not appeal to induction, gets baked right into the
explanation of the proof principle, as if it were part of the approach.
I find this categorical specialization to be unfortunate for two
reasons.</p>
<p>The first reason is that sometimes a proof needs a case split, but
this particular case split is <em>the wrong one</em>: in that it does
not help push the proof through. My favourite demonstration of this
phenomenon is a proof that any two positive natural numbers have a
greatest common divisor. This proof could be extended to integers, and
thus apply to Andrej’s proof as discussed above, but doing so would
deviate more from my main point than I would like. The proof involves a
helper lemma followed by a main theorem.</p>
<blockquote>
<p><strong>Lemma.</strong> For all positive natural numbers <span>\(a\)</span> and for all positive natural numbers
<span>\(b\)</span>, if <span>\(a
\geq b\)</span> then there exists a positive natural number <span>\(c\)</span> such that <span>\(xc = a\)</span> for some positive natural <span>\(x\)</span> and <span>\(yc =
b\)</span> for some positive natural <span>\(y\)</span>, and furthermore if <span>\(d\)</span> is a positive natural number that
satisfies these properties, then <span>\(c \geq
d\)</span>.</p>
</blockquote>
<p>This lemma can be proven by course-of-values induction. Then the
statement of the main theorem has the same structure, but does not
assume <span>\(a \geq b\)</span>. It can be proven
by splitting cases on whether <span>\(a \geq
b\)</span> or <span>\(b \geq a\)</span> and then
applying the lemma with the two numbers appropriately ordered (either
order will work if the numbers are equal).</p>
<p>I’m only going to give a sketch of the lemma’s proof, since it
suffices to make the relevant point. It proceeds by course-of-values
induction on <span>\(a\)</span> where the relevant
property of a is the substatement : “for all positive natural numbers
<span>\(b\)</span> ...” (now you know why I
explicitly separated the two variable quantifications in the prose
statement of the lemma). After assuming the induction hypothesis,
assuming <span>\(b\)</span> and assuming <span>\(a \geq b\)</span>, we proceed by cases on whether
<span>\(a = b\)</span> or <span>\(a &gt; b\)</span>. If <span>\(a = b\)</span> then we can show that the greatest
common divisor is the number itself, so <span>\(a\)</span>. If <span>\(a &gt;
b\)</span>, then we can show that the greatest common divisor of <span>\(a-b\)</span> and <span>\(b\)</span> is also the greatest common divisor of
<span>\(a\)</span> and <span>\(b\)</span>. However, to appropriately apply the
induction hypothesis, we must first determine which of <span>\(a-b\)</span> and <span>\(b\)</span> is larger: since <span>\(b\)</span> is positive, we know that <span>\(a-b &lt; a\)</span>, and we previously assumed
<span>\(b &lt; a\)</span>, so either can play the
role of “smaller <span>\(a\)</span>”, but to make
sufficient progress with the induction hypothesis, we need “next <span>\(b\)</span>” to be less than “smaller <span>\(a\)</span>”, so we split cases on whether <span>\(a-b &lt; a\)</span> or not, arbitrarily letting
the alternate case also handle <span>\(a-b =
a\)</span>.</p>
<p>The interesting part of the above proof is that two cases are
considered, and only one of them appeals to the induction hypothesis.
But the case that does not is not an <span>\(a=0\)</span> case as per the default template. In
fact <span>\(a = 0\)</span> could never apply since
we assumed that <span>\(a\)</span> is positive.</p>
<p>For exactness sake, it’s worth pointing out that one can perfectly
well devise a principle of course-of-values induction that applies to
just the positive integers, such that <span>\(a =
1\)</span> would be viewed as the “base case”. If we were to separate
out that case, we could deduce that <span>\(b =
1\)</span> because it must be a positive integer, and it must be less
than or equal <span>\(a\)</span>. So in practice,
the <span>\(a = 1\)</span> case can get handled
using the exact same reasoning as the other <span>\(a = b\)</span> cases, which happen to circumscribe
those situations where no appeal to an “induction hypothesis” is
required.</p>
<p>So the lesson to be drawn from my first gripe is that when performing
induction, if we reconceive of “base cases” to mean those cases that do
not appeal to an induction hypothesis, then such cases need not coincide
with the cases that involve the minimal elements of the well-founded
relation (or the unique minimum element of a well-ordered relation). For
many proofs the default heuristic helps, but that default is not a
universal law of induction.</p>
<h2 id="no-base-case-no-problem">No base case? no problem!</h2>
<p>To reiterate, my first problem with how course-of-values induction is
taught is that the default base-case/inductive-case split may not be the
most fruitful one. The second problem I have is that <em>you may not
even need such a split</em>. Usually it is assumed that there must be
some “base case”, that does not get to exploit the induction hypothesis,
for how could it ever apply? But in some proofs <em>you can always
exploit the induction hypothesis</em>. This is exactly the case in the
following proof of the Principle of Infinite Descent that uses the
Principle of Well-founded Induction.</p>
<p><strong>Theorem: Principle of Infinite Descent</strong> <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \sqsubset x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span></p>
<p><strong>Proof.</strong> Suppose <span>\((\forall
x\in X.\, \Phi(x) \implies \exists y \in X.\, y \sqsubset x \land
\Phi(y))\)</span>. Now we prove <span>\(\forall x\in
X.\, \neg\Phi(x)\)</span> by well-founded induction on <span>\(x\in X\)</span>. We will use as our predicate
<span>\(\Psi(x) := \neg\Phi(x)\)</span>, which is
synonymous with <span>\(\Phi(x) \implies
\bot\)</span>, i.e. <span>\(\Phi(x)\)</span> implies
contradiction. Suppose <span>\(x \in X\)</span>, and
suppose <span>\(((\forall y \in X.\, y \sqsubset x
\implies \neg\Phi(y))\)</span> At this point it suffices to show <span>\(\neg\Phi(x)\)</span>, for which it suffices to
assume <span>\(\Phi(x)\)</span> and deduce a
contradiction. So suppose <span>\(\Phi(x)\)</span>.
Now, applying our first assumption to this particular <span>\(x\)</span>, we learn <span>\(\Phi(x) \implies \exists y \in X.\, y \sqsubset x
\land \Phi(y))\)</span>, and combining this with our most recent
assumption, we learn that <span>\(\exists y \in X.\,
y \sqsubset x \land \Phi(y)\)</span>, so consider that <span>\(y \in X\)</span>. Since <span>\(y \sqsubset x\)</span>, we can use the induction
hypothesis to prove <span>\(\neg\Phi(y)\)</span>.
But we also have <span>\(\Phi(y)\)</span>, to which
we can apply <span>\(\neg\Phi(y)\)</span> to deduce
a contradiction. QED.</p>
<p>This proof of proof by infinite descent used course of values
induction, but did not need to consider distinct cases related to <span>\(x \in X\)</span>. There is no “base case” here, in
the sense that no part of the proof must be separately completed without
the help of an induction hypothesis. Now, when specialized to natural
numbers, one <em>could</em> do so, breaking out the <span>\(0\)</span> case and arguing directly that there is
no smaller number, without reference at all to <span>\(\Phi(x)\)</span>. Or more nebulously, we can split
on “minimal elements” versus “non-minimal elements”, but to what
end?</p>
<h2 id="part-way-back-around-without-proof-by-contradiction">Part way
back around, without proof by contradiction</h2>
<p>The following is a bonus: thanks to Andrej who made the observation
that inspired it.</p>
<p>We’ve proven that if <span>\(\sqsubset\)</span>
is well-founded, then principle of infinite descent applies. What about
the reverse? The answer is “it depends.” In particular, if you prefer to
work without proof by contradiction (i.e. constructively), then you can
only get part way there. But with some use of proof by contradiction,
you can get all the way there. In particular, we can prove that for an
arbitrary binary relation <span>\(R\)</span> on a
set <span>\(X\)</span>, if it satisfies the
statement of the principle of infinite descent, then it has no infinite
descending chains. Wait, isn’t that enough? Well, no, not in a world
where you want to work constructively, without proof by contradiction. I
sneakily defined well-foundedness as the assertion that all chains are
finite, which is a stronger statement than the assertion that there can
be no infinite descending chains, so long as you avoid proof by
contradiction. The positive conception is nice because it works in both
contexts, whereas “no infinite descending chains”, which is often taken
as the definition of well-foundedness in classical logic, does not.</p>
<p>Ok on to the proof. First, let’s get precise about descending chains.
Define a descending chain of a binary relation <span>\(R\)</span> to be a partial function <span>\(f : \mathbb{N} \rightharpoonup X\)</span> such
that for all natural numbers <span>\(n\)</span>, if
<span>\(f(n+1)\)</span> is defined, then so is <span>\(f(n)\)</span>, and furthermore <span>\(f(n+1) \mathrel{R} f(n)\)</span>. Then an infinite
descending chain is a descending chain that is defined for every natural
number <span>\(n\)</span>.</p>
<p>Now, we can prove that if <span>\(R\)</span> is
an arbitrary binary relation (rather than a well-founded onw) that
nonetheless satisfies the letter of the principle of infinite descent,
then <span>\(R\)</span> has no infinite descending
chains.</p>
<p><strong>Proof</strong>. Suppose <span>\(R
\subseteq X\times X\)</span>, and suppose that for any property <span>\(\Phi(x)\)</span>: <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \mathrel{R} x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span> Then it suffices to assume <span>\(f : \mathbb{N} \to X\)</span> is an infinite
descending chain and then deduce a contradiction. To do so, it further
suffices to let <span>\(\Phi(x) := \exists
n\in\mathbb{N}.f(n)=x\)</span> and prove the premise of the
proof-by-infinite-descent-shaped assumption, because from that we can
deduce that <span>\(\forall x\in X.\neg\exists n\in
N.\,f(n)=x\)</span>, (i.e. <span>\(f\)</span> is
totally undefined, the empty partial function) which combined with <span>\(x = f(0)\)</span> and <span>\(n = 0\)</span> suffices to deduce a
contradiction.</p>
<p>Let’s prove the sufficient condition: suppose <span>\(x \in X\)</span> and <span>\(\Phi(x)\)</span>, i.e. that <span>\(f(n) = x\)</span> for some <span>\(n \in \mathbb{N}\)</span>. Then <span>\(\Phi(f(n+1)\)</span> holds, and by assumption
<span>\(f(n+1) \mathrel{R} f(n)\)</span>, which can
be combined to prove the existential conclusion. QED.</p>
<h2 id="coda">Coda</h2>
<p>According to John Stillwell’s Elements of Algebra (Section 2.10),
Blaise Pascal was “the first to use induction in the ’base case,
induction step’ format” in a paper from 1654. But our modern
understanding of induction has it’s origins in Richard Dedekind’s
seminal 1888 book “Was sind und was sollen die Zahlen?” (sometimes
translated “What are the numbers and what are they for?”). Many
defaults—be they notation, techniques, and explanations—in mathematics
have historical origins that precede a more sophisticated understanding
of phenomena, and sometimes an impedance mismatch between the historical
and the modern can limit our understanding (treatment of variables and
functions by mathematical texts is one of my standard whipping horses,
but that’s a topic for another day). Those perspectives persist because
they were useful, and are still useful today, but it also helps to
consider how they might best be incorporated with those refined
conceptions we’ve gained since their inception.</p>
<p>As for the <em>use</em> of proof by infinite descent versus a proof
like Andrej’s that argues directly from minimality, one could reasonably
argue that explicitly calling out the existence of a minimal case is
more intuitively graspable for some arguments. It’s not clear to me
whether arguing from the perspective of “there must be one or more
minimal cases” versus “you can’t go down this way forever” is more
generally clear, especially once you have come to understand proof by
infinite descent. Furthermore, in the case of general well-foundedness,
there may not be <em>a</em> single smallest case, but rather a
(possibly) infinite number of minimal cases, in which case calling all
of them out abstractly may be less compelling than calling out a
singular minimum as was the case (pun intended) for the natural numbers.
Which argument is most enlightening probably depends on personal
taste.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Many thanks to Andrej Bauer for feedback on this post!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Venezuela is first Andean country to lose all of its glaciers (115 pts)]]></title>
            <link>https://www.nbcnews.com/news/latino/-great-sadness-venezuela-first-andean-country-lose-glaciers-rcna153784</link>
            <guid>40850313</guid>
            <pubDate>Mon, 01 Jul 2024 20:30:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/news/latino/-great-sadness-venezuela-first-andean-country-lose-glaciers-rcna153784">https://www.nbcnews.com/news/latino/-great-sadness-venezuela-first-andean-country-lose-glaciers-rcna153784</a>, See on <a href="https://news.ycombinator.com/item?id=40850313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the people of the Venezuelan state of Mérida, the glaciated peaks of its Sierra Nevada have been a source of pride since time immemorial: The mountains are part of the regional identity and the origin of various&nbsp;<a href="https://translate.google.com/website?sl=es&amp;tl=en&amp;hl=en&amp;client=webapp&amp;u=http://www.saber.ula.ve/bitstream/handle/123456789/49064/art.2_Cinco_Aguilas_Blancas.pdf?sequence%3D5%26isAllowed%3Dy" target="_blank">legends in the area</a>&nbsp;that relate them to mythical white eagles. </p><p>However, none of the six glaciers that crowned the mountains remain.</p><p>The International Climate and Cryosphere Initiative (ICCI), a science advocacy organization, recently declared that the Humboldt Glacier — also known as La Corona, or "the crown" in Spanish — is already "too small to be classified as a glacier.” In March, Venezuelan scientists had warned that the glacier had dramatically shrunk. </p><p>"Our tropical glaciers began to disappear since the '70s and their absence is felt. It is a great sadness and the only thing we can do is use their legacy to show children how beautiful our Sierra Nevada was,” Alejandra Melfo, an astrophysicist at the Universidad de los Andes in Mérida, said in an interview with Noticias Telemundo.</p><p>Venezuela had six glaciers in the Sierra Nevada, located about 16,000 feet above sea level. By 2011, five had already disappeared, but the Humboldt Glacier located near the second highest mountain in the country, Humboldt Peak, resisted the onslaught of the weather. Scientists believe its disappearance makes Venezuela the first country in the Americas — and the first country in modern history — to lose all its glaciers.</p><p>Glaciers are large masses of ice that have formed due to the accumulation of snow over centuries. According to the United States Geological Survey (USGS), they typically exist where average annual temperatures reach near-freezing levels and winter precipitation causes significant accumulations of&nbsp;snow.</p><p>An important aspect of glacier development is that temperatures during the rest of the year should not cause the complete loss of the previous winter’s snow accumulation, this is how glaciers are maintained and how they grow. And that’s what failed in the Humboldt case.</p><p>"In the case of the Humboldt, it's a process of erosion that has been going on for years without stopping," Melfo said. </p><p>With the increase in global temperatures due to climate change, the melting of large ice masses is a continuous phenomenon that, among other things, contributes to raising sea levels around the world.</p><p>"It is the end of a glacial cycle. And in the intertropical zones, basically below 5,000 meters, almost all the glaciers have been disappearing," said Maximiliano Bezada, a geological researcher at the University of Minnesota. "The case of Humboldt was iconic because it is at 4,800 meters and yet it remained for quite a long time, and that is a climatic anomaly."</p><p>Although the Humboldt Glacier was expected to last at least another decade, scientists had been unable to monitor the area where it's  located due to the country’s political turmoil.</p><p>“Venezuela’s glaciers are not the first to disappear, some have disappeared in Colombia and other countries. What happens is that Venezuela had few and all in the Sierra Nevada, I saw how the glaciers of Pico La Concha and Pico Bolívar disappeared. That is why it is the first country to run out of glaciers,” Melfo said.</p><h2>'The consequences of higher temperatures'</h2><p>Due to their large mass, glaciers tend to flow like very slow rivers. Although there is no universal consensus on how large an ice mass must be to be considered a glacier, the USGS states that a commonly accepted standard is about 25 acres. </p><p>The case of the Humboldt glacier is not the only one. Glaciers around the world are shrinking, and some are disappearing faster in defiance of scientific projections. A&nbsp;<a href="https://translate.google.com/website?sl=es&amp;tl=en&amp;hl=en&amp;client=webapp&amp;u=https://www.science.org/doi/10.1126/science.abo1324" target="_blank">2023 study</a>&nbsp;analyzed the planet’s 215,000 terrestrial glaciers more comprehensively than previous research and concluded that, if temperatures continue to increase, 83% of the world’s glaciers will be gone by the year 2100.</p><p>“Although the end of the glacier was something that was going to happen due to the cycle we are experiencing, there is no doubt that global warming, a product of greenhouse gases, has of course accelerated the disappearance process,” Bezada said.</p><p>Between 1952 and 2019 alone, Venezuela’s glacier surface went from 2,317 square kilometers to just 0.046 square kilometers, according to&nbsp;<a href="https://translate.google.com/website?sl=es&amp;tl=en&amp;hl=en&amp;client=webapp&amp;u=https://www.tandfonline.com/doi/full/10.1080/15230430.2020.1822728" target="_blank">a 2020 study</a>.</p><p>“There are several projects that monitor change in the Sierra Nevada with temperature sensors buried in the ground and that are measured every six months. The evidence shows warming, in addition, the plants that grow there are changing because climate change is already felt in the peaks of the Andes,” Melfo said.</p><p>Researchers believe that the El Niño climate phenomenon influenced the melting of the Humboldt Glacier, because it causes warmer temperatures that accelerate the disappearance of tropical glaciers.</p><p>“The speed at which glaciers are melting is evidence of climate change. However, this is not new. Glaciers began to disappear a long time ago, but the speed has changed due to high temperatures," Melfo said. "Beyond the glaciers, we are seeing rapid changes in the composition of species, plants and animals, and this is recorded. Denying climate change has become a very dangerous thing for everyone."</p><p>The Andes region — a mountain range running through parts of Argentina, Bolivia, Chile, Colombia, Ecuador, Peru and Venezuela — has seen a temperature rise of at least 0.10 degrees Celsius over the past seven decades. For several scientists, that is one of the main reasons why Venezuela has lost all its glaciers.</p><p>“In the Andean zone of Venezuela, there have been some months with monthly anomalies above average, which is exceptional in those tropical latitudes,” said Maximiliano Herrera, climatologist and weather historian.</p><p>However, the melting of the glacier is also an opportunity for further study. Melfo said that the end of the glacier in Venezuela marks the beginning of a new process in the area and an event that will have to be investigated.</p><p>"Life starts to rise and colonize the rock. The lichens come first, then the mosses create the soil, organic matter is created and that creates conditions for the plants to arrive, and then the animals come. This is how an ecosystem is assembled; it's called primary succession and it is a unique process," she said. </p><p>Meanwhile, what little ice remains on Humboldt will continue to melt. Residents of Mérida, including Melfo, say the glacier will continue to exist as long as the white vestiges can be seen from the city — which stopped happening with the other glaciers.</p><p>“For the people of Mérida, perhaps the most beloved glacier was that of Pico Bolívar, which since 2012 was a remnant of a glacier. However, people continued to say that it was a glacier until the last bit of ice that could be seen from the city disappeared in 2020," Melfo said. "I think the same thing is going to happen with the Humboldt: until the last piece disappears, we are going to continue saying that it is a glacier."</p><p><a href="https://www.telemundo.com/noticias/noticias-telemundo/medio-ambiente/glaciar-humboldt-venezuela-rcna153532" target="_blank">An earlier version of this story was first published in Noticias Telemundo.</a></p><br></div><div data-activity-map="expanded-byline-article-bottom"><p><span data-testid="byline-thumbnail"></span><span data-testid="byline-name">Albinson Linares, Noticias Telemundo</span><span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When RAND made magic in Santa Monica (117 pts)]]></title>
            <link>https://asteriskmag.com/issues/06/when-rand-made-magic-in-santa-monica</link>
            <guid>40849840</guid>
            <pubDate>Mon, 01 Jul 2024 19:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/06/when-rand-made-magic-in-santa-monica">https://asteriskmag.com/issues/06/when-rand-made-magic-in-santa-monica</a>, See on <a href="https://news.ycombinator.com/item?id=40849840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Pradyumna Prasad</span>
				   
					<span>Jordan Schneider</span>
							</h2>
			</section>
	
			<section id="rangyscope">
					<p>RAND’s halcyon days lasted two decades, during which the corporation produced some of the most influential developments in science and American foreign policy. So how did it become just another think tank?</p>
				<div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/06/when-rand-made-magic-in-santa-monica/e8f33b9ca6-1719845677/zebu.png" alt="">
  </p>
    <p>
    ZEBU  </p>
  </figure>
</div>
											<div><p>Between 1945 and 1960, RAND operated as the world’s most productive research organization. Initially envisioned as a research arm of the Air Force, RAND made century-defining breakthroughs both in basic science and applied strategic analysis. Its members helped define U.S. <a href="https://www.rand.org/pubs/commercial_books/CB137-1.html" rel="noopener noreferrer">nuclear strategy</a>, <a href="https://www.rand.org/pubs/special_memoranda/SM11827.html" rel="noopener noreferrer">conceptualized satellites</a>, pioneered systems analysis, and developed the <a href="https://www.rand.org/pubs/papers/P2926.html" rel="noopener noreferrer">earliest reports on defense economics</a>. They also revolutionized much of STEM: RAND scholars developed the basics of game theory, linear programming, and <a href="https://www.rand.org/pubs/papers/P766.html" rel="noopener noreferrer">Monte Carlo methods</a>. They helped <a href="https://www.thetripreport.com/p/psychedelic-winter-ai-spring" rel="noopener noreferrer">conceptualize generalized artificial intelligence</a>, developed the <a href="https://www.rand.org/about/history/baran.html" rel="noopener noreferrer">basics</a> for packet switching (which enables data transmission across networks), and built <a href="https://en.wikipedia.org/wiki/JOHNNIAC" rel="noopener noreferrer">one of the world’s first computers</a>.</p><p>Today, RAND remains a successful think tank — by some metrics, among the world’s best.<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
 In 2022, it brought in over $350 million in revenue, and large proportions still come from contracts with the US military. Its graduate school is among the largest for public policy in America.&nbsp;</p><p>But RAND’s modern achievements don’t capture the same fundamental policy mindshare as they once did. Its military reports may remain influential, but they hold much less of their early sway, as when they forced the U.S. Air Force to rethink several crucial assumptions in defense policy. And RAND’s fundamental research programs in science and technology have mostly stopped. Gone are the days when one could look to U.S. foreign policy or fundamental scientific breakthroughs and trace their development directly back to RAND.&nbsp;</p><p>How was magic made in Santa Monica? And why did it stop?&nbsp;</p></div>
											<p><h2>The Roots of RAND</h2>
</p>
											<div><p>Economists, physicists, and statisticians — civilian scientists to that point not traditionally valued by the military — first proved their utility in the late stages of World War II operational planning. American bomber units needed to improve their efficiency over long distances in the Pacific theater. The scientists hired by the Army Air Force proposed what at the time seemed a radical solution: removing the B-29 bomber’s armor to reduce weight and increase speed. This ran counter to USAAF doctrine, which assumed that an unprotected plane would be vulnerable to Japanese air attacks. The doctrine proved incorrect. The increased speed not only led to greater efficiency, it also led to more U.S. planes returning safely from missions, as Japanese planes and air defense systems were unable to keep up.<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
 Civilian scientists were suddenly in demand. By the end of the war, all USAAF units had built out their own operations research departments to optimize battle strategy. When the war ended, the question turned to how to retain the scientific brain trust it had helped to assemble.&nbsp;</p><p>General Henry “Hap” Arnold, who had led the Army Air Force’s expansion into the most formidable air force in the world, had started to consider this question long before the war had ended. He found an answer in September 1945, when Franklin Collbohm, a former test pilot and executive at Douglas Aircraft, walked into Arnold’s office with a plan: a military-focused think tank staffed by the sharpest civilian scientists. Collbohm did not have to finish describing his idea before Arnold jumped and agreed. Project RAND was born.</p><p>Arnold, along with General Curtis LeMay — famous for his “strategic bombing” of Japan, which killed hundreds of thousands of civilians — scrounged up $10 million from unspent war funds to provide the project’s seed money, which was soon supplemented with a grant from the Ford Foundation. This put RAND into a privileged position for a research organization: stably funded.&nbsp;</p><p>On top of that financial stability, RAND built what would become one of its greatest organizational strengths: a legendarily effective culture, and a workforce to match it.</p></div>
											<p><h2>Internal Culture and Talent</h2>
</p>
											<div><p>In an <a href="https://www.rand.org/pubs/drafts/DRU218.html" rel="noopener noreferrer">internal memo</a>, <a href="https://en.wikipedia.org/wiki/Bruno_Augenstein" rel="noopener noreferrer">Bruno Augestein</a>, a mathematician and physicist whose research on ballistic missiles helped usher in the missile age, highlighted a set of factors that catalyzed RAND’s early success. In short: RAND had the best and brightest people working with the best computing resources in an environment that celebrated excellence, welcomed individual quirks, and dispensed with micromanagement and red tape.</p><p>Early RAND leadership was, above all else, committed to bringing in top talent and jealously guarded the sort of intellectual independence to which their academic hires were accustomed. Taking the mathematics department as an example, RAND hired <a href="https://www.nytimes.com/1964/11/22/archives/john-williams-55-a-rand-researcher.html" rel="noopener noreferrer">John Williams</a>, <a href="https://en.wikipedia.org/wiki/Ted_Harris_(mathematician)" rel="noopener noreferrer">Ted Harris</a>, and <a href="https://www.nytimes.com/1988/06/08/obituaries/edward-s-quade-79-was-rand-researcher.html" rel="noopener noreferrer">Ed Quade</a> to run it. While these were accomplished mathematicians in their own right, these three were also able to attract superlative talents to work under and around them. As Alex Abella writes in <em>Soldiers of Reason</em>, his history of RAND, “No test for ideological correctness was given to join, but then none was needed. The nation’s best and brightest joining RAND knew what they were signing on for, and readily accepted the vision of a rational world — America and its Western allies — engaged in a life-and-death struggle with the forces of darkness: the USSR.”&nbsp;</p><p>As the Cold War intensified, the mission became the sell. The aim of RAND, as the historian David Hounshell has it, “was nothing short of the salvation of the human race.”<sup>
    <!-- <a id="fnref-3" href="#fn-3"> -->
    <span id="fnref-3">
        3    </span>
    <!-- </a> -->
</sup>
 The researchers attracted to that project believed that the only environment in which that aim could be realized was independent of the Air Force, its conventional wisdom, and — in particular — it’s conventional disciplinary boundaries</p><p>RAND’s earliest research aligned with the USAF’s (the Army Air Force had become its own service branch in 1947) initial vision: research in the hard sciences to attack problems like satellite launches and nuclear-powered jets.<sup>
    <!-- <a id="fnref-4" href="#fn-4"> -->
    <span id="fnref-4">
        4    </span>
    <!-- </a> -->
</sup>
 However, the mathematician John Davis Williams, Collbohm’s fifth hire, was convinced that RAND needed a wider breadth of disciplines to support the Air Force’s strategic thinking. He made the case to General LeMay, who supervised RAND, that the project needed “every facet of human knowledge to apply to problems.”<sup>
    <!-- <a id="fnref-5" href="#fn-5"> -->
    <span id="fnref-5">
        5    </span>
    <!-- </a> -->
</sup>
 To that end, he argued for recruiting economists, political scientists, and every other kind of social scientist. LeMay, once convinced, implored Williams to hire whoever it took to get the analysis right.</p><p>And so they did. RAND’s leadership invested heavily in recruiting the best established and emerging talent in academia. An invitation-only conference organized by Williams in New York in 1947 brought together top political scientists (Bernard Brodie), anthropologists (Margaret Mead), economists (Charles Hitch), sociologists (Hans Speier), and even a screenwriter (Leo Rosten). The promise of influence, exciting interdisciplinary research, and complete intellectual freedom drew many of the attendees to sign up.</p><p>Within two years, RAND had assembled 200 of America’s leading academics. The top end of RAND talent was (and would become) full of past (and future) Nobel winners, and Williams worked around many constraints — and eccentricities — to bring them on. For instance, RAND signed a contract with John von Neumann to produce a general theory of war, to be completed during a small slice of his time: that spent shaving. For his shaving thoughts, von Neumann received $200 a month, an average salary at the time.&nbsp;</p><p>Beyond the biggest names, RAND was <a href="https://www.rand.org/pubs/drafts/DRU218.html" rel="noopener noreferrer">“deliberate, vigorous, and proactive” in recruiting the “first-rate and youthful staff”</a> that made up most of its workforce. The average age of staff in 1950 was under 30.<sup>
    <!-- <a id="fnref-6" href="#fn-6"> -->
    <span id="fnref-6">
        6    </span>
    <!-- </a> -->
</sup>
 Competition between them helped drive the culture of excellence. Essays and working papers were passed around for comments, which were copious — and combative. New ideas had to pass “murder boards.” And the competition spilled into recreational life: Employees held tennis tournaments and boating competitions. James Drake, an aeronautical engineer, <a href="https://www.rand.org/about/faq.html%23:~:text=RAND%2520invented%2520windsurfing,%25E2%2580%259Cthe%2520father%2520of%2520windsurfing.%25E2%2580%259D" rel="noopener noreferrer">invented the sport of windsurfing</a>. The wives of RAND employees —&nbsp;who were, with a few notable exceptions, almost all male — even competed through a cooking club where they tried to make the most "exotic" recipes.</p><p>After bringing in such extraordinary talent, RAND’s leadership trusted them to largely self-organize.<strong> </strong>Department heads were given a budget and were free to spend it as they felt fit. They had control over personnel decisions, which allowed them the flexibility to attract and afford top talent. As a self-styled “university without students,” RAND researchers were affiliated with departments with clear disciplinary boundaries, which facilitated the movement of researchers between RAND and academia. But in practice, both departments and projects were organized along interdisciplinary lines.&nbsp;</p><p>The mathematics department brought on an anthropologist. The aeronautics department hired an MD. This hiring strategy paid off in surprising ways. For instance, while modeling the flow of drugs in the bloodstream, a group of mathematicians <a href="https://www.rand.org/pubs/papers/P2236-1.html" rel="noopener noreferrer">stumbled upon a technique</a> to solve a certain class of differential equations that came to be used in understanding the trajectory of intercontinental ballistic missiles.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/06/when-rand-made-magic-in-santa-monica/6610eda1e6-1712608223/editorial-whatever-works.gif" alt="">
  </p>
    <p>
    The caption of this image, from the May 11, 1959, issue of <em>Life</em> magazine, reads: ‘After-hours workers from RAND meet in home of Albert Wohlstetter (foreground), leader of RAND’s general war studies. They are economists gathered to discuss study involving economic recovery of U.S. after an all-out war.’ Leonard McCombe / The LIFE Picture Collection via Getty Images.  </p>
  </figure>
</div>
											<p><h2><strong>Finding an Institutional Footing&nbsp;</strong></h2>
</p>
											<div><p>RAND was at the forefront of a postwar explosion in federal funding for science. Hundreds of millions of dollars poured into universities, think tanks, and industrial R&amp;D labs. Almost all of it was directed toward one purpose: maintaining military superiority over the Soviet Union. In 1950, over 90% of the federal research budget came from just two agencies: the Atomic Energy Commission and the Department of Defense.<sup>
    <!-- <a id="fnref-7" href="#fn-7"> -->
    <span id="fnref-7">
        7    </span>
    <!-- </a> -->
</sup>
 Significant portions of this funding went toward basic research with no immediate military applications.<sup>
    <!-- <a id="fnref-8" href="#fn-8"> -->
    <span id="fnref-8">
        8    </span>
    <!-- </a> -->
</sup>
 Vannevar Bush, the influential head of the war-era Office of Scientific Research and Development, had argued for this approach in his 1945 book <em>Science, the Endless Frontier</em>: Freeing up scientists to follow their own research interests would inevitably lead to more innovation and ensure American technological dominance. Bush’s was not the only, or even the dominant, view of how postwar science should be organized —&nbsp;most science funding still went toward applied research — but his views helped inform the organization of a growing number of research institutions.<sup>
    <!-- <a id="fnref-9" href="#fn-9"> -->
    <span id="fnref-9">
        9    </span>
    <!-- </a> -->
</sup>
</p><p>No organization embodied this model more than RAND. Air Force contracts were the financial backbone of the organization. They provided the money required to run RAND, while profits were used to fund basic research. In the 1950s, USAF contracts comprised 56% of RAND’s work, while other sponsors made up just 7%.<sup>
    <!-- <a id="fnref-10" href="#fn-10"> -->
    <span id="fnref-10">
        10    </span>
    <!-- </a> -->
</sup>
 That left more than a third of RAND’s capacity open to pursue its own agenda in basic research. Many of the developments made there would be used in their applied research, making it stronger — and more profitable — in the process. This flywheel would become critical to RAND’s success.<strong>&nbsp;</strong></p><p>Not all of these developments were successful, especially at first. RAND’s early research efforts in systems analysis — an ambitious pursuit in applying mathematical modeling that RANDites were optimistic could produce a holistic “science of warfare” — were flops. The first project, which aimed to optimize a strategic bombing plan on the Soviet Union, used linear programming, state-of-the-art computing, and featured no fewer than 400,000 different configurations of bombs and bombers. It proved of little use to war planners. Its assumptions fell prey to the “specification problem:” trying to optimize one thing, in this case, calculating the most damage for the least cost led to misleading and simplistic conclusions.<sup>
    <!-- <a id="fnref-11" href="#fn-11"> -->
    <span id="fnref-11">
        11    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>But RAND would soon find its footing, and a follow up to this work became a classic of the age. The 1954 paper <em>Selection and Use of Strategic Air Bases</em> proved the value of RAND’s interdisciplinary approach — though its conclusions were at first controversial. Up to the 1950s, there had been little analysis of how the Strategic Air Command, responsible for the United States’s long range bomber and nuclear deterrent forces, should use its Air Force bases. At the time, the SAC had 32 bases across Europe and Asia. The study, led by political scientist Albert Wohlstetter, found that the SAC was dangerously vulnerable to a surprise Soviet attack. The SAC’s radar defenses wouldn’t be able to detect low-flying Soviet bombers, which could reduce American bombers to ash — and thereby neutralize any threat of retaliation — before the Americans had a chance to react. Wohlstetter’s study recommended that the SAC keep its bombers in the U.S., dispersed at several locations to avoid concentration at any place.&nbsp;</p><p>LeMay, RAND’s original benefactor and commander of the SAC, resisted Wohlstetter’s conclusions. He worried the plan would reduce his control over the country’s nuclear fleet: With the SAC based in the U.S., LeMay would have to cede some authority to the rest of the U.S. Air Force. He pushed against it many times, proposing several alternatives in which the SAC kept control over the bombers, but no plan fully addressed the vulnerabilities identified by the report.&nbsp;</p><p>Undaunted — and sure of his logic — Wohlstetter pushed his conclusions even further. He proposed a fail-safe mechanism, where nuclear bombers would have to receive confirmation of their attack from multiple checkpoints along the way, to prevent rogue or mistaken orders from being followed. Wohlstetter went around LeMay, to Defense Secretary Charles Wilson and General Nathan Twining, chairman of the Joint Chiefs of Staff, who ultimately accepted the study’s recommendations in full. It took over two decades, but they proved their value in 1980 when a faulty chip erroneously warned of an impending Soviet strike. While no order for a retaliatory attack was issued, had there been one, the fail-safe mechanism would have prevented the bombers from actually attacking the USSR. <em>Selection and Use of Strategic Air Bases</em> was a triumph for RAND. Not only had they provided correct advice to the USAF, they had also proved their independence from the institution’s internal politics.</p><p>And the flywheel would prove its value many times over. RAND’s basic research helped drive the development and strategy of ICBMs, the launch of the first meteorological satellite, and, later, on cost reductions in ICBM launch systems.</p></div>
											<p><h2>Diversification and Decline</h2>
</p>
											<div><p>RAND’s conclusions ran counter to USAF doctrine several times — and each time RAND fought to maintain its independence. When the USAF commissioned RAND to study the <a href="https://en.wikipedia.org/wiki/UGM-27_Polaris" rel="noopener noreferrer">Navy’s Polaris program</a> — in order to show that it was inferior to the Air Force’s bombers for nuclear weapon delivery — RAND found that the Polaris missiles were, in fact, superior. The same happened <a href="https://www.rand.org/pubs/corporate_pubs/CP564.html" rel="noopener noreferrer">with another study</a>, which challenged the effectiveness of the B-70 bomber in 1959.</p><p>Over time, however, these tensions added friction to the relationship. To make matters worse, between 1955 and 1960, the <a href="https://www.rand.org/content/dam/rand/pubs/reports/2009/R3807.pdf" rel="noopener noreferrer">USAF’s budget declined</a> in both absolute terms, and relative to the rest of the defense community. In 1959, the Air Force froze RAND’s budget, presumably due to the budget cuts — and their disputes with RAND.&nbsp;</p><p>This situation was not unique to the USAF, or to RAND. As the 1950s rolled into the ’60s, scientists at civilian institutions increasingly moved to disentangle themselves from their military benefactors. Throughout the decade, DOD funding for basic research would only continue to decline.<sup>
    <!-- <a id="fnref-12" href="#fn-12"> -->
    <span id="fnref-12">
        12    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>RAND weathered the transition by successfully seeking out new customers — the AEC, ARPA, the Office of the Comptroller, the Office of the Assistant Secretary of Defense for International Security Affairs (ISA), NASA, the NSF, the NIH, and the Ford Foundation, to name a few. The percent of the outside funding coming from the USAF dropped from 95% when RAND started to 68% in 1959.<sup>
    <!-- <a id="fnref-13" href="#fn-13"> -->
    <span id="fnref-13">
        13    </span>
    <!-- </a> -->
</sup>
 But their success came at a cost: This diversification is what led to RAND losing its edge in producing the cutting edge of policy and applied science.</p><p>Funding diversification reshaped both RAND’s culture and output. The increased number of clients made scheduling researchers’ work harder. Each client expected a different standard of work, and the tolerance levels for RAND’s previously freewheeling style varied. The transaction costs of starting a new contract were much higher and the flexible staffing protocols that had worked for the USAF in the 1950s needed to be systematized. The larger organization led to ballooning internal administration expenses.</p><p>Along with all of this, RAND’s increased size attracted more political detractors. In 1958, a RAND paper called <em><a href="https://www.rand.org/content/dam/rand/pubs/reports/2007/R308.pdf" rel="noopener noreferrer">Strategic Surrender</a></em>, which examined the historical conditions for surrender, had generated a political firestorm. Politicians were furious with RAND for exploring conditions under which it would be strategic for the U.S. to surrender. Senators weren’t particularly interested in the study itself, but those who wanted to run for president (like Stuart Symington of Missouri) <a href="https://ciaotest.cc.columbia.edu/olj/ad/ad_v9_2/swj01.html" rel="noopener noreferrer">used it as evidence</a> that the Eisenhower administration was weak on defense.&nbsp;</p><p>The Senate even passed a resolution (with an 88–2 margin) prohibiting the use of federal funds for studying U.S. surrender. RAND’s management, realizing that an intentional misinterpretation of their work potentially threatened future funding streams, now had to consider the wider domestic political context of their work. All of these factors changed RAND’s culture from one that encouraged innovation and individuality to one that sapped creativity.&nbsp;</p><p>But the biggest change was yet to come. In 1961, Robert McNamara took over the Department of Defense and brought with him a group of RAND scholars, commonly called the “Whiz Kids.” Their most important long-term contribution to U.S. governance was the Planning-Programming-Budgeting System. PPBS took a Randian approach to resource allocation, namely, modeling the most cost-effective ways to achieve desired outcomes. In 1965, after President Johnson faced criticism for poor targeting of his Great Society spending, he required nearly all executive agencies to adopt PPBS. Many RAND alumni were hired by McNamara and his team to help with the Great Society’s budgeting process.&nbsp;</p><p>In 1965, Henry Loomis, the deputy commissioner on education, approached RAND about conducting research on teaching techniques. Franklin Collbohm, RAND’s founder and then president, declined. He preferred that RAND stay within the realm of military analysis. RAND’s board disagreed and would eventually push Collbohm out of RAND in 1967. The board thought it was time for a change in leadership — and to RAND’s nonmilitary portfolio.&nbsp;</p><p>The <a href="https://web.archive.org/web/20220811023739/https://www.nytimes.com/2015/11/20/us/henry-s-rowen-professor-economist-and-ex-president-of-rand-dies-at-90.html" rel="noopener noreferrer">entry of a new president</a>, Henry S. Rowen, an economist who had started his career at RAND, cemented this change. By 1972, the last year of Rowen’s tenure, almost half of all RAND projects were related to social science. For better or worse, this eroded RAND’s ability to take on cutting-edge scientific research and development.&nbsp;</p><p>RAND entered domestic policy research with a splash — or, rather, a belly flop. The politics of social policy research were markedly different from working with the DOD. For one, there were substantially more stakeholders — and they were more vocal about voicing their disagreements. One crucial example is when RAND proposed police reforms in New York City, but pressure from the police unions forced them to retract.&nbsp;</p><p>John Lindsay, the Republican mayor of New York, had tasked RAND with improving the New York Police Department, which had recently been implicated in narcotics scams, corruption, and police brutality. The report showed that in less than 5% of the cases in which an officer was charged with a crime or abusing a citizen did the officers receive anything more than a reprimand. The findings were <a href="https://www.nytimes.com/1972/05/08/archives/study-here-suggests-police-rookies-with-poor-ratings-should-be.html" rel="noopener noreferrer">leaked to </a><em><a href="https://www.nytimes.com/1972/05/08/archives/study-here-suggests-police-rookies-with-poor-ratings-should-be.html" rel="noopener noreferrer">The New York Times</a></em>, which added to the impression among the police that RAND was the mayor’s mouthpiece.&nbsp;</p><p>RAND, for the first time, had to face the reality of <em>local</em> politics: a sometimes hostile environment, multiple stakeholders who sometimes acted in bad faith, and none of the free reign that characterized their first decades. RAND’s experience with the police report, and the controversy over the study of surrender, led RAND to be more conservative about the research it put out. And additionally, the focus on policy research crowded out the scientific research.&nbsp;</p><p>For example, beginning in the 1970s, <a href="https://www.rand.org/topics/mathematics.html?content-type=research&amp;page=5" rel="noopener noreferrer">RAND’s applied mathematics research</a> output slowed to a trickle, before stopping altogether in the 1990s. It was replaced by mathematics education policy. The same is true for <a href="https://www.rand.org/topics/physics.html?page=2" rel="noopener noreferrer">physics</a>, <a href="https://www.rand.org/topics/chemistry.html" rel="noopener noreferrer">chemistry</a>, and <a href="https://www.rand.org/topics/astronomy.html" rel="noopener noreferrer">astronomy</a>. Another emblematic development in the dilution of RAND’s focus was the founding in 1970 of the Pardee RAND Graduate School, the nation’s first Ph.D.-granting program in policy analysis. While the idea of training the next generation in RAND techniques is admirable, RAND in the early years explicitly defined itself as a “university without students.”</p><p>RAND is still an impressive organization. It continues to produce successful policy research, which commands the eyes of policymakers in over 82 federal organizations and across dozens of local and even foreign governments. Still, their work today is inarguably less groundbreaking and innovative than it was in the ’50s. This relative decline was partially caused by internal policy choices, and partially by the eventual loss of their initial team of leading scientists. But part of it was also inevitable: We no longer live in an era when branches of the U.S. military can cut massive blank checks to think tanks in the interests of beating the Soviets. The successes of 1950s RAND do come with lessons for modern research organizations —&nbsp;about the importance of talent, the relevance of institutional culture, and the possibilities of intellectual freedom —&nbsp;but the particular conditions that created them can’t be replicated. It is remarkable that they existed at all.&nbsp;</p></div>
										 
				</div>
		
	</section>
	 	<section>
		 		 <p><strong>Pradyumna Prasad</strong> authors the Bretton Goods substack and hosts the accompanying podcast. He is a first year undergraduate at the National University of Singapore.</p>		 		 		 <p><strong>Jordan Schneider</strong> is the creator of the ChinaTalk podcast and newsletter.</p>		 		 		 </section>
	 	<section>            
		<p>
			Published June 2024		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	
	<!--end published content, not coming soon-->

	<!--tags-->
		<section>
		<h4>Further Reading</h4>                
			<p>
				More:  
									<span data-no="tag-1">science</span>
									<span data-no="tag-2">history</span>
							</p>
			<!--related articles-->
			             
	</section>
	 
	
	  
	<p>Subscribe</p>
	<div id="signup-article-popup">
			
<p><img src="https://asteriskmag.com/assets/img/asterisk_x.png">
		</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Git story: Not so fun this time (120 pts)]]></title>
            <link>https://blog.brachiosoft.com/en/posts/git/</link>
            <guid>40849363</guid>
            <pubDate>Mon, 01 Jul 2024 19:10:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.brachiosoft.com/en/posts/git/">https://blog.brachiosoft.com/en/posts/git/</a>, See on <a href="https://news.ycombinator.com/item?id=40849363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>Linus Torvalds once wrote in a <a href="https://www.amazon.com/Just-Fun-Story-Accidental-Revolutionary/dp/0066620732/">book</a> that he created Linux just for fun, but it ended up sparking a revolution. Git, his second major creation, also an accidental revolution. It’s now a standard tool for software engineers, but its origin story wasn’t so much fun this time, at least for Linus.</p>
<h2 id="linus-doesnt-scale">Linus doesn’t scale</h2>
<p>1998 was a big year for Linux. Major companies like Sun, IBM, and Oracle started getting involved with Linux. That spring, Linus’s second daughter was born, and his family had been living in California for about a year, settling into their new life. Even though Linux hadn’t brought Linus much financial gain, he was doing well both professionally and personally.</p>
<p>On the other hand, the Linux kernel developer community was growing, and the existing collaboration methods were becoming insufficient. Linus started struggling to keep up with the pace of code changes from developers, becoming a bottleneck in the process.</p>
<p>On September 28, 1998, Linus was reading the Linux kernel mailing list as usual when he came across this message:</p>
<blockquote>
<p>Please don’t waste your time on creating these patches. These things are functional in the vger tree.</p>
</blockquote>
<p>This <a href="https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0524.html">message</a> annoyed Linus. Linux code changes relied heavily on Linus himself. If you wanted to make a change, you’d email the mailing list, and if Linus saw and approved it, he’d incorporate your patch into his version and release new versions on FTP from time to time. Linus liked to work this way because it allowed him to control all changes. And everyone trusted Linus to manage Linux.</p>
<p>However, since David Miller, a senior Linux kernel developer, set up a CVS server called vger, some people thought they could bypass Linus and just submit changes to vger. This wasn’t the first time Linus encountered this issue, and he <a href="https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0554.html">responded</a> unhappily on the mailing list:</p>
<blockquote>
<p>Note that saying “it’s in vger, so you’re wasting your time” is still completely and utterly stupid. The fact that it is in vger has absolutely no bearing, especially as there’s a <em>lot</em> of stuff in vger that will probably never make it into 2.2.</p>
</blockquote>
<p>A heated debate ensued between Linus and a few developers, who complained about Linus’s slow responses, sometimes requiring three emails to get a reply from the “benevolent dictator.”</p>
<p>“These people should look at themselves in the mirror,” Linus thought. “I have to read so many emails a day. If sending three emails is too much trouble, I’d rather not have the patch.” He left this <a href="https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0850.html">message</a> before storming off:</p>
<blockquote>
<p>Quite frankly, this particular discussion (and others before it) has just made me irritable, and is ADDING pressure.</p>
<p>Go away, people. Or at least don’t Cc me any more. I’m not interested, I’m
taking a vacation, and I don’t want to hear about it any more. In short,
get the hell out of my mailbox.</p>
</blockquote>
<p>Linus’s emotional outburst prompted some people to offer help.</p>
<p>One of the open source movement leaders, Eric S. Raymond, author of the famous essay “<a href="https://en.wikipedia.org/wiki/The_Cathedral_and_the_Bazaar">The Cathedral and the Bazaar</a>,” calmly <a href="https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0849.html">urged</a>:</p>
<blockquote>
<p>People, these are the early-warning signs of potential burnout. Heed them and take warning. Linus’s stamina has been astonishing, but it’s not limitless. All of us (and yes, that means you too, Linus) need to cooperate to <em>reduce</em> the pressure on the critical man in the middle, rather than increasing it.</p>
</blockquote>
<p>Larry McVoy also extended a helping hand. In an email titled “<a href="https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0957.html">A solution for growing pains</a>,” he wrote:</p>
<blockquote>
<p>The problem is that Linus doesn’t scale. We can’t expect to see the rate of change to the kernel, which gets more complex and larger daily, continue to increase and expect Linus to keep up. But we also don’t want to have Linus lose control and final say over the kernel, he’s demonstrated over and over that he is good at that.</p>
<p>Figure out a means by which Linus can surround himself with some number
of people who do part of his job. Add tools which make that possible.</p>
<p>The mechanism which allows all this to happen is a distributed source
management system…</p>
</blockquote>
<p>Larry was developing a new version control system called BitKeeper.</p>
<h2 id="the-origin-of-bitkeeper">The origin of BitKeeper</h2>
<p>In the early 1990s, Sun Microsystems introduced an internal tool called Network Software Environment (NSE) to manage their code, but NSE was slow and had a terrible user experience. Some engineers even quit in frustration.</p>
<p>Larry McVoy, a seasoned operating system developer with a background in performance work, was approached by Sun’s management to improve NSE’s performance.</p>
<p>When Larry looked at NSE’s code, he was surprised. “This thing wasn’t designed with performance in mind at all.” He also discovered that NSE was built on top of SCCS, a version control system from the 1970s, older than CVS and Subversion. Instead of trying to fix the deeply flawed NSE, Larry chose a different path: he wrote NSElite in Perl, implementing resync/resolve commands on top of SCCS, similar to Git’s clone/pull/push commands today.</p>
<p>NSElite was much faster than NSE, so Sun’s engineers started abandoning NSE for NSElite. Seeing this, a Sun VP saw a business opportunity and formed an eight-person team to rewrite Larry’s Perl scripts in C++ and turn them into a product called TeamWare.</p>
<p>TeamWare was likely the first distributed version control system (DVCS), and it eventually became essential for developing Sun’s Solaris operating system. Engineers who used TeamWare couldn’t go back: unlike CVS and Subversion, TeamWare allowed you to clone the entire project to your local machine, make changes locally, and merge your version back into the remote version when ready.</p>
<p>The team consisted of eight experienced C programmers. Since C++ was the hot new language, they learned C++ while developing TeamWare. Before TeamWare was completed, Larry continued developing NSElite, which would make the TeamWare team look bad: one guy with Perl was outpacing eight people with C++. The VP then told Larry, “This has been reported to Scooter (Scott McNealy, Sun’s CEO). If you release it again, you’re fired.”</p>
<p>In 1991, Larry stopped developing NSElite but couldn’t shake the idea of building a DVCS. He thought commercial software would follow TeamWare’s lead, but none did. In 1997, Larry began developing a DVCS called BitKeeper. However, it wasn’t until September 1998, when he saw Linus on the verge of burnout on the mailing list, that he felt truly motivated to take BitKeeper seriously.</p>
<h2 id="linux-kernel-adopts-bitkeeper">Linux kernel adopts BitKeeper</h2>
<p>One fall day in 1998, Larry invited Linus Torvalds, David Miller, and Richard Henderson to his home. After dinner, they sat on the floor and started brainstorming ways to reduce Linus’s workload. They drew diagrams on the floor for three or four hours, mostly based on how TeamWare had been working within Sun Microsystems. Larry knew them well.</p>
<p>In this framework, developers could use BitKeeper to work independently without interfering with each other. When Linus did the final integration, he wouldn’t lose the history of the changes, making it easier for him to review the code.</p>
<p>“Alright, if you build it and it works as you say, I’ll use it,” Linus said.<br>
“No problem, I’ve done this before. It should take about six months,” Larry replied.</p>
<p>Larry quickly realized he had underestimated the complexity of the task. He founded a company called BitMover and recruited some version control experts to help build BitKeeper. Nineteen months later, in May 2000, BitKeeper’s first version was released. By then, BitMover was a team of seven people.</p>
<p>The first version of BitKeeper included a command-line tool called <code>bk</code> and some graphical interface tools. The <code>bk clone/pull/push</code> commands functioned similarly to <code>git clone/pull/push</code>.</p>
<p>At that time, Sun’s TeamWare was already well-regarded, and BitKeeper was TeamWare on steroids. For example, while TeamWare only allowed data transfer over NFS file systems, BitKeeper could transfer files over HTTP, which made it more distributed. As a result, BitKeeper soon brought BitMover a healthy cash flow. By 2002, BitMover had grown to a 25-person team, completely self-sufficient without external funding.</p>
<figure>
  <img src="https://blog.brachiosoft.com/en/posts/git/mcvoy.jpg" alt="Larry McVoy, Linux Expo, 1999">
  <figcaption>Larry McVoy, Linux Expo, 1999</figcaption>
</figure>

<p>In January 2002, Linus’s workload issue resurfaced. Patches submitted by developers were either taking too long to get a response or were being ignored. Someone wrote “<a href="https://lkml.iu.edu/hypermail/linux/kernel/0201.3/1000.html">a modest proposal</a>” to try to address the problem. In the discussion, someone casually <a href="https://lkml.iu.edu/hypermail/linux/kernel/0201.3/1427.html">mentioned</a>, “BitKeeper is a really nice tool,” reminding Linus of that dinner three years ago at Larry’s house. Linus <a href="https://lkml.iu.edu/hypermail/linux/kernel/0201.3/1513.html">asked</a>, “How many other people are actually using bitkeeper already for the kernel?”</p>
<p>As it turned out, some kernel developers had already been using BitKeeper. The Linux PowerPC (PPC) team started testing BitKeeper in December 1999, and BitMover set up a bkbits.net server to support them.</p>
<p>A few days later, on February 5, 2002, the mailing list saw Linus begin testing BitKeeper. From then on, the main Linux kernel developers started adopting BitKeeper. You didn’t have to use BitKeeper to contribute to development, but if you did, the process went something like this:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># Download the repository</span>
</span></span><span><span>bk clone bk://linux.bkbits.net/linux-2.5 linux-2.5
</span></span><span><span>bk clone linux-2.5 alpha-2.5
</span></span><span><span>
</span></span><span><span><span># Pull changes from another place</span>
</span></span><span><span>cd alpha-2.5
</span></span><span><span>bk pull bk://gkernel.bkbits.net/alpha-2.5
</span></span><span><span>
</span></span><span><span><span># Edit files and push changes back to the remote</span>
</span></span><span><span>bk vi fs/inode.c 
</span></span><span><span>bk push bk://gkernel@bkbits.net/alpha-2.5 
</span></span></code></pre></div><p>To send changes to Linus, you’d email the mailing list with something like:</p>
<pre tabindex="0"><code>Here is an update for something something...

Please pull from: bk://gkernel.bkbits.net/alpha-2.5

example/file1.c | 6 ++++++
example/file2.c | 4 ----
2 files changed, 6 insertions(+), 4 deletions(-)
</code></pre><h2 id="no-more-free-bitkeeper">No more free BitKeeper</h2>
<p>Larry McVoy allowed Linux kernel developers to use BitKeeper for free, but there were some strings attached. For example, the free user license required:</p>
<ul>
<li>You couldn’t turn off Open Logging, which sent usage records to the BitMover server.</li>
<li>You couldn’t use BitKeeper for version control if you were working on version control software.</li>
<li>You had to get BitMover’s permission if you wanted to run BitKeeper alongside other similar software.</li>
</ul>
<p>The Linux community, full of free software advocates, had mixed reactions. Some scoffed at these terms, while others avoided them. However, for Linus and the main Kernel developers, the key point was that BitKeeper reduced their workload. Since there were no better alternatives at the time, they accepted BitKeeper’s terms for the convenience it offered.</p>
<p>Linus had always been open-minded about proprietary software. He had chosen the GPL for the Linux kernel purely to keep the commercial market from “tainting” Linux. The GPL fit his needs, so he used it. But he never thought all software had to be free software; he believed authors had the right to distribute their software however they wanted. To him, software use wasn’t a social movement.</p>
<p>Free software advocates didn’t share his view. Some extreme ones even considered proprietary software to be evil. These hackers preferred the freedom to modify software over the convenience of BitKeeper.</p>
<p>Larry felt the pressure from the community. To address the issue, the BitKeeper team set up a BitKeeper-to-CVS mirror in 2003, allowing those who didn’t want to install BitKeeper to access code history via CVS. However, the history from CVS was incomplete compared to BitKeeper, and people weren’t satisfied. “Why should our data be locked in BitKeeper’s proprietary format, and why are we prohibited from using other tools to read <strong>our</strong> own data?”</p>
<p>In response, Andrew Tridgell (Tridge), the Australian programmer behind Samba and rsync, started developing a free BitKeeper client in February 2005 to solve the problems faced by free software users.</p>
<p>Tridge did the following.</p>
<p>“Here’s a BitKeeper address, bk://thunk.org:5000. Let’s try connecting with telnet.”</p>
<pre tabindex="0"><code>$ telnet thunk.org 5000
Trying 69.25.196.29...
Connected to thunk.org.
Escape character is '^]'.
</code></pre><p>“We’re connected. Why not type the help command?”</p>
<pre tabindex="0"><code>help
? - print this help
abort - abort resolve
check - check repository
clone - clone the current repository
help - print this help
httpget - http get command
[...]
</code></pre><p>“The BitKeeper server is kind enough to list all the commands.”<br>
“So <code>clone</code> must be the command to download the repository?”</p>
<p>He typed <code>clone</code> and found that the output was a series of SCCS-formatted files. With that, the “reverse engineering” was mostly done; the rest was just writing the program.</p>
<p>Linus somehow learned what Tridge was doing — perhaps Tridge told him privately. Linus then informed his friend Larry. Larry was not impressed. A free third-party client would ruin BitKeeper’s business model. Larry, seeking help from Linus and Stuart Cohen (then CEO of OSDL, now the Linux Foundation), wanted to ask Tridge to stop.</p>
<p>Stuart Cohen chose to stay out of it, considering it none of OSDL’s business. But Linus didn’t want to lose BitKeeper, so he worked hard to mediate, trying to find a compromise acceptable to both sides. Tridge firmly believed he wasn’t doing anything wrong, thinking a third-party client would be a win-win for BitKeeper and kernel developers. In April 2005, he released <a href="https://sourceforge.net/projects/sourcepuller/">SourcePuller</a> on Freshmeat (later merged into SourceForge). In the README, he wrote:</p>
<blockquote>
<p>An open client combined with the ability to accurately import into other source code management tools would have been a big step forward, and should have allowed BitMover to flourish in the commercial environment while still being used by the free software community.</p>
<p>I would also like to say that BitMover is well within its rights to license BitKeeper as it sees fit. I am of course disappointed at how BitMover has portrayed some of my actions, but please understand that they are under a lot of pressure. Under stress people sometimes say things that perhaps they shouldn’t.</p>
</blockquote>
<p>Larry disagreed with the win-win idea. Supporting kernel development cost money. Not only did they not make money, but they were also risking harm to their existing business model. To protect BitMover’s livelihood, he chose to revoke the free use license from BitKeeper.</p>
<p>After weeks of negotiation, Linus was fed up with playing mediator. With no more free BitKeeper available, Linus was furious. He publicly blamed Tridge on the <a href="https://www.realworldtech.com/forum/?threadid=49168&amp;curpostid=49169">forum</a>, saying he “just tore down something new” and “screwed people over.” Linus could have paid for BitKeeper himself, but he couldn’t ask other kernel developers to do the same, so he needed a new solution. He kept on writing:</p>
<blockquote>
<p>Now, I’m dealing with the fall-out, and I’ll write my own kernel source tracking tool because I can’t use the best any more. That’s ok - I deal with my own problems, thank you very much.</p>
</blockquote>
<p>On April 6, 2005, Linus <a href="https://lkml.iu.edu/hypermail/linux/kernel/0504.0/1540.html">announced</a> on the mailing list that the Linux kernel was parting ways with BitKeeper. He first thanked Larry and his team for their help over the past three years. Then he said he would be offline for a week to find a replacement. Finally, he added:</p>
<blockquote>
<p>Don’t bother telling me about subversion. If you must, start reading up on “monotone”. That seems to be the most viable alternative.</p>
</blockquote>
<h2 id="monotone">Monotone</h2>
<p>Monotone was created by Graydon Hoare. In 2001, Graydon, who lived in Canada, wanted to work more easily with his Australian friend. So they developed a system similar to today’s Continuous Integration (CI), which wasn’t widely known yet. Their system ensured that the code always passed tests.</p>
<p>In 2002, Graydon became interested in combining version control with CI. At that time, only <a href="https://aegis.sourceforge.net/">Aegis</a> had such a concept. Graydon also saw his friends using BitKeeper and thought that merging Aegis with DVCS could be an opportunity. That’s how Monotone came into being.</p>
<p>Remarkably, Graydon later joined Mozilla and created the Rust programming language.</p>
<p>Unfortunately, Linus picked a bad time to play with Monotone. Monotone 0.7 had decent performance, but starting from v0.14, developers began adding many validation mechanisms. Just before Linus downloaded Monotone, Graydon released v0.17 and then went on vacation. This version included a lot of rigorous checks to ensure data integrity before writing to the database, but these checks hadn’t been optimized, slowing down performance. The release notes for 0.17 <a href="https://github.com/graydon/monotone/blob/75ec703df3612b538d55a0f708935358863b7438/NEWS#L2221-L2222">mentioned</a>:</p>
<blockquote>
<p>not yet fully optimized; “pull” may be very slow and use lots of cpu</p>
</blockquote>
<p>Someone tested downloading Monotone with Monotone itself, and it took two hours, with 71 minutes of CPU time. “A heavily sedated sloth with no legs is probably faster,” they <a href="https://lkml.iu.edu/hypermail/linux/kernel/0504.0/2017.html">commented</a>.</p>
<p>Linus reported the performance issues to the Monotone developers. On April 10, 2005, Monotone 0.18 was released, with many operations running at least twice as fast. Although Linus was listed as a <a href="https://github.com/graydon/monotone/blob/75ec703df3612b538d55a0f708935358863b7438/NEWS#L2161-L2162">contributor</a> in the 0.18 release, according to Monotone developer Nathaniel Smith:</p>
<blockquote>
<p>Linus hasn’t actually contributed any code to Monotone, or, to the best of my knowledge, any SCM besides git. He didn’t really provide any suggestions either, beyond “this is too slow!” ;-). He’s credited there because it was in discussions with him that I found the right test case to track down one of our major performance bugs. I debated for a bit whether I should actually credit him by name for that, exactly because it was likely to give people strange ideas, but, figured, if it had been anyone else I would have, so… *shrug*.</p>
</blockquote>
<p>Meanwhile, inspired by Monotone’s design, Linus started writing some C code from scratch.</p>
<h2 id="git-v001-first-look">Git v0.01: First look</h2>
<p>On April 7, 2005, Linus uploaded a thing called Git and <a href="https://lkml.iu.edu/hypermail/linux/kernel/0504.0/2022.html">wrote</a> on the mailing list:</p>
<blockquote>
<p>here’s a quick challenge for you, and any crazy hacker out there: if you want to play with something <em>really</em> nasty (but also very <em>very</em> fast), take a look at kernel.org:/pub/linux/kernel/people/torvalds/.</p>
<p>First one to send me the changelog tree of sparse-git (and a tool to commit and push/pull further changes) gets a gold star, and an honorable mention. I’ve put a hell of a lot of clues in there.</p>
</blockquote>
<p>This was Linus’s first public mention of Git.</p>
<p>The URL had the following files and directories:</p>
<pre tabindex="0"><code>git.git/                  09-Apr-2005 16:09    -
sparse.git/               07-Apr-2005 20:07    -
git-0.01.tar.bz2          07-Apr-2005 14:25   39K
git-0.01.tar.bz2.sign     07-Apr-2005 14:25  248
git-0.01.tar.gz           07-Apr-2005 14:25   40K
...
sparse-git.tar.bz2        08-Apr-2005 17:26   15M
</code></pre><p><code>git-0.01.tar.bz2</code> had about 1,000 lines of C code:</p>
<pre tabindex="0"><code>---------------------------------------------------------------------
File                             blank        comment           code
---------------------------------------------------------------------
./read-cache.c                      31             14            219
./update-cache.c                    32             23            198
./commit-tree.c                     23             26            128
./show-diff.c                        8              5             73
./cache.h                           17             23             53
./write-tree.c                      11              7             53
./read-tree.c                        4              5             39
./init-db.c                          4             14             38
./Makefile                          14              0             26
./cat-file.c                         2              5             21
---------------------------------------------------------------------
SUM:                               146            122            848
---------------------------------------------------------------------
</code></pre><p>Unlike today’s Git, which uses a single executable file, the earliest version of Git that Linus uploaded compiled into seven separate executables:</p>
<ul>
<li><code>init-db</code></li>
<li><code>update-cache</code></li>
<li><code>show-diff</code></li>
<li><code>write-tree</code></li>
<li><code>read-tree</code></li>
<li><code>commit-tree</code></li>
<li><code>cat-file</code></li>
</ul>
<p>The <code>init-db</code> command was simple. It created a directory named <code>.dircache/objects</code> in the current directory and then created 256 subdirectories numbered in hexadecimal from <code>00</code> to <code>ff</code> inside <code>.dircache/objects</code>.</p>
<p>The <code>.dircache/objects</code> directory represented an object database with the following types of objects:</p>
<ul>
<li>Blob: the file contents.</li>
<li>Tree: directories, essentially containing names of files (blob) and directories (trees).</li>
<li>Changeset: defined by the names of two trees, representing the change from tree A to tree B. “Changeset” was an early term for what later became known as a “commit.”</li>
</ul>
<p>Here object names are not file or directory names but the SHA-1 hash of their compressed content. Linus borrowed this idea from Monotone, but while Monotone used SQLite to store SHA-1 object names and contents, Linus chose to use system calls and the filesystem directly.</p>
<p>SHA-1’s uniqueness meant that the Git database would almost <strong>never</strong> have two objects with different names but identical content. If an object’s name was <code>ba93e701c0fe6dcd181377068f6b3923babdc150</code>, Git would store it in <code>.dircache/objects/ba/</code> as a file named <code>93e701c0fe6dcd181377068f6b3923babdc150</code>.</p>
<p>The seven executables focused on different operations around this “content-addressable” filesystem. For example:</p>
<ul>
<li><code>write-tree</code>: Creates a tree object, writing the snapshot of a directory into the database.</li>
<li><code>commit-tree</code>: Creates a changeset, linking two trees in the database, similar to today’s <code>git commit</code>.</li>
<li><code>update-cache</code>: Adds a file to the <code>.dircache/index</code>, akin to today’s <code>git add</code> to the staging area.</li>
</ul>
<p>Linus liked the SHA-1-based naming idea as soon as he saw it in Monotone — because it was simple. Simplicity was also what Linus liked about Unix. In his book “Just for Fun,” he described Unix:</p>
<blockquote>
<p>This simple design is what intrigued me, and most people, about Unix (well, at least us geeks). Pretty much everything you do in Unix is done with only six basic operations (system calls)…</p>
<p>And you can build up pretty much everything from those six basic system calls.</p>
</blockquote>
<p>Git followed this philosophy, with a data model simpler than CSV, Subversion, or BitKeeper. It essentially stored the state of the directory before and after changes, without tracking what specific files or lines changed. This information was already embedded in the before and after states of the trees.</p>
<p>The Git prototype Linus wrote in two days was simple. No extra validation. No relational database. Just C code, SHA-1 hashes, and system calls, completely tailored to Linus’s needs. Meanwhile, the Monotone project, entering its third year, was feature-rich and had to cater to a wide range of use cases. Plus, Monotone’s original author Graydon had added a bunch of unoptimized code before going on vacation, leaving it without leadership. Monotone couldn’t match Git’s speed since it was at a disadvantage.</p>
<p>The <code>sparse-git.tar.bz2</code> file Linus initially uploaded was likely the first Git repository ever. <a href="https://sparse.docs.kernel.org/en/latest/">Sparse</a> was a static analyzer for C that Linus wrote in 2003. If you’re still interested in Linus’s challenge, you can slightly modify the extracted <code>sparse-git.tar.bz2</code> and use today’s <code>git log</code> command to read the change history:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># Assuming you are in the sparse-git directory</span>
</span></span><span><span>mv .dircache .git
</span></span><span><span>mkdir .git/refs
</span></span><span><span>git log
</span></span></code></pre></div>
<p>
  <iframe src="https://www.youtube.com/embed/idLyobOhtO4" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="gits-early-contributors">Git’s early contributors</h2>
<p>The initial version of Git sparked lively discussion. A few days later, Linus created a dedicated mailing list for Git, allowing the Linux Kernel mailing list to get back on track. In the first month, the Git mailing list saw around 2,600 messages, while the Linux kernel, the most collaborative software project in history, had 7,000-9,000 messages each month during the same period.</p>
<p>For experts in the version control field, Git was just another project. Linus’s first upload of Git contained only a few low-level operations. It lacked essential commands like <code>clone</code> and <code>merge</code>, making it far from a usable version control system. And Linus’s constant praise of Git unintentionally belittled other version control systems. This <a href="https://lore.kernel.org/git/Pine.LNX.4.44.0504261301520.4678-100000@wax.eds.org/">irritated</a> Bram Cohen, the creator of BitTorrent.</p>
<p>At the time, Bram was promoting his own version control system, Codeville. Codeville was already a mature DVCS comparable to Monotone and featured an advanced merge algorithm. Seeing how Linus and his followers talked about merge algorithms, Bram felt that Linus, an outsider, was reinventing the wheel. “Git is weekend hack which looks like a weekend hack,” Bram <a href="https://bramcohen.livejournal.com/17319.html?thread=151207#t151207:~:text=Git%20is%20a-,weekend%20hack,-which%20looks%20like">wrote</a>.</p>
<p>Bram got a point, but this wasn’t just any weekend hack — it was Linus Torvalds’s hack, the Linux kernel creator’s hack. As a folk hero in the open-source software world, Linus’s every move is under the spotlight. Young developers looked up to him, seeing him as a role model. Consequently, after Linus uploaded Git, it quickly attracted a group of young developers eager to join the discussion and development.</p>
<p>One of the early contributors was Petr Baudis from the Czech Republic. The day Linus announced Git, Petr downloaded the code, became enchanted, and started contributing. Given the early Git’s usability issues, Petr developed git-pasky (pasky being Petr’s alias), which eventually became <a href="https://en.wikipedia.org/wiki/Cogito_(software)">Cogito</a>. If Git’s foundation was the plumbing, Cogito was the porcelain — the user-friendly interface.</p>
<p>In software development terminology, comparing low-level infrastructure to plumbing is hard to trace, but the use of “porcelain” to describe high-level packaging originated in the <a href="https://lore.kernel.org/git/4262938E.8010107@timesys.com/">Git mailing list</a>. To this day, Git uses the terms “plumbing” and “porcelain” to refer to low-level and high-level commands, respectively.</p>
<p>Additionally, Petr set up the first project homepage for Git, git.or.cz, and a code hosting service, repo.or.cz. These websites were the “official” Git sites until GitHub took over.</p>
<p>Petr contributed externally by building on top of Git and creating services around it. Another early contributor, Junio Hamano, contributed directly from within Git itself. He later took over as Git’s maintainer from Linus. He still holds this position today.</p>
<h2 id="the-successor">The successor</h2>
<p>Junio Hamano is a software engineer from Japan. Around 1995, about a year after graduating, he was sent to Los Angeles by his employer, Twin Sun, and has lived in the US ever since. There, he met Paul Eggert, who was also working at the same company at the time.</p>
<p>Paul Eggert has maintained many free or open-source software projects, including RCS (an early version control system) and Tar. He is currently a professor at UCLA and the maintainer of the <a href="https://en.wikipedia.org/wiki/Tz_database">timezone database</a>.</p>
<p>Influenced by Paul, Junio developed an interest in the world of open-source software. Although he wasn’t a kernel developer, he subscribed to mailing lists for open-source projects like the Linux kernel <strong>just for fun</strong>.</p>
<p>In April 2005, Junio saw Linus’s announcement on the mailing list that the Linux kernel was parting ways with BitKeeper. Junio had always wanted to make a mark in the open-source world, and this new project called Git seemed like a great opportunity — brand new, no historical baggage, easy to get into. He downloaded the tarball, spent about two hours reading through the initial Git code in one setting. He was impressed by how well it was written.</p>
<p>After the initial release of Git, Linus quickly added <code>commit</code> and <code>diff</code> commands, but there was no merge yet.</p>
<p>Although Linus had never written version control software before, he had used BitKeeper for three years. Before that, he had ten years of “version control human” experience. He knew what kind of merge algorithm he wanted. However, since the merge logic was more involved, Linus thought it might be better suited to a scripting language, <a href="https://lore.kernel.org/git/Pine.LNX.4.58.0504132020550.7211@ppc970.osdl.org/">writing</a>:</p>
<blockquote>
<p>I’ve been avoiding doing the merge-tree thing, in the hope  that somebody else does what I’ve described. I really do suck at scripting things, yet this is clearly something where using C to do a lot of the stuff is pointless.</p>
</blockquote>
<p>A week went by with no takers. Junio, between projects at the time, had some free time, so he wrote what Linus wanted in Perl and <a href="https://lore.kernel.org/git/7vfyxtsurd.fsf@assigned-by-dhcp.cox.net/">posted</a> it to the mailing list.</p>
<blockquote>
<p>I now have a Perl script that uses rev-tree, cat-file, … and merge (from RCS). Quick and dirty.</p>
</blockquote>
<p>Junio probably picked up some knowledge of RCS from his mentor Paul, so he had some understanding of version control software. In his email, he also detailed about 30 test cases covering various code branches.</p>
<p>It was already 1 AM, and with his kids waking up at 7 AM, Linus usually went to bed by 10 PM. But seeing Junio’s Perl script, Linus was thrilled and couldn’t help but <a href="https://lore.kernel.org/git/Pine.LNX.4.58.0504140051550.7211@ppc970.osdl.org/">reply</a>:</p>
<blockquote>
<p>That’s exactly what I wanted. Q’n’D is how the ball gets rolling.</p>
</blockquote>
<p>He eagerly continued the discussion with Junio.</p>
<p>“<a href="https://lore.kernel.org/git/20050414002902.GU25711@pasky.ji.cz/">Merge with git-pasky II</a>” originally started with Petr asking Linus about merging his version, but it soon diverted into a discussion on merge algorithms. During the discussion, Linus also explained why Git’s internals didn’t need to handle file renames.</p>
<p>Over the next 48 hours, starting from the midnight on April 14, Junio and Linus exchanged a dozen emails in that thread. Junio patiently revised the code to meet Linus’s vision for merging. It was clear from his words that Junio was a big fan of Linus. For example, Junio would quote Linus’s words from four years ago, “<a href="https://lore.kernel.org/git/7vwtr4ibkt.fsf@assigned-by-dhcp.cox.net/#:~:text=Linus%20is%0Aalways%20right">I’m always right</a>,” and would adequately flatter Linus.</p>
<p>At midnight on April 16, Linus had a brainwave and mentioned he had a “<a href="https://lore.kernel.org/git/Pine.LNX.4.58.0504152256520.7211@ppc970.osdl.org/#:~:text=my%20cunning%20plan%20is%20some%20good%20stuff">cunning plan</a>.”</p>
<blockquote>
<p>Damn, my cunning plan is some good stuff.</p>
<p>Or maybe it is <em>so</em> cunning that I just confuse even myself. But it looks like it is actually working, and that it allows pretty much instantaenous merges.</p>
</blockquote>
<p>Linus cleverly reused the existing index, introducing the concept of “stages” on top of it, which significantly simplified the implementation of merge.</p>
<p>Junio <a href="https://lore.kernel.org/git/7vis2ncf8j.fsf@assigned-by-dhcp.cox.net/">marveled</a> at Linus’s solution:</p>
<blockquote>
<p>I really like this a lot.  It is <em>so</em> <em>simple</em>, clear, flexible and an example of elegance.  This is one of the things I would happily say “Sheeeeeeeeeeeeeesh!  Why didn’t <em>I</em> think of <em>THAT</em> first!!!” to.</p>
</blockquote>
<p>This meant that Junio’s previous Perl code would be wasted, but the new solution was so brilliant that Junio accepted it wholeheartedly.</p>
<p>The merge algorithm was just the beginning. Junio continued to contribute more patches to Linus, gradually earning Linus’s trust.</p>
<p>Linus had mentioned before that he wouldn’t maintain Git long-term. Once the time was right, he would hand Git over to someone else and return to his main job with the Linux kernel. Junio was the obvious choice, as Linus appreciated his “good taste” in writing code. So, three months later, on July 26, Linus <a href="https://lore.kernel.org/git/Pine.LNX.4.58.0507262004320.3227@g5.osdl.org/T/#u">announced</a> that he was passing the role of Git maintainer to Junio.</p>
<p>Junio also posted an <a href="https://lore.kernel.org/git/7vmzo8ss2l.fsf@assigned-by-dhcp.cox.net/">announcement</a>:</p>
<blockquote>
<p>As some of you seem to have noticed even before the announcement by Linus, the official GIT repository at kernel.org is now owned by me. As Linus said in his message, this does not mean he is
leaving us, so please do not panic.</p>
<p>I would also like to thank Twin Sun Inc (my employer) and NEC for promising to support me working on GIT on a part time basis from now on. I expect to be spending 8 to 12 day-job hours per week; evenings and weekends are my own time as before. My tentative plan is to make Wednesdays and Saturdays my primary GIT days.</p>
<p>Earlier, I was producing as many patches as ideas cross my mind, throwing all of them at the list to see which ones stick, relying on somebody with a good taste upstream to drop all the bad ones.  Although it has been fun working that way with Linus, regrettably, I ended up wasting a lot of his time.</p>
<p>I will slow down and be more careful as the “shepherd of the main repository” from now on.  At least for now, you will see patches from me posted on the list like everybody else’s, before they hit the main repository.</p>
</blockquote>
<p>Under Junio’s leadership, Git 1.0.0 was released on December 21. <strong>19 years</strong> later (as of July 2024), Junio is working at Google and still maintains Git.</p>
<p>This article mentions Linus more often than Junio, but the biggest contributors to Git as it exists today are the persistent efforts of Junio and other developers in the background. “1% inspiration and 99% perspiration” might be a cliché, but it holds very true for successful projects like Git and the Linux kernel.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qs_xS1Y6nGc" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="github-and-the-ruby-people">GitHub and the Ruby people</h2>
<p>Although Git garnered a fair amount of attention early on, it was still pretty niche. In January 2006, the X Window team switched from CVS to Git, which <a href="https://lore.kernel.org/git/7vzmlgt5zt.fsf@assigned-by-dhcp.cox.net/">wowed</a> Junio. He didn’t expect such a big project like X Window to go through the trouble of changing version control systems.</p>
<p>After BitKeeper, many DVCSes started to emerge, including Monotone, Mercurial, Darcs, Bazaar, Arch, and Fossil. The most notable among them was Mercurial, created by Matt Mackall. It was released just a few days after Git, with more complete features and a more user-friendly interface. It also had backing from Google Code and BitBucket. The version control market was like the Wild West, with each system holding its own.</p>
<p>What truly pushed Git to the top and made it mainstream was GitHub. Or, as Linus put it, it’s the Ruby people, <a href="https://www.youtube.com/watch?v=0m4hlWx7oRk&amp;t=1080s">strange people</a>, who made Git an overnight success.</p>
<p>In February 2007, Git 1.5 was released, finally making Git more usable for normal people. At the time, Git was the hot new thing being talked about at Ruby meetups in San Francisco. Tom Preston-Werner, co-founder of GitHub, first heard about Git from his colleague Dave Fayram. Tom considered Dave to be the “<a href="https://tom.preston-werner.com/2011/03/29/ten-lessons-from-githubs-first-year#:~:text=I%20can%20calculate%2C-,patient%20zero,-for%20the%20spread">patient zero</a>” for the spread of Git adoption in the Ruby community.</p>
<p>Despite Git’s popularity in the Ruby community, the only Git hosting service available at the time was Petr Baudis’s repo.or.cz, which was quite basic. For example, your code had to be public with no option for private repositories. Tom saw a big opportunity there.</p>
<p>In 2007, social media was booming with Facebook, YouTube, and Twitter leading the way. Tom came up with an idea called GitHub: a social media hub for programmers for sharing Git repositories and exchanging ideas.</p>
<p>One day in October 2007, Tom met Chris Wanstrath at a sports bar in San Francisco. They had met before at Ruby meetups but didn’t know each other well. Tom struck up a conversation and shared his GitHub idea. Chris found it interesting and agreed to join.</p>
<p>At that time, both Tom and Chris had full-time jobs, so they spent their evenings and Saturdays building GitHub. Tom designed the user interface and used a Ruby library called Grit to interact with Git repositories, while Chris built the website with Ruby on Rails.</p>
<p>Three months later, they started sending out invites to friends to test GitHub. In February 2008, PJ Hyett joined as the third co-founder. On April 10, GitHub officially launched with the tagline “Social Code Hosting.”</p>
<figure>
  <img src="https://blog.brachiosoft.com/en/posts/git/github.png" alt="GitHub, August 2008">
  <figcaption>GitHub, August 2008</figcaption>
</figure>

<p>Rails, the killer app for Ruby, switched from Subversion to GitHub just before GitHub’s launch, giving Git an even bigger boost in the Ruby community. Most people writing Ruby at the time were developing Rails applications. When they saw their go-to framework using GitHub, more Ruby developers followed suit.</p>
<h2 id="merging-git-and-github-with-conflict">Merging Git and GitHub with conflict</h2>
<p>Scott Chacon wasn’t your typical Git + Ruby guy. Besides writing Ruby code, he was an excellent speaker, writer, and evangelist. He created videos, wrote documentation, and taught people how to use Git. He also had an in-depth understanding of Git internals and wrote an ebook called “Git Internals.”</p>
<p>For three years, the “official” homepage for Git had been git.or.cz, set up by Petr Baudis in 2005. Scott wanted to create a more user-friendly homepage for beginners. In July 2008, he reorganized the contents from git.or.cz and launched a new homepage, <a href="https://git-scm.com/">git-scm.com</a>. He then <a href="https://lore.kernel.org/git/d411cc4a0807251035i7aed2ec9wef7e8f1b3ae4c585@mail.gmail.com/">asked</a> for feedback from Git core developers (especially Petr) on the Git mailing list.</p>
<p>While Git had been popular in the Ruby community for a while, Ruby people were rarely seen on the Git mailing list. Most Git core developers were experienced C programmers active on the mailing list, while the Ruby crowd, mostly younger web developers, hung out at meetups, web forums, and GitHub, and probably never used a mailing list in their lives. The two groups didn’t interact much, and Scott’s post about git-scm.com on the Git mailing list was one of the few early interactions between them.</p>
<p>Another issue for Git core developers was that Tom, without any discussion, forked and customized the Git daemon using Erlang to meet GitHub’s own needs. This was because, first, Tom wasn’t familiar with C, and second, posting on the mailing list was terrifying. The list was full of people smarter than you, and if you didn’t format your messages correctly, you’d look like an idiot. The process was just too slow, so Tom decided to handle it himself.</p>
<p>Git-scm.com had a banner saying “hosting donated by GitHub,” which led some to question Scott’s motives. Some expressed dissatisfaction that GitHub was making money off Git while core Git developers didn’t see a share. However, most of the feedback was positive, and eventually, git-scm.com became the official Git homepage, with git.or.cz retiring.</p>
<p>Tom met Scott at a Ruby meetup. He <a href="https://tom.preston-werner.com/2011/03/29/ten-lessons-from-githubs-first-year#:~:text=he%20could%20become%20either%20a%20powerful%20ally%20or%20a%20dangerous%20foe">thought</a>, “This guy could become either a powerful ally or a dangerous foe.” In October 2008, Scott joined GitHub, continuing his mission to spread the word about Git. He wrote more documentation, offered consulting services, and taught companies how to use Git. He also wrote the book “Pro Git,” which became the official Git book. GitHub’s evangelism strategy worked perfectly, expanding Git’s reach beyond the Ruby community. And GitHub itself was the biggest beneficiary.</p>
<p>In October 2008, Google sponsored the first GitTogether conference. About 20 people from both the Git and GitHub teams met at Google’s headquarters in Mountain View. They put aside their differences, knowing that only by working together could they all become stronger.</p>
<figure>
  <img src="https://blog.brachiosoft.com/en/posts/git/gittogether.jpg" alt="GitTogether 2008">
  <figcaption>GitTogether 2008</figcaption>
</figure>

<h2 id="epilogue">Epilogue</h2>
<p>Unable to compete with Git and GitHub, BitKeeper eventually had to exit the market. In 2016, the team open sourced its code. This grandparent of DVCS, which inspired Git, Mercurial, Monotone, and others, is now a piece of history for people to observe and study. When asked for his thoughts, Larry McVoy <a href="https://news.ycombinator.com/item?id=26205688">responded</a>:</p>
<blockquote>
<p>Hind sight is 20-20. The BitKeeper business had a good run, we were around for 18 years. It made enough that I and my business guy are retired off of what we made.</p>
<p>On the other hand, we didn’t make enough for everyone to retire if they wanted to. We had a github like offering and it’s pretty clear that we should have put a bunch of money into that and open sourced BitKeeper.</p>
<p>All I can say is it is incredibly hard to make that choice when you have something that is paying the bills.</p>
<p>Shoulda, coulda, woulda, my biggest regret is not money, it is that Git is such an awful excuse for an SCM. It drives me nuts that the model is a tarball server. Even Linus has admitted to me that it’s a crappy design. It does what he wants, but what he wants is not what the world should want.</p>
</blockquote>
<p>Now, Larry enjoys his retirement. He likes to spend his time fishing with his kids.</p>
<p>In a 2022 <a href="https://survey.stackoverflow.co/2022#section-version-control-version-control-systems">survey</a> by Stack Overflow, Git had a market share of 94%, so much so that the following year, Stack Overflow stopped asking which version control system people used.</p>
<p>Never in history has a version control system dominated the market like Git. What will be the next to replace Git? Many say it might be related to AI, but no one can say for sure. What we can be sure is that the transition will likely involve a series of occasional events and a group of talented hackers.</p>
<h2 id="references">References</h2>
<p>Other than the links in the article, additional references are listed below:</p>
<ol>
<li>“<a href="https://www.amazon.com/Just-Fun-Story-Accidental-Revolutionary/dp/0066620732/">Just for Fun: The Story of an Accidental Revolutionary</a>” by Linus Torvalds and David Diamond, 2002</li>
<li>“<a href="https://news.ycombinator.com/item?id=11667494">Show HN: BitKeeper – Enterprise-ready version control, now open-source</a>” on Hacker News</li>
<li><a href="https://www.krsaborio.net/linux-kernel/research/2002/0528.html">Larry McVoy Interview with KernelTrap</a></li>
<li><a href="https://web.archive.org/web/20030603163213/http://www.linuxworld.com/2003/0127.barr.html">Larry McVoy Interview with LinuxWorld</a></li>
<li><a href="https://marc.merlins.org/linux/linuxexpo99/Day2/Bofs/Bitkeeper.html">Linuxexpo 1999: Day 2: BitKeeper</a></li>
<li>“<a href="https://lwn.net/Articles/132938/">How Tridge reverse engineered BitKeeper</a>” on LWN.net</li>
<li>“<a href="https://www.theregister.com/2005/04/22/tridgell_releases_sourcepuller/">Tridgell drops Bitkeeper bombshell</a>” on The Register</li>
<li>“<a href="https://web.archive.org/web/20120523134437/http://kerneltrap.org/node/4966">No More Free BitKeeper</a>” on KernelTrap</li>
<li>“<a href="https://lwn.net/Articles/130746/">The kernel and BitKeeper part ways</a>” on LWN.net</li>
<li>“<a href="https://graydon.livejournal.com/186550.html">not rocket science (the story of montone and bors)</a>”, Graydon Hoare on LiveJournal</li>
<li>“<a href="https://www.linuxjournal.com/content/git-origin-story">A Git Origin Story</a>” by Zack Brown</li>
<li>“<a href="https://www.linuxfoundation.org/blog/blog/10-years-of-git-an-interview-with-git-creator-linus-torvalds">10 Years of Git: An Interview with Git Creator Linus Torvalds</a>” from the Linux Foundation</li>
<li><a href="https://www.linkedin.com/in/petr-baudis-906a213/">Petr Baudis</a> on LinkedIn</li>
<li><a href="https://www.linkedin.com/in/gitster/">Junio Hamano</a> on LinkedIn</li>
<li>“<a href="https://bramcohen.livejournal.com/17319.html">Version Control Shenanigans</a>”, Bram Cohen on LiveJournal</li>
<li>“<a href="https://gihyo.jp/dev/serial/01/alpha-geek/0040">Gitメンテナ　濱野 純</a>”, 技術評論社</li>
<li>“<a href="https://tom.preston-werner.com/2008/10/18/how-i-turned-down-300k">How I Turned Down $300,000 from Microsoft to go Full-Time on GitHub</a>” by Tom Preston-Werner</li>
<li><a href="https://changelog.com/podcast/586">Replacing Git with Git</a> featuring Scott Chacon, the Changelog podcast</li>
<li><a href="https://gitster.livejournal.com/17887.html">GitTogether Group Photo</a>, Junio Hamano on LiveJournal</li>
<li><a href="http://mcvoy.com/lm/resume.html">Larry McVoy’s resume</a></li>
</ol>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pharma firms stash profits in Europe's tax havens (162 pts)]]></title>
            <link>https://www.investigate-europe.eu/posts/deadly-prices-pharma-firms-stash-profits-in-europes-tax-havens-as-patients-struggle-with-drug-prices</link>
            <guid>40848797</guid>
            <pubDate>Mon, 01 Jul 2024 18:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.investigate-europe.eu/posts/deadly-prices-pharma-firms-stash-profits-in-europes-tax-havens-as-patients-struggle-with-drug-prices">https://www.investigate-europe.eu/posts/deadly-prices-pharma-firms-stash-profits-in-europes-tax-havens-as-patients-struggle-with-drug-prices</a>, See on <a href="https://news.ycombinator.com/item?id=40848797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>When doctors removed Miriam Staunton's tumour from her armpit six years ago, they told the 51-year-old Irish woman that she had a 70 per cent chance of relapse. Yet, in the months following the operation, she was only offered local radiation and regular check-ups, but no drug treatment.&nbsp;</span> <br><span></span> <br><span>"I remember when I met the oncologist and he said that he wasn't in a position to offer me anything systemic at that point," Staunton recalls. "I didn't really understand exactly what he meant by it at that time."</span> <br><span></span> <br><span>What Staunton did not realise is that she would have to wait for her melanoma to return one year later before she could be entitled to effective but expensive medicines. After the cancer had progressed to stage four in February 2019, she started a course of Opdivo combined with Yervoy, breakthrough drugs known as immunotherapy, which were then restricted to the most severe forms of cancer in Ireland due to their high costs.&nbsp;</span> <br><span></span> <br><span>In other parts of Europe, Staunton could have taken Opdivo alone shortly after her surgery. In July 2018, the European Medicines Agency (EMA) opened the therapy to stage three melanoma patients. France immediately reimbursed it, but Ireland did not. "It's one thing when there is no cure, but when the treatment exists and people can't access it, that's fundamentally wrong," says Staunton, who is now cancer-free. </span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit0DSC00018.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit0DSC00018.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span>Miriam Staunton was unable at first to access the cancer drug she needed because it was not available in Ireland. </span><span>Maxence Peigné</span></p><hr></div><p><span>The reason for this delay is that Ireland and the American drugmaker, Bristol-Myers Squibb (BMS), could not agree on Opdivo's price. When the EMA approves new medicines for use in the EU, each member state has to strike reimbursement deals with producers individually. </span><a target="" href="https://www.investigate-europe.eu/posts/deadly-prices-medicine-dealers-europe-secret-drug-negotiations"><span>Negotiations can be lengthy, as companies often prioritise rich markets and governments seek confidential discounts.</span></a><span></span> <br><span></span> <br><span>Meanwhile, the pharmaceutical industry - like many other sectors - hoards eye-watering gains in tax havens. Investigate Europe can reveal that the 15 largest European and US drugmakers, including BMS, publicly disclose over 1,300 subsidiaries in tax havens and low-tax territories.&nbsp;</span> <br><span></span> <br><span>These jurisdictions offer corporations low taxes or ways to shift profits (sometimes both). In Europe, researchers and activists generally agree that they include Ireland, the Netherlands, Switzerland and Luxembourg. They are among the top five profit-shifting destinations globally, according to this year’s </span><a target="_blank" href="https://www.taxobservatory.eu//www-site/uploads/2023/10/global_tax_evasion_report_24.pdf"><span>EU Tax Observatory report</span></a><span>, an EU-funded think-tank.&nbsp;</span> <br><span></span> <br><span>The little-known structures in tax-friendly destinations have contributed to the 15 pharmaceutical firms amassing profits of €580 billion in the last five years.&nbsp;</span> <br><span></span> <br><span>This amount outweighs their research and development (R&amp;D) costs, despite the industry's frequent claim that high drug prices allow them to innovate and design new drugs. The returns are in keeping with the outsized profits that are synonymous with the wider sector. Some of the groups' Irish affiliates have racked up hundreds of billions of dollars and still rely on a version of the 'Double Irish' tax avoidance scheme, the analysis finds.</span> <br><span></span> <br><span>"Corporate tax avoidance is not victimless, fewer taxes mean less investment in healthcare in Ireland and also negative impacts for countries in the Global South," says Aideen Elliott of Oxfam Ireland. "Nothing these companies are doing is illegal. They are taking advantage of corporate tax rules."</span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2FNEW-shutterstock_2401059949.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2FNEW-shutterstock_2401059949.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span>The $580 billion made by the 15 firms in the past five years outweighs what they collectively spent on research and development.</span><span>Shutterstock</span></p><hr></div><p><span>All corporations cited in this article were contacted for comments. AstraZeneca, Bayer, Eli Lilly, Novartis, Novo Nordisk, Roche and Sanofi specifically replied on tax issues to say that they comply with all rules. Sanofi insisted that its presence in low-tax jurisdictions was justified by local patients' needs. Bayer said that as a German company, it is taxed on its offshore profits, adding that some of the countries mentioned in this article should not be considered tax havens.</span> <br><span></span> <br><span>In Ireland, BMS entered negotiations with health authorities with a starting price of</span><a target="_blank" href="https://www.ncpe.ie/wp-content/uploads/2019/10/Technical-Summary-Document-nivolumb-for-adv-mel.pdf"><span> €1,311 for a 100 mg</span></a><span> dose of Opdivo. This is a stark contrast with academics' estimates that similar antibodies can be manufactured for between </span><a target="_blank" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8868023/"><span>$9.50 (€8.85) and $20 (€18.60) per 100 mg.</span></a><span>&nbsp;</span> <br><span></span> <br><span></span><a target="_blank" href="https://www.hse.ie/eng/services/list/5/cancer/profinfo/medonc/trc/trc%20minutes%2004%20nov%202019.pdf"><span>In November 2019</span></a><span>, the Irish healthcare system stressed the "substantial budget impact" of providing the drug for stage three cancer and noted that talks with the company were ongoing. Opdivo was finally reimbursed in February 2021, two and a half years after France. The final discount remains a trade secret.</span> <br></p><div><h4>“<!-- -->Corporate tax avoidance is not victimless, fewer taxes mean less investment in healthcare in Ireland and also negative impacts for countries in the Global South.<!-- -->”</h4><p>— <!-- -->Aideen Elliott, Oxfam Ireland</p></div><p><span>Ironically, BMS makes Opdivo in Dublin, at a facility close to Staunton's home. While the treatment wasn't accessible to some Irish patients due to its cost, the supplier was raking in sky-high profits thanks to Ireland's attractive tax rules.</span> <br><span></span> <br><span>BMS's sprawling state-of-the-art campus in the Irish capital belongs to a subsidiary that boasted a $17.2 billion turnover in 2022, more than a third of the manufacturer's global revenues that year. Yet despite being registered in Ireland, Swords Laboratories is a Swiss entity for tax purposes.</span> <br><span></span> <br><span>Its direct parent, Bristol-Myers Squibb Holdings Ireland, enjoys a similar double residency and owns patents for several BMS therapies. In 2022, the holding valued the assets at more than $1 billion and pocketed $4.5 billion in royalties linked to drugs produced by Swords Laboratories, such as Eliquis, a bestselling blood thinner. In addition, the holding received almost $9 billion in dividends from the Dublin plant in just two years. </span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Feditshutterstock_2394208173.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Feditshutterstock_2394208173.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span>BMS has operations across the world. The firm turns over billions in revenue each year.</span><span>Shutterstock</span></p><hr></div><p><span>The arrangement resembles an infamous tax avoidance loophole that Ireland vowed to close. Dubbed "the Double Irish", it has been a common tool for tech and pharma groups to slash their effective tax bill below Ireland’s current 12.5 per cent corporate tax rate. The technique involved setting up two Irish companies: one for operational purposes and the other to hold intellectual property (IP). The first would pay royalties to the second, which would be a tax resident offshore, like in Bermuda.</span> <br><span></span> <br><span>"Ireland made changes to its corporate tax residence rules in Finance Act 2014 that are specifically designed to prevent such structures as the so-called 'Double Irish'," a Department of Finance spokesperson said. “These rules ensure that it is not possible for companies to exploit mismatches in tax residency rules.”</span> <br><span></span> <br><span>However, Dr James Stewart, adjunct professor in finance at Trinity College Dublin, says the structures can continue to exist because Ireland has a double taxation treaty with Switzerland.  "These firms have very large assets and flows of funds, generally have no employees and are very profitable. They are likely to be a source of profit extraction," he adds.</span> <br></p><div><h4>“<!-- -->Ireland made changes to its corporate tax residence rules in Finance Act 2014 that are specifically designed to prevent such structures as the so-called 'Double Irish'.<!-- -->”</h4><p>— <!-- -->Irish Department of Finance spokesperson</p></div><p><span>BMS Holdings Ireland's main direct shareholder is also an Irish outfit with Swiss tax residency. The two holdings and Swords Laboratories don't only funnel gains outside of Ireland, they also park them in their coffers. By the end of 2022, the trio had accumulated over $30 billion of equity.</span> <br><span></span> <br><span>Harbouring IP in tax havens is a common practice at BMS. Its patents on Opdivo and Yervoy sit in Delaware, an American state that levies no tax on royalties. The two drugs amounted to a quarter of the group's $45 billion revenue in 2023. That year, BMS listed 135 subsidiaries in tax havens: 81 in Delaware, 15 in Switzerland, 13 in Ireland and 12 in the Netherlands.&nbsp;</span> <br><span></span> <br><span>The structures helped the company reach an effective corporate tax rate of 4.7 per cent, far below the US statutory rate of 21 per cent. Part of it was due to a favourable tax ruling, but the largest reduction resulted from different fiscal treatments in Ireland, Switzerland and Puerto Rico, according to BMS's annual report.</span> <br><span></span> <br><span>The company did not reply to requests for comments.</span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit0shutterstock_467065226.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit0shutterstock_467065226.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span>15 of the world’s biggest drugmakers operate more than 1,300 subsidiaries in tax-friendly jurisdictions, such as the US state of Delaware.</span><span>Shutterstock</span></p><hr></div><p><span>BMS is hardly a unique case. Investigate Europe analysed the last five years of accounts filed by the 15 largest American and European pharmaceutical groups. Together, they declared 1,300 subsidiaries in tax havens, as of 2023. The true number is likely higher, as reporting rules only force multinationals to list those undertakings they consider "significant".&nbsp;</span> <br><span></span> <br><span>Delaware took the top spot with 700 entities. The Netherlands came second with almost 170. Switzerland and Ireland were next, with nearly 120 each. Like BMS, US giant Merck established a network of Irish subsidiaries with Swiss tax residency which held at least $44 billion of equity as of 2022.&nbsp;</span> <br><span></span> <br><span>Not all drugmakers rely on a Double Irish scheme. According to Investigate Europe estimates, many of their affiliates had amassed considerable equity in Ireland by 2022's close: $308 billion for Abbvie, over $102 billion for Johnson &amp; Johnson, $20 billion for AstraZeneca and $17 billion for Gilead. </span> <br></p><p><span></span><a target="_blank" href="https://www.ipha.ie/about-us/contribution-to-the-irish-economy/"><span>Nine of the 10 biggest</span></a><span> pharma groups in the world have operations in Ireland and the largest is "likely to be Pfizer," suspects Prof Stewart. "I say likely because there are no published accounts available for any Irish subsidiary. Nearly all Pfizer subsidiaries in Ireland operate as a branch of a Dutch entity."</span> <br><span></span> <br><span>
In the Netherlands, Pfizer booked three-quarters of its $100 billion global revenues with a Dutch holding at the helm of a myriad of subsidiaries. CPPI CV, a limited partnership, is "fiscally transparent", meaning its shareholders can draw profits untaxed. In the two years to the end of 2023, CPPI sent $35 billion to its parent companies in Delaware. Follow the Money, an investigative outlet, published several articles on Pfizer's Dutch affairs and </span><a target="" href="https://www.ftm.eu/articles/corona-and-tax-hacks-make-pfizer-the-most-profitable-company-in-the-netherlands?share=TdgNXnIlBg4VBVoTgQjg7akJl44DxHddcBwHeQESo%2BwA9dS%2FaQcUKJFs6oRpMi8%3D"><span>described how the partnership</span></a><span> became the most profitable company in the Netherlands. Pfizer did not respond to requests for comment.</span> <br><span></span> <br><span>"American companies have historically hoarded cash in low-tax jurisdictions to avoid taxes they would normally pay if they repatriated profits to the US," explains Reuven Avi-Yonah, a law professor at the University of Michigan.&nbsp;"In 2018, a US reform sought to change this with a 10.5 per cent tax on foreign income, but it actually encouraged big pharma to keep even more profits offshore, as they would be subject to this attractive rate rather than the US statutory rate of 21 per cent."</span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2FNEW-shutterstock_2424325787.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2FNEW-shutterstock_2424325787.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span> Pharmaceutical executives often cite expensive R&amp;D costs as a major reason why medicine prices are high.</span><span>Shutterstock</span></p><hr></div><p><span>"Everyone who has income wants to limit the tax exposure that they have from that income, companies are no exception," says Paul Fehlner, former head of IP at Novartis, a Swiss pharma behemoth. "So by putting ownership of patent rights into a low-tax jurisdiction and then flowing funds internally into a patent holding entity, you're able to reduce the overall tax burden."</span> <br><span>
</span> <br><span>Patents are filed by corporations or inventors on new products to prevent competition. In exchange for sharing their discovery with the public, patent holders are granted exclusive rights to manufacture and market the drug for a certain period, usually 20 years.</span> <br><span></span> <br><span>Generics are typically up to 85 per cent cheaper once rolled out, but as long as their monopolies last, drugmakers can impose high prices on governments and insurers. Pharmaceutical executives often cite </span><a target="_blank" href="https://abcnews.go.com/Business/big-pharma-ceos-grilled-capitol-hill-takeaways/story?id=107057364"><span>expensive R&amp;D costs</span></a><span> to justify this.&nbsp;</span> <br><span></span> <br><span>However, data compiled by Investigate Europe shows that the industry, when analysed collectively, reaps more profits from the sales of existing drugs, than it invests in developing new ones.&nbsp;</span> <br></p><div><p><iframe width="1920" height="1080" src="https://www.youtube.com/embed/Sqgx9NlgHg8?si=M_L2O7p9VkcSGxmW" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p><br></div><p><span>Over the five years analysed, the 15 multinationals made €580 billion after tax, while dedicating €572 billion to R&amp;D. The gains were mostly allotted to shareholders in dividends and stock buybacks for a total €558 billion. </span> <br><span></span> <br><span>As a result, the following groups shelled out more on rewarding investors than on R&amp;D: Abbvie, Johnson &amp; Johnson, Novartis, BMS, Pfizer, Novo Nordisk and Amgen. Other firms, including AstraZeneca, Merck and Bayer, did invest more in R&amp;D than they made profits or paid shareholders.</span> <br><span></span> <br><span>Big pharma's fortune amassed in European tax havens contrasts with access inequality and struggling healthcare budgets locally. As much as Ireland lures drugmakers with its fiscal perks, Irish patients can often wait longer than their western European peers to get innovative drugs.&nbsp;</span> <br><span> </span> <br><span>"Pharma companies make it clear that bigger markets are more important to them and that they wouldn't want to give us a discount as a small member," says a former Irish health official speaking on condition of anonymity. "A lot of the companies take their own sweet time in even applying for market authorisation in Ireland. Some have sometimes literally told me that Ireland is so insignificant that their bosses don’t really care whether their drugs are here or not." </span> <br></p><p><span>The Irish Pharmaceutical Healthcare Association (IPHA), </span><a target="_blank" href="https://www.ipha.ie/wp-content/uploads/2023/12/Oireachtas-briefing-06-12-2023.pdf"><span>an industry lobby, estimates</span></a><span> that over two years pass on average between the start of a new drug assessment by the Irish medicines watchdog and its reimbursement approval.&nbsp;</span> <br><span></span> <br><span>In its 2024 budget, the Irish government announced that there would be no fresh funds for new drugs before it made a </span><a target="" href="https://www.independent.ie/irish-news/health/new-hope-for-thousands-of-patients-as-20m-found-for-breakthrough-medicines/a252600831.html"><span>U-turn and set aside €20 million</span></a><span> for innovative medicines.&nbsp;</span> <br><span></span> <br><span>In the tax-friendly Netherlands too, the picture is contrasted. </span><a target="_blank" href="https://english.rekenkamer.nl/publications/reports/2020/04/23/miracle-cure-or-sticking-plaster-2020-the-results-of-negotiations-on-the-prices-of-medicines"><span>State auditors</span></a><span> have suggested the government should negotiate bigger discounts to safeguard its budget, highlighting that not all therapies approved are cost-effective.</span> <br><span>
</span> <br><span>Dutch courts are poised to become a battleground between one drugmaker and its detractors. In 2023, the Pharmaceutical Accountability Foundation (PAF), a public interest group, filed a lawsuit against US firm Abbvie </span><a target="_blank" href="https://www.pharmaceuticalaccountability.org/2023/11/15/abbvie-tries-to-escape-accountability-for-overcharging-the-dutch-healthcare-system-by-1-2-billion-euros/#:~:text=AMSTERDAM%2C%20THE%20NETHERLANDS%3A%20In%20February,law%20and%20human%20rights%20principles."><span>for abuse of dominant position</span></a><span>. PAF alleges that the company made excessive profits of €1.2 billion over 14 years on its Dutch sales of Humira, the </span><a target="" href="https://www.npr.org/sections/health-shots/2023/01/31/1152513058/abbvies-blockbuster-drug-humira-finally-loses-its-20-year-200-billion-monopoly"><span>world's best-selling drug</span></a><span> treating an array of ills.</span> <br></p><div><p><img srcset="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit-shutterstock_1557949541.jpg&amp;w=3840&amp;q=75 1x" src="https://www.investigate-europe.eu/_next/image?url=https%3A%2F%2Fcontent.investigateeurope.com%2Fuploads%2Fedit-shutterstock_1557949541.jpg&amp;w=3840&amp;q=75" width="3160" height="3160" decoding="async" data-nimg="1" loading="lazy"></p><p><span>Humira is the world's best-selling drug.</span><span>Shutterstock</span></p><hr></div><p><span>"We hope that the judge's ruling will be a warning to pharmaceutical companies: you can ask any price you want, but if you really get out of line, you can be hit back and have to pay back," says Wilbert Bannenberg, PAF's chairperson.</span> <br><span></span> <br><span>"We reject the unfounded allegations of the Pharmaceutical Accountability Foundation, which, as indicated to the court, calls into question the pricing system for all medicines, potentially hindering future innovation," an AbbVie spokesperson said.</span> <br><span></span> <br><span>
Before critics emerged in the Netherlands, the company was already under acute scrutiny in its home country. In 2022, </span><a target="" href="https://www.finance.senate.gov/imo/media/doc/Pharma%20Tax%20Report.pdf"><span>a US Senate committee</span></a><span> found that Abbvie dodged billions of dollars of tax by keeping its intellectual property in Bermuda and manufacturing its products in Ireland and Puerto Rico. </span> <br><span></span> <br><span>The same year, I-Mak, an advocacy organisation, revealed that the group filed 94 per cent of its 166 American patents on Humira after the medicine was already on the market. The ruse </span><a target="" href="https://vermontbiz.com/news/2023/july/27/welch-calls-out-big-pharmas-patent-abuse-during-senate-hearing"><span>kept competitors at bay</span></a><span> and delayed cheaper generics.</span> <br></p><div><h4>“<!-- -->I don't think I hold [pharmaceutical companies] responsible. Do you hold the lion responsible for eating the zebra? No.<!-- -->”</h4><p>— <!-- -->Paul Fehlner</p></div><p><span>"They had all these patents covering all these variations, different dosages, even different sort of needle sizes on the pens that deliver the drug," says Tahir Amin, I-Mak's CEO. "All this built up to block-off competition because when you go to litigation, you pay millions of dollars to just remove one patent." The practice known as "evergreening", is criticised by I-Mak and others as a flaw in the patent system that allows corporations to prolong lucrative monopolies. </span> <br><span></span> <br><span>Fehlner, now the CEO of a biotech that repurposes existing medicines, is more nuanced: "There is a definite interest in companies in maintaining the profitability of drugs as long as possible. They're incentivised to do that."&nbsp;</span> <br><span></span> <br><span>For the former Novartis director, it is up to governments to impose conditions that curtail prices and support competition when signing contracts with pharma groups.&nbsp; "Should the companies themselves do certain things? I don't know, they're organised to maximise their profit," he says. "So I don't think I hold them responsible. Do you hold the lion responsible for eating the zebra? No."</span> <br><span>
</span> <br><em><span>Full company responses can be read </span></em><a target="_blank" href="https://content.investigateeurope.com/uploads/IE-company-responses-tax%20havens.pdf"><em><span>here</span></em></a><em><span>.&nbsp;</span></em> <br><span>
</span> <br><em><span>Contributor: Catrien Spijkerman</span></em> <br><em><span>Editor: Chris Matthews</span></em> <br></p></div></div>]]></description>
        </item>
    </channel>
</rss>