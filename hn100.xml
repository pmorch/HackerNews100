<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 20 Jun 2025 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I will do anything to end homelessness except build more homes (225 pts)]]></title>
            <link>https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes</link>
            <guid>44325617</guid>
            <pubDate>Fri, 20 Jun 2025 08:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes">https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes</a>, See on <a href="https://news.ycombinator.com/item?id=44325617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="o-wrapper">
    <main>
        <header>
    <div>
      <div>
          <p><span><img role="none" src="https://www.mcsweeneys.net/assets/search-614fbdcc4e71f0730ad039e484ec78a1085f24294fa0b4514da70b0a930b2dce.svg"></span></p>        </div>
      <div>
        <ul>
          <li><a href="https://www.mcsweeneys.net/">Internet Tendency</a></li>
          <li><a href="https://store.mcsweeneys.net/">The Store</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/books">Books Division</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/timothy-mcsweeneys-quarterly-concern">Quarterly Concern</a></li>
          <li><a href="https://thebeliever.net/">The Believer</a></li>
          <li><a href="https://www.mcsweeneys.net/donate">Donate</a></li>
        </ul>
      </div>
    </div>
    
  </header>


      
  <div>
    <h6>MCSWEENEY'S QUARTERLY SUBSCRIPTIONS</h6>
    
  </div>


      
<article>
    
   
    <div>
      <p>Homelessness in America has reached crisis levels, and I am determined to do everything in my power to fix the problem as long as it doesn’t involve changing zoning laws or my ability to drive alone to work or, well, changing anything, really. I’m more than happy to give a hungry man a sandwich once a year and then brag to my friends about it as long as he doesn’t sit down anywhere in my line of sight to eat it. Same goes for hungry women because I’m also a feminist.</p>
<p>This is so important because everyone should have a bed to sleep in at night, and also, nothing destroys property values faster than a desperate person on a sidewalk asking for change. I’m not saying I don’t care about human suffering; I just care much, much more about my immediate self-interest because I’m the kind of person who contributes to society by starting companies that leverage technology to build smart tea kettles that brew themselves while you sleep at night. I’m a fucking innovator.</p>
<p>I’m innovating for win-win-whatever solutions where I win, my community wins, and we do whatever to get rid of homelessness. Fixing the problem means lots of things: letters to the editor of my local newspaper, bombastic statements to the press that will make the fruit of my loins cringe for generations, and especially writing vaguely discriminatory, definitely ugly posts on social media about the crisis as it unfolds in my community. Also, I call the police a lot.</p>
<p>Ending homelessness doesn’t mean building more homes because this town is full of homes already, especially mine, which is a single-family mini-mansion on an acre lot that I inherited from my parents and/or managed to purchase with the kind of job and bank terms and economic equality that don’t exist anymore for anyone and only ever really existed for well-educated white Americans. Either that or it’s a magnificent luxury condo with expansive views that I don’t want marred by more luxury condos or—god forbid—affordable housing.</p>
<p>Every room in my Instagram-worthy abode is either filled with clutter or rented out nightly to hipsters from another gentrified, monotone city also suffering from a homelessness crisis—this is a national epidemic, after all. I’m a good person, a generous person, and what made me the person I am is having to work hard for everything my parents gave me, and everything I will, in turn, give to my children.</p>
<p>Listen, I know that the unholy concentration of wealth in America is a big, big problem, but so is having to constantly say no to people asking for change as I whizz into Whole Foods in my Tesla or Prius (depending on how my startup investments pan out). What’s the point of having all this money if I have to feel bad about it? Also, has anyone actually verified that the homeless people claiming to be veterans aren’t just pulling some elaborate fraud? I’ve never actually met a veteran and I forget for, like, decades at a time that the military even exists because the bubble of privilege where I reside is literally impregnable, but I’m suspicious nonetheless.</p>
<p>I know we need more housing, but I was here first, and I’m not giving up even one blade of grass on my water-guzzling, pesticide-leaching lawn or a single burner on my twelve-burner Viking range that I never actually use to house another human soul. Tough luck, homeless people. You and your allies can call me names, but I won’t hear you over the lushness of my climate-inappropriate rose bushes and the stucco walls I’m paying some desperate immigrant under the table to build for me on the cheap before I low-key call <span>ICE</span> and have them deported.</p>
<p>Look, if you give people homes, the next thing you know, they’re going to start to get their lives together and then get jobs and start organizing. Then they’ll expand Medicare to everyone and build a fucking light rail line instead of a goddamn border wall, and no one will drive anymore, and cars will die out, and the air will get clean, and can you imagine the problems we’ll have then?</p>
<p>No. Stop it with the new housing; I’d rather have a homeless crisis.</p>
    </div>
    

    <div>
    <p>
        Please help support our writers and keep our site ad-free by becoming a patron.
    </p>
    
  </div>

  

  

</article>

    


      <div>
        <h5>Suggested Reads</h5>
        <ul>
            <li>
    <a href="https://www.mcsweeneys.net/articles/have-you-been-the-victim-of-a-vaccine-mandate-if-so-you-may-be-entitled">
      <p>November 22, 2021</p>
      <p>Have You Been the Victim of a Vaccine Mandate? If So, You May Be Entitled</p>
</a>      
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/in-this-housing-market-ill-never-be-able-to-afford-to-haunt-my-own-home">
      <p>October 21, 2022</p>
      <p>In This Housing Market, I’ll Never Be Able to Afford to Haunt My Own Home</p>
</a>      <p><span>by </span>Zoe Pearl</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/how-could-i-be-privileged-when-my-family-didnt-have-a-housekeeper-for-our-ocean-front-home">
      <p>March  9, 2018</p>
      <p>How Could I Be Privileged When My Family Didn’t Have a Housekeeper for Our Ocean Front Home?</p>
</a>      <p><span>by </span>Arianna Durnell</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/my-remote-job-gives-me-the-freedom-to-displace-people-all-over-the-world">
      <p>September  8, 2022</p>
      <p>My Remote Job Gives Me the Freedom to Displace People All Over the World</p>
</a>      <p><span>by </span>Henry Block</p>
  </li>

        </ul>
      </div>


  <section>
        <div>
      <h5>Trending 🔥</h5>
      <ol>
          <li>
    <a href="https://www.mcsweeneys.net/articles/congrats-dipshit-youre-a-dad-now">
      <p>June 13, 2025</p>
      <p>Congrats, Dipshit,  You’re a Dad Now</p>
</a>      <p><span>by </span>Carlos Greaves</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-saruman-have-ended-my-alliance-with-the-dark-lord-sauron">
      <p>June  6, 2025</p>
      <p>I, Saruman, Have Ended My Alliance with the Dark Lord Sauron</p>
</a>      <p><span>by </span>Carlos Greaves</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/what-a-straight-mans-favorite-musical-says-about-him">
      <p>February 10, 2015</p>
      <p>What a Straight Man’s Favorite Musical Says About Him</p>
</a>      <p><span>by </span>Mara Wilson</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/its-not-going-great-but-imagine-how-much-worse-things-would-be-with-a-woman-president">
      <p>June  9, 2025</p>
      <p>It’s Not Going Great, but Imagine How Much Worse Things Would Be with a Woman President</p>
</a>      <p><span>by </span>Talia Argondezzi</p>
  </li>

      </ol>
    </div>

      <div>
    <h5>Recently</h5>
    <ul>
        <li>
    <a href="https://www.mcsweeneys.net/articles/the-revolution-will-not-be-televised-but-it-will-be-optimized-presented-in-beta">
      <p>June 19, 2025</p>
      <p>The Revolution Will Not Be Televised, But It Will Be Optimized (Presented in Beta)</p>
</a>      <p><span>by </span>David Shih</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-am-your-body-and-i-am-done-keeping-score">
      <p>June 18, 2025</p>
      <p>I Am Your Body and I Am Done Keeping Score</p>
</a>      <p><span>by </span>Madeleine Trebenski</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/the-trump-playbook-for-brokering-peace-between-israel-and-iran">
      <p>June 18, 2025</p>
      <p>The Trump Playbook for Brokering Peace Between Israel and Iran</p>
</a>      <p><span>by </span>Dash M<span>ac</span>Intyre</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/ive-figured-out-what-my-mayoral-run-is-missing-i-need-to-start-sexually-harassing-women">
      <p>June 17, 2025</p>
      <p>I’ve Figured Out What My Mayoral Run Is Missing: I Need to Start Sexually Harassing Women</p>
</a>      <p><span>by </span>Jessica M. Goldstein</p>
  </li>

    </ul>
  </div>

  </section>


    
  


    
  
  
  




        

    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn Makefiles (210 pts)]]></title>
            <link>https://makefiletutorial.com/</link>
            <guid>44325611</guid>
            <pubDate>Fri, 20 Jun 2025 08:05:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://makefiletutorial.com/">https://makefiletutorial.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44325611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="right">
                                <p><b>I built this guide because I could never quite wrap my head around Makefiles.</b> They seemed awash with hidden rules and esoteric symbols, and asking simple questions didn’t yield simple answers. To solve this, I sat down for several weekends and read everything I could about Makefiles. I've condensed the most critical knowledge into this guide. Each topic has a brief description and a self contained example that you can run yourself.</p>
<p>If you mostly understand Make, consider checking out the <a href="#makefile-cookbook">Makefile Cookbook</a>, which has a template for medium sized projects with ample comments about what each part of the Makefile is doing.</p>
<p>Good luck, and I hope you are able to slay the confusing world of Makefiles!</p>
<h2 id="getting-started">Getting Started</h2>
<h2 id="why-do-makefiles-exist">Why do Makefiles exist?</h2>
<p>Makefiles are used to help decide which parts of a large program need to be recompiled. In the vast majority of cases, C or C++ files are compiled. Other languages typically have their own tools that serve a similar purpose as Make. Make can also be used beyond compilation too, when you need a series of instructions to run depending on what files have changed. This tutorial will focus on the C/C++ compilation use case.</p>
<p>Here's an example dependency graph that you might build with Make. If any file's dependencies changes, then the file will get recompiled:</p>
<p><img src="https://makefiletutorial.com/assets/dependency_graph.png">
</p>

<h2 id="what-alternatives-are-there-to-make">What alternatives are there to Make?</h2>
<p>Popular C/C++ alternative build systems are <a href="https://scons.org/">SCons</a>, <a href="https://cmake.org/">CMake</a>, <a href="https://bazel.build/">Bazel</a>, and <a href="https://ninja-build.org/">Ninja</a>. Some code editors like <a href="https://visualstudio.microsoft.com/">Microsoft Visual Studio</a> have their own built in build tools. For Java, there's <a href="https://ant.apache.org/">Ant</a>, <a href="https://maven.apache.org/what-is-maven.html">Maven</a>, and <a href="https://gradle.org/">Gradle</a>. Other languages like Go, Rust, and TypeScript have their own build tools.</p>
<p>Interpreted languages like Python, Ruby, and raw Javascript don't require an analogue to Makefiles. The goal of Makefiles is to compile whatever files need to be compiled, based on what files have changed. But when files in interpreted languages change, nothing needs to get recompiled. When the program runs, the most recent version of the file is used.</p>
<h2 id="the-versions-and-types-of-make">The versions and types of Make</h2>
<p>There are a variety of implementations of Make, but most of this guide will work on whatever version you're using. However, it's specifically written for GNU Make, which is the standard implementation on Linux and MacOS. All the examples work for Make versions 3 and 4, which are nearly equivalent other than some esoteric differences.</p>
<h2 id="running-the-examples">Running the Examples</h2>
<p>To run these examples, you'll need a terminal and "make" installed. For each example, put the contents in a file called <code>Makefile</code>, and in that directory run the command <code>make</code>. Let's start with the simplest of Makefiles:</p>
<pre><code><span>hello:</span>
	echo <span>"Hello, World"</span></code></pre>
<blockquote>
<p>Note: Makefiles <strong>must</strong> be indented using TABs and not spaces or <code>make</code> will fail.</p>
</blockquote>
<p>Here is the output of running the above example:</p>
<pre><code><span>$</span><span> make</span>
echo "Hello, World"
Hello, World</code></pre>
<p>That's it! If you're a bit confused, here's a video that goes through these steps, along with describing the basic structure of Makefiles.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zeEMISsjO38" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="makefile-syntax">Makefile Syntax</h2>
<p>A Makefile consists of a set of <em>rules</em>. A rule generally looks like this:</p>
<pre><code><span>targets: prerequisites</span>
	command
	command
	command</code></pre>
<ul>
<li>The <em>targets</em> are file names, separated by spaces. Typically, there is only one per rule.</li>
<li>The <em>commands</em> are a series of steps typically used to make the target(s). These <em>need to start with a tab character</em>, not spaces.</li>
<li>The <em>prerequisites</em> are also file names, separated by spaces. These files need to exist before the commands for the target are run. These are also called <em>dependencies</em></li>
</ul>
<h2 id="the-essence-of-make">The essence of Make</h2>
<p>Let's start with a hello world example:</p>
<pre><code><span>hello:</span>
	echo <span>"Hello, World"</span>
	echo <span>"This line will print if the file hello does not exist."</span></code></pre>
<p>There's already a lot to take in here. Let's break it down:</p>
<ul>
<li>We have one <em>target</em> called <code>hello</code></li>
<li>This target has two <em>commands</em></li>
<li>This target has no <em>prerequisites</em></li>
</ul>
<p>We'll then run <code>make hello</code>. As long as the <code>hello</code> file does not exist, the commands will run. If <code>hello</code> does exist, no commands will run.</p>
<p>It's important to realize that I'm talking about <code>hello</code> as both a <em>target</em> and a <em>file</em>. That's because the two are directly tied together. Typically, when a target is run (aka when the commands of a target are run), the commands will create a file with the same name as the target. In this case, the <code>hello</code> <em>target</em> does not create the <code>hello</code> <em>file</em>.</p>
<p>Let's create a more typical Makefile - one that compiles a single C file. But before we do, make a file called <code>blah.c</code> that has the following contents:</p>
<pre><code><span>// blah.c</span>
<span><span>int</span> <span>main</span><span>()</span> </span>{ <span>return</span> <span>0</span>; }</code></pre>
<p>Then create the Makefile (called <code>Makefile</code>, as always):</p>
<pre><code><span>blah:</span>
	cc blah.c -o blah</code></pre>
<p>This time, try simply running <code>make</code>. Since there's no target supplied as an argument to the <code>make</code> command, the first target is run. In this case, there's only one target (<code>blah</code>). The first time you run this, <code>blah</code> will be created. The second time, you'll see <code>make: 'blah' is up to date</code>. That's because the <code>blah</code> file already exists. But there's a problem: if we modify <code>blah.c</code> and then run <code>make</code>, nothing gets recompiled.</p>
<p>We solve this by adding a prerequisite:</p>
<pre><code><span>blah: blah.c</span>
	cc blah.c -o blah</code></pre>
<p>When we run <code>make</code> again, the following set of steps happens:</p>
<ul>
<li>The first target is selected, because the first target is the default target</li>
<li>This has a prerequisite of <code>blah.c</code></li>
<li>Make decides if it should run the <code>blah</code> target. It will only run if <code>blah</code> doesn't exist, or <code>blah.c</code> is <em>newer than</em> <code>blah</code></li>
</ul>
<p>This last step is critical, and is the <strong>essence of make</strong>. What it's attempting to do is decide if the prerequisites of <code>blah</code> have changed since <code>blah</code> was last compiled. That is, if <code>blah.c</code> is modified, running <code>make</code> should recompile the file. And conversely, if <code>blah.c</code> has not changed, then it should not be recompiled.</p>
<p>To make this happen, it uses the filesystem timestamps as a proxy to determine if something has changed. This is a reasonable heuristic, because file timestamps typically will only change if the files are
modified. But it's important to realize that this isn't always the case. You could, for example, modify a file, and then change the modified timestamp of that file to something old. If you did, Make would incorrectly guess that the file hadn't changed and thus could be ignored.</p>
<p>Whew, what a mouthful. <strong>Make sure that you understand this. It's the crux of Makefiles, and might take you a few minutes to properly understand</strong>. Play around with the above examples or watch the video above if things are still confusing.</p>
<h2 id="more-quick-examples">More quick examples</h2>
<p>The following Makefile ultimately runs all three targets. When you run <code>make</code> in the terminal, it will build a program called <code>blah</code> in a series of steps:</p>
<ul>
<li>Make selects the target <code>blah</code>, because the first target is the default target</li>
<li><code>blah</code> requires <code>blah.o</code>, so make searches for the <code>blah.o</code> target</li>
<li><code>blah.o</code> requires <code>blah.c</code>, so make searches for the <code>blah.c</code> target</li>
<li><code>blah.c</code> has no dependencies, so the <code>echo</code> command is run</li>
<li>The <code>cc -c</code> command is then run, because all of the <code>blah.o</code> dependencies are finished</li>
<li>The top <code>cc</code> command is run, because all the <code>blah</code> dependencies are finished</li>
<li>That's it: <code>blah</code> is a compiled c program</li>
</ul>
<pre><code><span>blah: blah.o</span>
	cc blah.o -o blah <span># Runs third</span>

<span>blah.o: blah.c</span>
	cc -c blah.c -o blah.o <span># Runs second</span>

<span># Typically blah.c would already exist, but I want to limit any additional required files</span>
<span>blah.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; blah.c <span># Runs first</span></code></pre>
<p>If you delete <code>blah.c</code>, all three targets will be rerun. If you edit it (and thus change the timestamp to newer than <code>blah.o</code>), the first two targets will run. If you run <code>touch blah.o</code> (and thus change the timestamp to newer than <code>blah</code>), then only the first target will run. If you change nothing, none of the targets will run. Try it out!</p>
<p>This next example doesn't do anything new, but is nontheless a good additional example. It will always run both targets, because <code>some_file</code> depends on <code>other_file</code>, which is never created.</p>
<pre><code><span>some_file: other_file</span>
	echo <span>"This will always run, and runs second"</span>
	touch some_file

<span>other_file:</span>
	echo <span>"This will always run, and runs first"</span></code></pre>
<h2 id="make-clean">Make clean</h2>
<p><code>clean</code> is often used as a target that removes the output of other targets, but it is not a special word in Make. You can run <code>make</code> and <code>make clean</code> on this to create and delete <code>some_file</code>.</p>
<p>Note that <code>clean</code> is doing two new things here:</p>
<ul>
<li>It's a target that is not first (the default), and not a prerequisite. That means it'll never run unless you explicitly call <code>make clean</code></li>
<li>It's not intended to be a filename. If you happen to have a file named <code>clean</code>, this target won't run, which is not what we want. See <code>.PHONY</code> later in this tutorial on how to fix this</li>
</ul>
<pre><code><span>some_file: </span>
	touch some_file

<span>clean:</span>
	rm -f some_file</code></pre>
<h2 id="variables">Variables</h2>
<p>Variables can only be strings. You'll typically want to use <code>:=</code>, but <code>=</code> also works. See <a href="#variables-pt-2">Variables Pt 2</a>.</p>
<p>Here's an example of using variables:</p>
<pre><code>files := file1 file2
<span>some_file: <span>$(files)</span></span>
	echo <span>"Look at this variable: "</span> <span>$(files)</span>
	touch some_file

<span>file1:</span>
	touch file1
<span>file2:</span>
	touch file2

<span>clean:</span>
	rm -f file1 file2 some_file</code></pre>
<p>Single or double quotes have no meaning to Make. They are simply characters that are assigned to the variable. Quotes <em>are</em> useful to shell/bash, though, and you need them in commands like <code>printf</code>. In this example, the two commands behave the same:</p>
<pre><code>a := one two<span># a is set to the string "one two"</span>
b := 'one two' <span># Not recommended. b is set to the string "'one two'"</span>
<span>all:</span>
	printf '$a'
	printf $b</code></pre>
<p>Reference variables using either <code>${}</code> or <code>$()</code></p>
<pre><code>x := dude

<span>all:</span>
	echo <span>$(x)</span>
	echo ${x}

	<span># Bad practice, but works</span>
	echo $x </code></pre>
<h2 id="targets">Targets</h2>
<h2 id="the-all-target">The all target</h2>
<!--  (Section 4.4) -->
<p>Making multiple targets and you want all of them to run? Make an <code>all</code> target.
Since this is the first rule listed, it will run by default if <code>make</code> is called without specifying a target.</p>
<pre><code><span>all: one two three</span>

<span>one:</span>
	touch one
<span>two:</span>
	touch two
<span>three:</span>
	touch three

<span>clean:</span>
	rm -f one two three
</code></pre>
<h2 id="multiple-targets">Multiple targets</h2>
<!--  (Section 4.8) -->
<p>When there are multiple targets for a rule, the commands will be run for each target. <code>$@</code> is an <a href="#automatic-variables">automatic variable</a> that contains the target name.</p>
<pre><code><span>all: f1.o f2.o</span>

f1.o f2.o:
	echo <span>$@</span>
<span># Equivalent to:</span>
<span># f1.o:</span>
<span>#	 echo f1.o</span>
<span># f2.o:</span>
<span>#	 echo f2.o</span>
</code></pre>
<h2 id="automatic-variables-and-wildcards">Automatic Variables and Wildcards</h2>
<h2 id="-wildcard">* Wildcard</h2>
<!--  (Section 4.2) -->
<p>Both <code>*</code> and <code>%</code> are called wildcards in Make, but they mean entirely different things. <code>*</code> searches your filesystem for matching filenames. I suggest that you always wrap it in the <code>wildcard</code> function, because otherwise you may fall into a common pitfall described below.</p>
<pre><code><span># Print out file information about every .c file</span>
<span>print: $(wildcard *.c)</span>
	ls -la  <span>$?</span></code></pre>
<p><code>*</code> may be used in the target, prerequisites, or in the <code>wildcard</code> function.</p>
<p>Danger: <code>*</code> may not be directly used in a variable definitions</p>
<p>Danger: When <code>*</code> matches no files, it is left as it is (unless run in the <code>wildcard</code> function)</p>
<pre><code>thing_wrong := *.o <span># Don't do this! '*' will not get expanded</span>
thing_right := <span>$(<span>wildcard</span> *.o)</span>

<span>all: one two three four</span>

<span># Fails, because $(thing_wrong) is the string "*.o"</span>
<span>one: <span>$(thing_wrong)</span></span>

<span># Stays as *.o if there are no files that match this pattern :(</span>
<span>two: *.o </span>

<span># Works as you would expect! In this case, it does nothing.</span>
<span>three: <span>$(thing_right)</span></span>

<span># Same as rule three</span>
<span>four: $(wildcard *.o)</span></code></pre>
<h2 id="-wildcard-1">% Wildcard</h2>
<p><code>%</code> is really useful, but is somewhat confusing because of the variety of situations it can be used in.</p>
<ul>
<li>When used in "matching" mode, it matches one or more characters in a string. This match is called the stem.</li>
<li>When used in "replacing" mode, it takes the stem that was matched and replaces that in a string.</li>
<li><code>%</code> is most often used in rule definitions and in some specific functions.</li>
</ul>
<p>See these sections on examples of it being used:</p>
<ul>
<li><a href="#static-pattern-rules">Static Pattern Rules</a></li>
<li><a href="#pattern-rules">Pattern Rules</a></li>
<li><a href="#string-substitution">String Substitution</a></li>
<li><a href="#the-vpath-directive">The vpath Directive</a></li>
</ul>
<h2 id="automatic-variables">Automatic Variables</h2>
<!--  (Section 10.5) -->
<p>There are many <a href="https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html">automatic variables</a>, but often only a few show up:</p>
<pre><code><span>hey: one two</span>
	<span># Outputs "hey", since this is the target name</span>
	echo <span>$@</span>

	<span># Outputs all prerequisites newer than the target</span>
	echo <span>$?</span>

	<span># Outputs all prerequisites</span>
	echo <span>$^</span>

	<span># Outputs the first prerequisite</span>
	echo <span>$&lt;</span>

	touch hey

<span>one:</span>
	touch one

<span>two:</span>
	touch two

<span>clean:</span>
	rm -f hey one two
</code></pre>
<h2 id="fancy-rules">Fancy Rules</h2>
<h2 id="implicit-rules">Implicit Rules</h2>
<!--  (Section 10) -->
<p>Make loves c compilation. And every time it expresses its love, things get confusing. Perhaps the most confusing part of Make is the magic/automatic rules that are made. Make calls these "implicit" rules. I don't personally agree with this design decision, and I don't recommend using them, but they're often used and are thus useful to know. Here's a list of implicit rules:</p>
<ul>
<li>Compiling a C program: <code>n.o</code> is made automatically from <code>n.c</code> with a command of the form <code>$(CC) -c $(CPPFLAGS) $(CFLAGS) $^ -o $@</code></li>
<li>Compiling a C++ program: <code>n.o</code> is made automatically from <code>n.cc</code> or <code>n.cpp</code> with a command of the form <code>$(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@</code></li>
<li>Linking a single object file: <code>n</code> is made automatically from <code>n.o</code> by running the command <code>$(CC) $(LDFLAGS) $^ $(LOADLIBES) $(LDLIBS) -o $@</code></li>
</ul>
<p>The important variables used by implicit rules are:</p>
<ul>
<li><code>CC</code>: Program for compiling C programs; default <code>cc</code></li>
<li><code>CXX</code>: Program for compiling C++ programs; default <code>g++</code></li>
<li><code>CFLAGS</code>: Extra flags to give to the C compiler</li>
<li><code>CXXFLAGS</code>: Extra flags to give to the C++ compiler</li>
<li><code>CPPFLAGS</code>: Extra flags to give to the C preprocessor</li>
<li><code>LDFLAGS</code>: Extra flags to give to compilers when they are supposed to invoke the linker</li>
</ul>
<p>Let's see how we can now build a C program without ever explicitly telling Make how to do the compilation:</p>
<pre><code>CC = gcc <span># Flag for implicit rules</span>
CFLAGS = -g <span># Flag for implicit rules. Turn on debug info</span>

<span># Implicit rule #1: blah is built via the C linker implicit rule</span>
<span># Implicit rule #2: blah.o is built via the C compilation implicit rule, because blah.c exists</span>
<span>blah: blah.o</span>

<span>blah.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; blah.c

<span>clean:</span>
	rm -f blah*</code></pre>
<h2 id="static-pattern-rules">Static Pattern Rules</h2>
<!--  (Section 4.10) -->
<p>Static pattern rules are another way to write less in a Makefile. Here's their syntax:</p>
<pre><code><span>targets...: target-pattern: prereq-patterns ...</span>
   commands</code></pre>
<p>The essence is that the given <code>target</code> is matched by the <code>target-pattern</code> (via a <code>%</code> wildcard). Whatever was matched is called the <em>stem</em>. The stem is then substituted into the <code>prereq-pattern</code>, to generate the target's prereqs.</p>
<p>A typical use case is to compile <code>.c</code> files into <code>.o</code> files. Here's the <em>manual way</em>:</p>
<pre><code>objects = foo.o bar.o all.o
<span>all: <span>$(objects)</span></span>
	<span>$(CC)</span> <span>$^</span> -o all

<span>foo.o: foo.c</span>
	<span>$(CC)</span> -c foo.c -o foo.o

<span>bar.o: bar.c</span>
	<span>$(CC)</span> -c bar.c -o bar.o

<span>all.o: all.c</span>
	<span>$(CC)</span> -c all.c -o all.o

<span>all.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; all.c

<span># Note: all.c does not use this rule because Make prioritizes more specific matches when there is more than one match.</span>
<span>%.c:</span>
	touch <span>$@</span>

<span>clean:</span>
	rm -f *.c *.o all</code></pre>
<p>Here's the more <em>efficient way</em>, using a static pattern rule:</p>
<pre><code>objects = foo.o bar.o all.o
<span>all: <span>$(objects)</span></span>
	<span>$(CC)</span> <span>$^</span> -o all

<span># Syntax - targets ...: target-pattern: prereq-patterns ...</span>
<span># In the case of the first target, foo.o, the target-pattern matches foo.o and sets the "stem" to be "foo".</span>
<span># It then replaces the '%' in prereq-patterns with that stem</span>
<span>$(objects)</span>: %.o: %.c
	<span>$(CC)</span> -c <span>$^</span> -o <span>$@</span>

<span>all.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; all.c

<span># Note: all.c does not use this rule because Make prioritizes more specific matches when there is more than one match.</span>
<span>%.c:</span>
	touch <span>$@</span>

<span>clean:</span>
	rm -f *.c *.o all</code></pre>
<h2 id="static-pattern-rules-and-filter">Static Pattern Rules and Filter</h2>
<!--  (Section 4.10) -->
<p>While I introduce the <a href="#the-filter-function">filter function</a> later on, it's common to use in static pattern rules, so I'll mention that here. The <code>filter</code> function can be used in Static pattern rules to match the correct files. In this example, I made up the <code>.raw</code> and <code>.result</code> extensions.</p>
<pre><code>obj_files = foo.result bar.o lose.o
src_files = foo.raw bar.c lose.c

<span>all: <span>$(obj_files)</span></span>
<span># Note: PHONY is important here. Without it, implicit rules will try to build the executable "all", since the prereqs are ".o" files.</span>
<span><span>.PHONY</span>: all </span>

<span># Ex 1: .o files depend on .c files. Though we don't actually make the .o file.</span>
<span>$(<span>filter</span> %.o,<span>$(obj_files)</span>)</span>: %.o: %.c
	echo <span>"target: <span>$@</span> prereq: <span>$&lt;</span>"</span>

<span># Ex 2: .result files depend on .raw files. Though we don't actually make the .result file.</span>
<span>$(<span>filter</span> %.result,<span>$(obj_files)</span>)</span>: %.result: %.raw
	echo <span>"target: <span>$@</span> prereq: <span>$&lt;</span>"</span> 

%.c %.raw:
	touch <span>$@</span>

<span>clean:</span>
	rm -f <span>$(src_files)</span></code></pre>
<h2 id="pattern-rules">Pattern Rules</h2>
<p>Pattern rules are often used but quite confusing. You can look at them as two ways:</p>
<ul>
<li>A way to define your own implicit rules</li>
<li>A simpler form of static pattern rules</li>
</ul>
<p>Let's start with an example first:</p>
<pre><code><span># Define a pattern rule that compiles every .c file into a .o file</span>
%.o : %.c
		<span>$(CC)</span> -c <span>$(CFLAGS)</span> <span>$(CPPFLAGS)</span> <span>$&lt;</span> -o <span>$@</span></code></pre>
<p>Pattern rules contain a '%' in the target. This '%' matches any nonempty string, and the other characters match themselves. ‘%’ in a prerequisite of a pattern rule stands for the same stem that was matched by the ‘%’ in the target.</p>
<p>Here's another example:</p>
<pre><code><span># Define a pattern rule that has no pattern in the prerequisites.</span>
<span># This just creates empty .c files when needed.</span>
<span>%.c:</span>
   touch <span>$@</span></code></pre>
<h2 id="double-colon-rules">Double-Colon Rules</h2>
<!--  (Section 4.11) -->
<p>Double-Colon Rules are rarely used, but allow multiple rules to be defined for the same target. If these were single colons, a warning would be printed and only the second set of commands would run.</p>
<pre><code><span>all: blah</span>

<span>blah::</span>
	echo <span>"hello"</span>

<span>blah::</span>
	echo <span>"hello again"</span></code></pre>
<h2 id="commands-and-execution">Commands and execution</h2>
<h2 id="command-echoingsilencing">Command Echoing/Silencing</h2>
<!--  (Section 5.1) -->
<p>Add an <code>@</code> before a command to stop it from being printed<br>You can also run make with <code>-s</code> to add an <code>@</code> before each line  </p>
<pre><code><span>all: </span>
	@echo <span>"This make line will not be printed"</span>
	echo <span>"But this will"</span></code></pre>
<h2 id="command-execution">Command Execution</h2>
<!--  (Section 5.2) -->
<p>Each command is run in a new shell (or at least the effect is as such)</p>
<pre><code><span>all: </span>
	cd ..
	<span># The cd above does not affect this line, because each command is effectively run in a new shell</span>
	echo `pwd`

	<span># This cd command affects the next because they are on the same line</span>
	cd ..;echo `pwd`

	<span># Same as above</span>
	cd ..; \
	echo `pwd`
</code></pre>
<h2 id="default-shell">Default Shell</h2>
<!--  (Section 5.2) -->
<p>The default shell is <code>/bin/sh</code>. You can change this by changing the variable SHELL:</p>
<pre><code>SHELL=/bin/bash

<span>cool:</span>
	echo <span>"Hello from bash"</span></code></pre>
<h2 id="double-dollar-sign">Double dollar sign</h2>
<p>If you want a string to have a dollar sign, you can use <code>$$</code>. This is how to use a shell variable in <code>bash</code> or <code>sh</code>.</p>
<p>Note the differences between Makefile variables and Shell variables in this next example.</p>
<pre><code>make_var = I am a make variable
<span>all:</span>
	<span># Same as running "sh_var='I am a shell variable'; echo $sh_var" in the shell</span>
	sh_var='I am a shell variable'; echo $$sh_var

	<span># Same as running "echo I am a make variable" in the shell</span>
	echo <span>$(make_var)</span></code></pre>
<h2 id="error-handling-with--k--i-and--">Error handling with <code>-k</code>, <code>-i</code>, and <code>-</code></h2>
<!--  (Section 5.4) -->
<p>Add <code>-k</code> when running make to continue running even in the face of errors. Helpful if you want to see all the errors of Make at once.<br>Add a <code>-</code> before a command to suppress the error<br>Add <code>-i</code> to make to have this happen for every command.</p>
<!--  (Section 5.4) -->
<pre><code><span>one:</span>
	<span># This error will be printed but ignored, and make will continue to run</span>
	-false
	touch one
</code></pre>
<h2 id="interrupting-or-killing-make">Interrupting or killing make</h2>
<!--  (Section 5.5) -->
<p>Note only: If you <code>ctrl+c</code> make, it will delete the newer targets it just made.</p>
<h2 id="recursive-use-of-make">Recursive use of make</h2>
<!--  (Section 5.6) -->
<p>To recursively call a makefile, use the special <code>$(MAKE)</code> instead of <code>make</code> because it will pass the make flags for you and won't itself be affected by them.</p>
<pre><code>new_contents = <span>"hello:\n\ttouch inside_file"</span>
<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span>clean:</span>
	rm -rf subdir
</code></pre>
<h2 id="export-environments-and-recursive-make">Export, environments, and recursive make</h2>
<!--  (Section 5.6) -->
<p>When Make starts, it automatically creates Make variables out of all the environment variables that are set when it's executed.</p>
<pre><code><span># Run this with "export shell_env_var='I am an environment variable'; make"</span>
<span>all:</span>
	<span># Print out the Shell variable</span>
	echo $$shell_env_var

	<span># Print out the Make variable</span>
	echo <span>$(shell_env_var)</span></code></pre>
<p>The <code>export</code> directive takes a variable and sets it the environment for all shell commands in all the recipes:</p>
<pre><code>shell_env_var=Shell env var, created inside of Make
<span>export</span> shell_env_var
<span>all:</span>
	echo <span>$(shell_env_var)</span>
	echo $$shell_env_var</code></pre>
<p>As such, when you run the <code>make</code> command inside of make, you can use the <code>export</code> directive to make it accessible to sub-make commands. In this example, <code>cooly</code> is exported such that the makefile in subdir can use it.</p>
<pre><code>new_contents = <span>"hello:\n\techo \$<span>$(cooly)</span>"</span>

<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	@echo <span>"---MAKEFILE CONTENTS---"</span>
	@cd subdir &amp;&amp; cat makefile
	@echo <span>"---END MAKEFILE CONTENTS---"</span>
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span># Note that variables and exports. They are set/affected globally.</span>
cooly = <span>"The subdirectory can see me!"</span>
<span>export</span> cooly
<span># This would nullify the line above: unexport cooly</span>

<span>clean:</span>
	rm -rf subdir</code></pre>
<!--  (Section 5.6) -->
<p>You need to export variables to have them run in the shell as well.  </p>
<pre><code>one=this will only work locally
<span>export</span> two=we can run subcommands with this

<span>all: </span>
	@echo <span>$(one)</span>
	@echo $$one
	@echo <span>$(two)</span>
	@echo $$two</code></pre>
<!--  (Section 5.6) -->
<p><code>.EXPORT_ALL_VARIABLES</code> exports all variables for you.</p>
<pre><code><span>.EXPORT_ALL_VARIABLES:</span>
new_contents = <span>"hello:\n\techo \$<span>$(cooly)</span>"</span>

cooly = <span>"The subdirectory can see me!"</span>
<span># This would nullify the line above: unexport cooly</span>

<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	@echo <span>"---MAKEFILE CONTENTS---"</span>
	@cd subdir &amp;&amp; cat makefile
	@echo <span>"---END MAKEFILE CONTENTS---"</span>
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span>clean:</span>
	rm -rf subdir</code></pre>
<h2 id="arguments-to-make">Arguments to make</h2>
<!--  (Section 9) -->

<p>There's a nice <a href="http://www.gnu.org/software/make/manual/make.html#Options-Summary">list of options</a> that can be run from make. Check out <code>--dry-run</code>, <code>--touch</code>, <code>--old-file</code>. </p>
<p>You can have multiple targets to make, i.e. <code>make clean run test</code> runs the <code>clean</code> goal, then <code>run</code>, and then <code>test</code>.</p>
<h2 id="variables-pt-2">Variables Pt. 2</h2>
<h2 id="flavors-and-modification">Flavors and modification</h2>
<!-- (6.1, 6.2, 6.3) -->
<p>There are two flavors of variables:  </p>
<ul>
<li>recursive (use <code>=</code>) - only looks for the variables when the command is <em>used</em>, not when it's <em>defined</em>.  </li>
<li>simply expanded (use <code>:=</code>) - like normal imperative programming -- only those defined so far get expanded</li>
</ul>
<pre><code><span># Recursive variable. This will print "later" below</span>
one = one ${later_variable}
<span># Simply expanded variable. This will not print "later" below</span>
two := two ${later_variable}

later_variable = later

<span>all: </span>
	echo <span>$(one)</span>
	echo <span>$(two)</span></code></pre>
<p>Simply expanded (using <code>:=</code>) allows you to append to a variable. Recursive definitions will give an infinite loop error.  </p>
<pre><code>one = hello
<span># one gets defined as a simply expanded variable (:=) and thus can handle appending</span>
one := ${one} there

<span>all: </span>
	echo <span>$(one)</span></code></pre>
<p><code>?=</code> only sets variables if they have not yet been set</p>
<pre><code>one = hello
one ?= will not be set
two ?= will be set

<span>all: </span>
	echo <span>$(one)</span>
	echo <span>$(two)</span></code></pre>
<p>Spaces at the end of a line are not stripped, but those at the start are. To make a variable with a single space, use <code>$(nullstring)</code></p>
<pre><code>with_spaces = hello   <span># with_spaces has many spaces after "hello"</span>
after = <span>$(with_spaces)</span>there

nullstring =
space = <span>$(nullstring)</span> <span># Make a variable with a single space.</span>

<span>all: </span>
	echo <span>"<span>$(after)</span>"</span>
	echo start<span>"<span>$(space)</span>"</span>end</code></pre>
<p>An undefined variable is actually an empty string!</p>
<pre><code><span>all: </span>
	<span># Undefined variables are just empty strings!</span>
	echo <span>$(nowhere)</span></code></pre>
<p>Use <code>+=</code> to append</p>
<pre><code>foo := start
foo += more

<span>all: </span>
	echo <span>$(foo)</span></code></pre>
<p><a href="#string-substitution">String Substitution</a> is also a really common and useful way to modify variables. Also check out <a href="https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions">Text Functions</a> and <a href="https://www.gnu.org/software/make/manual/html_node/File-Name-Functions.html#File-Name-Functions">Filename Functions</a>.</p>
<h2 id="command-line-arguments-and-override">Command line arguments and override</h2>
<!--  (Section 6.7) -->
<p>You can override variables that come from the command line by using <code>override</code>.
Here we ran make with <code>make option_one=hi</code></p>
<pre><code><span># Overrides command line arguments</span>
<span>override</span> option_one = did_override
<span># Does not override command line arguments</span>
option_two = not_override
<span>all: </span>
	echo <span>$(option_one)</span>
	echo <span>$(option_two)</span></code></pre>
<h2 id="list-of-commands-and-define">List of commands and define</h2>
<!--  (Section 6.8) -->
<p>The <a href="https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html">define directive</a> is not a function, though it may look that way. I've seen it used so infrequently that I won't go into details, but it's mainly used for defining <a href="https://www.gnu.org/software/make/manual/html_node/Canned-Recipes.html#Canned-Recipes">canned recipes</a> and also pairs well with the <a href="https://www.gnu.org/software/make/manual/html_node/Eval-Function.html#Eval-Function">eval function</a>.</p>
<p><code>define</code>/<code>endef</code> simply creates a variable that is set to a list of commands. Note here that it's a bit different than having a semi-colon between commands, because each is run in a separate shell, as expected.</p>
<pre><code>one = <span>export</span> blah=<span>"I was set!"</span>; echo $$blah

<span>define</span> two
<span>export</span> blah=<span>"I was set!"</span>
echo $$blah
<span>endef</span>

<span>all: </span>
	@echo <span>"This prints 'I was set'"</span>
	@<span>$(one)</span>
	@echo <span>"This does not print 'I was set' because each command runs in a separate shell"</span>
	@<span>$(two)</span></code></pre>
<h2 id="target-specific-variables">Target-specific variables</h2>
<!--  (Section 6.10) -->
<p>Variables can be set for specific targets</p>
<pre><code><span>all: one = cool</span>

<span>all: </span>
	echo one is defined: <span>$(one)</span>

<span>other:</span>
	echo one is nothing: <span>$(one)</span></code></pre>
<h2 id="pattern-specific-variables">Pattern-specific variables</h2>
<!--  (Section 6.11) -->
<p>You can set variables for specific target <em>patterns</em></p>
<pre><code><span>%.c: one = cool</span>

<span>blah.c: </span>
	echo one is defined: <span>$(one)</span>

<span>other:</span>
	echo one is nothing: <span>$(one)</span></code></pre>
<h2 id="conditional-part-of-makefiles">Conditional part of Makefiles</h2>
<h2 id="conditional-ifelse">Conditional if/else</h2>
<!--  (Section 7.1) -->
<pre><code>foo = ok

<span>all:</span>
<span>ifeq</span> (<span>$(foo)</span>, ok)
	echo <span>"foo equals ok"</span>
<span>else</span>
	echo <span>"nope"</span>
<span>endif</span></code></pre>
<h2 id="check-if-a-variable-is-empty">Check if a variable is empty</h2>
<!--  (Section 7.2) -->
<pre><code>nullstring =
foo = <span>$(nullstring)</span> <span># end of line; there is a space here</span>

<span>all:</span>
<span>ifeq</span> (<span>$(<span>strip</span> <span>$(foo)</span>)</span>,)
	echo <span>"foo is empty after being stripped"</span>
<span>endif</span>
<span>ifeq</span> (<span>$(nullstring)</span>,)
	echo <span>"nullstring doesn't even have spaces"</span>
<span>endif</span></code></pre>
<h2 id="check-if-a-variable-is-defined">Check if a variable is defined</h2>
<!--  (Section 7.2) -->
<p>ifdef does not expand variable references; it just sees if something is defined at all</p>
<pre><code>bar =
foo = <span>$(bar)</span>

<span>all:</span>
<span>ifdef</span> foo
	echo <span>"foo is defined"</span>
<span>endif</span>
<span>ifndef</span> bar
	echo <span>"but bar is not"</span>
<span>endif</span>
</code></pre>
<h2 id="makeflags">$(MAKEFLAGS)</h2>
<!-- `(Section 7.3) -->
<p>This example shows you how to test make flags with <code>findstring</code> and <code>MAKEFLAGS</code>. Run this example with <code>make -i</code> to see it print out the echo statement.</p>
<pre><code><span>all:</span>
<span># Search for the "-i" flag. MAKEFLAGS is just a list of single characters, one per flag. So look for "i" in this case.</span>
<span>ifneq</span> (,<span>$(<span>findstring</span> i, <span>$(MAKEFLAGS)</span>)</span>)
	echo <span>"i was passed to MAKEFLAGS"</span>
<span>endif</span></code></pre>
<h2 id="functions">Functions</h2>
<h2 id="first-functions">First Functions</h2>
<!--  (Section 8.1) -->
<p><em>Functions</em> are mainly just for text processing. Call functions with <code>$(fn, arguments)</code> or <code>${fn, arguments}</code>. Make has a decent amount of <a href="https://www.gnu.org/software/make/manual/html_node/Functions.html">builtin functions</a>.</p>
<pre><code>bar := ${subst not,<span>"totally"</span>, <span>"I am not superman"</span>}
<span>all: </span>
	@echo <span>$(bar)</span>
</code></pre>
<p>If you want to replace spaces or commas, use variables</p>
<pre><code>comma := ,
empty:=
space := <span>$(empty)</span> <span>$(empty)</span>
foo := a b c
bar := <span>$(<span>subst</span> <span>$(space)</span>,<span>$(comma)</span>,<span>$(foo)</span>)</span>

<span>all: </span>
	@echo <span>$(bar)</span></code></pre>
<p>Do NOT include spaces in the arguments after the first. That will be seen as part of the string.</p>
<pre><code>comma := ,
empty:=
space := <span>$(empty)</span> <span>$(empty)</span>
foo := a b c
bar := <span>$(<span>subst</span> <span>$(space)</span>, <span>$(comma)</span> , <span>$(foo)</span>)</span> <span># Watch out!</span>

<span>all: </span>
	<span># Output is ", a , b , c". Notice the spaces introduced</span>
	@echo <span>$(bar)</span>
</code></pre>
<!-- # 8.2, 8.3, 8.9 TODO do something about the fns   
# TODO 8.7 origin fn? Better in documentation?
-->

<h2 id="string-substitution">String Substitution</h2>
<p><code>$(patsubst pattern,replacement,text)</code> does the following:</p>
<p>"Finds whitespace-separated words in text that match pattern and replaces them with replacement. Here pattern may contain a ‘%’ which acts as a wildcard, matching any number of any characters within a word. If replacement also contains a ‘%’, the ‘%’ is replaced by the text that matched the ‘%’ in pattern. Only the first ‘%’ in the pattern and replacement is treated this way; any subsequent ‘%’ is unchanged." (<a href="https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions">GNU docs</a>)</p>
<p>The substitution reference <code>$(text:pattern=replacement)</code> is a shorthand for this.</p>
<p>There's another shorthand that replaces only suffixes: <code>$(text:suffix=replacement)</code>. No <code>%</code> wildcard is used here.</p>
<p>Note: don't add extra spaces for this shorthand. It will be seen as a search or replacement term.</p>
<pre><code>foo := a.o b.o l.a c.o
one := <span>$(<span>patsubst</span> %.o,%.c,<span>$(foo)</span>)</span>
<span># This is a shorthand for the above</span>
two := $(foo:%.o=%.c)
<span># This is the suffix-only shorthand, and is also equivalent to the above.</span>
three := $(foo:.o=.c)

<span>all:</span>
	echo <span>$(one)</span>
	echo <span>$(two)</span>
	echo <span>$(three)</span></code></pre>
<h2 id="the-foreach-function">The foreach function</h2>
<!--  (Section 8.4) -->
<p>The foreach function looks like this: <code>$(foreach var,list,text)</code>. It converts one list of words (separated by spaces) to another. <code>var</code> is set to each word in list, and <code>text</code> is expanded for each word.<br>This appends an exclamation after each word:</p>
<pre><code>foo := who are you
<span># For each "word" in foo, output that same word with an exclamation after</span>
bar := <span>$(<span>foreach</span> wrd,<span>$(foo)</span>,<span>$(wrd)</span>!)</span>

<span>all:</span>
	<span># Output is "who! are! you!"</span>
	@echo <span>$(bar)</span></code></pre>
<h2 id="the-if-function">The if function</h2>
<!--  (Section 8.5) -->
<p><code>if</code> checks if the first argument is nonempty. If so, runs the second argument, otherwise runs the third.</p>
<pre><code>foo := <span>$(<span>if</span> this-is-not-empty,then!,else!)</span>
empty :=
bar := <span>$(<span>if</span> <span>$(empty)</span>,then!,else!)</span>

<span>all:</span>
	@echo <span>$(foo)</span>
	@echo <span>$(bar)</span></code></pre>
<h2 id="the-call-function">The call function</h2>
<!--  (Section 8.6) -->
<p>Make supports creating basic functions. You "define" the function just by creating a variable, but use the parameters <code>$(0)</code>, <code>$(1)</code>, etc. You then call the function with the special <a href="https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function"><code>call</code></a> builtin function. The syntax is <code>$(call variable,param,param)</code>. <code>$(0)</code> is the variable, while <code>$(1)</code>, <code>$(2)</code>, etc. are the params.</p>
<pre><code>sweet_new_fn = Variable Name: $(0) First: $(1) Second: $(2) Empty Variable: $(3)

<span>all:</span>
	<span># Outputs "Variable Name: sweet_new_fn First: go Second: tigers Empty Variable:"</span>
	@echo <span>$(<span>call</span> sweet_new_fn, go, tigers)</span></code></pre>
<h2 id="the-shell-function">The shell function</h2>
<!--  (Section 8.8) -->
<p>shell - This calls the shell, but it replaces newlines with spaces!</p>
<pre><code><span>all: </span>
	@echo <span>$(<span>shell</span> ls -la)</span> <span># Very ugly because the newlines are gone!</span></code></pre>
<h2 id="the-filter-function">The filter function</h2>
<p>The <code>filter</code> function is used to select certain elements from a list that match a specific pattern. For example, this will select all elements in <code>obj_files</code> that end with <code>.o</code>.</p>
<pre><code>obj_files = foo.result bar.o lose.o
filtered_files = <span>$(<span>filter</span> %.o,<span>$(obj_files)</span>)</span>

<span>all:</span>
	@echo <span>$(filtered_files)</span></code></pre>
<p>Filter can also be used in more complex ways:</p>
<ol>
<li><p><strong>Filtering multiple patterns</strong>: You can filter multiple patterns at once. For example, <code>$(filter %.c %.h, $(files))</code> will select all <code>.c</code> and <code>.h</code> files from the files list.</p>
</li>
<li><p><strong>Negation</strong>: If you want to select all elements that do not match a pattern, you can use <code>filter-out</code>. For example, <code>$(filter-out %.h, $(files))</code> will select all files that are not <code>.h</code> files.</p>
</li>
<li><p><strong>Nested filter</strong>: You can nest filter functions to apply multiple filters. For example, <code>$(filter %.o, $(filter-out test%, $(objects)))</code> will select all object files that end with <code>.o</code> but don't start with <code>test</code>.</p>
</li>
</ol>
<h2 id="other-features">Other Features</h2>
<h2 id="include-makefiles">Include Makefiles</h2>
<p>The include directive tells make to read one or more other makefiles. It's a line in the makefile that looks like this:</p>
<pre><code><span>include</span> filenames...</code></pre>
<p>This is particularly useful when you use compiler flags like <code>-M</code> that create Makefiles based on the source. For example, if some c files includes a header, that header will be added to a Makefile that's written by gcc. I talk about this more in the <a href="#makefile-cookbook">Makefile Cookbook</a></p>
<h2 id="the-vpath-directive">The vpath Directive</h2>
<!--  (Section 4.3.2) -->
<p>Use vpath to specify where some set of prerequisites exist. The format is <code>vpath &lt;pattern&gt; &lt;directories, space/colon separated&gt;</code>
<code>&lt;pattern&gt;</code> can have a <code>%</code>, which matches any zero or more characters.
You can also do this globallyish with the variable VPATH</p>
<pre><code><span>vpath</span> %.h ../headers ../other-directory

<span># Note: vpath allows blah.h to be found even though blah.h is never in the current directory</span>
<span>some_binary: ../headers blah.h</span>
	touch some_binary

<span>../headers:</span>
	mkdir ../headers

<span># We call the target blah.h instead of ../headers/blah.h, because that's the prereq that some_binary is looking for</span>
<span># Typically, blah.h would already exist and you wouldn't need this.</span>
<span>blah.h:</span>
	touch ../headers/blah.h

<span>clean:</span>
	rm -rf ../headers
	rm -f some_binary
</code></pre>
<h2 id="multiline">Multiline</h2>
<p>The backslash ("\") character gives us the ability to use multiple lines when the commands are too long</p>
<pre><code><span>some_file: </span>
	echo This line is too long, so \
		it is broken up into multiple lines</code></pre>
<h2 id="phony">.phony</h2>
<p>Adding <code>.PHONY</code> to a target will prevent Make from confusing the phony target with a file name. In this example, if the file <code>clean</code> is created, make clean will still be run. Technically, I should have used it in every example with <code>all</code> or <code>clean</code>, but I wanted to keep the examples clean. Additionally, "phony" targets typically have names that are rarely file names, and in practice many people skip this.</p>
<pre><code><span>some_file:</span>
	touch some_file
	touch clean

<span><span>.PHONY</span>: clean</span>
<span>clean:</span>
	rm -f some_file
	rm -f clean</code></pre>
<h2 id="delete_on_error">.delete_on_error</h2>
<!-- (Section 5.4) -->

<p>The make tool will stop running a rule (and will propogate back to prerequisites) if a command returns a nonzero exit status.<br><code>DELETE_ON_ERROR</code> will delete the target of a rule if the rule fails in this manner. This will happen for all targets, not just the one it is before like PHONY. It's a good idea to always use this, even though make does not for historical reasons.  </p>
<pre><code><span>.DELETE_ON_ERROR:</span>
<span>all: one two</span>

<span>one:</span>
	touch one
	false

<span>two:</span>
	touch two
	false</code></pre>
<h2 id="makefile-cookbook">Makefile Cookbook</h2>
<p>Let's go through a really juicy Make example that works well for medium sized projects.</p>
<p>The neat thing about this makefile is it automatically determines dependencies for you. All you have to do is put your C/C++ files in the <code>src/</code> folder.</p>
<pre><code><span># Thanks to Job Vranish (https://spin.atomicobject.com/2016/08/26/makefile-c-projects/)</span>
TARGET_EXEC := final_program

BUILD_DIR := ./build
SRC_DIRS := ./src

<span># Find all the C and C++ files we want to compile</span>
<span># Note the single quotes around the * expressions. The shell will incorrectly expand these otherwise, but we want to send the * directly to the find command.</span>
SRCS := <span>$(<span>shell</span> find <span>$(SRC_DIRS)</span> -name '*.cpp' -<span>or</span> -name '*.c' -<span>or</span> -name '*.s')</span>

<span># Prepends BUILD_DIR and appends .o to every src file</span>
<span># As an example, ./your_dir/hello.cpp turns into ./build/./your_dir/hello.cpp.o</span>
OBJS := $(SRCS:%=<span>$(BUILD_DIR)</span>/%.o)

<span># String substitution (suffix version without %).</span>
<span># As an example, ./build/hello.cpp.o turns into ./build/hello.cpp.d</span>
DEPS := $(OBJS:.o=.d)

<span># Every folder in ./src will need to be passed to GCC so that it can find header files</span>
INC_DIRS := <span>$(<span>shell</span> find <span>$(SRC_DIRS)</span> -type d)</span>
<span># Add a prefix to INC_DIRS. So moduleA would become -ImoduleA. GCC understands this -I flag</span>
INC_FLAGS := <span>$(<span>addprefix</span> -I,<span>$(INC_DIRS)</span>)</span>

<span># The -MMD and -MP flags together generate Makefiles for us!</span>
<span># These files will have .d instead of .o as the output.</span>
CPPFLAGS := <span>$(INC_FLAGS)</span> -MMD -MP

<span># The final build step.</span>
<span>$(BUILD_DIR)</span>/<span>$(TARGET_EXEC)</span>: <span>$(OBJS)</span>
	<span>$(CXX)</span> <span>$(OBJS)</span> -o <span>$@</span> <span>$(LDFLAGS)</span>

<span># Build step for C source</span>
<span>$(BUILD_DIR)</span>/%.c.o: %.c
	mkdir -p <span>$(<span>dir</span> <span>$@</span>)</span>
	<span>$(CC)</span> <span>$(CPPFLAGS)</span> <span>$(CFLAGS)</span> -c <span>$&lt;</span> -o <span>$@</span>

<span># Build step for C++ source</span>
<span>$(BUILD_DIR)</span>/%.cpp.o: %.cpp
	mkdir -p <span>$(<span>dir</span> <span>$@</span>)</span>
	<span>$(CXX)</span> <span>$(CPPFLAGS)</span> <span>$(CXXFLAGS)</span> -c <span>$&lt;</span> -o <span>$@</span>


<span><span>.PHONY</span>: clean</span>
<span>clean:</span>
	rm -r <span>$(BUILD_DIR)</span>

<span># Include the .d makefiles. The - at the front suppresses the errors of missing</span>
<span># Makefiles. Initially, all the .d files will be missing, and we don't want those</span>
<span># errors to show up.</span>
<span>-include</span> <span>$(DEPS)</span></code></pre>
<!--
TODO: This example fails initially because blah.d doesn't exist. I'm not sure how to fix this example, there are probably better ones out there..

# Generating Prerequisites Automatically (Section 4.12)
Example requires: blah.c  
Generating prereqs automatically  
This makes one small makefile per source file  
Notes:  
1) $$ is the current process id in bash. $$$$ is just $$, with escaping. We use it to make a temporary file, that doesn't interfere with others if there is some parallel builds going on.  
2) cc -MM outputs a makefile line. This is the magic that generates prereqs automatically, by looking at the code itself  
3) The purpose of the sed command is to translate (for example):  
    main.o : main.c defs.h  
    into:  
    main.o main.d : main.c defs.h  
4) Running `make clean` will rerun the rm -f ... rule because the include line wants to include an up to date version of the file. There is such a target that updates it, so it runs that rule before including the file.  
```makefile
# Run make init first, then run make
# This outputs
all: blah.d

clean:
    rm -f blah.d blah.c blah.h blah.o blah

%.d: %.c
    rm -f $@; \
     $(CC) -MM $(CPPFLAGS) $< > $@.$$$$; \
     sed 's,\($*\)\.o[ :]*,\1.o $@ : ,g' < $@.$$$$ > $@; \
     rm -f $@.$$$$

init:
    echo "#include \"blah.h\"; int main() { return 0; }" > blah.c
    touch blah.h

sources = blah.c

include $(sources:.c=.d)
```
-->

                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Break Up Big Tech: Civil Society Declaration – People vs. Big Tech (185 pts)]]></title>
            <link>https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/</link>
            <guid>44325596</guid>
            <pubDate>Fri, 20 Jun 2025 08:02:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/">https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/</a>, See on <a href="https://news.ycombinator.com/item?id=44325596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" tabindex="-1">

			<main id="main">

				<article>

										
						

						
<figure><picture fetchpriority="high" decoding="async">
<source type="image/webp" srcset="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png.webp 996w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-300x74.png.webp 300w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-768x190.png.webp 768w" sizes="(max-width: 996px) 100vw, 996px">
<img fetchpriority="high" decoding="async" width="996" height="246" src="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png" alt="" srcset="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png 996w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-300x74.png 300w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-768x190.png 768w" sizes="(max-width: 996px) 100vw, 996px">
</picture>
</figure>



<p>We, people and civil society organisations from Europe and around the world, call on the European Commission to act now to break up the powerful Big Tech monopolies that have a stranglehold over our digital world. Big Tech isn’t just dominating markets – it’s dominating European democracy.</p>



<p>Europe needs a thriving and diverse digital economy that serves the needs of European citizens, not billionaire tech CEOs. President von der Leyen has affirmed that in the EU, “<a href="https://www.zeit.de/politik/2025-04/ursula-von-der-leyen-eu-usa-donald-trump-english/komplettansicht"><u>we don’t have bros or oligarchs making the rules</u></a>.” The Commission must now stand up to the tech oligarchy by strongly enforcing the EU’s digital rules and competition law.</p>



<p>Right now, the Commission has a once-in-a-generation opportunity to dismantle Google’s advertising monopoly, which is destroying the news media, ripping off consumers, and was ruled illegal in a landmark US judgement.</p>



<h2>Big Tech’s monopoly power threatens democracy</h2>



<p>We cannot address Big Tech’s harms without first confronting its power. A handful of tech giants have concentrated control of our core digital infrastructure – including search engines, social media, app stores, and cloud. The companies’ unchecked power over their digital empires enables them to abuse people’s rights, exploit businesses, and crush competitors.</p>



<p>Spanish Prime Minister Pedro Sanchez has warned that tech billionaires want “<a href="https://www.politico.eu/article/spain-pedro-sanchez-big-tech-billionaires-democracy-social-media/"><u>to overthrow democracy</u></a>”. When a small number of billionaires and tech giants control the internet, they wield their power – and their vast profits – to influence political discourse and interfere with democratic laws. This year, tech CEOs and the Trump administration have <a href="https://www.techpolicy.press/tracking-recent-statements-on-the-enforcement-of-eu-tech-laws/#US-Leaders"><u>worked hand in glove</u></a> to try to thwart the EU’s landmark digital laws that hold Big Tech to account.</p>



<h2>Break up Big Tech monopolies</h2>



<p>Teresa Ribera, the EU’s competition chief, <a href="https://www.bloomberg.com/news/articles/2024-12-05/google-split-still-on-the-table-eu-s-new-antitrust-chief-says"><u>recognises</u></a> that break-ups can prevent Big Tech from grabbing too much market power. These corporations treat billion-euro fines as the cost of doing business, while behavioural remedies are ineffective and often flouted by the companies. Forcing these giants to sell off parts of their businesses will curb conflicts of interest, level the digital playing field, and make the companies easier to hold accountable for their growing societal harms.</p>



<p>Breaking up Google’s advertising monopoly is an open goal for the EU, backed by <a href="https://clubmadrid.org/former-eu-leaders-breaking-up-googles-adtech-monopoly-is-vital-for-democracy/"><u>eighteen former European presidents and prime ministers</u></a>. Google’s monopoly unfairly sucks revenue from publishers, killing journalism and the news media, while forcing consumers to pay more through an “adtech tax” to <a href="https://www.ft.com/content/9ee0ebd3-346f-45b1-8b92-aa5c597d4389">industry middlemen</a>. In its final ruling on Google ad-tech, the Commission must reaffirm that “<a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_3207"><u>only the mandatory divestment</u></a>” by Google of part of its services will address competition concerns.</p>



<p>Breaking up tech monopolies is a step towards a freer, fairer internet. Europe can and must resist threats from Big Tech and the Trump administration, and stand firm in upholding EU law against Big Tech. Break up Google. Break up Big Tech.</p>



<h2>Signatories:</h2>



<ol>
<li>Balanced Economy Project</li>



<li>Foundation The London Story</li>



<li>LobbyControl</li>



<li>People vs Big Tech</li>



<li>Rebalance Now</li>



<li>WeMove Europe</li>



<li>Defend Democracy</li>



<li>Foxglove</li>



<li>Xnet, Institute for Democratic Digitalisation – Spain</li>



<li>Uplift, Ireland</li>



<li>Corporate Europe Observatory (CEO)</li>



<li>SOMO</li>



<li>Enforce (Irish Council for Civil Liberties)</li>



<li>AlgorithmWatch</li>



<li>Save Social - Networks for democracy</li>



<li>Canadian Anti-Monopoly Project (CAMP)</li>



<li>Open Markets Institute</li>



<li>Hope and Courage Collective, Ireland</li>



<li>IT for Change</li>



<li>German NGO Forum on Environment &amp; Development</li>



<li>taxmenow</li>



<li>Goliathwatch</li>



<li>Campact</li>



<li>Global Justice Now</li>



<li>Another Europe Is Possible</li>



<li>Avaaz Foundation</li>



<li>Epicenter.works - for digital rights</li>



<li>Digital Action</li>



<li>European Federation of Journalists (EFJ)</li>



<li>Greek Helsinki Monitor</li>



<li>India Labour Solidarity</li>



<li>Waag Futurelab</li>



<li>Deutscher Journalisten-Verband (DJV, German Journalists Association)</li>



<li>The Citizens</li>



<li>Alliance4Europe</li>



<li>Global Project Against Hate and Extremism</li>
</ol>
						
						
						
						
									
						<nav>
		<a href="https://peoplevsbig.tech/opportunity-ctrlaltreclaim-community-lead/" rel="prev"><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M21.3333 24.6289H24V19.2956H21.3333V21.9622L2.66667 21.9622L2.66667 3.29557L21.3333 3.29557V5.96224H24V0.628906L0 0.628906L0 24.6289L21.3333 24.6289ZM5.33333 13.9622H8V16.6289H10.6667L10.6667 19.2956H13.3333L13.3333 16.6289H10.6667V13.9622L24 13.9622V11.2956L10.6667 11.2956V8.62891H13.3333V5.96224H10.6667V8.62891L8 8.62891V11.2956H5.33333V13.9622Z" fill="currentColor"></path>
<path d="M21.3333 24.6289H24V19.2956H21.3333V21.9622L2.66667 21.9622L2.66667 3.29557L21.3333 3.29557V5.96224H24V0.628906L0 0.628906L0 24.6289L21.3333 24.6289ZM5.33333 13.9622H8V16.6289H10.6667L10.6667 19.2956H13.3333L13.3333 16.6289H10.6667V13.9622L24 13.9622V11.2956L10.6667 11.2956V8.62891H13.3333V5.96224H10.6667V8.62891L8 8.62891V11.2956H5.33333V13.9622Z" fill="currentColor" fill-opacity="0.2"></path>
</svg> <span>Previous <span>article</span></span></a>						</nav>
		
					<!-- .footer-widget -->
				</article>
					

			</main><!-- #main -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JavaScript broke the web (and called it progress) (127 pts)]]></title>
            <link>https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/</link>
            <guid>44325563</guid>
            <pubDate>Fri, 20 Jun 2025 07:52:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/">https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/</a>, See on <a href="https://news.ycombinator.com/item?id=44325563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
				
				<div><p>19th June, 2025</p><div><picture><img sizes="(max-width: 96px) 100vw, 96px" alt="" src="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=96&amp;q=85&amp;sharpen=1&amp;width=96" srcset="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=96&amp;q=85&amp;sharpen=1&amp;width=96 96w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=144&amp;q=85&amp;sharpen=1&amp;width=144 144w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=192&amp;q=85&amp;sharpen=1&amp;width=192 192w" height="96" width="96" decoding="async"></picture></div><picture><img alt="" decoding="async" fetchpriority="high" height="350" sizes="(max-width: 760px) calc(100vw - 2.5rem), 760px" src="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=350&amp;q=85&amp;width=760" srcset="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=350&amp;q=85&amp;width=760 760w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=525&amp;q=85&amp;width=1140 1140w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=700&amp;q=85&amp;width=1520 1520w" width="760"></picture></div>
<p>Most websites are&nbsp;awful.</p>



<p>Not just slow – <em>awful</em>. Bloated, fragile, over-engineered disasters. They load slowly, render erratically, and hide their content behind megabytes of JavaScript. They glitch on mobile. They frustrate users and confuse search engines. They’re impossible to maintain. And somehow, we’re calling this <em>progress</em>.</p>



<p>The tragedy is, none of this is necessary. Once upon a&nbsp;time, we had a&nbsp;fast, stable, resilient web. But we replaced it with a&nbsp;JavaScript cargo&nbsp;cult.</p>



<p>Now it takes four engineers, three frameworks, and a&nbsp;CI/CD pipeline just to change a&nbsp;heading. It’s inordinately complex to simply <em>publish a&nbsp;webpage</em>.</p>



<p>This isn’t evolution. It’s self-inflicted complexity. And we’ve normalised it – because somewhere along the way, we started building websites for <em>developers</em>, not for <em>users</em>.</p>



<h2 id="h-how-we-got-here">How we got&nbsp;here</h2>



<p>Around 2010, something shifted. The iPhone was ascendant. Native apps were sleek, fast, fluid. Angular, the first mainstream javascript framework for the web, elhad just emerged. And suddenly, every CMO started saying the same thing in website briefs: <em>“Can we make it feel like an&nbsp;app?”</em></p>



<p>Developers, armed with new frameworks and good intentions, said yes. JavaScript could, in theory, do seamless transitions and slick UI. So we built towards that promise. Or tried&nbsp;to.</p>



<p>Spoiler alert: we didn’t get app-like performance. We didn’t get better user experiences. What we got was an <em>arms race of complexity</em>.</p>



<p>We started solving simple problems – like navigation or layout – with tools built for full-blown applications.</p>



<p>At the same time, JavaScript stopped being just a&nbsp;front-end language. With the rise of Node.js, JS moved server-side, and with it came a&nbsp;wave of app developers entering the web ecosystem. These weren’t web designers or content publishers. They were engineers, trained to build applications, not documents. And they brought with them an architecture-first mindset: patterns, state management, dependency injection, abstracted logic. The result? A&nbsp;slow cultural shift from building pages to engineering systems – even when all the user needed was to load an article.</p>



<p>And so, we rewrote the rules of web development around entirely different needs, almost overnight. Not content, not speed, not interoperability, not discoverability. Just&nbsp;code.</p>



<p>The further we went down this road, the more the stack drifted from the fundamentals. Semantic HTML? Optional. Server-side rendering? Rebuilt from scratch. Accessibility? Maybe, if there’s time. Performance? Who cares, when you can save costs by putting loading burdens onto the user’s device, instead of your server?</p>



<p>So gradually, the web became something you had to <em>compile</em> before you could publish. Not because users needed it. But because developers wanted it to feel modern.</p>



<p>And we’re still paying for that decision.</p>



<h2 id="h-the-cult-of-developer-experience">The cult of developer experience</h2>



<p>Today, we optimise for “DX” – developer experience. Not user experience. Not performance. Not outcomes.</p>



<p>Today’s popular frameworks are sold on their DX. The docs are slick. The onboarding is smooth. The tooling is smart, integrated, clever. You can spin up a&nbsp;new app with a&nbsp;CLI command and feel productive before you’ve even written a&nbsp;line of content.</p>



<p>But good DX doesn’t guarantee good UX. In fact, it’s often the opposite. Because the more comfortable we make things for developers, the more abstraction we add. And every abstraction creates distance between the thing being built and the people it’s&nbsp;for.</p>



<p>Now we have component libraries generating button markup. We have page metadata managed in JavaScript functions. We have image loading strategies buried in config files.</p>



<p>Everything’s optimised for developers – and hostile to everyone else.</p>



<p>This isn’t accidental. It’s cultural. We’ve created an industry where complexity is celebrated. Where cleverness is rewarded. Where engineering sophistication is valued more than clarity, usability, or commercial effectiveness.</p>



<p>It’s easier to win an argument by citing SSR compatibility issues than it is to ask, “<em>Why are we using React for a&nbsp;blog?</em>”</p>



<p>And so we keep optimising for the wrong things. Because it feels good. Because it’s fun. Because it looks modern. And because nobody stops&nbsp;us.</p>



<h2 id="h-complexity-becomes-the-default">Complexity becomes the default</h2>



<p>This is how it spirals.</p>



<p>We don’t just tolerate complexity anymore – we expect it. We assume that every site needs a&nbsp;build step, a&nbsp;bundler, a&nbsp;hydration strategy, a&nbsp;routing layer, an API layer, a&nbsp;design system, and some clever cache invalidation logic. We build in microservices, host on edge networks, and deploy pipelines to ship basic content.</p>



<p>It doesn’t matter if you’re publishing a&nbsp;blog post or an ecommerce site – the stack is the same. Heavy, abstract, engineered to the edge of usefulness.</p>



<p>And nobody understands it. Not&nbsp;fully.</p>



<p>Not the marketers, not the SEOs, not even the developers who built it six months ago. Every new tool brings new abstractions, new syntax, new mental models. Making a&nbsp;simple tweak to a&nbsp;headline, a&nbsp;meta tag, or a&nbsp;layout becomes a&nbsp;three-step deployment process.</p>



<p>It’s madness.</p>



<p>We’ve rebuilt the web like an air traffic control system – just to serve a&nbsp;few kilobytes of&nbsp;text.</p>



<p>And the worst part? Most of this complexity exists just to retrofit things we used to get by <em>default</em>: routing, metadata, caching, templating, layout.</p>



<p>We’re not innovating. We’re rebuilding broken versions of tools the web already gave us – and doing it&nbsp;badly.</p>



<h2 id="h-the-stack-is-rebuilding-itself-in-its-own-image">The stack is rebuilding itself in its own&nbsp;image</h2>



<p>Fast forward to today. Ironically, after years of chasing abstraction and complexity, the JavaScript ecosystem is now scrambling to reintroduce the things we&nbsp;lost.</p>



<p>Server-side rendering? Back in fashion. Routing? Carefully managed. URL structures, metadata, even HTML output – all being rebuilt, one plugin at a&nbsp;time.</p>



<p>It all looks increasingly like the thing we started with: a&nbsp;conventional CMS, serving HTML, rendered on the server, cached close to the&nbsp;user.</p>



<p>Except now it’s slower, harder to maintain, and dependent on a&nbsp;brittle ecosystem of packages, compilers, and edge handlers.</p>



<p>We’re (re)building platforms like WordPress and it’s features, but with 10x the overhead and none of the usability.</p>



<p>Worse, every new layer introduces new bugs, new compatibility issues, and new cognitive burden. Now we’re maintaining hydration logic <em>and</em> cache strategies <em>and</em> build pipelines just to get a&nbsp;homepage online.</p>



<p>It would be funny if it weren’t so exhausting.</p>



<p>This is the endgame of a&nbsp;development culture obsessed with novelty. We’re not shipping better sites. We’re reinventing basic infrastructure in increasingly convoluted ways – then celebrating the fact that it <em>almost works</em>.</p>



<h2 id="h-the-cycle-of-iteration-and-instability">The cycle of iteration and instability</h2>



<p>The stack never settles.</p>



<p>Nothing is stable. Nothing is finished. Every sprint, every roadmap, every quarter brings a&nbsp;new initiative: migrate to the latest framework, adopt the new bundler, refactor the routing layer, replace the CMS integration, rebuild the&nbsp;cache.</p>



<p>It never ends. And it rarely helps.</p>



<p>Most of this churn isn’t solving real user problems. It’s solving the problems created by the last round of architecture decisions. We’re not iterating toward impact – we’re iterating just to stay afloat.</p>



<p>And while the stack is busy trying to fix itself, everything else slows&nbsp;down.</p>



<p>Marketing campaigns get delayed because the component library isn’t flexible enough. A/B tests get scrapped because the analytics layer isn’t compatible with the hydration strategy. Content updates wait days for a&nbsp;build. Basic SEO tweaks get buried in backlog.</p>



<p>Meanwhile, the users still can’t load the&nbsp;page.</p>



<p>This is what happens when complexity becomes the product. We don’t optimise for outcomes anymore. We optimise the optimisation layer.</p>



<p>And then we do it&nbsp;again.</p>



<h2 id="h-collateral-damage-to-marketers-and-users">Collateral damage to marketers and&nbsp;users</h2>



<p>All this complexity doesn’t just frustrate developers. It locks everyone else&nbsp;out.</p>



<p>Marketers can’t update copy or run experiments without raising tickets. They can’t preview content, test layouts, or launch pages. Every change has to go through developers, pipelines, approvals, and rebuilds.</p>



<p>SEOs are stuck trying to diagnose rendering issues they can’t control. Pages load empty, or late, or not at all. Crawl traps appear. Metadata disappears. Structured data gets bundled into a&nbsp;JavaScript object and forgotten.</p>



<p>Content strategists and editors are left editing JSON blobs, Markdown files, or headless CMS forms that have no connection to the thing the user actually sees.</p>



<p>Even basic QA is a&nbsp;mess. Does the page show the right headline? Does the canonical tag resolve correctly? You won’t know until you’ve deployed it.&nbsp;Maybe.</p>



<p>And users? They’re stuck staring at loading spinners. Tapping broken buttons. Waiting for the back button to un-break itself. Watching text reflow as the layout shuffles into&nbsp;place.</p>



<p>This isn’t the future of the web. It’s a&nbsp;slow-motion disaster.</p>



<p>We’ve made websites harder to publish, harder to find, harder to use, and harder to maintain – all in the name of modern development.</p>



<h2 id="h-javascript-is-powerful-but-misused">JavaScript is powerful – but misused</h2>



<p>Let’s be clear: JavaScript isn’t the villain. It’s powerful. It’s essential. It enables rich interactivity, dynamic content, real-time updates. It lets us build tools, not just&nbsp;pages.</p>



<p>Used wisely, it elevates the&nbsp;web.</p>



<p>But most websites don’t need to be tools. They don’t need complex state. They don’t need real-time data or dynamic routing. They’re not apps. They’re brochures, catalogs, portfolios, articles.</p>



<p>And for those use cases, the modern JS stack is complete overkill.</p>



<p>Even ecommerce sites – with product options, variation pickers, add-to-cart functionality, and modal overlays – don’t need full frameworks. These can all be built with minimal, lean, well-targeted JavaScript. No client-side routing. No hydration. No component trees.</p>



<p>A few lines of well-written vanilla JavaScript (or yes, even jquery) can handle 95% of what most websites actually need. Faster. Simpler. More accessibly.</p>



<p>Modern CSS alone can now handle many of the tasks we used to need JavaScript for – like toggles, modals, and even carousels – reducing the need for scripting altogether.</p>



<p>And yes, some sites do have genuine client-side state needs login states, currency selectors, regional availability, and so on. But even those can often be handled more cleanly and performantly with server-side logic, or simple asynchronous JavaScript and AJAX. We don’t need a&nbsp;full reactive runtime to show a ‘logged in’ button or switch from USD to&nbsp;EUR.</p>



<p>But instead, we default to frameworks. We reach for React to build a&nbsp;contact page. We deploy hydration strategies for static content. We compile, bundle, transpile, and optimise code that doesn’t need to&nbsp;exist.</p>



<p>It’s not just wasteful. It’s damaging.</p>



<p>We’re burning user attention, developer time, and business resources to simulate interactivity that nobody asked&nbsp;for.</p>



<p>JavaScript should be the icing. Not the cake. And certainly not the oven, the recipe, and the kitchen sink.</p>



<h2 id="h-the-power-problem">The power problem</h2>



<p>The more complex the stack becomes, the more power it concentrates.</p>



<p>Marketers, content editors, SEOs, designers – they’re all locked out of the process. Because now, even simple tasks require technical fluency. Want to change a&nbsp;title tag? Talk to engineering. Want to launch a&nbsp;campaign? Raise a&nbsp;ticket and wait two sprints.</p>



<p>Everything flows through the dev team. Which means the dev team gets to decide what matters, what ships, and what gets deprioritised indefinitely.</p>



<p>And the more complexity they add, the more indispensable they become.</p>



<p>It’s not (usually) malicious. It’s structural. The stack is built by devs, for devs. So when something breaks, or needs changing, or needs explaining – it goes back to the people who built it. Which reinforces the model. Which deepens the dependency. Which justifies more abstraction. And more control.</p>



<p>This isn’t just a&nbsp;technical issue. It’s an organisational one. We’ve handed control of the web to the only people who understand the machinery. And they’re too busy fixing the machine to stop and ask whether we needed it in the first&nbsp;place.</p>



<h2 id="h-websites-that-work">Websites that&nbsp;work</h2>



<p>There is a&nbsp;better way. And it doesn’t require a&nbsp;complete rewrite of the internet or a&nbsp;return to&nbsp;2005.</p>



<p>We don’t need to abandon CMSs. We don’t need to ban JavaScript. We just need to stop treating every website like a&nbsp;software product.</p>



<p>Most sites need to load fast, be easy to navigate, show up in search, and let users do simple things – read, click, scroll, buy. That’s it. And we already have the tools to build&nbsp;that:</p>



<ul>
<li>Server-rendered HTML.</li>



<li>Semantic markup.</li>



<li>Clean URLs.</li>



<li>Lightweight templates.</li>



<li>Edge caching.</li>



<li>Sensible use of JavaScript where it adds real&nbsp;value.</li>
</ul>



<p>That could be WordPress. That could be Eleventy. That could be a&nbsp;custom setup. The point isn’t the tool – it’s the mindset.</p>



<p>Build for the user. Build for performance. Build for maintainability.</p>



<p>Choose simplicity over cleverness. Choose transparency over abstraction. Choose outcomes over architecture.</p>



<p>We can still have modern workflows. We can still version control content. We can still preview, collaborate, deploy, iterate. But the foundation has to be the web – not an app, not a&nbsp;shell, not a&nbsp;simulation.</p>



<p>It’s not about going backwards. It’s about stopping the freefall.</p>



<p>The web can work again. We just have to let&nbsp;it.</p>



<h2 id="h-reclaiming-the-web">Reclaiming the&nbsp;web</h2>



<p>If you’ve ever felt like your website is harder to manage than it should be – you’re not imagining it.</p>



<p>If it takes days to update a&nbsp;title tag, if your product pages glitch, if your blog can’t load without JavaScript… that’s not “just how it works.” That’s a&nbsp;choice. One made without you in the&nbsp;room.</p>



<p>So ask questions. Push&nbsp;back.</p>



<ul>
<li>“Why are we using a&nbsp;full JS framework for a&nbsp;mostly static site?”</li>



<li>“Why can’t I&nbsp;update this content without engineering help?”</li>



<li>“Why does it take a&nbsp;build pipeline to change a&nbsp;headline?”</li>



<li>“Why isn’t this just&nbsp;HTML?”</li>
</ul>



<p>You don’t need to write code to challenge architecture. You just need to make outcomes the priority.</p>



<p>And remember – complexity isn’t just a&nbsp;technical burden. It’s a&nbsp;financial one. More engineers. Slower launches. Higher maintenance. Less agility. When the stack bloats, so do the&nbsp;costs.</p>



<p>Faster sites. Easier publishing. Better rankings. Happier users.</p>



<p>You can demand those things.</p>



<p>Because they’re not unreasonable. They’re what the web was built&nbsp;for.</p>



<p>And it’s time to start demanding better.</p>



<p>Ask more. Expect more. Push for outcomes, not architecture.</p>



<p>The web isn’t broken by accident. It’s broken by design. And we don’t have to accept it.</p>



<p>That doesn’t mean frameworks have no place. Large or distributed teams often benefit from architectural scaffolding, shared conventions, and modular approaches. But that scaffolding is rarely right-sized. More often, it justifies itself by growing – and creates the need for even more engineers to maintain the complexity it introduced.</p>



<p>And yes, frameworks <em>can</em> be fast, accessible, and SEO-friendly. But let’s be honest: they almost never are. Not in the wild. Not without significant expertise, time, and care. Most developers don’t know what they don’t know. They rely on default configurations and magic middleware that silently breaks the basics.</p>



<p>The result?<br>Broken back buttons.<br>Image bloat.<br>Inaccessible markup.<br>URLs that don’t behave like URLs.<br>Metadata that disappears.<br>Content you can’t copy.<br>Buttons you can’t keyboard to.<br>Modals that trap you.<br>Scroll positions that reset for no reason.<br>Headlines that shift mid-read.<br>Analytics that don’t match reality.<br>Preview environments that lie.<br>And pages that load… eventually.</p>



<p>All fixable.<br>All avoidable.<br>All caused by choosing tools that were never built for this&nbsp;job.</p>



<p>This isn’t about going back to table layouts or banning JavaScript.<br>It’s about building with intent.<br>Understanding what the web gives us by default – and resisting the urge to rebuild it from scratch.</p>



<p>It’s not about purity. It’s about outcomes.<br>Use what&nbsp;works.<br></p>



<p>But question whether it’s working for your users, or just for your developers.&nbsp;</p>
    
    
    
    
    			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hurl: Run and test HTTP requests with plain text (324 pts)]]></title>
            <link>https://github.com/Orange-OpenSource/hurl</link>
            <guid>44324592</guid>
            <pubDate>Fri, 20 Jun 2025 03:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Orange-OpenSource/hurl">https://github.com/Orange-OpenSource/hurl</a>, See on <a href="https://news.ycombinator.com/item?id=44324592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true"> 
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-dark.svg?sanitize=true"> 
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true" width="264px" alt="Hurl Logo">
</picture></themed-picture>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/actions"><img src="https://github.com/Orange-OpenSource/hurl/workflows/test/badge.svg" alt="deploy status"></a>
<a href="https://orange-opensource.github.io/hurl/coverage" rel="nofollow"><img src="https://camo.githubusercontent.com/19edc85a2bb776555d2d2ed00e86d9926f7c0befd6339b768874bc7c866eaaa4/68747470733a2f2f4f72616e67652d4f70656e536f757263652e6769746875622e696f2f6875726c2f636f7665726167652f6261646765732f666c61742e737667" alt="coverage" data-canonical-src="https://Orange-OpenSource.github.io/hurl/coverage/badges/flat.svg"></a>
<a href="https://crates.io/crates/hurl" rel="nofollow"><img src="https://camo.githubusercontent.com/9b74b944af9e26d5adb9d2f853bb93c53c45d75f888cabc4d3406fa838b813fa/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6875726c2e737667" alt="Crates.io" data-canonical-src="https://img.shields.io/crates/v/hurl.svg"></a>
<a href="https://hurl.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/d78580786d47c7d5ecc3d261edae2f60c95978e25086984df45588f4a1214929/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d646f63756d656e746174696f6e2d666630323838" alt="documentation" data-canonical-src="https://img.shields.io/badge/-documentation-ff0288"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's Hurl?</h2><a id="user-content-whats-hurl" aria-label="Permalink: What's Hurl?" href="#whats-hurl"></a></p>
<p dir="auto">Hurl is a command line tool that runs <b>HTTP requests</b> defined in a simple <b>plain text format</b>.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very
versatile: it can be used for both <b>fetching data</b> and <b>testing HTTP</b> sessions.</p>
<p dir="auto">Hurl makes it easy to work with <b>HTML</b> content, <b>REST / SOAP / GraphQL</b> APIs, or any other <b>XML / JSON</b> based APIs.</p>
<div data-snippet-clipboard-copy-content="# Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code># Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto">Chaining multiple requests is easy:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3"><pre lang="hurl"><code>GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Also an HTTP Test Tool</h2><a id="user-content-also-an-http-test-tool" aria-label="Permalink: Also an HTTP Test Tool" href="#also-an-http-test-tool"></a></p>
<p dir="auto">Hurl can run HTTP requests but can also be used to <b>test HTTP responses</b>.
Different types of queries and predicates are supported, from <a href="https://en.wikipedia.org/wiki/XPath" rel="nofollow">XPath</a> and <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a> on body response,
to assert on status code and response headers.</p>
<p dir="auto"><a href="https://hurl.dev/player.html?id=starwars&amp;speed=3" rel="nofollow"><img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/poster-starwars.png" width="100%" alt="Hurl Demo"></a></p>
<p dir="auto">It is well adapted for <b>REST / JSON APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;4568&quot;,
    &quot;evaluate&quot;: true
}
HTTP 200
[Asserts]
header &quot;X-Frame-Options&quot; == &quot;SAMEORIGIN&quot;
jsonpath &quot;$.status&quot; == &quot;RUNNING&quot;    # Check the status code
jsonpath &quot;$.tests&quot; count == 25      # Check the number of items
jsonpath &quot;$.id&quot; matches /\d{4}/     # Check the format of the id"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "4568",
    "evaluate": true
}
HTTP 200
[Asserts]
header "X-Frame-Options" == "SAMEORIGIN"
jsonpath "$.status" == "RUNNING"    # Check the status code
jsonpath "$.tests" count == 25      # Check the number of items
jsonpath "$.id" matches /\d{4}/     # Check the format of the id
</code></pre></div>
<p dir="auto"><b>HTML content</b></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
xpath &quot;normalize-space(//head/title)&quot; == &quot;Hello world!&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
xpath "normalize-space(//head/title)" == "Hello world!"
</code></pre></div>
<p dir="auto"><b>GraphQL</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200"><pre lang="hurl"><code>POST https://example.org/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200
</code></pre></div>
<p dir="auto">and even <b>SOAP APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto">Hurl can also be used to test the <b>performance</b> of HTTP endpoints</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration < 1000  # Duration in ms"><pre lang="hurl"><code>GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration &lt; 1000  # Duration in ms
</code></pre></div>
<p dir="auto">And check response bytes</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto">Finally, Hurl is easy to <b>integrate in CI/CD</b>, with text, JUnit, TAP and HTML reports</p>
<themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png">
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-dark.png">
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png" width="480" alt="HTML report">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Hurl?</h2><a id="user-content-why-hurl" aria-label="Permalink: Why Hurl?" href="#why-hurl"></a></p>
<ul dir="auto">
    <li><b>Text Format:</b> for both devops and developers</li>
    <li><b>Fast CLI:</b> a command line for local dev and continuous integration</li>
    <li><b>Single Binary:</b> easy to install, with no runtime required</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Powered by curl</h2><a id="user-content-powered-by-curl" aria-label="Permalink: Powered by curl" href="#powered-by-curl"></a></p>
<p dir="auto">Hurl is a lightweight binary written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. Under the hood, Hurl HTTP engine is
powered by <a href="https://curl.se/libcurl/" rel="nofollow">libcurl</a>, one of the most powerful and reliable file transfer libraries.
With its text file format, Hurl adds syntactic sugar to run and test HTTP requests,
but it's still the <a href="https://curl.se/" rel="nofollow">curl</a> that we love: <strong>fast</strong>, <strong>efficient</strong> and <strong>IPv6 / HTTP/3 ready</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedbacks</h2><a id="user-content-feedbacks" aria-label="Permalink: Feedbacks" href="#feedbacks"></a></p>
<p dir="auto">To support its development, <a href="https://github.com/Orange-OpenSource/hurl/stargazers">star Hurl on GitHub</a>!</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/issues">Feedback, suggestion, bugs or improvements</a> are welcome.</p>
<div data-snippet-clipboard-copy-content="POST https://hurl.dev/api/feedback
{
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;feedback&quot;: &quot;Hurl is awesome!&quot;
}
HTTP 200"><pre lang="hurl"><code>POST https://hurl.dev/api/feedback
{
  "name": "John Doe",
  "feedback": "Hurl is awesome!"
}
HTTP 200
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resources</h2><a id="user-content-resources" aria-label="Permalink: Resources" href="#resources"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/license.html" rel="nofollow">License</a></p>
<p dir="auto"><a href="https://hurl.dev/blog/" rel="nofollow">Blog</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/tutorial/your-first-hurl-file.html" rel="nofollow">Tutorial</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/installation.html" rel="nofollow">Documentation</a> (download <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.html">HTML</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.pdf">PDF</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.md">Markdown</a>)</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl">GitHub</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#samples">Samples</a>
<ul dir="auto">
<li><a href="#getting-data">Getting Data</a>
<ul dir="auto">
<li><a href="#http-headers">HTTP Headers</a></li>
<li><a href="#query-params">Query Params</a></li>
<li><a href="#basic-authentication">Basic Authentication</a></li>
<li><a href="#passing-data-between-requests">Passing Data between Requests </a></li>
</ul>
</li>
<li><a href="#sending-data">Sending Data</a>
<ul dir="auto">
<li><a href="#sending-html-form-data">Sending HTML Form Data</a></li>
<li><a href="#sending-multipart-form-data">Sending Multipart Form Data</a></li>
<li><a href="#posting-a-json-body">Posting a JSON Body</a></li>
<li><a href="#templating-a-json-body">Templating a JSON Body</a></li>
<li><a href="#templating-a-xml-body">Templating a XML Body</a></li>
<li><a href="#using-graphql-query">Using GraphQL Query</a></li>
<li><a href="#using-dynamic-datas">Using Dynamic Datas</a></li>
</ul>
</li>
<li><a href="#testing-response">Testing Response</a>
<ul dir="auto">
<li><a href="#testing-status-code">Testing Status Code</a></li>
<li><a href="#testing-response-headers">Testing Response Headers</a></li>
<li><a href="#testing-rest-apis">Testing REST APIs</a></li>
<li><a href="#testing-html-response">Testing HTML Response</a></li>
<li><a href="#testing-set-cookie-attributes">Testing Set-Cookie Attributes</a></li>
<li><a href="#testing-bytes-content">Testing Bytes Content</a></li>
<li><a href="#ssl-certificate">SSL Certificate</a></li>
<li><a href="#checking-full-body">Checking Full Body</a></li>
</ul>
</li>
<li><a href="#reports">Reports</a>
<ul dir="auto">
<li><a href="#html-report">HTML Report</a></li>
<li><a href="#json-report">JSON Report</a></li>
<li><a href="#junit-report">JUnit Report</a></li>
<li><a href="#tap-report">TAP Report</a></li>
<li><a href="#json-output">JSON Output</a></li>
</ul>
</li>
<li><a href="#others">Others</a>
<ul dir="auto">
<li><a href="#http-version">HTTP Version</a></li>
<li><a href="#ip-address">IP Address</a></li>
<li><a href="#polling-and-retry">Polling and Retry</a></li>
<li><a href="#delaying-requests">Delaying Requests</a></li>
<li><a href="#skipping-requests">Skipping Requests</a></li>
<li><a href="#testing-endpoint-performance">Testing Endpoint Performance</a></li>
<li><a href="#using-soap-apis">Using SOAP APIs</a></li>
<li><a href="#capturing-and-using-a-csrf-token">Capturing and Using a CSRF Token</a></li>
<li><a href="#redacting-secrets">Redacting Secrets</a></li>
<li><a href="#checking-byte-order-mark-bom-in-response-body">Checking Byte Order Mark (BOM) in Response Body</a></li>
<li><a href="#aws-signature-version-4-requests">AWS Signature Version 4 Requests</a></li>
<li><a href="#using-curl-options">Using curl Options</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#manual">Manual</a>
<ul dir="auto">
<li><a href="#name">Name</a></li>
<li><a href="#synopsis">Synopsis</a></li>
<li><a href="#description">Description</a></li>
<li><a href="#hurl-file-format">Hurl File Format</a>
<ul dir="auto">
<li><a href="#capturing-values">Capturing values</a></li>
<li><a href="#asserts">Asserts</a></li>
</ul>
</li>
<li><a href="#options">Options</a></li>
<li><a href="#environment">Environment</a></li>
<li><a href="#exit-codes">Exit Codes</a></li>
<li><a href="#www">WWW</a></li>
<li><a href="#see-also">See Also</a></li>
</ul>
</li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#binaries-installation">Binaries Installation</a>
<ul dir="auto">
<li><a href="#linux">Linux</a>
<ul dir="auto">
<li><a href="#debian--ubuntu">Debian / Ubuntu</a></li>
<li><a href="#alpine">Alpine</a></li>
<li><a href="#arch-linux--manjaro">Arch Linux / Manjaro</a></li>
<li><a href="#nixos--nix">NixOS / Nix</a></li>
</ul>
</li>
<li><a href="#macos">macOS</a>
<ul dir="auto">
<li><a href="#homebrew">Homebrew</a></li>
<li><a href="#macports">MacPorts</a></li>
</ul>
</li>
<li><a href="#freebsd">FreeBSD</a></li>
<li><a href="#windows">Windows</a>
<ul dir="auto">
<li><a href="#zip-file">Zip File</a></li>
<li><a href="#installer">Installer</a></li>
<li><a href="#chocolatey">Chocolatey</a></li>
<li><a href="#scoop">Scoop</a></li>
<li><a href="#windows-package-manager">Windows Package Manager</a></li>
</ul>
</li>
<li><a href="#cargo">Cargo</a></li>
<li><a href="#conda-forge">conda-forge</a></li>
<li><a href="#docker">Docker</a></li>
<li><a href="#npm">npm</a></li>
</ul>
</li>
<li><a href="#building-from-sources">Building From Sources</a>
<ul dir="auto">
<li><a href="#build-on-linux">Build on Linux</a>
<ul dir="auto">
<li><a href="#debian-based-distributions">Debian based distributions</a></li>
<li><a href="#fedora-based-distributions">Fedora based distributions</a></li>
<li><a href="#red-hat-based-distributions">Red Hat based distributions</a></li>
<li><a href="#arch-based-distributions">Arch based distributions</a></li>
<li><a href="#alpine-based-distributions">Alpine based distributions</a></li>
</ul>
</li>
<li><a href="#build-on-macos">Build on macOS</a></li>
<li><a href="#build-on-windows">Build on Windows</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Samples</h2><a id="user-content-samples" aria-label="Permalink: Samples" href="#samples"></a></p>
<p dir="auto">To run a sample, edit a file with the sample content, and run Hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl"><pre>$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl</pre></div>
<p dir="auto">By default, Hurl behaves like <a href="https://curl.se/" rel="nofollow">curl</a> and outputs the last HTTP response's <a href="https://hurl.dev/docs/entry.html" rel="nofollow">entry</a>. To have a test
oriented output, you can use <a href="https://hurl.dev/docs/manual.html#test" rel="nofollow"><code>--test</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test sample.hurl"><pre>$ hurl --test sample.hurl</pre></div>
<p dir="auto">A particular response can be saved with <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options] section</code></a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200"><pre lang="hurl"><code>GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200
</code></pre></div>
<p dir="auto">Finally, Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test integration/*.hurl
$ hurl --test ."><pre>$ hurl --test integration/<span>*</span>.hurl
$ hurl --test <span>.</span></pre></div>
<p dir="auto">You can check <a href="https://github.com/Orange-OpenSource/hurl/tree/master/integration/hurl/tests_ok">Hurl tests suite</a> for more samples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Data</h2><a id="user-content-getting-data" aria-label="Permalink: Getting Data" href="#getting-data"></a></p>
<p dir="auto">A simple GET:</p>

<p dir="auto">Requests can be chained:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c"><pre lang="hurl"><code>GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#method" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Headers</h3><a id="user-content-http-headers" aria-label="Permalink: HTTP Headers" href="#http-headers"></a></p>
<p dir="auto">A simple GET with headers:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive"><pre lang="hurl"><code>GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Params</h3><a id="user-content-query-params" aria-label="Permalink: Query Params" href="#query-params"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100"><pre lang="hurl"><code>GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100
</code></pre></div>
<p dir="auto">Or:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100"><pre lang="hurl"><code>GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100
</code></pre></div>
<blockquote>
<p dir="auto">With <code>[Query]</code> section, params don't need to be URL escaped.</p>
</blockquote>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#query-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Authentication</h3><a id="user-content-basic-authentication" aria-label="Permalink: Basic Authentication" href="#basic-authentication"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/protected
[BasicAuth]
bob: secret"><pre lang="hurl"><code>GET https://example.org/protected
[BasicAuth]
bob: secret
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#basic-authentication" rel="nofollow">Doc</a></p>
<p dir="auto">This is equivalent to construct the request with a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization" rel="nofollow">Authorization</a> header:</p>
<div data-snippet-clipboard-copy-content="# Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== "><pre lang="hurl"><code># Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== 
</code></pre></div>
<p dir="auto">Basic authentication section allows per request authentication. If you want to add basic authentication to all the
requests of a Hurl file you could use <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>-u/--user</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --user bob:secret login.hurl"><pre>$ hurl --user bob:secret login.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a> option can also be set per request:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200"><pre lang="hurl"><code>GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passing Data between Requests</h3><a id="user-content-passing-data-between-requests" aria-label="Permalink: Passing Data between Requests" href="#passing-data-between-requests"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Captures</a> can be used to pass data from one request to another:</p>
<div data-snippet-clipboard-copy-content="POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath &quot;$.order.id&quot;

GET https://sample.org/orders/{{order_id}}
HTTP 200"><pre lang="hurl"><code>POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath "$.order.id"

GET https://sample.org/orders/{{order_id}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sending Data</h2><a id="user-content-sending-data" aria-label="Permalink: Sending Data" href="#sending-data"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending HTML Form Data</h3><a id="user-content-sending-html-form-data" aria-label="Permalink: Sending HTML Form Data" href="#sending-html-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344"><pre lang="hurl"><code>POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#form-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending Multipart Form Data</h3><a id="user-content-sending-multipart-form-data" aria-label="Permalink: Sending Multipart Form Data" href="#sending-multipart-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip"><pre lang="hurl"><code>POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multipart-form-data" rel="nofollow">Doc</a></p>
<p dir="auto">Multipart forms can also be sent with a <a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">multiline string body</a>:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
Content-Type: multipart/form-data; boundary=&quot;boundary&quot;
```
--boundary
Content-Disposition: form-data; name=&quot;key1&quot;

value1
--boundary
Content-Disposition: form-data; name=&quot;upload1&quot;; filename=&quot;data.txt&quot;
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name=&quot;upload2&quot;; filename=&quot;data.html&quot;
Content-Type: text/html

<div>Hello <b>World</b>!</div>
--boundary--
```"><pre lang="hurl"><code>POST https://example.org/upload
Content-Type: multipart/form-data; boundary="boundary"
```
--boundary
Content-Disposition: form-data; name="key1"

value1
--boundary
Content-Disposition: form-data; name="upload1"; filename="data.txt"
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name="upload2"; filename="data.html"
Content-Type: text/html

&lt;div&gt;Hello &lt;b&gt;World&lt;/b&gt;!&lt;/div&gt;
--boundary--
```
</code></pre></div>
<p dir="auto">In that case, files have to be inlined in the Hurl file.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Posting a JSON Body</h3><a id="user-content-posting-a-json-body" aria-label="Permalink: Posting a JSON Body" href="#posting-a-json-body"></a></p>
<p dir="auto">With an inline JSON:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;456&quot;,
    &quot;evaluate&quot;: true
}"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "456",
    "evaluate": true
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">With a local file:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
Content-Type: application/json
file,data.json;"><pre lang="hurl"><code>POST https://example.org/api/tests
Content-Type: application/json
file,data.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a JSON Body</h3><a id="user-content-templating-a-json-body" aria-label="Permalink: Templating a JSON Body" href="#templating-a-json-body"></a></p>
<div data-snippet-clipboard-copy-content="PUT https://example.org/api/hits
Content-Type: application/json
{
    &quot;key0&quot;: &quot;{{a_string}}&quot;,
    &quot;key1&quot;: {{a_bool}},
    &quot;key2&quot;: {{a_null}},
    &quot;key3&quot;: {{a_number}}
}"><pre lang="hurl"><code>PUT https://example.org/api/hits
Content-Type: application/json
{
    "key0": "{{a_string}}",
    "key1": {{a_bool}},
    "key2": {{a_null}},
    "key3": {{a_number}}
}
</code></pre></div>
<p dir="auto">Variables can be initialized via command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl"><pre>$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl</pre></div>
<p dir="auto">Resulting in a PUT request with the following JSON body:</p>
<div data-snippet-clipboard-copy-content="{
    &quot;key0&quot;: &quot;apple&quot;,
    &quot;key1&quot;: true,
    &quot;key2&quot;: null,
    &quot;key3&quot;: 42
}"><pre><code>{
    "key0": "apple",
    "key1": true,
    "key2": null,
    "key3": 42
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a XML Body</h3><a id="user-content-templating-a-xml-body" aria-label="Permalink: Templating a XML Body" href="#templating-a-xml-body"></a></p>
<p dir="auto">Using templates with <a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">XML body</a> is not currently supported in Hurl. You can use templates in
<a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">XML multiline string body</a> with variables to send a variable XML body:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/echo/post/xml
```xml
<?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?>
<Request>
    <Login>{{login}}</Login>
    <Password>{{password}}</Password>
</Request>
```"><pre lang="hurl"><code>POST https://example.org/echo/post/xml
```xml
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;Request&gt;
    &lt;Login&gt;{{login}}&lt;/Login&gt;
    &lt;Password&gt;{{password}}&lt;/Password&gt;
&lt;/Request&gt;
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using GraphQL Query</h3><a id="user-content-using-graphql-query" aria-label="Permalink: Using GraphQL Query" href="#using-graphql-query"></a></p>
<p dir="auto">A simple GraphQL query:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
</code></pre></div>
<p dir="auto">A GraphQL query with variables:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  &quot;episode&quot;: &quot;JEDI&quot;,
  &quot;withFriends&quot;: false
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  "episode": "JEDI",
  "withFriends": false
}
```
</code></pre></div>
<p dir="auto">GraphQL queries can also use <a href="https://hurl.dev/docs/templates.html" rel="nofollow">Hurl templates</a>.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#graphql-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Dynamic Datas</h3><a id="user-content-using-dynamic-datas" aria-label="Permalink: Using Dynamic Datas" href="#using-dynamic-datas"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Functions</a> like <code>newUuid</code> and <code>newDate</code> can be used in templates to create dynamic datas:</p>
<p dir="auto">A file that creates a dynamic email (i.e <code>0531f78f-7f87-44be-a7f2-969a1c4e6d97@test.com</code>):</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/foo
{
  &quot;name&quot;: &quot;foo&quot;,
  &quot;email&quot;: &quot;{{newUuid}}@test.com&quot;
}"><pre lang="hurl"><code>POST https://example.org/api/foo
{
  "name": "foo",
  "email": "{{newUuid}}@test.com"
}
</code></pre></div>
<p dir="auto">A file that creates a dynamic query parameter (i.e <code>2024-12-02T10:35:44.461731Z</code>):</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200"><pre lang="hurl"><code>GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing Response</h2><a id="user-content-testing-response" aria-label="Permalink: Testing Response" href="#testing-response"></a></p>
<p dir="auto">Responses are optional, everything after <code>HTTP</code> is part of the response asserts.</p>
<div data-snippet-clipboard-copy-content="# A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;running&quot;"><pre lang="hurl"><code># A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath "$.state" == "running"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Status Code</h3><a id="user-content-testing-status-code" aria-label="Permalink: Testing Status Code" href="#testing-status-code"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
HTTP 200"><pre lang="hurl"><code>GET https://example.org/order/435
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status >= 200
status < 300"><pre lang="hurl"><code>GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status &gt;= 200
status &lt; 300
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#status-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Response Headers</h3><a id="user-content-testing-response-headers" aria-label="Permalink: Testing Response Headers" href="#testing-response-headers"></a></p>
<p dir="auto">Use implicit response asserts to test header values:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto">Or use explicit response asserts with <a href="https://hurl.dev/docs/asserting-response.html#predicates" rel="nofollow">predicates</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 302
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 302
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#header-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit and explicit asserts can be combined:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing REST APIs</h3><a id="user-content-testing-rest-apis" aria-label="Permalink: Testing REST APIs" href="#testing-rest-apis"></a></p>
<p dir="auto">Asserting JSON body response (node values, collection count etc...) with <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath &quot;$.validated&quot; == true
jsonpath &quot;$.userInfo.firstName&quot; == &quot;Franck&quot;
jsonpath &quot;$.userInfo.lastName&quot; == &quot;Herbert&quot;
jsonpath &quot;$.hasDevice&quot; == false
jsonpath &quot;$.links&quot; count == 12
jsonpath &quot;$.state&quot; != null
jsonpath &quot;$.order&quot; matches &quot;^order-\\d{8}$&quot;
jsonpath &quot;$.order&quot; matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath &quot;$.created&quot; isIsoDate"><pre lang="hurl"><code>GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath "$.validated" == true
jsonpath "$.userInfo.firstName" == "Franck"
jsonpath "$.userInfo.lastName" == "Herbert"
jsonpath "$.hasDevice" == false
jsonpath "$.links" count == 12
jsonpath "$.state" != null
jsonpath "$.order" matches "^order-\\d{8}$"
jsonpath "$.order" matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath "$.created" isIsoDate
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#jsonpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing HTML Response</h3><a id="user-content-testing-html-response" aria-label="Permalink: Testing HTML Response" href="#testing-html-response"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath &quot;string(/html/head/title)&quot; contains &quot;Example&quot; # Check title
xpath &quot;count(//p)&quot; == 2  # Check the number of p
xpath &quot;//p&quot; count == 2  # Similar assert for p
xpath &quot;boolean(count(//h2))&quot; == false  # Check there is no h2  
xpath &quot;//h2&quot; not exists  # Similar assert for h2
xpath &quot;string(//div[1])&quot; matches /Hello.*/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath "string(/html/head/title)" contains "Example" # Check title
xpath "count(//p)" == 2  # Check the number of p
xpath "//p" count == 2  # Similar assert for p
xpath "boolean(count(//h2))" == false  # Check there is no h2  
xpath "//h2" not exists  # Similar assert for h2
xpath "string(//div[1])" matches /Hello.*/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Set-Cookie Attributes</h3><a id="user-content-testing-set-cookie-attributes" aria-label="Permalink: Testing Set-Cookie Attributes" href="#testing-set-cookie-attributes"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/home
HTTP 200
[Asserts]
cookie &quot;JSESSIONID&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Value]&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Expires]&quot; contains &quot;Wed, 13 Jan 2021&quot;
cookie &quot;JSESSIONID[Secure]&quot; exists
cookie &quot;JSESSIONID[HttpOnly]&quot; exists
cookie &quot;JSESSIONID[SameSite]&quot; == &quot;Lax&quot;"><pre lang="hurl"><code>GET https://example.org/home
HTTP 200
[Asserts]
cookie "JSESSIONID" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Value]" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Expires]" contains "Wed, 13 Jan 2021"
cookie "JSESSIONID[Secure]" exists
cookie "JSESSIONID[HttpOnly]" exists
cookie "JSESSIONID[SameSite]" == "Lax"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#cookie-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Bytes Content</h3><a id="user-content-testing-bytes-content" aria-label="Permalink: Testing Bytes Content" href="#testing-bytes-content"></a></p>
<p dir="auto">Check the SHA-256 response body hash:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#sha-256-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SSL Certificate</h3><a id="user-content-ssl-certificate" aria-label="Permalink: SSL Certificate" href="#ssl-certificate"></a></p>
<p dir="auto">Check the properties of a SSL certificate:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
certificate &quot;Subject&quot; == &quot;CN=example.org&quot;
certificate &quot;Issuer&quot; == &quot;C=US, O=Let's Encrypt, CN=R3&quot;
certificate &quot;Expire-Date&quot; daysAfterNow > 15
certificate &quot;Serial-Number&quot; matches /[\da-f]+/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
certificate "Subject" == "CN=example.org"
certificate "Issuer" == "C=US, O=Let's Encrypt, CN=R3"
certificate "Expire-Date" daysAfterNow &gt; 15
certificate "Serial-Number" matches /[\da-f]+/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#ssl-certificate-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Full Body</h3><a id="user-content-checking-full-body" aria-label="Permalink: Checking Full Body" href="#checking-full-body"></a></p>
<p dir="auto">Use implicit body to test an exact JSON body match:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/cats/123
HTTP 200
{
  &quot;name&quot; : &quot;Purrsloud&quot;,
  &quot;species&quot; : &quot;Cat&quot;,
  &quot;favFoods&quot; : [&quot;wet food&quot;, &quot;dry food&quot;, &quot;<strong>any</strong> food&quot;],
  &quot;birthYear&quot; : 2016,
  &quot;photo&quot; : &quot;https://learnwebcode.github.io/json-example/images/cat-2.jpg&quot;
}"><pre lang="hurl"><code>GET https://example.org/api/cats/123
HTTP 200
{
  "name" : "Purrsloud",
  "species" : "Cat",
  "favFoods" : ["wet food", "dry food", "&lt;strong&gt;any&lt;/strong&gt; food"],
  "birthYear" : 2016,
  "photo" : "https://learnwebcode.github.io/json-example/images/cat-2.jpg"
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">Or an explicit assert file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#body-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit asserts supports XML body:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/catalog
HTTP 200
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<catalog>
   <book id=&quot;bk101&quot;>
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications with XML.</description>
   </book>
</catalog>"><pre lang="hurl"><code>GET https://example.org/api/catalog
HTTP 200
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;catalog&gt;
   &lt;book id="bk101"&gt;
      &lt;author&gt;Gambardella, Matthew&lt;/author&gt;
      &lt;title&gt;XML Developer's Guide&lt;/title&gt;
      &lt;genre&gt;Computer&lt;/genre&gt;
      &lt;price&gt;44.95&lt;/price&gt;
      &lt;publish_date&gt;2000-10-01&lt;/publish_date&gt;
      &lt;description&gt;An in-depth look at creating applications with XML.&lt;/description&gt;
   &lt;/book&gt;
&lt;/catalog&gt;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto">Plain text:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,&quot;ac, abs, moon&quot;,3000.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition&quot;&quot;&quot;,&quot;&quot;,4900.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition, Very Large&quot;&quot;&quot;,,5000.00
1996,Jeep,Grand Cherokee,&quot;MUST SELL! air, moon roof, loaded&quot;,4799.00
```"><pre lang="hurl"><code>GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,"ac, abs, moon",3000.00
1999,Chevy,"Venture ""Extended Edition""","",4900.00
1999,Chevy,"Venture ""Extended Edition, Very Large""",,5000.00
1996,Jeep,Grand Cherokee,"MUST SELL! air, moon roof, loaded",4799.00
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">One line:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/helloworld
HTTP 200
`Hello world!`"><pre lang="hurl"><code>POST https://example.org/helloworld
HTTP 200
`Hello world!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#oneline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">File:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
file,data.bin;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
file,data.bin;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reports</h2><a id="user-content-reports" aria-label="Permalink: Reports" href="#reports"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTML Report</h3><a id="user-content-html-report" aria-label="Permalink: HTML Report" href="#html-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-html build/report/ *.hurl"><pre>$ hurl --test --report-html build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Report</h3><a id="user-content-json-report" aria-label="Permalink: JSON Report" href="#json-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-json build/report/ *.hurl"><pre>$ hurl --test --report-json build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JUnit Report</h3><a id="user-content-junit-report" aria-label="Permalink: JUnit Report" href="#junit-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-junit build/report.xml *.hurl"><pre>$ hurl --test --report-junit build/report.xml <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">TAP Report</h3><a id="user-content-tap-report" aria-label="Permalink: TAP Report" href="#tap-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-tap build/report.txt *.hurl"><pre>$ hurl --test --report-tap build/report.txt <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Output</h3><a id="user-content-json-output" aria-label="Permalink: JSON Output" href="#json-output"></a></p>
<p dir="auto">A structured output of running Hurl files can be obtained with <a href="https://hurl.dev/docs/manual.html#json" rel="nofollow"><code>--json</code> option</a>. Each file will produce a JSON export of the run.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Others</h2><a id="user-content-others" aria-label="Permalink: Others" href="#others"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Version</h3><a id="user-content-http-version" aria-label="Permalink: HTTP Version" href="#http-version"></a></p>
<p dir="auto">Testing HTTP version (HTTP/1.0, HTTP/1.1, HTTP/2 or HTTP/3) can be done using implicit asserts:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200"><pre lang="hurl"><code>GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<p dir="auto">Or explicit:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
version == &quot;3&quot;

GET https://bar.com
HTTP 200
[Asserts]
version == &quot;2&quot;
version toFloat > 1.1"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
version == "3"

GET https://bar.com
HTTP 200
[Asserts]
version == "2"
version toFloat &gt; 1.1
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">IP Address</h3><a id="user-content-ip-address" aria-label="Permalink: IP Address" href="#ip-address"></a></p>
<p dir="auto">Testing the IP address of the response, as a string. This string may be IPv6 address:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
ip == &quot;2001:0db8:85a3:0000:0000:8a2e:0370:733&quot;
ip startsWith &quot;2001&quot;
ip isIpv6"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
ip == "2001:0db8:85a3:0000:0000:8a2e:0370:733"
ip startsWith "2001"
ip isIpv6
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Polling and Retry</h3><a id="user-content-polling-and-retry" aria-label="Permalink: Polling and Retry" href="#polling-and-retry"></a></p>
<p dir="auto">Retry request on any errors (asserts, captures, status code, runtime etc...):</p>
<div data-snippet-clipboard-copy-content="# Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath &quot;$.id&quot;
[Asserts]
jsonpath &quot;$.state&quot; == &quot;RUNNING&quot;


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;COMPLETED&quot;"><pre lang="hurl"><code># Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath "$.id"
[Asserts]
jsonpath "$.state" == "RUNNING"


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath "$.state" == "COMPLETED"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/entry.html#retry" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Delaying Requests</h3><a id="user-content-delaying-requests" aria-label="Permalink: Delaying Requests" href="#delaying-requests"></a></p>
<p dir="auto">Add delay for every request, or a particular request:</p>
<div data-snippet-clipboard-copy-content="# Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200"><pre lang="hurl"><code># Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#delay" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skipping Requests</h3><a id="user-content-skipping-requests" aria-label="Permalink: Skipping Requests" href="#skipping-requests"></a></p>
<div data-snippet-clipboard-copy-content="# a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d"><pre lang="hurl"><code># a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#skip" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Endpoint Performance</h3><a id="user-content-testing-endpoint-performance" aria-label="Permalink: Testing Endpoint Performance" href="#testing-endpoint-performance"></a></p>
<div data-snippet-clipboard-copy-content="GET https://sample.org/helloworld
HTTP *
[Asserts]
duration < 1000   # Check that response time is less than one second"><pre lang="hurl"><code>GET https://sample.org/helloworld
HTTP *
[Asserts]
duration &lt; 1000   # Check that response time is less than one second
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#duration-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using SOAP APIs</h3><a id="user-content-using-soap-apis" aria-label="Permalink: Using SOAP APIs" href="#using-soap-apis"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing and Using a CSRF Token</h3><a id="user-content-capturing-and-using-a-csrf-token" aria-label="Permalink: Capturing and Using a CSRF Token" href="#capturing-and-using-a-csrf-token"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#xpath-capture" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Redacting Secrets</h3><a id="user-content-redacting-secrets" aria-label="Permalink: Redacting Secrets" href="#redacting-secrets"></a></p>
<p dir="auto">Using command-line for known values:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --secret token=1234 file.hurl"><pre>$ hurl --secret token=1234 file.hurl</pre></div>
<div data-snippet-clipboard-copy-content="POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code>POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#secrets" rel="nofollow">Doc</a></p>
<p dir="auto">Using <code>redact</code> for dynamic values:</p>
<div data-snippet-clipboard-copy-content="# Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header &quot;X-Token&quot; redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code># Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header "X-Token" redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#redacting-secrets" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Byte Order Mark (BOM) in Response Body</h3><a id="user-content-checking-byte-order-mark-bom-in-response-body" aria-label="Permalink: Checking Byte Order Mark (BOM) in Response Body" href="#checking-byte-order-mark-bom-in-response-body"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;"><pre lang="hurl"><code>GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#bytes-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AWS Signature Version 4 Requests</h3><a id="user-content-aws-signature-version-4-requests" aria-label="Permalink: AWS Signature Version 4 Requests" href="#aws-signature-version-4-requests"></a></p>
<p dir="auto">Generate signed API requests with <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html" rel="nofollow">AWS Signature Version 4</a>, as used by several cloud providers.</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto">The Access Key is given per <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a>, either with command line option or within the <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code></a> section:</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#aws-sigv4" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using curl Options</h3><a id="user-content-using-curl-options" aria-label="Permalink: Using curl Options" href="#using-curl-options"></a></p>
<p dir="auto">curl options (for instance <a href="https://hurl.dev/docs/manual.html#resolve" rel="nofollow"><code>--resolve</code></a> or <a href="https://hurl.dev/docs/manual.html#connect-to" rel="nofollow"><code>--connect-to</code></a>) can be used as CLI argument. In this case, they're applicable
to each request of an Hurl file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl"><pre>$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl</pre></div>
<p dir="auto">Use  <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code> section</a> to configure a specific request:</p>
<div data-snippet-clipboard-copy-content="GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`"><pre lang="hurl"><code>GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#options" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Manual</h2><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Name</h2><a id="user-content-name" aria-label="Permalink: Name" href="#name"></a></p>
<p dir="auto">hurl - run and test HTTP requests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synopsis</h2><a id="user-content-synopsis" aria-label="Permalink: Synopsis" href="#synopsis"></a></p>
<p dir="auto"><strong>hurl</strong> [options] [FILE...]</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Description</h2><a id="user-content-description" aria-label="Permalink: Description" href="#description"></a></p>
<p dir="auto"><strong>Hurl</strong> is a command line tool that runs HTTP requests defined in a simple plain text format.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very versatile, it can be used for fetching data and testing HTTP sessions: HTML content, REST / SOAP / GraphQL APIs, or any other XML / JSON based APIs.</p>

<p dir="auto">If no input files are specified, input is read from stdin.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo GET http://httpbin.org/get | hurl
    {
      &quot;args&quot;: {},
      &quot;headers&quot;: {
        &quot;Accept&quot;: &quot;*/*&quot;,
        &quot;Accept-Encoding&quot;: &quot;gzip&quot;,
        &quot;Content-Length&quot;: &quot;0&quot;,
        &quot;Host&quot;: &quot;httpbin.org&quot;,
        &quot;User-Agent&quot;: &quot;hurl/0.99.10&quot;,
        &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-5eedf4c7-520814d64e2f9249ea44e0&quot;
      },
      &quot;origin&quot;: &quot;1.2.3.4&quot;,
      &quot;url&quot;: &quot;http://httpbin.org/get&quot;
    }"><pre>$ <span>echo</span> GET http://httpbin.org/get <span>|</span> hurl
    {
      <span><span>"</span>args<span>"</span></span>: {},
      <span><span>"</span>headers<span>"</span></span>: {
        <span><span>"</span>Accept<span>"</span></span>: <span><span>"</span>*/*<span>"</span></span>,
        <span><span>"</span>Accept-Encoding<span>"</span></span>: <span><span>"</span>gzip<span>"</span></span>,
        <span><span>"</span>Content-Length<span>"</span></span>: <span><span>"</span>0<span>"</span></span>,
        <span><span>"</span>Host<span>"</span></span>: <span><span>"</span>httpbin.org<span>"</span></span>,
        <span><span>"</span>User-Agent<span>"</span></span>: <span><span>"</span>hurl/0.99.10<span>"</span></span>,
        <span><span>"</span>X-Amzn-Trace-Id<span>"</span></span>: <span><span>"</span>Root=1-5eedf4c7-520814d64e2f9249ea44e0<span>"</span></span>
      },
      <span><span>"</span>origin<span>"</span></span>: <span><span>"</span>1.2.3.4<span>"</span></span>,
      <span><span>"</span>url<span>"</span></span>: <span><span>"</span>http://httpbin.org/get<span>"</span></span>
    }</pre></div>
<p dir="auto">Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<p dir="auto">Output goes to stdout by default. To have output go to a file, use the <a href="#output"><code>-o, --output</code></a> option:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl -o output input.hurl"><pre>$ hurl -o output input.hurl</pre></div>
<p dir="auto">By default, Hurl executes all HTTP requests and outputs the response body of the last HTTP call.</p>
<p dir="auto">To have a test oriented output, you can use <a href="#test"><code>--test</code></a> option:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Hurl File Format</h2><a id="user-content-hurl-file-format" aria-label="Permalink: Hurl File Format" href="#hurl-file-format"></a></p>
<p dir="auto">The Hurl file format is fully documented in <a href="https://hurl.dev/docs/hurl-file.html" rel="nofollow">https://hurl.dev/docs/hurl-file.html</a></p>
<p dir="auto">It consists of one or several HTTP requests</p>
<div data-snippet-clipboard-copy-content="GET http://example.org/endpoint1
GET http://example.org/endpoint2"><pre lang="hurl"><code>GET http://example.org/endpoint1
GET http://example.org/endpoint2
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing values</h3><a id="user-content-capturing-values" aria-label="Permalink: Capturing values" href="#capturing-values"></a></p>
<p dir="auto">A value from an HTTP response can be-reused for successive HTTP requests.</p>
<p dir="auto">A typical example occurs with CSRF tokens.</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath &quot;normalize-space(//meta[@name='_csrf_token']/@content)&quot;

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}"><pre lang="hurl"><code>GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath "normalize-space(//meta[@name='_csrf_token']/@content)"

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
</code></pre></div>
<p dir="auto">More information on captures can be found here <a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">https://hurl.dev/docs/capturing-response.html</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Asserts</h3><a id="user-content-asserts" aria-label="Permalink: Asserts" href="#asserts"></a></p>
<p dir="auto">The HTTP response defined in the Hurl file are used to make asserts. Responses are optional.</p>
<p dir="auto">At the minimum, response includes assert on the HTTP status code.</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301"><pre lang="hurl"><code>GET http://example.org
HTTP 301
</code></pre></div>
<p dir="auto">It can also include asserts on the response headers</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
Location: http://www.example.org"><pre lang="hurl"><code>GET http://example.org
HTTP 301
Location: http://www.example.org
</code></pre></div>
<p dir="auto">Explicit asserts can be included by combining a query and a predicate</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
[Asserts]
xpath &quot;string(//title)&quot; == &quot;301 Moved&quot;"><pre lang="hurl"><code>GET http://example.org
HTTP 301
[Asserts]
xpath "string(//title)" == "301 Moved"
</code></pre></div>
<p dir="auto">With the addition of asserts, Hurl can be used as a testing tool to run scenarios.</p>
<p dir="auto">More information on asserts can be found here <a href="https://hurl.dev/docs/asserting-response.html" rel="nofollow">https://hurl.dev/docs/asserting-response.html</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<p dir="auto">Options that exist in curl have exactly the same semantics.</p>
<p dir="auto">Options specified on the command line are defined for every Hurl file's entry,
except if they are tagged as cli-only (can not be defined in the Hurl request [Options] entry)</p>
<p dir="auto">For instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --location foo.hurl"><pre>$ hurl --location foo.hurl</pre></div>
<p dir="auto">will follow redirection for each entry in <code>foo.hurl</code>. You can also define an option only for a particular entry with an <code>[Options]</code> section. For instance, this Hurl file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200"><pre lang="hurl"><code>GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200
</code></pre></div>
<p dir="auto">will follow a redirection only for the second entry.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#aws-sigv4" id="user-content-aws-sigv4"><code>--aws-sigv4 &lt;PROVIDER1[:PROVIDER2[:REGION[:SERVICE]]]&gt;</code></a></td>
<td>Generate an <code>Authorization</code> header with an AWS SigV4 signature.<p>Use <a href="#user"><code>-u, --user</code></a> to specify Access Key Id (username) and Secret Key (password).</p><p>To use temporary session credentials (e.g. for an AWS IAM Role), add the <code>X-Amz-Security-Token</code> header containing the session token.</p></td>
</tr>
<tr>
<td><a href="#cacert" id="user-content-cacert"><code>--cacert &lt;FILE&gt;</code></a></td>
<td>Specifies the certificate file for peer verification. The file may contain multiple CA certificates and must be in PEM format.<br>Normally Hurl is built to use a default file for this, so this option is typically used to alter that default file.<br></td>
</tr>
<tr>
<td><a href="#cert" id="user-content-cert"><code>-E, --cert &lt;CERTIFICATE[:PASSWORD]&gt;</code></a></td>
<td>Client certificate file and password.<p>See also <a href="#key"><code>--key</code></a>.</p></td>
</tr>
<tr>
<td><a href="#color" id="user-content-color"><code>--color</code></a></td>
<td>Colorize debug output (the HTTP response output is not colorized).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#compressed" id="user-content-compressed"><code>--compressed</code></a></td>
<td>Request a compressed response using one of the algorithms br, gzip, deflate and automatically decompress the content.<br></td>
</tr>
<tr>
<td><a href="#connect-timeout" id="user-content-connect-timeout"><code>--connect-timeout &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow Hurl's connection to take.<p>You can specify time units in the connect timeout expression. Set Hurl to use a connect timeout of 20 seconds with <code>--connect-timeout 20s</code> or set it to 35,000 milliseconds with <code>--connect-timeout 35000ms</code>. No spaces allowed.</p><p>See also <a href="#max-time"><code>-m, --max-time</code></a>.</p></td>
</tr>
<tr>
<td><a href="#connect-to" id="user-content-connect-to"><code>--connect-to &lt;HOST1:PORT1:HOST2:PORT2&gt;</code></a></td>
<td>For a request to the given HOST1:PORT1 pair, connect to HOST2:PORT2 instead. This option can be used several times in a command line.<p>See also <a href="#resolve"><code>--resolve</code></a>.</p></td>
</tr>
<tr>
<td><a href="#continue-on-error" id="user-content-continue-on-error"><code>--continue-on-error</code></a></td>
<td>Continue executing requests to the end of the Hurl file even when an assert error occurs.<br>By default, Hurl exits after an assert error in the HTTP response.<p>Note that this option does not affect the behavior with multiple input Hurl files.</p><p>All the input files are executed independently. The result of one file does not affect the execution of the other Hurl files.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie" id="user-content-cookie"><code>-b, --cookie &lt;FILE&gt;</code></a></td>
<td>Read cookies from FILE (using the Netscape cookie file format).<p>Combined with <a href="#cookie-jar"><code>-c, --cookie-jar</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie-jar" id="user-content-cookie-jar"><code>-c, --cookie-jar &lt;FILE&gt;</code></a></td>
<td>Write cookies to FILE after running the session.<br>The file will be written using the Netscape cookie file format.<p>Combined with <a href="#cookie"><code>-b, --cookie</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#curl" id="user-content-curl"><code>--curl &lt;FILE&gt;</code></a></td>
<td>Export each request to a list of curl commands.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#delay" id="user-content-delay"><code>--delay &lt;MILLISECONDS&gt;</code></a></td>
<td>Sets delay before each request (aka sleep). The delay is not applied to requests that have been retried because of <a href="#retry"><code>--retry</code></a>. See <a href="#retry-interval"><code>--retry-interval</code></a> to space retried requests.<p>You can specify time units in the delay expression. Set Hurl to use a delay of 2 seconds with <code>--delay 2s</code> or set it to 500 milliseconds with <code>--delay 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#error-format" id="user-content-error-format"><code>--error-format &lt;FORMAT&gt;</code></a></td>
<td>Control the format of error message (short by default or long)<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#file-root" id="user-content-file-root"><code>--file-root &lt;DIR&gt;</code></a></td>
<td>Set root directory to import files in Hurl. This is used for files in multipart form data, request body and response output.<br>When it is not explicitly defined, files are relative to the Hurl file's directory.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#from-entry" id="user-content-from-entry"><code>--from-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file from ENTRY_NUMBER (starting at 1).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#glob" id="user-content-glob"><code>--glob &lt;GLOB&gt;</code></a></td>
<td>Specify input files that match the given glob pattern.<p>Multiple glob flags may be used. This flag supports common Unix glob patterns like *, ? and [].<br>However, to avoid your shell accidentally expanding glob patterns before Hurl handles them, you must use single quotes or double quotes around each pattern.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#header" id="user-content-header"><code>-H, --header &lt;HEADER&gt;</code></a></td>
<td>Add an extra header to include in information sent. Can be used several times in a command<p>Do not add newlines or carriage returns</p></td>
</tr>
<tr>
<td><a href="#http10" id="user-content-http10"><code>-0, --http1.0</code></a></td>
<td>Tells Hurl to use HTTP version 1.0 instead of using its internally preferred HTTP version.<br></td>
</tr>
<tr>
<td><a href="#http11" id="user-content-http11"><code>--http1.1</code></a></td>
<td>Tells Hurl to use HTTP version 1.1.<br></td>
</tr>
<tr>
<td><a href="#http2" id="user-content-http2"><code>--http2</code></a></td>
<td>Tells Hurl to use HTTP version 2.<br>For HTTPS, this means Hurl negotiates HTTP/2 in the TLS handshake. Hurl does this by default.<br>For HTTP, this means Hurl attempts to upgrade the request to HTTP/2 using the Upgrade: request header.<br></td>
</tr>
<tr>
<td><a href="#http3" id="user-content-http3"><code>--http3</code></a></td>
<td>Tells Hurl to try HTTP/3 to the host in the URL, but fallback to earlier HTTP versions if the HTTP/3 connection establishment fails. HTTP/3 is only available for HTTPS and not for HTTP URLs.<br></td>
</tr>
<tr>
<td><a href="#ignore-asserts" id="user-content-ignore-asserts"><code>--ignore-asserts</code></a></td>
<td>Ignore all asserts defined in the Hurl file.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#include" id="user-content-include"><code>-i, --include</code></a></td>
<td>Include the HTTP headers in the output<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#insecure" id="user-content-insecure"><code>-k, --insecure</code></a></td>
<td>This option explicitly allows Hurl to perform "insecure" SSL connections and transfers.<br></td>
</tr>
<tr>
<td><a href="#interactive" id="user-content-interactive"><code>--interactive</code></a></td>
<td>Stop between requests.<p>This is similar to a break point, You can then continue (Press C) or quit (Press Q).</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#ipv4" id="user-content-ipv4"><code>-4, --ipv4</code></a></td>
<td>This option tells Hurl to use IPv4 addresses only when resolving host names, and not for example try IPv6.<br></td>
</tr>
<tr>
<td><a href="#ipv6" id="user-content-ipv6"><code>-6, --ipv6</code></a></td>
<td>This option tells Hurl to use IPv6 addresses only when resolving host names, and not for example try IPv4.<br></td>
</tr>
<tr>
<td><a href="#jobs" id="user-content-jobs"><code>--jobs &lt;NUM&gt;</code></a></td>
<td>Maximum number of parallel jobs in parallel mode. Default value corresponds (in most cases) to the<br>current amount of CPUs.<p>See also <a href="#parallel"><code>--parallel</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#json" id="user-content-json"><code>--json</code></a></td>
<td>Output each Hurl file result to JSON. The format is very closed to HAR format.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#key" id="user-content-key"><code>--key &lt;KEY&gt;</code></a></td>
<td>Private key file name.<br></td>
</tr>
<tr>
<td><a href="#limit-rate" id="user-content-limit-rate"><code>--limit-rate &lt;SPEED&gt;</code></a></td>
<td>Specify the maximum transfer rate you want Hurl to use, for both downloads and uploads. This feature is useful if you have a limited pipe and you would like your transfer not to use your entire bandwidth. To make it slower than it otherwise would be.<br>The given speed is measured in bytes/second.<br></td>
</tr>
<tr>
<td><a href="#location" id="user-content-location"><code>-L, --location</code></a></td>
<td>Follow redirect. To limit the amount of redirects to follow use the <a href="#max-redirs"><code>--max-redirs</code></a> option<br></td>
</tr>
<tr>
<td><a href="#location-trusted" id="user-content-location-trusted"><code>--location-trusted</code></a></td>
<td>Like <a href="#location"><code>-L, --location</code></a>, but allows sending the name + password to all hosts that the site may redirect to.<br>This may or may not introduce a security breach if the site redirects you to a site to which you send your authentication info (which is plaintext in the case of HTTP Basic authentication).<br></td>
</tr>
<tr>
<td><a href="#max-filesize" id="user-content-max-filesize"><code>--max-filesize &lt;BYTES&gt;</code></a></td>
<td>Specify the maximum size in bytes of a file to download. If the file requested is larger than this value, the transfer does not start.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#max-redirs" id="user-content-max-redirs"><code>--max-redirs &lt;NUM&gt;</code></a></td>
<td>Set maximum number of redirection-followings allowed<p>By default, the limit is set to 50 redirections. Set this option to -1 to make it unlimited.</p></td>
</tr>
<tr>
<td><a href="#max-time" id="user-content-max-time"><code>-m, --max-time &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow a request/response to take. This is the standard timeout.<p>You can specify time units in the maximum time expression. Set Hurl to use a maximum time of 20 seconds with <code>--max-time 20s</code> or set it to 35,000 milliseconds with <code>--max-time 35000ms</code>. No spaces allowed.</p><p>See also <a href="#connect-timeout"><code>--connect-timeout</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc" id="user-content-netrc"><code>-n, --netrc</code></a></td>
<td>Scan the .netrc file in the user's home directory for the username and password.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a> and <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-file" id="user-content-netrc-file"><code>--netrc-file &lt;FILE&gt;</code></a></td>
<td>Like <a href="#netrc"><code>--netrc</code></a>, but provide the path to the netrc file.<p>See also <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-optional" id="user-content-netrc-optional"><code>--netrc-optional</code></a></td>
<td>Similar to <a href="#netrc"><code>--netrc</code></a>, but make the .netrc usage optional.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a>.</p></td>
</tr>
<tr>
<td><a href="#no-color" id="user-content-no-color"><code>--no-color</code></a></td>
<td>Do not colorize output.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#no-output" id="user-content-no-output"><code>--no-output</code></a></td>
<td>Suppress output. By default, Hurl outputs the body of the last response.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#noproxy" id="user-content-noproxy"><code>--noproxy &lt;HOST(S)&gt;</code></a></td>
<td>Comma-separated list of hosts which do not use a proxy.<p>Override value from Environment variable no_proxy.</p></td>
</tr>
<tr>
<td><a href="#output" id="user-content-output"><code>-o, --output &lt;FILE&gt;</code></a></td>
<td>Write output to FILE instead of stdout.<br></td>
</tr>
<tr>
<td><a href="#parallel" id="user-content-parallel"><code>--parallel</code></a></td>
<td>Run files in parallel.<p>Each Hurl file is executed in its own worker thread, without sharing anything with the other workers. The default run mode is sequential. Parallel execution is by default in <a href="#test"><code>--test</code></a> mode.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#path-as-is" id="user-content-path-as-is"><code>--path-as-is</code></a></td>
<td>Tell Hurl to not handle sequences of /../ or /./ in the given URL path. Normally Hurl will squash or merge them according to standards but with this option set you tell it not to do that.<br></td>
</tr>
<tr>
<td><a href="#pinnedpubkey" id="user-content-pinnedpubkey"><code>--pinnedpubkey &lt;HASHES&gt;</code></a></td>
<td>When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key provided to this option, Hurl aborts the connection before sending or receiving any data.<br></td>
</tr>
<tr>
<td><a href="#progress-bar" id="user-content-progress-bar"><code>--progress-bar</code></a></td>
<td>Display a progress bar in test mode. The progress bar is displayed only in interactive TTYs. This option forces the progress bar to be displayed even in non-interactive TTYs.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#proxy" id="user-content-proxy"><code>-x, --proxy &lt;[PROTOCOL://]HOST[:PORT]&gt;</code></a></td>
<td>Use the specified proxy.<br></td>
</tr>
<tr>
<td><a href="#repeat" id="user-content-repeat"><code>--repeat &lt;NUM&gt;</code></a></td>
<td>Repeat the input files sequence NUM times, -1 for infinite loop. Given a.hurl, b.hurl, c.hurl as input, repeat two<br>times will run a.hurl, b.hurl, c.hurl, a.hurl, b.hurl, c.hurl.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-html" id="user-content-report-html"><code>--report-html &lt;DIR&gt;</code></a></td>
<td>Generate HTML report in DIR.<p>If the HTML report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-json" id="user-content-report-json"><code>--report-json &lt;DIR&gt;</code></a></td>
<td>Generate JSON report in DIR.<p>If the JSON report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-junit" id="user-content-report-junit"><code>--report-junit &lt;FILE&gt;</code></a></td>
<td>Generate JUnit File.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-tap" id="user-content-report-tap"><code>--report-tap &lt;FILE&gt;</code></a></td>
<td>Generate TAP report.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#resolve" id="user-content-resolve"><code>--resolve &lt;HOST:PORT:ADDR&gt;</code></a></td>
<td>Provide a custom address for a specific host and port pair. Using this, you can make the Hurl requests(s) use a specified address and prevent the otherwise normally resolved address to be used. Consider it a sort of /etc/hosts alternative provided on the command line.<br></td>
</tr>
<tr>
<td><a href="#retry" id="user-content-retry"><code>--retry &lt;NUM&gt;</code></a></td>
<td>Maximum number of retries, 0 for no retries, -1 for unlimited retries. Retry happens if any error occurs (asserts, captures, runtimes etc...).<br></td>
</tr>
<tr>
<td><a href="#retry-interval" id="user-content-retry-interval"><code>--retry-interval &lt;MILLISECONDS&gt;</code></a></td>
<td>Duration in milliseconds between each retry. Default is 1000 ms.<p>You can specify time units in the retry interval expression. Set Hurl to use a retry interval of 2 seconds with <code>--retry-interval 2s</code> or set it to 500 milliseconds with <code>--retry-interval 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#secret" id="user-content-secret"><code>--secret &lt;NAME=VALUE&gt;</code></a></td>
<td>Define secret value to be redacted from logs and report. When defined, secrets can be used as variable everywhere variables are used.<br></td>
</tr>
<tr>
<td><a href="#ssl-no-revoke" id="user-content-ssl-no-revoke"><code>--ssl-no-revoke</code></a></td>
<td>(Windows) This option tells Hurl to disable certificate revocation checks. WARNING: this option loosens the SSL security, and by using this flag you ask for exactly that.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#test" id="user-content-test"><code>--test</code></a></td>
<td>Activate test mode: with this, the HTTP response is not outputted anymore, progress is reported for each Hurl file tested, and a text summary is displayed when all files have been run.<p>In test mode, files are executed in parallel. To run test in a sequential way use <code>--job 1</code>.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#to-entry" id="user-content-to-entry"><code>--to-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file to ENTRY_NUMBER (starting at 1).<br>Ignore the remaining of the file. It is useful for debugging a session.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#unix-socket" id="user-content-unix-socket"><code>--unix-socket &lt;PATH&gt;</code></a></td>
<td>(HTTP) Connect through this Unix domain socket, instead of using the network.<br></td>
</tr>
<tr>
<td><a href="#user" id="user-content-user"><code>-u, --user &lt;USER:PASSWORD&gt;</code></a></td>
<td>Add basic Authentication header to each request.<br></td>
</tr>
<tr>
<td><a href="#user-agent" id="user-content-user-agent"><code>-A, --user-agent &lt;NAME&gt;</code></a></td>
<td>Specify the User-Agent string to send to the HTTP server.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#variable" id="user-content-variable"><code>--variable &lt;NAME=VALUE&gt;</code></a></td>
<td>Define variable (name/value) to be used in Hurl templates.<br></td>
</tr>
<tr>
<td><a href="#variables-file" id="user-content-variables-file"><code>--variables-file &lt;FILE&gt;</code></a></td>
<td>Set properties file in which your define your variables.<p>Each variable is defined as name=value exactly as with <a href="#variable"><code>--variable</code></a> option.</p><p>Note that defining a variable twice produces an error.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#verbose" id="user-content-verbose"><code>-v, --verbose</code></a></td>
<td>Turn on verbose output on standard error stream.<br>Useful for debugging.<p>A line starting with '&gt;' means data sent by Hurl.<br>A line staring with '&lt;' means data received by Hurl.<br>A line starting with '*' means additional info provided by Hurl.</p><p>If you only want HTTP headers in the output, <a href="#include"><code>-i, --include</code></a> might be the option you're looking for.</p></td>
</tr>
<tr>
<td><a href="#very-verbose" id="user-content-very-verbose"><code>--very-verbose</code></a></td>
<td>Turn on more verbose output on standard error stream.<p>In contrast to  <a href="#verbose"><code>--verbose</code></a> option, this option outputs the full HTTP body request and response on standard error. In addition, lines starting with '**' are libcurl debug logs.</p></td>
</tr>
<tr>
<td><a href="#help" id="user-content-help"><code>-h, --help</code></a></td>
<td>Usage help. This lists all current command line options with a short description.<br></td>
</tr>
<tr>
<td><a href="#version" id="user-content-version"><code>-V, --version</code></a></td>
<td>Prints version information<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment</h2><a id="user-content-environment" aria-label="Permalink: Environment" href="#environment"></a></p>
<p dir="auto">Environment variables can only be specified in lowercase.</p>
<p dir="auto">Using an environment variable to set the proxy has the same effect as using the <a href="#proxy"><code>-x, --proxy</code></a> option.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>http_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTP.<br></td>
</tr>
<tr>
<td><code>https_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTPS.<br></td>
</tr>
<tr>
<td><code>all_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use if no protocol-specific proxy is set.<br></td>
</tr>
<tr>
<td><code>no_proxy &lt;comma-separated list of hosts&gt;</code></td>
<td>List of host names that shouldn't go through any proxy.<br></td>
</tr>
<tr>
<td><code>HURL_name value</code></td>
<td>Define variable (name/value) to be used in Hurl templates. This is similar than <a href="#variable"><code>--variable</code></a> and <a href="#variables-file"><code>--variables-file</code></a> options.<br></td>
</tr>
<tr>
<td><code>NO_COLOR</code></td>
<td>When set to a non-empty string, do not colorize output (see <a href="#no-color"><code>--no-color</code></a> option).<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exit Codes</h2><a id="user-content-exit-codes" aria-label="Permalink: Exit Codes" href="#exit-codes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td>Success.<br></td>
</tr>
<tr>
<td><code>1</code></td>
<td>Failed to parse command-line options.<br></td>
</tr>
<tr>
<td><code>2</code></td>
<td>Input File Parsing Error.<br></td>
</tr>
<tr>
<td><code>3</code></td>
<td>Runtime error (such as failure to connect to host).<br></td>
</tr>
<tr>
<td><code>4</code></td>
<td>Assert Error.<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">WWW</h2><a id="user-content-www" aria-label="Permalink: WWW" href="#www"></a></p>
<p dir="auto"><a href="https://hurl.dev/" rel="nofollow">https://hurl.dev</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">See Also</h2><a id="user-content-see-also" aria-label="Permalink: See Also" href="#see-also"></a></p>
<p dir="auto">curl(1)  hurlfmt(1)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Binaries Installation</h2><a id="user-content-binaries-installation" aria-label="Permalink: Binaries Installation" href="#binaries-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">Precompiled binary (depending on libc &gt;=2.35) is available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl-$VERSION-x86_64-unknown-linux-gnu.tar.gz | tar xvz -C $INSTALL_DIR
$ export PATH=$INSTALL_DIR/hurl-$VERSION-x86_64-unknown-linux-gnu/bin:$PATH"><pre>$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu.tar.gz <span>|</span> tar xvz -C <span>$INSTALL_DIR</span>
$ <span>export</span> PATH=<span>$INSTALL_DIR</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu/bin:<span>$PATH</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian / Ubuntu</h4><a id="user-content-debian--ubuntu" aria-label="Permalink: Debian / Ubuntu" href="#debian--ubuntu"></a></p>
<p dir="auto">For Debian &gt;=12 / Ubuntu &gt;=22.04, Hurl can be installed using a binary .deb file provided in each Hurl release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl_${VERSION}_amd64.deb
$ sudo apt update &amp;&amp; sudo apt install ./hurl_${VERSION}_amd64.deb"><pre>$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl_<span>${VERSION}</span>_amd64.deb
$ sudo apt update <span>&amp;&amp;</span> sudo apt install ./hurl_<span>${VERSION}</span>_amd64.deb</pre></div>
<p dir="auto">For Ubuntu &gt;=18.04, Hurl can be installed from <code>ppa:lepapareil/hurl</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=&quot;${VERSION}&quot;*"><pre>$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=<span><span>"</span><span>${VERSION}</span><span>"</span></span><span>*</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine</h4><a id="user-content-alpine" aria-label="Permalink: Alpine" href="#alpine"></a></p>
<p dir="auto">Hurl is available on <code>testing</code> channel.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl"><pre>$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch Linux / Manjaro</h4><a id="user-content-arch-linux--manjaro" aria-label="Permalink: Arch Linux / Manjaro" href="#arch-linux--manjaro"></a></p>
<p dir="auto">Hurl is available on <a href="https://archlinux.org/packages/extra/x86_64/hurl/" rel="nofollow">extra</a> channel.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">NixOS / Nix</h4><a id="user-content-nixos--nix" aria-label="Permalink: NixOS / Nix" href="#nixos--nix"></a></p>
<p dir="auto"><a href="https://search.nixos.org/packages?from=0&amp;size=1&amp;sort=relevance&amp;type=packages&amp;query=hurl" rel="nofollow">NixOS / Nix package</a> is available on stable channel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<p dir="auto">Precompiled binaries for Intel and ARM CPUs are available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew</h4><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">MacPorts</h4><a id="user-content-macports" aria-label="Permalink: MacPorts" href="#macports"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">FreeBSD</h3><a id="user-content-freebsd" aria-label="Permalink: FreeBSD" href="#freebsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows requires the <a href="https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version" rel="nofollow">Visual C++ Redistributable Package</a> to be installed manually, as this is not included in the installer.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Zip File</h4><a id="user-content-zip-file" aria-label="Permalink: Zip File" href="#zip-file"></a></p>
<p dir="auto">Hurl can be installed from a standalone zip file at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>. You will need to update your <code>PATH</code> variable.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installer</h4><a id="user-content-installer" aria-label="Permalink: Installer" href="#installer"></a></p>
<p dir="auto">An executable installer is also available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Chocolatey</h4><a id="user-content-chocolatey" aria-label="Permalink: Chocolatey" href="#chocolatey"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Scoop</h4><a id="user-content-scoop" aria-label="Permalink: Scoop" href="#scoop"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Windows Package Manager</h4><a id="user-content-windows-package-manager" aria-label="Permalink: Windows Package Manager" href="#windows-package-manager"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Cargo</h3><a id="user-content-cargo" aria-label="Permalink: Cargo" href="#cargo"></a></p>
<p dir="auto">If you're a Rust programmer, Hurl can be installed with cargo.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cargo install --locked hurl"><pre>$ cargo install --locked hurl</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">conda-forge</h3><a id="user-content-conda-forge" aria-label="Permalink: conda-forge" href="#conda-forge"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ conda install -c conda-forge hurl"><pre>$ conda install -c conda-forge hurl</pre></div>
<p dir="auto">Hurl can also be installed with <a href="https://conda-forge.org/" rel="nofollow"><code>conda-forge</code></a> powered package manager like <a href="https://prefix.dev/" rel="nofollow"><code>pixi</code></a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ docker pull ghcr.io/orange-opensource/hurl:latest"><pre>$ docker pull ghcr.io/orange-opensource/hurl:latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">npm</h3><a id="user-content-npm" aria-label="Permalink: npm" href="#npm"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm install --save-dev @orangeopensource/hurl"><pre>$ npm install --save-dev @orangeopensource/hurl</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building From Sources</h2><a id="user-content-building-from-sources" aria-label="Permalink: Building From Sources" href="#building-from-sources"></a></p>
<p dir="auto">Hurl sources are available in <a href="https://github.com/Orange-OpenSource/hurl">GitHub</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Linux</h3><a id="user-content-build-on-linux" aria-label="Permalink: Build on Linux" href="#build-on-linux"></a></p>
<p dir="auto">Hurl depends on libssl, libcurl and libxml2 native libraries. You will need their development files in your platform.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian based distributions</h4><a id="user-content-debian-based-distributions" aria-label="Permalink: Debian based distributions" href="#debian-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev"><pre>$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fedora based distributions</h4><a id="user-content-fedora-based-distributions" aria-label="Permalink: Fedora based distributions" href="#fedora-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Red Hat based distributions</h4><a id="user-content-red-hat-based-distributions" aria-label="Permalink: Red Hat based distributions" href="#red-hat-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch based distributions</h4><a id="user-content-arch-based-distributions" aria-label="Permalink: Arch based distributions" href="#arch-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang"><pre>$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine based distributions</h4><a id="user-content-alpine-based-distributions" aria-label="Permalink: Alpine based distributions" href="#alpine-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev"><pre>$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on macOS</h3><a id="user-content-build-on-macos" aria-label="Permalink: Build on macOS" href="#build-on-macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xcode-select --install
$ brew install pkg-config"><pre>$ xcode-select --install
$ brew install pkg-config</pre></div>
<p dir="auto">Hurl is written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. You should <a href="https://www.rust-lang.org/tools/install" rel="nofollow">install</a> the latest stable release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl https://sh.rustup.rs -sSf | sh -s -- -y
$ source $HOME/.cargo/env
$ rustc --version
$ cargo --version"><pre>$ curl https://sh.rustup.rs -sSf <span>|</span> sh -s -- -y
$ <span>source</span> <span>$HOME</span>/.cargo/env
$ rustc --version
$ cargo --version</pre></div>
<p dir="auto">Then build hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone https://github.com/Orange-OpenSource/hurl
$ cd hurl
$ cargo build --release
$ ./target/release/hurl --version"><pre>$ git clone https://github.com/Orange-OpenSource/hurl
$ <span>cd</span> hurl
$ cargo build --release
$ ./target/release/hurl --version</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Windows</h3><a id="user-content-build-on-windows" aria-label="Permalink: Build on Windows" href="#build-on-windows"></a></p>
<p dir="auto">Please follow the <a href="https://github.com/Orange-OpenSource/hurl/blob/master/contrib/windows/README.md">contrib on Windows section</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asterinas: A new Linux-compatible kernel project (131 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/</link>
            <guid>44324084</guid>
            <pubDate>Fri, 20 Jun 2025 01:56:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/">https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/</a>, See on <a href="https://news.ycombinator.com/item?id=44324084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
Born from research at the <a href="https://www.sustech.edu.cn/en/">Southern University of Science and
Technology</a> (SUSTech) in Shenzen, China, <a href="https://asterinas.github.io/">Asterinas</a> is a new
Linux-ABI-compatible kernel project written in Rust, based on what the
authors call a "framekernel architecture".  The project overlaps somewhat
with the goals of the <a href="https://rust-for-linux.com/">Rust for Linux
project</a>, but approaches the problem space from a different direction by
trying to get the best from both monolithic and microkernel designs.

</p><h4>What's a framekernel?</h4>

<p>
The framekernel concept is explained in the September 2024 paper "<a href="https://dl.acm.org/doi/10.1145/3678015.3680492">Framekernel: A Safe
and Efficient Kernel Architecture via Rust-based Intra-kernel Privilege
Separation</a>" by Yuke Peng et al.  <a href="https://arxiv.org/abs/2506.03876">A fuller version of the paper</a>
was published in early June.


</p><p>
Traditionally, monolithic kernels lump everything into one kernel-mode
address space, whereas microkernels only implement a minimal <a href="https://en.wikipedia.org/wiki/Trusted_computing_base">trusted
computing base (TCB)</a> in kernel space and rely on user-mode services for
much of the operating system's functionality.  This separation implies the
use of interprocess communication (IPC) between the microkernel and those
services. This IPC often has a performance impact, which is a big part of
why microkernels have remained relatively unpopular.

<!-- middle-ad -->
</p><p>
The core of Asterinas's "framekernel" design is the encapsulation of all
code that needs Rust's <tt>unsafe</tt> features inside a library, enabling
the rest of the kernel (the services) to be developed using safe
abstractions.  Those services remain within the kernel's address space, but
only have access to the resources that the core library gives to them.
This design is meant to improve the safety of the system while retaining
the simple and performant shared-memory architecture of monolithic
kernels. The <a href="https://asterinas.github.io/book/">Asterinas book</a>
on the project's website provides a nice <a href="https://asterinas.github.io/book/kernel/the-framekernel-architecture.html">
architectural mission statement and overview</a>.


</p><p>
The aptness of the "framekernel" nomenclature can perhaps be debated.  The
frame part refers to the development framework wrapping the unsafe
parts behind a memory-safe API.  The concept of the TCB is, of
course, not exclusive to microkernel architectures but, because there are
strong incentives to strictly scrutinize and, in some contexts, even <a href="https://en.wikipedia.org/wiki/Formal_verification">formally
verify</a> the TCB of a system, keeping the TCB as small as possible is a
central aspect of microkernel designs.


</p><p>
An update on the project is available on the Asterinas blog in the
June&nbsp;4 post titled "<a href="https://asterinas.github.io/2025/06/04/kernel-memory-safety-mission-accomplished.html">Kernel
Memory Safety: Mission Accomplished</a>".  The post explains the team's
motivations and the need for the industry to address memory-safety
problems; it provides some illustrations that explain how the framekernel
is different from monolithic kernels and microkernels. It also takes a
moment to emphasize that the benefits of Rust don't stop with memory
safety; there are improvements to <a href="https://jacko.io/safety_and_soundness.html">soundness</a> as well.
Perhaps most importantly, the post highlights the upcoming Asterinas
presentation at the <a href="https://www.usenix.org/conference/atc25/technical-sessions">2025
USENIX Annual Technical Conference</a>.
</p><h4>Related work</h4>

<p>
In their paper, the authors compare Asterinas to some prior Rust-based
operating-system work, exploring the benefits of the language's
memory-safety features and explain how Asterinas differs from that previous
work.  Specifically, the paper contrasts Asterinas with <a href="https://www.usenix.org/conference/osdi20/presentation/narayanan-vikram">
RedLeaf</a>, an operating system written in Rust and presented at the 14th
USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)
in 2020.  Asterinas uses hardware isolation to permit running user-space
programs written in any programming language, aims to be general-purpose,
and provides a Linux-compatible ABI, while RedLeaf is a microkernel that is
designed <i>not</i> to use the hardware's isolation features, and the
project focuses on different things.
</p><p>
Another project of interest is <a href="https://tockos.org/">Tock</a>, an
embedded system that targets SoCs with limited hardware protection
functionality. Like Asterinas, Tock also divides the kernel into a
trusted core allowed to use <tt>unsafe</tt> and untrusted "capsules" that
are not.  As mentioned, Asterinas does rely on hardware protection and
isn't intended for strictly embedded use, which differentiates it from
Tock.


</p><p>
It bears mentioning that the Rust for Linux project, which is introducing
Rust code into the upstream Linux kernel, has similar goals as
Asterinas. It also aims to encapsulate kernel interfaces with safe
abstractions in such a way that drivers can be written in Rust without any
need for <tt>unsafe</tt>.


</p><h4>Work toward formal verification</h4>

<p>
One goal of shrinking the TCB of an operating system is to make it feasible
to have it formally verified.  In February 2025, the Asterinas blog
featured <a href="https://asterinas.github.io/2025/02/13/towards-practical-formal-verification-for-a-general-purpose-os-in-rust.html">a
post detailing plans to do just that</a>.  The best known formally verified
kernel is <a href="https://sel4.systems/About/">seL4</a>, an L4-family
microkernel.

</p><p>
Asterinas aims to use the framekernel approach to achieve a system that has
a small, formally verified TCB akin to a lean microkernel, but also a
simple shared-memory architecture with Linux ABI compatibility, all at the
same time.  This is a radical departure from any previously formally
verified kernel; the blog post describes those kernels as deliberately
small and limited compared to "<q>full-fledged, UNIX-style OSes</q>".


</p><p>
The Asterinas project is collaborating with a security-auditing company
called <a href="https://www.certik.com/">CertiK</a> to use <a href="https://github.com/verus-lang/verus">Verus</a> to formally verify the
kernel.  There is an extensive <a href="https://github.com/asterinas/slides/blob/f62c764ea9c4831a747dbe8fa415b56e48493482/slides/2025-01-28%20Asterinas%20Security%20Assessment%20by%20CertiK.pdf">
report</a> available from CertiK on how Asterinas was audited and the
issues that were found.


</p><h4>Libraries and tools</h4>

<p>
The Asterinas kernel is only one result of the project. The other two are
<a href="https://crates.io/crates/ostd">OSTD</a>, described as "<q>a Rust
OS framework that facilitates the development of and innovation in OS
kernels written in Rust</q>", and <a href="https://asterinas.github.io/book/osdk/guide/index.html">OSDK</a>, a
Cargo addon to assist with the development, building, and testing of
kernels based on OSTD.


</p><p>
There are four stated goals for OSTD as a separate crate. One is to lower
the entry bar for operating-system innovation and to lay the groundwork for
newcomers to operating-system development. The second is to enhance memory
safety for operating systems written in Rust; other projects can benefit
from its encapsulation and abstraction of low-level operations. The third is
to promote code reuse across Rust-based operating-system projects. The
fourth is to boost productivity by enabling testing of new code in user
mode, allowing developers to iterate without having to reboot.


</p><p>
It is worth emphasizing that the kernels that can be written with OSTD do
not have to be Linux-compatible or, in any way, Unix-like. The APIs
provided are more generic than that; they are memory-safe abstractions for
functionality like x86 hardware management, booting, virtual memory, SMP,
tasks, users, and timers.  Like most Rust crates, OSTD is <a href="https://docs.rs/ostd/0.14.1/ostd/index.html">documented on
docs.rs</a>.


</p><p>
Asterinas reports Intel, among others, as a sponsor of the project.
Intel's interest is likely related to its <a href="https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html">Trust
Domain Extensions (TDX)</a> feature, which provides hardware modes and
features to facilitate isolation of virtual machines, and memory
encryption.  The Asterinas book has a brief <a href="https://asterinas.github.io/book/osdk/guide/intel-tdx.html">section
on TDX</a>, and the OSDK supports it.


</p><p>
The OSTD, or at least the parts that Asterinas ends up using, seems to
essentially be the restricted TCB that allows <tt>unsafe</tt>. For an
illustrative example, we could take a look at the <tt>network</tt> kernel
component's <a href="https://github.com/asterinas/asterinas/blob/ecb33ca98d2b2ac680daf1d2a48e4d011db2fbcf/kernel/comps/network/src/buffer.rs">source
code</a> and see that the buffer code uses DMA, locking, allocation, and
virtual-memory code from the OSTD through memory-safe APIs.


</p><h4>Current state</h4>
<p>
Asterinas was first released under the Mozilla Public License in early
2024; it has undergone rapid development over the past year.  GitHub <a href="https://github.com/asterinas/asterinas/graphs/contributors">lists 45
individual committers</a>, but the majority of the commits are from a
handful of PhD students from SUSTech, Peking University, and Fudan
University, as well as a Chinese company called <a href="https://www.antgroup.com/en">Ant Group</a>, which is a sponsor of
Asterinas.

</p><p>
At the time of writing, Asterinas supports two architectures, x86 and RISC-V.
In the January blog post linked above, it was reported that Asterinas
supported 180 Linux system calls, but the number has since grown to <a href="https://github.com/asterinas/asterinas/blob/1fe0fef41003c824b780b7b228f7b01a46497be0/kernel/src/syscall/arch/x86.rs">206
on x86</a>.  As of version 6.7, Linux has 368 system calls in total, so there is
some way to go yet.


</p><p>
Overall, Asterinas is in early development. There have been no releases,
release announcements, changelogs, or much of anything other than Git tags
and a short installation guide in the documentation.  The <a href="https://crates.io/crates/ostd/reverse_dependencies">Dependents
tab</a> of the OSTD crate on crates.io shows that no unrelated, published
crate yet uses OSTD.


</p><p>
It does not seem like Asterinas is able to run any applications yet.  <a href="https://github.com/asterinas/asterinas/issues/1868">Issue #1868</a>
in Asterinas's repository outlines preliminary plans toward a first
distribution.  The initial focus on a custom initramfs and some rudimentary
user-space applications, followed by being able to <a href="https://github.com/asterinas/asterinas/issues/1851">run
Docker</a>. There are initial plans to bootstrap a distribution based on
Nix. Notably (but unsurprisingly), this issue mentions that Asterinas
doesn't support loading Linux kernel modules, nor does it ever
plan to.


</p><h4>Near-future goals</h4>

<p>
The <a href="https://asterinas.github.io/book/kernel/roadmap.html">Roadmap</a>
section of the Asterinas book says that the near-term goals are to expand
the support for CPU architectures and hardware, as well as to focus on
real-world usability in the cloud by providing a host OS for virtual
machines.  Apparently, the support for Linux virtio devices is already
there, so a major hurdle has already been cleared.  In particular, the
Chinese cloud market, in the form of Aliyun (also known as Alibaba Cloud)
<a href="https://github.com/asterinas/asterinas/issues/1501">is a
focus</a>.  The primary plans involve creating a container host OS with a
tight, formally verified TCB and support for some trusted-computing
features in Intel hardware, for the Chinese cloud service.


</p><p>
While both Rust for Linux and Asterinas have similar goals (providing a
safer kernel by relying on Rust's memory safety), their scopes and
approaches are different.  Rust for Linux focuses on safe abstractions
strictly for new device drivers to be written in safe Rust, but this leaves
the rest of the kernel untouched.
Asterinas, on the other hand, aims to build a whole new kernel from the ground
up, restricting the <tt>unsafe</tt>-permitting core to the absolute minimum,
which can then be formally verified.  Asterinas also focuses on
containers and cloud computing, at least for now, while Rust for Linux looks to
benefit the whole of the Linux ecosystem.


</p><p>
Despite the stated cloud focus, there is more going on, for example building
support for <a href="https://github.com/asterinas/asterinas/issues/2008">X11</a>
and <a href="https://github.com/asterinas/asterinas/issues/2112">Xfce</a>.
Also, the OSTD could, of course, prove interesting for OS development
enthusiasts irrespective of the Asterinas project, but so far it remains unknown
and untested by a wider audience.

</p><p>
Asterinas is certainly a refreshingly innovative take on principles for
operating-system development, leaning on the safety and soundness
foundations provided by the Rust language and compiler. So far it is at an
early exploratory stage driven by enthusiastic Chinese researchers and
doesn't see any serious practical use, but it is worth keeping an eye
on. It will be interesting to see the reception it will get from the
Rust for Linux team and the Linux community at large.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Koistinen_Ronja">Koistinen, Ronja</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FedFlix — Public Domain Stock Footage Library (123 pts)]]></title>
            <link>https://public.resource.org/ntis.gov/index.html</link>
            <guid>44323914</guid>
            <pubDate>Fri, 20 Jun 2025 01:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public.resource.org/ntis.gov/index.html">https://public.resource.org/ntis.gov/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323914">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<h4>FedFlix—Public Domain Stock Footage Library &amp; Government Theater</h4>
			 
			<div id="theagree">
			<!-- this is invisible at first -->
				
				<h3>JOINT VENTURE</h3> <h5>BETWEEN</h5> <h3><a href="https://www.ntis.gov/">THE NATIONAL TECHNICAL INFORMATION SERVICE</a></h3> <h5>AND</h5> <h3><a href="https://public.resource.org/">PUBLIC.RESOURCE.ORG, INC.</a></h3> <h5>Agreement No. NTIS-1832.</h5> 
<h5>Renewed and Amended <a href="https://law.resource.org/pub/us/case/govdocs/gov.ntis_20090428_from.pdf">April 28, 2009.</a></h5>
				<p>
					Pursuant to Section <a href="https://www.law.cornell.edu/uscode/text/15/3704b">3704b(a)(1)A</a> of Title 15 of the United States Code, the National Technical Information Service (NTIS), a bureau within the Department of Commerce that operates on a self-sustaining basis without annual appropriations, and Public.Resource.Org, Inc. (PRO), a company incorporated under the laws of the State of California, hereby agree to enter into a joint venture to promote public access to multimedia products in the NTIS collection. The joint venture is based on an unsolicited proposal by PRO. 
				</p><ol>
					<li>
						Each month NTIS will select between ten and twenty non-copyrighted videotapes from available stock in its collection and ship them to PRO at its own expense. 
					</li>
					<li>
						Immediately upon receipt, PRO will, at its own expense, digitize the videotape and return the videotape and a copy in digital video disk (DVD) format to NTIS. The videotape and the DVD copy are both considered to be property of the United States Government. PRO will normally return the videotape and DVD within 15 days of receipt. A monthly submission to PRO will normally not occur until the DVDs sent the previous month have been returned to NTIS. 
					</li>
					<li>
						PRO will reimburse NTIS for the retail value of any videotape not returned to NTIS as provided in section 2. 
					</li>
					<li>
						Each party is free to make the content of the videotape available to the public through a web site or other means in any format and at any price, or for free, and to retain 100% of the revenue from any sales of the content. 
					</li>
					<li>
						PRO will assert no intellectual property claim to the content provided by NTIS or the resulting DVD in any manner whatsoever. 
					</li>
					<li>
						Nothing in this joint venture purports to be an exclusive arrangement. NTIS may provide content in its videotape collection, including content digitized by PRO under this agreement, to any other business partner. 
					</li>
					<li>
						Unless renewed earlier, this joint venture will terminate one year from the date of execution, except that either party may terminate it with 60 days written notice to the other. If NTIS terminates, PRO may either return any videotapes it has not yet digitized at NTIS' expense or it may treat those videotapes as subject to section 4. If PRO terminates, it may either return any videotapes not yet digitized at its own expense or it may treat those videotapes as subject to section 4. 
					</li>
					<li>
						Neither party may assign its rights under this Agreement to a third party without the written consent of the other party. 
					</li>
					<li>
						This agreement will be construed in accordance with applicable Federal law as construed by the United States Court of Federal Claims. 
					</li>
					<li>
						Nothing in this agreement shall be construed as creating a partnership and neither party shall have the power to bind the other in any respect. 
					</li>
				</ol>
				<table>
					<tbody><tr>
						<td><br>
							<strong>Carl Malamud, President</strong>
							<br>
							Public.Resource.Org, Inc. 
							<br>
							1005 Gravenstein Hwy North 
							<br>
							Sebastopol CA 95472 
						</td>
						<td><br>
							<strong>Donald Hagen</strong>
							<br>
							Associate Director 
							<br>
							Product and Program Management 
							<br>
							NTIS 
						</td>
					</tr>
					<tr>
						<td>
							Date: 11/2/2007 
						</td>
						<td>
							Date: 11/2/2007 
						</td>
					</tr>
				</tbody></table>
			</div>

<!-- FOOTER AREA -->
		
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source can't coordinate (148 pts)]]></title>
            <link>https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</link>
            <guid>44323904</guid>
            <pubDate>Fri, 20 Jun 2025 01:06:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html">https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article>
        <h2>
          Open Source Can’t Coordinate <time datetime="2025-05-20">May 20, 2025</time>
        </h2>
        <p>
          I was taking a shower this morning, and was pondering <a href="https://matklad.github.io/2025/05/19/profiling-challenge-results.html">yesterday’s problem</a>, where I <em>suspect</em>
          that I have an outdated version of <a href="https://github.com/KDAB/hotspot">hotspot</a> Linux profiler, but I can’t just go and download a fresh
          release from GitHub, because hotspot is a KDE app, and I use NixOS.
          And NixOS isn’t a problem — it’s a solution.
        </p>
        <p>
          Linux on desktop is a rickety tower of competing libraries, protocols
          and standards, which is always in an Escheresque sort of perpetual
          motion, taking off but simultaneously falling, and the best way to
          enjoy it is to take a photo, a frozen snapshot in time.
        </p>
        <p>
          The underlying force there is the absence of one unified baseline set
          of APIs for writing desktop programs. There’s no single entity that
          can coordinate the API, in contrast to Windows and MacOS.
        </p>
        <p>
          But then, how can Linux exist? How does that square with “never break
          the user space?” I’ll let you ponder the question, but let me first
          tell you a story from a domain where I consider myself an expert.
        </p>
        <section id="Better-LSP-Than-Never">
          <h2>
            <a href="#Better-LSP-Than-Never">Better LSP Than Never </a>
          </h2>
          <p>
            The past ten years saw a big shift in how we are writing software:
            baseline level of “interactive static analysis” became the norm, go
            to definition is universally available. The surprising fact here is
            that the shift occurred a decade too late!
          </p>
          <p>
            The shift was caused by Microsoft releasing its Language Server
            Protocol specification. But there’s little value in the protocol
            itself. Its implementation is
            <a href="https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html">mediocre</a>, it was strictly worse than <a href="https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/8e6a02d899ef62ef5b8405518b36340e609198e2/pkg/analysis_server/doc/api.html">the state of the art at that time</a>, and its
            <a href="https://github.com/microsoft/language-server-protocol/pull/2027#issuecomment-2822857896">governance is abysmal</a>. The only great thing about LSP is that
            it exists!
          </p>
          <p>
            If you were anywhere near JetBrains a decade ago, it was blindingly
            obvious that the absence of broad availability of basic IDE features
            leaves a lot of the value on the table, and that the multi-process
            IPC architecture is the way to go (JetBrains did IPC for Rider). But
            it is also clear why JetBrains didn’t do LSP — why would they? While
            the right solution on the technical grounds, you aren’t going to get
            paid for being technically right. As sad as it is, some amount of
            <a href="https://en.wikipedia.org/wiki/Deadweight_loss">deadweight loss</a> is needed to capture some of the value you are
            producing, and you need to be able to capture value to invest in
            things! So the world had to wait for Microsoft to pick up the slack
            here, when they decided to gobble up the entire developer ecosystem
            as an investment.
          </p>
          <p>
            There was a decade of opportunity for OSS to coordinate around an
            IDE protocol, but that didn’t happen, because OSS is bad at
            coordination.
          </p>
        </section>
        <section id="Why-Linux">
          <h2>
            <a href="#Why-Linux">Why Linux? </a>
          </h2>
          <p>
            But then, why and how does Linux exist? I think part of that is a
            rather unique governance structure, where there’s a centralized
            control over the API area and strong commitment to the public
            interfaces. But the bigger part is POSIX. The reason why we have
            Linux, and BSDs, and XNU is that they all provide the same baseline
            API, which was defined from the outside. The coordination problem
            was pre-solved, and what remained is just filling-in the
            implementation. But there was no one to coordinate Linux on desktop.
          </p>
        </section>
      </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Mac OS X (242 pts)]]></title>
            <link>https://blog.persistent.info/2025/03/infinite-mac-os-x.html</link>
            <guid>44323719</guid>
            <pubDate>Fri, 20 Jun 2025 00:16:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.persistent.info/2025/03/infinite-mac-os-x.html">https://blog.persistent.info/2025/03/infinite-mac-os-x.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323719">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p><strong>tl;dr:</strong> Infinite Mac can now <a href="https://infinitemac.org/?filter=macosx">run early Mac OS X</a>, with <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1">10.1</a> and <a href="https://infinitemac.org/2003/Mac%20OS%20X%2010.3">10.3</a> being the best supported versions. It’s not particularly snappy, but as someone who lived through that period, I can tell you that it wasn’t much better on real hardware. Infinite HD has also been rebuilt to have some notable indie software from that era.</p>

<p>
  <img alt="Mac OS X 10.1 running NetNewsWire Lite and Terminal" height="928" src="https://persistent.info/images/infinite-mac-mac-os-x-10.1.webp" width="1184">
</p>

<h3>Porting PearPC</h3>

<p>I’ve been <a href="https://github.com/search?q=repo%3Amihaip%2Finfinite-mac+219&amp;type=commits&amp;s=committer-date&amp;o=desc">tracking</a> DingusPPC progress since my initial <a href="https://blog.persistent.info/2023/12/dingusppc.html">port</a> and making the occasional contribution <a href="https://github.com/dingusdev/dingusppc/commits?author=mihaip">myself</a>, with the hope of using it to run Mac OS X in Infinite Mac. While it has continued to improve, I reached a plateau last summer; my attempts would result in either kernel panics or graphical corruption. I tried to reduce the problem a bit via a <a href="https://github.com/dingusdev/dingusppc/pull/120">deterministic execution mode</a>, but it wasn’t really clear where to go next. I decided to take a break from this emulator and explore alternate paths of getting Mac OS X to run.</p>

<p><a href="https://github.com/sebastianbiallas/pearpc">PearPC</a> was the obvious choice – it was created with the express purpose of emulating Mac OS X on x86 Windows and Linux machines in the early 2000s. By <a href="https://www.osnews.com/story/7085/pearpc-01-is-it-a-miracle/">all accounts</a>, it did this successfully for a few years, until interest waned after the Intel switch. I had earlier <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=I%20also%20briefly%20considered%20PearPC%20(which%20is%20much%20more%20focused%20on%20early%20PowerMacs%20than%20QEMU)%2C%20but%20it%E2%80%99s%20also%20in%20a%20state%20of%20abandonment%20(development%20mostly%20stopped%20in%202005%2C%20with%20a%20brief%20resurrection%20in%202015).">dismissed it</a> as a “dead” codebase, but I decided that the satisfaction of getting something working compensated for dealing with legacy C++ (complete with its own <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/str.h">string class</a>, <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/snprintf.cc">sprintf implementation</a>, and <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/system/gif.cc">GIF decoder</a>). An encouraging discovery was that <a href="https://github.com/kanjitalk755">kanjitalk755</a> (the de-facto Basilisk II and SheepShaver maintainer) had somewhat recently set up <a href="https://github.com/sebastianbiallas/pearpc/compare/master...kanjitalk755:pearpc:macos_sdl2">an experimental branch</a> of PearPC that built and ran on modern macOS. I was able to replicate their work without too much trouble, and with that existence proof I started on my sixth port of an emulator to WebAssembly/Emscripten and the Infinite Mac runtime.</p>

<p>In some ways PearPC not being actively developed made things easier –&nbsp;I didn’t have to worry about merging in changes from upstream, or agonize over how to structure my modifications to make them easier to contribute back. It was also helpful that PearPC was already a multi-platform codebase and thus had the right layers of abstraction to make adding another target pretty easy. As a bonus, it didn’t make pervasive use of threads or other harder-to-port concepts. Over the course of a few days, I was able to <a href="https://github.com/mihaip/pearpc/commit/a63c1145964843c09e4d21fc55c182ccb53e82ce">get it to build</a>, <a href="https://github.com/mihaip/pearpc/commit/b13f6813321af579895122a71aa09ba2cb793717">output video</a>, <a href="https://github.com/mihaip/pearpc/commit/dde5322f13a2ca64727cd94a98795f5c1f20f6b0">load disk images</a>, and <a href="https://github.com/mihaip/pearpc/commit/526ba08845122e991268c5d995167efbd083ac8e">get mouse and keyboard input</a> hooked up. It was pretty satisfying to have Mac OS X 10.2 running in a browser more reliably than it previously had.</p>

<h3>Performance</h3>

<p>While PearPC ran 10.2 more reliably, it felt slower than DingusPCC. I had spent some time last year making <a href="https://github.com/dingusdev/dingusppc/commit/564c43c907917f498d7090c6f108ead03f6b123d">some</a> <a href="https://github.com/dingusdev/dingusppc/commit/b759f25d87a21b95ea0384fa9a83644591bb6305">optimizations</a> to the latter, partly inspired by the <a href="https://github.com/kwhr0/macemu/blob/master/SheepShaver/src/TinyPPC.cpp">TinyPPC emulator</a> in <a href="http://kwhr0.g2.xrea.com/macemu.html">this SheepShaver fork</a> (aren’t all these names fun?). I <a href="https://github.com/mihaip/pearpc/commit/0856ed0acb9674420fb6c858e684a02033b3cdc3">ported</a> DingusPPC’s benchmark harness and then <a href="https://github.com/mihaip/pearpc/commit/75dbcfb9f5e28735792bff085d58cb206631564b">set</a> <a href="https://github.com/mihaip/pearpc/commit/71059084de0169b760f4c908d52961d2e69399a1">about</a> <a href="https://github.com/mihaip/pearpc/commit/c87caace8a5479caf160a6a0a8d9183de5165132">replicating</a> <a href="https://github.com/mihaip/pearpc/commit/4ac34d860b0b58d6ff3cefa630d98f5681443b5b">the</a> <a href="https://github.com/mihaip/pearpc/commit/3e979205950b9d540577204d8e86a494f53157a2">performance</a> <a href="https://github.com/mihaip/pearpc/commit/14d050101f1ada51c49197e494211f7e9e15e847">work</a> <a href="https://github.com/mihaip/pearpc/commit/c3b29968fde9c5d860ba9fdfcf5c5a3b3537760b">in</a> <a href="https://github.com/mihaip/pearpc/commit/6cad14c927b12ec832709d15d9663ba1b2b0dd78">PearPC</a> (both emulators are pure interpreters driven by a lookup table, so the process was relatively straightforward). I was able to shave off about 15 seconds from the 10.2 boot time – it helps from a <a href="https://folklore.org/Saving_Lives.html">saving lives perspective</a>, but is still not enough given that it takes almost 2 minutes to be fully operational. In the end, I copped out and <a href="https://github.com/mihaip/infinite-mac/commit/280a527ef0b682dc142bd14ec61cbe37978a39f7">added a UI disclaimer</a> that Mac OS X can be slow to boot. I also got flashbacks to the <a href="https://arstechnica.com/gadgets/2001/04/macos-x/#page-6:~:text=will%20Mac%20OS%20X%20have%20a%20snappy%20UI">“is it snappy yet?”</a> discussions from the early days of Mac OS X –&nbsp;it was indeed slow, but not this slow.</p>

<p>Performance is still not as good as DingusPPC’s – the biggest bottleneck is the lack of any kind of caching in the MMU, so all loads and stores are expensive since they involve complex address computations. DingusPPC has a much more mature <a href="https://github.com/dingusdev/dingusppc/blob/master/zdocs/developers/cpu/powerpc/mmuemu.md">tiered cache</a> that appears to be quite effective. More generally, while PearPC may be more stable than DingusPPC at running 10.2-10.4, it’s a much less principled codebase (I came across <a href="https://github.com/sebastianbiallas/pearpc/commit/152604c0af3f0613bae37cf4287f188a42be0c06">many mystery commits</a>) and it “cheats” in many ways (it has a <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/io/prom/promboot.cc#L977">custom</a> firmware and <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/ppccfg.example#L75-L78">video driver</a>, and only the <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/cpu/cpu_generic/ppc_alu.cc#L116-L117">subset</a> of PowerPC instructions that are needed for Mac OS X are implemented). I’m still holding out hope for DingusPPC to be the fast, stable, and correct choice for the long term.</p>

<h3>A Side Quest</h3>

<p>I implemented the “unified decoding table” approach in PearPC’s interpreter one opcode family at a time. When I got to the floating point operations, I assumed it was going to be another mechanical change. I was instead surprised to see that behavior regressed – I got some rendering glitches in the Dock, and the Finder windows would not open at all. After some debugging, I noticed that the <a href="https://github.com/mihaip/pearpc/blob/3e979205950b9d540577204d8e86a494f53157a2/src/cpu/cpu_generic/ppc_dec.cc#L106-L172">dispatching for opcode groups 59 and 63</a> didn’t just do a basic lookup on the relevant instruction bits. It first checked the <code>FP</code> bit of the <a href="https://en.wikipedia.org/wiki/Machine_state_register">Machine State Register (MSR)</a>, and if it was not set it would throw a “floating point unavailable” exception.</p>

<p>I initially thought this was the emulator being pedantic – all PowerPC chips used in Macs had an FPU, so this should never happen. However, setting a breakpoint showed that the exception was being hit pretty frequently during Mac OS X startup. The <a href="https://github.com/apple-oss-distributions/xnu/tree/xnu-124.7">xnu kernel sources</a> of that time period are available, and though I’m not familiar with the details, there are places where the FP bit <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L201">is</a> <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L1012">cleared</a> and a <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L656-L707">handler for the resulting exception</a> is registered. I assume this is an optimization to avoid having to save/restore FPU registers during context switches (if they’re not being used). The upshot was that once I implemented the equivalent <code>FP</code> check in my optimized dispatch code, the rendering problems went away.</p>

<p>This reminded me of the rendering glitches that I had encountered when trying to run Mac OS X under DingusPPC. Even when booting from the 10.2 install CD (which does not kernel panic) I would end up with missing text and other issues:</p>

<p>
  <img alt="Mac OS X 10.2 installer showing text rendering glitches" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-broken.webp" width="832">
</p>

<p>Checking the DingusPPC sources showed that it never checked the <code>FP</code> bit, and always allowed floating point instructions to go through. I did a quick hack to check it and raise an exception if needed, and the glitches went away!</p>

<p>
  <img alt="Mac OS X 10.2 installer correctly rendering text" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-fixed.webp" width="832">
</p>

<p>The <a href="https://github.com/dingusdev/dingusppc/pull/135">proper implementation</a> was a bit more complicated, and I ended up <a href="https://github.com/dingusdev/dingusppc/pull/136">revising it a bit</a> to avoid a performance hit (and another contributor did <a href="https://github.com/dingusdev/dingusppc/commit/82a48899f0c28a9418a07b56b5d39f7e161b1549">another pass</a>). But at the end of it all, DingusPPC became a lot more stable, which was a nice side effect. Better yet, it can run 10.1 reliably, which PearPC cannot. I ended up using a combination of both emulators to run a broader subset of early Mac OS X (unfortunately 10.0 is still unstable, and the Public Beta kernel panics immediately, but I’m holding out hope for the future).</p>

<h3>Rebuilding Infinite HD</h3>

<p>Part of the appeal of Infinite Mac is that the emulated machines also have an “Infinite HD” mounted with a lot of era-appropriate software to try. With Mac OS X running, it was time to build an alternate version that went beyond the 80s and 90s classic Mac apps I had collected. I had my favorites, but I also <a href="https://hachyderm.io/@mihaip/113977444999284253">put out a call for suggestions</a> and got plenty of ideas.</p>

<p>For actually building the disk image, I extended the <a href="https://blog.persistent.info/2022/03/blog-post.html#:~:text=Building%20Disk%20Images%2C%20or%20Docker%201995%2Dstyle">automated approach</a> that I first launched the site with. Disk images were even more popular in the early days of Mac OS X than they are today, so I <a href="https://github.com/mihaip/infinite-mac/commit/a7f69373a7b2eb1d85ea33e975180b4a2ca02a44">added a way</a> to import .dmgs as additional folders in the generated image. However, I quickly discovered that despite having the same extension, there are <a href="https://github.com/libyal/libmodi/blob/main/documentation/Mac%20OS%20disk%20image%20types.asciidoc#1-overview">many variants</a>, and the <code>hdiutil</code> that ships with modern macOS cannot always mount images generated more than 20 years ago. In the end I ended up with a <a href="https://github.com/mihaip/infinite-mac/commit/119000a268bb3f21180e06ea899331b2307b695e">Rube Goldberg approach</a> that first extracts the raw partition via <a href="https://github.com/Lekensteyn/dmg2img">dmg2img</a> and then recreates a “modern” disk image that can be mounted and copied from.</p>

<p>As for getting the actual software, the usual sites like <a href="https://macintoshgarden.org/">Macintosh Garden</a> do have some from that era, but it’s not a priority for them. Early to mid 2000s Mac OS X software appears to be a bit of a blind spot –&nbsp;it’s too new to be truly “retro”, but too old to still be available from the original vendor (<a href="https://rogueamoeba.com/legacy/">though</a> <a href="https://files.omnigroup.com/software/MacOSX/">there</a> <a href="https://download-cdn.panic.com/">are</a> <a href="https://c-command.com/dropdmg/support#older-versions">exceptions</a>). I ended up using the <a href="https://web.archive.org/">Wayback Machine</a> a lot. As a bonus, I also installed the companion “Developer” CDs for each Mac OS X version, so tools like Project Builder and Interface Builder are also accessible.</p>

<p>
  <img alt="Mac OS X 10.4 running Delicious Library, CandyBar, PCalc and Pixelmator" height="768" src="https://persistent.info/images/infinite-mac-mac-os-x-hd.webp" width="1024">
</p>

<p>The only limitation that I ran into is that my disk build process is centered around HFS, but HFS+ was the default of that time period, and it introduced more advanced capabilities like longer file names containing arbitrary Unicode characters. Files from disk images that rely HFS+ features do not translate losslessly, but luckily this was not an issue for most software. To actually mount multiple drives (up to 3, between the boot disk, Infinite HD, and <a href="https://blog.persistent.info/2023/09/infinite-mac-improved-persistence.html">Saved HD</a>), I <a href="https://github.com/mihaip/dingusppc/commit/51019e4fa0109fa8268cd547b92dee0e7065ac5c">ended</a> <a href="https://github.com/mihaip/pearpc/commit/93f224a8a9676479ff79aad9bf7632d400a5c693">up</a> <a href="https://github.com/mihaip/dingusppc/commit/b220d7b9ed39953780d2a42f9f83caaf8a6cf06e">borrowing</a> a clever solution from a <a href="https://github.com/joevt/dingusppc/">DingusPPC fork</a>: a multi-partition disk image is created on the fly from an arbitrary number of partition images that are specified at startup.</p>

<h3>Aqua</h3>

<p>To make the addition of Mac OS X to Infinite Mac complete, I also wanted to have an Aqua mode for the site’s controls, joining the <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=To%20reduce%20the%20cognitive%20dissonance%20(and%20to%20have%20a%20bit%20of%20fun)%2C%20I%20made%20the%20UI%20resemble%20the%20look%2Dand%2Dfeel%20of%20the%20OS%20that%20is%20being%20booted">classic, Platinum</a>, and <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=With%20the%20initial%20emulator%20being%20brought%20up%2C%20there%20were%20some%20more%20fun%20tasks%2C%20like%20adding%20a%20NeXT%2Dstyle%20monitor%20frame%20and%20a%20NeXT%20appearance%20to%20the%20Infinite%20Mac%20controls%20(working%20on%20them%20is%20giving%20me%20Kaleidoscope%20scheme%20flashbacks).">NeXT</a> appearances. That prompted the question: <a href="https://512pixels.net/projects/aqua-screenshot-library/">which Aqua</a>?</p>

<p>
  <img alt="Screenshots of the logout dialog in Mac OS X 10.1 to 10.4" height="369" src="https://persistent.info/images/infinite-mac-mac-os-x-aqua.webp" width="901"><br>
  <i>Aqua: the early years</i>
</p>

<p>Though the more subdued versions from 10.3 and 10.4 are my favorites, I decided to go with the 10.0/10.1 one since it has the biggest nostalgia factor. I wanted to use the exact same image assets as the OS, and since they make heavy use of semi-transparency, regular screenshots were not going to be good enough. I used <a href="https://github.com/fuzziqersoftware/resource_dasm">resource_dasm</a> and <a href="https://kwasi-ich.de/software/aqua/">pxm2tga</a> to extract the original assets from <a href="http://www.atpm.com/11.06/customizing.shtml">Extras.rsrc</a> and create <a href="https://github.com/mihaip/infinite-mac/commit/cbc6a3ea8ac0523fbea27dbd57770837c60465db">my own version of Aqua</a>:</p>

<p>
  <img alt="Infinite Mac custom instance configuration dialog, rendered with an Aqua appearance" height="708" src="https://persistent.info/images/infinite-mac-mac-os-x-custom.webp" width="661">
</p>

<p>If the recent rumors of a <a href="https://www.bloomberg.com/news/articles/2025-03-10/apple-readies-dramatic-design-overhauls-for-ios-19-ipados-19-and-macos-16">big UI revamp</a> do come true, it’ll be nice to have this reference point of its ancestor.</p>

<h3>Odds and Ends</h3>

<p>The ability to mount multiple images means that you can also have a Mac OS 9 partition and start the Classic compatibility environment (this only works under 10.1 – PearPC never supported Classic). You can thus emulate classic Mac apps inside an emulated Mac OS X inside a WebAssembly virtual machine:</p>

<p>
  <img alt="Mac OS X 10.1 running Stickies, Scrapbook and Calculator under Classic" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-classic.webp" width="832">
</p>

<p>There was a recent storm in a teacup about <a href="https://mjtsai.com/blog/2025/01/30/repeating-calculator-operations/">a Calculator behavior change</a>. Using these Mac OS X images, it’s possible to verify that versions through 10.3 didn’t have the “repeatedly press equals” behavior, but 10.4 did.</p>

<p>Since Mac OS X boot is rather slow, I wanted to have a way to show more progress. PearPC has <a href="https://github.com/mihaip/infinite-mac/blob/cb6b16c3ace1b36c9228d991397176c0036bc960/src/Data/PearPCConfig.txt#L56-L61">a built-in way</a> to trigger verbose mode, but DingusPPC did not, so I added a way to <a href="https://github.com/dingusdev/dingusppc/commit/a6e1b8c338b4b93fcafe97605dc8b493c61fb2a3">specify Open Firmware variables at startup</a>. This is now exposed in the <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1?edit">custom instance dialog</a> via the “Debug Mode” switch.</p>

<p>Though I’ve moved away from custom domain names, I thought <a href="https://macosx.app/">macosx.app</a> would make a nice <a href="https://system6.app/">addition</a> <a href="https://system7.app/">to</a> <a href="https://macos8.app/">my</a> <a href="https://macos9.app/">collection</a>. Unfortunately it’s taken, though in a rather weird way. I even contacted the YouTuber whose video it redirects to, and he said he was not the one that registered it. It expires in a couple of months, so maybe I’ll be able to grab it.</p>

<h3>The End Of The Line?</h3>

<blockquote>“When Alexander saw the breadth of his domain, he wept for there were no more worlds to conquer.”<br>
— <s>Hans Gruber</s> <s>Plutarch</s> <a href="https://www.theparisreview.org/blog/2020/03/19/and-alexander-wept/">Some Frenchman</a></blockquote>

<p>Mac OS X support catches Infinite Mac up to the modern day, unless I happen to get access to some <a href="https://web.archive.org/web/20171006210639/https://twitter.com/mcclure111/status/916405883202129921">time travel mechanics</a>. There are of course two more CPU transitions to go through and numerous small changes, but Tiger is fundamentally recognizable to any current-day macOS user.</p>
<p>Except that in the retrocomputing world, it’s always possible to go deeper or more obscure. <a href="https://en.wikipedia.org/wiki/A/UX">A/UX</a> is not something that I’m very familiar with, but it was a contemporary of classic Mac OS and would be interesting to compare to NeXTStep. <a href="https://github.com/pruten/shoebill">Shoebill</a> runs it, and the codebase looks approachable enough to port. Then there’s <a href="https://github.com/mihaip/infinite-mac/issues/167">Lisa</a>, the <a href="https://en.wikipedia.org/wiki/Apple_Pippin">Pippin</a> (DingusPPC has some <a href="https://github.com/dingusdev/dingusppc/blob/master/machines/machinepippin.cpp">nascent support</a>), and further afield the Newton (via <a href="https://github.com/pguyot/Einstein">Einstein</a>?). We’ll see what moves me next.</p>

<h3>A Post-Credits Sequence</h3>

<p>When I first began exploring ways of running Mac OS X, I mentioned that <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=The%20obvious%20choice%20was%20QEMU%20%E2%80%93%20it%20has%20very%20broad%20guest%20OS%20support%20and%20is%20very%20actively%20developed.%20However%2C%20it%E2%80%99s%20also%20a%20beast%20of%20a%20project%20to%20build%20and%20navigate%20around%3B%20it%20didn%E2%80%99t%20seem%20like%20it%20would%20be%20something%20I%20would%20able%20to%20make%20much%20progress%20on%20while%20working%20on%20it%20for%20a%20few%20hours%20a%20week.">QEMU seemed too daunting to port</a> to WebAssembly given my limited time. Furthermore, the performance of the <a href="https://github.com/atrosinenko/qemujs">qemu.js</a> experiment from a few years ago made it seem like even if it did run, it would be much too slow to be usable. However, I recently became aware of <a href="https://github.com/ktock/qemu-wasm">qemu-wasm</a> via <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-6290-running-qemu-inside-browser/">this FOSDEM presentation</a>. The performance of its Linux guest <a href="https://ktock.github.io/qemu-wasm-demo/">demos</a> is encouraging: I ran an impromptu bennmark of computing an MD5 checksum of 100 MB of data and it completed it in 8 seconds (vs. 13 for DingusPPC and 18 for PearPC). There’s still a big gap between that and a graphical guest like Mac OS X, but it’s nice to have this existence proof.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Giant, All-Seeing Telescope Is Set to Revolutionize Astronomy (131 pts)]]></title>
            <link>https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy</link>
            <guid>44323389</guid>
            <pubDate>Thu, 19 Jun 2025 23:17:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy">https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy</a>, See on <a href="https://news.ycombinator.com/item?id=44323389">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a new BitTorrent tracker in Elixir (335 pts)]]></title>
            <link>https://github.com/Dahrkael/ExTracker</link>
            <guid>44323253</guid>
            <pubDate>Thu, 19 Jun 2025 22:49:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dahrkael/ExTracker">https://github.com/Dahrkael/ExTracker</a>, See on <a href="https://news.ycombinator.com/item?id=44323253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Dahrkael/ExTracker/blob/master/.github/extracker-logo.png"><img src="https://github.com/Dahrkael/ExTracker/raw/master/.github/extracker-logo.png" alt="ExTracker"></a>
The Bittorrent Tracker made in Elixir</p>
<p dir="auto"><a href="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml/badge.svg" alt="CI"></a></p>
<p dir="auto">👷‍♂️This project is a Work In Progress. While not ready for full industrial usage it does work.<br>
There is a testing instance running at <a href="http://extracker.dahrkael.net:6969/about" rel="nofollow">extracker.dahrkael.net:6969</a> with all current features enabled (<a href="http://extracker.dahrkael.net:9568/tracker-stats.html" rel="nofollow">Live statistics</a>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Implementation Legend:
🔲 Not Yet 🔰 Partially ✅ Done ❌ Won't do</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Important Features</h3><a id="user-content-important-features" aria-label="Permalink: Important Features" href="#important-features"></a></p>
<ul dir="auto">
<li>✅ High performance (uses ALL the available cores, in-memory storage)</li>
<li>✅ Low memory usage (~200MB of RAM for each 1.000.000 peers)</li>
<li>✅ Zero setup (launch it and it just works)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tracker-related BitTorrent Enhancement Proposals</h3><a id="user-content-tracker-related-bittorrent-enhancement-proposals" aria-label="Permalink: Tracker-related BitTorrent Enhancement Proposals" href="#tracker-related-bittorrent-enhancement-proposals"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Final and Active Process BEPs</h4><a id="user-content-final-and-active-process-beps" aria-label="Permalink: Final and Active Process BEPs" href="#final-and-active-process-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 0:</strong> <a href="https://www.bittorrent.org/beps/bep_0003.html" rel="nofollow">The BitTorrent Protocol Specification</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Accepted BEPs</h4><a id="user-content-accepted-beps" aria-label="Permalink: Accepted BEPs" href="#accepted-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 15:</strong> <a href="https://www.bittorrent.org/beps/bep_0015.html" rel="nofollow">UDP Tracker Protocol</a></li>
<li>✅ <strong>BEP 23:</strong> <a href="https://www.bittorrent.org/beps/bep_0023.html" rel="nofollow">Tracker Returns Compact Peer Lists</a></li>
<li>🔲 <strong>BEP 27:</strong> <a href="https://www.bittorrent.org/beps/bep_0027.html" rel="nofollow">Private Torrents</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Draft BEPs</h4><a id="user-content-draft-beps" aria-label="Permalink: Draft BEPs" href="#draft-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 7:</strong> <a href="https://www.bittorrent.org/beps/bep_0007.html" rel="nofollow">IPv6 Tracker Extension</a></li>
<li>🔲 <strong>BEP 21:</strong> <a href="https://www.bittorrent.org/beps/bep_0021.html" rel="nofollow">Extension for partial seeds</a></li>
<li>✅ <strong>BEP 24:</strong> <a href="https://www.bittorrent.org/beps/bep_0024.html" rel="nofollow">Tracker Returns External IP</a></li>
<li>🔲 <strong>BEP 31:</strong> <a href="https://www.bittorrent.org/beps/bep_0031.html" rel="nofollow">Tracker Failure Retry Extension</a></li>
<li>✅ <strong>BEP 41:</strong> <a href="https://www.bittorrent.org/beps/bep_0041.html" rel="nofollow">UDP Tracker Protocol Extensions</a></li>
<li>🔰 <strong>BEP 48:</strong> <a href="https://www.bittorrent.org/beps/bep_0048.html" rel="nofollow">Tracker Protocol Extension: Scrape</a></li>
<li>✅ <strong>BEP 52:</strong> <a href="https://www.bittorrent.org/beps/bep_0052.html" rel="nofollow">The BitTorrent Protocol Specification v2</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Deferred BEPs</h4><a id="user-content-deferred-beps" aria-label="Permalink: Deferred BEPs" href="#deferred-beps"></a></p>
<ul dir="auto">
<li>❌ <strong>BEP 8:</strong> <a href="https://www.bittorrent.org/beps/bep_0008.html" rel="nofollow">Tracker Peer Obfuscation</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other Features</h3><a id="user-content-other-features" aria-label="Permalink: Other Features" href="#other-features"></a></p>
<ul dir="auto">
<li>✅ HTTPS support</li>
<li>✅ Database backups to disk</li>
<li>❌ WebTorrent</li>
<li>🔰 Infohash whitelist/blacklist</li>
<li>🔰 Peer management (interval enforcement, cleanup, banning, etc)</li>
<li>🔰 Metrics</li>
<li>🔰 GeoIP support (statistics, peer restrictions)</li>
<li><strong>Feel free to propose features in the <a href="https://github.com/Dahrkael/ExTracker/issues">Issues</a></strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">There are 3 main ways of running ExTracker currently</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Straight from source code</h3><a id="user-content-straight-from-source-code" aria-label="Permalink: Straight from source code" href="#straight-from-source-code"></a></p>
<p dir="auto">For this method to work you need to have <strong>Erlang</strong> and <strong>Elixir</strong> installed on your system</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">config/runtime.exs</a> to fit your needs</li>
<li>run <code>MIX_ENV=prod iex -S mix</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Releases</h3><a id="user-content-from-releases" aria-label="Permalink: From Releases" href="#from-releases"></a></p>
<p dir="auto">Currently there are no official releases built (soon™️). You can however make your own and deploy it where needed:</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>run <code>MIX_ENV=prod mix release extracker</code> for Linux or <code>MIX_ENV=prod mix release extrackerw</code> for Windows</li>
<li>Find the release files inside the <em>_build/prod/rel/extracker</em> folder (if its a different machine make sure the OS and architecture is the same!)</li>
<li>Copy the folder to its final destination</li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">releases/{VERSION}/runtime.exs</a> to fit your needs</li>
<li>Run <code>bin/extracker start</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">For this method you can directly run the <a href="https://github.com/Dahrkael/ExTracker/pkgs/container/extracker/422008654?tag=latest">available docker image</a>: <code>docker run ghcr.io/dahrkael/extracker:latest</code><br>
or use it as part of docker-compose. Theres an <a href="https://github.com/Dahrkael/ExTracker/blob/master/docker-compose.yml">example compose file</a> available.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Since modifying the <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">runtime.exs</a> file to tune the configuration inside the container is not easy you can also configure it using <strong>Environment Variables</strong>, see the example compose file for the complete list.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Copyright and license</h2><a id="user-content-copyright-and-license" aria-label="Permalink: Copyright and license" href="#copyright-and-license"></a></p>
<p dir="auto">Copyright (c) Dahrkael &lt;dahrkael at outlook dot com&gt;<br>
Distributed under the terms of the Apache License, Version 2.0. Please refer to the <a href="https://github.com/Dahrkael/ExTracker/blob/master/LICENSE">LICENSE file</a> in the repository root directory for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Literate programming tool for any language (122 pts)]]></title>
            <link>https://github.com/zyedidia/Literate</link>
            <guid>44323045</guid>
            <pubDate>Thu, 19 Jun 2025 22:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zyedidia/Literate">https://github.com/zyedidia/Literate</a>, See on <a href="https://news.ycombinator.com/item?id=44323045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Literate</h2><a id="user-content-literate" aria-label="Permalink: Literate" href="#literate"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Literate programming?</h2><a id="user-content-what-is-literate-programming" aria-label="Permalink: What is Literate programming?" href="#what-is-literate-programming"></a></p>
<p dir="auto">Literate programming is a style of programming invented by Donald Knuth, where the main idea is that a program's source code is made primarily to be read and understood by other people, and secondarily to be executed by the computer.</p>
<p dir="auto">This frees the programmer from the structure of a program imposed by the computer and means that the programmer can develop programs in the order of the flow of their thoughts.</p>
<p dir="auto">A Literate program generally consists of explanation of the code in a natural language such as English, interspersed with snippets of code to be executed. This means that Literate programs are very easy to understand and share, as all the code is well explained.</p>
<hr>
<p dir="auto">Literate is a tool for creating literate programs.</p>
<p dir="auto">The goal of this project is to create a literate programming tool which keeps most, if not all of the features of Knuth and Levy's original CWEB system, but simplifies the system and adds even more features.</p>
<p dir="auto">You can view the main website about Literate <a href="https://zyedidia.github.io/literate" rel="nofollow">here</a> including a <a href="https://zyedidia.github.io/literate/manual.html" rel="nofollow">manual</a> on how to use Literate.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Supports any language including syntax highlighting and pretty printing in HTML</li>
<li>Markdown based -- very easy to read and write Literate source.</li>
<li>Reports syntax errors back from the compiler to the right line in the literate source</li>
<li>Generates readable and commented code in the target language (the generated code is usable by others)</li>
<li>Supports TeX equations with <code>$</code> notation.</li>
<li>Literate source code is readable whether you are looking at the <code>.lit</code> file, or the generated HTML.</li>
<li>Highly customizable (you can add your own HTML or CSS)</li>
<li>Runs fast -- wc.lit compiled for me in 7ms for both code and HTML output</li>
<li>Automatically generates hyperlinks between code sections</li>
<li>Formatted output similar to CWEB</li>
<li>Supported by <a href="https://github.com/zyedidia/micro">micro</a> (by default)</li>
<li>Compatible with Vim (<a href="https://github.com/zyedidia/literate.vim">literate.vim</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<p dir="auto">Here is a trivial example of a literate program saved in the file <code>hello.lit</code>.</p>
<p dir="auto">For a full example of a literate program, please see <a href="https://github.com/zyedidia/Literate/blob/master/examples/wc.lit"><code>examples/wc.lit</code></a> which
is a literate implementation of the <code>wc</code> (word count) program found on Unix systems.
You can find the compiled html <a href="https://zyedidia.github.io/literate/examples/wc.html" rel="nofollow">here</a>.</p>
<div data-snippet-clipboard-copy-content="@title Hello world in C

@s Introduction

This is an example hello world C program.
We can define codeblocks with `---`

--- hello.c
@{Includes}

int main() {
    @{Print a string}
    return 0;
}
---

Now we can define the `Includes` codeblock:

--- Includes
#include <stdio.h>
---

Finally, our program needs to print &quot;hello world&quot;

--- Print a string
printf(&quot;hello world\n&quot;);
---"><pre><code>@title Hello world in C

@s Introduction

This is an example hello world C program.
We can define codeblocks with `---`

--- hello.c
@{Includes}

int main() {
    @{Print a string}
    return 0;
}
---

Now we can define the `Includes` codeblock:

--- Includes
#include &lt;stdio.h&gt;
---

Finally, our program needs to print "hello world"

--- Print a string
printf("hello world\n");
---
</code></pre></div>
<p dir="auto">To compile this code simply run</p>
<p dir="auto"><code>$ lit hello.lit</code></p>
<p dir="auto">Which generates <a href="https://zyedidia.github.io/literate/examples/hello.c" rel="nofollow">hello.c</a> and <a href="https://zyedidia.github.io/literate/examples/hello.html" rel="nofollow">hello.html</a>.</p>
<p dir="auto">You can also find this program in <code>examples/hello.lit</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prebuilt binaries</h3><a id="user-content-prebuilt-binaries" aria-label="Permalink: Prebuilt binaries" href="#prebuilt-binaries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Download</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-osx.tar.gz" rel="nofollow">Mac OS X</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux64.tar.gz" rel="nofollow">64 bit Linux</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux32.tar.gz" rel="nofollow">32 bit Linux</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux-arm.tar.gz" rel="nofollow">Arm Linux</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from Source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mac</h4><a id="user-content-mac" aria-label="Permalink: Mac" href="#mac"></a></p>
<p dir="auto">On Mac you can use brew to build Literate from source:</p>
<div data-snippet-clipboard-copy-content="$ brew tap zyedidia/literate
$ brew install --HEAD literate"><pre><code>$ brew tap zyedidia/literate
$ brew install --HEAD literate
</code></pre></div>
<p dir="auto">For now, Literate is head only.</p>
<hr>
<p dir="auto">Literate is made with the <a href="https://dlang.org/" rel="nofollow">D programming language</a> so you must install <a href="https://dlang.org/download.html#dmd" rel="nofollow">dmd</a> (D compiler) and <a href="https://code.dlang.org/download" rel="nofollow">dub</a> (D package manager). Then you should download the zip or clone the repository and run the following commands:</p>

<p dir="auto">You can find the binary in path/to/Literate/bin (you may want to add this to your path or move it to <code>/usr/local/bin</code>).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Editors</h3><a id="user-content-editors" aria-label="Permalink: Editors" href="#editors"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Micro</h3><a id="user-content-micro" aria-label="Permalink: Micro" href="#micro"></a></p>
<p dir="auto">The micro editor has support for literate by default. Download it <a href="https://github.com/zyedidia/micro">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Vim</h3><a id="user-content-vim" aria-label="Permalink: Vim" href="#vim"></a></p>
<p dir="auto">You might also want to go install the <a href="https://github.com/zyedidia/literate.vim">Vim plugin</a> (it has syntax highlighting of the embedded code, linting with Neomake, and jumping to codeblock definitions).
I'm sorry that no other editors are supported -- I don't know how to make plugins for other editors.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div data-snippet-clipboard-copy-content="Lit: Literate Programming System

Usage: lit [options] <inputs>

Options:
--help       -h         Show this help text
--tangle     -t         Only compile code files
--weave      -w         Only compile HTML files
--no-output  -no        Do not generate any output files
--out-dir    -odir DIR  Put the generated files in DIR
--compiler   -c         Report compiler errors (needs @compiler to be defined)
--linenums   -l    STR  Write line numbers prepended with STR to the output file
--md-compiler COMPILER  Use COMPILER as the markdown compiler instead of the built-in one
--version    -v         Show the version number and compiler information"><pre><code>Lit: Literate Programming System

Usage: lit [options] &lt;inputs&gt;

Options:
--help       -h         Show this help text
--tangle     -t         Only compile code files
--weave      -w         Only compile HTML files
--no-output  -no        Do not generate any output files
--out-dir    -odir DIR  Put the generated files in DIR
--compiler   -c         Report compiler errors (needs @compiler to be defined)
--linenums   -l    STR  Write line numbers prepended with STR to the output file
--md-compiler COMPILER  Use COMPILER as the markdown compiler instead of the built-in one
--version    -v         Show the version number and compiler information
</code></pre></div>
<p dir="auto">For more information see the <a href="https://zyedidia.github.io/literate/manual.html" rel="nofollow">manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Literate is written in Literate D and you can find the source code in the <code>lit</code> directory. You can also read the source code compiled by Literate <a href="https://zyedidia.github.io/literate/literate-source" rel="nofollow">here</a>.
I am happy to accept pull requests, and if you find any bugs, please report them. Thanks!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Estrogen: A Trip Report (159 pts)]]></title>
            <link>https://smoothbrains.net/posts/2025-06-15-estrogen.html</link>
            <guid>44322153</guid>
            <pubDate>Thu, 19 Jun 2025 20:15:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smoothbrains.net/posts/2025-06-15-estrogen.html">https://smoothbrains.net/posts/2025-06-15-estrogen.html</a>, See on <a href="https://news.ycombinator.com/item?id=44322153">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    <section>
        
<hr>

<hr>
<p>I have <a href="https://en.wikipedia.org/wiki/Gender_dysphoria">gender dysphoria</a>. I find labels overly reifying; I feel reluctant to call myself <em>transgender</em>, per se: when prompted to state my gender identity or preferred pronouns, I fold my hands into the <a href="https://www.yogapedia.com/definition/6871/dhyana-mudra"><em>dhyana mudra</em></a> and state that I <em>practice <a href="https://en.wikipedia.org/wiki/%C5%9A%C5%ABnyat%C4%81">emptiness</a> on the concept of gender</em>. Mostly people seem to vibe it, but sometimes it feels a little like weasel words. Other times, when I’m in a sillier mood, I’ll tell people I’m <em>genderfluid</em> – if only because it sounds like something I’d put in my station wagon. Of course, my faithful Subaru Outback was made before 2008, which means it wants the <a href="https://www.amazon.com/Genuine-Subaru-SOA868V9210-Coolant-Gallon/dp/B007L72U1C/">green, long-life genderfluid</a>…</p>
<p>I experience an ongoing <a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">brain-body map</a> <a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/">prediction error</a> – my brain seems to expect a differently shaped body to the one I wound up with. I have been acutely aware of this since before I hit puberty. Out of shame and embarassment, I suppressed this, but I also made a promise to myself that if I hadn’t come out by the time I turned thirty then I was allowed to get as weird as I needed to.</p>
<!-- To expand on the above: While I experience strong bodily dysphoria, I don't necessarily experience strong dysphoria around my sense of identity. It's possible that this is because I'm so chronically depersonalised that there's nothing really *there* to hang a sense of identity on. It's also possible that any sense of femininity I once felt was so deeply buried by the time I unearthed all this that I have a difficult time reconnecting to it. -->
<p>During the COVID-19 pandemic I went through a phase of using self-administered ketamine therapy to refactor a long list of maladaptive behavioural patterns, and eventually this particular issue became impossible to ignore. I had avoided reifying it for long enough, and this wasn’t working for me – I had to try something different. One evening in July 2021, I sat down with a close friend. <em>I am going to put a large amount of ketamine up my nose</em>, I said. <em>Your job is to start asking me questions about my sexuality.</em></p>
<p>Not long after, I had jumped through the relevant bureaucratic hoops, <!-- backed up my gametes, --> and subsequently found myself cycling home from the pharmacy with a paper bag filled with repurposed menopause medication – a starter pack of <em>100 µg/24 hr</em> estradiol patches, to be applied twice a week.</p>
<figure>
<img src="https://smoothbrains.net/images/random/estrogen/patches.jpg">
</figure>
<p>While the <em>physical</em> effects of estrogen are <a href="https://genderdysphoria.fyi/en/second-puberty-fem">well-documented</a>, back when I came out I had difficulty finding detailed phenomenological reports of the <em>subjective</em> effects of estrogen. I did wind up reading a large number of anecdotal reports on <a href="https://www.reddit.com/r/asktransgender">Reddit</a>, and found that in aggregate, people tend to report <a href="https://www.reddit.com/r/asktransgender/comments/rfpokm/mental_effects_of_estrogen_hrt/">positive subjective effects</a>. One could propose a number of non-exclusive hypotheses as to why – I’ll attempt to review these later in this post.</p>
<p>Did it make sense for me to try this? It was time to find out for myself. I unboxed the patches and placed one on my stomach.</p>

<h2 id="what-does-estrogen-do"><a href="#what-does-estrogen-do">What does estrogen <em>do</em>?</a></h2>
<p>The <a href="https://en.wikipedia.org/wiki/Sex_hormone">sex hormones</a> – <a href="https://en.wikipedia.org/wiki/Androgen">androgens</a>, <a href="https://en.wikipedia.org/wiki/Estrogen">estrogens</a>, and <a href="https://en.wikipedia.org/wiki/Progestogen">progestogens</a> – are produced by the <a href="https://en.wikipedia.org/wiki/Endocrine_system">endocrine system</a>. They are released into the bloodstream in response to a range of regulatory factors – primarily the <a href="https://en.wikipedia.org/wiki/Hypothalamic%E2%80%93pituitary%E2%80%93gonadal_axis">hypothalamic–pituitary–gonadal axis</a> – as a signal for distant cells to regulate a wide variety of bodily functions.</p>

<p>At the other end, <a href="https://en.wikipedia.org/wiki/Receptor_(biochemistry)"><em>receptors</em></a> are – very generally speaking – a class of proteins which can <a href="https://en.wikipedia.org/wiki/Conformational_change">change their shape</a> when <a href="https://en.wikipedia.org/wiki/Ligand_(biochemistry)">specific molecules</a> bind to them. Of these, <a href="https://en.wikipedia.org/wiki/Estrogen_receptor"><em>estrogen receptors</em></a> are primarily <a href="https://en.wikipedia.org/wiki/Nuclear_receptor"><em>nuclear receptors</em></a>, although a smaller fraction of them are <a href="https://en.wikipedia.org/wiki/Cell_surface_receptor"><em>cell surface receptors</em></a>. These are typically located in the cell’s <a href="https://en.wikipedia.org/wiki/Cytoplasm"><em>cytoplasm</em></a> – but when activated, they pass through the <a href="https://en.wikipedia.org/wiki/Nuclear_envelope"><em>nuclear membrane</em></a>, bind directly to DNA, and <a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression">regulate the expression of specific genes</a>. For comparison, <a href="https://en.wikipedia.org/wiki/Neurotransmitter_receptor"><em>neurotransmitter receptors</em></a> are primarily <a href="https://en.wikipedia.org/wiki/Cell_surface_receptor"><em>cell surface receptors</em></a>. These are located in the <a href="https://en.wikipedia.org/wiki/Cell_membrane"><em>cell membrane</em></a> – and when activated might <a href="https://en.wikipedia.org/wiki/Ligand-gated_ion_channel">allow ions to pass through the cell membrane</a> or <a href="https://en.wikipedia.org/wiki/Metabotropic_receptor">trigger other messaging systems within the cell</a>.</p>
<figure>
<a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression#/media/File:Regulation_of_gene_expression_by_steroid_hormone_receptor.svg"><img src="https://smoothbrains.net/images/random/estrogen/regulation_of_gene_expression.png"></a>
<figcaption>
Illustration of a hormone receptor regulating gene expression, from <a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression">Wikipedia</a>.
</figcaption>
</figure>
<p>Estrogen receptors are located throughout the body. Of these, there are two main types – <a href="https://en.wikipedia.org/wiki/ER%CE%B1">ERα</a> and <a href="https://en.wikipedia.org/wiki/Estrogen_receptor_beta">ERβ</a>. These have similar <a href="https://en.wikipedia.org/wiki/Ligand_(biochemistry)#binding_affinity">binding affinities</a> for estradiol, but are expressed in different proportions in different bodily tissues, and can have different effects on gene regulation.</p>
<p>Estrogen receptors are of course also located in the brain. <a href="https://pubmed.ncbi.nlm.nih.gov/33396472/">The Role of Estrogen Receptors and Their Signaling across Psychiatric Disorders</a> (Hwang et al., 2020) includes a map of where they are concentrated:</p>
<blockquote>
<figure>
<a href="https://pubmed.ncbi.nlm.nih.gov/33396472/#&amp;gid=article-figures&amp;pid=figure-1-uid-0"><img src="https://smoothbrains.net/images/random/estrogen/estrogen_receptor_distributions.jpg"></a>
<figcaption>
<strong>Figure 1.</strong> A schematic diagram of distributions of estrogen receptor alpha and estrogen receptor beta in our brains. The receptors have a different predominance of expression in distinct regions. ERα is predominantly expressed in the <a href="https://en.wikipedia.org/wiki/Amygdala">amygdala</a> and <a href="https://en.wikipedia.org/wiki/Hypothalamus">hypothalamus</a>, whereas ERβ is predominantly expressed in the <a href="https://en.wikipedia.org/wiki/Primary_somatosensory_cortex">somatosensory cortex</a>, <a href="https://en.wikipedia.org/wiki/Hippocampus">hippocampus</a>, <a href="https://en.wikipedia.org/wiki/Thalamus">thalamus</a>, and <a href="https://en.wikipedia.org/wiki/Cerebellum">cerebellum</a>.
</figcaption>
</figure>
</blockquote>
<p>It is not surprising, then, that estrogen can have an influence on multiple aspects of brain function, including neurotransmitter levels. There’s a recent review paper which covers the latest information we have on this. From <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1348551/full">The impact of estradiol on serotonin, glutamate, and dopamine systems</a> (Bendis et al., 2024):</p>
<blockquote>
<figure>
<a href="https://www.frontiersin.org/files/Articles/1348551/fnins-18-1348551-HTML-r1/image_m/fnins-18-1348551-t001.jpg"><img src="https://smoothbrains.net/images/random/estrogen/estradiol_table_1.png"></a>
<figcaption>
<strong>Table 1</strong>. Summary of the main findings on the role of estradiol on serotonin, glutamate, and dopamine systems.
</figcaption>
</figure>
</blockquote>
<blockquote>
<p>Estradiol is a steroid hormone that influences the serotonergic, dopaminergic, and glutamatergic systems. Estradiol exerts its effects through classical mechanisms by binding to nuclear estrogen receptors α, and β, or through nonclassical mechanisms through binding to membrane bound estrogen receptors α, β, and <a href="https://en.wikipedia.org/wiki/GPER">GPER</a>.</p>
</blockquote>
<p>The effects are so wide-ranging that any review I can write will no doubt oversimplify things. That said, I’d like to highlight two findings relevant to neurotransmitter levels:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Serotonin"><em>Serotonin</em></a> synthesis is upregulated by ERβ via <a href="https://en.wikipedia.org/wiki/Tryptophan_hydroxylase">tryptophan hydroxylase</a> transcription.</li>
<li><a href="https://en.wikipedia.org/wiki/Dopamine"><em>Dopamine</em></a> synthesis is upregulated by ERα and downregulated by ERβ via <a href="https://en.wikipedia.org/wiki/Tyrosine_hydroxylase">tyrosine hydroxylase</a> transcription. Potentially, they work in tandem to maintain homeostatic levels, but ERα has greater influence at higher estradiol levels.</li>
</ul>
<p>These neurotransmitters are, of course, <a href="https://x.com/AskYatharth/status/1615157727625637888">stereotypically</a> associated with <em>mood</em> and <em>reward</em>.</p>

<p>Estrogen receptors can also upregulate or downregulate production of neurotransmitter receptors. However, most of the evidence we have for this is from <a href="https://en.wikipedia.org/wiki/Ligand_binding_assay">binding assays</a> performed on <em>rats</em>. As stated in another review paper, <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00037/full">Sex hormones affect neurotransmitters and shape the adult female brain during hormonal transition periods</a> (Barth et al., 2015):</p>
<blockquote>
<p>Evidence from neuroimaging findings to link estrogen and the
serotonergic system in humans are still relatively sparse. Animal
data support ovariectomy to decrease <a href="https://en.wikipedia.org/wiki/5-HT1_receptor">5-HT1</a> binding, <a href="https://en.wikipedia.org/wiki/5-HT2A_receptor">5-HT2A</a> binding and expression, and <a href="https://en.wikipedia.org/wiki/Serotonin_transporter">5-HT transporter</a> binding sites and expression. These findings have
been shown to be reversible with estrogen replacement therapy.</p>
</blockquote>
<p>This process involves several steps: First, researchers remove the ovaries from female rats, and then divide them into two groups – one receiving estrogen treatment and the other serving as a control. Next, finely sliced brain samples are taken from both groups and exposed to a radioactive ligand, which binds to the receptor of interest. Finally, these radioactive samples are used to <a href="https://en.wikipedia.org/wiki/Autoradiograph">create images on radiosensitive film</a>, which is then developed and analysed.</p>
<blockquote>
<figure>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6740259/"><img src="https://smoothbrains.net/images/random/estrogen/rat_hippocampi.png"></a>
<figcaption>
Autoradiographs of <sup>3</sup>H-<a href="https://en.wikipedia.org/wiki/Dizocilpine">MK-801</a> binding in the hippocampus of female rats which received: <strong>(a)</strong> a sham surgery with no ovariectomy; <strong>(b)</strong> ovariectomy and injection with a control substance; <strong>(c)</strong> ovariectomy and <em>40 μg/kg</em> estrogen; <strong>(d)</strong> ovariectomy and <em>0.5 mg/kg</em> progesterone.
</figcaption>
</figure>
</blockquote>
<p>This is not the kind of procedure we generally perform on humans. Additionally, these preclinical rat model studies concern ovarectomized female rats and are intended to inform treatment programmes for postmenopausal human women – so their relevance to humans starting from an androgenic baseline is possibly somewhat limited. Still, there’s a <a href="https://academic.oup.com/endo/article-abstract/131/2/662/2496261">couple</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/096007609500075B">of</a> these studies I’d like to highlight, which found estrogen caused:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/NMDA_receptor"><em>NMDA receptor</em></a> upregulation in the <a href="https://en.wikipedia.org/wiki/Hippocampus_proper#CA1">CA1 region</a> of the <a href="https://en.wikipedia.org/wiki/Hippocampus">hippocampus</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/5-HT2A_receptor"><em>5-HT2A receptor</em></a> upregulation in the <a href="https://en.wikipedia.org/wiki/Forebrain">forebrain</a>, particularly the <a href="https://en.wikipedia.org/wiki/Prefrontal_cortex">anterior frontal cortex</a>, <a href="https://en.wikipedia.org/wiki/Anterior_cingulate_cortex">anterior cingulate cortex</a>, <a href="https://en.wikipedia.org/wiki/Primary_olfactory_cortex">primary olfactory cortex</a> and the <a href="https://en.wikipedia.org/wiki/Nucleus_accumbens">nucleus accumbens</a>.</li>
</ul>
<p>That said, there <em>do</em> exist a <a href="https://pubmed.ncbi.nlm.nih.gov/12900319/">couple</a> <a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext">of</a> studies assessing the influence of estrogen on 5-HT2A receptor binding in humans, using a radioactive ligand and <a href="https://en.wikipedia.org/wiki/Positron_emission_tomography">positron emission tomography</a>. In both studies, five postmenopausal women were assessed both before and after hormone replacement therapy, and both found estrogen increased 5-HT2A receptor binding in <a href="https://en.wikipedia.org/wiki/Prefrontal_cortex">prefrontal regions</a>. The resolution is pretty low, but see for yourself:</p>
<blockquote>
<figure>
<a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext"><img src="https://smoothbrains.net/images/random/estrogen/binding_sites_5-ht2a.png"></a>
<figcaption>
Regions where 5-HT2A receptor binding potential increased following hormone replacement therapy. <strong>Row A</strong> and <strong>Row B</strong> indicate estradiol and combined estradiol and progesterone treatment respectively, with a voxel threshold of <em>P</em> &lt; 0.01. <strong>Row C</strong> indicates estradiol treatment, with a less strict voxel threshold of <em>P</em> &lt; 0.05.
</figcaption>
</figure>
</blockquote>
<p>Alright, so what are these <em>NMDA</em> and <em>5-HT2A</em> receptors responsible for? These are glutamate and serotonin receptors, respectively – and these are also the specific receptors that are <a href="https://en.wikipedia.org/wiki/Receptor_antagonist"><em>antagonised</em></a> by <a href="https://psychonautwiki.org/wiki/Ketamine">ketamine</a> and <a href="https://en.wikipedia.org/wiki/Agonist"><em>agonised</em></a> by most <a href="https://psychonautwiki.org/wiki/Serotonergic_psychedelic">serotonergic psychedelics</a>. If recreational drugs targeting these receptors can engender euphoric subjective effects – what might estrogen be capable of?</p>

<!--
Comments from Anna:

- [https://docs.google.com/document/d/1YkfMTobh2VFviFrd_9kmDwGf_IJTpJc7CBVF-Po3l-U/](https://docs.google.com/document/d/1YkfMTobh2VFviFrd_9kmDwGf_IJTpJc7CBVF-Po3l-U/)

All this is to say that I think the basic science in your post is correct, but I am significantly skeptical that:

A. Potential neurological effects of increasing estrogen levels in normal healthy adults won’t tend to get buffered out by other regulatory systems, given that you're acting a couple steps upstream
B. We should typically expect to be able to generalize from AMABs to AFABs when it comes to this kind of thing.
-->
<h2 id="what-does-estrogen-feel-like"><a href="#what-does-estrogen-feel-like">What does estrogen <em>feel like</em>?</a></h2>
<p>The subjective perceptual and psychological effects of estrogen are wide-ranging and subtle. I’ll start by discussing the more mundane sensory changes I experienced before moving on to those which might be more nebulous or ineffable.</p>
<!-- The big parts were that estrogen decreased autistic sensory sensitivities, decreased muscular tension and increased emotional fluidity. But I'll go through these in detail. -->
<h4 id="dosage"><a href="#dosage">Dosage</a></h4>
<p>At the time of writing, I’ve been on and off estrogen for a period of nearly three years. My initial dosage was one of the <em>100 µg/24 hr</em> <a href="https://en.wikipedia.org/wiki/Estradiol">estradiol</a> patches, but I doubled this after a short while. I have also tried <em>2 mg</em> <a href="https://en.wikipedia.org/wiki/Estradiol_valerate">estradiol valerate</a> pills, twice or three times daily – though this turned out to be too low, and I wound up switching back to patches. I have found using patches to result in the most striking and noticeable subjective effects. I have not yet tried injected estrogen, though I anticipate doing so before long.</p>
<!-- I did also take a [selective estrogen receptor modulator](https://transfemscience.org/articles/nonbinary-transfem-overview/#selective-estrogen-receptor-modulators-serms) because I wish to attenuate breast growth – *60 mg* [raloxifene](https://en.wikipedia.org/wiki/Raloxifene), once daily. This has worked to prevent development of breast tissue, but it has not prevented fat redistribution. It is hard to tell if this has any subjective effect. -->
<p>Additionally, at one point I tried taking a <em>300 mg</em> <a href="https://en.wikipedia.org/wiki/Progesterone">progesterone</a> suppository. This made me feel quite stupid the following day, so I did not try this again.</p>
<h3 id="gustatory-perception"><a href="#gustatory-perception">Gustatory perception</a></h3>
<p>I’ve long been in the bad habit of rolling out of bed and grabbing a Monster Zero straight from the fridge first thing in the morning, and I tend to follow this up with Diet Coke throughout the day. This means that I’m fairly attuned to the taste of artificial sweeteners, so naturally the change in taste perception was the first thing I noticed – within a day or two of first putting the patches on, I found that <em>sweet</em> things tasted <em>sweeter</em>; and <em>sour</em> things tasted both <em>sweeter</em> and more <em>metallic</em> – and the cinnamon taste in my standard reference Diet Coke really <em>shone through</em>.</p>
<p>This was rather exciting; I was not expecting to find that the <a href="https://en.wikipedia.org/wiki/Taste#Basic_tastes">primary tastes</a> were not in fact primal, but in fact could shift around inside a lower-dimensional <a href="https://en.wikipedia.org/wiki/Latent_space">latent space</a>. This got me theorising – as I wrote <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-somatic-field">elsewhere</a>:</p>
<blockquote>
<p>Perhaps taste could be built out of something like <a href="https://en.wikipedia.org/wiki/Dyad_(music)"><em>dyadic</em></a> vibrations, tuned by evolution towards <a href="https://en.wikipedia.org/wiki/Consonance_and_dissonance">consonance or dissonance</a> in order to generate an attractive or aversive response in the organism?</p>
</blockquote>
<!-- What might "metallic" mean, here? Slapback reverb? -->
<h3 id="olfactory-perception"><a href="#olfactory-perception">Olfactory perception</a></h3>
<p>It took me a little while before I noticed any change to my sense of smell, but this was more a factor of encountering the relevant stimulus. It was boys. Boys smelt different.</p>
<p>Much earlier in life, I’d had to convince myself I was gay by using the fact that boys smelt <em>really good</em>. This was very much no longer the case, and I began to notice wide variation in the way boys smelt, which sometimes was really quite unpleasant – <em>oniony</em>, even.</p>

<!-- In return, the boys in my life took turns smelling my armpits; they all said I smelt great. -->
<!-- Estrogen is known to [upregulate 5-HT2A receptor expression in the olfactory cortex of rats](https://pubmed.ncbi.nlm.nih.gov/7632610/). I was unable to find any similar information about the gustatory cortex. -->
<h3 id="somatic-perception"><a href="#somatic-perception">Somatic perception</a></h3>
<p>I have somatic sensory issues. Skin sensations have always been overwhelming – my mother will confirm that I would scream if she attempted to dress me in wool, and in adulthood I avoid buying clothing with sleeves. By default, my skin feels like a bag of white noise – and when things get bad it can feel like my whole body is covered with randomised pinprick sensations, like minuscule <a href="https://smoothbrains.net/posts/2024-03-01-5-meo-dmt.html">topological defects</a> in the <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-somatic-field">somatic field</a>.</p>
<p>This has interfered with my ability to experience intimacy; simply lying in bed with somebody could be a stressful time for me. Estrogen ramps all of this way down in intensity – it’s a tremendous relief.</p>
<p>Perhaps my cleaning habits can provide an objective measure. Because things like sweat on my skin or leftover food in my mouth constitute intolerable sensory distractions, I’d tend to shower up to four times a day and brush my teeth about as often – since starting estrogen, I’m much less neurotic about both of these things.</p>
<p>A less turbulent nervous system also seems to be less disruptive for sleep. Beforehand, I took it for granted that I would often wake up throughout the night in a state of discomfort, whereas while I am on estrogen I reliably wake up in the morning feeling well-rested.</p>
<h3 id="visual-perception"><a href="#visual-perception">Visual perception</a></h3>
<p>It’s fairly common to hear reports of <a href="https://www.reddit.com/r/MtF/comments/xcr66g/color_on_estrogen/">colours becoming more intense after starting hormone replacement therapy</a>. I’m familiar with how <a href="https://psychonautwiki.org/wiki/Color_enhancement">serotonergic psychedelics can produce this effect</a>, but I can’t say I observed any such thing myself. What did change was my sense of <em>space</em>.</p>
<p>This one’s quite subtle – it was the kind of thing that was more noticeable when I experimented with deliberately spiking my hormones. I’ll do my best to explain. It’s as if I took the entire volumetric representation of the space around me and increased the degree to which every point within that could influence the location of every other point, recursively. This allows everything to elastically settle into a more harmonious equilibrium. This effect is basically identical to what a small dose of psychedelics can do, specifically a tryptamine like <a href="https://psychonautwiki.org/wiki/Psilocybin_mushrooms">psilocybin</a> or <a href="https://psychonautwiki.org/wiki/DMT">DMT</a>.</p>

<p>It’s hard to say what the utility of this might be. The balance between entropy and harmony is an important one – too much entropy and it’s hard to tell signal from noise, and too much harmony and you might miss important details. I did feel that with a more parsimonious model of the space around me, I got better at driving – though my friends would say I got more <em>confident</em> at driving. Competence might be orthogonal to confidence, but I maintain that parallel parking is much easier now.</p>
<h3 id="motor-output"><a href="#motor-output">Motor output</a></h3>
<p>I ride my bicycle every morning – this is my primary meditative practice. I am also surrounded by steep hills, so I noticed within a couple of days that I could not activate my quads and hamstrings as hard as I was used to. This happened much faster than could possibly be accounted for by muscular atrophy, so I surmised that this must be a neuromuscular phenomenon. Later on I switched back to my own hormones for a short period, and once again the change was quite rapid. There was nothing quite like the rush of <em>powering</em> uphill once again.</p>
<p>Being less strong honestly sucked pretty bad, and this required some psychological adjustment. <!-- I learned that muscular strength is but one of many axes along which one can maximise one's agency. --> The flipside of this was that I found estrogen to be a <em>superb</em> muscle relaxant, and ultimately this made the effect a net positive.</p>
<p>Around the time I transitioned was also the period when I was exploring some quite extreme ketamine-assisted <a href="https://www.fasciaresearch.com/literature/sensory-innervation/InnervationExcerpt.pdf">myofascial release</a> techniques in order to shake off a lifetime’s worth of accumulated tension from things like bad ergonomics and social anxiety. I’d say estrogen has been partially instrumental in getting me from a place where I’m constantly attacking myself with a foam roller and massage gun just to feel comfortable in my own body – to one where massage is more of a light maintenance task, like a bird preening its feathers.</p>
<!-- It's a fair trade. I like being soft and pliable. -->

<h3 id="emotional-modulation"><a href="#emotional-modulation">Emotional modulation</a></h3>
<p>I have spent a big chunk of my life navigating chronic emotional disaffection – high school sucked, and later I had an acute week-long dissociative episode when I was twenty-one which I’m not sure I ever quite came back from. Suffice it to say I lived an emotionally stagnant existence for most of my twenties – so when the hormones opened things up, I got quite attached to my new feelings.</p>
<p>Funny things were <em>funnier</em> – I recall a moment about a week after I started the hormone treatment, when I laughed at something I saw on YouTube – the surge of joy was like an electric cauteriser through my breastbone. Music <a href="https://www.youtube.com/watch?v=XGWbIw8oK9I"><em>works</em></a> now. I can lean in to the sense of affection I feel towards my friends. I cry more frequently; but this is clearly critical for releasing tension that would otherwise remain below the surface.</p>
<p>There’s another side to all this. I have had to navigate a number of situations where I now found myself unable to dissociate from some issue in my life that had been bothering me – I <em>had</em> to do something. Often this felt destructive; in retrospect there’s things I could have handled with far more grace and care, but instead I chose to drive a bulldozer through them.</p>
<!-- when normally I'd weather emotionally turbulent events without too much fuss -->
<p>For better or worse, this is what the hormones can do. It’s a bit of an epistemic nightmare – do I take action to deal with the thing that’s bugging me, or would it be better to skip my hormones for a day or two and see if I consider things differently? I can only recommend entering into this groundless game of instrumental hormone manipulation if one is comfortable taking responsibility for epistemic frame-shifting.</p>
<h3 id="attentional-modulation"><a href="#attentional-modulation">Attentional modulation</a></h3>
<p>I’d engaged with a number of deliberate psychological interventions in the lead-up to coming out, with the general aim of managing my social self-awareness. I knew I needed the confidence. If I was to socially transition, I’d need to not get too overwhelmed or hung up on what other people thought of me.</p>
<p>Of these, the most effective was <a href="https://x.com/m_ashcroft">Michael Ashcroft</a>’s <a href="http://expandingawareness.org/">extremely straightforward course</a> on <a href="https://en.wikipedia.org/wiki/Alexander_Technique">Alexander Technique</a>. I wrote about this in my writeup on <a href="https://smoothbrains.net/posts/2023-10-28-attention-and-awareness.html">attention and awareness</a>:</p>
<blockquote>
<p>Here’s how I usually explain it to people: You have <em>awareness</em>, which corresponds to everything currently in your sensorium. Then you have <em>attention</em>, which is a subset of that – like the beam of a spotlight – and most importantly, you have <em>agency</em> over it, you can choose where to point it and how wide or narrow you would like it to be.</p>
</blockquote>
<p>Sometimes we might feel that our attention is involuntarily yanked around by invisible aversive forces that are seemingly beyond our control – for instance, I might find it challenging to make eye contact with people at a party, and spend the whole time with my attention collapsed and pointed at the floor.</p>
<p>I think what Alexander Technique does is <a href="https://x.com/m_ashcroft/status/1807008725548363845">teach mindfulness of this class of phenomena and how to <em>expand</em> attention out of them</a>. Prior to transition, I deliberately experimented with this form of attentional modulation – primarily in the kind of social setting that I would normally find overwhelming, but also just while riding my bicycle outside. I think this kind of practice has a lot of potential for helping undo the archetypal trauma-induced behavioural patterns displayed by socially anxious autistic people. Personally I found it to be remarkably effective, and after some months of this I felt that my anxiety disorder was mostly in remission.</p>
<p>So it was a humungous letdown when I found that all of this got <em>significantly harder</em> on estrogen. I cringed my way through social events, and returned to staring at the floor – but I didn’t let this stop me. I thought of it like Goku training in the <a href="https://dragonball.fandom.com/wiki/Gravity_Machine">one hundred times Earth gravity chamber</a>. I just learned it all again from scratch.</p>
<h2 id="how-does-estrogen-work"><a href="#how-does-estrogen-work">How does estrogen <em>work</em>?</a></h2>
<p>If someone feels that they’d rather have a feminine body, estrogen is going to satisfy this desire – <em>within reason</em>. This is obvious. I’m more interested in finer-grained, <em>bottom-up</em> rather than <em>top-down</em> sensory phenomena. What are the other reasons that estrogen might <em>feel good</em>? I’d like to propose a number of theories – I’ll try to order them from least speculative to most speculative.</p>
<p>What should my <a href="https://en.wikipedia.org/wiki/Null_hypothesis">null hypothesis</a> be? <a href="https://www.reddit.com/r/DrWillPowers/comments/fcxboa/the_story_of_how_i_screwed_up_a_dose_calculation/">Would estrogen make someone without gender dysphoria feel good too?</a> Is it just a miraculous coincidence that estrogen just so happens to fix other issues that tend to be correlated with gender dysphoria – or do people with gender dysphoria suffer from an innate neurochemical deficit which can be corrected by hormone therapy?</p>

<h3 id="estrogen-is-like-the-opposite-of-ketamine"><a href="#estrogen-is-like-the-opposite-of-ketamine">Estrogen is like the opposite of ketamine</a></h3>
<p>Transgender writer <a href="https://zinniajones.com/">Zinnia Jones</a> suffers from <a href="https://en.wikipedia.org/wiki/Depersonalization-derealization_disorder">depersonalisation-derealisation disorder</a>, and found that her symptoms were <em>dissolved completely</em> when she started hormone replacement therapy.</p>
<!--
<aside>
   I'll avoid using the term *dissociation*, which could mean [about four or five different things](https://x.com/br___ian/status/1761429178115932653).
</aside>
-->
<p>The phenomenology of depersonalisation-derealisation is notoriously difficult to describe, but Zinnia has written the single best description of it that I’ve ever read. From her blog post, <a href="https://zinniajones.medium.com/trip-report-lamotrigine-a-drug-to-treat-depersonalization-e8171e165813">Trip report: Lamotrigine, a drug to treat depersonalization</a>:</p>
<blockquote>
<p>There was no point where I didn’t feel somehow removed from the world around me – this disconcerting sensation was present from my earliest memories. As a child I just didn’t really see the point of practically anything I was doing, or that anyone else was doing; it held no real emotional resonance or meaning for me. Whatever interests I chose to pursue felt more like an obligatory way of filling time, not something that had any value or importance in its own right.</p>
<p>I always felt the lack of spontaneity characteristic of depersonalization disorder, and whenever I chose to say anything, it felt rehearsed and acted out as if I had to engage my every word and action manually. Most of the time I would choose to say nothing at all. My feelings seemed to be kept at a distance, happening as something separate from an interior “me” who didn’t truly experience these emotions and seemingly couldn’t be touched by them. I was painfully conscious of all of these things.</p>
</blockquote>
<p>She continues with a visual description which I found particularly fascinating:</p>
<blockquote>
<p>In sufferers of depersonalization, symptoms can become more prominent in the form of sudden attacks – and it gets worse the more you keep thinking about it. Later that night, I step outside to get some air, and the thought enters my mind that the trees, cars, and houses on our street could just be particularly elaborate Lego pieces. The clouds in the night sky could easily pass for a simple rendering in Blender. Isn’t at least half of what we see practically a hallucination that’s filled in by our brain without us even noticing? If all these things were just renderings, it seems like it would be easy to take advantage of that.</p>
<p>I can almost envision everything on our street coming apart piece by piece like an exploded technical diagram. The asphalt, the curb, the patches of grass, all of them could just lift into the air and drift apart, nothing but thin surfaces, almost like abstractions or mere representations. If I were to take a shovel and start digging a hole in the road, it would just be an indentation in that surface, pushing it to extend a bit in one direction or another – but underneath it, nothing. The houses along the street are just outgrowths of the surface, a sort of puckering in it, like a ball on a rubber sheet to demonstrate how gravity is the curvature of spacetime.</p>
</blockquote>
<!--
See also, her [comment on r/transgender](https://www.reddit.com/r/asktransgender/comments/7t1z1w/comment/dt9e6xx/):

> Depersonalization (unreality and "no-self" feelings) was a really prominent feature of my life before transitioning, and it was highly distressing. I felt like a robot, like all my expressed emotions and actions were running entirely on manual, and I just wished anything could make me stop feeling this way. HRT made it go away within a week or two, and I had no idea that could even happen – I thought that was just my "normal", and it turns out it wasn't (I didn't even know depersonalization was a thing until a few years ago, so I had no language to describe it). I've been so, so happy since then and I feel that was when my life really began. It turns out depersonalization is much more common among trans people than among cis people, and that it declines after transitioning, specifically after treatment with HRT.
>
> I don't know enough about the relevant chemistry to remark on how this might have worked for your friend, but ketamine does have a rapid antidepressant effect and has been used in trials for this purpose, so it's possible that's what they were experiencing. Lamotrigine (Lamictal) is an anticonvulsant that's something like the opposite of ketamine: it inhibits glutamate release whereas ketamine stimulates it, resulting in ketamine's dissociative and DP/DR effects. It specifically blunts many of ketamine's effects (e.g. ketamine as an anesthetic will not work in cases of lamotrigine overdose). Lamotrigine, in combination with an SSRI, is one of the very few (possibly the only) treatments that's been found to be mostly effective for depersonalization disorder – it seems to have an anti-dissociative effect.
>
> I got on lamotrigine a few weeks back because I was curious about this (I really can't recommend this, as it can have serious side effects). After I'd titrated up, I went off my hormones for about 11 days. Normally when this happens I have a really noticeable and unbearable return of my depersonalization within 3-4 days. This time I was easily able to hold out for a week or so. Somehow, I felt almost normal. Things didn't really feel quite the same, but overall it felt like my DP/DR was at a 4 when it would normally be a screaming 10. I had no sense of feeling robotic, lacking spontaneity, or having a compulsive inner-monologue "observer", or lacking in genuine emotions. But by the last day I was starting to have some cognitive fog and a sense of the world being nothing but some strange infinitesimally thin surface stretched over infinite hollowness. It made me pretty uneasy, so since then I've been back on my HRT and that's all gone away.
-->
<p>When I read this, I could not help but think two things:</p>
<ul>
<li>Wow, <em>this sounds just like my life</em>.</li>
<li>Wow, <em>this sounds just like being on <a href="https://smoothbrains.net/posts/2023-08-01-ketamine.html">ketamine</a></em>.</li>
</ul>
<p>I related very strongly to both her description of feeling distanced from life – as well as her description of the <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-visual-field">visual field</a> being – as she has written <a href="https://www.reddit.com/r/asktransgender/comments/7t1z1w/comment/dt9e6xx/">elsewhere</a> – <em>nothing but some strange infinitesimally thin surface stretched over infinite hollowness</em>. Both of these effects increase when I experiment with ketamine, and I also notice that both of these effects reverse when I use estrogen. In particular, the way in which estrogen alters <a href="#attentional-modulation">attentional modulation</a> also seems responsible for an increase in <a href="https://slehar.wordpress.com/2014/09/12/amodal-perception/">amodal perception</a>, which in turn makes the visual field feel less <em>hollow</em> – though I don’t necessarily regard this as <em>desirable</em> or <em>undesirable</em>. It just is.</p>
<figure>
<a href="https://slehar.wordpress.com/2014/09/12/amodal-perception/"><img src="https://smoothbrains.net/images/random/estrogen/tomatoamodal.png"></a>
<figcaption>
Illustration of amodal perception, by <a href="https://smoothbrains.net/posts/2022-10-01-an-introduction-to-steven-lehar-part-i.html">Steven Lehar</a>. I found estrogen made objects feel less “hollow”.
</figcaption>
</figure>
<p>I’d also previously read <a href="https://x.com/slatestarcodex">Scott Alexander</a>’s blog post, <a href="https://slatestarcodex.com/2017/06/28/why-are-transgender-people-immune-to-optical-illusions">Why Are Transgender People Immune To Optical Illusions</a>, in which he speculates that if ketamine is an <em>NMDA receptor antagonist</em> which causes depersonalisation – and if estrogen <em>upregulates NDMA receptor expression</em> – then it’s possible that changes to the NMDA receptor network could be what’s responsible for the relevant changes in phenomenology.</p>
<figure>
<a href="http://slehar.com/wwwRel/cartoonepist/cartoonepist12.html"><img src="https://smoothbrains.net/images/random/estrogen/Fig12.jpg"></a>
<figcaption>
Illustration of the visual field, by <a href="https://smoothbrains.net/posts/2022-10-01-an-introduction-to-steven-lehar-part-i.html">Steven Lehar</a>. I found estrogen made it feel less “flat”. Can you imagine how this would make someone’s internal world simulation feel less “fake”?
</figcaption>
</figure>
<p>Right now I don’t have much to add beyond: <em>wow, I think this checks out</em>. The question remains – does estrogen correct some kind of underlying <em>NMDA receptor expression deficit</em>, which ultimately leads to the psychological problems correlated with gender dysphoria – and, how does this relate to gender dysphoria itself?</p>

<!--
<aside>
    Speculatively, I also think ketamine *hits harder* when I'm not on estrogen, but that's another story.
</aside>
-->
<h3 id="estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time"><a href="#estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time">Estrogen is like being on a mild dose of psychedelics all the time</a></h3>
<p>There’s a psychedelic research paper I’m a fan of – <a href="https://www.nature.com/articles/s41598-022-11999-8">Phenomenology and content of the inhaled <em>N</em>, <em>N</em>-DMT experience</a> (Lawrence et al., 2022) – in which the authors scrape ten years’ worth of comments from the <a href="https://www.reddit.com/r/DMT/">r/DMT</a> Reddit community, and tabulate different aspects of the <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/2">somatic</a>, <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/3">visual</a>, and <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/4">entity encounter</a> phenomenology by how frequently they were reported.</p>
<p>Much of my personal research simply consists of reading a large number of Reddit comments. As such, I sorely wish for there to exist an equivalent paper to the DMT phenomenology one, but which scrapes <a href="http://reddit.com/r/asktransgender/">transgender</a> <a href="https://www.reddit.com/r/AskMtFHRT/">support</a> <a href="https://www.reddit.com/r/TransDIY/">subreddits</a> for subjective reports instead. However, until such time as one exists, the reader may just have to take my word for it when I claim a particular effect of estrogen is “commonly reported”.</p>
<p>One effect “commonly reported” by people just starting estrogen is that <a href="https://www.reddit.com/search/?q=estrogen+color">colours appear more saturated</a>. From a <a href="https://www.reddit.com/r/MtF/comments/1dxe691/comment/lc1eyab/">typical comment</a> on an <a href="https://www.reddit.com/r/MtF/">r/MtF</a> thread <a href="https://www.reddit.com/r/MtF/comments/1dxe691/anyone_on_hrt_do_any_of_yall_see_colors_more/">asking if anyone experiences colours more vibrantly</a>:</p>
<blockquote>
<p>Yes! I was at the art museum yesterday and I became utterly infatuated with a shade of blue I’ve never seen before. Sat and stared at it for like 15 minutes.</p>
<p>Then again, I may just be happier now.</p>
</blockquote>
<p>Referring back to the DMT phenomenology paper, <em>vivid</em> or <em>hyperintense</em> colours were reported in 25.2% of experiences. Personally, I didn’t experience any shift in colour perception, but I did find the other <a href="#visual-perception">visual perception</a> changes I experienced to be distinctively <em>psychedelic</em> in nature – as I mentioned earlier, particularly reminiscent of a tryptamine like <a href="https://psychonautwiki.org/wiki/Psilocybin_mushrooms">psilocybin</a> or <a href="https://psychonautwiki.org/wiki/DMT">DMT</a>. This is especially noticeable when I deliberately spike my levels with an extra patch, and on some days I suspect I even notice a slight amount of increased <a href="https://x.com/MatthijsCox/status/1611363519093694465">symmetrical texture repetition</a>.</p>
<figure>
<iframe src="https://www.youtube.com/embed/sY8nsjo__ek" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<figcaption>
Replication of psilocybin visuals, by <a href="https://www.youtube.com/@SymmetricVision">Symmetric Vision</a> on YouTube.
</figcaption>
</figure>
<p>Estrogen is known to <em>upregulate 5-HT2A receptor expression</em>, which is of course the same serotonin receptor which is agonised by most <a href="https://en.wikipedia.org/wiki/Psychedelic_drug">serotonergic psychedelics</a>. It seems quite reasonable to me to assume that this is what’s responsible for the various reported sensory enhancements in addition to the <a href="#emotional-modulation">changes in mood</a>.</p>
<p>I now have an additional question. In addition to correcting some kind of <em>NMDA receptor expression deficit</em> inherent to the gender dysphoric neurotype, does estrogen also correct a <em>5-HT2A receptor expression deficit</em> – or does tripping on estrogen <em>just feel good</em>?</p>
<!--
<aside>
    The neuroscientist [Robin Carhart-Harris](https://en.wikipedia.org/wiki/Robin_Carhart-Harris) theorises that the serotonin system is responsible for managing ongoing stress – and that the *5-HT1A receptor* is responsible for a *passive coping* mechanism while the *5-HT2A receptor* is responsible for an *active coping* mechanism. For a discussion of this theory, please see my post, [5-MeO-DMT: A crash course in phenomenal field topology](/posts/2024-03-01-5-meo-dmt.html).
</aside>
-->
<h3 id="estrogen-loosens-the-bodymind"><a href="#estrogen-loosens-the-bodymind">Estrogen loosens the bodymind</a></h3>
<p>As <a href="#motor-output">mentioned above</a>, I found estrogen to be an incredibly powerful muscle relaxant. Using the <a href="https://slatestarcodex.com/2016/09/12/its-bayes-all-the-way-up/">Bayesian brain</a> model to understand this, it seems as if my nervous system holds <a href="https://www.lesswrong.com/w/priors"><em>priors</em></a> for how tense every muscle in my body should be in response to a given situation – and these priors are <em>relaxed</em> under the influence of estrogen.</p>
<p>I have to credit estrogen with helping fix a number of long-standing neck and upper back problems which I’ve been dealing with for most of my life. It’s sufficiently powerful that I am skeptical that I would have been able to fix these issues while I was on testosterone. Notably, these issues don’t return when I stop taking estrogen.</p>
<p>The effects feel more foundational than this, however; estrogen feels like it reshapes my body map itself, <a href="https://smoothbrains.net/posts/2024-05-29-what-is-a-bodymind-knot.html">smoothing out knots</a> – like an elastic membrane being tightened, or a soap bubble reaching equilibrium. I’ve seen it “commonly reported” that estrogen makes people feel <em>more embodied</em>, and I suspect that this is what people might tend to mean by that.</p>
<figure>
<a href="https://a.carapetis.com/csf/">
<video autoplay="" loop="" muted="" playsinline="">
<source src="https://smoothbrains.net/images/random/estrogen/curve_shortening_flow.mp4" type="video/mp4">
</video>
</a>
<figcaption>
Demonstration of <a href="http://en.wikipedia.org/wiki/Curve-shortening_flow">curve-shortening flow</a>, from <a href="https://a.carapetis.com/csf/">Anthony Carapetis’ personal website</a>.
</figcaption>
</figure>
<p>Could this be related to the serotonergic activity? Might the estrogen be unwinding a lifetime of accumulated neuromuscular trauma through a form of low-dose psychedelic therapy? I suspect this effect is also responsible for my <a href="#emotional-modulation">changes in mood</a> – do emotions resonate more freely through a more parsimonious bodymind?</p>
<h3 id="estrogen-downregulates-autistic-sensory-sensitivity-issues"><a href="#estrogen-downregulates-autistic-sensory-sensitivity-issues">Estrogen downregulates autistic sensory sensitivity issues</a></h3>
<p>There’s a <a href="http://x.com/johnsonmxe">Mike Johnson</a> post I relate to, proposing a novel theory about <a href="https://en.wikipedia.org/wiki/Autism">autistic spectrum disorders</a>. From <a href="https://opentheory.net/2023/05/autism-as-a-disorder-of-dimensionality/">Autism as a disorder of dimensionality</a>:</p>
<blockquote>
<p>Every circuit has its own <a href="https://en.wikipedia.org/wiki/Hausdorff_dimension">natural density/dimensionality</a> it’s designed for, and my intuition is that organs closer to the brain are designed to have higher dimensionality. In some sense this makes them more capable of general processing, but also more prone to the particular deficits expressed in autism, with the brain as the apex of this hierarchy.</p>
<p>Over time, civilization has thrown humanity increasingly high-dimensional challenges, leading to evolution progressively ‘dialing the dimensionality knob up’ on our nervous systems. Perhaps we can view dysfunctional autists as those who overshot the human nervous system’s current ‘Goldilocks zone’ for dimensionality and have nervous systems dominated by static/turbulence as a result. There may be different ‘flavors’ of autism, depending on which brain regions and tissues have elevated dimensionality.</p>
</blockquote>
<!-- [Neuron Number and Size in Prefrontal Cortex of Children With Autism](https://jamanetwork.com/journals/jama/fullarticle/1104609) (Courchesne et al., 2011) -->
<p>When I read this some years ago, I had something of an <em>I’m in this picture and I don’t like it</em> moment. I don’t know that his theory is necessarily true, but I certainly felt that my own sensorium was <em>dominated by static/turbulence</em>.</p>
<figure>
<img src="https://smoothbrains.net/images/random/estrogen/lain_static.gif">
<figcaption>
Static is used as a recurring motif in the anime <a href="https://en.wikipedia.org/wiki/Serial_Experiments_Lain">Serial Experiments Lain</a>, in which it is strongly hinted that the protagonist experiences sensory sensitivities.
</figcaption>
</figure>
<p>As <a href="#somatic-perception">mentioned above</a>, I found that estrogen toned down my ongoing somatic sensitivities to more manageable levels – and there’s a handful of trans women I’ve spoken to who agreed with me that it turned the static down.</p>
<p>Autism tends to be <a href="https://www.cdc.gov/mmwr/volumes/74/ss/ss7402a1.htm">diagnosed more often in those assigned male at birth</a>, and there’s a fair amount of research into the <a href="https://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2024.1371148/full">links between hormone levels and neuroatypicality</a>. Some researchers have even <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5193073/#__ffn_sectitle">proposed estrogen as a therapeutic target</a> for autism spectrum disorders.</p>
<p>Additionally, as <a href="https://x.com/slatestarcodex">Scott Alexander</a> mentions in <a href="https://www.astralcodexten.com/p/why-do-transgender-people-report">Why Do Transgender People Report Hypermobile Joints?</a>, <a href="https://www.theatlantic.com/health/archive/2016/11/the-link-between-autism-and-trans-identity/507509/"><em>people with autism are about 8x more likely to be gender divergent than the general population</em></a>. Certainly this fits popular stereotypes of trans women, at least in my corner of the internet. Scott speculates:</p>
<blockquote>
<p>My guess is something like joint issues → poor proprioception → all sensory experience is noisy and confusing → the brain, which is embodied and spends most of its time trying to process sensory experience, learns a different reasoning style → different reasoning style is less context-dependent (producing symptoms of autism) → different reasoning style when trying to interpret bodily correlates of gender (eg sex hormones) → transgender.</p>
</blockquote>
<p>Personally, I don’t have any joint issues, and I think that his theory of dyphoria could be simpler than this. Perhaps autistic sensory sensitivities mean that the brain is constanly dealing with having to reject overly noisy sensory input, leading to a stressed out, overly tense, disembodied nervous system – and this is what ultimately manifests as dysphoria? However, this would only explain <em>sensory dysphoria</em>, and not <em>gender dysphoria</em>.</p>
<p>I also find that <a href="https://en.wikipedia.org/wiki/Ketogenic_diet">ketogenic dieting</a> helps with my sensory issues – as well as <a href="https://slatestarcodex.com/2019/07/18/know-your-gabapentinoids/">gabapentinoids like phenibut and pregabalin</a> – presumably by <em>reducing glutamatergic signalling</em>. Occasional <a href="https://opentheory.net/2019/11/neural-annealing-toward-a-neural-theory-of-everything/">neural annealing</a> through mild doses of <a href="https://psychonautwiki.org/wiki/Serotonergic_psychedelic">serotonergic psychedelics</a> is also quite helpful. It’s difficult to say whether it’s the glutamate or serotonin system which is the root cause, but perhaps estrogen is particularly effective because it delivers changes to both?</p>
<h3 id="estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal"><a href="#estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal">Estrogen can produce a psychological shift from autistic to schizotypal</a></h3>
<p>A couple of years ago <a href="https://x.com/ElytraMithra">Ely</a> recommended that I read the paper, <a href="https://journals.sagepub.com/doi/10.1177/17456916221075252">Autistic-Like Traits and Positive Schizotypy as Diametric Specializations of the Predictive Mind</a> (Andersen, 2022). It turned out to be the most interesting paper I read while writing this post. The author proposes that the archetypal behavioural traits observed in <a href="https://en.wikipedia.org/wiki/Autism"><em>autism</em></a> and <a href="https://en.wikipedia.org/wiki/Schizotypy"><em>schizotypy</em></a> – like variation in attentional modulation, theory of mind, and exploratory behaviour – are downstream from a fundamental <em>oversensitivity</em> or <em>undersensitivity</em> to sensory <a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/">prediction errors</a>, respectively:</p>
<blockquote>
<p>It has previously been argued that autism-spectrum conditions can be understood as resulting from a predictive-processing mechanism in which an inflexibly high weight is given to sensory-prediction errors that results in overfitting their predictive models to the world. Deficits in executive functioning, theory of mind, and central coherence are all argued to flow naturally from this core underlying mechanism.</p>
<p>The diametric model of autism and psychosis suggests a simple extension of this hypothesis. If people on the autism spectrum give an inflexibly high weight to sensory input, could it be that people with a predisposition to psychosis (i.e., people high in <em>positive schizotypy</em>) give an inflexibly <em>low</em> weight to sensory input?</p>
</blockquote>
<p>Andersen carefully describes the terms <em>autism</em> and <em>schizotypy</em> as he uses them in the paper, emphasizing that these categories should be viewed as flexible and not defined by dysfunction:</p>
<blockquote>
<p>In this article I refer to this axis as the <em>autism-schizotypy continuum</em>. For convenience, I refer to people on either end of this continuum as being an “autistic type” or a “schizotype”, although it should be understood that there are no clear-cut “types” and that these differences are continuous rather than categorical.</p>
<p>According to these models, everyone falls somewhere on the autism–schizotypy continuum, and neither autistic-like traits nor positive schizotypy represent dysfunction. Instead, each side of the continuum is accompanied by its own set of cognitive-perceptual strengths and weaknesses. People high in autistic-like traits are detail-oriented, have a focused attentional style that allows them to ignore distractors, have some advantages in sensory-discrimination abilities, and have highly developed systemizing skills, allowing them to learn and use complicated rules-based systems.</p>
<p>People high in positive schizotypy tend to be imaginative and creative and have a more diffuse attentional style (compared with the average person) that allows them to switch their attention more easily. There is also some evidence that people high in positive schizotypy tend to direct their attention toward highly abstract, “big-picture” concerns rather than focusing on details.</p>
</blockquote>
<p>Andersen proposes that in the case of schizotypy, lower sensitivity to prediction errors permits sensory input to flow further up the predictive processing hierarchy, which is what results in the observed behavioural traits:</p>
<blockquote>
<p>In autism, inflexibly high precision weighting of sensory input means that prediction matching tends to take place at relatively low levels of the processing hierarchy. Inflexibly low precision weighting of sensory input with positive schizotypy would have the opposite effect. Because the schizotype is, on average, handling fewer sensory-prediction errors than the autistic type (because they pay attention only to the large errors and ignore the smaller ones), prediction errors will tend to propagate farther up the processing hierarchy, affecting values, goals, and beliefs at higher levels of abstraction.</p>
</blockquote>
<p>At this stage, I had to ask myself if the hormone I’d been taking which seemed to reduce my symptoms of autism was doing so by reducing an inherent oversensitivity to prediction errors? If this was the case, might it also be pushing me further towards the other end of the <em>autism-schizotypy continuum</em>? What might that look like? The paper has this to say about schizotypal patterns of belief:</p>
<blockquote>
<p>Although the autistic type may rely more on culturally inherited high-level belief systems, the schizotype’s proclivity for tinkering with high-level priors may lead to the construction of relatively idiosyncratic high-level belief systems. In our own culture, this could manifest as having odd or (seemingly) unlikely beliefs about high-level causes. This may include beliefs in the paranormal, idiosyncratic religious beliefs (e.g., being “spiritual but not religious”), or believing conspiracy theories, all of which are associated with positive schizotypy.</p>
</blockquote>
<p>I’ll outline some of the psychological changes I’ve noticed in myself since starting estrogen. The term “schizo” is used very informally in today’s internet vernacular, making it difficult to discuss these concepts in a sensible manner – but if the reader is comfortable playing armchair psychologist, perhaps they can judge for themselves whether the following makes me more “schizo”:</p>
<ul>
<li>Increased predisposition towards <a href="https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(23)00094-3"><em>associative thinking</em></a>. Activities like tarot are more appealing.</li>
<li>Increased predisposition towards <a href="https://x.com/cube_flipper/status/1757637512682692991"><em>magical thinking</em></a>, leading to some idiosyncratic worldviews. This can probably be gauged by the <a href="https://x.com/cube_flipper/status/1800179966992400775">nonsense I post on Twitter</a>.</li>
<li>Increased experience of <a href="https://meaningness.com/"><em>meaningness</em></a> in day-to-day life. <a href="#emotional-modulation">This felt really good</a>.</li>
<li>Increased <em>mentalising</em> of other people’s internal states, resulting in a mixture of higher empathy and higher social anxiety. I’m somewhat more neurotic about potential threats.</li>
<li>Decreased <a href="#somatic-perception"><em>sensory sensitivity</em></a>.</li>
<li>Decreased <a href="#attentional-modulation"><em>attentional diffusion</em></a>, contrary to what the paper predicts.</li>
<li>Decreased <em>systematising</em> and <em>attention to detail</em>, for instance with tedious matters like finances.</li>
</ul>
<!--
<aside>
    Mind you, I was already kinda like this anyway.
</aside>
-->
<p>Armchair diagnoses aside, I do wish to assert that these psychological changes are quite similar to the kind of psychological changes I tend to experience while on a mild dose of psychedelics. So far as the pharmacology goes, there is an argument to be made that psychedelics induce a temporary state of psychosis via 5-HT2A agonism. From <a href="https://journals.sagepub.com/doi/full/10.1177/0269881120959637">Pivotal mental states</a> (Brouwer and Carhart-Harris, 2021):</p>
<blockquote>
<p>The psychotomimetic (psychosis-mimicking) effects of classic 5-HT2A receptor agonist psychedelics have been well documented. Importantly, psychedelics are felt to be useful models of <em>incipient</em> psychotic states that may be more likely to display psychedelic-like phenomena, such as changes in perception, cognition and ego functioning. Conversely, established psychotic disorders such as schizophrenia are more likely to feature characteristics of <em>rigid</em> cognition such as fixed delusions. Selective 5-HT2A receptor antagonism attenuates the main characteristic subjective effects of LSD, psilocybin and ayahuasca and the intensity of psychedelic states is reliably predicted by 5-HT2A receptor occupancy.</p>
</blockquote>
<p>It’s important to note that the authors are specifically discussing <em>psychosis</em> rather than <em>schizotypy</em>, and I couldn’t find any evidence that <em>schizotypy</em> involves 5-HT2A receptor signalling. That said, given the two are related, and given that estrogen <em>upregulates 5-HT2A receptor expression</em>, could estrogen be responsible for increased positive schizotypy via a similar mechanism to psychedelics?</p>
<!--
<aside>
The leading predictive processing based theory of psychedelic action, [REBUS and the Anarchic Brain: Toward a Unified
Model of the Brain Action of Psychedelics](https://pmc.ncbi.nlm.nih.gov/articles/PMC6588209/) ("Relaxed beliefs under psychedelics") (Carhart-Harris and Friston, 2019) implicates *loosened priors*, rather than *decreased sensitivity to prediction errors*. I'm not sure how to square these models
</aside>
-->
<!--
<aside>
Ely also recommended that I read [A Neuronal Model of Predictive Coding Accounting for the Mismatch Negativity](https://www.jneurosci.org/content/32/11/3665) (Wacongne et al., 2012). I haven't done so yet.
</aside>
-->
<hr>

<p>I’d like to review what I’ve claimed so far:</p>
<ul>
<li>Estrogen <em>upregulates NMDA receptor expression</em>, which may result in:
<ul>
<li><a href="#estrogen-is-like-the-opposite-of-ketamine">Decreased depersonalisation and derealisation</a></li>
</ul></li>
<li>Estrogen <em>upregulates 5-HT2A receptor expression</em>, which may result in:
<ul>
<li><a href="#estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time">Increased “psychedelic” phenomenology</a></li>
<li><a href="#estrogen-loosens-the-bodymind">Increased “bodymind” flexibility and sense of embodiment</a></li>
<li><a href="#estrogen-downregulates-autistic-sensory-sensitivity-issues">Decreased autistic traits</a></li>
<li><a href="#estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal">Increased schizotypal traits</a></li>
</ul></li>
</ul>
<p>First of all, I should note that I don’t expect these claims about estrogen phenomenology to generalise from trans women to cis women, and I’d also be cautious about generalizing neuroendocrinological findings from postmenopausal women to people starting from an androgenic baseline. <!-- Additionally, the neurological effects I've described may be buffered by other regulatory systems, given that estrogen acts several steps upstream in complex biological pathways. --> All this aside, I think this should be mostly sufficient to explain why estrogen might make somebody <em>feel good</em>, especially if they are predisposed to depersonalisation, disembodiment, or autistic sensory sensitivities. However, I don’t think we’re that much closer to understanding whether hormone replacement therapy is actually correcting some kind of <em>innate deficit</em>.</p>
<p>Innateness of gender identity is a difficult topic to discuss. Here we are in 2025, and different political factions are motivated to claim that <em>gender dysphoria</em> is either a <a href="https://genderdysphoria.fyi/en/causes"><em>genuine phenomenon</em></a> or <a href="https://x.com/cube_flipper/status/1909409074619543977"><em>just a delusion</em></a>. Theories abound, and one of the more colourful – and <em>confronting</em> – treatments of the topic was written by <a href="https://sinceriously.blog-mirror.com/">Ziz</a>… <a href="https://x.com/kenthecowboy_/status/1884393311827550716">who is currently in jail</a>. From <a href="https://sinceriously.blog-mirror.com/intersex-brains-and-conceptual-warfare/">Intersex Brains And Conceptual Warfare</a>:</p>
<blockquote>
<p>The simplest explanation which fits the data (including nonbrain intersex conditions) is that sexual differentiation is a fragile rube goldberg machine, prone to random breakage. I speculate that humans have intersex brains so often because of evolution pulling out all stops for large brains and breaking things as a side effect.</p>
</blockquote>
<p>Any honest public appraisal of the topic is likely to be clouded by politics, and given the current political climate, it seems unlikely that research may continue. Which is a shame, because I suspect research into <a href="https://www.nature.com/articles/s41598-020-72486-6">prenatal hormone exposure</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/34030966/">neuroanatomical variation</a>, and <a href="https://www.reddit.com/r/DrWillPowers/wiki/meyer-powers_syndrome_faq/">atypical endocrine signalling</a> are promising avenues of exploration.</p>
<p>While I don’t think people should have to convince the medical system of the validity of their internal experience in order to justify a hormone prescription – other people <em>do</em>, and I don’t think this is likely to change anytime soon. So I think this research is <em>important</em> – not least because this is an issue that directly affects an unusually productive and talented segment of society, many of whom I consider my friends.</p>

<h3 id="phenomenology-of-gender-dysphoria"><a href="#phenomenology-of-gender-dysphoria">Phenomenology of gender dysphoria</a></h3>
<p>Here’s how I’d like to thread the needle. Gender dysphoria occupies an unusual epistemic status within a society not known for <a href="https://cosmicindigestion.substack.com/p/around-here-we-take-our-phenomenology">taking phenomenology seriously</a>, because – at least in liberal spaces – people’s self reports are generally never questioned.</p>
<p>I’m not complaining – I don’t think this is a bad thing, even though I can be picky with my metaepistemics sometimes. What I would like to see is further development into phenomenological models of gender dysphoria. <a href="https://genderdysphoria.fyi/">Existing models</a> are already quite comprehensive, covering phenomena from high-level <a href="https://genderdysphoria.fyi/en/social-dysphoria"><em>social dysphoria</em></a> to low-level <a href="https://genderdysphoria.fyi/en/physical-dysphoria"><em>physical dysphoria</em></a> – but I think they could utilise <em>even more</em> detail, as it may provide essential clues to what’s going on.</p>
<figure>
<a href="https://www.ebmconsult.com/articles/homunculus-sensory-motor-cortex"><img src="https://smoothbrains.net/images/random/dmt/somatosensory_and_motor_homunculus.png"></a>
<figcaption>
The <a href="https://en.wikipedia.org/wiki/Primary_somatosensory_cortex">somatosensory cortex</a> is a long thin section of cortex which wraps around the brain like a headband. It is located just posterior to the <a href="https://en.wikipedia.org/wiki/Motor_cortex">motor cortex</a>, which follows a similar shape. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5830421/">Electrode studies on live humans</a> have revealed the shape of their respective homunculi.
</figcaption>
</figure>
<p>The low-level phenomenology of <a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">brain-body map mismatches</a> seems like a big part of the puzzle. There’s an old friend of mine, a loud-mouthed transman with a thick Queensland accent who swears up and down that he’s got a <em>fuckin’ ghost cock, mate</em>. Certainly the prevalence of phantom penises is <a href="https://www.researchgate.net/publication/348950276_Phantom_Penis_Extrapolating_Neuroscience_and_Employing_Imagination_for_Trans_Male_Sexual_Embodiment">well-documented in the literature</a>. What’s going on there? My understanding of the <a href="https://en.wikipedia.org/wiki/Cortical_homunculus">somatosensory homunculus</a> is that it can be quite <a href="https://smoothbrains.net/posts/2023-06-30-the-oral-tesseract.html">flexible with its representations</a>, so why might it persistently render a body corresponding to the opposite gender?</p>
<p>This wouldn’t be a <a href="https://smoothbrains.net/">smoothbrains.net</a> post if it didn’t have some nonsensical spitballing at the end. My usual psychedelic research requires me to entertain all kinds of metaphysical schizotheories – so I’m not averse to considering all kinds of theories of gender dysphoria, including ones incorporating <!-- [*body schemas*](https://x.com/cube_flipper/status/1702351420475990020) --> <a href="https://x.com/cube_flipper/status/1671342436294221826"><em>morphogenetic fields</em></a>, <a href="https://smoothbrains.net/posts/2024-05-29-what-is-a-bodymind-knot.html"><em>bodymind knots</em></a>, <a href="https://x.com/KanizsaBoundary/status/1809314763345908004"><em>past lives</em></a>, or even <a href="https://x.com/KanizsaBoundary/status/1808991203570209226"><em>vector field topology</em></a>.</p>
<p>Could it be the case that gender dysphoria is a morphic resonance phenomenon – and estrogen helps access the cosmic feminine unconscious by loading a different configuration file from the akashic records? <em>Who can say.</em> After all, if estrogen does make me more schizotypal… <em>why not lean into it</em>?</p>

<hr>
<h2 id="references"><a href="#references">References</a></h2>
<h4 id="hormone-replacement-therapy"><a href="#hormone-replacement-therapy">Hormone replacement therapy</a></h4>
<ul>
<li><a href="https://www.lesswrong.com/posts/KznQLLpDprpwqcAKD/gender-exploration">Gender Exploration</a> by <a href="https://www.lesswrong.com/users/deluks917">sapphire</a> on <a href="https://www.lesswrong.com/">LessWrong</a> (2024)</li>
<li><a href="https://transfemscience.org/articles/transfem-intro/">An Introduction to Hormone Therapy for Transfeminine People</a> by <a href="https://transfemscience.org/about/#aly">Aly</a> on <a href="https://transfemscience.org/">Transfeminine Science</a> (2024)</li>
</ul>
<h4 id="gender-dysphoria"><a href="#gender-dysphoria">Gender dysphoria</a></h4>
<ul>
<li><a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">Typical mind and gender identity</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://slatestarcodex.com/">Slate Star Codex</a> (2013)</li>
<li><a href="https://slatestarcodex.com/2017/06/28/why-are-transgender-people-immune-to-optical-illusions">Why Are Transgender People Immune To Optical Illusions</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://slatestarcodex.com/">Slate Star Codex</a> (2017)</li>
<li><a href="https://zinniajones.medium.com/trip-report-lamotrigine-a-drug-to-treat-depersonalization-e8171e165813">Trip report: Lamotrigine, a drug to treat depersonalization</a> by <a href="https://zinniajones.com/">Zinnia Jones</a> on <a href="https://zinniajones.medium.com/">Medium</a> (2018)</li>
<li><a href="https://sinceriously.blog-mirror.com/intersex-brains-and-conceptual-warfare/">Intersex Brains And Conceptual Warfare</a> by <a href="https://sinceriously.blog-mirror.com/author/Ziz/">Ziz</a> on <a href="https://sinceriously.blog-mirror.com/">Sinceriously</a> (2019)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/34030966/">The Neuroanatomy of Transgender Identity: Mega-Analytic Findings From the ENIGMA Transgender Persons Working Group</a> (Mueller et al., 2021)</li>
<li><a href="https://www.astralcodexten.com/p/why-do-transgender-people-report">Why Do Transgender People Report Hypermobile Joints?</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://www.astralcodexten.com/">Astral Codex Ten</a> (2023)</li>
</ul>
<h4 id="autism-and-schizotypy"><a href="#autism-and-schizotypy">Autism and schizotypy</a></h4>
<ul>
<li><a href="https://opentheory.net/2023/05/autism-as-a-disorder-of-dimensionality/">Autism as a disorder of dimensionality</a> by <a href="http://x.com/johnsonmxe">Mike Johnson</a> on <a href="https://opentheory.net/">opentheory.net</a></li>
<li><a href="https://journals.sagepub.com/doi/10.1177/17456916221075252">Autistic-Like Traits and Positive Schizotypy as Diametric Specializations of the Predictive Mind</a> (Andersen, 2022)</li>
</ul>
<h4 id="estrogen"><a href="#estrogen">Estrogen</a></h4>
<ul>
<li><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00037/full">Sex hormones affect neurotransmitters and shape the adult female brain during hormonal transition periods</a> (Barth et al., 2015)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/33396472/">The Role of Estrogen Receptors and Their Signaling across Psychiatric Disorders</a> (Hwang et al., 2020)</li>
<li><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1348551/full">The impact of estradiol on serotonin, glutamate, and dopamine systems</a> (Bendis et al., 2024)</li>
<li><a href="https://www.reddit.com/r/DrWillPowers/wiki/meyer-powers_syndrome_faq/">Meyer-Powers Syndrome FAQ</a> by <a href="https://www.reddit.com/user/Drwillpowers/">Dr.&nbsp;Will Powers</a> on <a href="https://www.reddit.com/r/DrWillPowers/">r/DrWillPowers</a> (2025)</li>
</ul>
<h4 id="estrogen-and-the-glutamate-system"><a href="#estrogen-and-the-glutamate-system">Estrogen and the glutamate system</a></h4>
<ul>
<li><a href="https://academic.oup.com/endo/article-abstract/131/2/662/2496261">Estradiol selectively regulates agonist binding sites on the N-methyl-D-aspartate receptor complex in the CA1 region of the hippocampus</a> (Weiland, 1992)</li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6740259/">Effects of estrogen and progesterone treatment on rat hippocampal NMDA receptors: Relationship to Morris water maze performance</a> (El-Bakri et al., 2004)</li>
</ul>
<h4 id="estrogen-and-the-serotonin-system"><a href="#estrogen-and-the-serotonin-system">Estrogen and the serotonin system</a></h4>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/096007609500075B">Estrogen increases the density of 5-Hydroxytryptamine<sub>2A</sub> receptors in cerebral cortex and nucleus accumbens in the female rat</a> (Sumner and Fink, 1995)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/12900319/">Increase in Prefrontal Cortex Serotonin 2A Receptors Following Estrogen Treatment in Postmenopausal Women</a> (Kugaya et al., 2003)</li>
<li><a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext">Widespread increases of cortical serotonin type 2A receptor availability after hormone therapy in euthymic postmenopausal women</a> (Moses-Kolko et al., 2003)</li>
</ul>
<h4 id="the-serotonin-system"><a href="#the-serotonin-system">The serotonin system</a></h4>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/28858536/">Serotonin and brain function: a tale of two receptors</a> (Carhart-Harris and Nutt, 2017)</li>
<li><a href="https://journals.sagepub.com/doi/10.1177/0269881120959637">Pivotal mental states</a> (Brouwer and Carhart-Harris, 2021)</li>
<li><a href="https://academic.oup.com/brain/article-abstract/147/1/56/7273051">A role for the serotonin 2A receptor in the expansion and functioning of human transmodal cortex</a> (Luppi et al., 2024)</li>
</ul>
    </section>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compiling LLMs into a MegaKernel: A path to low-latency inference (267 pts)]]></title>
            <link>https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17</link>
            <guid>44321672</guid>
            <pubDate>Thu, 19 Jun 2025 19:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17">https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17</a>, See on <a href="https://news.ycombinator.com/item?id=44321672">Hacker News</a></p>
Couldn't get https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Juneteenth in Photos (215 pts)]]></title>
            <link>https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</link>
            <guid>44320851</guid>
            <pubDate>Thu, 19 Jun 2025 17:41:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/">https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=44320851">Hacker News</a></p>
Couldn't get https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[In praise of "normal" engineers (147 pts)]]></title>
            <link>https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</link>
            <guid>44320806</guid>
            <pubDate>Thu, 19 Jun 2025 17:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/">https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</a>, See on <a href="https://news.ycombinator.com/item?id=44320806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><em>This article was originally <a href="https://refactoring.fm/p/in-praise-of-normal-engineers">commissioned by Luca Rossi</a> (paywalled) for refactoring.fm, on February 11th, 2025. Luca edited a version of it that emphasized the importance of building “10x engineering teams” . It was later picked up by IEEE Spectrum (!!!), who scrapped most of the teams content and published a <a href="https://spectrum.ieee.org/10x-engineer">different, shorter piece</a> on March 13th.</em></p>
<p><em>This is my personal edit. It is not exactly identical to either of the versions that have been publicly released to date. It contains a lot of the source material for the talk I gave last week at #LDX3 in London, “<a href="https://speakerdeck.com/charity/in-praise-of-normal-engineers-ldx3">In Praise of ‘Normal’ Engineers</a>” (slides), and a couple weeks ago at CraftConf.&nbsp;</em></p>

<p>Most of us have encountered a few engineers who seem practically magician-like, a class apart from the rest of us in their ability to reason about complex mental models, leap to non-obvious yet elegant solutions, or emit waves of high quality code at unreal velocity.<img data-recalc-dims="1" decoding="async" data-attachment-id="10015" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-praise-black-squish/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="In Praise of “Normal” Engineers" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=174%2C174&amp;ssl=1" alt="In Praise of &quot;Normal&quot; Engineers" width="174" height="174" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 174px) 100vw, 174px"></p>
<p>I have run into any number of these incredible beings over the course of my career. I think this is what explains the curious durability of the “10x engineer” meme. It may be based on flimsy, shoddy research, and the claims people have made to defend it have often been&nbsp;risible (e.g. “10x engineers have dark backgrounds, are rarely seen doing UI work, are poor mentors and interviewers”), or blatantly double down on stereotypes (“we look for young dudes in hoodies that remind us of Mark Zuckerberg”). But damn if it doesn’t resonate with experience. It just feels true.</p>
<p>The problem is not the idea that there are engineers who are 10x as productive as other engineers. I don’t have a problem with this statement; in fact, that much seems self-evidently true. The problems I do have are twofold.</p>
<h2>Measuring productivity is fraught and imperfect</h2>
<p>First: how are you measuring productivity? I have a problem with the implication that there is One True Metric of productivity that you can standardize and sort people by. Consider, for a moment, the sheer combinatorial magnitude of skills and experiences at play:</p>
<ul>
<li>Are you working on microprocessors, IoT, database internals, web services, user experience, mobile apps, consulting, embedded systems, cryptography, animation, training models for gen AI… what?</li>
<li>Are you using golang, python, COBOL, lisp, perl, React, or brainfuck? What version, which libraries, which frameworks, what data models? What other software and build dependencies must you have mastered?<img data-recalc-dims="1" decoding="async" data-attachment-id="10009" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-rainbow-black/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-rainbow-black" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=173%2C173&amp;ssl=1" alt="" width="173" height="173" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 173px) 100vw, 173px"></li>
<li>What adjacent skills, market segments, or product subject matter expertise are you drawing upon…design, security, compliance, data visualization, marketing, finance, etc?</li>
<li>What stage of development? What scale of usage? What matters most — giving good advice in a consultative capacity, prototyping rapidly to find product-market fit, or writing code that is maintainable and performant over many years of amortized maintenance? Or are you writing for the Mars Rover, or shrinkwrapped software you can never change?</li>
</ul>
<p>Also: people and their skills and abilities are not static. At one point, I was a pretty good DBRE (I even co-wrote the book on it). Maybe I was even a 10x DB engineer then, but certainly not now. I haven’t debugged a query plan in years.</p>
<p>“10x engineer” makes it sound like 10x productivity is an immutable characteristic of a person. But someone who is a 10x engineer in a particular skill set is still going to have infinitely more areas where they are normal or average (or less). I know a lot of world class engineers, but I’ve never met anyone who is 10x better than everyone else across the board, in every situation.</p>
<h2>Engineers don’t own software, teams own software</h2>
<p>Second, and even more importantly: So what? It doesn’t matter. Individual engineers don’t own software, teams own software. <strong>The smallest unit of software ownership and delivery is the engineering team</strong>. It doesn’t matter how fast an individual engineer can write software, what matters is how fast the team can collectively write, test, review, ship, maintain, refactor, extend, architect, and revise the software that they own.</p>
<p>Everyone uses the same software delivery pipeline. If it takes the slowest engineer at your company five hours to ship a single line of code, it’s going to take the fastest engineer at your company five hours to ship a single line of code. The time spent writing code is typically dwarfed by the time spent on every other part of the software development lifecycle.</p>
<p>If you have services or software components that are owned by a single engineer, that person is a single point of failure.<img data-recalc-dims="1" fetchpriority="high" decoding="async" data-attachment-id="10013" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-spof/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-spof" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=226%2C226&amp;ssl=1" alt="" width="226" height="226" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 226px) 100vw, 226px"></p>
<p>I’m not saying this should never happen. It’s quite normal at startups to have individuals owning software, because the biggest existential risk that you face is not moving fast enough, not finding product market fit, and going out of business. But as you start to grow up as a company, as users start to demand more from you, and you start planning for the survival of the company to extend years into the future…ownership needs to get handed over to a team. Individual engineers get sick, go on vacation, and leave the company, and the business has got to be resilient to that.</p>
<p>If teams own software, then the key job of any engineering leader is to craft high-performing engineering teams. If you must 10x something, 10x this. <strong>Build 10x engineering teams.</strong></p>
<h2>The best engineering orgs are the ones where normal engineers can do great work</h2>
<p>When people talk about world-class engineering orgs, they often have in mind teams that are top-heavy with staff and principal engineers, or recruiting heavily from the ranks of ex-FAANG employees or top universities.</p>
<p>But I would argue that a truly great engineering org is one where you don’t HAVE to be one of the “best” or most pedigreed engineers in the world to get shit done and have a lot of impact on the business.</p>
<p>I think it’s actually the other way around. A truly great engineering organization is one where perfectly normal, workaday software engineers, with decent software engineering skills and an ordinary amount of expertise, can consistently move fast, ship code, respond to users, understand the systems they’ve built, and move the business forward a little bit more, day by day, week by week.</p>
<p>Any asshole can build an org where the most experienced, brilliant engineers in the world can build product and make progress. That is not hard. And putting all the spotlight on individual ability has a way of letting your leaders off the hook for doing their jobs. It is a HUGE competitive advantage if you can build sociotechnical systems where less experienced engineers can convert their effort and energy into product and business momentum.</p>
<p>A truly great engineering org also happens to be one that mints world-class software engineers. But we’re getting ahead of ourselves, here.</p>
<h2>Let’s talk about “normal” for a moment</h2>
<p>A lot of technical people got really attached to our identities as smart kids. The software industry tends to reflect and reinforce this preoccupation at every turn, from Netflix’s “we look for the top 10% of global talent” to Amazon’s talk about “bar-raising” or Coinbase’s recent claim to “hire the top .1%”. (Seriously, guys? Ok, well, Honeycomb is going to hire only the top <em>.00001%</em>!)</p>
<p>In this essay, I would like to challenge us to set that baggage to the side and think about ourselves as <em>normal people</em>.</p>
<p>It can be humbling to think of ourselves as normal people, but most of us are in fact pretty normal people (albeit with many years of highly specialized practice and experience), and<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10011" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-made-not-born/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-made-not-born" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=264%2C264&amp;ssl=1" alt="" width="264" height="264" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 264px) 100vw, 264px"> there is <em>nothing wrong with that</em>. Even those of us who are certified geniuses on certain criteria are likely quite normal in other ways — kinesthetic, emotional, spatial, musical, linguistic, etc.</p>
<p>Software engineering both selects for and develops certain types of intelligence, particularly around abstract reasoning, but <em>nobody</em> is born a great software engineer. <strong>Great engineers are made, not born</strong>. I just don’t think there’s a lot more we can get out of thinking of ourselves as a special class of people, compared to the value we can derive from thinking of ourselves collectively as relatively normal people who have practiced a fairly niche craft for a very long time.</p>
<h2>Build sociotechnical systems with “normal people” in mind</h2>
<p>When it comes to hiring talent and building teams, yes, absolutely, we should focus on identifying the ways people are exceptional and talented and strong. But when it comes to building sociotechnical systems for software delivery, we should focus on all the ways people are <em>normal</em>.</p>
<h4><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=122%2C122&amp;ssl=1" alt="" width="122" height="122" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 122px) 100vw, 122px"></h4>
<p>Normal people have cognitive biases — confirmation bias, recency bias, hindsight bias. We work hard, we care, and we do our best; but we also forget things, get impatient, and zone out. Our eyes are inexorably drawn to the color red (unless we are colorblind). We develop habits and ways of doing things, and resist changing them. When we see the same text block repeatedly, we stop reading it.</p>
<p>We are embodied beings who can get overwhelmed and fatigued. If an alert wakes us up at 3 am, we are much more likely to make mistakes while responding to that alert than if we tried to do the same thing at 3pm. Our emotional state can affect the quality of our work. Our relationships impact our ability to get shit done.</p>
<p>When your systems are designed to be used by normal engineers, all that excess brilliance they have can get poured into the product itself, instead of wasting it on navigating the system itself.</p>
<h2>How do you turn normal engineers into 10x engineering teams?</h2>
<p>None of this should be terribly surprising; it’s all well known wisdom. In order to build the kind of sociotechnical systems for software delivery that enable normal engineers to move fast, learn continuously, and deliver great results as a team, you should:</p>
<h4>Shrink the interval between when you write the code and when the code goes live.</h4>
<p>Make it as short as possible; the shorter the better. I’ve written and given talks about this many, many times. The shorter the interval, the lower the cognitive carrying costs. The faster you can iterate, the better. The more of your brain can go into the product instead of the process of building it.</p>
<p>One of the most powerful things you can do is have a short, fast enough deploy cycle that you can ship one commit per deploy. I’ve referred to this as the “software engineering death spiral” … when the deploy cycle takes so long that you end up batching together a bunch of engineers’ diffs in every build. The slower it gets, the more you batch up, and the harder it becomes to figure out what happened or roll back. The longer it takes, the more people you need, the higher the coordination costs, and the more slowly everyone moves.</p>
<p>Deploy time is the feedback loop at the heart of the development process. It is almost impossible to overstate the centrality of keeping this short and tight.</p>
<h4>Make it easy and fast to roll back or recover from mistakes.</h4>
<p>Developers should be able to deploy their own code, figure out if it’s working as intended or not, and if not, roll forward or back swiftly and easily. No muss, no fuss, no thinking involved.</p>
<h4>Make it easy to do the right thing and hard to do the wrong thing. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10018" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-sparkles/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-sparkles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=137%2C137&amp;ssl=1" alt="" width="137" height="137" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 137px) 100vw, 137px"></h4>
<p>Wrap designers and design thinking into all the touch points your engineers have with production systems. Use your platform engineering team to think about how to empower people to swiftly make changes and self-serve, but also remember that a lot of times people will be engaging with production late at night or when they’re very stressed, tired, and&nbsp;possibly freaking out. Build guard rails. The fastest way to ship a single line of code should also be the easiest way to ship a single line of code.</p>
<h4>Invest in instrumentation and observability.</h4>
<p>You’ll never know — not really — what the code you wrote does just by reading it. The only way to be sure is by instrumenting your code and watching real users run it in production. Good, friendly sociotechnical systems invest <em>heavily</em> in tools for sense-making.</p>
<p>Being able to visualize your work is what makes engineering abstractions accessible to actual engineers. You shouldn’t have to be a world-class engineer just to debug your own damn code.</p>
<h4>Devote engineering cycles to internal tooling and enablement.</h4>
<p>If fast, safe deploys, with guard rails, instrumentation, and highly parallelized test suites are “everybody’s job”, they will end up nobody’s job. Engineering productivity isn’t something you can outsource. Managing the interfaces between your software vendors and your own teams is both a science and an art. Making it look easy and intuitive is really hard. It needs an owner.</p>
<h4>Build an inclusive culture.</h4>
<p>Growth is the norm, growth is the baseline. People do their best work when they feel a sense of belonging. An inclusive culture is one where everyone feels safe to ask questions, explore, and make mistakes; where everyone is held to the same high standard, and given the support and encouragement they need to achieve their goals.</p>
<h4>Diverse teams are resilient teams.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=196%2C196&amp;ssl=1" alt="" width="196" height="196" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 196px) 100vw, 196px"></h4>
<p>Yeah, a team of super-senior engineers who all share a similar background can move incredibly fast, but a monoculture is fragile. Someone gets sick, someone gets pregnant, you start to grow and you need to integrate people from other backgrounds and the whole team can get derailed — fast.</p>
<p>When your teams are used to operating with a mix of genders, racial backgrounds, identities, age ranges, family statuses, geographical locations, skill sets, etc — when this is just table stakes, standard operating procedure — you’re better equipped to roll with it when life happens.</p>
<h4>Assemble engineering teams from a range of levels.</h4>
<p>The best engineering teams aren’t top-heavy with staff engineers and principal engineers. The best engineering teams are ones where nobody is running on autopilot, banging out a login page for the 300th time; everyone is working on something that challenges them and pushes their boundaries. Everyone is learning, everyone is teaching, everyone is pushing their own boundaries and growing. All the time.</p>
<p>By the way — all of that work you put into making your systems resilient, well-designed, and humane is the same work you would need to do to help onboard new engineers, develop junior talent, or let engineers move between teams.</p>
<p>It gets used and reused. Over and over and over again.</p>
<h2>The only meaningful measure of productivity is impact to the business</h2>
<p>The only thing that actually matters when it comes to engineering productivity is whether or not you are moving the business materially forward.</p>
<p>Which means…we can’t do this in a vacuum. The most important question is whether or not we are working on the right thing, which is a problem engineering can’t answer without help from product, design, and the rest of the business.</p>
<p>Software engineering isn’t about writing lots of lines of code, it’s about solving business problems using technology.</p>
<p>Senior and intermediate engineers are actually the workhorses of the industry. They move the business forward, step by step, day by day. They get to put their heads down and crank instead of constantly looking around the org and solving coordination problems. If you have to be a staff+ engineer to move the product forward, something is seriously wrong.</p>
<h2>Great engineering orgs mint world-class engineers</h2>
<p>A great engineering org is one where you don’t HAVE to be one of the best engineers in the world to have a lot of impact. But — rather ironically — great engineering orgs mint world class engineers like nobody’s business.</p>
<p>The best engineering orgs are not the ones with the smartest, most experienced people in the world, they’re the ones where normal software engineers can consistently make progress, deliver value to users, and move the business forward, day after day.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10019" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-system-does/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-system-does" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=253%2C253&amp;ssl=1" alt="" width="253" height="253" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 253px) 100vw, 253px"></p>
<p>Places where engineers can get shit done and have a lot of impact are a magnet for top performers. Nothing makes engineers happier than building things, solving problems, making progress.</p>
<p>If you’re lucky enough to have world-class engineers in your org, good for you! Your role as a leader is to leverage their brilliance for the good of your customers and your other engineers, without coming to depend on their brilliance. After all, these people don’t belong to you. They may walk out the door at any moment, and that has to be okay.</p>
<p>These people can be phenomenal assets, assuming they can be team players and keep their egos in check. Which is probably why so many tech companies seem to obsess over identifying and hiring them, especially in Silicon Valley.</p>
<p>But companies categorically overindex on finding these people after they’ve already been minted, which ends up reinforcing and replicating all the prejudices and inequities of the world at large. Talent may be evenly distributed across populations, but opportunity is not.</p>
<h2>Don’t hire the “best” people. Hire the right people.</h2>
<p>We (by which I mean the entire human race) place too much emphasis on individual agency and characteristics, and not enough on the systems that shape us and inform our behaviors.</p>
<p>I feel like a whole slew of issues (candidates self-selecting out of the interview process, diversity of applicants, etc) would be improved simply by shifting the focus on engineering hiring and interviewing away from this inordinate emphasis on hiring the BEST PEOPLE and realigning around the more reasonable and accurate RIGHT PEOPLE. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10023" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-hire/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-hire" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=182%2C182&amp;ssl=1" alt="" width="182" height="182" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 182px) 100vw, 182px"></p>
<p>It’s a competitive advantage to build an environment where people can be hired for their unique strengths, not their lack of weaknesses; where the emphasis is on composing teams rather than hiring the BEST people; where inclusivity is a given both for ethical reasons and&nbsp;because it raises the bar for performance for everyone. Inclusive culture is what actual meritocracy depends on.</p>
<p>This is the kind of place that engineering talent (and good humans) are drawn to like a moth to a flame. <strong>It feels good to ship</strong>. It feels <em>good</em> to move the business forward. It feels <em>good</em> to sharpen your skills and improve your craft. It’s the kind of place that people go when they want to become world class engineers. And it’s the kind of place where world class engineers want to stick around, to train up the next generation.</p>
<p>&lt;3, charity</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: EnrichMCP – A Python ORM for Agents (119 pts)]]></title>
            <link>https://github.com/featureform/enrichmcp</link>
            <guid>44320772</guid>
            <pubDate>Thu, 19 Jun 2025 17:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/featureform/enrichmcp">https://github.com/featureform/enrichmcp</a>, See on <a href="https://news.ycombinator.com/item?id=44320772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">EnrichMCP</h2><a id="user-content-enrichmcp" aria-label="Permalink: EnrichMCP" href="#enrichmcp"></a></p>
<p dir="auto"><strong>The ORM for AI Agents - Turn your data model into a semantic MCP layer</strong></p>
<p dir="auto"><a href="https://github.com/featureform/enrichmcp/actions/workflows/ci.yml"><img src="https://github.com/featureform/enrichmcp/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://codecov.io/gh/featureform/enrichmcp" rel="nofollow"><img src="https://camo.githubusercontent.com/7855073cf4372a4aceef8ff09904a532a0f7c9e5fe32ae01099e0acd39de873a/68747470733a2f2f636f6465636f762e696f2f67682f66656174757265666f726d2f656e726963686d63702f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/featureform/enrichmcp/branch/main/graph/badge.svg"></a>
<a href="https://pypi.org/project/enrichmcp/" rel="nofollow"><img src="https://camo.githubusercontent.com/eb717e44a9bca52f6bba59058aaee7ffb7d1117a378af677b2e15712e355594c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f656e726963686d63702e737667" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/enrichmcp.svg"></a>
<a href="https://www.python.org/downloads/" rel="nofollow"><img src="https://camo.githubusercontent.com/1e5852941fcfe768cdba62e1ef6b1db0d9c87c4f9017432c39ad06853f6d4df9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31312b2d626c75652e737667" alt="Python 3.11+" data-canonical-src="https://img.shields.io/badge/python-3.11+-blue.svg"></a>
<a href="https://github.com/featureform/enrichmcp/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/c355f200ea90fddaa407b6eaab303663a669248ea3ca7b1fcf77dbe04ff5f48c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-Apache%202.0-blue.svg"></a></p>
<p dir="auto">EnrichMCP is a Python framework that helps AI agents understand and navigate your data. Built on MCP (Model Context Protocol), it adds a semantic layer that turns your data model into typed, discoverable tools - like an ORM for AI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is EnrichMCP?</h2><a id="user-content-what-is-enrichmcp" aria-label="Permalink: What is EnrichMCP?" href="#what-is-enrichmcp"></a></p>
<p dir="auto">Think of it as SQLAlchemy for AI agents. EnrichMCP automatically:</p>
<ul dir="auto">
<li><strong>Generates typed tools</strong> from your data models</li>
<li><strong>Handles relationships</strong> between entities (users → orders → products)</li>
<li><strong>Provides schema discovery</strong> so AI agents understand your data structure</li>
<li><strong>Validates all inputs/outputs</strong> with Pydantic models</li>
<li><strong>Works with any backend</strong> - databases, APIs, or custom logic</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install enrichmcp

# With SQLAlchemy support
pip install enrichmcp[sqlalchemy]"><pre>pip install enrichmcp

<span><span>#</span> With SQLAlchemy support</span>
pip install enrichmcp[sqlalchemy]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Show Me Code</h2><a id="user-content-show-me-code" aria-label="Permalink: Show Me Code" href="#show-me-code"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: I Have SQLAlchemy Models (30 seconds)</h3><a id="user-content-option-1-i-have-sqlalchemy-models-30-seconds" aria-label="Permalink: Option 1: I Have SQLAlchemy Models (30 seconds)" href="#option-1-i-have-sqlalchemy-models-30-seconds"></a></p>
<p dir="auto">Transform your existing SQLAlchemy models into an AI-navigable API:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP
from enrichmcp.sqlalchemy import include_sqlalchemy_models, sqlalchemy_lifespan, EnrichSQLAlchemyMixin
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship

engine = create_async_engine(&quot;postgresql+asyncpg://user:pass@localhost/db&quot;)

# Add the mixin to your declarative base
class Base(DeclarativeBase, EnrichSQLAlchemyMixin):
    pass

class User(Base):
    __tablename__ = &quot;users&quot;

    id: Mapped[int] = mapped_column(primary_key=True)
    email: Mapped[str] = mapped_column(unique=True)
    status: Mapped[str] = mapped_column(default=&quot;active&quot;)
    orders: Mapped[list[&quot;Order&quot;]] = relationship(back_populates=&quot;user&quot;)

class Order(Base):
    __tablename__ = &quot;orders&quot;

    id: Mapped[int] = mapped_column(primary_key=True)
    user_id: Mapped[int] = mapped_column(ForeignKey(&quot;users.id&quot;))
    total: Mapped[float] = mapped_column()
    user: Mapped[User] = relationship(back_populates=&quot;orders&quot;)

# That's it! Create your MCP app
app = EnrichMCP(
    &quot;E-commerce Data&quot;,
    lifespan=sqlalchemy_lifespan(Base, engine, cleanup_db_file=True),
)
include_sqlalchemy_models(app, Base)

if __name__ == &quot;__main__&quot;:
    app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>
<span>from</span> <span>enrichmcp</span>.<span>sqlalchemy</span> <span>import</span> <span>include_sqlalchemy_models</span>, <span>sqlalchemy_lifespan</span>, <span>EnrichSQLAlchemyMixin</span>
<span>from</span> <span>sqlalchemy</span>.<span>ext</span>.<span>asyncio</span> <span>import</span> <span>create_async_engine</span>
<span>from</span> <span>sqlalchemy</span>.<span>orm</span> <span>import</span> <span>DeclarativeBase</span>, <span>Mapped</span>, <span>mapped_column</span>, <span>relationship</span>

<span>engine</span> <span>=</span> <span>create_async_engine</span>(<span>"postgresql+asyncpg://user:pass@localhost/db"</span>)

<span># Add the mixin to your declarative base</span>
<span>class</span> <span>Base</span>(<span>DeclarativeBase</span>, <span>EnrichSQLAlchemyMixin</span>):
    <span>pass</span>

<span>class</span> <span>User</span>(<span>Base</span>):
    <span>__tablename__</span> <span>=</span> <span>"users"</span>

    <span>id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>primary_key</span><span>=</span><span>True</span>)
    <span>email</span>: <span>Mapped</span>[<span>str</span>] <span>=</span> <span>mapped_column</span>(<span>unique</span><span>=</span><span>True</span>)
    <span>status</span>: <span>Mapped</span>[<span>str</span>] <span>=</span> <span>mapped_column</span>(<span>default</span><span>=</span><span>"active"</span>)
    <span>orders</span>: <span>Mapped</span>[<span>list</span>[<span>"Order"</span>]] <span>=</span> <span>relationship</span>(<span>back_populates</span><span>=</span><span>"user"</span>)

<span>class</span> <span>Order</span>(<span>Base</span>):
    <span>__tablename__</span> <span>=</span> <span>"orders"</span>

    <span>id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>primary_key</span><span>=</span><span>True</span>)
    <span>user_id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>ForeignKey</span>(<span>"users.id"</span>))
    <span>total</span>: <span>Mapped</span>[<span>float</span>] <span>=</span> <span>mapped_column</span>()
    <span>user</span>: <span>Mapped</span>[<span>User</span>] <span>=</span> <span>relationship</span>(<span>back_populates</span><span>=</span><span>"orders"</span>)

<span># That's it! Create your MCP app</span>
<span>app</span> <span>=</span> <span>EnrichMCP</span>(
    <span>"E-commerce Data"</span>,
    <span>lifespan</span><span>=</span><span>sqlalchemy_lifespan</span>(<span>Base</span>, <span>engine</span>, <span>cleanup_db_file</span><span>=</span><span>True</span>),
)
<span>include_sqlalchemy_models</span>(<span>app</span>, <span>Base</span>)

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>app</span>.<span>run</span>()</pre></div>
<p dir="auto">AI agents can now:</p>
<ul dir="auto">
<li><code>explore_data_model()</code> - understand your entire schema</li>
<li><code>list_users(status='active')</code> - query with filters</li>
<li><code>get_user(id=123)</code> - fetch specific records</li>
<li>Navigate relationships: <code>user.orders</code> → <code>order.user</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: I Have REST APIs (2 minutes)</h3><a id="user-content-option-2-i-have-rest-apis-2-minutes" aria-label="Permalink: Option 2: I Have REST APIs (2 minutes)" href="#option-2-i-have-rest-apis-2-minutes"></a></p>
<p dir="auto">Wrap your existing APIs with semantic understanding:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP, EnrichModel, Relationship
from pydantic import Field

app = EnrichMCP(&quot;API Gateway&quot;)

@app.entity
class Customer(EnrichModel):
    &quot;&quot;&quot;Customer in our CRM system.&quot;&quot;&quot;

    id: int = Field(description=&quot;Unique customer ID&quot;)
    email: str = Field(description=&quot;Primary contact email&quot;)
    tier: str = Field(description=&quot;Subscription tier: free, pro, enterprise&quot;)

    # Define navigable relationships
    orders: list[&quot;Order&quot;] = Relationship(description=&quot;Customer's purchase history&quot;)

@app.entity
class Order(EnrichModel):
    &quot;&quot;&quot;Customer order from our e-commerce platform.&quot;&quot;&quot;

    id: int = Field(description=&quot;Order ID&quot;)
    customer_id: int = Field(description=&quot;Associated customer&quot;)
    total: float = Field(description=&quot;Order total in USD&quot;)
    status: str = Field(description=&quot;Order status: pending, shipped, delivered&quot;)

    customer: Customer = Relationship(description=&quot;Customer who placed this order&quot;)

# Define how to fetch data
@app.resource
async def get_customer(customer_id: int) -> Customer:
    &quot;&quot;&quot;Fetch customer from CRM API.&quot;&quot;&quot;
    response = await http.get(f&quot;/api/customers/{customer_id}&quot;)
    return Customer(**response.json())

# Define relationship resolvers
@Customer.orders.resolver
async def get_customer_orders(customer_id: int) -> list[Order]:
    &quot;&quot;&quot;Fetch orders for a customer.&quot;&quot;&quot;
    response = await http.get(f&quot;/api/customers/{customer_id}/orders&quot;)
    return [Order(**order) for order in response.json()]

app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>, <span>EnrichModel</span>, <span>Relationship</span>
<span>from</span> <span>pydantic</span> <span>import</span> <span>Field</span>

<span>app</span> <span>=</span> <span>EnrichMCP</span>(<span>"API Gateway"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Customer</span>(<span>EnrichModel</span>):
    <span>"""Customer in our CRM system."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Unique customer ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Primary contact email"</span>)
    <span>tier</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Subscription tier: free, pro, enterprise"</span>)

    <span># Define navigable relationships</span>
    <span>orders</span>: <span>list</span>[<span>"Order"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Customer's purchase history"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Order</span>(<span>EnrichModel</span>):
    <span>"""Customer order from our e-commerce platform."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order ID"</span>)
    <span>customer_id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Associated customer"</span>)
    <span>total</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order total in USD"</span>)
    <span>status</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order status: pending, shipped, delivered"</span>)

    <span>customer</span>: <span>Customer</span> <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Customer who placed this order"</span>)

<span># Define how to fetch data</span>
<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>get_customer</span>(<span>customer_id</span>: <span>int</span>) <span>-&gt;</span> <span>Customer</span>:
    <span>"""Fetch customer from CRM API."""</span>
    <span>response</span> <span>=</span> <span>await</span> <span>http</span>.<span>get</span>(<span>f"/api/customers/<span><span>{</span><span>customer_id</span><span>}</span></span>"</span>)
    <span>return</span> <span>Customer</span>(<span>**</span><span>response</span>.<span>json</span>())

<span># Define relationship resolvers</span>
<span>@<span>Customer</span>.<span>orders</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>get_customer_orders</span>(<span>customer_id</span>: <span>int</span>) <span>-&gt;</span> <span>list</span>[<span>Order</span>]:
    <span>"""Fetch orders for a customer."""</span>
    <span>response</span> <span>=</span> <span>await</span> <span>http</span>.<span>get</span>(<span>f"/api/customers/<span><span>{</span><span>customer_id</span><span>}</span></span>/orders"</span>)
    <span>return</span> [<span>Order</span>(<span>**</span><span>order</span>) <span>for</span> <span>order</span> <span>in</span> <span>response</span>.<span>json</span>()]

<span>app</span>.<span>run</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: I Want Full Control (5 minutes)</h3><a id="user-content-option-3-i-want-full-control-5-minutes" aria-label="Permalink: Option 3: I Want Full Control (5 minutes)" href="#option-3-i-want-full-control-5-minutes"></a></p>
<p dir="auto">Build a complete data layer with custom logic:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP, EnrichModel, Relationship, EnrichContext
from datetime import datetime
from decimal import Decimal

app = EnrichMCP(&quot;Analytics Platform&quot;)

@app.entity
class User(EnrichModel):
    &quot;&quot;&quot;User with computed analytics fields.&quot;&quot;&quot;

    id: int = Field(description=&quot;User ID&quot;)
    email: str = Field(description=&quot;Contact email&quot;)
    created_at: datetime = Field(description=&quot;Registration date&quot;)

    # Computed fields
    lifetime_value: Decimal = Field(description=&quot;Total revenue from user&quot;)
    churn_risk: float = Field(description=&quot;ML-predicted churn probability 0-1&quot;)

    # Relationships
    orders: list[&quot;Order&quot;] = Relationship(description=&quot;Purchase history&quot;)
    segments: list[&quot;Segment&quot;] = Relationship(description=&quot;Marketing segments&quot;)

@app.entity
class Segment(EnrichModel):
    &quot;&quot;&quot;Dynamic user segment for marketing.&quot;&quot;&quot;

    name: str = Field(description=&quot;Segment name&quot;)
    criteria: dict = Field(description=&quot;Segment criteria&quot;)
    users: list[User] = Relationship(description=&quot;Users in this segment&quot;)

# Complex resource with business logic
@app.resource
async def find_high_value_at_risk_users(
    lifetime_value_min: Decimal = 1000,
    churn_risk_min: float = 0.7,
    limit: int = 100
) -> list[User]:
    &quot;&quot;&quot;Find valuable customers likely to churn.&quot;&quot;&quot;
    users = await db.query(
        &quot;&quot;&quot;
        SELECT * FROM users
        WHERE lifetime_value >= ? AND churn_risk >= ?
        ORDER BY lifetime_value DESC
        LIMIT ?
        &quot;&quot;&quot;,
        lifetime_value_min, churn_risk_min, limit
    )
    return [User(**u) for u in users]

# Async computed field resolver
@User.lifetime_value.resolver
async def calculate_lifetime_value(user_id: int) -> Decimal:
    &quot;&quot;&quot;Calculate total revenue from user's orders.&quot;&quot;&quot;
    total = await db.query_single(
        &quot;SELECT SUM(total) FROM orders WHERE user_id = ?&quot;,
        user_id
    )
    return Decimal(str(total or 0))

# ML-powered field
@User.churn_risk.resolver
async def predict_churn_risk(user_id: int, context: EnrichContext) -> float:
    &quot;&quot;&quot;Run churn prediction model.&quot;&quot;&quot;
    features = await gather_user_features(user_id)
    model = context.get(&quot;ml_models&quot;)[&quot;churn&quot;]
    return float(model.predict_proba(features)[0][1])

app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>, <span>EnrichModel</span>, <span>Relationship</span>, <span>EnrichContext</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>
<span>from</span> <span>decimal</span> <span>import</span> <span>Decimal</span>

<span>app</span> <span>=</span> <span>EnrichMCP</span>(<span>"Analytics Platform"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>User</span>(<span>EnrichModel</span>):
    <span>"""User with computed analytics fields."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"User ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Contact email"</span>)
    <span>created_at</span>: <span>datetime</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Registration date"</span>)

    <span># Computed fields</span>
    <span>lifetime_value</span>: <span>Decimal</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Total revenue from user"</span>)
    <span>churn_risk</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"ML-predicted churn probability 0-1"</span>)

    <span># Relationships</span>
    <span>orders</span>: <span>list</span>[<span>"Order"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Purchase history"</span>)
    <span>segments</span>: <span>list</span>[<span>"Segment"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Marketing segments"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Segment</span>(<span>EnrichModel</span>):
    <span>"""Dynamic user segment for marketing."""</span>

    <span>name</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Segment name"</span>)
    <span>criteria</span>: <span>dict</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Segment criteria"</span>)
    <span>users</span>: <span>list</span>[<span>User</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Users in this segment"</span>)

<span># Complex resource with business logic</span>
<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>find_high_value_at_risk_users</span>(
    <span>lifetime_value_min</span>: <span>Decimal</span> <span>=</span> <span>1000</span>,
    <span>churn_risk_min</span>: <span>float</span> <span>=</span> <span>0.7</span>,
    <span>limit</span>: <span>int</span> <span>=</span> <span>100</span>
) <span>-&gt;</span> <span>list</span>[<span>User</span>]:
    <span>"""Find valuable customers likely to churn."""</span>
    <span>users</span> <span>=</span> <span>await</span> <span>db</span>.<span>query</span>(
        <span>"""</span>
<span>        SELECT * FROM users</span>
<span>        WHERE lifetime_value &gt;= ? AND churn_risk &gt;= ?</span>
<span>        ORDER BY lifetime_value DESC</span>
<span>        LIMIT ?</span>
<span>        """</span>,
        <span>lifetime_value_min</span>, <span>churn_risk_min</span>, <span>limit</span>
    )
    <span>return</span> [<span>User</span>(<span>**</span><span>u</span>) <span>for</span> <span>u</span> <span>in</span> <span>users</span>]

<span># Async computed field resolver</span>
<span>@<span>User</span>.<span>lifetime_value</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>calculate_lifetime_value</span>(<span>user_id</span>: <span>int</span>) <span>-&gt;</span> <span>Decimal</span>:
    <span>"""Calculate total revenue from user's orders."""</span>
    <span>total</span> <span>=</span> <span>await</span> <span>db</span>.<span>query_single</span>(
        <span>"SELECT SUM(total) FROM orders WHERE user_id = ?"</span>,
        <span>user_id</span>
    )
    <span>return</span> <span>Decimal</span>(<span>str</span>(<span>total</span> <span>or</span> <span>0</span>))

<span># ML-powered field</span>
<span>@<span>User</span>.<span>churn_risk</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>predict_churn_risk</span>(<span>user_id</span>: <span>int</span>, <span>context</span>: <span>EnrichContext</span>) <span>-&gt;</span> <span>float</span>:
    <span>"""Run churn prediction model."""</span>
    <span>features</span> <span>=</span> <span>await</span> <span>gather_user_features</span>(<span>user_id</span>)
    <span>model</span> <span>=</span> <span>context</span>.<span>get</span>(<span>"ml_models"</span>)[<span>"churn"</span>]
    <span>return</span> <span>float</span>(<span>model</span>.<span>predict_proba</span>(<span>features</span>)[<span>0</span>][<span>1</span>])

<span>app</span>.<span>run</span>()</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔍 Automatic Schema Discovery</h3><a id="user-content--automatic-schema-discovery" aria-label="Permalink: 🔍 Automatic Schema Discovery" href="#-automatic-schema-discovery"></a></p>
<p dir="auto">AI agents explore your entire data model with one call:</p>
<div dir="auto" data-snippet-clipboard-copy-content="schema = await explore_data_model()
# Returns complete schema with entities, fields, types, and relationships"><pre><span>schema</span> <span>=</span> <span>await</span> <span>explore_data_model</span>()
<span># Returns complete schema with entities, fields, types, and relationships</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔗 Relationship Navigation</h3><a id="user-content--relationship-navigation" aria-label="Permalink: 🔗 Relationship Navigation" href="#-relationship-navigation"></a></p>
<p dir="auto">Define relationships once, AI agents traverse naturally:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# AI can navigate: user → orders → products → categories
user = await get_user(123)
orders = await user.orders()  # Automatic resolver
products = await orders[0].products()"><pre><span># AI can navigate: user → orders → products → categories</span>
<span>user</span> <span>=</span> <span>await</span> <span>get_user</span>(<span>123</span>)
<span>orders</span> <span>=</span> <span>await</span> <span>user</span>.<span>orders</span>()  <span># Automatic resolver</span>
<span>products</span> <span>=</span> <span>await</span> <span>orders</span>[<span>0</span>].<span>products</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🛡️ Type Safety &amp; Validation</h3><a id="user-content-️-type-safety--validation" aria-label="Permalink: 🛡️ Type Safety &amp; Validation" href="#️-type-safety--validation"></a></p>
<p dir="auto">Full Pydantic validation on every interaction:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.entity
class Order(EnrichModel):
    total: float = Field(ge=0, description=&quot;Must be positive&quot;)
    email: EmailStr = Field(description=&quot;Customer email&quot;)
    status: Literal[&quot;pending&quot;, &quot;shipped&quot;, &quot;delivered&quot;]"><pre><span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Order</span>(<span>EnrichModel</span>):
    <span>total</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>ge</span><span>=</span><span>0</span>, <span>description</span><span>=</span><span>"Must be positive"</span>)
    <span>email</span>: <span>EmailStr</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Customer email"</span>)
    <span>status</span>: <span>Literal</span>[<span>"pending"</span>, <span>"shipped"</span>, <span>"delivered"</span>]</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">✏️ Mutability &amp; CRUD</h3><a id="user-content-️-mutability--crud" aria-label="Permalink: ✏️ Mutability &amp; CRUD" href="#️-mutability--crud"></a></p>
<p dir="auto">Fields are immutable by default. Mark them as mutable and use
auto-generated patch models for updates:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.entity
class Customer(EnrichModel):
    id: int = Field(description=&quot;ID&quot;)
    email: str = Field(mutable=True, description=&quot;Email&quot;)

@app.create
async def create_customer(email: str) -> Customer:
    ...

@app.update
async def update_customer(cid: int, patch: Customer.PatchModel) -> Customer:
    ...

@app.delete
async def delete_customer(cid: int) -> bool:
    ..."><pre><span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Customer</span>(<span>EnrichModel</span>):
    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>mutable</span><span>=</span><span>True</span>, <span>description</span><span>=</span><span>"Email"</span>)

<span>@<span>app</span>.<span>create</span></span>
<span>async</span> <span>def</span> <span>create_customer</span>(<span>email</span>: <span>str</span>) <span>-&gt;</span> <span>Customer</span>:
    ...

<span>@<span>app</span>.<span>update</span></span>
<span>async</span> <span>def</span> <span>update_customer</span>(<span>cid</span>: <span>int</span>, <span>patch</span>: <span>Customer</span>.<span>PatchModel</span>) <span>-&gt;</span> <span>Customer</span>:
    ...

<span>@<span>app</span>.<span>delete</span></span>
<span>async</span> <span>def</span> <span>delete_customer</span>(<span>cid</span>: <span>int</span>) <span>-&gt;</span> <span>bool</span>:
    ...</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">📄 Pagination Built-in</h3><a id="user-content--pagination-built-in" aria-label="Permalink: 📄 Pagination Built-in" href="#-pagination-built-in"></a></p>
<p dir="auto">Handle large datasets elegantly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import PageResult

@app.resource
async def list_orders(
    page: int = 1,
    page_size: int = 50
) -> PageResult[Order]:
    orders, total = await db.get_orders_page(page, page_size)
    return PageResult.create(
        items=orders,
        page=page,
        page_size=page_size,
        total_items=total
    )"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>PageResult</span>

<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>list_orders</span>(
    <span>page</span>: <span>int</span> <span>=</span> <span>1</span>,
    <span>page_size</span>: <span>int</span> <span>=</span> <span>50</span>
) <span>-&gt;</span> <span>PageResult</span>[<span>Order</span>]:
    <span>orders</span>, <span>total</span> <span>=</span> <span>await</span> <span>db</span>.<span>get_orders_page</span>(<span>page</span>, <span>page_size</span>)
    <span>return</span> <span>PageResult</span>.<span>create</span>(
        <span>items</span><span>=</span><span>orders</span>,
        <span>page</span><span>=</span><span>page</span>,
        <span>page_size</span><span>=</span><span>page_size</span>,
        <span>total_items</span><span>=</span><span>total</span>
    )</pre></div>
<p dir="auto">See the <a href="https://featureform.github.io/enrichmcp/pagination" rel="nofollow">Pagination Guide</a> for more examples.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔐 Context &amp; Authentication</h3><a id="user-content--context--authentication" aria-label="Permalink: 🔐 Context &amp; Authentication" href="#-context--authentication"></a></p>
<p dir="auto">Pass auth, database connections, or any context:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.resource
async def get_user_profile(user_id: int, context: EnrichContext) -> UserProfile:
    # Access context provided by MCP client
    auth_user = context.get(&quot;authenticated_user_id&quot;)
    if auth_user != user_id:
        raise PermissionError(&quot;Can only access your own profile&quot;)
    return await db.get_profile(user_id)"><pre><span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>get_user_profile</span>(<span>user_id</span>: <span>int</span>, <span>context</span>: <span>EnrichContext</span>) <span>-&gt;</span> <span>UserProfile</span>:
    <span># Access context provided by MCP client</span>
    <span>auth_user</span> <span>=</span> <span>context</span>.<span>get</span>(<span>"authenticated_user_id"</span>)
    <span>if</span> <span>auth_user</span> <span>!=</span> <span>user_id</span>:
        <span>raise</span> <span>PermissionError</span>(<span>"Can only access your own profile"</span>)
    <span>return</span> <span>await</span> <span>db</span>.<span>get_profile</span>(<span>user_id</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why EnrichMCP?</h2><a id="user-content-why-enrichmcp" aria-label="Permalink: Why EnrichMCP?" href="#why-enrichmcp"></a></p>
<p dir="auto">EnrichMCP adds three critical layers on top of MCP:</p>
<ol dir="auto">
<li><strong>Semantic Layer</strong> - AI agents understand what your data means, not just its structure</li>
<li><strong>Data Layer</strong> - Type-safe models with validation and relationships</li>
<li><strong>Control Layer</strong> - Authentication, pagination, and business logic</li>
</ol>
<p dir="auto">The result: AI agents can work with your data as naturally as a developer using an ORM.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Check out the <a href="https://github.com/featureform/enrichmcp/blob/main/examples/README.md">examples directory</a>:</p>
<ul dir="auto">
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/hello_world">hello_world</a> - The smallest possible EnrichMCP app</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api">shop_api</a> - In-memory shop API with pagination and filters</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api_sqlite">shop_api_sqlite</a> - SQLite-backed version</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api_gateway">shop_api_gateway</a> - EnrichMCP as a gateway in front of FastAPI</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/sqlalchemy_shop">sqlalchemy_shop</a> - Auto-generated API from SQLAlchemy models</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<ul dir="auto">
<li>📖 <a href="https://featureform.github.io/enrichmcp" rel="nofollow">Full Documentation</a></li>
<li>🚀 <a href="https://featureform.github.io/enrichmcp/getting-started" rel="nofollow">Getting Started Guide</a></li>
<li>🔧 <a href="https://featureform.github.io/enrichmcp/api" rel="nofollow">API Reference</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions! See <a href="https://github.com/featureform/enrichmcp/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache 2.0 - See <a href="https://github.com/featureform/enrichmcp/blob/main/LICENSE">LICENSE</a></p>
<hr>
<p dir="auto">Built by <a href="https://featureform.com/" rel="nofollow">Featureform</a> • <a href="https://modelcontextprotocol.io/" rel="nofollow">MCP Protocol</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why do we need DNSSEC? (104 pts)]]></title>
            <link>https://howdnssec.works/why-do-we-need-dnssec/</link>
            <guid>44320497</guid>
            <pubDate>Thu, 19 Jun 2025 17:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://howdnssec.works/why-do-we-need-dnssec/">https://howdnssec.works/why-do-we-need-dnssec/</a>, See on <a href="https://news.ycombinator.com/item?id=44320497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div>
    
    <p>Good question! Why do we need DNSSEC?</p>
    <p><img src="https://howdnssec.works/public/images/ep1/1.svg" alt="Good question! Why do we need DNSSEC?" draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>DNS was created the Internet was tiny small.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/2.svg" alt="DNS was created the Internet was tiny small." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Security was not a primary concern in its design.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/3.svg" alt="Security was not a primary concern in its design." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Simply put, DNS main job is to translate human-friendly names to IP addresses needed by your laptop, phones, and other network devices.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/4.svg" alt="Simply put, DNS main job is to translate human-friendly names to IP addresses needed by your laptop, phones, and other network devices." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>DNS is like a big phone book that your devices use to fetch you a website, or deliver your emails.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/5.svg" alt="DNS is like a big phone book that your devices use to fetch you a website, or deliver your emails." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p><strong>DNS resolvers</strong> are the ones in charge of tracking down this information for you.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/6.svg" alt="**DNS resolvers** are the ones in charge of tracking down this information for you." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>And that data is often provided by <strong>authoritative servers</strong>.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/7.svg" alt="And that data is often provided by **authoritative servers**." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>But DNS resolvers have no way to verify the authenticity of a response from an authoritative server.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/8.svg" alt="But DNS resolvers have no way to verify the authenticity of a response from an authoritative server." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>What if the response has been tampered with?</p>
    <p><img src="https://howdnssec.works/public/images/ep1/9.svg" alt="What if the response has been tampered with?" draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>This is where <strong>DNSSEC</strong> comes in.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/10.svg" alt="This is where **DNSSEC** comes in." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Resolvers? Authoritative name servers? What are all these things? Check out <a href="https://howdns.works/" target="_blank"><strong>HowDNS.works</strong></a> for a refresher and come back here.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/11.svg" alt="Resolvers? Authoritative name servers? What are all these things? Check out <a href='https://howdns.works' target='_blank'>**HowDNS.works**</a> for a refresher and come back here." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>I’ll be waiting.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/12.svg" alt="I'll be waiting." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>DNSSEC is short for Domain Name System Security Extensions.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/13.svg" alt="DNSSEC is short for Domain Name System Security Extensions." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Like HTTPS, DNSSEC provides a layer of security by allowing authenticated answers on top of DNS.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/14.svg" alt="Like HTTPS, DNSSEC provides a layer of security by allowing authenticated answers on top of DNS." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>However, there is a important difference.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/15.svg" alt="However, there is a important difference." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>HTTPS encrypts traffic so no crabs can spy on your data.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/16.svg" alt="HTTPS encrypts traffic so no crabs can spy on your data." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p><strong>DNSSEC signs DNS data</strong> to detect that no crabs have been messing with your DNS responses.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/17.svg" alt="**DNSSEC signs DNS data** to detect that no crabs have been messing with your DNS responses." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Bad crab. Bad.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/18.svg" alt="Bad crab. Bad." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>DNSSEC doesn't include full encryption like HTTPS does.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/19.svg" alt="DNSSEC doesn't include full encryption like HTTPS does." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>The data is not kept confidential and secret between the resolver and the authoritative server.</p>
    <p><img src="https://howdnssec.works/public/images/ep1/20.svg" alt="The data is not kept confidential and secret between the resolver and the authoritative server." draggable="false" loading="lazy">
  </p></div>
  <div>
    
    <p>Let’s dig a bit deeper into DNSSEC. Ready?</p>
    <p><img src="https://howdnssec.works/public/images/ep1/21.svg" alt="Let's dig a bit deeper into DNSSEC. Ready?" draggable="false" loading="lazy">
  </p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How OpenElections uses LLMs (107 pts)]]></title>
            <link>https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html</link>
            <guid>44320001</guid>
            <pubDate>Thu, 19 Jun 2025 16:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html">https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44320001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
  

<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">





<p>In the 12-plus years that we’ve been turning official precinct election results into data at <a href="https://github.com/openelections">OpenElections</a>, the single biggest problem has been converting pictures of results into CSV files. Many of the precinct results files we get are image PDFs, and for those there are essentially two options: data entry or Optical Character Recognition. The former has some advantages, but not many. While most people are not great at manual repetitive tasks, you can improve with lots of practice, to the point where the results are very accurate. In the past we did pay for data entry services, and while we developed working relationships with two individuals in particular, the results almost always contained some mistakes and the cost could run into the hundreds of dollars pretty quickly. For a volunteer project, it just didn’t make sense.</p>
<p>We also used commercial OCR software, most often Able2Extract, which did pretty well, but had a harder time with PDFs that had markings or were otherwise difficult to parse. Thankfully, most election results PDFs are in one of a small handful of formats, which makes things a bit less complicated, but commercial OCR has too many restrictions.</p>
<p>For parsing image PDFs into CSV files, Google’s Gemini is my model of choice, for two main reasons. First, the results are usually very, very accurate (with a few caveats I’ll detail below), and second, Gemini’s large context window means it’s possible to work with PDF files that can be multiple MBs in size. Here are some examples using image PDFs from Texas counties of how OpenElections uses Gemini for its work.</p>
<section id="limestone-county">
<h3 data-anchor-id="limestone-county">Limestone County</h3>
<p>The Limestone County file containing its 2024 general election results isn’t too bad for an image PDF:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/limestone.png" width="800"></p>
</figure>
</div>
<p>It has clear black text on a white background without markings. But two big issues make it hard for most OCR software to deal with: the two-column layout, with results from races on the left and the right; and those annoying dots between the end of candidate values and the vote totals. It’s like a delimited layout within a fixed-width layout. If you use OCR software, generally you have to draw the boxes around areas of PDFs like this in order to make the extraction results usable. <a href="https://github.com/openelections/openelections-sources-tx/blob/master/2024/general/2024%20Limestone%20County%2C%20TX%20precinct-level%20results.pdf">This PDF</a> isn’t too large at 42 pages, but that’s still a fair bit of manual labor to get the results, and even then there would be some cleanup required.</p>
<p>This is where good LLMs should be able to make a difference, because what you want is high-quality OCR results <em>and</em> the ability to provide some domain or business logic to the process without having to do it all yourself. You can see from <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221vZq4hi_eCqR58TkuzqPugDcOc2kE1tms%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">this Google Gemini session</a> that I didn’t have to provide much in the way of instructions after giving an example of the CSV output and some basic office standardization, just “The results are split into two columns on each page; parse the left column first and then the right column.”</p>
<p>How did Gemini do? Pretty well, almost perfectly. The numbers are accurate, according to some spot checks of candidate totals from <a href="https://results.texas-election.com/county">the Texas Secretary of State website</a>. It did make some formatting mistakes; removing a blank column in some of the Registered Voters and Ballots Cast rows, for example. But that’s a quick fix, and the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__limestone__precinct.csv">finished result</a> is exactly what we need. It’s easy to be impressed, but it’s also just 42 pages and had a simple format.</p>
</section>
<section id="live-oak-county">
<h3 data-anchor-id="live-oak-county">Live Oak County</h3>
<p>The PDF with results from Live Oak County comes in a common format that features a green background. But Live Oak’s image PDF is a black and white scan with different variations of shading, plus we don’t want the four columns containing percentages. For commercial OCR software, this would be a real problem thanks to the layout alone. Indeed, for electronic PDFs that are produced using the same software, we’ve got <a href="https://github.com/openelections/openelections-data-tx/blob/master/python-parsers/greenbox.py">a Python script that converts the PDF to text and parses it into a CSV file</a>. But this one is different:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/live_oak.png" width="800"></p>
</figure>
</div>
<p>The <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221gLcHgzgEkJsJYe8q1FeBjR9vBy55C8gb%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">prompt to convert this 90-page image PDF</a> is like the first one: an example tailored to the first set of results and the unusual placement of the registered voters and ballots cast figures. Gemini repeated the earlier mistake of removing a blank column from the Registered Voters and Ballots Cast rows, but otherwise was spot on in its accuracy. Here’s the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__live_oak__precinct.csv">fixed CSV result</a>.</p>
</section>
<section id="cameron-county">
<h3 data-anchor-id="cameron-county">Cameron County</h3>
<p>One of the areas where LLMs, even Gemini, can struggle with is sustained processes. Converting a few or a few dozen pages is usually pretty simple work for high-performing models, but what about hundreds of pages? <a href="https://github.com/openelections/openelections-sources-tx/blob/master/2024/general/2024%20Cameron%20County%2C%20TX%20precinct-level%20results.pdf">Cameron County’s PDF</a>, all 11.7 MB of it, offers a good challenge, and not just owing to its size:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/cameron.png" width="800"></p>
</figure>
</div>
<p>Notice how the “Precinct 16” is slightly obscured by an actual punch-hole in this document, and the same is true at the bottom of the image with “Overvotes” and “Undervotes”. Both of those issues could trip up commercial OCR engines. Providing an example of the output, as in the Limestone example, should help fill those literal holes, along with further instructions to ignore the <code>VOTE %</code> column entirely. The first attempt at parsing the 653-page PDF eventually “worked” in that it produced a CSV file. But I had to urge Gemini to “continue” multiple times, and it appeared to need more attention starting about halfway through. Most important, the vote figures in the CSV file were close, but not always correct. Back to the drawing board.</p>
<p>The <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221-Wiq7tYnEC12-TOckMUja1EyUp_lJ_bQ%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">process that generated an accurate CSV file</a> involved splitting the single PDF into multiple parts of about 100 pages each and feeding them one at a time to Gemini. That did mean copying and pasting the output, and one drawback of providing a lot of information in one session was that some of the offices didn’t get quoted properly in the CSV file (to be fair, this probably wouldn’t matter if I were using Gemini’s structured output feature). That meant a little bit of clean-up work, but again, the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__cameron__precinct.csv">end result</a> is an accurate precinct results file in about an hour. From a 653-page image PDF, with no data entry.</p>
<p>Could other models do similar work? Probably so, especially for smaller PDFs. But there are couple of other things that make Gemini the first choice for this: its <a href="https://aistudio.google.com/">AI Studio</a> UI allows me to turn the temperature down to 0 (less creativity) and, for models where the “thinking mode” is optional, the ability to disable it if the task at hand is pretty straight-forward. In the six weeks since we started working on Texas precinct results, we’ve been able to convert them for more than half of the state’s 254 counties, including many image PDFs like the ones on display here. That pace simply wouldn’t be possible with data entry or traditional OCR software.</p>
<p>Speed isn’t the most important factor here, though: accuracy is, and using LLMs still means a system of checks to ensure that the results are what the originals say they are. One step in that is taken care of by a suite of tests that run every time a new or changed CSV gets pushed to one of our data repositories. Those tests look for some formatting issues, duplicate records and basic math inconsistencies. A second step - for now manual - is verifying that multiple totals derived from the precinct CSV match the numbers in an official cumulative report <a href="https://www.co.live-oak.tx.us/upload/page/1218/2024/Entered%20By%20Bec/official%20cumulative%20results.pdf">like this one from Live Oak County</a>. A better version of that could also involve using LLMs to produce both cumulative and precinct-level data, but that would raise the possibility that a model makes similar mistakes in different documents. If you have ideas, head over to <a href="https://github.com/openelections">our GitHub organization</a> and get involved.</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
    </channel>
</rss>