<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 21 Apr 2025 11:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Pope Francis has died (218 pts)]]></title>
            <link>https://www.bbc.co.uk/news/live/crknlnzlrzdt</link>
            <guid>43749449</guid>
            <pubDate>Mon, 21 Apr 2025 08:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/live/crknlnzlrzdt">https://www.bbc.co.uk/news/live/crknlnzlrzdt</a>, See on <a href="https://news.ycombinator.com/item?id=43749449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" data-testid="main-content"><div><div><ul role="tablist"><li role="presentation" selected=""><a role="tab" id="tab-LiveReporting" href="#LiveReporting" tabindex="0" aria-selected="false">Live Reporting</a></li><li role="presentation"><a role="tab" id="tab-Watch&amp;listen" href="#Watch&amp;listen" tabindex="0" aria-selected="false">Watch &amp; listen</a></li></ul></div><div width="300" role="tabpanel" aria-labelledby="tab-LiveReporting" id="LiveReporting" tabindex="-1"><div id="summaryPoints"><h2 type="section-heading">Summary</h2><div spacing="4" data-testid="test-election-component-editorial-text"><ul role="list"><li><p>Pope Francis has died aged 88, <a href="https://www.bbc.co.uk/news/live/crknlnzlrzdt?post=asset%3Add577a2c-b3e1-442e-b2aa-5906bfee7d25#post">the Vatican says</a></p></li><li><p>The Pope, who was the first Latin American leader of the Roman Catholic Church, died at 07:35 local time on Easter Monday</p></li><li><p><a href="https://www.bbc.co.uk/news/live/crknlnzlrzdt?post=asset%3A27b7f460-4410-4471-981a-9c036501db1e#post">World leaders pay tribute</a> to his "contagious smile" and "boundless compassion", with French President Emmanuel Macron calling him <a href="https://www.bbc.co.uk/news/live/crknlnzlrzdt?post=asset%3A92a15719-ca32-4aa1-98e6-8428debecfec#post">a "man of humility"</a></p></li><li><p>His death comes a day after <a href="https://www.bbc.co.uk/news/live/crknlnzlrzdt?post=asset%3A4afaa8db-62fb-44cd-8311-c214bb734290#post">he appeared in St Peter's Square</a> to wish "Happy Easter" to thousands of worshippers</p></li><li><p>He was recently discharged from hospital last month after five weeks of treatment for an infection</p></li><li><p>Francis's death sets in motion the centuries-old process of <a href="https://www.bbc.co.uk/news/articles/c70q0980224o">electing a new Pope</a></p></li></ul></div></div><div data-testid="component-wrapper" role="group" aria-label="Key Highlight media"><figure><figcaption><span>Media caption, </span><p>Watch BBC's religion editor Aleem Maqbool on the life of the late Pope</p></figcaption></figure></div><div><div data-testid="byline-wrapper"><h2 type="section-heading">Live Reporting</h2><p>Edited by Thomas Spender and Jack Burgess</p></div><div data-testid="stream-container"><ol role="list" spacing="6" tabindex="0" data-testid="postList"><li><div><article data-testid="content-post" id="asset:3381edbb-7a31-4556-9512-7297b8b9acb0"><header><span><h3 type="normal"><span role="text"><span>UK politicians pay tribute to Pope's leadership</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:29 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Kemi Badenoch delivering a speech" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/fb939c72-5344-4f89-ab07-2b450f08073d.jpg.webp 800w" width="1879" height="1057"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Conservative leader Kemi Badenoch met the Pope in 2022</p></figcaption></figure><p>The leaders of UK political parties have praised Pope Francis's courage and leadership.</p><p>Conservative leader <b>Kemi Badenoch</b> pays tribute to the pontiff's "humility, courage and conviction".</p><p>Leader of the Liberal Democrats, <b>Sir Ed Davey</b>, calls Pope Francis a "leader of compassion and courage".</p><p>Reform UK leader <b>Nigel Farage</b> says his "sympathies go out to all in the Catholic Church".</p><p>Welsh First Minister <b>Eluned Morgan</b> praises the late Pope's "example of compassionate leadership".</p><p>Scottish First Minister <b>John Swinney</b> says the Pope "brought comfort, assurance and hope".</p><p>We haven't heard from the UK Prime Minister Sir Keir Starmer, or King Charles III yet, but we'll let you know as soon as we hear from them.</p></article></div></li><li><div><article data-testid="content-post" id="asset:7f667ccd-41bc-4c7a-8acc-d9718faad944"><header><span><h3 type="normal"><span role="text"><span>Health issues clouded the Pope's final months</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:21 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="The Pope gives the thumbs up from a balcony at his hospital in Rome." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/ac9c35d7-f1fa-4199-8c2c-71103117e692.jpg.webp 800w" width="887" height="499"></span><span role="text"><span>Image source, </span>EPA</span></p></figure><p>In the final months of his life, the Pope's ill-health saw him spend several weeks in hospital.</p><p>On 14 February, the 88-year-old was taken to the Gemelli hospital in Rome to be treated for pneumonia in both lungs. He had experienced difficulties breathing for several days.</p><p>He was discharged from hospital on 23 March.</p><p>The pontiff was particularly susceptible to pneumonia, which is an infection of the lungs that can be caused by bacteria, viruses or fungi, after undergoing a partial lung removal as a young man.</p></article></div></li><li><div><article data-testid="content-post" id="asset:767e821b-a9f1-4745-9666-f6367213e6dc"><header><span><h3 type="normal"><span role="text"><span>'My heart goes out': JD Vance pays tribute day after meeting Pope Francis</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:16 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><figure><p><span><img alt="JD Vance and Pope." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/690f942f-58b7-4cd2-8af7-670cb1766b53.jpg.webp 800w" width="948" height="533"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>US Vice-President JD Vance had a brief meeting Pope Francis yesterday</p></figcaption></figure><p>US Vice-President JD Vance says he has just learned of the passing of Pope Francis.</p><p>He adds: "My heart goes out to the millions of Christians all over the world who loved him."</p><p>Vance arrived in Rome on Friday and on Saturday met Vatican officials.</p><p>He also had a brief private meeting with the Pope. </p></article></div></li><li><div><article data-testid="content-post" id="asset:fdf6cc53-18d6-4abc-9431-32f30664a17b"><header><span><h3 type="normal"><span role="text"><span>'A good, warm and sensitive man' - tributes continue to pour in for Pope Francis</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:13 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Ursula von der Leyen and the Pope" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/3d5f59e8-064b-4366-b266-50538c7840b1.jpg.webp 800w" width="882" height="496"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>Ursula von der Leyen, chief of the European Commission, says her thoughts are with all who feel this profound loss</p></figcaption></figure><p>We can bring you some more reaction now from leaders around the world:</p><ul><li spacing="rich-text"><b>European Commission President Ursula von der Leyen</b> says "he inspired millions, far beyond the Catholic Church, with his humility and love so pure for the less fortunate"
    </li><li spacing="rich-text"><b>India's Prime Minister Narendra Modi</b> says he is "deeply pained" by the passing of Pope Francis
    </li><li spacing="rich-text"><b>Polish Prime Minister Donald Tusk</b> remembers Pope Francis as a "good, warm and sensitive man"
    </li><li spacing="rich-text"><b>Egypt's President Abdul Fattah al-Sisi </b>says Pope Francis "was a voice of peace, love and compassion"
    </li></ul></article></div></li><li><div><article data-testid="content-post" id="asset:55d32dd5-6500-427d-b937-98ad1d882a4f"><header><span><h3 type="normal"><span role="text"><span>Pope Francis's rise from Buenos Aires to Catholic Church leader</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:01 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Pope Francis in red robes as he sits while cardinals look at him" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/5c5a96c8-dae2-4345-9cb3-47fa0dfe006e.jpg.webp 800w" width="976" height="549"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Pope Francis was born Jorge Mario Bergoglio, in Buenos Aires, Argentina, on 17 December 1936.</p><p>The eldest of five children, his parents had fled their native Italy to escape the evils of fascism.  </p><p>He enjoyed tango dancing and became a supporter of his local football club, San Lorenzo.</p><p>He was lucky to escape with his life after a serious bout of pneumonia, undergoing an operation to remove part of a lung. It would leave him susceptible to infection throughout his life.</p><p>As an elderly man he also suffered from pain in his right knee, which he described as a "physical humiliation".</p><p>The young Bergoglio worked as a nightclub bouncer and floor sweeper, before graduating as a chemist.</p><p>At a local factory, he worked closely with Esther Ballestrino, who campaigned against Argentina's military dictatorship. She was tortured, her body never found.</p><p>He became a Jesuit, studied philosophy and taught literature and psychology. Ordained a decade later, he won swift promotion, becoming provincial superior for Argentina in 1973.</p></article></div></li><li><div><article data-testid="content-post" id="asset:f6a845d2-6496-4de9-af02-76b80392acf1"><header><span><h3 type="normal"><span role="text"><span>Pope Francis leaves a profound legacy - Spanish PM</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:58 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Pedro Sánchez" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/e70f16ab-2190-407f-925b-23986c104230.jpg.webp 800w" width="955" height="537"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>Spain's Prime Minister Pedro Sánchez hails Pope Francis's commitment to the "most vulnerable".</p><p>He says in a post on the social media platform X: "I mourn the passing of Pope Francis. His commitment to peace, social justice, and the most vulnerable leaves a profound legacy.

Rest in peace."</p></article></div></li><li><div><article data-testid="content-post" id="asset:d670b0a8-4cde-4db4-b909-5889116fc0d8"><header><span><h3 type="normal"><span role="text"><span>'A great man has left us' - Italy's PM</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:55 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><figure><p><span><img alt="Giorgia Meloni." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/4a301ac1-7437-43f8-b8ee-d1511480e0c7.jpg.webp 800w" width="935" height="526"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>Italian Prime Minister Giorgia Meloni says "this news saddens us deeply".</p><p>"I had the privilege of enjoying his friendship," she adds in the statement.</p><p>Meloni adds "he asked the world, once again, for the courage to change direction, to follow a path that 'does not destroy, but cultivates, repairs, protects'".</p><p>"His teaching and his legacy will not be lost. We greet the Holy Father with hearts full of sadness, but we know that he is now in the peace of the Lord."</p></article></div></li><li><div><article data-testid="content-post" id="asset:93946807-4b53-4fd9-ab2b-69e6a1777511"><header><span><h3 type="normal"><span role="text"><span>Pope Francis's final message: No peace without freedom of religion, thought and expression</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:54 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Pope sitting in centre, with an aide on either side, on the balcony of St Peter's Basilica. Aide on left is reading out the Easter Sunday address on his behalf from a white-covered book." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/f054de66-55b1-48a2-bd2d-138306d77d94.jpg.webp 800w" width="2265" height="1274"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Pope Francis' Easter Sunday message was one of peace and "respect for the views of others".</p><p>An aide read on his behalf:</p><div><blockquote><div spacing="rich-text"><p><span>Quote Message</span></p><p>There can be no peace without freedom of religion, freedom of thought, freedom of expression."</p></div></blockquote></div><p>In his final address, the pontiff remembered the people of Gaza, in particular its Christian population, as the conflict "causes death and destruction" and creates a "deplorable humanitarian situation". He also called growing global antisemitism "worrisome".</p><p>"What a great thirst for death, for killing we see in the many conflicts raging in different parts of the world," he said.</p><p>"I express my closeness to the sufferings... for all the Israeli people and the Palestinian people," the message said. "Call a ceasefire, release the hostages and come to the aid of a starving people that aspires to a future of peace."</p><p>The Pope also encouraged all parties involved in the Ukraine war to "pursue efforts aimed at achieving a just and lasting peace".</p></article></div></li><li><div><article data-testid="content-post" id="asset:387ff0cd-c90c-42b8-a8fa-8f0b22db6691"><header><span><h3 type="normal"><span role="text"><span>Church of England's acting head pays tribute</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:49 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Archbishop of York." src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/364d3f0b-b71d-4c57-b4bb-bb059eed1bc0.jpg.webp 800w" width="1022" height="575"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>Archbishop of York Stephen Cottrell - who is the acting head of the Church of England - has reacted to Pope Francis's death. The paid met in 2023.</p><p>"<i>We saw that compellingly in Francis’s service of the poor, his love of neighbour especially the displaced, migrant, the asylum seeker, his deep compassion for the well-being of the earth and his desire to lead and build the church in new ways.</i></p><p><i>"Francis showed us how to follow Jesus and encouraged us to go and do likewise... </i><i>In their humility and focus on those in the margins, those actions, his whole life, was instantly recognisable as those of one who followed Jesus."</i></p><p>Archbishop Cottrell also referred to Pope Francis's work to resolve religious differences, saying he had been "a<i>cutely aware of the divisions between our churches and how they stand in the way of seeing Jesus Christ more fully".</i></p><p>And he paid tribute to his character, describing him as a "holy man of God" who was "also very human".</p><div><blockquote><div spacing="rich-text"><p><span>Quote Message</span></p><p>I remember, in the brief times I spent with him, how this holy man of God was also very human. He was witty, lively, good to be with, and the warmth of his personality and interest in others shone out from him. May he rest in peace and rise in glory."</p></div></blockquote></div></article></div></li><li><div><article data-testid="content-post" id="asset:9ab97463-78fc-4a63-b20e-531522ada5fc"><header><span><h3 type="normal"><span role="text"><span>Pope's death comes in Catholic jubilee year</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:45 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Pope with his back to the camera and both hands on the Holy Door. He is wearing white" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/65502b59-5024-49e6-bcb8-090ddb845295.jpg.webp 800w" width="3489" height="1962"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>The pontiff's death not only follows the most important calendar event for Catholics, but falls into the special jubilee year, which comes around every 25 years.</p><p>The jubilee kicked off when the Pope opened the usually bricked-up Holy Door at St Peter's Basilica on 24 December, and sees millions of pilgrims descend on the Vatican to pass through the doorway and seek forgiveness for their sins. </p><p>Tens of thousands of Catholics had gathered for the Easter Mass in this special year. </p></article></div></li><li><div><article data-testid="content-post" id="asset:4455a153-0225-4eb1-8036-c3d627f3a5c2"><header><span><h3 type="normal"><span role="text"><span>Watch: Pope Francis, the bouncer who became pontiff</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:41 British Summer Time</span></span></span></span></h3></span></header><p>The BBC's religion editor, Aleem Maqbool, takes us through the life of the late Pope Francis in this short, 90-second video:</p><div data-testid="component-wrapper"><figure><figcaption><span>Media caption, </span><p>Pope Francis: The bouncer who became pontiff</p></figcaption></figure></div></article></div></li><li><div><article data-testid="content-post" id="asset:27b7f460-4410-4471-981a-9c036501db1e"><header><span><h3 type="normal"><span role="text"><span>'A voice for peace with a contagious smile': World leaders' tributes</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:32 British Summer Time</span></span></span></span></h3></span></header><p>Tributes are pouring in now:</p><ul><li spacing="rich-text"><b>Dutch Prime Minister Dick Schoof </b>says "Pope Francis was in every way a man of the people"
    </li><li spacing="rich-text"><b>European Parliament President Roberta Metsola</b> says "his contagious smile captured millions of people’s hearts across the globe"
    </li><li spacing="rich-text"><b>Israeli President Isaac Herzog </b>hails his "boundless compassion"
    </li><li spacing="rich-text"><b>Swiss President Karin Keller-Sutter</b> says Pope Francis was a "great spiritual leader, a tireless advocate for peace"
    </li><li spacing="rich-text"><b>Scottish First Minister John Swinney</b> describes him as "a voice for peace, tolerance and reconciliation"
    </li></ul></article></div></li><li><div><article data-testid="content-post" id="asset:92a15719-ca32-4aa1-98e6-8428debecfec"><header><span><h3 type="normal"><span role="text"><span>Pope Francis was a 'man of humility', Macron says</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:29 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><figure><p><span><img alt="Macron meeting Pope Francis" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/477783c5-8b75-4592-a10a-11de74081b81.jpg.webp 800w" width="3000" height="1688"></span><span role="text"><span>Image source, </span>EPA</span></p><figcaption><span>Image caption, </span><p>The French president is pictured here meeting the Pope in 2023</p></figcaption></figure><p>French President Emmanuel Macron is among the first world leaders to pay tribute to Pope Francis, calling him a "man of humility, on the side of the most vulnerable and most fragile".</p></article></div></li><li><div><article data-testid="content-post" id="asset:4afaa8db-62fb-44cd-8311-c214bb734290"><header><span><h3 type="normal"><span role="text"><span>Pope's last public appearance was for Easter Sunday blessing</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:21 British Summer Time</span></span></span></span></h3></span></header><div data-testid="component-wrapper"><figure><figcaption><span>Media caption, </span><p>Watch: Pope Francis wishes the faithful a "happy Easter" to applause from Vatican crowds</p></figcaption></figure></div><p>The Pope's death comes fewer than 24 hours after he<a href="https://www.bbc.co.uk/news/articles/ckg291ngq7qo"> made an appearance at the Vatican's St Peter's Square</a> for Easter Sunday.</p><p>He came out in a wheelchair and waved from the balcony of St Peter's Basilica to cheering crowds and said: "Dear brothers and sisters, happy Easter."</p><ul></ul><figure><p><span><img alt="Pope sitting in wheelchair on balcony" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/243774d6-f18d-45e0-9595-8f9b53f08a08.jpg.webp 800w" width="3167" height="1781"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>His traditional Easter address and blessing was read by an aide while he sat, watching.</p><p>Following the blessing, he was driven around the square. As he passed through the crowds, his procession paused a number of times as babies were brought over for him to bless.</p><ul><li spacing="rich-text"><a href="https://www.bbc.co.uk/news/articles/ckg291ngq7qo">Read the full story from Sunday here</a></li></ul><figure><p><span><img alt="Pope in white roofless Mercedes being driven down a cleared path in the square. There are crowds behind barriers on either side" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/94a1217c-7b7a-48a5-a46c-0db16692d607.jpg.webp 800w" width="1022" height="575"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure></article></div></li><li><div><article data-testid="content-post" id="asset:2106656c-d1f6-4e12-924a-0e50383544ab"><header><span><h3 type="normal"><span role="text"><span>Watch the scene at the Vatican</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:18 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="A view of people in St Peter's Square, Vatican City" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/e4432eb6-5af3-4319-b281-cd4bce7acfdb.jpg.webp 800w" width="1920" height="1080"></span><span role="text"><span>Image source, </span>AFP</span></p></figure><p>See the latest at the Vatican in our live stream above - press <b>watch live </b>at the top of the page.</p></article></div></li><li><div><article data-testid="content-post" id="asset:a3644c58-c4ed-4b08-b70e-7d70ebd4a811"><header><span><h3 type="normal"><span role="text"><span>What happens when the Pope dies?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:16 British Summer Time</span></span></span></span></h3></span></header><p>A papal funeral has traditionally been an elaborate affair, but Pope Francis recently approved plans to make the whole procedure less complex.</p><p>Previous pontiffs were buried in three nested coffins made of cypress, lead and oak. </p><p>Pope Francis has opted for a simple wooden coffin lined with zinc.</p><p>He has also scrapped the tradition of placing the Pope's body on a raised platform - known as a catafalque - in St Peter's Basilica for public viewing.</p><p>Instead, mourners will be invited to pay their respects while his body remains inside the coffin, with the lid removed.</p><p>Francis will also be the first Pope in more than a Century to be buried outside the Vatican.</p><p>He will be laid to rest in the Basilica of St Mary Major, one of four major papal basilicas in Rome.</p></article></div></li><li><div><article data-testid="content-post" id="asset:b716ce4e-34bb-4556-86f8-24962769f8bc"><header><span><h3 type="normal"><span role="text"><span>The first non-European Pope in centuries</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:11 British Summer Time</span></span></span></span></h3></span></header><figure><p><span><img alt="Alt: Graffiti of the pope waving on the back of a white building with a man walking in front of it" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/68969772-a073-47ef-a636-fe5ee67718d1.jpg.webp 800w" width="974" height="547"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Francis's papacy heralded many firsts and while he never stopped introducing reforms to the Catholic Church, he remained popular among traditionalists.</p><p>He was the first Pope from the Americas or the southern hemisphere. Not since Syrian-born Gregory III died in 741 had there been a non-European Bishop of Rome.</p><p>He was also the first Jesuit to be elected to the throne of St Peter - Jesuits were historically looked on with suspicion by Rome.</p><p>Francis's predecessor, Benedict XVI, was the first Pope to retire voluntarily in almost 600 years and for almost a decade the Vatican Gardens hosted two popes.</p><p>As Cardinal Bergoglio of Argentina, he was already in his seventies when he became Pope in 2013.</p></article></div></li><li><div><article data-testid="content-post" id="asset:dd577a2c-b3e1-442e-b2aa-5906bfee7d25"><header><span><h3 type="normal"><span role="text"><span>Vatican announces Pope Francis's death - statement in full</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:06 British Summer Time</span></span></span></span></h3></span></header><p>A short while ago, His Eminence, Cardinal Farrell, announced with sorrow the death of Pope Francis, with these words:
“Dearest brothers and sisters, with deep sorrow I must announce the death of our Holy Father Francis.</p><div><blockquote><div spacing="rich-text"><p><span>Quote Message</span></p><p>At 7:35 this morning (local time), the Bishop of Rome, Francis, returned to the house of the Father. His entire life was dedicated to the service of the Lord and His Church."</p></div></blockquote></div><p>"He taught us to live the values ​​of the Gospel with fidelity, courage and universal love, especially in favour of the poorest and most marginalised."</p><p>Farrell adds: "With immense gratitude for his example as a true disciple of the Lord Jesus, we commend the soul of Pope Francis to the infinite merciful love of the One and Triune God.”</p></article></div></li><li><div><article data-testid="content-post" id="asset:9b3daf20-594e-4e1e-8d13-6da2b5de50d0"><header><span><h3 type="normal"><span role="text"><span>Vatican statement</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:01 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p>Pope Francis died on Easter Monday, April 21, 2025, at the age of 88 at his residence in the Vatican's Casa Santa Marta.</p><p>Follow our coverage by clicking the button at the top of this page.</p></article></div></li><li><div><article data-testid="content-post" id="asset:f5f70f5b-2bc6-4d15-bf3c-08068b1a7d55"><header><span><h3 type="normal"><span role="text"><span>Pope Francis dies aged 88</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:01 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><figure><p><span><img alt="The Pope sat giving a sermon in front of a cross" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/21/a98184ec-c7b3-4362-958d-1350da5ef529.jpg.webp 800w" width="976" height="549"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Pope Francis has died at the age of 88, the Vatican has announced.</p><p>Cardinal Jorge Mario Bergoglio was elected to lead the Catholic Church in March 2013 after Pope Benedict XVI stood down.</p></article></div></li></ol></div></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pope Francis has died (229 pts)]]></title>
            <link>https://www.reuters.com/world/pope-francis-has-died-vatican-says-video-statement-2025-04-21/</link>
            <guid>43749405</guid>
            <pubDate>Mon, 21 Apr 2025 08:00:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/pope-francis-has-died-vatican-says-video-statement-2025-04-21/">https://www.reuters.com/world/pope-francis-has-died-vatican-says-video-statement-2025-04-21/</a>, See on <a href="https://news.ycombinator.com/item?id=43749405">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/pope-francis-has-died-vatican-says-video-statement-2025-04-21/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Python's new t-strings (207 pts)]]></title>
            <link>https://davepeck.org/2025/04/11/pythons-new-t-strings/</link>
            <guid>43748512</guid>
            <pubDate>Mon, 21 Apr 2025 04:31:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davepeck.org/2025/04/11/pythons-new-t-strings/">https://davepeck.org/2025/04/11/pythons-new-t-strings/</a>, See on <a href="https://news.ycombinator.com/item?id=43748512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Template strings, also known as t-strings, have been <a href="https://peps.python.org/pep-0750/">officially accepted</a> as a feature in Python 3.14, which will ship in late 2025. 🎉</p>
<p>I’m excited; t-strings open the door to safer more flexible string processing in Python.</p>
<h4 id="whats-the-big-idea-with-t-strings">What’s the big idea with t-strings?</h4>
<p>Since they were introduced in Python 3.6, <a href="https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals">f-strings</a> have become a <em>very</em> popular way to format strings. They are concise, readable, and powerful.</p>
<p>In fact, they’re <em>so</em> delightful that many developers use f-strings for everything… even when they shouldn’t!</p>
<p>Alas, f-strings are often dangerously (mis)used to format strings that contain user input. I’ve seen f-strings used for SQL (<code>f"SELECT * FROM users WHERE name = '{user_name}'"</code>) and for HTML (<code>f"&lt;div&gt;{user_name}&lt;/div&gt;"</code>). These are not safe! If <code>user_name</code> contains a malicious value, it can lead to <a href="https://owasp.org/www-community/attacks/SQL_Injection">SQL injection</a> or <a href="https://owasp.org/www-community/attacks/xss/">cross-site scripting</a>.</p>
<p>Template strings are a <em>generalization</em> of Python’s f-strings. Whereas f-strings immediately become a string, t-strings evaluate to a new type, <code>string.templatelib.Template</code>:</p>
<pre tabindex="0" data-language="python"><code><span><span>from</span><span> string.templatelib </span><span>import</span><span> Template</span></span>
<span><span>name </span><span>=</span><span> "World"</span></span>
<span><span>template: Template </span><span>=</span><span> t</span><span>"Hello </span><span>{name}</span><span>!"</span></span>
<span></span></code></pre>
<p>Importantly, <code>Template</code> instances are <em>not</em> strings. The <code>Template</code> type does not provide its own <code>__str__()</code> implementation, which is to say that calling <code>str(my_template)</code> does not return a useful value. Templates <em>must</em> be processed before they can be used; that processing code can be written by the developer or provided by a library and can safely escape the dynamic content.</p>
<p>We can imagine a library that provides an <code>html()</code> function that takes a <code>Template</code> and returns a safely escaped string:</p>
<pre tabindex="0" data-language="python"><code><span><span>evil </span><span>=</span><span> "&lt;script&gt;alert('bad')&lt;/script&gt;"</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"&lt;p&gt;</span><span>{evil}</span><span>&lt;/p&gt;"</span></span>
<span><span>safe </span><span>=</span><span> html(template)</span></span>
<span><span>assert</span><span> safe </span><span>==</span><span> "&lt;p&gt;&amp;lt;script&amp;gt;alert('bad')&amp;lt;/script&amp;gt;&lt;/p&gt;"</span></span>
<span></span></code></pre>
<p>Of course, t-strings are useful for more than just safety; they also allow for more flexible string processing. For example, that <code>html()</code> function could return a new type, <code>HTMLElement</code>. It could also accept all sorts of useful substitutions in the HTML itself:</p>
<pre tabindex="0" data-language="python"><code><span><span>attributes </span><span>=</span><span> {</span><span>"src"</span><span>: </span><span>"roquefort.jpg"</span><span>, </span><span>"alt"</span><span>: </span><span>"Yum"</span><span>}</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"&lt;img </span><span>{attributes}</span><span> /&gt;"</span></span>
<span><span>element </span><span>=</span><span> html(template)</span></span>
<span><span>assert</span><span> str</span><span>(element) </span><span>==</span><span> "&lt;img src='roquefort.jpg' alt='Yum' /&gt;"</span></span>
<span></span></code></pre>
<p>If you’ve worked with JavaScript, t-strings may feel familiar. They are the pythonic parallel to JavaScript’s <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates">tagged templates</a>.</p>
<h4 id="how-do-i-work-with-t-strings">How do I work with t-strings?</h4>
<p>To support processing, <code>Template</code>s give developers access to the string and its interpolated values <em>before</em> they are combined into a final string.</p>
<p>The <code>.strings</code> and <code>.values</code> properties of a <code>Template</code> return tuples:</p>
<pre tabindex="0" data-language="python"><code><span><span>name </span><span>=</span><span> "World"</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"Hello </span><span>{name}</span><span>!"</span></span>
<span><span>assert</span><span> template.strings </span><span>==</span><span> (</span><span>"Hello "</span><span>, </span><span>"!"</span><span>)</span></span>
<span><span>assert</span><span> template.values </span><span>==</span><span> (name,)</span></span>
<span></span></code></pre>
<p>There is always one more (possibly empty) string than value. That is, <code>t"".strings == ("",)</code> and <code>t"{name}".strings == ("", "")</code>.</p>
<p>As a shortcut, it’s also possible to iterate over a <code>Template</code>:</p>
<pre tabindex="0" data-language="python"><code><span><span>name </span><span>=</span><span> "World"</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"Hello </span><span>{name}</span><span>!"</span></span>
<span><span>contents </span><span>=</span><span> list</span><span>(template)</span></span>
<span><span>assert</span><span> contents[</span><span>0</span><span>] </span><span>==</span><span> "Hello "</span></span>
<span><span>assert</span><span> contents[</span><span>1</span><span>].value </span><span>==</span><span> name</span></span>
<span><span>assert</span><span> contents[</span><span>2</span><span>] </span><span>==</span><span> "!"</span></span>
<span></span></code></pre>
<p>Developers writing complex processing code can also access the gory details of each interpolation:</p>
<pre tabindex="0" data-language="python"><code><span><span>name </span><span>=</span><span> "World"</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"Hello </span><span>{name</span><span>!s:&gt;8</span><span>}</span><span>!"</span></span>
<span><span>assert</span><span> template.interpolations[</span><span>0</span><span>].value </span><span>==</span><span> name</span></span>
<span><span>assert</span><span> template.interpolations[</span><span>0</span><span>].expression </span><span>==</span><span> "name"</span></span>
<span><span>assert</span><span> template.interpolations[</span><span>0</span><span>].conversion </span><span>==</span><span> "s"</span></span>
<span><span>assert</span><span> template.interpolations[</span><span>0</span><span>].format_spec </span><span>==</span><span> "&gt;8"</span></span>
<span></span></code></pre>
<p>In addition to supporting the literal (<code>t"foo"</code>) form, <code>Template</code>s can also be instantiated directly:</p>
<pre tabindex="0" data-language="python"><code><span><span>from</span><span> string.templatelib </span><span>import</span><span> Template, Interpolation</span></span>
<span><span>template </span><span>=</span><span> Template(</span></span>
<span><span>	"Hello "</span><span>,</span></span>
<span><span>	Interpolation(</span><span>value</span><span>=</span><span>"World"</span><span>, </span><span>expression</span><span>=</span><span>"name"</span><span>),</span></span>
<span><span>	"!"</span></span>
<span><span>)</span></span>
<span></span></code></pre>
<p>Strings and interpolations can be provided to the <code>Template</code> constructor in any order.</p>
<h4 id="a-simple-t-string-example">A simple t-string example</h4>
<p>Let’s say we wanted to write code to convert all substituted words into pig latin. All it takes is a simple function:</p>
<pre tabindex="0" data-language="python"><code><span><span>def</span><span> pig_latin</span><span>(template: Template) -&gt; </span><span>str</span><span>:</span></span>
<span><span>	"""Convert a Template to pig latin."""</span></span>
<span><span>	result </span><span>=</span><span> []</span></span>
<span><span>	for</span><span> item </span><span>in</span><span> template:</span></span>
<span><span>		if</span><span> isinstance</span><span>(item, </span><span>str</span><span>):</span></span>
<span><span>			result.append(item)</span></span>
<span><span>		else</span><span>:</span></span>
<span><span>			word </span><span>=</span><span> item.value</span></span>
<span><span>			if</span><span> word </span><span>and</span><span> word[</span><span>0</span><span>] </span><span>in</span><span> "aeiou"</span><span>:</span></span>
<span><span>				result.append(word </span><span>+</span><span> "yay"</span><span>)</span></span>
<span><span>			else</span><span>:</span></span>
<span><span>				result.append(word[</span><span>1</span><span>:] </span><span>+</span><span> word[</span><span>0</span><span>] </span><span>+</span><span> "ay"</span><span>)</span></span>
<span><span>	return</span><span> ""</span><span>.join(result)</span></span>
<span></span>
<span><span>name </span><span>=</span><span> "world"</span></span>
<span><span>template </span><span>=</span><span> t</span><span>"Hello </span><span>{name}</span><span>!"</span></span>
<span><span>assert</span><span> pig_latin(template) </span><span>==</span><span> "Hello orldway!"</span></span>
<span></span></code></pre>
<p>This is a goofy example; if you’d like to see some <em>less</em> silly examples, check out the <a href="https://github.com/davepeck/pep750-examples/">PEP 750 examples repository</a>.</p>
<h4 id="whats-next-once-t-strings-ship">What’s next once t-strings ship?</h4>
<p>T-strings are a powerful new feature that will make Python string processing safer and more flexible. I hope to see them used in all sorts of libraries and frameworks, especially those that deal with user input.</p>
<p>In addition, I hope that the tooling ecosystem will adapt to support t-strings. For instance, I’d love to see <code>black</code> and <code>ruff</code> format t-string <em>contents</em>, and <code>vscode</code> <em>color</em> those contents, if they’re a common type like HTML or SQL.</p>
<p>It’s been fun to get to know and work with <a href="https://github.com/jimbaker">Jim</a>, <a href="https://github.com/pauleveritt">Paul</a>, <a href="https://github.com/koxudaxi">Koudai</a>, <a href="https://github.com/lysnikolaou">Lysandros</a>, and <a href="https://en.wikipedia.org/wiki/Guido_van_Rossum">Guido</a> on this project and to interact with <a href="https://discuss.python.org/t/pep750-template-strings-new-updates/71594">many more members of the Python community</a> online without whose input PEP 750 simply wouldn’t have come together. I can’t wait to see what developers build with t-strings once they ship!</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Effect of Deactivating Facebook and Instagram on Users' Emotional State (271 pts)]]></title>
            <link>https://www.nber.org/papers/w33697</link>
            <guid>43748486</guid>
            <pubDate>Mon, 21 Apr 2025 04:24:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nber.org/papers/w33697">https://www.nber.org/papers/w33697</a>, See on <a href="https://news.ycombinator.com/item?id=43748486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div>
      
              <p>
                  <span>
      <a href="https://www.nber.org/people/matthew_gentzkow">Matthew Gentzkow</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/benjamin_wittenbrink">Benjamin Wittenbrink</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/juan_carlos_cisneros">Juan Carlos Cisneros</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/adriana_crespo-tenorio">Adriana Crespo-Tenorio</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/ddimmery">Drew Dimmery</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/deen_freelon">Deen Freelon</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/sandra_gonzalez-bailon">Sandra González-Bailón</a>,     </span>
                      <span>
        <span>
      <a href="https://www.nber.org/people/andyguess">Andrew M. Guess</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/young_mie_kim">Young Mie Kim</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/david_lazer">David Lazer</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/neil_malhotra">Neil Malhotra</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/devra_moehler">Devra Moehler</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/sameer_nair-desai">Sameer Nair-Desai</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/brendan_nyhan">Brendan Nyhan</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/jennifer_pan">Jennifer Pan</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/jaime_settle">Jaime Settle</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/emily_thorson">Emily Thorson</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/rebekah_tromble">Rebekah Tromble</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/carlos_velasco_rivera">Carlos Velasco Rivera</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/arjun_wilkins">Arjun Wilkins</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/magdalena_wojcieszak">Magdalena Wojcieszak</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/annie_franco">Annie Franco</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/chad_kiewiet_de_jonge">Chad Kiewiet de Jonge</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/winter_mason">Winter Mason</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/natalie_jomini_stroud">Natalie Jomini Stroud</a>    </span>
                  <span>
       &amp; <a href="https://www.nber.org/people/joshua_tucker">Joshua A. Tucker</a>    </span>
        </span>
    
      

    </p></div>
    
    <div>
        <p><span>Working Paper</span> 33697
  </p>

        <p><span>DOI</span> 10.3386/w33697
  </p>

        <p><span>Issue Date</span> <time datetime="2025-04-11T12:00:00Z">April 2025</time>

  </p>

          </div>
  </div><div>
    <p>
We estimate the effect of social media deactivation on users’ emotional state in two large randomized experiments before the 2020 U.S. election. People who deactivated Facebook for the six weeks before the election reported a 0.060 standard deviation improvement in an index of happiness, depression, and anxiety, relative to controls who deactivated for just the first of those six weeks. People who deactivated Instagram for those six weeks reported a 0.041 standard deviation improvement relative to controls. Exploratory analysis suggests the Facebook effect is driven by people over 35, while the Instagram effect is driven by women under 25.
</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I thought I bought a camera, but no DJI sold me a LICENSE to use their camera [video] (265 pts)]]></title>
            <link>https://www.youtube.com/watch?v=aUOnQ_boqCw</link>
            <guid>43748133</guid>
            <pubDate>Mon, 21 Apr 2025 02:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=aUOnQ_boqCw">https://www.youtube.com/watch?v=aUOnQ_boqCw</a>, See on <a href="https://news.ycombinator.com/item?id=43748133">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse engineering the obfuscated TikTok VM (195 pts)]]></title>
            <link>https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering</link>
            <guid>43747921</guid>
            <pubDate>Mon, 21 Apr 2025 01:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering">https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering</a>, See on <a href="https://news.ycombinator.com/item?id=43747921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TikTok VM Reverse Engineering (webmssdk.js)</h2><a id="user-content-tiktok-vm-reverse-engineering-webmssdkjs" aria-label="Permalink: TikTok VM Reverse Engineering (webmssdk.js)" href="#tiktok-vm-reverse-engineering-webmssdkjs"></a></p>
<p dir="auto">This project is for reverse engineering the TikTok Virtual Machine (VM).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">TikTok uses a custom virtual machine (VM) as part of its obfuscation and security layers. This project includes tools to:</p>
<ul dir="auto">
<li><strong>Deobfuscate</strong> <code>webmssdk.js</code> that has the virtual machine.</li>
<li><strong>Decompile</strong> TikTok’s virtual machine instructions into readable form.</li>
<li><strong>Script Inject</strong> Replace webmssdk.js with the deobfuscated VM <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/injector.js">injector</a>.</li>
<li><strong>Sign URLs</strong> Generate signed URLs which can be used to perform auth-based requests eg. Post comments.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deobfuscating</h2><a id="user-content-deobfuscating" aria-label="Permalink: Deobfuscating" href="#deobfuscating"></a></p>
<p dir="auto">When looking at <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfVersions/raw.js">webmssdk.js</a> you're met with a
heavily obfuscated file. The main method of obfuscating Javascript
is to take advantage of bracket notation which let's you index a variable
using another variable.</p>
<p dir="auto">So when you see something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Line 3391 of ./deobfVersions/raw.js
r[Gb[301]](Gb[57], e))"><pre><span>// Line 3391 of ./deobfVersions/raw.js</span>
<span>r</span><span>[</span><span>Gb</span><span>[</span><span>301</span><span>]</span><span>]</span><span>(</span><span>Gb</span><span>[</span><span>57</span><span>]</span><span>,</span> <span>e</span><span>)</span><span>)</span></pre></div>
<p dir="auto">You have absolutely no idea what it's indexing.</p>
<p dir="auto">Each use of this method is using an array <code>Gb</code> defined as</p>
<div dir="auto" data-snippet-clipboard-copy-content="    var Gb = [&quot;ydTGHdFNV&quot;, &quot;sNxpGNHMrpLV&quot;, &quot;xyrNMLEN Fpp rpMu&quot;, &quot;ydWyNe&quot;, ...].map(function(a) {
        return a.split(&quot;&quot;).map(function(c) {
            return &quot;LsfVNxutyOcrEMpYAGdFHneaUKRXSgoJDbhqICzPZklivTmWBwQj&quot;.indexOf(c) == -1 ? c : &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;[&quot;LsfVNxutyOcrEMpYAGdFHneaUKRXSgoJDbhqICzPZklivTmWBwQj&quot;.indexOf(c)]
        }).join(&quot;&quot;)
    });"><pre>    <span>var</span> <span>Gb</span> <span>=</span> <span>[</span><span>"ydTGHdFNV"</span><span>,</span> <span>"sNxpGNHMrpLV"</span><span>,</span> <span>"xyrNMLEN Fpp rpMu"</span><span>,</span> <span>"ydWyNe"</span><span>,</span> ...<span>]</span><span>.</span><span>map</span><span>(</span><span>function</span><span>(</span><span>a</span><span>)</span> <span>{</span>
        <span>return</span> <span>a</span><span>.</span><span>split</span><span>(</span><span>""</span><span>)</span><span>.</span><span>map</span><span>(</span><span>function</span><span>(</span><span>c</span><span>)</span> <span>{</span>
            <span>return</span> <span>"LsfVNxutyOcrEMpYAGdFHneaUKRXSgoJDbhqICzPZklivTmWBwQj"</span><span>.</span><span>indexOf</span><span>(</span><span>c</span><span>)</span> <span>==</span> <span>-</span><span>1</span> ? <span>c</span> : <span>"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"</span><span>[</span><span>"LsfVNxutyOcrEMpYAGdFHneaUKRXSgoJDbhqICzPZklivTmWBwQj"</span><span>.</span><span>indexOf</span><span>(</span><span>c</span><span>)</span><span>]</span>
        <span>}</span><span>)</span><span>.</span><span>join</span><span>(</span><span>""</span><span>)</span>
    <span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">As you can see we can't even read this either as it's all encoded
using this string <code>"LsfVNxutyOcrEMpYAGdFHneaUKRXSgoJDbhqICzPZklivTmWBwQj"</code>.</p>
<p dir="auto">Because this code get's executed immediately we can simply take this snippet
and run it in any console and retrieve:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[
    &quot;isTrusted&quot;,
    &quot;beforeunload&quot;,
    &quot;filename too long&quot;,
    &quot;isView&quot;,
    ...
]"><pre><span>[</span>
    <span>"isTrusted"</span><span>,</span>
    <span>"beforeunload"</span><span>,</span>
    <span>"filename too long"</span><span>,</span>
    <span>"isView"</span><span>,</span>
    ...
<span>]</span></pre></div>
<p dir="auto">We can now see each of these strings, therefore we can use RegEx to go through
the script and replace all uses of the array as seen <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfuscation/changeNotation.js#L322">here</a>
It will also convert the bracket notation back to readable dot notation.</p>
<p dir="auto">After that we've left with <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfVersions/ems1.js">webmssdk1</a>.</p>
<p dir="auto">The example from above now looks like this</p>
<div dir="auto" data-snippet-clipboard-copy-content="r.addEventListener(&quot;abort&quot;, e),"><pre><span>r</span><span>.</span><span>addEventListener</span><span>(</span><span>"abort"</span><span>,</span> <span>e</span><span>)</span><span>,</span></pre></div>
<p dir="auto">Much better.</p>
<p dir="auto">Another significant obfuscation method used is for disguising function calls.</p>
<p dir="auto">Each function is defined in an array <code>Ab</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="  var Ab = [function(e) {
      return &quot;[object Array]&quot; === Object.prototype.toString.call(e)
  }
  , function(e) {
      return e &amp;&amp; e.__esModule &amp;&amp; Object.prototype.hasOwnProperty.call(e, &quot;default&quot;) ? e.default : e
  }
  , function() {
      var Ga;
      Ga = [0, 1],
      (je = !Ga[0],
      le &amp;&amp; (setTimeout(function() {
          document.dispatchEvent(new Event(pe))
      }, Ga[1]),
      document.removeEventListener(&quot;DOMContentLoaded&quot;, Ab[40]),
      document.removeEventListener(&quot;readystatechange&quot;, Ab[75])))
  }
  ...]"><pre>  <span>var</span> <span>Ab</span> <span>=</span> <span>[</span><span>function</span><span>(</span><span>e</span><span>)</span> <span>{</span>
      <span>return</span> <span>"[object Array]"</span> <span>===</span> <span>Object</span><span>.</span><span>prototype</span><span>.</span><span>toString</span><span>.</span><span>call</span><span>(</span><span>e</span><span>)</span>
  <span>}</span>
  <span>,</span> <span>function</span><span>(</span><span>e</span><span>)</span> <span>{</span>
      <span>return</span> <span>e</span> <span>&amp;&amp;</span> <span>e</span><span>.</span><span>__esModule</span> <span>&amp;&amp;</span> <span>Object</span><span>.</span><span>prototype</span><span>.</span><span>hasOwnProperty</span><span>.</span><span>call</span><span>(</span><span>e</span><span>,</span> <span>"default"</span><span>)</span> ? <span>e</span><span>.</span><span>default</span> : <span>e</span>
  <span>}</span>
  <span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
      <span>var</span> <span>Ga</span><span>;</span>
      <span>Ga</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>]</span><span>,</span>
      <span>(</span><span>je</span> <span>=</span> <span>!</span><span>Ga</span><span>[</span><span>0</span><span>]</span><span>,</span>
      <span>le</span> <span>&amp;&amp;</span> <span>(</span><span>setTimeout</span><span>(</span><span>function</span><span>(</span><span>)</span> <span>{</span>
          <span>document</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span> <span>Event</span><span>(</span><span>pe</span><span>)</span><span>)</span>
      <span>}</span><span>,</span> <span>Ga</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
      <span>document</span><span>.</span><span>removeEventListener</span><span>(</span><span>"DOMContentLoaded"</span><span>,</span> <span>Ab</span><span>[</span><span>40</span><span>]</span><span>)</span><span>,</span>
      <span>document</span><span>.</span><span>removeEventListener</span><span>(</span><span>"readystatechange"</span><span>,</span> <span>Ab</span><span>[</span><span>75</span><span>]</span><span>)</span><span>)</span><span>)</span>
  <span>}</span>
  <span>.</span><span>.</span><span>.</span><span>]</span></pre></div>
<p dir="auto">And it used by calling <code>Ab[index](args)</code> like:</p>

<p dir="auto">When using common IDE's if we click on this function it will just bring us to
the start of the array making it difficult to keep track of what function call
is calling what function.</p>
<p dir="auto">We can make this readable by:</p>
<ul dir="auto">
<li>Taking the array</li>
<li>Replace each of the function element with it's own standard function calling it <code>function Abindex(args)</code></li>
<li>Replace each call to <code>Ab[index](args)</code> with <code>Abindex(args)</code></li>
</ul>
<p dir="auto">We can do this by using the AST form of the script via bapel as seen <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfuscation/bapel.js#L55">here</a></p>
<p dir="auto">Which gives us <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfVersions/ems2.js#L1798">this</a></p>
<p dir="auto">The Virtual Machine part of the script, specifically when executing the bytecode
is a nested if else statement as seen <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/deobfVersions/ems2.js#L2235">here</a></p>
<p dir="auto">It is actually just a normal switch case but has been disguised pretty well. After manually
doing some of the cases, AI was able to help me out and do the rest. Which gave me <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/handleBytecode.js">this</a>,
which looks pretty standard for a bytecode VM.</p>
<p dir="auto">When debugging the Virtual Machine later and seeing which functions it uses
I was able to tell what it's doing and changed some of var names.</p>
<p dir="auto">After all of this and a few more small obfuscation techniques
<a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/latestDeobf.js">here</a> is the latest version of the file.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Decrypting Bytecode</h2><a id="user-content-decrypting-bytecode" aria-label="Permalink: Decrypting Bytecode" href="#decrypting-bytecode"></a></p>
<p dir="auto">With the file fully deobfuscated, figuring out the functionality was much easier,
I easily found how the VM was being initiated <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/latestDeobf.js#L3041">here</a>.</p>
<p dir="auto">The bytecode is stored as a long string that's all been XOR'ed with a key that
lies within the string.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Line 3046 of latestDeobf.js
// Getting XOR key
for (var t = atob(payload), r = 0, n = 4; n < 8; ++n) r += t.charCodeAt(n);

// Decryping bytecode
unZip(Uint8Array.from(t.slice(8), XOR, r % 256), {  i: 2 }, t &amp;&amp; t.out, t &amp;&amp; t.dictionary),

// Extracting strings, functions and metadata for each function
for (var n = leb128(t), o = 0; o < n; ++o) strings.push(Ab27(t)); 
i = leb128(t);
for (o = 0; o < i; ++o) {
  for (var argsLength = leb128(t), isStrictMode = Boolean(leb128(t)), exceptionHandlers = new Array(), p = leb128(t), m = 0; m < p; ++m)    exceptionHandlers.push([leb128(t), leb128(t), leb128(t), leb128(t)]);
  for (var instructions = new Array(), h = leb128(t), v = 0; v < h; ++v) instructions.push(leb128(t));
  instructionSets.push([instructions, argsLength, isStrictMode, exceptionHandlers]);
}"><pre><span>// Line 3046 of latestDeobf.js</span>
<span>// Getting XOR key</span>
<span>for</span> <span>(</span><span>var</span> <span>t</span> <span>=</span> <span>atob</span><span>(</span><span>payload</span><span>)</span><span>,</span> <span>r</span> <span>=</span> <span>0</span><span>,</span> <span>n</span> <span>=</span> <span>4</span><span>;</span> <span>n</span> <span>&lt;</span> <span>8</span><span>;</span> <span>++</span><span>n</span><span>)</span> <span>r</span> <span>+=</span> <span>t</span><span>.</span><span>charCodeAt</span><span>(</span><span>n</span><span>)</span><span>;</span>

<span>// Decryping bytecode</span>
<span>unZip</span><span>(</span><span>Uint8Array</span><span>.</span><span>from</span><span>(</span><span>t</span><span>.</span><span>slice</span><span>(</span><span>8</span><span>)</span><span>,</span> <span>XOR</span><span>,</span> <span>r</span> <span>%</span> <span>256</span><span>)</span><span>,</span> <span>{</span>  <span>i</span>: <span>2</span> <span>}</span><span>,</span> <span>t</span> <span>&amp;&amp;</span> <span>t</span><span>.</span><span>out</span><span>,</span> <span>t</span> <span>&amp;&amp;</span> <span>t</span><span>.</span><span>dictionary</span><span>)</span><span>,</span>

<span>// Extracting strings, functions and metadata for each function</span>
<span>for</span> <span>(</span><span>var</span> <span>n</span> <span>=</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>o</span> <span>=</span> <span>0</span><span></span><span>;</span> <span>o</span> <span>&lt;</span> <span>n</span><span>;</span> <span>++</span><span>o</span><span>)</span> <span>strings</span><span>.</span><span>push</span><span>(</span><span>Ab27</span><span>(</span><span>t</span><span>)</span><span>)</span><span>;</span> 
<span>i</span> <span>=</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>;</span>
<span>for</span> <span>(</span><span>o</span> <span>=</span> <span>0</span><span>;</span> <span>o</span> <span>&lt;</span> <span>i</span><span>;</span> <span>++</span><span>o</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>var</span> <span>argsLength</span> <span>=</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>isStrictMode</span> <span>=</span> <span>Boolean</span><span>(</span><span>leb128</span><span>(</span><span>t</span><span>)</span><span>)</span><span>,</span> <span>exceptionHandlers</span> <span>=</span> <span>new</span> <span>Array</span><span>(</span><span>)</span><span>,</span> <span>p</span> <span>=</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>m</span> <span>=</span> <span>0</span><span>;</span> <span>m</span> <span>&lt;</span> <span>p</span><span>;</span> <span>++</span><span>m</span><span>)</span>    <span>exceptionHandlers</span><span>.</span><span>push</span><span>(</span><span>[</span><span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>]</span><span>)</span><span>;</span>
  <span>for</span> <span>(</span><span>var</span> <span>instructions</span> <span>=</span> <span>new</span> <span>Array</span><span>(</span><span>)</span><span>,</span> <span>h</span> <span>=</span> <span>leb128</span><span>(</span><span>t</span><span>)</span><span>,</span> <span>v</span> <span>=</span> <span>0</span><span>;</span> <span>v</span> <span>&lt;</span> <span>h</span><span>;</span> <span>++</span><span>v</span><span>)</span> <span>instructions</span><span>.</span><span>push</span><span>(</span><span>leb128</span><span>(</span><span>t</span><span>)</span><span>)</span><span>;</span>
  <span>instructionSets</span><span>.</span><span>push</span><span>(</span><span>[</span><span>instructions</span><span>,</span> <span>argsLength</span><span>,</span> <span>isStrictMode</span><span>,</span> <span>exceptionHandlers</span><span>]</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">NOTE: The string was gZip-ed and each value was leb128 encoded both for compression</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Virtual Machine decompiling</h2><a id="user-content-virtual-machine-decompiling" aria-label="Permalink: Virtual Machine decompiling" href="#virtual-machine-decompiling"></a></p>
<p dir="auto">TikTok is using a full-fledged bytecode VM, if you browse through <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/vm.js">it</a>, it supports
scopes, nested functions and exception handling. This isn't a typical VM and shows that
it is definitely sophiscated.</p>
<p dir="auto">To be able to write a form of decompilation I simply went through each of the cases
and wrote appropriate code for each one, and any case that jumps to another position
for loops like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="case 2:
    var a = instructions[index++];
    stack[pointer] ? --pointer : index += a;
    break;"><pre>case <span>2</span>:
    <span>var</span> <span>a</span> <span>=</span> <span>instructions</span><span>[</span><span>index</span><span>++</span><span>]</span><span>;</span>
    <span>stack</span><span>[</span><span>pointer</span><span>]</span> ? <span>--</span><span>pointer</span> : <span>index</span> <span>+=</span> <span>a</span><span>;</span>
    <span>break</span><span>;</span></pre></div>
<p dir="auto">I would simply stop it from doing so:</p>
<div dir="auto" data-snippet-clipboard-copy-content="case 2:
    var a = instructions[index++];
    //stack[pointer] ? --pointer : index += a;

    addCode(`// if (!v${pointer}) skip ${a} to ${index + a}`, byteCodePos)
    break;"><pre>case <span>2</span>:
    <span>var</span> <span>a</span> <span>=</span> <span>instructions</span><span>[</span><span>index</span><span>++</span><span>]</span><span>;</span>
    <span>//stack[pointer] ? --pointer : index += a;</span>

    <span>addCode</span><span>(</span><span>`// if (!v<span><span>${</span><span>pointer</span><span>}</span></span>) skip <span><span>${</span><span>a</span><span>}</span></span> to <span><span>${</span><span>index</span> <span>+</span> <span>a</span><span>}</span></span>`</span><span>,</span> <span>byteCodePos</span><span>)</span>
    <span>break</span><span>;</span></pre></div>
<p dir="auto">After doing this for all the cases I dumped each file <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions">here</a>.
It's not completely readable but you should be able to make out a general idea
of what each function is doing, for example <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM223.js">VM223</a> which is
generating random characters.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Debugging</h2><a id="user-content-debugging" aria-label="Permalink: Debugging" href="#debugging"></a></p>
<p dir="auto">As this is a Javascript file executed on the web, it is actually possible to replace
the normal <code>webmssdk.js</code> with the deobfuscated file and use TikTok normally.</p>
<p dir="auto">This can be achieved by using two browser extensions known as <a href="https://chromewebstore.google.com/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en-GB" rel="nofollow">Tampermonkey</a> for executing
custom code and <a href="https://chromewebstore.google.com/detail/disable-content-security/ieelmcmcagommplceebfedjlakkhpden?hl=en-GB&amp;pli=1" rel="nofollow">CSP</a> to disable CSP so I can fetch files from blocked origins. This is so I
can put <code>latestDeobf.js</code> in my own file server and have it be fetched each time, this is so I can easily
edit the file and let the changes take effect each time I refresh. This makes it much easier to bebug
when reversing functions.</p>
<p dir="auto">The script can be found <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/injector.js">here</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requests</h2><a id="user-content-requests" aria-label="Permalink: Requests" href="#requests"></a></p>
<p dir="auto">Now that we have deobfuscated the file and decompiled the VM we can
start to reverse any function we want and figure out what it's doing.</p>
<p dir="auto">When you make a request to the server it usually consists of 3 additional headers.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Header</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>msToken</code></td>
<td>Sent by the server and reissued on each request.</td>
</tr>
<tr>
<td><code>X-Bogus</code></td>
<td>Generated by webmssdk.js based on request.</td>
</tr>
<tr>
<td><code>_signature</code></td>
<td>Generated by webmssdk.js based on request.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">When making a request that doesn't require authentication like querying a user. Only <code>X-Bogus</code> is
needed to be generated which can be done using <code>window.frontierSign</code>. <code>_signature</code> isn't needed
and any <code>msToken</code> can be used.</p>
<p dir="auto">This popular <a href="https://github.com/davidteather/TikTok-Api">API</a> let's you make those requests.
It uses a webdriver library called <a href="https://playwright.dev/python/docs/api/class-playwright" rel="nofollow">playwright</a>, that simply sets up a browser instance, so it can easily call <code>window.frontierSign</code>.</p>
<p dir="auto">When it comes to making authentication-based requests like posting a comment, <code>_signature</code> is needed
and isn't exposed to <code>window</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Signer</h2><a id="user-content-signer" aria-label="Permalink: Signer" href="#signer"></a></p>
<p dir="auto">The inital function call for each request is <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM86.js">VM86</a> which then calls</p>
<p dir="auto"><a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM113.js">VM113</a> for <code>X-bogus</code></p>
<p dir="auto"><a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM189.js">VM189</a> for <code>_signature</code></p>
<p dir="auto">I was able to write <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/signer.js">signer</a> which
succesfully signs URL's.</p>
<p dir="auto">Here's a demo of posting a comment and checking it using a
private browser to ensure it's successful.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description PostCommentTest1.mp4">PostCommentTest1.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/50531317/435448001-746aa1a1-d171-487a-819b-5b0ca1894c47.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUyMjA5MDEsIm5iZiI6MTc0NTIyMDYwMSwicGF0aCI6Ii81MDUzMTMxNy80MzU0NDgwMDEtNzQ2YWExYTEtZDE3MS00ODdhLTgxOWItNWIwY2ExODk0YzQ3Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIxVDA3MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4MDE1ZWMwMTVlZWMzMzA0OTFhM2U3NmYzOGRjYTAyNTYwZjY4Zjk2Y2FiMmM0NzY1NTNjMTg4ZWY1ZTRmMTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.jydUDrg3C7mj_xsXrRBA1-FfxEXN3PfYOKQa_fotZVM" data-canonical-src="https://private-user-images.githubusercontent.com/50531317/435448001-746aa1a1-d171-487a-819b-5b0ca1894c47.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUyMjA5MDEsIm5iZiI6MTc0NTIyMDYwMSwicGF0aCI6Ii81MDUzMTMxNy80MzU0NDgwMDEtNzQ2YWExYTEtZDE3MS00ODdhLTgxOWItNWIwY2ExODk0YzQ3Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIxVDA3MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4MDE1ZWMwMTVlZWMzMzA0OTFhM2U3NmYzOGRjYTAyNTYwZjY4Zjk2Y2FiMmM0NzY1NTNjMTg4ZWY1ZTRmMTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.jydUDrg3C7mj_xsXrRBA1-FfxEXN3PfYOKQa_fotZVM" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">NOTE: There are also some bot protection methods such as mouse tracking (<a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM120.js">VM120</a>)
and environment checking (<a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM265.js">VM265</a>) within <a href="https://github.com/LukasOgunfeitimi/TikTok-ReverseEngineering/blob/main/decompiler/functions/VM86.js">VM86</a>, but it is a completely client-sided check and doesn't communicate
with the server about, so it can be ignored when generating the signatures.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Extra info</h2><a id="user-content-extra-info" aria-label="Permalink: Extra info" href="#extra-info"></a></p>
<ul dir="auto">
<li><strong>Note:</strong> The TikTok VM is constantly changing with new releases. There's a high chance the main algorithms will change and decompilation of the new VM is needed.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pete Hegseth shared Yemen attack details in second Signal chat (121 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/apr/20/pete-hegseth-signal-chat-yemen-attack</link>
            <guid>43747310</guid>
            <pubDate>Sun, 20 Apr 2025 23:27:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/apr/20/pete-hegseth-signal-chat-yemen-attack">https://www.theguardian.com/us-news/2025/apr/20/pete-hegseth-signal-chat-yemen-attack</a>, See on <a href="https://news.ycombinator.com/item?id=43747310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Before the US launched military strikes on <a href="https://www.theguardian.com/world/yemen" data-link-name="in body link">Yemen</a> in March, <a href="https://www.theguardian.com/us-news/pete-hegseth" data-link-name="in body link">Pete Hegseth</a>, the defense secretary, sent detailed information about the planned attacks to a private Signal group chat that he created himself, which included his wife, his brother and about a dozen other people, <a href="https://www.nytimes.com/2025/04/20/us/politics/hegseth-yemen-attack-second-signal-chat.html?smid=nytcore-ios-share&amp;referringSource=articleShare" data-link-name="in body link">the New York Times reported</a> on Sunday.</p><p>The Guardian has independently confirmed the existence of Hegseth’s own private group chat.</p><p>According to unnamed sources familiar with the chat who spoke to the Times, Hegseth sent the private group of his personal associates some of the same information, including the flight schedules for the F/A-18 Hornets that would strike Houthi rebel targets in Yemen, that he also shared with another Signal group of top officials that was created by Mike Waltz, the national security adviser.</p><p>The existence of the Signal group chat created by Waltz, in which <a href="https://www.theguardian.com/us-news/2025/mar/24/journalist-trump-yemen-war-chat-reaction" data-link-name="in body link">detailed attack plans were divulged</a> by Hegseth to other Trump administration officials on the private messaging app, was <a href="https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/" data-link-name="in body link">made public last month</a> by Jeffrey Goldberg of the Atlantic, who had been accidentally added to the group by Waltz.</p><figure id="06b68203-5ef2-4f56-bfd6-b86c6e7646cb" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:4,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Exclusive: how the Atlantic’s Jeffrey Goldberg got added to the White House Signal group chat&quot;,&quot;elementId&quot;:&quot;06b68203-5ef2-4f56-bfd6-b86c6e7646cb&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2025/apr/06/signal-group-chat-leak-how-it-happened&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The fact that Hegseth also shared the plans in a second Signal group chat, according to “people familiar with the matter” who spoke to the Times, is likely to add to <a href="https://www.politico.com/news/2025/04/18/defense-secretary-chief-of-staff-joe-kasper-departure-00299508" data-link-name="in body link">growing criticism</a> of the former Fox weekend anchor’s ability to manage the Pentagon, a massive organization which operates in matters of life and death around the globe.</p><p>According to the Times, the private chat also included two senior advisers to Hegseth – Dan Caldwell and Darin Selnick – who were fired last week after being accused of leaking unauthorized information.</p><p>Hegseth has <a href="https://www.youtube.com/watch?v=sYLUIBBUNJ0" data-link-name="in body link">previously been criticized</a> for including his wife, Jennifer, a former Fox News producer, <a href="https://www.theguardian.com/us-news/2025/mar/29/pete-hegseth-wife-jennifer-foreign-defense-official-meetings" data-link-name="in body link">in sensitive meetings with foreign leaders</a>, including a discussion of the war in Ukraine with British military leaders. Phil Hegseth, the secretary’s younger brother, was hired as a senior Pentagon adviser and is the defense department’s liaison to the Department of Homeland Security. It is unclear why either would need to know about the details of strikes plans in advance.</p><p>According to the Times, Hegseth used his private phone, rather than a government device, to access the Signal chat with his family and friends.</p><p>CNN <a href="https://www.cnn.com/2025/04/20/politics/hegseth-second-signal-chat-military-plans/index.html" data-link-name="in body link">reported later on Sunday</a> that three sources familiar with Hegseth’s private Signal group confirmed to the broadcaster that he had used it to share Yemen attack plans before the strikes were launched.</p><p>A person familiar with the contents and those who received the messages, confirmed the second chat to the Associated Press ands said that it included 13 people.</p><p>Shortly after the news of the second Signal chat broke, Politico published an opinion article by Hegseth’s former press secretary, John Ullyot, <a href="https://www.politico.com/news/magazine/2025/04/20/pentagon-chaos-ullyot-hegseth-00205594" data-link-name="in body link">who wrote</a>: “It’s been a month of total chaos at the Pentagon. From leaks of sensitive operational plans to mass firings, the dysfunction is now a major distraction for the president – who deserves better from his senior leadership”.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Thai authorities use online doxxing to suppress dissent (132 pts)]]></title>
            <link>https://citizenlab.ca/2025/04/how-thai-authorities-use-online-doxxing-to-suppress-dissent/</link>
            <guid>43747242</guid>
            <pubDate>Sun, 20 Apr 2025 23:15:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://citizenlab.ca/2025/04/how-thai-authorities-use-online-doxxing-to-suppress-dissent/">https://citizenlab.ca/2025/04/how-thai-authorities-use-online-doxxing-to-suppress-dissent/</a>, See on <a href="https://news.ycombinator.com/item?id=43747242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container"> <!--TODO move to stylesheet -->
		<main id="main" role="main" itemscope="" itemprop="mainContentOfPage" itemtype="http://schema.org/Blog">
			<section id="content">


						
							

     <article id="post-82154" dir="ltr" 82154role="article" itemscope="" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

        <header>
          <span dir="ltr"><a href="https://citizenlab.ca/category/research/">Back to Research</a></span>
            
            

          <!-- Display the link for the PDF version of the post -->
          
        </header>         
                <section itemprop="articleBody">
                  <h2><span><strong>Abstract</strong>&nbsp;</span></h2>
<p><span>A sustained, coordinated social media harassment and doxxing campaign – which we codenamed JUICYJAM – targeting the pro-democracy movement in Thailand has run uninterrupted, and unchallenged, since at least August 2020. We define doxxing as the search for and the publication of an individual’s personal data on the Internet with malicious intent, in this instance, to suppress and harass the Thai pro-democracy movement. The operation utilized an inauthentic persona over multiple social media platforms (primarily X and Facebook) to target pro-democracy protesters by doxxing individuals, continuously harassing them, and instructing followers to report them to the police. Through our analysis of public social media posts we determined that the campaign was not only inauthentic, but the information revealed could not have been reasonably sourced from a private individual. Thanks to a public leak of confidential military and police documents in March 2025, we can now attribute the campaign to the Royal Thai Armed Forces and/or the Royal Thai Police. With a high rate of following and engagement across platforms, JUICYJAM is an uncommon instance of a successful state-sponsored influence operation. JUICYJAM’s tactics support a larger network of judicial harassment and democratic suppression that is infrequently enforced by social media platforms, but poses a significant threat to civil society.&nbsp;</span></p>
<h2><strong>Key Findings</strong></h2>
<ul>
<li aria-level="1"><span>Since at least August 2020, a coordinated social media harassment and doxxing campaign targeting the Thai pro-democracy movement has run uninterrupted and unchallenged. We codenamed it JUICYJAM.&nbsp;</span></li>
<li aria-level="1"><span>Thanks to a public leak of confidential military and police documents that occurred in March 2025, we can now attribute the campaign to the Royal Thai Armed Forces and/or the Royal Thai Police, whose online repression efforts have allegedly been merged into a joint “Cyber Team” since 2023.</span></li>
<li aria-level="1"><span>The campaign operates within a broader context of dissent repression tactics, both online and offline, that closely resemble those we have previously analyzed in other regions – such as, for example, in Hong Kong.</span></li>
<li aria-level="1"><span>JUICYJAM’s longstanding, uninterrupted activity over multiple social media platforms (primarily X and Facebook) once again exposes the shortcomings of platforms in creating and enforcing policies on highly coordinated and harmful doxxing campaigns intended to suppress civil society.&nbsp;</span></li>
<li aria-level="1"><span>Platforms’ policies on doxxing seldom consider the behaviour in the context of coordinated – and often state-sponsored – campaigns against civil society. They also do not consider environmental factors, such as the doxxing happening during unrest and protests.</span></li>
</ul>
<h2><strong><a id="background"></a>Background</strong></h2>
<p><span>In 2014, Thailand faced its second military coup of the century, placing a military junta – the National Council for Peace and Order – in power. The junta immediately imposed martial law, ratified a military-backed constitution, and, in 2019, the former army chief who led the coup, Prayuth Chan-o-cha, was elected Prime Minister. In July 2020, youth-led pro-democracy protests broke out across the country, demanding a more democratic constitution and reforms to the monarchy. The protesters were met with severe repression, and after a two-year </span><a href="https://www.fidh.org/IMG/pdf/thailand_report_second_wave_774a_sg_au_210906.pdf" target="_blank" rel="noopener"><span>pause</span></a><span> of prosecutions, in November 2020, Prime Minister Prayuth ordered authorities to bring back the enforcement of </span><i><span>lèse-majesté</span></i><span>, or Section 112 of the Criminal Code, which criminalizes “insulting the monarchy”. Thailand’s use of </span><i><span>lèse-majesté</span></i><span> has been both arbitrary and prolific; protesters can be arrested for as little as </span><a href="https://www.bbc.com/thai/thailand-49963123" target="_blank" rel="noopener"><span>sharing social media posts</span></a><span> that are ‘insulting to the monarchy’. Furthermore, the weaponization of </span><i><span>lèse-majesté</span></i><span> has devastating consequences: those convicted under Section 112 face three to 15 years in prison per count. Thai authorities have extensively used </span><i><span>lèse-majesté </span></i><span>as a tool to punish pro-democracy advocates, with around 270 protesters detained and convicted </span><a href="https://www.ohchr.org/en/press-releases/2025/01/thailand-must-immediately-repeal-lese-majeste-laws-say-un-experts" target="_blank" rel="noopener"><span>since 2020</span></a><span>.</span></p>
<p><span>Weaponizing the judiciary has not been enough, however. Since the 2014 coup, the Thai pro-democracy movement has been heavily targeted through various digital means. In 2022, Citizen Lab researchers uncovered an extensive </span><a href="https://citizenlab.ca/2022/07/geckospy-pegasus-spyware-used-against-thailands-pro-democracy-movement/"><span>espionage campaign</span></a><span> impacting several groups within the movement, such as FreeYOUTH and WeVo. In fact, one of the authors of this report, Katekanok Wongsapakdee, was also found to be targeted.</span></p>
<p><span>Additionally, </span><a href="https://globaldemocracycoalition.org/library/state-sponsored-online-disinformation-impact-on-electoral-integrity-in-thailand/" target="_blank" rel="noopener"><span>multiple influence operations</span></a><span> (IOs) have been exposed for their attempts to discredit the pro-democracy movement and intimidate its members. In October 2020, the company now called X (formerly Twitter) exposed one of the most notorious online IOs targeting the Thai protest movement when it </span><a href="https://web.archive.org/web/20240810002008/https://blog.x.com/en_us/topics/company/2020/disclosing-removed-networks-to-our-archive-of-state-linked-information" target="_blank" rel="noopener"><span>announced</span></a><span> the removal of 926 covertly coordinated accounts. The network of accounts was attributed with high confidence to the Royal Thai Army (RTA). Twitter found the accounts to be “engaging in amplifying pro-RTA and pro-government content, as well as engaging in behavior targeting prominent political opposition figures.”<a id="fnref1" role="doc-noteref" href="#fn1"><sup>1</sup></a></span></p>
<p><span>Further analysis conducted by the </span><a href="https://purl.stanford.edu/ym245nv3149" target="_blank" rel="noopener"><span>Stanford Internet Observatory</span></a><span> found that this influence operation did not achieve any relevant traction with legitimate audiences. The authors state that “the accounts had few followers, the tweets received very low levels of engagement, and the magnitude of tweets is unlikely to have effectively diverted public attention”. Despite the relative investment of resources to conduct this operation, it appears to have failed.</span></p>
<p><span>Twitter’s takedown did not, however, stop influence operations from being deployed to repress the then still very active pro-democracy protests in Thailand. Within this context, we identified several social media campaigns for research candidates, and singled out one that appeared to show the hallmarks of a well-coordinated, and resourced, influence operation. We set out to investigate the campaign’s footprint, tactics, and to determine attribution.&nbsp;</span></p>
<p><span>We codenamed this operation JUICYJAM.</span></p>
<h2><strong>The Leak</strong></h2>
<p><span>While compiling our initial analysis on JUICYJAM, there was a significant leak of information from a Member of the Thai Parliament. On March 25, 2025, Thai MP Chayaphon Satondee, released confidential </span><a href="https://x.com/ThaiEnquirer/status/1904559473940955395" target="_blank"><span>documents</span></a><span> allegedly illustrating the influence operation’s machinery put in place by the Thai authorities to quash dissent.</span></p>
<p><span>It is important to clarify the following:</span></p>
<ul>
<li aria-level="1"><span>We could not independently verify the documents as authentic, or complete. The documents were released by a Thai opposition MP, who claimed to have obtained them from “military and police officers who love democracy,”<a id="fnref2" role="doc-noteref" href="#fn2"><sup>2</sup></a> in the context of a general debate for a vote of no confidence in Prime Minister Paethongtarn Shinawatra.</span></li>
<li aria-level="1"><span>The MP claims the documents originated from a joint-forces “Cyber ​​Team” created in 2023<a id="fnref3" role="doc-noteref" href="#fn3"><sup>3</sup></a>. They allegedly contain the “Weekly Cyber ​​Team Operations Report” for August 17-23, 2024, or the first week after Paethongtarn Shinawatra received parliamentary approval to assume the position of Prime Minister, and the report for October 19-25, 2024, or the period after Paethongtarn assumed the position of Prime Minister.&nbsp;</span></li>
<li aria-level="1"><span>We could review the available documents in detail thanks to the MP making them available on the web<a id="fnref4" role="doc-noteref" href="#fn4"><sup>4</sup></a>, which allowed us to assess them as, at the very least, highly plausible.</span>
<ul>
<li aria-level="2"><span>The documents’ layout, language, and alleged purpose are consistent with those from internal reports produced by a military or law enforcement agency.</span></li>
<li aria-level="2"><span>The documents were reported about in detail by international, as well as local, media, such as the </span><a href="https://www.bbc.com/thai/articles/c20lw5qx4z1o" target="_blank" rel="noopener"><span>BBC</span></a><span>.</span></li>
<li aria-level="2"><span>What caught our attention, however, was the presence, within a set of leaked presentation slides ostensibly explaining the strategy behind the IO, of several tweets where the account’s handle was consistently cut off from the presented screenshot, as if to protect it from inadvertent exposure.</span></li>
<li aria-level="2"><span>Through cross-comparison, we were able to confirm that the tweets seen in the documents had been posted by the X handle we had been researching as the main online asset for </span>JUICYJAM<span>: <code>@jjookklong3</code>.</span></li>
</ul>
</li>
</ul>
<p>If authentic, the leaked documents prove JUICYJAM to be a state-sponsored influence operation, designed to suppress the protest groups, and to counter protest narratives, through a variety of aggressive tactics.</p>
<h2><strong>A Well-Coordinated Suppression Network</strong></h2>
<h2><strong>Summary</strong></h2>
<p><i>Note</i><i><span>: as we have done in </span></i><a href="https://citizenlab.ca/2023/07/hkleaks-covert-and-overt-online-harassment-tactics-to-repress-the-2019-hong-kong-protests/"><i><span>previous research</span></i></a><i><span>, in this report we define </span></i><a href="https://www.tandfonline.com/doi/full/10.1080/01296612.2020.1850000" target="_blank" rel="noopener"><i><span>doxxing</span></i></a><i><span> as the search for and the publication of an individual’s personal data on the Internet with malicious intent.</span></i></p>
<p>JUICYJAM is a prolific set of social media entities, particularly on X and on Facebook, working in coordination to dox and harass individuals and groups within the broader Thai pro-democracy camp. It centres around a single persona, a supposed middle-aged businesswoman going by the name of “Ms. Juk Khlong Sam”. Visually, it consistently utilizes a character from the popular Japanese Anime comic “One Piece”<a id="fnref5" role="doc-noteref" href="#fn5"><sup>5</sup></a> in its profile and cover photos.</p>
<p>Unlike many other influence operations<a id="fnref6" role="doc-noteref" href="#fn6"><sup>6</sup></a>, JUICYJAM can be considered as highly successful. Utilizing its visible views and engagement metrics as a proxy measure for influence, we can observe that the campaign enjoys:</p>
<ul>
<li aria-level="1">Almost 110,000 followers on its X account, with tweet views often upwards of 15,000 (peaks of more than 50,000), and a consistent flow of likes, replies, and retweets.</li>
<li aria-level="1">A combined (non-unique) count of more than 133,000 followers on Facebook<span>, divided between Pages (claimed to be non-official, as we will see, but reposting the X account’s same doxxing content), and a Group. An average post by one of the Facebook Pages typically achieved several hundred reactions, and dozens of comments.</span></li>
<li aria-level="1"><span><span>The vast majority of that audience, and of the consequent engagement, appears to be authentic – i.e. generated by real users, rather than other accounts operated by JUICYJAM.</span></span></li>
</ul>
<figure><p><img fetchpriority="high" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new.png" alt="" width="700" height="595" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 1" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new.png 700w, https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new-300x255.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new-400x340.png 400w, https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new-234x199.png 234w, https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new-326x277.png 326w, https://citizenlab.ca/wp-content/uploads/2025/04/fig1-new-180x153.png 180w" sizes="(max-width: 700px) 100vw, 700px"></p><figcaption><strong>Figure 1.</strong>&nbsp;A <a href="https://www.facebook.com/photo/?fbid=680026037363826&amp;set=a.427559995943766" target="_blank" rel="noopener">doxxing post</a> <span>(</span><a href="https://archive.ph/ZRBFg" target="_blank" rel="noopener"><span>archive</span></a><span>) </span>published by the Facebook Page “เจ๊จุก คลองสาม FC v.1”, sharing the location of a bakery owned by the sister of pro-democracy protester Panusaya Sithijirawattanakul and encouraging followers to leave a negative review. The post shows over 2,000 reactions, 144 comments, and almost 50 shares.</figcaption></figure>
<h2><strong><a id="timeline"></a>Timeline</strong></h2>
<p>We can observe JUICYJAM’s activity as far back as August 2020. At that time, two identical blogs were created on separate platforms – WordPress<a id="fnref7" role="doc-noteref" href="#fn7"><sup>7</sup></a> and Blogger<a id="fnref8" role="doc-noteref" href="#fn8"><sup>8</sup></a>, respectively – only days apart. On them, the previously unseen alias “Ms. Juk Khlong Sam”<span> published two separate posts containing photos and private information – the veracity of which we could not verify – on two alleged members of the Thai protest movement. Some of the information being exposed included the names of the individuals’ family members; the schools they attended; or the name and location of the small businesses their families owned.</span></p>
<p><span>The blogs were no longer updated after the two posts were made. The persona, however, lived on.</span></p>
<p>On September 1, 2020, a Twitter (now X) account was created utilizing the same alias as the blogs: <code>@jjookklong3</code>. The profile for the first time displayed pictures of the “Big Mom” Anime character – which will remain a constant theme for the operation across its several years of activity.</p>
<figure><p><img decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-2.png" alt="" width="1043" height="545" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 2" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-2.png 1043w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-300x157.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-1024x535.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-768x401.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-605x316.png 605w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-297x155.png 297w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-500x261.png 500w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-2-180x94.png 180w" sizes="(max-width: 1043px) 100vw, 1043px"></p><figcaption><strong>Figure 2.</strong> Header of the <code>@jjookklong3</code> X (Twitter) <a href="https://x.com/jjookklong3" target="_blank">account</a>, showing the “Big Mom” character from “One Piece” as the profile picture.</figcaption></figure>

<p><span>According to what is visible today, the account began posting approximately one week after its creation, on September 9, 2020. Its </span><a href="https://x.com/jjookklong3/status/1303518244414791680" target="_blank"><span>first known tweet</span></a><span> (</span><a href="https://archive.ph/oiIre" target="_blank" rel="noopener"><span>archive</span></a><span>) described the account’s operator as a woman, disconcerted and indignant with the protest movement’s actions. The persona will be further built over the following years, as we will see later in this report.</span></p>
<p><span>Shortly after the publishing of the Twitter account, several assets utilizing the same (or very similar) naming convention, and an identical “Big Mom” visual theme, surfaced on Facebook.</span></p>
<ul>
<li aria-level="1"><span>The first, created in mid November 2020, was a </span>Facebook <a href="https://www.facebook.com/groups/jjookklong3/" target="_blank" rel="noopener">Group</a> called “เจ๊จุก คลองสาม Family” (Ms. Juk Khlong Sam Family).
<ul>
<li aria-level="2">The Group was set as private, but visible<a id="fnref9" role="doc-noteref" href="#fn9"><sup>9</sup></a>, meaning that we could observe the existence of the Group itself, as well as some other information related to it, but not its contents.</li>
<li aria-level="2">The Facebook Group in question utilized the same alias, and the same anime character, seen everywhere else until that moment.</li>
<li aria-level="2">On its Twitter/X account, “Ms. Juk Khlong Sam” repeatedly claimed ownership of the Facebook Group<span>, even redirecting its followers to specific posts made within it.</span></li>
<li aria-level="2"><span>The Group remains very active to this day, with approximately 13 posts made per day, according to the visible statistics.</span></li>
</ul>
</li>
</ul>

<figure><p><img decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-3.png" alt="" width="1122" height="543" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 3" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-3.png 1122w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-300x145.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-1024x496.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-768x372.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-605x293.png 605w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-297x144.png 297w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-500x242.png 500w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-3-180x87.png 180w" sizes="(max-width: 1122px) 100vw, 1122px"></p><figcaption><strong>Figure 3</strong>. The landing page for the Facebook Group “เจ๊จุก คลองสาม Family”, using the alias jjookklong3. The widget shows the creation date (November 12, 2020), as well as the privacy settings for the Group.</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-4.png" alt="" width="612" height="447" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 4" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-4.png 612w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-4-300x219.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-4-466x340.png 466w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-4-272x199.png 272w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-4-379x277.png 379w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-4-180x131.png 180w" sizes="auto, (max-width: 612px) 100vw, 612px"></p><figcaption><strong>Figure 4.</strong>&nbsp;A screenshot (captured on April 4, 2025) of the “Activity” widget on the landing page for the Facebook Group “เจ๊จุก คลองสาม Family”, showing posts and users statistics.</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-5.png" alt="" width="1061" height="434" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 5" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-5.png 1061w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-300x123.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-1024x419.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-768x314.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-605x247.png 605w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-297x121.png 297w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-500x205.png 500w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-5-180x74.png 180w" sizes="auto, (max-width: 1061px) 100vw, 1061px"></p><figcaption><strong>Figure 5.</strong> A screenshot from a <a href="https://x.com/jjookklong3/status/1347468177555394565" target="_blank">tweet</a> (<a href="https://archive.ph/B5McT" target="_blank" rel="noopener">archive</a>) in which <code>@jjookklong3</code> redirects followers to the Facebook Group “เจ๊จุก คลองสาม Family” to watch a video attacking WeVo. The text translates to: “The full, long clip of the WeVo group’s arrogance is on the Facebook group ‘Jae Juk Khlong Sam Family’. Go watch it in full. Let me tell you, you’ll see every action and behavior. It’s like these drunk WeVo people can’t keep their cool.”</figcaption></figure>

<ul>
<li aria-level="1"><span>A few months after the Group, in March 2021, the first of several </span>Facebook Pages<span> (</span><a href="https://www.facebook.com/jjookklong3" target="_blank" rel="noopener"><span>1</span></a><span>, </span><a href="https://www.facebook.com/jjookklong3v1/" target="_blank" rel="noopener"><span>2</span></a><span>, </span><a href="https://www.facebook.com/jjookklong3v2" target="_blank" rel="noopener"><span>3</span></a><span>, </span><a href="https://www.facebook.com/profile.php?id=100064600722544" target="_blank" rel="noopener"><span>4</span></a><span>) using the same naming and visual patterns, and reposting the same content as the Twitter account, was published.</span>
<ul>
<li aria-level="2"><span>Unlike the Group, none of them were claimed by <code>@jjookklong3</code></span><span>&nbsp;– at that point steadily at the epicenter of the campaign. In fact, the X profile even </span><a href="https://archive.ph/7lvwK" target="_blank" rel="noopener"><span>repudiated</span></a><span> them on occasions, which apparently prompted the Pages’ administrators to </span><a href="https://archive.ph/NfDas" target="_blank" rel="noopener"><span>explain</span></a><span><a id="fnref10" role="doc-noteref" href="#fn10"><sup>10</sup></a> that their intent was to further amplify the contents of the Twitter account over Facebook.</span></li>
<li aria-level="2"><span>All Pages went inactive in 2021, except for </span><a href="https://www.facebook.com/jjookklong3v1" target="_blank" rel="noopener"><span>one</span></a><span> (เจ๊จุก คลองสาม FC v.1).</span></li>
</ul>
</li>
</ul>
<p><span>A broader set of social media accounts replicating the Twitter account’s and other existing profiles’ patterns was published in the subsequent years:</span></p>
<ul>
<li aria-level="1"><span>An Instagram </span><a href="https://instagram.com/jjook_klong3/" target="_blank" rel="noopener"><span>account</span></a><span> with two posts, which was linked to in the bio header of the <code>@jjookklong3</code></span><span>&nbsp;Twitter account, allowing us to confirm it as affiliated.</span></li>
<li aria-level="1"><span>A TikTok </span><a href="https://www.tiktok.com/@jjook_klong3" target="_blank" rel="noopener"><span>profile</span></a><span>, with only one video posted.</span></li>
<li aria-level="1"><span>A Telegram </span><a href="https://t.me/jjookklong3" target="_blank"><span>account</span></a><span> – we were unable to review its posts.</span></li>
<li aria-level="1"><span>A Threads </span><a href="https://www.threads.net/@jjook_klong3" target="_blank" rel="noopener"><span>profile</span></a><span> with approximately 30 publicly visible posts</span><span>.<a id="fnref11" role="doc-noteref" href="#fn11"><sup>11</sup></a></span></li>
</ul>
<p><span>On April 4, 2025, as we were preparing this report for publication, a new </span><a href="https://www.facebook.com/jjook.klongsam" target="_blank" rel="noopener"><span>Facebook Page</span></a><span> was created. For the first time, the X profile </span><code><span>@jjookklong3</span></code> <a href="https://archive.ph/vAkAr" target="_blank" rel="noopener"><span>claimed it</span></a><span> as its own, and asked its X audience to follow it. Given the limited available time, we did not conduct in-depth analysis of the Page’s activity.</span></p>
<p>Overall, the core of the activity for the operations appeared to rely on the X profile and the Facebook Group. However, the ostensibly “unofficial” (but evidently tolerated, at the very least) Facebook Pages effectively also acted as an amplifier for the same harassment and doxxing content posted on Twitter. <span>The newly created “official” Facebook Page could now also acquire a prominent role in the campaign, showing it as fully active as of April 2025.</span></p>
<h2><strong><a id="ecosystem"></a>A Broader Ecosystem</strong></h2>
<p><span>While their analysis is out of scope for this report, we nonetheless note that JUICYJAM does not exist in isolation. We were able to identify several other social media entities covertly amplifying its contents, as well as producing their own.</span></p>
<p><span>Several of the social media handles revealed as operated by the Thai authorities in the March 2025 leak were also found to be reposting, or otherwise interacting with JUICYJAM.</span></p>
<p><span>Finally, we found at least one news channel consistently amplifying and propagating JUICYJAM’s doxxing posts, both on broadcast and social media.</span></p>
<h2><strong>Confirming JUICYJAM as an Influence Operation</strong></h2>
<p><span>Several signals had pointed us towards the assessment that “Ms. Juk Khlong Sam”</span> <span>was most likely an inauthentic persona.</span></p>
<ol>
<li aria-level="1"><span>First, no piece of content ever posted by any of the JUICYJAM online assets contained verified identifiable information on the account’s owner. Claims that the operator owned a factory, that “she” was a middle-aged woman with a past in the protest movement herself, or that she had directly taken pictures of protesters – none of that could be confirmed through what the persona ever published.</span></li>
<li aria-level="1"><span>Secondly, a significant portion of the photographic and video footage included in the posts, as well as many of the personal details shared about the targets, could not reasonably have been sourced by a private individual. We show a few examples below.<br>
</span></li>
</ol>
<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-6.png" alt="" width="1074" height="949" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 6" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-6.png 1074w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-300x265.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-1024x905.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-768x679.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-385x340.png 385w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-225x199.png 225w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-313x277.png 313w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-6-180x159.png 180w" sizes="auto, (max-width: 1074px) 100vw, 1074px"></p><figcaption><strong>Figure 6.</strong> A screenshot from a <a href="https://x.com/jjookklong3/status/1344546206555406337" target="_blank">tweet</a> (<a href="https://archive.ph/iKogj" target="_blank" rel="noopener">archive</a>) posted by <code>@jjookklong3</code> on December 31, 2020. In the text, the account operator claims to have “told my subordinates to take the video”. The recording happened in the middle of a riot police unit heading towards the suppression of a protest event.</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-7.png" alt="" width="1123" height="1004" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 7" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-7.png 1123w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-300x268.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-1024x915.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-768x687.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-380x340.png 380w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-223x199.png 223w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-310x277.png 310w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-7-180x161.png 180w" sizes="auto, (max-width: 1123px) 100vw, 1123px"></p><figcaption><strong>Figure 7.</strong> Another example (<a href="https://x.com/jjookklong3/status/1344833884983160832" target="_blank">tweet</a>, <a href="https://archive.ph/jRZ8r" target="_blank" rel="noopener">archive</a>) of a video taken from within a group of police officers – therefore, most likely by one of them, or an authorized partner – during a confrontation with demonstrators.</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new.png" alt="" width="497" height="776" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 8" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new.png 497w, https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new-192x300.png 192w, https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new-218x340.png 218w, https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new-127x199.png 127w, https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new-177x277.png 177w, https://citizenlab.ca/wp-content/uploads/2025/04/fig8-new-180x281.png 180w" sizes="auto, (max-width: 497px) 100vw, 497px"></p><figcaption><strong>Figure 8. <span>A Facebook post originally published by iLaw, a Thai civil society organization, which was re-shared and captioned by a target who was later doxxed in a blog post on jjookklong3.wordpress[.]com. The screenshot was used as evidence that the target insulted the monarchy. The post’s privacy settings (highlighted in red) show that it was originally only visible&nbsp; to the target’s Facebook contacts. This denotes privileged access to the content by the JUICYJAM operators, either directly (for example, through the confiscation of a phone, or the planting of spyware on it), or via sources, such as a malicious or compromised contact who could view the post.&nbsp;</span></strong></figcaption></figure>
<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-9.png" alt="" width="1123" height="862" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 9" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-9.png 1123w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-300x230.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-1024x786.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-768x590.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-443x340.png 443w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-259x199.png 259w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-361x277.png 361w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-9-180x138.png 180w" sizes="auto, (max-width: 1123px) 100vw, 1123px"></p><figcaption><strong>Figure 9.</strong> A<span>&nbsp;</span><a href="https://www.facebook.com/jjookklong3/posts/pfbid0dYyWxrovyyeyLwxnD2gLRi9PwWzQfReSvS6BcskbbCeCSCKuSB1cc7MG1RX8PnWvl" target="_blank" rel="noopener"><span>post</span></a><span> doxxing a protestor published by the Facebook Page “เจ๊จุก คลองสาม FC” on August 15, 2021. The composite of photos includes private pictures; pictures from a demonstration; one Facebook post by the target person originally set to be only visible to friends (therefore, only accessible by the person’s approved contacts, or by an actor with privileged access – such as for example the military, or the police); and a picture from a work badge (as seen in </span><a href="https://www.facebook.com/photo.php?fbid=10157827966752163&amp;set=p.10157827966752163&amp;type=3" target="_blank" rel="noopener"><span>this other post</span></a><span>).</span></figcaption></figure>

<h2><strong>Attributing JUICYJAM</strong></h2>
<p>Based on the leaked documents, as well as circumstantial evidence we have collected during our research, we can now attribute JUICYJAM to the Royal Thai Armed Forces and/or the Royal Thai Police. Drawing from our observations – discussed in the following section – on the content type, behavioural patterns, and language utilized for JUICYJAM, however, we assess that this particular operation is more likely to be run by the Royal Thai Police. We detail the rationale behind our assessment further below.</p>
<h2><strong>Evidence from Leaked Documents</strong></h2>
<p><span>It is important to start by saying that the documents released to the public on March 25, 2025 show an alleged coordinated effort across multiple branches of the Thai military and police forces since at least 2023. JUICYJAM – active since 2020 – was probably merged into the broader coordinated effort when that was formed.</span></p>
<p><span>As summarized by the local news outlet </span><a href="https://archive.ph/N10Gx" target="_blank" rel="noopener"><span>Thai Enquirer</span></a><span>, “documents from the army show that before the 2023 election, the military convened security meetings to analyze movements deemed anti-monarchy. This led to the creation of a “Special Security Task Force” coordinating operations across military branches.” Additionally, “the Cyber Team was established to coordinate efforts across agencies”, and “the IO structure was unified before the 2023 election”. The 2023 Thai general election happened on </span><a href="https://web.archive.org/web/20230320164814/https://ratchakitcha.soc.go.th/documents/140A022N0000000000100.pdf" target="_blank" rel="noopener"><span>May 14, 2023</span></a><span>.</span></p>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-10.png" alt="" width="893" height="818" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 10" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-10.png 893w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-300x275.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-768x703.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-371x340.png 371w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-217x199.png 217w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-302x277.png 302w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-10-180x165.png 180w" sizes="auto, (max-width: 893px) 100vw, 893px"></p><figcaption><strong>Figure 10.</strong>&nbsp;The organizational chart of the “Cyber Team” leadership, created in 2023 to coordinate the influence operations efforts by the Thai government, as shown on one of the leaked documents (คณะทำงาน ความมั่นคงพิเศษ ทบ Cyber team.pdf). The column at the right end identifies police officials – marked by red boxes – while the other columns show military officials. The picture was posted by the X account for Thai Enquirer at this <a href="https://x.com/ThaiEnquirer/status/1904559473940955395/photo/1" target="_blank">address</a> (<a href="https://archive.ph/Vb34j" target="_blank" rel="noopener">archive</a>).</figcaption></figure>

<p>In this context, we could identify at least two leaked presentations intended to demonstrate the Cyber Team’s tactics to an internal audience. As part of that demonstration, the two documents show a total of five tweets that we can prove were published by the Twitter (X) account <code>@jjookklong3</code>.</p>
<p>The files are titled “Our Strategy August 67”<a id="fnref12" role="doc-noteref" href="#fn12"><sup>12</sup></a> (ยุทธศาสตร์ฝ่ายเรา สิงหาคม 67.pdf) and “Our Strategy October 67” (ยุทธศาสตร์ฝ่ายเรา ตุลาคม 67.pdf), respectively.</p>
<p><span>The slides present the tweets by <code>@jjookklong3</code></span><span>&nbsp;– whose handle, as previously mentioned, is redacted – as tactical responses deployed to suppress protest narratives perceived as threatening for the establishment.</span></p>
<p><span>The first example showed how <code>@jjookklong3</code> </span><span>was utilized to counter a specific protest narrative. The narrative was popularized in response to the arrest and conviction of Jatuporn Sae-ung, an activist whose doxxing we address later on in this report.&nbsp;</span></p>
<p><span>In the leaked slides provided below, <code>@jjookklong3</code> </span><span>was employed by the ‘Cyber Team’ to counteract the protest narrative through two common IO methods:</span></p>
<ol>
<li aria-level="1"><span>Distraction: moving the focus of its audience towards a more defensible argument than the one for which the target was arrested and charged;</span></li>
<li aria-level="1"><span>Smear: discrediting the target by suggesting they were associated with a given person or group (in the example provided, a now disbanded political party in the Thai opposition).&nbsp;</span></li>
</ol>
<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-11.png" alt="" width="1120" height="628" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 11" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-11.png 1120w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-300x168.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-1024x574.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-768x431.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-605x340.png 605w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-297x167.png 297w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-494x277.png 494w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-11-180x101.png 180w" sizes="auto, (max-width: 1120px) 100vw, 1120px"></p><figcaption><strong>Figure 11.</strong> A slide on page 33 of the leaked document “ยุทธศาสตร์ฝ่ายเรา สิงหาคม 67.pdf” (Our Strategy August 67.pdf), titled “Countering the distorted narrative: ‘Just wearing traditional Thai costume could get you charged under Section 112’”. The two screenshots presented are taken from tweets by <code>@jjookklong3</code>, originally posted <a href="https://x.com/jjookklong3/status/1825405903182643209" target="_blank">here</a> (<a href="https://archive.ph/9osXy" target="_blank" rel="noopener">archive</a>) and <a href="https://x.com/jjookklong3/status/1825839714475106715" target="_blank">here</a> (<a href="https://archive.ph/mukl3" target="_blank" rel="noopener">archive</a>).</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-12.png" alt="" width="666" height="1081" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 12" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-12.png 666w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-185x300.png 185w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-631x1024.png 631w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-209x340.png 209w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-123x199.png 123w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-171x277.png 171w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-12-180x292.png 180w" sizes="auto, (max-width: 666px) 100vw, 666px"></p><figcaption><strong>Figure 12.</strong> A screenshot from the original <a href="https://archive.ph/9osXy" target="_blank" rel="noopener">tweet</a> by <code>@jjookklong3</code> shown on the left half of the leaked presentation slide, highlighting a photo captioned:“Love the remix of the Royal Guards March on the background”. The caption on the&nbsp; post by <code>@jjookklong3</code> states: “It was not simply about wearing a traditional Thai costume. Whoever thinks this is not wrong, just come out and wear the costume. Do you dare to do that?”</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-13.png" alt="" width="848" height="945" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 13" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-13.png 848w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-269x300.png 269w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-768x856.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-305x340.png 305w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-179x199.png 179w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-249x277.png 249w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-13-180x201.png 180w" sizes="auto, (max-width: 848px) 100vw, 848px"></p><figcaption><strong>Figure 13.</strong> A screenshot from the original <a href="https://archive.ph/mukl3" target="_blank" rel="noopener">tweet</a> by <code>@jjookklong3</code> shown on the right half of the leaked presentation slide, with a caption stating “The organisers of the protest prepared everything from the theme, scene, actors, and banners. Anybody who sees this can immediately understand what their intention was. It is not simply wearing a traditional Thai costume.”</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-14.png" alt="" width="1122" height="673" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 14" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-14.png 1122w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-300x180.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-1024x614.png 1024w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-768x461.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-567x340.png 567w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-297x178.png 297w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-462x277.png 462w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-14-180x108.png 180w" sizes="auto, (max-width: 1122px) 100vw, 1122px"></p><figcaption><strong>Figure 14.</strong> A slide on page 18 of the leaked document “ยุทธศาสตร์ฝ่ายเรา สิงหาคม 67.pdf” (Our Strategy August 67.pdf), titled “Linking “New” Jatuporn Sae-ung to the Move Forward Party Leaders.”</figcaption></figure>

<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/fig-15.png" alt="" width="801" height="924" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 15" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/fig-15.png 801w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-260x300.png 260w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-768x886.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-295x340.png 295w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-173x199.png 173w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-240x277.png 240w, https://citizenlab.ca/wp-content/uploads/2025/04/fig-15-180x208.png 180w" sizes="auto, (max-width: 801px) 100vw, 801px"></p><figcaption><strong>Figure 15.</strong> A screenshot from the original tweet by <code>@jjookklong3</code> shown on the left half of the leaked presentation slide at page 18, with a caption stating: “Wearing a traditional Thai costume does not get you a lèse-majesté charge. So good at lying. You do not need to look so far to the Arun Temple. Just look at those who are close to you who wear traditional Thai costumes and do not get the charge. Stop lying to the people. #Supporting112 #MustEndUpInJail”. The tweet was originally posted <a href="https://x.com/jjookklong3/status/1825736668298490288" target="_blank">here</a> (<a href="https://archive.ph/pI1IF" target="_blank" rel="noopener">archive</a>).</figcaption></figure>

<p><span>In addition to the examples shown above, within the leaked slides we could also identify:</span></p>
<ul>
<li aria-level="1"><span>The targeted response to the publication of a book by an academic professor – Puangthong Pawakapan – critical of the military rule (document titled: “ยุทธศาสตร์ฝ่ายเรา ตุลาคม 67.pdf”, page 5. Original tweet posted </span><a href="https://x.com/jjookklong3/status/1849331238240477406" target="_blank"><span>here</span></a><span>, and archived </span><a href="https://archive.ph/3Y5GC" target="_blank" rel="noopener"><span>here</span></a><span>). The slide also illustrates the coordinated use of the hashtag </span><span>#ในนามความมั่นคงภายใน</span><span> (“</span><span>#InTheNameOfInternalSecurity</span><span>”).</span></li>
<li aria-level="1"><span>The deliberate framing of a protest leader – Panupong “Mike Rayong” Jadnok – as “living a comfortable life”, in an apparent attempt to discredit him in the eyes of his supporters (document titled: ยุทธศาสตร์ฝ่ายเรา ตุลาคม 67.pdf, page 4. Original tweets posted </span><a href="https://x.com/jjookklong3/status/1849292366441861369" target="_blank"><span>here</span></a><span> and </span><a href="https://x.com/jjookklong3/status/1848658805963505884" target="_blank"><span>here</span></a><span>; archived </span><a href="https://archive.ph/jpeD6" target="_blank" rel="noopener"><span>here</span></a><span> and </span><a href="https://archive.ph/xxwsJ" target="_blank" rel="noopener"><span>here</span></a><span>).</span></li>
<li aria-level="1"><span>A mocking, derogatory response to requests for an amnesty towards the protesters imprisoned under the Section 112 of the Thai Criminal Code (</span><i><span>Lèse-majesté</span></i><span>). (Document titled: ยุทธศาสตร์ฝ่ายเรา ตุลาคม 67.pdf, page 5. Original tweet posted </span><a href="https://x.com/jjookklong3/status/1848279553116123248" target="_blank"><span>here</span></a><span> (</span><a href="https://archive.ph/hgnGw" target="_blank" rel="noopener"><span>archive</span></a><span>)).</span></li>
</ul>
<p><span>The reproduction, verbatim, of tweets by <code>@jjookklong3</code></span><span>&nbsp;in the context of regular internal reports on the IO tactics deployed by the interforce “cyber team” has no other plausible explanation than the fact that the account – and therefore the entire campaign – was run by the Cyber Team itself.</span></p>
<p><span>As for the specific branch responsible for creating and operating JUICYJAM, we cannot reach a definitive conclusion. However, we do note</span> circumstantial evidence <span>that this particular IO could be conducted by the</span> Royal Thai Police<span>. For example:</span></p>
<ul>
<li>In the <a href="#background">mentioned 2020 influence operation</a> attributed to the Royal Thai Army by X, formerly Twitter, the tweets made available by the platform showed an insisted focus on promoting the Royal Thai Army and attacking individual protesters.</li>
<li>A qualitative comparison of the language used by the 2020 IO and @jjookklong3 shows a clear difference. @jjookklong3’s focus is on targeting individual protesters, calling for their arrest, and promoting the Royal Thai Police.</li>
<li>As mentioned before, several pieces of photographic and video content posted by @jjookklong3 – and the connected social media and blogging handles – appear to have been either captured or likely acquired by the Royal Thai Police.</li>
</ul>
<h2><strong><a id="real-life-impact-of-JJ"></a>The Real-Life Impact of JUICYJAM: A Multidimensional Attack on the Protest Movement</strong></h2>
<p><span>Like comparable influence operations designed to quash protest movements and prop autocratic regimes, it is critical to consider the real-life implications of JUICYJAM. Similarly to what we had highlighted in the context of the 2020-2021 pro-democracy protests in Hong Kong – see our report on the “</span><a href="https://citizenlab.ca/2023/07/hkleaks-covert-and-overt-online-harassment-tactics-to-repress-the-2019-hong-kong-protests/"><span>HKLEAKS</span></a><span>” campaign – the Thai actors appear to maximize their impact through the concurrent action of smear campaigns, intimidation, illegal assaults, and judicial harassment.</span></p>
<p><span>We identified a pattern that linked the doxxing and online harassment of individual protesters by </span><span><code>@jjookklong3</code> </span><span>to their arbitrary detention, and subsequent charging, by the local authorities. On some occasions, the targets have also been assaulted by unidentified masked gangs before their arrest.</span></p>
<p><span>The modus operandi utilized the following methods:</span></p>
<figure><p><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176.png" alt="" width="829" height="638" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 16" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176.png 829w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-300x231.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-768x591.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-442x340.png 442w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-259x199.png 259w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-360x277.png 360w, https://citizenlab.ca/wp-content/uploads/2025/04/JuicyJam-IO-tactics-1-e1744059145176-180x139.png 180w" sizes="auto, (max-width: 829px) 100vw, 829px"></p><figcaption>View footnotes <a id="fnref13" role="doc-noteref" href="#fn13"><sup>13</sup></a> and&nbsp; <a id="fnref14" role="doc-noteref" href="#fn14"><sup>14</sup></a></figcaption></figure>
<p>The ultimate goal of following up doxxing with judicial harassment – a process that has been documented in <a href="https://www.tandfonline.com/doi/full/10.1080/13510347.2025.2461478" target="_blank" rel="noopener"><span>previous research</span></a><span> – is to reduce the target to silence and inaction, if not exile, through the combined power of covert and overt repression.</span></p>
<p><span>A few examples of the impact of these combined methods include:</span></p>
<ul>
<li aria-level="1"><b>Jatuporn Sae-ung (จตุพร แซ่อึง), also known as “New”</b>
<ul>
<li aria-level="1"><span>Jatuporn Sae-ung was at the centre of the </span><code>@jjookklong3</code> <span>tweets we observed as part of the leaked documents allowing us to attribute the campaign to the Thai authorities. She was accused by JUICYJAM of having mocked the Monarchy – a crime punishable under the </span><i><span>lèse-majesté</span></i><span> law, also known as Section 112 – for wearing a traditional Thai costume at a protest demonstration.</span></li>
<li aria-level="1"><span>The JUICYJAM action was twofold: it doxxed and belittled Jatuporn (tweet </span><a href="https://archive.ph/PCVLC" target="_blank" rel="noopener"><span>here</span></a><span>) and the protesters (</span><a href="https://archive.ph/mukl3" target="_blank" rel="noopener"><span>here</span></a><span>) in regards to the traditional costume, and to the related protest; and it sought to link her to the now-defunct opposition Move Forward Party (</span><a href="https://archive.ph/pI1IF" target="_blank" rel="noopener"><span>here</span></a><span>). Two of these tweets were shown in the leaked presentation slides promoting the “Cyber Team” actions internally, as seen in the previous sections.</span></li>
<li aria-level="1"><span>In September 2022, Jatuporn was </span><a href="https://archive.ph/atqtY" target="_blank" rel="noopener"><span>sentenced</span></a><span><span> to three years in prison for mocking Queen Suthida, and temporarily released on bail.<br>
</span></span></li>
</ul>
</li>
</ul>
<ul>
<li aria-level="1"><span><b>Itthikorn Sapchang</b> (</span><span>อิทธิกร ทรัพย์แฉ่ง)</span>
<ul>
<li aria-level="2"><span>Itthikorn Sapchang participated in several events organized by the </span><a href="https://www.facebook.com/FreeYOUTHth" target="_blank" rel="noopener"><span>Free YOUTH</span></a><span> (</span><span>เยาวชนปลดแอก) </span><span>movement, one of most active protest groups.&nbsp;</span></li>
<li aria-level="2"><span>On March 20, 2021, he joined a demonstration dubbed REDEM, which was organized by Free YOUTH and the Democracy Restoration Group (DRG) in Bangkok.&nbsp;</span></li>
<li aria-level="2"><span>Later on the same night, he was assaulted and brutally beaten by an unidentified group dressed in black. According to a Facebook </span><a href="https://www.facebook.com/poramin.rassameesawas/posts/pfbid0jpCoFpJSBUqA3JAAG8QeW2meA4hjypZRqVrjnGVRrU2BKiyvtZnAsBUzaTukqdvnl" target="_blank" rel="noopener"><span>post</span></a><span> published by a friend of his, he was beaten with steel batons, and “suffered a cracked head, a cracked cheek, and a cracked lip. He required 14 stitches in total. The doctor said it affected nerves and could cause disability, and he needed to be closely monitored.”</span></li>
<li aria-level="2"><span>A photo published on the same Facebook post showed the outcome of the attack [</span><b>WARNING</b><span><span>: graphic picture – click to view]</span></span><figure><p><a href="https://citizenlab.ca/wp-content/uploads/2025/04/fig-16.png"><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8.png" alt="" width="715" height="715" title="JUICYJAM: How Thai Authorities Use Online Doxxing to Suppress Dissent 17" srcset="https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8.png 912w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-300x300.png 300w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-150x150.png 150w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-768x768.png 768w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-340x340.png 340w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-199x199.png 199w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-277x277.png 277w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-180x180.png 180w, https://citizenlab.ca/wp-content/uploads/2025/04/3aef4b77-d28a-45c6-96bf-f0175ab329f8-125x125.png 125w" sizes="auto, (max-width: 715px) 100vw, 715px"></a></p><figcaption><strong>Figure 16. </strong><em>[Graphic content warning – click image to view]</em> A photo of of Itthikorn Sapchang lying on the ground immediately after the assault he suffered on March 20, 2021, following his participation in a protest in Bangkok. Originally <a href="https://www.facebook.com/poramin.rassameesawas/posts/pfbid0jpCoFpJSBUqA3JAAG8QeW2meA4hjypZRqVrjnGVRrU2BKiyvtZnAsBUzaTukqdvnl" target="_blank" rel="noopener">posted here</a>.</figcaption></figure></li>
</ul>
</li>
</ul>
<ul>
<li>
<ul>
<li aria-level="1"><span>The Royal Thai Police claimed that they could not identify the perpetrators, as they alleged that every CCTV camera in the area was broken – as claimed in the same Facebook post.</span></li>
<li aria-level="1"><span>On May 2, 2021, after Itthikorn had joined another REDEM demonstration on that same day, </span><span>@jjookklong3</span> <a href="https://x.com/jjookklong3/status/1388805856624484352" target="_blank"><span>posted</span></a><span> (</span><a href="https://archive.ph/QAS5H" target="_blank" rel="noopener"><span>archive</span></a><span>) photos of a man strongly resembling him, although his face was covered by a motorbike helmet. It asked its followers: “guess who [is it]?”</span>
<ul>
<li aria-level="1"><span>We note that the man shown in the photos has a similar build as Itthikorn, as well as similar clothing to the one he wore when he was assaulted on March 20, 2021. </span></li>
</ul>
</li>
<li aria-level="1">Eventually, on May 14, 2021, he was <a href="https://tlhr2014.com/archives/29719" target="_blank" rel="noopener">charged</a> with “gathering in groups of 10 or more people, using violence to cause chaos in the country, where one of the offenders is armed; when an official orders the gathering to stop and the offenders do not stop; gathering in violation of the Emergency Decree and the Communicable Disease Act; contempt of court or judges during a hearing; using a loudspeaker without permission; and obstructing the sidewalk in violation of the Traffic Act and the Cleanliness Act.”</li>
</ul>
</li>
</ul>
<ul>
<li aria-level="1"><b>Weeraphab Wongsaman (</b><b>วีรภาพ วงษ์สมาน)</b><b>, also known as “Rev’’</b>
<ul>
<li aria-level="2"><span>The protester nicknamed “Rev” was </span><a href="https://web.archive.org/web/20210327203140/https://twitter.com/jjookklong3/status/1375427669198696450" target="_blank" rel="noopener"><span>doxxed</span></a><span><a id="fnref15" role="doc-noteref" href="#fn15"><sup>15</sup></a> by <code>@jjookklong3</code> on March 26, 2021, after he allegedly participated in the mentioned March 20th REDEM protest. Rev became a frequent target of </span><span><code>@jjookklong3</code></span><span>, identifying him in protest images from </span><a href="https://web.archive.org/web/20210503065448/https://twitter.com/jjookklong3/status/1389111122372923392" target="_blank" rel="noopener"><span>May</span></a><span>, </span><a href="https://archive.ph/rWFic" target="_blank" rel="noopener"><span>July</span></a><span>, </span><a href="https://archive.ph/oMUM1" target="_blank" rel="noopener"><span>August</span></a><span>, and </span><a href="https://archive.ph/gWkuE" target="_blank" rel="noopener"><span>September</span></a><span> 2021.</span></li>
<li aria-level="2"><span>On May 14, 2021, he was arrested for participating in the May 2 REDEM rally and released on bail.&nbsp;</span></li>
<li aria-level="2"><span>On September 15, 2021, he was arrested for his alleged participation in the September 13 Din Daeng protest and held in pre-trial detention at the Bangkok Remand Prison.&nbsp;</span></li>
<li aria-level="2"><span>On October 29, 2021, “Rev” and another activist, Auttasit Nussa, were dragged and </span><a href="https://archive.ph/He9nr" target="_blank" rel="noopener"><span>beaten</span></a><span> by the police while they were in custody at the Din Daeng Police Station.</span></li>
<li aria-level="2"><span>In November 2021, “Rev” and Auttasit filed a complaint against the police at the Din Daeng police station, and later at the Department of Special Investigation (DSI). Despite requesting CCTV footage of the incident, the police refused to give it to them. The investigation was eventually </span><a href="https://archive.ph/XJIOI" target="_blank" rel="noopener"><span>closed</span></a><span>, as the Torture Sub-committee determined that the beating did not constitute torture.</span></li>
<li aria-level="2"><span>On September 28, 2023, he was </span><a href="https://archive.ph/qRigH" target="_blank" rel="noopener"><span>sentenced</span></a><span> to three years in prison for </span><i><span>lèse-majesté</span></i><span>. He remains in prison since then after having been denied multiple bail requests.</span></li>
</ul>
</li>
</ul>
<h2><strong>How Could JUICYJAM Operate Unchallenged For So Long?</strong></h2>
<h2><strong>Key Factors</strong></h2>
<ul>
<li aria-level="1"><span>The notion of doxxing is only sparsely captured within the policies of the main social media platforms.&nbsp; It is therefore difficult for an external reader to conclusively identify the rules and actions that the platforms promise to enact in response to its deployment.</span></li>
<li aria-level="1"><span>Moreover, as doxxing is typically framed merely as a privacy violation, the platforms’ policies do not expressly consider its use by adversarial coordinated actors, particularly in the context of state repression.</span></li>
<li aria-level="1"><span>Additionally, our analysis of JUICYJAM’s history shows that even when doxxing is specifically mentioned in policies, the related prohibitions are inconsistently enforced on.</span></li>
</ul>
<h2><strong>Reviewing the Policies on Doxxing for X and Meta</strong></h2>
<p><span>In the current version of their </span><a href="https://help.x.com/en/rules-and-policies/personal-information" target="_blank" rel="noopener"><span>Private Information policy</span></a><span> (last updated in March 2024), </span>X<span> states:&nbsp;</span></p>
<figure><div><span>“You may not threaten to expose, incentivize others to expose, or publish or post other people’s private information without their express authorization and permission, or share private media of individuals without their consent. </span><span>&nbsp;</span>
<p><span>Sharing someone’s private information online without their permission, sometimes called “doxxing,” is a breach of their privacy and can pose serious safety and security risks for those affected.”</span></p></div></figure>
<p><span>While JUICYJAM did primarily post pictures and videos taken at public demonstrations, it very frequently enriched them with private information and footage, including in certain cases government IDs and other official documents – which would most definitely qualify as “a breach of [the targets’] privacy” and posing “serious safety and security risks for those affected”. The continued, and highly prominent, activity and existence of the </span><code>@jjookklong3</code><span> account therefore appears to be a clear failure in this policy’s enforcement by the platform.</span></p>
<p><span>Additionally:</span></p>
<ul>
<li aria-level="1"><span>Platforms’ policies on doxxing seldom consider the behaviour in the context of coordinated – and often state-sponsored – campaigns against civil society, where the great imbalance of power between attackers and targets exponentially increases their harm, as we have seen in this report.&nbsp;</span></li>
<li aria-level="1"><span>They also do not consider environmental factors, such as the doxxing happening during unrest and protests.</span></li>
</ul>
<p><span>In <a href="https://www.oversightboard.com/news/673967193790462-oversight-board-publishes-policy-advisory-opinion-on-the-sharing-of-private-residential-information/" target="_blank" rel="noopener">2022</a>, these issues were addressed in a set of 17 recommendations made to Meta by the Oversight Board <a id="fnref16" role="doc-noteref" href="#fn16"><sup>16</sup></a> </span><span>&nbsp;in response to a request for a policy advisory opinion on “Sharing Private Residential Information”<a id="fnref17" role="doc-noteref" href="#fn17"><sup>17</sup></a>. Recommendations 11 and 12 are especially relevant to the case of JUICYJAM:</span></p>
<figure><div><table>
<tbody>
<tr>
<td><span><strong>Recommendation</strong><br>
</span></td>
<td><strong>Details</strong></td>
</tr>
<tr>
<td><a href="https://transparency.meta.com/en-gb/pao-private-residential-information-policy" target="_blank" rel="noopener"><span>Private Residential Info Policy Advisory Opinion – Recommendation #11</span></a></td>
<td>Meta should create a specific channel of communications for victims of doxing (available both for users and non-users). Additionally, Meta could provide financial support to organizations that already have hotlines in place. Meta should prioritize action when the impacted person references belonging to a group facing heightened risk to safety in the region where the private residence is located. The Board will consider this implemented when Meta creates the channel and publicly announces how to use it.</td>
</tr>
<tr>
<td><a href="https://transparency.meta.com/en-gb/pao-private-residential-information-policy" target="_blank" rel="noopener"><span>Private Residential Info Policy Advisory Opinion – Recommendation #12</span></a></td>
<td>Meta should consider the violation of its Privacy Violations policy as “severe,” prompting temporary account suspension, in cases where the sharing of private residential information is clearly related to malicious action that created a risk of violence or harassment. The Board will consider this implemented when Meta updates its Transparency Center description of the strikes system to make clear that some Privacy Violations are severe and may result in account suspension.</td>
</tr>
</tbody>
</table></div><figcaption><p><span><strong>Table 1.</strong> Recommendations 11 and 12 as provided by the Oversight Board to Meta. Excerpt from the </span><a href="https://transparency.meta.com/en-gb/pao-private-residential-information-policy" target="_blank" rel="noopener"><span>full list</span></a><span> of 17 recommendations provided in response to the company’s </span><a href="https://www.oversightboard.com/news/673967193790462-oversight-board-publishes-policy-advisory-opinion-on-the-sharing-of-private-residential-information/" target="_blank" rel="noopener"><span>request</span></a><span> for a policy advisory opinion on its “Sharing Private Residential Information” policy.</span></p></figcaption></figure>

<p><span>The Oversight Board’s </span><a href="https://transparency.meta.com/en-gb/oversight/oversight-board-recommendations/" target="_blank" rel="noopener"><span>recommendations</span></a><span> – unlike </span><span>decisions</span><span> – are not binding. </span><span>Neither of these recommendations were implemented by Meta at the time of publication of this report.&nbsp;</span></p>
<ul>
<li><span>Recommendation 11 was blocked (“no further action”), with Meta deferring its intended purposes to the existing partnership with “850 safety partners globally, including helplines and organisations that work with victims of harassment, online and offline”.</span></li>
<li><span>Recommendation 12 was initially labeled with “assessing feasibility”, stating that “to assess the board’s recommendation, we will first need to determine how to identify when sharing private residential information ‘is clearly related to malicious action that created a risk of violence or harassment’ and how we can log this type of information in our system.” However, the most recent update was shown to have happened on June 12, 2023.&nbsp;</span>
<ul>
<li><span>We note that in the </span><a href="https://transparency.meta.com/en-gb/oversight/oversight-board-recommendations/" target="_blank" rel="noopener"><span>complete list</span></a><span> of recommendations provided by the Oversight Board to Meta, Recommendation 12 on “Sharing Private Information” is also labelled as “no further action” and “no further updates”, signalling that the company has eventually decided not to implement it.</span></li>
</ul>
</li>
</ul>
<p><span>As shown before in this report <a id="fnref16" role="doc-noteref" href="#fn18"><sup>18</sup></a></span><span>, JUICYJAM’s inauthentic persona, and its doxxing and harassing content, continues to be visible – and highly reachable – on at least four Facebook Pages, one Facebook Group, one Instagram account, and one Threads account as of April 2025.</span></p>
<p><span>Finally, successes in enforcing policies against coordinated doxxing do happen, occasionally. In June 2021, shortly before JUICYJAM started, </span>Google <a href="https://www.reuters.com/world/asia-pacific/google-takes-down-maps-targeting-hundreds-thais-accused-opposing-king-2021-06-28/" target="_blank" rel="noopener"><span>removed</span></a><span> two custom Google Maps that “had listed the names and addresses of hundreds of Thai activists who were accused by royalists of opposing the monarchy”. The maps had been published by a team coordinated by Songklod “Pukem” Chuenchoopol, a prominent pro-monarchy activist, with the intention of reporting everyone named to the police for </span><i><span>lèse-majesté</span></i><span>. We also noticed that the hashtag </span><span>#CaptainPooKhem</span><span> – commonly used by his supporters to amplify his posts – appears to be blocked on </span>Facebook<span>, returning </span><a href="https://www.facebook.com/hashtag/captainpookhem" target="_blank" rel="noopener"><span>no results</span></a><span>. It remains however possible to post it, as can be seen on </span><a href="https://www.facebook.com/TheNationThailand/posts/10157447102161937" target="_blank" rel="noopener"><span>existing posts</span></a><span>.</span></p>
<h2><strong>Conclusions: The Ongoing Harm of Coordinated Doxxing Continues to be Underestimated</strong></h2>
<p><span>Government-operated doxxing campaigns are potent tools of repression, and it is no accident that they are often targeted against peaceful pro-democracy movements.&nbsp; Critically, whether in Hong Kong, Thailand, or </span><a href="https://eastasiaforum.org/2022/12/05/doxxing-and-deficiencies-in-indonesias-cybersecurity-framework/" target="_blank" rel="noopener"><span>elsewhere</span></a><span>, governments and their proxies often deploy them to complement and enhance more traditional forms of state repression, like violence and deprivation of liberty.</span></p>
<p><span>In the case of JUICYJAM, for example, targets of the campaign were also detained, charged, and often physically assaulted.<a id="fnref16" role="doc-noteref" href="#fn19"><sup>19</sup></a></span><span>&nbsp;The harm can be devastating.&nbsp;</span></p>
<h2><strong>Low Risk, High Reward</strong></h2>
<p><span>While JUICYJAM was ostensibly the work of a fictitious persona, the campaign was fueled with information and content only available to government entities. The veil of plausible deniability it offered to them was sufficient for the campaign to thrive for several years before being exposed as linked to the Thai authorities. There is also no guarantee that it will stop now.</span></p>
<p><span>In the conclusions to our </span><a href="https://citizenlab.ca/2023/07/hkleaks-covert-and-overt-online-harassment-tactics-to-repress-the-2019-hong-kong-protests/"><span>report</span></a><span> on the HKLEAKS influence operation – which, as we have seen, followed the same general playbook as JUICYJAM – we had stated: “If digital repression is about raising the cost of activism, then the HKLEAKS case suggests that doxxing can be a fairly low risk but potentially high reward instrument of digital repression.”</span></p>
<p><span>Despite the extremely serious harms for the targets of doxxing campaigns, this statement continues to be accurate.</span></p>
<h2><strong>Coordinated Government-Backed Doxxing: Likely to Grow</strong></h2>
<p><span>JUICYJAM’s five-year-and-counting run in Thailand without serious disruption shows that the current tools, attention, and approach to this problem were largely insufficient to mitigate the harm caused to peaceful protesters and activists.&nbsp;</span></p>
<p><span>Social media companies frame their limited action on doxxing as a necessary balance of freedom of expression and safety (and the difficulties of determining public vs. private information) <a id="fnref16" role="doc-noteref" href="#fn20"><sup>20</sup></a>.</span><span> However, repressive states specifically deploy coordinated doxxing as a technique to punish authentic freedom of expression </span><i><span>and</span></i><span> threaten safety. </span><span>Today, most major social media platforms are moving towards reducing, </span><a href="https://www.forbes.com/sites/thomasbrewster/2024/01/10/elon-musk-fired-80-per-cent-of-twitter-x-engineers-working-on-trust-and-safety/?sh=71c80f1c79b3" target="_blank" rel="noopener"><span>gutting</span></a><span>, and </span><a href="https://www.bbc.co.uk/news/articles/cly74mpy8klo" target="_blank" rel="noopener"><span>eliminating</span></a><span> programs originally aimed at increasing ecosystem safety and health initiatives.&nbsp; Campaigns like JUICYJAM are likely to become more common as states learn from each other and operate in an increasingly permissive environment on certain platforms. The playbook stands to be repeated on a potentially global scale in a world that is seeing a continued </span><a href="https://freedomhouse.org/report/freedom-world/2024/mounting-damage-flawed-elections-and-armed-conflict" target="_blank" rel="noopener"><span>trend of democratic decline</span></a><span>.</span></p>
<h2><strong>Outreach to Platforms</strong></h2>
<p><span>On April 9, 2025, we sent emails to </span><a href="https://citizenlab.ca/wp-content/uploads/2025/04/Citizen-Lab-Letter-to-Meta_Redacted.pdf"><span>Meta</span></a><span> and </span><a href="https://citizenlab.ca/wp-content/uploads/2025/04/Citizen-Lab-Letter-to-X_Redacted.pdf"><span>X</span></a><span> with questions and recommendations to address the concerns raised by our work. At the time of publication, we had not received a response from X. While Meta acknowledged receipt, they did not answer our questions.</span></p>
<p><span>Our recommendations to X and Meta include:</span></p>
<ol>
<li aria-level="1"><b>Provide an easily accessible and responsive way (i.e. a hotline) for victims of doxxing to report the malicious public sharing of their private content</b><span>. The content should be quickly removed after Meta and X verified it as the product of doxxing.</span></li>
<li aria-level="1"><b>Implement instruments for Meta and X to identify, and remove, networks acting in a coordinated manner to conduct doxxing</b><span>. The action should not only consist in the removal of individual pieces of content, but in the simultaneous removal, permanent ban, and subsequent monitoring of the networked actors responsible for the malicious activity.</span></li>
<li aria-level="1"><b>Develop and implement instruments for the protection of civil society from doxxing</b><span> through Meta’s and X’s platforms in hybrid and authoritarian regimes according to The Economist Democracy Index, or Partly Free and Not Free countries according Freedom House’s Freedom in the World survey. Such instruments should include appropriate solutions on both the policy and the technological side.</span></li>
<li aria-level="1"><b>Conduct an audit on the existence and activity of potential coordinated doxxing networks</b>, with priority on illiberal countries as defined per point above. Implement a coordinated removal of the networks confirmed as conducting doxxing. Publicly disclose proven cases of state-sponsored doxxing networks.</li>
</ol>
<h2><strong>Acknowledgements</strong></h2>
<p><span>We would like to thank Rebekah Brown and Siena Anstis, for peer reviewing this report. Special thanks to Adam Senft and Alyson Bruce.</span></p>
<p><span>Research for this project was supervised by Ronald Deibert.</span></p>

<h2><strong>Indicators</strong></h2>
<figure><div><table>
<thead>
<tr>
<th><b>Selector</b></th>
<th><b>Type</b></th>
<th><b>Platform</b></th>
</tr>
</thead>
<tbody>
<tr>
<td>jjookklong3.wordpress[.]com</td>
<td><span>Blog</span></td>
<td><span>WordPress</span></td>
</tr>
<tr>
<td>jjookklong3.blogspot[.]com</td>
<td><span>Blog</span></td>
<td><span>Blogspot</span></td>
</tr>
<tr>
<td>https://www.facebook.com/jjookklong3</td>
<td><span>FB Page</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/jjookklong3v1/</td>
<td><span>FB Page</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/jjookklong3v2</td>
<td><span>FB Page</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/jjook.klongsam</td>
<td><span>FB Page</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/profile.php?id=100064600722544</td>
<td><span>FB Page</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/groups/jjookklong3/</td>
<td><span>FB Group</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/profile.php?id=100066932562498</td>
<td><span>FB Profile (admin of the FB Group)</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/profile.php?id=100061845026654</td>
<td><span>FB Profile (admin of the FB Group)</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/mam.bunyaporn.9</td>
<td><span>FB Profile (admin of the FB Group)</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/ce.cuk.khlxng.sam</td>
<td><span>FB Profile (admin of the FB Group)</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>https://www.facebook.com/profile.php?id=100060925375093</td>
<td><span>FB Profile (admin of the FB Group)</span></td>
<td><span>Facebook</span></td>
</tr>
<tr>
<td>instagram.com/jjook_klong3/</td>
<td><span>Instagram account</span></td>
<td><span>Instagram</span></td>
</tr>
<tr>
<td>https://www.threads.net/@jjook_klong3</td>
<td><span>Threads account</span></td>
<td><span>Threads</span></td>
</tr>
<tr>
<td>https://x.com/jjookklong3</td>
<td><span>X account</span></td>
<td><span>X</span></td>
</tr>
<tr>
<td>https://www.tiktok.com/@jjook_klong3</td>
<td><span>TikTok account</span></td>
<td><span>TikTok</span></td>
</tr>
<tr>
<td><a href="https://citizenlab.ca/cdn-cgi/l/email-protection" data-cfemail="d5bfbfbababebeb9bab8b2e695b2b8b4bcb9fbb6bab8">[email&nbsp;protected]</a><span> <a id="fnref16" role="doc-noteref" href="#fn21"><sup>21</sup></a></span></td>
<td><span>Email address</span></td>
<td><span>Gmail</span></td>
</tr>
<tr>
<td>https://t.me/jjookklong3</td>
<td><span>Telegram user</span></td>
<td><span>Telegram</span></td>
</tr>
<tr>
<td>jjookad</td>
<td><span>WordPress author</span></td>
<td><span>WordPress</span></td>
</tr>
<tr>
<td>https://www.blogger.com/profile/14058024983323444123</td>
<td><span>Blogger profile</span></td>
<td><span>Blogger/Blogspot</span></td>
</tr>
</tbody>
</table></div></figure>

<section id="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn1">“Disclosing networks to our state-linked information operations archive,” October 8, 2020. The entire company blog was scrubbed and is unavailable since the company named Twitter became known as X. <a role="doc-backlink" href="#fnref1">↩︎</a></li>
<li id="fn2">“ฝ่ายค้านกล่าวหารัฐบาลแพทองธาร ปล่อยให้กองทัพมีปฏิบัติการไอโอ – เผย 46 รายชื่อเป้าหมายถูก “ล็อกเป้า” (“Opposition accuses Paethongtarn’s government of allowing the military to carry out IO operations – Reveals 46 target names were “locked on””). <a href="https://www.bbc.com/thai/articles/c20lw5qx4z1o" target="_blank" rel="noopener">BBC News ไทย</a>.<a role="doc-backlink" href="#fnref2">↩︎</a></li>
<li id="fn3"><span>&nbsp;From a purely political point of view, this is notable since Thailand has ostensibly returned to civilian rule in 2023 following the 2014 military coup. Nevertheless, the documents show how the military, and the police, continue to operate covertly, and pervasively, to ensure that power remains in the hands of the pro-establishment representatives. From a technical standpoint, the leak of these documents presents a rare opportunity for researchers to observe the inner workings of a covert influence operation (IO)</span>. <a role="doc-backlink" href="#fnref3">↩︎</a></li>
<li id="fn4">At a <a href="https://drive.google.com/drive/folders/16n2xNG_NvlcEM52vW9uPlpi7bsfVUJ5q" target="_blank" rel="noopener">Google Drive folder</a> linked in a Facebook post on Satondee’s <a href="https://www.facebook.com/photo?fbid=1081526900659087&amp;set=a.307971828014602" target="_blank" rel="noopener">Facebook page</a>.<a role="doc-backlink" href="#fnref4">↩︎</a></li>
<li id="fn5">In the English version, Charlotte Linlin, better known as “<a href="https://onepiece.fandom.com/wiki/Charlotte_Linlin" target="_blank" rel="noopener">Big Mom</a>“, is a villain character, leader of the group called “Big Mom Pirates”. <a role="doc-backlink" href="#fnref5">↩︎</a></li>
<li id="fn6">It has been well documented over a decade of research how even major geopolitical powers like <a href="https://www.wired.com/story/china-bad-at-disinformation/" target="_blank" rel="noopener">China</a>, <a href="https://secondaryinfektion.org/report/lessons-learned-and-questions-unanswered/" target="_blank" rel="noopener">Russia</a>, or <a href="https://citizenlab.ca/2019/05/burned-after-reading-endless-mayflys-ephemeral-disinformation-campaign/">Iran</a> often struggle to acquire authentic audiences and engagement for their influence operations.<a role="doc-backlink" href="#fnref6">↩︎</a></li>
<li id="fn7">https://jjookklong3.wordpress[.]com<a role="doc-backlink" href="#fnref7">↩︎</a></li>
<li id="fn8">https://jjookklong3.blogspot[.]com<a role="doc-backlink" href="#fnref8">↩︎</a></li>
<li id="fn9">On Facebook, a Group is an online community that can be created by any one profile, and managed by multiple profiles at the same time. Groups can be either public or private; additionally, private groups can be either visible, or hidden.<a role="doc-backlink" href="#fnref9">↩︎</a></li>
<li id="fn10">We could no longer locate the original Facebook post shown in this tweet.<a role="doc-backlink" href="#fnref10">↩︎</a></li>
<li id="fn11">As total post numbers are not shown on Threads users’ headers, we cannot accurately estimate the actual amount of posting by the account.<a role="doc-backlink" href="#fnref11">↩︎</a></li>
<li id="fn12">“67” indicates the year 2567 in Buddhist Era according to the <a href="https://en.wikipedia.org/wiki/2024_in_Thailand#:~:text=The%20year%202024%20is%20reckoned,Buddhist%20Era%2C%20the%20Thai%20calendar" target="_blank" rel="noopener">Thai calendar</a>, and corresponds to 2024.<a role="doc-backlink" href="#fnref12">↩︎</a></li>
<li id="fn13">See “<a href="#ecosystem">A Broader Ecosystem</a>”.<a role="doc-backlink" href="#fnref13">↩︎</a></li>
<li id="fn14">It is often assumed within the protest movement that the attackers belonged to radical ultra-royalist groups, such as those united within the “Protecting the Monarchy” umbrella group. They have been <a href="https://prachatai.com/journal/2024/02/108012" target="_blank" rel="noopener">documented</a> as attacking pro-democracy demonstrators in an even overt manner.<a role="doc-backlink" href="#fnref14">↩︎</a></li>
<li id="fn15">Online archive services did not allow us to successfully archive the video attached to the post, which contains the doxxing of “Rev”.<a role="doc-backlink" href="#fnref15">↩︎</a></li>
<li id="fn16">The <a href="https://www.oversightboard.com/" target="_blank" rel="noopener">body was created in 2018</a> as an external reviewer and decision-maker on content moderation issues on Meta’s platforms.<a role="doc-backlink" href="#fnref16">↩︎</a></li>
<li id="fn17">This policy is captured, for Facebook, within the “Privacy violations” section of the platform’s <a href="https://transparency.meta.com/en-gb/policies/community-standards/privacy-violations/" target="_blank" rel="noopener">Community Standards</a>.<a role="doc-backlink" href="#fnref17">↩︎</a></li>
<li id="fn18">See “<a href="#timeline">Timeline</a>“.<a role="doc-backlink" href="#fnref18">↩︎</a></li>
<li id="fn19">See “<a href="#real-life-impact-of-JJ">The Real-Life Impact of JUICYJAM: a Multidimensional Attack on the Protest Movement</a>”<a role="doc-backlink" href="#fnref19">↩︎</a></li>
<li id="fn20">Meta, for example, had requested the mentioned Policy Advisory Opinion on its policy on private residential information from the Oversight Board stating the reason as being: “we found it significant and difficult as it creates tension between our values of voice and safety”. <a href="https://transparency.meta.com/en-gb/pao-private-residential-information-policy" target="_blank" rel="noopener">See here for reference</a>.<a role="doc-backlink" href="#fnref20">↩︎</a></li>
<li id="fn21">Shown on the unofficial Facebook pages. The address seems to misspell the JUICYJAM alias (“m” instead of “n”). <a role="doc-backlink" href="#fnref21">↩︎</a></li>
</ol>
</section>

                </section>
                                 
              </article> 
						
												

			</section>
		</main>
			 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Find the Odd Disk (141 pts)]]></title>
            <link>https://colors2.alessandroroussel.com/</link>
            <guid>43745868</guid>
            <pubDate>Sun, 20 Apr 2025 19:17:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://colors2.alessandroroussel.com/">https://colors2.alessandroroussel.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43745868">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Click the disk that's a different color. Use your eyes only! Make sure to disable any blue-light filter on your screen.
		<br>Clique sur le disque qui est d'une couleur différente. Utilise seulement tes yeux ! Assurez-vous de désactiver tout filtre de lumière bleue sur votre écran.
		<br>Haz clic en el disco que tiene un color diferente. ¡Usa solo tus ojos! Asegúrate de desactivar cualquier filtro de luz azul en tu pantalla.</p><div id="end-screen">
		<h2>Game Over!</h2>
		
		<p>Thank you for participating. Please feel free to play again, the more data the better!
			<br>Merci pour ta participation. N'hésite pas à rejouer, plus il y a de données, mieux c’est !
			<br>Gracias por participar. ¡No dudes en jugar de nuevo, entre más datos tengamos, mejor!</p>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: JuryNow – Get an anonymous instant verdict from 12 real people (200 pts)]]></title>
            <link>https://jurynow.app/</link>
            <guid>43745554</guid>
            <pubDate>Sun, 20 Apr 2025 18:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jurynow.app/">https://jurynow.app/</a>, See on <a href="https://news.ycombinator.com/item?id=43745554">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. citizen in Arizona detained by immigration officials for 10 days (196 pts)]]></title>
            <link>https://news.azpm.org/p/news-articles/2025/4/18/224512-us-citizen-in-arizona-detained-by-immigration-officials-for-10-days/</link>
            <guid>43745469</guid>
            <pubDate>Sun, 20 Apr 2025 18:20:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.azpm.org/p/news-articles/2025/4/18/224512-us-citizen-in-arizona-detained-by-immigration-officials-for-10-days/">https://news.azpm.org/p/news-articles/2025/4/18/224512-us-citizen-in-arizona-detained-by-immigration-officials-for-10-days/</a>, See on <a href="https://news.ycombinator.com/item?id=43745469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img src="https://media.azpm.org/master/image/2019/10/23/hero/ice.jpg" alt="ICE arrests">
<span>A March 2018 photo of U.S. Immigration and Customs Enforcement (ICE) officers.</span></p><p>ICE/Flickr</p>
</div><div>




<p>19-year-old Jose Hermosillo, who is visiting Tucson from Albuquerque, says he was lost and walking near the Border Patrol headquarters when an agent arrested him for illegally entering the country. Hermosillo was not carrying identification.</p>
<p>Court documents say a Border Patrol agent arrested Hermosillo “at or near Nogales, Arizona, without proper immigration documents” and that Hermosillo admitted to illegally entering the U.S.</p>
<p>Hermosillo and his girlfriend, who have a 9-month-old child together, live in Albuquerque, New Mexico, and are visiting family in Tucson. He says he has never been to Nogales. </p>
<p>His girlfriend’s aunt Grace Layva says she and her family made numerous calls looking for him before they found out he was being detained in the Florence Correctional Center, which Immigration and Customs Enforcement uses to detain people. </p>
<p>Another family member drove to the detention center, about 70 miles northwest of Tucson, but said officials wouldn’t provide any information or release him. </p>
<p>ICE did not respond to a request for comment about the wrongful detention. </p>
<p>The family later provided officials with his birth certificate and social security card.</p>
<p>“He did say he was a U.S. citizen, but they didn't believe him,” Layva said. “I think they would have kept him. I think they would have if they would have not got that information yesterday in the court and gave that to ICE and the Border Patrol. He probably would have been deported already to Mexico.”</p>
<p>A magistrate judge in Tucson dismissed his case on Thursday, and family says he was released much later that night. </p>
<p>There have been other recent cases of U.S. citizens being wrongly detained by immigration officials, including a man wrongly held in Florida after being pulled over during his commute to work. </p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First hormone-free male birth control pill enters human trials (191 pts)]]></title>
            <link>https://scitechdaily.com/99-effective-first-hormone-free-male-birth-control-pill-enters-human-trials/</link>
            <guid>43745296</guid>
            <pubDate>Sun, 20 Apr 2025 17:54:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scitechdaily.com/99-effective-first-hormone-free-male-birth-control-pill-enters-human-trials/">https://scitechdaily.com/99-effective-first-hormone-free-male-birth-control-pill-enters-human-trials/</a>, See on <a href="https://news.ycombinator.com/item?id=43745296">Hacker News</a></p>
Couldn't get https://scitechdaily.com/99-effective-first-hormone-free-male-birth-control-pill-enters-human-trials/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[How encryption for Cinema Movies works (130 pts)]]></title>
            <link>https://serverless.industries/2024/05/31/digital-cinema.en.html</link>
            <guid>43745281</guid>
            <pubDate>Sun, 20 Apr 2025 17:52:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://serverless.industries/2024/05/31/digital-cinema.en.html">https://serverless.industries/2024/05/31/digital-cinema.en.html</a>, See on <a href="https://news.ycombinator.com/item?id=43745281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>The Cinema Industry is using its own standards for creating and distributing movies in a secure way. The DCI (Digital Cinema Initiatives) specification defines everything from file formats and encryption to the projection systems itself.</p>

<p>The specification itself is <a href="https://www.dcimovies.com/" target="_blank">publicly available</a> but relies on various IEEE (Institute of Electrical and Electronics Engineers) and SMPTE (Society of Motion Picture and Television Engineers) standards, which have to be purchased.</p>

<h2 id="scope">Scope</h2>

<p>This document will show a rough overview of the DCI workflow and describe in detail how the encryption of a DCI movie works. It will <strong>not</strong> show how to break any encryption and no encryption has been broken while writing this document. <strong>From our perspective, the DCI standard is safe</strong>.</p>

<p>The author of this document has been operating a cinema since 2021, without any insight to the distribution or production side of the industry. Some information may be incomplete.</p>

<h2 id="how-its-started">How it’s started</h2>

<p>End of 2023 the movie <a href="https://www.imdb.com/title/tt6166392/" target="_blank">WONKA</a> was released. Some cinemas reported, that they are unable to start this movie on their projector.</p>

<p>The reason was, that a certificate used by the distributor was expired. This certificate was used to sign the DCP files.</p>

<p>The distributor published new files, starting the movie worked again.</p>

<p>Out of curiosity the author started to check how the validation process on the projector is working.</p>

<h2 id="glossar">Glossar</h2>

<ul>
  <li>
<strong>DCP</strong>: Digital Cinema Package - A folder which contains all components of a movie. Metadata, Subtitles, Audio and Picture in seperate files</li>
  <li>
<strong>CPL</strong>: Composition Playlist - A DCP can contain multiple audio and video streams which will combined in a CPL</li>
  <li>
<strong>KDM</strong>: Key Delivery Message - A XML file which contains the cryptographical information to allow a movie playback on a specific DCI certified projection system</li>
  <li>
<strong>DKDM</strong>: Distribution Key Delivery Message - Similar to a KDM, but for a remastering or distribution system, not for a projection system</li>
</ul>

<h2 id="distribution-process">Distribution Process</h2>

<pre><code>graph TD
    classDef red fill:#a91900
    classDef green fill:#126500
    classDef purple fill:#650072
    legendprod[Producer]:::red
    legenddist[Distributor]:::green
    legendcine[Cinema]:::purple
    legendvendors[Projector Manufacturer]
</code></pre>

<pre><code>graph LR
    classDef red fill:#a91900
    classDef green fill:#126500
    classDef purple fill:#650072

    dcpcreated(["DCP\ncreated"]):::red --"AES Key"--&gt; dkdmcreated
    dkdmcreated(["DKDM\ncreated"]):::red --"encrypted\nAES Key"--&gt; dkdmp
    
    dkdmp[DKDM]:::green --&gt; verify(["Projector\nverified"]):::green
    dcpcreated --"to Distributor"--&gt; dcp(["DCP by\nDownload or\nHarddrive"]):::green
    distcert["Distributor\nCertificate"]:::green --"to Producer"--&gt; dkdmcreated
    
    verify --"to Cinema"--&gt; kdm[KDM]:::purple
    dcp --"to Cinema"--&gt; dcp2["DCP"]:::purple
    cinecert["Projector\nCertificate"]:::purple --"to Distributor"--&gt; verify
    trusted["Trusted Device List"] --&gt; verify
    dcp2 --&gt; projector[Projector]:::purple
    kdm --&gt; projector
</code></pre>

<h2 id="projection-systems">Projection Systems</h2>

<p>Most of the Projection Systems consists of Server, Audio Processor and Projector.</p>

<pre><code>graph LR
  server[Server] --&gt; mediablock[Media Block]
  hdmi[HDMI Source] --&gt; splitter[Audio Splitter]
  splitter --"Video"--&gt; projector
  splitter --"Audio"--&gt; sound
  subgraph Projector
   mediablock --"Video"--&gt; projector[Projector]
  end
  
  projector --&gt; screen[Theatre Screen]
  mediablock --"Audio"--&gt; sound[Audio Processor]
  sound --&gt; speakers[Speakers]
</code></pre>

<p>The Server stores the DCPs and KDMs, manages Playlists and controls the Projector and Audio Processor hardware.</p>

<p>Many Cinemas also connect their Theatre Automation (light, curtains, etc.) to the projector. By setting time-based commands into the playlists, lights and screen curtain can be controlled automatically. The Projector Server provides 12V/24V relays for this.</p>

<p>These time-based commands are also used to set the correct Aspect Ratio and Volume on the different DCPs in a Playlist.</p>

<p>The Server can be controlled remotely by a PC or in larger cinemas by a Theatre Management System.</p>

<p>The DCPs are imported from USB/CRU hard drives or by internet download to the server. They are stored encrypted at all times.</p>

<p>The projector includes a so called “Media Block” which handles DRM and decryption. It receives the DCP data and the KDM to decrypt each frame in real time.</p>

<p>On DCP playback the Projector will send the decrypted PCM audio to the Audio Processor which will then send each processed Audio Channel to the respective Speakers.</p>

<p><img src="https://serverless.industries/assets/digital-cinema-disks.jpg" alt="DCP Disks"></p>

<h2 id="dcp-format">DCP Format</h2>

<p>A DCP is a folder which contains XML metadata files and multiple MXF files for the actual movie.</p>

<h3 id="folder-naming-pattern">Folder Naming Pattern</h3>

<pre><code>AwesomeMovie_FTR-2_S_DE-XX_DE-16_51_4K_20240119_SMPTE_OV
</code></pre>

<ul>
  <li>
<code>AwesomeMovie</code>: A short version of the movie title</li>
  <li>
<code>FTR</code>: Media Type, in this case “Feature”</li>
  <li>
<code>2</code>: Version Number</li>
  <li>
<code>S</code>: Aspect ratio, in this case 2.35:1 aka “Sope”</li>
  <li>
<code>DE</code>: Audio Language</li>
  <li>
<code>XX</code>: Subtitle Language, in this case is no subtitle available</li>
  <li>
<code>DE</code>: Territory</li>
  <li>
<code>16</code>: Age Rating</li>
  <li>
<code>51</code>: Audio channels, in this case 5.1 surround sound</li>
  <li>
<code>4K</code>: Movie resolution, in this case 4096x1716 pixels</li>
  <li>
<code>20240119</code>: Mastering timestamp</li>
  <li>
<code>SMPTE</code>: DCP standard, there is also <code>Interop</code>
</li>
  <li>
<code>OV</code>: Package type, original version or <code>VF</code> for version file</li>
</ul>

<p>Credits: <a href="http://static.kinofreund.com/dcnt/" target="_blank">http://static.kinofreund.com/dcnt/</a></p>

<h3 id="mastering-process">Mastering Process</h3>

<p>During the Mastering Process a static AES 128 bit key is generated and the original medium is converted into MXF files. One for picture and one for audio.</p>

<p>For mastering the tool <a href="https://dcpomatic.com/" target="_blank">DCP-o-matic</a> can be used. There are also some commercial products.</p>

<pre><code>graph LR
    movie["Source"] --&gt; mastering{{"Movie Mastering"}}
    mastering --&gt; dcpkey["Static&lt;br&gt;AES-128 Key"]
    mastering --&gt; dcp["Digital Cinema Package (DCP)"]
    dcp --&gt; dcppics["Encrypted&lt;br&gt;Picture Data"]
    dcp --&gt; dcpsound["Encrypted&lt;br&gt;Audio Data"]
    dcp --&gt; dcpsub["Encrypted&lt;br&gt;Subtitle Data"]
</code></pre>

<p>The video stream is encoded as one single JPEG2000 picture per frame. Each frame is encrypted with the same static AES key.</p>

<p>The audio stream is (most likely) chunked into one BWF (Broadcast Wave Format) stream per frame and also encrypted separately. (The author haven’t found any information about this yet.)</p>

<p>A DCP can have a size of 200 GB or more. Some newer releases can hit the Terabyte, if multiple versions (Languages, Subtitles, 2D/3D) are shipped on the same harddrive.</p>

<p>The subtitles are provided in an XML file or are burned directly into the picture frames. If it is provided as an XML file, the projector will render the subtitles using a TTF font file.</p>

<div><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;DCSubtitle</span> <span>Version=</span><span>"1.0"</span><span>&gt;</span>
    <span>&lt;SubtitleID&gt;</span>xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx<span>&lt;/SubtitleID&gt;</span>
    <span>&lt;MovieTitle&gt;</span>MovieTitle<span>&lt;/MovieTitle&gt;</span>
    <span>&lt;ReelNumber&gt;</span>1<span>&lt;/ReelNumber&gt;</span>
    <span>&lt;Language&gt;</span>de<span>&lt;/Language&gt;</span>
    <span>&lt;LoadFont</span> <span>Id=</span><span>"Font1"</span> <span>URI=</span><span>"Arial.ttf"</span> <span>/&gt;</span>
    <span>&lt;Font</span> <span>Id=</span><span>"Font1"</span> <span>Color=</span><span>"ffffffff"</span> <span>Effect=</span><span>"border"</span> <span>EffectColor=</span><span>"ff000000"</span> <span>Italic=</span><span>"no"</span> <span>Script=</span><span>"normal"</span> <span>Size=</span><span>"42"</span> <span>Underlined=</span><span>"no"</span> <span>Weight=</span><span>"normal"</span> <span>AspectAdjust=</span><span>"1"</span> <span>Spacing=</span><span>"0em"</span><span>&gt;</span>
        <span>&lt;Subtitle</span> <span>SpotNumber=</span><span>"1"</span> <span>TimeIn=</span><span>"00:07:45:094"</span> <span>TimeOut=</span><span>"00:07:48:000"</span> <span>FadeUpTime=</span><span>"000"</span> <span>FadeDownTime=</span><span>"000"</span><span>&gt;</span>
            <span>&lt;Text</span> <span>HPosition=</span><span>"0"</span> <span>VAlign=</span><span>"bottom"</span> <span>VPosition=</span><span>"7"</span><span>&gt;</span>WÜSTE VON NEVADA - HEUTE<span>&lt;/Text&gt;</span>
        <span>&lt;/Subtitle&gt;</span>
    <span>&lt;/Font&gt;</span>
<span>&lt;/DCSubtitle&gt;</span>
</code></pre></div>



<p>A supplemental DCP allows to reuse the Original DCP (OV, Original File) picture and replace audio or subtitle tracks. This makes it possible to support different languages without the need of shipping hundreds of gigabytes of duplicated picture data to the cinemas.</p>

<pre><code>graph TD
    f[PaktDerWoelfe_FTR_S-235_FR-XX_DE_51_4K_SC_20230926_EGB_SMPTE_OV]
    f --&gt; a[PaktDerWoelBoC_FTR_S-235_DE-DE_DE_51_4K_SC_20231115_EGB_SMPTE_VF]
    f --&gt; b[PaktDerWoelBoC_FTR_S-235_FR-DE_DE_51_4K_SC_20231115_EGB_SMPTE_VF]
</code></pre>

<p>Example: One version file for German with German subtitles and one for French with German subtitles.</p>

<p>It is even possible to provide differnt cuts of a movie for different regions.</p>

<h3 id="software">Software</h3>

<p>Two Open Source C++ implementations, both in active development, one from the industry!</p>

<p>cth103/libdcp, a C++ library written by the makers of DCP-o-matic:</p>

<ul>
  <li><a href="https://git.carlh.net/gitweb/?p=dcpomatic.git;a=shortlog;h=refs/heads/main" target="_blank">https://git.carlh.net/gitweb/?p=dcpomatic.git;a=shortlog</a></li>
  <li>
<a href="https://dcpomatic.com/" target="_blank">https://dcpomatic.com/</a> (<a href="https://git.carlh.net/gitweb/?p=libdcp.git;a=summary" target="_blank">source code</a>)</li>
</ul>

<p>asdcplib, a C++ library written by companies active in the cinema industry:</p>

<blockquote>
  <p>The asdcplib project was originally exchanged by FTP. The project was on SourceForge between 2005 and 2008, when it moved to a release-only distribution via CineCert. As of late February 2019, its new home is on github.</p>

  <p>– <a href="https://github.com/cinecert/asdcplib" target="_blank">https://github.com/cinecert/asdcplib</a></p>
</blockquote>

<p>Almost all software, commercial or open source is using one of these libraries.</p>

<h2 id="distribution">Distribution</h2>

<p>The symmetric encryption key for the DCP has to be protected in some way. For this, the producer will create a DKDM XML file, containing the AES Key, which has been encrypted with the Certificate Public Key of the distributor.</p>

<p>The distributor can then use the DKDM to create KDM XML files for cinemas. This means decrypting the DCP AES Key and encrypting it again with the Certificate Public Key of the target projection system.</p>

<h2 id="certificate-chains">Certificate Chains</h2>

<p>Both projectors and distributors use SSL certificate chains to sign and encrypt/decrypt data.</p>

<p>A chain always consists of a Root Certificate Authority (CA), Intermediate CA and a Leaf Certificate.</p>

<pre><code>graph TD
    a["dnQualifier=ZwVjULQy61,CN=.smpte-430-2.root,OU=movies.serverless.industries,O=serverless.industries"]
    a --&gt; b["dnQualifier=/JLF0JtscFuJahVNXfYu1w1u7SI=,CN=.smpte-430-2.intermediate,OU=movies.serverless.industries,O=serverless.industries"]
    b --&gt; c["dnQualifier=TEqiLeRuVnkbNOUsPlbDHIdp1tM=,CN=CS.smpte-430-2.leaf,OU=movies.serverless.industries,O=serverless.industries"]
</code></pre>

<p>The field <code>dnQualifier</code> in the subject is the fingerprint of the public key of the generated certificate:</p>

<div><pre><code><span>cat </span>leaf.pem | openssl x509 <span>-pubkey</span> <span>-noout</span> | <span>\</span>
    openssl <span>base64</span> <span>-d</span> | <span>dd </span><span>bs</span><span>=</span>1 <span>skip</span><span>=</span>24 2&gt;/dev/null | <span>\</span>
    openssl sha1 <span>-binary</span> | openssl <span>base64</span>
</code></pre></div>

<p>Script for creating a certificate chain: <a href="https://github.com/NEU-Deli/dcitools/blob/master/create-smpte-chain.sh" target="_blank">create-smpte-chain.sh</a></p>

<h2 id="key-delivery-messages">Key Delivery Messages</h2>

<p>A KDM is a XML file which contains the AES key of the DCP encrypted with the projectors Public Key.</p>

<ul>
  <li>Various XML Schemas: SMPTE 430-1, SMPTE 430-3</li>
  <li>Document signing with XML-DSig</li>
  <li>One or more <code>&lt;enc:CipherValue&gt;</code> elements contain the AES keys and some metadata for multiple DCP OV/VF, both encrypted</li>
</ul>

<p>Decrypt the <code>&lt;enc:CipherValue&gt;</code> with <code>openssl</code>:</p>

<div><pre><code><span>cat </span>KDM_KaizoTrap_FTR-1_F_XX-XX_20_2K_20240119_SMPTE_OV_My_nonexistent_cinema_Nonexistent_Screen_1.xml | <span>\</span>
    xq <span>-r</span> <span>'.DCinemaSecurityMessage.AuthenticatedPrivate."enc:EncryptedKey"[0]."enc:CipherData"."enc:CipherValue"'</span> | <span>\</span>
    <span>base64</span> <span>-d</span> | <span>\</span>
    openssl pkeyutl <span>-decrypt</span> <span>-inkey</span> leaf.key <span>-pkeyopt</span> rsa_padding_mode:oaep <span>&gt;</span> kdminfo.bin
</code></pre></div>

<p>Output of <code>hexdump -C kdminfo.bin</code>:</p>

<pre><code>00000000  f1 dc 12 44 60 16 9a 0e  85 bc 30 06 42 f8 66 ab  |...D`.....0.B.f.|
00000010  28 fd 80 bf a9 bb f1 dc  48 d9 87 e9 5c c9 a5 41  |(.......H...\..A|
00000020  ab 8e 14 82 88 40 c3 90  2a 0b 46 21 b4 10 49 6b  |.....@..*.F!..Ik|
00000030  b8 a4 a9 4f 4d 44 41 4b  2e 2e 05 b5 bb ed 45 79  |...OMDAK......Ey|
00000040  96 cc 9c d6 00 ed db 4c  32 30 32 34 2d 30 31 2d  |.......L2024-01-|
00000050  32 38 54 31 39 3a 30 30  3a 30 30 2b 30 31 3a 30  |28T19:00:00+01:0|
00000060  30 32 30 32 34 2d 30 32  2d 30 34 54 32 30 3a 30  |02024-02-04T20:0|
00000070  30 3a 30 30 2b 30 31 3a  30 30 4c 3a b6 ed 71 eb  |0:00+01:00L:..q.|
00000080  29 25 90 48 6b 4f 96 2f  44 f6                    |)%.HkO./D.|
0000008a
</code></pre>

<p>The file can now be sliced into single fields with <code>dd</code>:</p>

<div><pre><code><span># fingerprint base64 encoded</span>
<span>dd </span><span>if</span><span>=</span>kdminfo.bin <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>16 <span>count</span><span>=</span>20 <span>status</span><span>=</span>none | <span>base64</span>

<span># AES key in hexadecimal</span>
<span>dd </span><span>if</span><span>=</span>kdminfo.bin <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>122 <span>count</span><span>=</span>16 <span>status</span><span>=</span>none | hexdump <span>-C</span>

<span># date string in plain text ASCII</span>
<span>dd </span><span>if</span><span>=</span>kdminfo.bin <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>97 <span>count</span><span>=</span>25 <span>status</span><span>=</span>none<span>;</span> <span>echo</span>
</code></pre></div>

<p>Format:</p>

<table>
  <thead>
    <tr>
      <th>Start</th>
      <th>Length</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>16</td>
      <td>Structure ID, binary, static <code>0xf1dc124460169a0e85bc300642f866ab</code>
</td>
    </tr>
    <tr>
      <td>16</td>
      <td>20</td>
      <td>Signer certificate fingerprint, binary, <code>KP2Av6m78dxI2YfpXMmlQauOFII=</code>
</td>
    </tr>
    <tr>
      <td>36</td>
      <td>16</td>
      <td>Composition Playlist UUID, <code>8840c390-2a0b-4621-b410-496bb8a4a94f</code>
</td>
    </tr>
    <tr>
      <td>52</td>
      <td>4</td>
      <td>Key Type, ASCII, <code>MDAK</code> = Main Sound</td>
    </tr>
    <tr>
      <td>56</td>
      <td>16</td>
      <td>Key UUID, <code>2e2e05b5-bbed-4579-96cc-9cd600eddb4c</code>
</td>
    </tr>
    <tr>
      <td>72</td>
      <td>25</td>
      <td>Not valid before date string, ASCII, <code>2024-01-28T19:00:00+01:00</code>
</td>
    </tr>
    <tr>
      <td>97</td>
      <td>25</td>
      <td>Not valid after date string, ASCII, <code>2024-02-04T20:00:00+01:00</code>
</td>
    </tr>
    <tr>
      <td>122</td>
      <td>16</td>
      <td>AES decryption key, binary, <code>0x4c3ab6ed71eb292590486b4f962f44f6</code>
</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Validate signer certificate: Should match the fingerprint of the leaf certificate used to sign the KDM XML structure</li>
</ul>

<div><pre><code>openssl asn1parse <span>-in</span> leaf.pem <span>-noout</span> <span>-strparse</span> 4 <span>-out</span> - | <span>\</span>
    openssl dgst <span>-sha1</span> <span>-binary</span> | <span>\</span>
    openssl <span>base64</span>
</code></pre></div>

<ul>
  <li>Validate Composition Playlist UUID: Should appear in the KDM XML field <code>&lt;CompositionPlaylistId&gt;</code>
</li>
  <li>Validate Key UUID: Should appear in the KDM XML field <code>&lt;KeyId&gt;</code>
</li>
  <li>Validate Key Type: Should match the type for the respective Key UUID <code>&lt;TypedKeyId&gt;</code> block</li>
  <li>Validate Dates: Should appear in the KDM XML fields <code>&lt;ContentKeysNotValidBefore&gt;</code> and <code>&lt;ContentKeysNotValidAfter&gt;</code>
</li>
</ul>

<p>(This is a subset of checks documented in the <a href="https://www.dcimovies.com/compliance_test_plan/" target="_blank">DCI Compliance Test Plan</a>)</p>

<p>The projector itself has no trusted CA store for validating KDMs or DCPs. The whole process relies on the fingerprint stored in the <code>&lt;enc:CipherValue&gt;</code> and that the recipient cinema has no access to the Projectors Private Key.</p>

<h2 id="trusted-device-list">Trusted Device List</h2>

<p>Could one just build their own DCI/DCP projector?</p>

<p>Yes and no.</p>

<p>The software exists, in theory just a Linux PC and any projector / sound system is required.</p>

<p>The distributors use a so called “Trusted Device List” provided by the DCI certified projection system manufacturers. Projectors which are not mentioned on these lists will not get a DCP/KDM from many distributors.</p>

<p>Also a DCI certified projection system must be installed by an authorized company.</p>

<ul>
  <li>KDM Request by Serial Number: Many distributors just ask for projector model and serial number. They can query the actual projection system certificate in their distribution system</li>
  <li>KDM Request by Certificate: The cinema has to provide their projector certificate which is then validated against the projection systems manufacturer root certificate</li>
</ul>

<p>If a cinema is not “playing by the rules”, a 30k+ EUR projection system will become an expensive brick.</p>

<h2 id="mxf-file-format">MXF File Format</h2>

<p>MXF is used by the whole movie and broadcasting industry.</p>

<p>The paper of the SMPTE standard is again purchase-only.</p>

<p>Since the standard is quite complex, the Author used <a href="https://github.com/Myriadbits/MXFInspect" target="_blank">MXFInspect</a> as a shortcut and only parsed a single Frame / Triplet.</p>

<h3 id="ber-encoding">BER Encoding</h3>

<p><strong>B</strong>asic <strong>E</strong>ncoding <strong>R</strong>ules:</p>

<ul>
  <li>BER is indicated if the first bit of the byte is a <code>1</code>
</li>
  <li>Bits 2-8 contain the number of bytes used for the length</li>
  <li>The length bytes contain the length of the data</li>
</ul>

<table>
  <thead>
    <tr>
      <th>BER Indicator</th>
      <th>Length</th>
      <th>Content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
<code>0x83</code> = <code>10000011b</code><br>= 3 bytes for length</td>
      <td>
<code>0x004F0C</code><br>= <code>20236d</code>
</td>
      <td>20236 bytes of data</td>
    </tr>
  </tbody>
</table>

<h3 id="triplet-format-single-movie-frame">Triplet Format (Single Movie Frame)</h3>

<h4 id="frame-triplet-structure">Frame Triplet Structure</h4>

<table>
  <thead>
    <tr>
      <th>Start</th>
      <th>Type</th>
      <th>Length</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>DAT</td>
      <td>16</td>
      <td>Encrypted triplet key</td>
    </tr>
    <tr>
      <td>16</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>17</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x004F0C</code> = <code>20236d</code> = Length of the data</td>
    </tr>
    <tr>
      <td>20</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>21</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x000010</code> = <code>16d</code> = Length of the next field</td>
    </tr>
    <tr>
      <td>24</td>
      <td>DAT</td>
      <td>16</td>
      <td>Cryptographic Context Link</td>
    </tr>
    <tr>
      <td>40</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>41</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x000008</code> = <code>8d</code> = Length of the next field</td>
    </tr>
    <tr>
      <td>44</td>
      <td>DAT</td>
      <td>8</td>
      <td>Plaintext offset</td>
    </tr>
    <tr>
      <td>52</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>53</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x000010</code> = <code>16d</code> = Length of the next field</td>
    </tr>
    <tr>
      <td>56</td>
      <td>DAT</td>
      <td>16</td>
      <td>Source Key</td>
    </tr>
    <tr>
      <td>72</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>73</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x000008</code> = <code>8d</code> = Length of the next field</td>
    </tr>
    <tr>
      <td>76</td>
      <td>DAT</td>
      <td>8</td>
      <td>Source Length</td>
    </tr>
    <tr>
      <td>84</td>
      <td>BER</td>
      <td>1</td>
      <td>BER <code>0x83</code> = <code>10000011b</code> = Next field is 3 bytes long</td>
    </tr>
    <tr>
      <td>85</td>
      <td>LEN</td>
      <td>3</td>
      <td>
<code>0x004e90</code> = <code>20112d</code> = Length of the next field</td>
    </tr>
    <tr>
      <td>88</td>
      <td>DAT</td>
      <td>20112</td>
      <td>Encrypted Source Value</td>
    </tr>
  </tbody>
</table>

<!--
```
Cryptographic Context Link = 2F347C27660A4F87844B36F957D753A6
Plaintext Offset           = 0000000000000000
Source Key                 = 060E2B34010201010D01030115010801
Source Length              = 0000000000004E61 = 20065d
```

> [color=#e862ea] TODO: What are these fields? 🤷‍♂️
-->

<h4 id="slice-the-data">Slice the data</h4>

<div><pre><code><span># slice the first frame from the MXF bodypartition</span>
<span># offsets from MXFInspect</span>
<span>dd </span><span>if</span><span>=</span>file.mxf <span>bs</span><span>=</span>1 <span>count</span><span>=</span>20256 <span>skip</span><span>=</span>16524 <span>of</span><span>=</span>block.bin

<span># slice data from the frame</span>
<span>dd </span><span>if</span><span>=</span>block.bin <span>skip</span><span>=</span>88 <span>count</span><span>=</span>20112 <span>bs</span><span>=</span>1 <span>of</span><span>=</span>block-encrypted-data.bin
</code></pre></div>

<h3 id="decrypt-frame-data">Decrypt Frame Data</h3>

<p>The DCP encryption key: <code>4c3ab6ed71eb292590486b4f962f44f6</code></p>

<h4 id="the-frame-iv">The frame IV</h4>

<p>Every Frame is using a unique IV (Initialization Vector), which ensures that the AES Block Cipher generates always different cipher texts and makes brute force harder. This works similar to a Password Salt.</p>

<div><pre><code><span># the data starts with 16 bytes of iv and 16 bytes of cv</span>
<span># AES iv bytes</span>
<span>dd </span><span>if</span><span>=</span>block-encrypted-data.bin <span>bs</span><span>=</span>1 <span>count</span><span>=</span>16 <span>of</span><span>=</span>iv.bin
</code></pre></div>

<p>Output of <code>hexdump -C iv.bin</code>:</p>

<div><pre><code>00000000  16 6e 7b d1 67 81 44 2e  7a ca de 3c 46 cc d7 39  |.n{.g.D.z..&lt;F..9|
00000010
</code></pre></div>

<h4 id="validate-cv">Validate CV</h4>

<p>Since there is no way to know if a decryption was successful when the content of the data is unknown, a CV (Check Value) is used. The Check Value is encrypted with the same AES Key + IV, but the plain text value is known.</p>

<div><pre><code><span># the data starts with 16 bytes of iv and 16 bytes of cv</span>
<span># AES cv bytes</span>
<span>dd </span><span>if</span><span>=</span>block-encrypted-data.bin <span>bs</span><span>=</span>1 <span>count</span><span>=</span>16 <span>skip</span><span>=</span>16 <span>of</span><span>=</span>cv.bin
</code></pre></div>

<div><pre><code><span>cat </span>cv.bin | openssl enc <span>-aes128</span> <span>-d</span> <span>\</span>
    <span>-K</span> 4c3ab6ed71eb292590486b4f962f44f6 <span>\</span>
    <span>-iv</span> 166e7bd16781442e7acade3c46ccd739 <span>\</span>
    <span>-nosalt</span> <span>-nopad</span> | hexdump <span>-C</span>
</code></pre></div>

<div><pre><code>00000000  43 48 55 4b 43 48 55 4b  43 48 55 4b 43 48 55 4b  |CHUKCHUKCHUKCHUK|
00000010
</code></pre></div>

<p>If the result matches <code>0x4348554B4348554B4348554B4348554B</code> the key is correct.</p>

<h4 id="decrypt-data">Decrypt data</h4>

<div><pre><code><span># Remove IV and CV from the encrypted data block</span>
<span>dd </span><span>bs</span><span>=</span>1 <span>skip</span><span>=</span>32 <span>\</span>
    <span>if</span><span>=</span>block-encrypted-data.bin <span>\</span>
    <span>of</span><span>=</span>block-encrypted-data-nocryptinfo.bin
</code></pre></div>

<div><pre><code><span># Decrypt data block</span>
<span>cat </span>block-encrypted-data-nocryptinfo.bin | <span>\</span>
    openssl enc <span>-aes128</span> <span>-d</span> <span>\</span>
        <span>-K</span> 4c3ab6ed71eb292590486b4f962f44f6 <span>\</span>
        <span>-iv</span> 166e7bd16781442e7acade3c46ccd739 <span>\</span>
        <span>-nosalt</span> <span>-nopad</span> <span>&gt;</span> block-decrypted-data.bin
</code></pre></div>

<p>MXFs created by DCP-o-Matic contain <code>libdcp</code> in the hexdump, which indicates that the decryption was successful.</p>

<p>Output of <code>hexdump -C block-decrypted-data.bin | head</code>:</p>

<div><pre><code>00000000  3a f0 b7 f5 53 49 eb b7  c0 c0 cb a5 c9 2f 35 19  |:...SI......./5.|
00000010  00 00 00 00 00 00 00 00  00 00 07 ce 00 00 04 38  |...............8|
00000020  00 00 00 00 00 00 00 00  00 03 0b 01 01 0b 01 01  |................|
00000030  0b 01 01 ff 52 00 12 01  04 00 01 01 05 03 03 00  |....R...........|
00000040  00 77 88 88 88 88 88 ff  5c 00 23 22 97 20 96 f0  |.w......\.#". ..|
00000050  96 f0 96 c0 8f 00 8f 00  8e e0 87 50 87 50 87 68  |...........P.P.h|
00000060  70 05 70 05 70 47 77 d3  77 d3 77 62 ff 55 00 13  |p.p.pGw.w.wb.U..|
00000070  00 50 00 00 00 4d 40 00  00 00 00 49 00 00 00 00  |.P...M@....I....|
00000080  49 ff 64 00 0a 00 01 6c  69 62 64 63 70 ff 90 00  |I.d....libdcp...|
00000090  0a 00 00 00 00 4d 40 00  03 ff 93 ef fe 2c 71 ff  |.....M@......,q.|
</code></pre></div>

<h2 id="magic-signatures">Magic Signatures</h2>

<p>At first, the decrypted Frame could not be opened in GIMP.</p>

<p>To enable programs to open a file in the correct way, many files contain so called “<a href="https://en.wikipedia.org/wiki/List_of_file_signatures" target="_blank">Magic Signatures</a>” at its beginning.</p>

<p>This magic value in <code>block-decrypted-data.bin</code> is incorrect for unknown reasons. When extracting a JPEG2000 frame from an unencrypted MXF, the signature is correct. As a simple hack, the author just copied the signature from the unencrypted MXF frame to the decrypted one:</p>

<div><pre><code><span># offset again from MXFInspect</span>
<span>dd </span><span>if</span><span>=</span>j2c_caa6b39e-bd57-4676-9797-112e96a6f0c3.mxf <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>16524 <span>count</span><span>=</span>20085 <span>of</span><span>=</span>frame.bin

<span># unencrypted frame does not contain crypto info</span>
<span># so we just have to slice the first BER header</span>
<span>dd </span><span>if</span><span>=</span>framedata.bin.j2k <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>20 <span>count</span><span>=</span>16 <span>of</span><span>=</span>j2k_header.bin

<span># now back to the decrypted mxf frame</span>
<span># replace signature</span>
<span>cp </span>j2k_header.bin frame.j2k
<span>dd </span><span>if</span><span>=</span>block-decrypted-data.bin <span>bs</span><span>=</span>1 <span>skip</span><span>=</span>16 <span>&gt;&gt;</span> image.j2k
</code></pre></div>

<p>It should now be possible to open the file in GIMP. GIMP will show the frame with wrong colors, as MXF files use a custom color space.</p>

<p><img src="https://serverless.industries/assets/kaizotrap-decrypted.jpg" alt="Movie Screenshot with wrong color space"></p>

<p>The original Frame with correct colors:</p>

<p><img src="https://serverless.industries/assets/kaizotrap-original.jpg" alt="Movie Screenshot with correct colors"></p>

<p>Credit: <a href="https://www.youtube.com/watch?v=lIES3ii-IOg" target="_blank">Kaizo Trap by Guy Collins Animation</a></p>

<h2 id="why-its-safe">Why it’s safe</h2>

<p>Everything relies on “never reusing AES Keys” and “protected private keys”.</p>

<ul>
  <li>KDM data is encrypted with a 2048 bit RSA key</li>
  <li>MXF data is encrypted with AES-128</li>
  <li>Decryption keys are always stored in TPM-like hardware</li>
  <li>Every DCP uses unique encryption keys</li>
  <li>Every projector uses unique certificates/keys</li>
  <li>A DCI certified projector is required</li>
  <li>Distributors can verify if a certificate belongs to a certified DCI projector</li>
</ul>

<h2 id="just-record-it">Just record it</h2>

<p>Encrypted DCPs use <a href="https://dcpomatic.com/forum/viewtopic.php?t=2372" target="_blank">Forensic Watermarks</a> which contain the serial number of the
projection system. So if a recorded copy of a movie appears online, the theatre will have to answer
serious questions and may never get movies again.</p>

<p>Pirated copies of movies have it’s origin most likely from other sources.</p>

<h2 id="how-its-going">How it’s going</h2>

<p>DCI has released version 1.4.4 of the <a href="https://www.dcimovies.com/specification/" target="_blank">specification</a>, which now allows playback of DCPs with expired signer certificate.</p>

<p>The manufacturers already started to work on a software update.</p>

<h2 id="sources">Sources</h2>

<ul>
  <li><a href="https://www.dcimovies.com/specification/index.html" target="_blank">DCI Specification</a></li>
  <li><a href="https://www.dcimovies.com/compliance_test_plan/" target="_blank">DCI Compliance Test Plan</a></li>
  <li><a href="https://marc.info/?l=openssl-users&amp;m=114884533706459&amp;w=2" target="_blank">OpenSSL Foo</a></li>
  <li><a href="https://github.com/wolfgangw/digital_cinema_tools_distribution/blob/master/cinemaslides#L1737" target="_blank">Key Types</a></li>
  <li><a href="https://github.com/wolfgangw/digital_cinema_tools_distribution/tree/master" target="_blank">DC Tools by WolfgangW</a></li>
  <li><a href="https://github.com/Myriadbits/MXFInspect" target="_blank">MXFInspect</a></li>
  <li><a href="https://tech.ebu.ch/docs/techreview/trev_2010-Q3_MXF-2.pdf" target="_blank">MXF Triplets</a></li>
  <li><a href="https://web.archive.org/web/20201103045630id_/https://ieeexplore.ieee.org/ielx7/8984679/8984680/08984681.pdf" target="_blank">SMPTE Standard</a></li>
  <li><a href="https://interop-docs.cinepedia.com/Document_Release_2.0/mpeg_ii_track_file_encryption.pdf" target="_blank">MXF Triplet Encryption</a></li>
  <li><a href="https://github.com/cth103/libdcp/issues/11" target="_blank">Showing jpeg2000 in Gimp / parsing jpeg2000 data from mxf</a></li>
  <li><a href="https://en.wikipedia.org/wiki/List_of_file_signatures" target="_blank">List of magic signatures</a></li>
  <li><a href="https://dcpomatic.com/forum/viewtopic.php?t=2372" target="_blank">Forensic Watermarks in DCPs</a></li>
</ul>

<h2 id="credits">Credits</h2>

<p>Thanks for reading and feedback goes to: Pliskin, babel</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Movie Mistake Mystery from "Revenge of the Sith" (410 pts)]]></title>
            <link>https://fxrant.blogspot.com/2025/04/the-movie-mistake-mystery-from-revenge.html</link>
            <guid>43745141</guid>
            <pubDate>Sun, 20 Apr 2025 17:29:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fxrant.blogspot.com/2025/04/the-movie-mistake-mystery-from-revenge.html">https://fxrant.blogspot.com/2025/04/the-movie-mistake-mystery-from-revenge.html</a>, See on <a href="https://news.ycombinator.com/item?id=43745141">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Movies are handmade, and just like any other art form, sometimes the seams that hold movies together become visible to the audience. For movie fans, these moments are very exciting. Catching a glimpse behind the scenes is an exhilarating experience. My favorite kind of “movie mistake” is the kind that is hiding in plain sight... but the casual viewer missed it upon first viewing. Or perhaps even the second viewing, or even the third.&nbsp;</p><p>I’m particularly obsessed with moments that reveal the craft and artistry of the magic trick of a shot that slightly shatters the illusion of cinema. These revealing moments have been in movies since the dawn of cinema, and are everywhere (if you know exactly where to look).</p><p>One of my favorite films of all time also has one of the funniest revealing mistakes I've seen. Edward Zwick's "Glory" (1989) takes place during the American Civil War, and this scene has a blink-and-you'll-miss-it reminder of the film's very modern production:</p><p>Because the audiences' eyes are firmly fixed on Morgan Freeman's character in the center of frame, very few will ever pick up the little kid with the extremely modern wristwatch that enters frame on far screen right. Sometimes the on-set teams that work with featured extras—as well as the costume department that dress the extras—will occasionally miss a modern piece of jewelry on an actor.</p><p>Here's a fun one from Martin Scorsese's masterpiece "Goodfellas" (1990), in one of the closing shots of a nail-bitingly tense scene where Karen nearly walks into an ambush:</p><p>The period-appropriate "movie" license plate dramatically dangles then completely falls off the car in the middle of the take, revealing the actual 1990-era license plate of the car used for the scene. This is an accidental and hilarious glimpse into the detailed hard work that goes into making a Hollywood period piece (this portion of the film takes place in 1980), where every license plate of every car in the movie needed special, detailed work to make them period-appropriate.&nbsp;</p><div><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMcj2VC4Ju_5PCmfKdkGkSC6r2UzvK2qzh0d6NcxdtSdPSk24l8m5oTt3Yeq5GLp0wPZqjUlq1pHDiutRKWpMZucWukSa3qBfHw8J8KOu-dGExAWf97ym5Ikpif9BbZnKqLOwef_z1I2FXFFradn3C8BOr2GkMU8SfJzmBafEDtnv_4d8FeV4/s1908/illustration.png"><img data-original-height="1080" data-original-width="1908" height="226" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMcj2VC4Ju_5PCmfKdkGkSC6r2UzvK2qzh0d6NcxdtSdPSk24l8m5oTt3Yeq5GLp0wPZqjUlq1pHDiutRKWpMZucWukSa3qBfHw8J8KOu-dGExAWf97ym5Ikpif9BbZnKqLOwef_z1I2FXFFradn3C8BOr2GkMU8SfJzmBafEDtnv_4d8FeV4/w400-h226/illustration.png" width="400"></a></p><p>The finale of James Cameron's epic "Aliens" (1986) features the android Bishop (Lance Henriksen) getting severed in half, but still functioning enough to save Newt (Carrie Henn) from getting sucked into the vacuum of space. The action-packed scene features an absolutely wonderful accidental reveal of how the cut-in-half android was accomplished on the set:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHvAdErohL2BD-qytmJ7mGVvxdRGRuzMOiwXiI8kR6y0Pw707rqoLC58rp3AWp3gHhAt-O5YeR-thdq5AbnQrlhTtoc44TQsDctIyA2Ykga8UQVB7gGQphV1-wPNOChutR7MIFC2dzrBfxkRyeWXr0NjwW9kwU8N28sIgHlotDkprZNKZP9EY/s1920/bishop.png"><img data-original-height="1036" data-original-width="1920" height="216" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHvAdErohL2BD-qytmJ7mGVvxdRGRuzMOiwXiI8kR6y0Pw707rqoLC58rp3AWp3gHhAt-O5YeR-thdq5AbnQrlhTtoc44TQsDctIyA2Ykga8UQVB7gGQphV1-wPNOChutR7MIFC2dzrBfxkRyeWXr0NjwW9kwU8N28sIgHlotDkprZNKZP9EY/w400-h216/bishop.png" width="400"></a></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrvAm_i6yGBzc5507CmHJY6q_LcLnMS-eTcXVQhyphenhyphenA8uYrX4dXL80CVd4EwJOAEbJZPgeGawDEUn2pdc5KqlBuZJLuaw7fWJdzoG-r2a1vy_uQU_neb-5N5Yz8AaiDR0UtxciF4GhUhY3Tc6-0VamANpf-FePIL0YbeFnucGGA4QEKyVhMau7E/s433/alienshole.2025-04-17%2012_43_03.gif"><img data-original-height="227" data-original-width="433" height="210" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrvAm_i6yGBzc5507CmHJY6q_LcLnMS-eTcXVQhyphenhyphenA8uYrX4dXL80CVd4EwJOAEbJZPgeGawDEUn2pdc5KqlBuZJLuaw7fWJdzoG-r2a1vy_uQU_neb-5N5Yz8AaiDR0UtxciF4GhUhY3Tc6-0VamANpf-FePIL0YbeFnucGGA4QEKyVhMau7E/w400-h210/alienshole.2025-04-17%2012_43_03.gif" width="400"></a></p><p><i><span>"Aliens" (1986)</span></i></p><p>The amazing makeup effects applied to Henriksen's body covers the bottom half of his body which is hidden through a hole in the set. But in order to get that little bit of extra athletic stretch to grab Newt, Henriksen popped his body out of the hole a little too far, revealing the classic stage trick. However, I'd gather that 99% of the audience has never noticed this little reveal of stagecraft since our eyes are fixed on Newt on screen right, sliding toward the airlock, and not on the ground contact of Bishop's half-body, which had already been firmly established in the scene.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjU9LeqQEqiQZjf4bniZIvtLsXvLwZa6loSJneVo01NSsgsU60jw0nlF-YB-lQmdd3o-Uq1GOWb19_ctP1J5GMakIBHgCWrFCIlg2OQ1QS49k1ZIFyPaqOCOhpnfLCJCnWn3rWQ-QmSqboHlgpw6WxJPAy-OnoK0rnsMiPOX5SqBjT9fLJOQRc/s1045/circled.png"><img data-original-height="568" data-original-width="1045" height="217" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjU9LeqQEqiQZjf4bniZIvtLsXvLwZa6loSJneVo01NSsgsU60jw0nlF-YB-lQmdd3o-Uq1GOWb19_ctP1J5GMakIBHgCWrFCIlg2OQ1QS49k1ZIFyPaqOCOhpnfLCJCnWn3rWQ-QmSqboHlgpw6WxJPAy-OnoK0rnsMiPOX5SqBjT9fLJOQRc/w400-h217/circled.png" width="400"></a></p><p>Avoiding reflections of the crew appearing to camera is a constant struggle for filmmakers. In Steven Spielberg's first masterpiece "Duel" (1971), David (Dennis Weaver) gets into a phone booth to make a call, with the front glass face of the booth aimed directly at the camera, and if the audience's gaze drifted off of Weaver's face, they could catch a glimpse of the crew:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiF2nMOIJJcigCUwmwYiNCUFK3LSPyqR98CGn7XdriPNtxl1cJ-wHIb11RxPjm3u9LVV8LmypcMzbLLQl8DTTNwrp5eGMx6rs-PPazN7hPp2PihyphenhyphenZrkldyEB49amd3N0gr4tlT-KCokNOIhysaS60VIYxoVWxvTWUoNJR6QUAzH99MOtfshAHY/s442/duel_short.gif"><img data-original-height="249" data-original-width="442" height="225" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiF2nMOIJJcigCUwmwYiNCUFK3LSPyqR98CGn7XdriPNtxl1cJ-wHIb11RxPjm3u9LVV8LmypcMzbLLQl8DTTNwrp5eGMx6rs-PPazN7hPp2PihyphenhyphenZrkldyEB49amd3N0gr4tlT-KCokNOIhysaS60VIYxoVWxvTWUoNJR6QUAzH99MOtfshAHY/w400-h225/duel_short.gif" width="400"></a></p><p><i><span>"Duel" (1971)</span></i></p><p>In the reflection, we see a few crew members on screen left, the camera itself, and director Spielberg on the right (he's the one shuffling left and right, who lowers his head in the middle of the take). Again, like all the examples I'm providing in this article, hardly anyone would ever notice these moments. When a viewer catches these brief moments, the illusion of the movie is briefly broken, but for fans of the filmmaking process, it's a joyful reminder of the overall magic trick. The most intimate movie scene with only two characters in a desolate, isolated environment actually was created by dozens and dozens of crew members standing slightly out of frame.</p><p>Look for another accidental 'crew caught on camera' moment in the reflection in a car window in the 'leave the gun, take the cannoli' scene from "The Godfather" (1972), one that very few people ever notice.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgASHi1vEZJq9xexlwe6N6XnaKUFAH4aOLXmHKCv9BVNxVMiPwJ_Pj_nEabuKrD-nJqZDhITBBmRoNdyYmO3jKQEgLzkHPChAr50lpMRd5yJYt6whAJlaIVY7wOBLK18qVEOOpCbj4b7YeAIAjvItvDNC0tKFlLCk2P8s3NtQRy7Ahvy9kMCe8/s1920/duel_circle.png"><img data-original-height="1080" data-original-width="1920" height="225" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgASHi1vEZJq9xexlwe6N6XnaKUFAH4aOLXmHKCv9BVNxVMiPwJ_Pj_nEabuKrD-nJqZDhITBBmRoNdyYmO3jKQEgLzkHPChAr50lpMRd5yJYt6whAJlaIVY7wOBLK18qVEOOpCbj4b7YeAIAjvItvDNC0tKFlLCk2P8s3NtQRy7Ahvy9kMCe8/w400-h225/duel_circle.png" width="400"></a></p><p>Here's a super quick revealing mistake from "The Dark Knight" (2008) that is a true "you'll never see this in real time" moment:</p><div><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg914mIcnatARLUxXQIIv3YV-sMpkCbW5HIt6fqjlMW70OT5z6_Rn39zeenC42Sq_UYQk-eFX6DwW4aAUj9td-cqk0pzWhx0utnQOq8yuzxDn2hSJ2ptXYxhfydZaTz-F8Dho6lDeOgrdNuegiP2B0cHQe8UuDjRSX4EhWDSoU_HilsML5NXIA/s526/darkknight_crew_BRIGHTfull.2025-04-17%2012_56_27.gif"><img data-original-height="219" data-original-width="526" height="166" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg914mIcnatARLUxXQIIv3YV-sMpkCbW5HIt6fqjlMW70OT5z6_Rn39zeenC42Sq_UYQk-eFX6DwW4aAUj9td-cqk0pzWhx0utnQOq8yuzxDn2hSJ2ptXYxhfydZaTz-F8Dho6lDeOgrdNuegiP2B0cHQe8UuDjRSX4EhWDSoU_HilsML5NXIA/w400-h166/darkknight_crew_BRIGHTfull.2025-04-17%2012_56_27.gif" width="400"></a></p><p><i><span>"The Dark Knight" (2008)</span></i></p></div><p>Although "The Dark Knight" example gives the audience a much clearer look at the camera operator, the focus puller(?) and the camera itself reflected in the interrogation room’s mirrors, the shot is a lot harder to see the crew members and equipment in real time due to the chaotic and energetic camera movement, as opposed to the locked off nature of the "Duel" example.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0YNfNS0gG-xlaqmH-9KJDvwwpsHkIMycqul7SW8X2hE-LNZf0RHBM3LIXuQRlqQo0xD4sj5xzUW_Cu-A2gMXeBUmN55gZwHMlDuBL3nuxqCt0rJDDSGM2hTUzrkuWXxuxIg73mSaclQudBt75y_w_X8YsuWQRFC7iPc5NDSb6dQnQ2D3JxAQ/s1918/darkknight_compare.png"><img data-original-height="800" data-original-width="1918" height="166" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0YNfNS0gG-xlaqmH-9KJDvwwpsHkIMycqul7SW8X2hE-LNZf0RHBM3LIXuQRlqQo0xD4sj5xzUW_Cu-A2gMXeBUmN55gZwHMlDuBL3nuxqCt0rJDDSGM2hTUzrkuWXxuxIg73mSaclQudBt75y_w_X8YsuWQRFC7iPc5NDSb6dQnQ2D3JxAQ/w400-h166/darkknight_compare.png" width="400"></a></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibaiynJTHf2-1u0HH7_do8IU4-CU7kzWOzAUP4syOn9_7YRAVLSowGvKwEPI52YA3rk4xAUpd4BzXJbBpfnADRmYZoijN4Vkim_OHVJjFrp1S1e8p2AokM1GJDAPSojCoRP4DgcbKlGzmjGpRLrPrZoADLBab4haCQzNsrzxSHo7ThaySW63w/s500/abyss_wipe.gif"><img data-original-height="281" data-original-width="500" height="225" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibaiynJTHf2-1u0HH7_do8IU4-CU7kzWOzAUP4syOn9_7YRAVLSowGvKwEPI52YA3rk4xAUpd4BzXJbBpfnADRmYZoijN4Vkim_OHVJjFrp1S1e8p2AokM1GJDAPSojCoRP4DgcbKlGzmjGpRLrPrZoADLBab4haCQzNsrzxSHo7ThaySW63w/w400-h225/abyss_wipe.gif" width="400"></a></p><p><i><span>"The Abyss" (1989)</span></i></p><p>Amazingly, many folks who watch that clip from the dramatic drowning sequence cannot consciously see the bit of filmmaking that literally blocks the actors in an intimate moment. This is my favorite example of a movie's incredible emotional power — the scene is so dramatic and intense that most viewers cannot consciously see a giant cloth wiping away water from the lens of the camera in the middle of a shot.</p><p>Incidentally, <b>some of these revealing mistakes are being erased from cinema history</b> due to overzealous restoration projects — the process of “cleaning up” a film for newer formats like Blu-ray and 4K — which is deeply wrong. This is a much bigger topic on which I have very strong thoughts and the hottest of takes. Just look at what modern restorations have done to two of these revealing mistakes from "Goodfellas" and "Aliens":</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHamPBMDtOZiH_6g10yv7e4Pp9vRyA26atkaG2cW-uzswK3zQqOUHwgGiH_mvWTXKWIvddFqc4RKdsaanqjgxHOtGHlUZa79k81xaf_i-YV1AeIpbNzfCx1DBMMSeHkBYMQWsyuKrevfCYObg-z5MoMRfn6k5uVnxSqPtvZFIqBlwmClkwU80/s640/LicensePlate%20_restoration.gif"><img data-original-height="362" data-original-width="640" height="226" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHamPBMDtOZiH_6g10yv7e4Pp9vRyA26atkaG2cW-uzswK3zQqOUHwgGiH_mvWTXKWIvddFqc4RKdsaanqjgxHOtGHlUZa79k81xaf_i-YV1AeIpbNzfCx1DBMMSeHkBYMQWsyuKrevfCYObg-z5MoMRfn6k5uVnxSqPtvZFIqBlwmClkwU80/w400-h226/LicensePlate%20_restoration.gif" width="400"></a></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhjczOajV2AciOuOHRI9NXzBIfGyIKJbjRdfinr7TKVb_TTBP-uQQtDCWqGuDeoaY1FJElsr6HXU_I8sqhXHx7gAdNKKbpk8WHL6ByirFITWb_Vhqsq_TL042SKHjqftXYhZSbYXDGxA73zmjHaF3vBPtHDp_POCUDligVeWAi5N5G8XYRKL_A/s500/alienshole_fullmoviewithtextandcompare.gif"><img data-original-height="270" data-original-width="500" height="216" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhjczOajV2AciOuOHRI9NXzBIfGyIKJbjRdfinr7TKVb_TTBP-uQQtDCWqGuDeoaY1FJElsr6HXU_I8sqhXHx7gAdNKKbpk8WHL6ByirFITWb_Vhqsq_TL042SKHjqftXYhZSbYXDGxA73zmjHaF3vBPtHDp_POCUDligVeWAi5N5G8XYRKL_A/w400-h216/alienshole_fullmoviewithtextandcompare.gif" width="400"></a></p><p>Painting out these movie mistakes as part of a restoration is wrong. <i>What's in the movie is in the movie, </i>and altering the movie to this extent is a form of revisionist history. Cinema is worse off when over-aggressive restorations alter the action within the frame. To me, this is equivalent to swapping out an actor's performance with a different take, or changing the music score during an action sequence, or replacing a puppet creature with a computer graphics version of the same creature decades after release. But I digress.</p><p>• &nbsp;• &nbsp;• &nbsp;•</p><p>Like I said at the start, movies are handmade, and that's true even in today's landscape where digital visual effects are a prominent part of filmmaking. In the same way that physical crews use physical tools to build sets, construct costumes and craft props, visual effects artists use digital tools to craft an image. And with the hand-made nature of any art form, the lack of clinical accuracy lends to its charm and sometimes offers an accidental peek behind the scenes of how the art was constructed.</p><p>Every few years, a "Star Wars" revealing mistake bubbles up on the internet, one from the Mustafar sequence from Episode III, "Revenge of the Sith" (2005). But the bizarre moment in the single shot was not as easily explainable as the examples I've shown above.</p><p>Being in the privileged position of currently working at Industrial Light &amp; Magic, the visual effects company that made the visual effects for the movie (and having worked on that movie [and that sequence!]), I took it upon myself to try and solve the mystery.</p><p>Please enjoy the story, written by Ian Kintzle, of how I investigated the mystery of the "Force Ghost" in "Revenge of the Sith", as it originally appeared in the Star Wars Celebration Program for Japan 2025.</p><p>• &nbsp;• &nbsp;• &nbsp;• &nbsp;• &nbsp;• &nbsp;• &nbsp;•</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgEb2mtF1FNE5KEKPJjSs9hyphenhyphend5cAatilKzhr5B1E8cS-zRT1QI3XEXcX4SBRgLql4-C9ilaCiSSETbvWEl6SlxcbW495GsA6SbcjvulKOl6ZhyynisOsIH22CMDP-JmdMXb2opBnT-iOGoHglz_E6rgqXc8HSvqgbgm4Ibihz-P1RVnOKewPmQ/s1918/finalshot_singleframeA.jpg"><img data-original-height="816" data-original-width="1918" height="170" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgEb2mtF1FNE5KEKPJjSs9hyphenhyphend5cAatilKzhr5B1E8cS-zRT1QI3XEXcX4SBRgLql4-C9ilaCiSSETbvWEl6SlxcbW495GsA6SbcjvulKOl6ZhyynisOsIH22CMDP-JmdMXb2opBnT-iOGoHglz_E6rgqXc8HSvqgbgm4Ibihz-P1RVnOKewPmQ/w400-h170/finalshot_singleframeA.jpg" width="400"></a></p><p><i><b><span>THE FORCE GHOST IN THE MACHINE</span></b></i></p><p><i><span>By Ian Kintzle</span></i></p><p><i><span>April 2025, for Star Wars Celebration Japan</span></i></p><p><span>It was spring 2005, and Industrial Light &amp; Magic (ILM)— George Lucas’ dream factory—had just completed two years of work on one of its most ambitious projects yet: "Star Wars: Revenge of the Sith". A massive undertaking, "Sith" required a herculean effort from hundreds of artists and technicians at ILM, crafting 367 computer- generated models, hundreds of 3D and 2D environments, 47 practical miniature setups, and 13,000,000 renders and composites across 2,151 effects shots.</span></p><p><span>Out of all of the effects sequences in the picture, perhaps none was more challenging than the operatic duel between Darth Vader (Hayden Christensen) and Obi-Wan Kenobi (Ewan McGregor) on the volcanic planet of Mustafar. The battle starts within the Klegger Corp Mining Facility situated high on the rocky banks of a vast lava river, and progresses through the facility onto a heat-collection arm stretching over a fast- moving river of boiling magma, and then onto a pair of lava skiffs and panning droids. The battle finally ends on a bank with Vader severely burned and maimed.</span></p><p><span>For the Mustafar sequence, ILM’s team of compositors, led by Compositing Supervisor Pat Tubach and Sequence Supervisor Michael Conte, were faced with the daunting challenge of seamlessly blending all of these live-action plates, computer-generated imagery, and miniature effects, into one cohesive sequence. But with so many individual elements, mistakes happen, and in the case of Revenge of the Sith, a peculiar anomaly slipped through the cracks at precisely 1 hour, 59 minutes, and 2 seconds into the film.</span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9Y3af6L5NqwRyByVmK5V-h8fEwV8KjiN0r1UbtqwggsMCVMTciUmSBPrJO9YHUushdOESEJ2UsYi4113wq3UGQo2_Q1LRMccUwyI3_lR7dpLbGn3D0EQoVvELQYDjg8yHCrD9b6mN-evcA8cmvodXq1CS13glDu4Yw_rgxKZMR53P3gDJHGc/s500/finalsequence.gif"><span><img data-original-height="213" data-original-width="500" height="170" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9Y3af6L5NqwRyByVmK5V-h8fEwV8KjiN0r1UbtqwggsMCVMTciUmSBPrJO9YHUushdOESEJ2UsYi4113wq3UGQo2_Q1LRMccUwyI3_lR7dpLbGn3D0EQoVvELQYDjg8yHCrD9b6mN-evcA8cmvodXq1CS13glDu4Yw_rgxKZMR53P3gDJHGc/w400-h170/finalsequence.gif" width="400"></span></a></p><p><span>The internet, ever vigilant, began to take notice of this curious artifact around 2015 – a blink-and-you’ll-miss- it moment of a ghostly-robed figure with dark hair that appears behind Anakin Skywalker for only a frame or two just as he leaps from the panning droid to meet Obi-Wan on the lava skiff. The strange figure sparked countless theories and speculation. Was it a “Force ghost”? An easter egg from a mischievous ILM artist?</span></p><p><span>Todd Vaziri, a seasoned veteran at ILM who also worked on the film as a compositor, was intrigued by the mystery. “Just before the release of The Force Awakens, I started to see this ‘easter egg’ bubble up on social media from time to time of what appears to be a Force ghost on Mustafar,” Vaziri says. “The discourse would really get going. Somebody would spot the artifact and go, ‘What the heck was this?’ And another would say, ‘What do you mean? I don’t see anything.’ And only when you step through the scene, frame-by-frame, do you see what looks like a ghostly face behind Anakin in the shot where he jumps up from the panning droid to continue the lightsaber duel on the lava skiff. And honestly, in-motion, nobody can spot this.”</span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvOBxrHhHq0CiZlSavot6K1cDeaDHKK-OxHOqGpiSBTKMahcyR_4sUwab0y8EJscd2r8mJQ75Diy1xT2gfg4jxRGa6TTmg6dmtG7WUF2u08Se3LSXIRzPUQBE9ItefL8dKzv8yAISsj9fjyVb3VtciyuWcKQDtQpefp2SocuSAFUSMAxeL_M/s500/animation.gif"><span><img data-original-height="213" data-original-width="500" height="170" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvOBxrHhHq0CiZlSavot6K1cDeaDHKK-OxHOqGpiSBTKMahcyR_4sUwab0y8EJscd2r8mJQ75Diy1xT2gfg4jxRGa6TTmg6dmtG7WUF2u08Se3LSXIRzPUQBE9ItefL8dKzv8yAISsj9fjyVb3VtciyuWcKQDtQpefp2SocuSAFUSMAxeL_M/w400-h170/animation.gif" width="400"></span></a></p><p><span>Getting to the bottom of the mystery would prove difficult. ILM works on dozens of motion pictures and television shows per year, and as older projects are moved offline into their archives, the steps to bring them back to the servers are involved. Revenge of the Sith was no exception. It would require scavenging through terabytes of unaltered greenscreen photography that hasn’t been touched in years. So Vaziri put it behind him – for a time. But in 2024 when the discourse regarding the “Force ghost” roared alive again on social media, Vaziri decided that enough was enough. But in order to locate the anomaly, he would need to spelunk into the film’s digital archives at ILM which had since gone dark.</span></p><p><span>“I think it took 24 hours to unearth the footage and put it back on our servers. I was so excited, my heart was pounding out of my chest. No one had seen the original greenscreen footage for nearly twenty years,” Vaziri says. “The problem was I didn’t remember exactly what these plates looked like, both because it wasn’t my shot, and it was two decades prior. So I dug, and I dug, and finally I found the plate photography. I couldn’t believe it. There on set was a man—likely a stunt rigger—wearing not a robe, but a peculiar shirt that resembled one, standing behind Hayden, manually puppeteering the greenscreen lava skiff that he and Ewan were fighting on. His face and the “Force ghost” matched up frame-for-frame.” During this excavation process, Vaziri was also able to uncover a variety of in-progress versions of the shot composited with very basic layering. In those early takes, the robed man was not present. This meant one thing: the compositor had done some articulates to remove the mystery man, but the green screen extraction wasn’t quite done yet.</span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxmX6_02BHHum6AiA3Hz9X3NDxDsyzBCfeyj6Rs-rmTDZoZEw78OEj1hvTlxbHn1-G1R-Ur0Qdy7G2vhbuy_AP1tza0uAlHr216oz-MXNbrp0WWbLEGNjVDALO9UZJG8WYd1jKz2yv5HAic4dNDS4SpXNTxr1dWCdI4rmtyb8VLFBnqDvRw74/s1175/greenscreen_compare.png"><span><img data-original-height="1175" data-original-width="1024" height="400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxmX6_02BHHum6AiA3Hz9X3NDxDsyzBCfeyj6Rs-rmTDZoZEw78OEj1hvTlxbHn1-G1R-Ur0Qdy7G2vhbuy_AP1tza0uAlHr216oz-MXNbrp0WWbLEGNjVDALO9UZJG8WYd1jKz2yv5HAic4dNDS4SpXNTxr1dWCdI4rmtyb8VLFBnqDvRw74/w349-h400/greenscreen_compare.png" width="349"></span></a></p><p><span>“We have to do frame-by-frame tweaking by hand, which means creating new garbage mattes in order to paint details into the motion- blurred edges,” Vaziri explains. “At some point during the process of refining the edges of the green screen extraction—which required new garbage mattes—the stunt rigger’s head was inadvertently revealed again in that paint process—but because you can’t see it unless you are stepping through it frame-by-frame— it was deemed finished by the artist, by the compositing supervisor, by the visual effects supervisor, by the editors, and by George Lucas himself. Nobody that was part of this process ever caught that and that’s how it made it in the movie. But in a way, I think it’s really wonderful. Plenty of my shots have mistakes in them, and as the saying goes: perfect is the enemy of good. We want our shots to be as perfect as they can be, but we can’t hit everything. In the last 20 years, we have evolved what we call the “Final Check” process, which is our way of scrutinizing shots before they leave ILM. An extra step of quality control, if you will. The bottom line is that we put human hands on every single one of the thousands of shots that you see in Star Wars. This world is handmade, and little things like this become part of ILM history.”</span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTXZ4c7qoZ-d8aejJQ29QoqgvIpqihCiRAzFobTxRC5Wd_fJxQThJNkviLOd6L1Af4jhMZrRBRq4ZqoqelEiwSrtaeucjjLlMbdIxhRj_JY9uZccfDtynD7uPPTj-leY98QlCpz2uyy8cFBtkyQiBRHMF2a7EsFY6sfBlL6gDr9XFN2VCBI7E/s1593/greenscreen_singleframeBCROP.jpeg"><span><img data-original-height="783" data-original-width="1593" height="196" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTXZ4c7qoZ-d8aejJQ29QoqgvIpqihCiRAzFobTxRC5Wd_fJxQThJNkviLOd6L1Af4jhMZrRBRq4ZqoqelEiwSrtaeucjjLlMbdIxhRj_JY9uZccfDtynD7uPPTj-leY98QlCpz2uyy8cFBtkyQiBRHMF2a7EsFY6sfBlL6gDr9XFN2VCBI7E/w400-h196/greenscreen_singleframeBCROP.jpeg" width="400"></span></a></p><p><span><span><i>detail of the original greenscreen footage</i></span></span></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMNJa-NicVw7dMWKVk8mXjvd0wilCDs1xhqFR8-_L8uo2WD7_q9AcNWKUmY6eO8KNuHB1RflBg_z2UnTAJV-EB4BUJJrkEqzWcr4SrauZGkSAK2TqA9LHHvNJ1-6oiNdIYZVlsaVrE4AV4l4uIqArxzA8HfgyNJkzXgHnPHUvWw2eBUa0SJzg/s1918/finalshot_singleframeB.jpg"><span><img data-original-height="816" data-original-width="1918" height="170" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMNJa-NicVw7dMWKVk8mXjvd0wilCDs1xhqFR8-_L8uo2WD7_q9AcNWKUmY6eO8KNuHB1RflBg_z2UnTAJV-EB4BUJJrkEqzWcr4SrauZGkSAK2TqA9LHHvNJ1-6oiNdIYZVlsaVrE4AV4l4uIqArxzA8HfgyNJkzXgHnPHUvWw2eBUa0SJzg/w400-h170/finalshot_singleframeB.jpg" width="400"></span></a></p><p><span><span><i>the final shot as it appears in the film</i></span></span></p><p><span>So there you have it, readers. Another Star Wars mystery solved. In this case it wasn’t a Force ghost, but a stunt rigger who slipped into the shot during the compositing process, providing a wonderful look at the technical seams and handmade nature of the world of visual effects. Star Wars: Revenge of the Sith is streaming now on Disney+.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Signal Carnival (115 pts)]]></title>
            <link>https://www.quiss.org/signal_carnival/</link>
            <guid>43745040</guid>
            <pubDate>Sun, 20 Apr 2025 17:13:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quiss.org/signal_carnival/">https://www.quiss.org/signal_carnival/</a>, See on <a href="https://news.ycombinator.com/item?id=43745040">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="main_content_wrap">

<iframe width="560" height="315" src="https://www.youtube.com/embed/_Orvsms7Ils?si=z9KbNEWr_E6vsuZV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>At Revision 2025, we released "Signal Carnival" (<a href="https://csdb.dk/release/?id=252090">csdb</a>, <a href="https://youtu.be/_Orvsms7Ils">YouTube</a>). This demo asks you to
switch the audio and video cable of your C64:</p>

<p><img src="https://www.quiss.org/signal_carnival/cross_small.png" alt="Diagram of audio and video crossed" title="">
(<strong>Diagram by Felidae</strong>)</p>

<p>Technically, "misplugging" those cables is not a completely new idea. In the
90s, it was a common thing to connect audio to both speaker and video,
to get screen flickering timed with the music beats.</p>

<p>However, "Signal Carnival" is the first production to switch both these
cables, while still being able to play meaningful audio and video.</p>

<h2>How to drive audio using a video signal</h2>

<p>The C64's VIC chip operates at a frequency of 7.9Mhz, and new values can be
written to it by the 6502 at a rate of up to 246kHz. Since even high
quality audio rarely exceeds 44kHz, this is easily a high enough frequency
to generate music.</p>

<p>Inspired by the music routine from freespin, we combined two timers to
get an interesting waveform, which is adjusted once per frame. This is
the code that drives audio:</p>

<pre><code>lda $dc06
ora $dd06
eor $02
sta $d020
</code></pre>

<p>Here, <code>$dc06</code> and <code>$dd06</code> are the lower bytes of the B timers of CIA #1 and #2,
respectively. They're in turn increased every time their A timers
overflow. And those are set to a new value for every new note.</p>

<p>Eor-ing with the value at zeropage <code>$02</code> allows to slightly tweak the waveform (and volume!),
and then the result is written to <code>$d020</code>, which is the screen color.
Only the brightness of said color matters (chrominance is encoded at the
PAL color carrier frequency, which is outside of the human hearing
range). There's no obvious relationship between the brightness of the C64 color
and its number, but that's fine - it actually makes the
waveforms more interesting.</p>

<p>Of course, the above uses up all four timers the C64 CIAs have, which means there
are no timers left for e.g. video stabilization, which is instead done
through the lightpen circuitry. (Finally! A use case for <code>$d013</code>. :))</p>

<p>Music is just one voice, but the song switches between voices (and
waveforms) often enough to sound mildly polyphonic.</p>

<h2>How to drive video using an audio signal</h2>

<p>The SID chip of the C64 internally operates (for PAL) at 9.85Mhz, and,
like the VIC, can be fed with new values at a rate of up to 246kHz.</p>

<p>The SID has a number of audio features. It can generate three voices
using multiple waveforms, it has an ADSR envelope generator, can sync
between voices, and apply filters.
Unfortunately, all this circuitry works at a (for video)
glacial pace: The highest frequency the chip can output is 3906Hz, which
is the equivalent of changing the video output every four rasterlines.
Similar with ADSR, for which the smallest possible configurable attack
time is 2 ms, so about 32 rasterlines.</p>

<p>But thankfully, there's also circuitry that is wired more directly and
and gives instant output: the volume register ($d418)!
This has been used in the past to generate samples at high frequencies
(16+ khz), and is a good choice for generating video, as well.</p>

<p>However, the C64 mainboard also, vexingly, passes the SID signal through
a analogue bandpass filter. And this always happens, regardless of
whether filtering is on or not.</p>

<p><img src="https://www.quiss.org/signal_carnival/filter.png" alt="Subsection of C64 mainboard circuit diagram" title=""></p>

<p>This means that the pixels we work with are very wide, and also horizontally
blurred. Here's one "pixel", displayed on my 1084 monitor:</p>

<p><img src="https://www.quiss.org/signal_carnival/onepixel_cropped.png" alt="Photo of 1084 display, with a blurry horizontal &quot;pixel&quot;" title=""></p>

<p>This blurryness poses an interesting constraint on effects. While technically,
you do have some degree of horizontal resolution, the blurriness makes it
unenticing to use it for scrollers. Here are a few letters, for illustration:</p>

<p><img src="https://www.quiss.org/signal_carnival/end.jpg" alt="Photo of three letters, heavily blurred" title=""></p>

<p>Signal Carnival makes heavy use of both axis,
but to cope with the bluriyness, the x axis is used for graphics elements that
are fine to blur, like e.g. textures.</p>

<p>Other than that, driving the video is just your normal vanilla video
bitbanging. Due to the bandpass filter, horizontal syncs (i.e., pulling
the signal line to ground) need to be precisely timed, so they get
recognized, but not mistaken for vertical syncs. (which differ from
horizontal syncs only in that the signal is pulled to ground a
little bit longer)</p>

<p>Video sync generation is happening at the same refresh frequency that
the VIC would have produced (so we can use raster interrupts and query
the lightpen), but we use a different horizontal frequency (64 cycles
per line instead of 63), since having that extra cycle proved useful
in a lot of effects. And besides, if you're generating your own
video signal, you might as well make your own rules!</p>

<h2>Loading</h2>

<p>I've written a new loader for probably every demo I've ever released on the C64,
and this one is no exception. Since a lot of the effects are quite
memory-hungry (we even play a sample at the end), loading breaks are
long enough that we can't just
<a href="http://www.quiss.org/freespin/loading.html">pause audio while they happen</a>.</p>

<p>Hence, we have to bitbang audio the entire time. Also while transferring
data from the drive to the C64. Also during decrunching. (The
decruncher actually unrolls all copy loops, also for that reason)</p>

<p>The loader has a few gimmicks, like doing on-the-fly GCR decoding that
allows to write to any page (not just stack), and it buffers (stashes) a
full kilobyte. <em>But</em> it's also a one-off, so it's missing tons of
features seen in fully-fledged C64 loaders. It doesn't even support
loading from tracks 18 and above yet (the demo uses 1-10.)
Also no checksumming. (So remember, kids, dust off your 1541 drives, or
Signal Carnival might not work!)</p>

<p>Talking about GCR decoding, I found it tedious to handcode the decoding
tables, so we instead wrote a solver that generates them given the code
that uses the tables, and the desired input/output. Very useful tool,
hopefully to be released soon.</p>


</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turing-Drawings (120 pts)]]></title>
            <link>https://github.com/maximecb/Turing-Drawings</link>
            <guid>43744609</guid>
            <pubDate>Sun, 20 Apr 2025 16:00:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/maximecb/Turing-Drawings">https://github.com/maximecb/Turing-Drawings</a>, See on <a href="https://news.ycombinator.com/item?id=43744609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>GitHub Advanced Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:maximecb/Turing-Drawings" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="3YKtS4VAeyYHAsm0bjOfkutVs8KS6Kz20IdUN0dE9UAf9sBR_WBCjDgJ5dfVP3sRX3JJWVG-BJLmXS4gKCKHEg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="maximecb/Turing-Drawings" data-current-org="" data-current-owner="maximecb" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=maximecb%2FTuring-Drawings" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/maximecb/Turing-Drawings&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="eaf56557bc40b1f72873b38d98a046e468db80c4a47f3d9beddd2981638813f5" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>

              
          
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things Zig comptime won't do (393 pts)]]></title>
            <link>https://matklad.github.io/2025/04/19/things-zig-comptime-wont-do.html</link>
            <guid>43744591</guid>
            <pubDate>Sun, 20 Apr 2025 15:57:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2025/04/19/things-zig-comptime-wont-do.html">https://matklad.github.io/2025/04/19/things-zig-comptime-wont-do.html</a>, See on <a href="https://news.ycombinator.com/item?id=43744591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article>
        <h2>
          Things Zig comptime Won’t Do <time datetime="2025-04-19">Apr 19, 2025</time>
        </h2>

        <figure>
          <blockquote>
            <p>
              Es el disco de Odín. Tiene un solo lado. En la tierra no hay otra
              cosa que tenga un solo lado.
            </p>
          </blockquote>
        </figure>
        <p>
          Zig’s comptime feature is most famous for what it can do: generics!,
          <a href="https://mitchellh.com/writing/zig-comptime-conditional-disable">conditional compilation</a>!,
          <a href="https://mitchellh.com/writing/zig-comptime-tagged-union-subset">subtyping</a>!, serialization!,
          <a href="https://matklad.github.io/2025/03/19/comptime-zig-orm.html">ORM</a>! That’s fascinating, but, to be fair, there’s a bunch of
          languages with quite powerful compile time evaluation capabilities
          that can do equivalent things. What I find more interesting is that
          Zig comptime is actually quite restrictive, by design, and won’t do
          many things! It manages to be very expressive <em>despite</em> being
          pretty limited. Let’s see!
        </p>
        <section id="No-Host-Leakage">
          <h2>
            <a href="#No-Host-Leakage">No Host Leakage </a>
          </h2>
          <p>
            When you execute code at compile time, on which machine does it
            execute? The natural answer is “on your machine”, but it is wrong!
            The code might not run on your machine, it can be cross compiled!
            For overall development sanity, it is important that <code>comptime</code> code observes the same behavior as the runtime
            code, and doesn’t leak details about the host on which the code is
            compiled. Zig doesn’t give comptime code access to host architecture
            (host — machine on which you compile code). Consider this Zig
            program:
          </p>

          <figure>
            <pre><code><span><span>const</span> std = <span>@import</span>(<span>"std"</span>);</span>
<span></span>
<span><span>comptime</span> {</span>
<span>    <span>const</span> x: <span>usize</span> = <span>0xbeef</span>;</span>
<span>    <span>const</span> xs: []<span>const</span> <span>u8</span> = std.mem.asBytes(<span>&amp;</span>x);</span>
<span>    <span>for</span> (xs) <span>|</span>byte<span>|</span> {</span>
<span>        <span>@compileLog</span>(byte);</span>
<span>    }</span>
<span>}</span></code></pre>
          </figure>
          <p>
            I get the following output when compiling normally, on my computer
            for my computer:
          </p>

          <figure>
            <pre><code><span>λ ~/zig-0.14/zig build-lib main.zig</span>
<span>@as(u8, 239)</span>
<span>@as(u8, 190)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span></code></pre>
          </figure>
          <p>
            But if I cross compile to a 32 bit big-endian architecture, comptime
            observes correct <code>usize</code>:
          </p>

          <figure>
            <pre><code><span>λ ~/zig-0.14/zig build-lib -target thumbeb-freestanding-none main.zig</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 0)</span>
<span>@as(u8, 190)</span>
<span>@as(u8, 239)</span></code></pre>
          </figure>
          <p>
            My understanding is that Jai, for example, doesn’t do this, and runs
            comptime code on the host.
          </p>
          <p>
            Rust’s declarative macros and const-fn don’t observe host
            architecture, but procedural macros do.
          </p>
        </section>
        <section id="No-eval">
          <h2>
            <a href="#No-eval">No #eval </a>
          </h2>
          <p>
            Many powerful compile-time meta programming systems work by allowing
            you to inject arbitrary strings into compilation, sort of like <code>#include</code> whose argument is a shell-script that generates the
            text to include dynamically. For example, D mixins work that way:
            <a href="https://dlang.org/articles/mixin.html">https://dlang.org/articles/mixin.html</a>
          </p>
          <p>
            And Rust macros, while technically producing a token-tree rather
            than a string, are more or less the same. In contrast, there’s
            absolutely no facility for dynamic source code generation in Zig.
            You just can’t do that, the feature isn’t!
          </p>
          <p>
            Zig has a completely different feature, partial
            evaluation/specialization, which, none the less, is enough to cover
            most of use-cases for dynamic code generation. Let’s see an
            artificial example:
          </p>

          <figure>
            <pre><code><span><span>fn</span><span> f</span>(x: <span>u32</span>, y: <span>u32</span>) <span>u32</span> {</span>
<span>    <span>if</span> (x <span>==</span> <span>0</span>) <span>return</span> y <span>+</span> <span>1</span>;</span>
<span>    <span>if</span> (x <span>==</span> <span>1</span>) <span>return</span> y <span>*</span> <span>2</span>;</span>
<span>    <span>return</span> y;</span>
<span>}</span></code></pre>
          </figure>
          <p>
            This is a normal function that dispatches on the first argument to
            select an operation to apply to the second argument. Nothing fancy!
            Now, the single feature that Zig has is marking the first argument
            with <code>comptime</code>
          </p>

          <figure>
            <pre><code><span><span>fn</span><span> f</span>(<span>comptime</span> x: <span>u32</span>, y: <span>u32</span>) <span>u32</span> {</span>
<span>    <span>if</span> (x <span>==</span> <span>0</span>) <span>return</span> y <span>+</span> <span>1</span>;</span>
<span>    <span>if</span> (x <span>==</span> <span>1</span>) <span>return</span> y <span>*</span> <span>2</span>;</span>
<span>    <span>return</span> y;</span>
<span>}</span></code></pre>
          </figure>
          <p>
            The restriction here is that now, of course, when you call <code>f</code>, the first argument must be comptime-known. You can <span><code>f(92, user_input())</code>,</span> but you can’t
            <span><code>f(user_input(), 92)</code>.</span>
          </p>
          <p>
            The carrot you’ll get in exchange is a guarantee that, for each
            specific call with a particular value of <code>x</code>, the
            compiler will partially evaluate <code>f</code>, so only one branch
            will be left.
          </p>
          <p>
            Zig is an imperative language. Not everything is a function, there’s
            also control flow expressions, and they include partially-evaluated
            variations. For example, <code>for(xs)</code> is a normal runtime
            for loop over a slice, <code>comptime for(xs)</code> evaluates the
            entire loop at compile time, requiring that <code>xs</code> is
            comptime-known, and <code>inline for(xs)</code> requires that just
            the length of <code>xs</code> is known at comptime.
          </p>
          <p>
            Let’s apply specialization to the classic problem solved by
            code-generation — printing. You can imagine a proc-macro style
            solution that prints a struct by reflecting on which fields it has
            and emitting the code to print each field.
          </p>
          <p>
            In Zig, the same is achieved by specializing a recursive <code>print</code> function on the value of type:
          </p>

          <figure>
            <pre><code><span><span>const</span> S = <span>struct</span> {</span>
<span>    int: <span>u32</span>,</span>
<span>    string: []<span>const</span> <span>u8</span>,</span>
<span>    nested: <span>struct</span> {</span>
<span>        int: <span>u32</span>,</span>
<span>    },</span>
<span>};</span>
<span></span>
<span><span>pub</span> <span>fn</span><span> main</span>() <span>void</span> {</span>
<span>    <span>const</span> s: S = .{</span>
<span>        .int = <span>1</span>,</span>
<span>        .string = <span>"hello"</span>,</span>
<span>        .nested = .{ .int = <span>2</span> },</span>
<span>    };</span>
<span>    print(S, s);</span>
<span>}</span>
<span></span>
<span><span>fn</span><span> print</span>(<span>comptime</span> T: <span>type</span>, value: T) <span>void</span> {</span>
<span>    <span>if</span> (T <span>==</span> <span>u32</span>) <span>return</span> print_u32(value);</span>
<span>    <span>if</span> (T <span>==</span> []<span>const</span> <span>u8</span>) <span>return</span> print_string(value);</span>
<span>    <span>switch</span> (<span>@typeInfo</span>(T)) {</span>
<span>        .@<span>"struct"</span> =&gt; <span>|</span>info<span>|</span> {</span>
<span>            print_literal(<span>"{"</span>);</span>
<span>            <span>var</span> space: []<span>const</span> <span>u8</span> = <span>""</span>;</span>
<span>            <span>inline</span> <span>for</span> (info.fields) <span>|</span>field<span>|</span> {</span>
<span>                print_literal(space);</span>
<span>                space = <span>", "</span>;</span>
<span></span>
<span>                print_literal(field.name);</span>
<span>                print_literal(<span>" = "</span>);</span>
<span>                <span>const</span> field_value = <span>@field</span>(value, field.name);</span>
<span>                print(field.<span>type</span>, field_value);</span>
<span>            }</span>
<span>            print_literal(<span>"}"</span>);</span>
<span>        },</span>
<span>        <span>else</span> =&gt; <span>comptime</span> <span>unreachable</span>,</span>
<span>    }</span>
<span>}</span>
<span></span>
<span><span>fn</span><span> print_u32</span>(value: <span>u32</span>) <span>void</span> {</span>
<span>    std.debug.print(<span>"{d}"</span>, .{value});</span>
<span>}</span>
<span></span>
<span><span>fn</span><span> print_string</span>(value: []<span>const</span> <span>u8</span>) <span>void</span> {</span>
<span>    std.debug.print(<span>"<span>\"</span>{s}<span>\"</span>"</span>, .{value});</span>
<span>}</span>
<span></span>
<span><span>fn</span><span> print_literal</span>(literal: []<span>const</span> <span>u8</span>) <span>void</span> {</span>
<span>    std.debug.print(<span>"{s}"</span>, .{literal});</span>
<span>}</span></code></pre>
          </figure>
          <p>
            Our <code>print</code> is set up exactly as our <code>f</code>
            before — the first argument is a comptime-known dispatch parameter.
            If <code>T</code> is an int or a string, the compiler calls <code>print_u32</code> or <code>print_string</code> directly.
          </p>
          <p>
            The third case is more complicated. First, we use <code>@typeInfo</code> to get a comptime value describing our type, and,
            in particular, the list of fields it has. Then, we iterate this list
            and recursively print each field. Note that although the list of
            fields is known in its entirety, we can’t <code>comptime for</code>
            it, we need <code>inline for</code>. This is because the <em>body</em> of our loop depends on the runtime
            <code>value</code>, and can’t be fully evaluated at compile time.
            This might be easier to see if you think in terms of functions. The
            <code>for</code> loop is essentially a map:
          </p>

          <figure>
            <pre><code><span>map :: [a] -&gt; (a -&gt; b) -&gt; [b]</span>
<span>map xs f = ...</span></code></pre>
          </figure>
          <p>
            If both <code>xs</code> and <code>f</code> are comptime-known, you
            can evaluate the entire loop at compile time. But in our case <code>f</code> actually closes over a runtime value, so we can’t evaluate
            everything. Still, we can specialize on the first argument, which
            <em>is</em> known at compile time. This is precisely the difference
            between <code>comptime</code> and <code>inline</code>
            <code>for</code>.
          </p>
        </section>
        <section id="No-DSLs">
          <h2>
            <a href="#No-DSLs">No DSLs </a>
          </h2>
          <p>
            Many meta programming systems, like macros in Lisp or Rust, not only
            <em>produce</em> arbitrary code, but also take arbitrary custom
            syntax as input, as long as parentheses are matched:
          </p>

          <figure>
            <pre><code><span><span>use</span> inline_python::python;</span>
<span></span>
<span><span>let</span> <span>who</span> = <span>"world"</span>;</span>
<span><span>let</span> <span>n</span> = <span>5</span>;</span>
<span>python! {</span>
<span>    <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>'n</span>):</span>
<span>        <span>print</span>(i, <span>"Hello"</span>, <span>'who</span>)</span>
<span>    <span>print</span>(<span>"Goodbye"</span>)</span>
<span>}</span></code></pre>
          </figure>
          <p>
            Zig doesn’t have any extension points for custom syntax. Indeed, you
            can’t pass Zig <em>syntax</em> (code) to comptime functions at all!
            Everything operates on Zig values. That being said, Zig is very
            lightweight when it comes to describing free-form data, so this
            isn’t much of a hindrance. <em>And</em>
            in any case, you can always pass your custom syntax as a comptime
            string. This is exactly how “printf” works:
          </p>

          <figure>
            <pre><code><span><span>pub</span> <span>fn</span><span> print</span>(<span>comptime</span> fmt: []<span>const</span> <span>u8</span>, args: <span>anytype</span>) <span>void</span></span></code></pre>
          </figure>
          <p>
            Here, <code>fmt</code> is an embedded DSL, which is checked at
            compile time to match the arguments.
          </p>
        </section>
        <section id="No-RTTI">
          <h2>
            <a href="#No-RTTI">No RTTI </a>
          </h2>
          <p>
            Zig printing code looks suspiciously close to how you’d do this sort
            of thing in a dynamic language like Python. In fact, it is <em>precisely</em> that same code, except that it is specialized over
            runtime type information Python has to enable this sort of thing.
            Furthermore, Zig actually <em>requires</em> that all type meta
            programming is specialized away. Types as values <em>only</em> exist
            at compile time. Still, looking at our print, we might be concerned
            over code size — we are effectively generating a fresh copy of <code>print</code> for any data structure. Our code will be smaller, and
            will compile faster if there’s just a single <code>print</code> that
            takes an opaque pointer and runtime parameter describing the type of
            the value (its fields and offsets). So let’s roll our own runtime
            type information. For our example, we support ints, strings, and
            structs with fields. For fields, our RTTI should include their names
            and offsets:
          </p>

          <figure>
            <pre><code><span><span>const</span> RTTI = <span>union</span>(<span>enum</span>) {</span>
<span>    <span>u32</span>,</span>
<span>    string,</span>
<span>    @<span>"struct"</span>: []<span>const</span> Field,</span>
<span></span>
<span>    <span>const</span> Field = <span>struct</span> {</span>
<span>        name: []<span>const</span> <span>u8</span>,</span>
<span>        offset: <span>u32</span>,</span>
<span>        rtti: RTTI,</span>
<span>    };</span>
<span>};</span></code></pre>
          </figure>
          <p>
            The printing itself is not particularly illuminating, we just need
            to cast an opaque pointer according to RTTI:
          </p>

          <figure>
            <pre><code><span><span>fn</span><span> print_dyn</span>(T: RTTI, value: <span>*</span><span>const</span> anyopaque) <span>void</span> {</span>
<span>    <span>switch</span> (T) {</span>
<span>        .<span>u32</span> =&gt; {</span>
<span>            <span>const</span> value_u32: <span>*</span><span>const</span> <span>u32</span> =</span>
<span>                <span>@alignCast</span>(<span>@ptrCast</span>(value));</span>
<span>            print_u32(value_u32.<span>*</span>);</span>
<span>        },</span>
<span>        .string =&gt; {</span>
<span>            <span>const</span> value_string: <span>*</span><span>const</span> []<span>const</span> <span>u8</span> =</span>
<span>                <span>@alignCast</span>(<span>@ptrCast</span>(value));</span>
<span>            print_string(value_string.<span>*</span>);</span>
<span>        },</span>
<span>        .@<span>"struct"</span> =&gt; <span>|</span>info<span>|</span> {</span>
<span>            print_literal(<span>"{"</span>);</span>
<span>            <span>var</span> space: []<span>const</span> <span>u8</span> = <span>""</span>;</span>
<span>            <span>for</span> (info) <span>|</span>field<span>|</span> {</span>
<span>                print_literal(space);</span>
<span>                space = <span>", "</span>;</span>
<span></span>
<span>                print_literal(field.name);</span>
<span>                print_literal(<span>" = "</span>);</span>
<span>                <span>const</span> field_ptr: <span>*</span><span>const</span> anyopaque =</span>
<span>                    <span>@as</span>([<span>*</span>]<span>const</span> <span>u8</span>, <span>@ptrCast</span>(value)) <span>+</span> field.offset;</span>
<span>            }</span>
<span>            print_literal(<span>"}"</span>);</span>
<span>        },</span>
<span>    }</span>
<span>}</span></code></pre>
          </figure>
          <p>
            Finally, we need to compute <code>RTTI</code>, which amounts to
            taking comptime-only Zig type info and extracting important bits
            into an <code>RTTI</code> struct which is computed at compile time,
            but can exist at runtime as well:
          </p>

          <figure>
            <pre><code><span><span>fn</span><span> reflect</span>(<span>comptime</span> T: <span>type</span>) RTTI {</span>
<span>    <span>comptime</span> {</span>
<span>        <span>if</span> (T <span>==</span> <span>u32</span>) <span>return</span> .<span>u32</span>;</span>
<span>        <span>if</span> (T <span>==</span> []<span>const</span> <span>u8</span>) <span>return</span> .string;</span>
<span>        <span>switch</span> (<span>@typeInfo</span>(T)) {</span>
<span>            .@<span>"struct"</span> =&gt; <span>|</span>info<span>|</span> {</span>
<span>                <span>var</span> fields: [info.fields.len]Field = <span>undefined</span>;</span>
<span>                <span>for</span> (<span>&amp;</span>fields, info.fields) <span>|</span><span>*</span>slot, field<span>|</span> {</span>
<span>                    slot.<span>*</span> = .{</span>
<span>                        .name = field.name,</span>
<span>                        .offset = <span>@offsetOf</span>(T, field.name),</span>
<span>                        .rtti = reflect(field.<span>type</span>),</span>
<span>                    };</span>
<span>                }</span>
<span>                <span>const</span> fields_frozen = fields;</span>
<span>                <span>return</span> .{ .@<span>"struct"</span> = <span>&amp;</span>fields_frozen };</span>
<span>            },</span>
<span>            <span>else</span> =&gt; <span>unreachable</span>,</span>
<span>        }</span>
<span>    }</span>
<span>}</span></code></pre>
          </figure>
          <p>
            The call site is illustrative: we need <code>comptime</code> to <em>compute</em> the type information, but then we reify it as some
            real bytes in the binary, and use it as runtime value when calling
            <code>print_dyn</code>.
          </p>

          <figure>
            <pre><code><span><span>pub</span> <span>fn</span><span> main</span>() <span>void</span> {</span>
<span>    <span>const</span> s: S = .{</span>
<span>        .int = <span>1</span>,</span>
<span>        .string = <span>"hello"</span>,</span>
<span>        .nested = .{ .int = <span>2</span> },</span>
<span>    };</span>
<span>    print_dyn(<span>comptime</span> RTTI.reflect(S), <span>&amp;</span>s);</span>
<span>}</span></code></pre>
          </figure>
        </section>
        <section id="No-New-API">
          <h2>
            <a href="#No-New-API">No New API </a>
          </h2>
          <p>
            You can use Zig comptime to create new types. That’s how a <a href="https://matklad.github.io/2025/03/19/comptime-zig-orm.html">Zig ORM</a> can work. However, it is impossible to add methods to
            generated types, they must be inert bundles of fields. In Rust, when
            you use a derive macro, it can arbitrarily extend type’s public API,
            and you need to read proc macro docs (or look at the generated code)
            to figure out what’s available. In Zig, types’s API is always hand
            written, but it can use comptime reflection internally.
          </p>
          <p>
            So, if you are building a JSON serialization library in Zig, you
            can’t add <code>.to_json</code> method to user-types. You’ll
            necessarily have to supply a normal top-level function like
          </p>

          <figure>
            <pre><code><span><span>fn</span><span> to_json</span>(<span>comptime</span> T: <span>type</span>, value: T, writer: Writer) <span>!</span><span>void</span> {</span>
<span>    ...</span>
<span>}</span></code></pre>
          </figure>
          <p>
            If you want to make sure that types explicitly opt-in JSON
            serialization, you need to ask the user to mark types specially:
          </p>

          <figure>
            <pre><code><span><span>const</span> Person = <span>struct</span> {</span>
<span>    first_name: []<span>const</span> <span>u8</span>,</span>
<span>    last_name: []<span>const</span> <span>u8</span>,</span>
<span></span>
<span>    <span>pub</span> <span>const</span> JSONOptions = .{</span>
<span>        .style = .camelCase,</span>
<span>    };</span>
<span>}</span></code></pre>
          </figure>
          <p>
            With this setup, <code>to_json</code> can only allow primitives and
            types with <code>JSONOptions</code>.
          </p>
        </section>
        <section id="No-IO">
          <h2>
            <a href="#No-IO">No IO </a>
          </h2>
          <p>
            Last but not least, Zig comptime does not allow any kind of input
            output. There isn’t even any kind of sandbox, as there are no IO
            facilities in the first place. So, while compiling the code, you
            can’t talk to your database to generate the schema. In exchange,
            compile time evaluation is hermetic, reproducible, safe, and
            cacheable.
          </p>
          <p>
            If you do need to talk to the database at build time, you can still
            do that, just through the build system! Zig’s <code>build.zig</code>
            is a general purpose build system, which easily supports the
            use-case of running an arbitrary Zig program to generate arbitrary
            Zig code which can then be normally
            <code>@import</code>ed.
          </p>
        </section>
        <section id="El-Disco">
          <h2>
            <a href="#El-Disco">El Disco </a>
          </h2>
          <p>
            <a href="https://www.tedinski.com/2018/01/30/the-one-ring-problem-abstraction-and-power.html">Any abstraction has two sides</a>. Powerful abstractions are useful
            because they are more expressive. But the flip-side is that
            abstraction-using code becomes harder to reason about, because the
            space of what it can possibly do is so vast. This dependency is not
            zero sum. A good abstraction can be simultaneously more powerful and
            easier to reason about than a bad one.
          </p>
          <p>
            Meta programming is one of the more powerful abstractions. It is
            very capable in Zig, and comes at a significant cost — Zig doesn’t
            have declaration-site type checking of comptime code. That being
            said, I personally find Zig’s approach to be uniquely tidy, elegant,
            and neat! It does much less than alternative systems, but ends
            extremely ergonomic in practice, and <em>relatively</em> easy to
            wrap ones head around.
          </p>
        </section>
      </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The skill of the future is not 'AI', but 'Focus' (173 pts)]]></title>
            <link>https://www.carette.xyz/posts/focus_will_be_the_skill_of_the_future/</link>
            <guid>43744394</guid>
            <pubDate>Sun, 20 Apr 2025 15:28:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.carette.xyz/posts/focus_will_be_the_skill_of_the_future/">https://www.carette.xyz/posts/focus_will_be_the_skill_of_the_future/</a>, See on <a href="https://news.ycombinator.com/item?id=43744394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>If you frequent Hacker News regurlarly, you have likely noticed the buzz around engineers using AI
(specifically Large Language Models, or LLMs) to tackle Computer Science problems.</p>
<p>I want to be clear: <strong>I’m not against LLMs</strong>.<br>
LLMs are incredibly powerful tools, and <strong>can</strong> be a huge boon to engineers.
They can automate repetitive tasks, generate code snippets, help with brainstorming, assist in debugging, …
and this can frees up engineers’ time and mental energy, which could be channeled into more complex, creative problem-solving.<br>
But, like any tool, LLMs should be used <strong>wisely</strong>.<br>
LLMs can hallucinate, exhibit inconsistencies (especially with self-reflection models), and harbor biases. These limitations mean that LLM outputs require careful review before they can be trusted.</p>
<p>A key concern with LLMs lies in their training data.<br>
The data can be biased, contradictory sometimes, but those data contain solutions to known problems.<br>
If an engineer wants to “reinvent the wheel,” an LLM might offer a solution (good or bad, depending on the prompt). But when faced with truly <em>novel</em> problems, LLMs often provide unreliable responses, placing the burden of error detection squarely on the engineer.</p>
<p>This reliance on readily available solutions, particularly for familiar problems, creates a real risk: engineers may inadvertently atrophy their own problem-solving skills, hindering their ability to tackle truly novel challenges.<br>
The solution lies is <strong>balance</strong>, and a focus on the “why”, not just the “what”.<br>
Engineers should strive to understand the <em>reasoning</em> behind LLM-generated solutions, not simply accept them blindly.  Blind acceptance shifts the focus from <em>solving</em> problems to merely <em>obtaining</em> a solution.  Crucially, solving complex problems often depends on mastering simpler and foundational skills, which the engineer might lose quickly.</p>
<p>This idea summarizes why I disagree with those who equate the LLM revolution to the rise of search engines, like Google in the 90s.
Search enginers offer a good choice between <em>Exploration</em> (crawl through the list and pages of results) and
<em>Exploitation</em> (click on the top result).<br>
LLMs, however, do not give this choice, and tend to encourage immediate exploitation instead.
Users may explore if the first solution <strong>does not work</strong>, but the first
choice is <strong>always</strong> to exploit.<br>
<em>Exploitation</em> and <em>exploration</em> are complementary. Remove the exploration and you will introduce more and more instability into the exploitation process.</p>
<p>Computer Science emerged because Humans needed <strong>tools</strong> to solve problems faster and wanted to <strong>focus</strong> on the real problems, not repetitive tasks.
Humans built machines to accelerate problem-solving, but engineers remained the masters of the algorithms.<br>
I fear we’re losing our grip on this mastery.
Not because engineers are becoming less and less intelligent, but because the pressure to deliver solutions quickly is paramount.<br>
In embracing these “fast-paced solutions”, we risk losing a fundamental skill: <em>focus</em>. Because focus, like any skill, requires practice.</p>
<p>This is a worrying trend. If engineers become less adept at solving complex problems, what does the future hold?
Will our ability to tackle complex challenges rest solely on self-reflecting AIs, rather than human ingenuity?</p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jagged AGI: o3, Gemini 2.5, and everything after (215 pts)]]></title>
            <link>https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything</link>
            <guid>43744173</guid>
            <pubDate>Sun, 20 Apr 2025 14:55:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything">https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything</a>, See on <a href="https://news.ycombinator.com/item?id=43744173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Amid today’s AI boom, it’s disconcerting that we still don’t know how to measure how smart, creative, or empathetic these systems are. Our tests for these traits, never great in the first place, were made for humans, not AI. </span><a href="https://ai-analytics.wharton.upenn.edu/generative-ai-labs/research-and-technical-reports/tech-report-prompt-engineering-is-complicated-and-contingent/" rel="">Plus, our recent paper testing prompting techniques</a><span> finds that AI test scores can change dramatically based simply on how questions are phrased. Even famous challenges like the Turing Test, where humans try to differentiate between an AI and another person in a text conversation, were designed as thought experiments at a time when such tasks seemed impossible. But now that </span><a href="https://arxiv.org/pdf/2503.23674" rel="">a new paper shows that AI passes the Turing Test</a><span>, we need to admit that we really don’t know what that actually means. </span></p><p><span>So, it should come as little surprise that one of the most important milestones in AI development, Artificial General Intelligence, or AGI, is badly defined and much debated. Everyone agrees that it has something to do with the ability of AIs to perform human-level tasks, though no one agrees whether this means expert or average human performance, or how many tasks and which kinds an AI would need to master to qualify. Given the definitional morass surrounding AGI, illustrating its nuances and history from its precursors to its initial coining by Shane Legg, Ben Goertzel and Peter Voss to today is challenging. As an experiment in both substance and form (and speaking of potentially intelligent machines) I delegated the work entirely to AI. I had Google Deep Research put together a </span><a href="https://docs.google.com/document/d/1VJ-OzBRJUChgUB0L0--dbdNjU2e-14PXnoTqNFYgXNQ/edit?tab=t.0" rel="">really solid 26 page summary on the topic</a><span>. I then had HeyGen turn it into a video podcast discussion between a twitchy AI-generated version of me and an AI-generated host. It’s not actually a bad discussion (though I don’t fully agree with AI-me), but every part of it, from the research to the video to the voices is 100% AI generated.</span></p><p><span>Given all this, it was interesting to see </span><a href="https://marginalrevolution.com/marginalrevolution/2025/04/o3-and-agi-is-april-16th-agi-day.html" rel="">this post </a><span>by influential economist and close AI observer Tyler Cowen declaring that o3 is AGI. Why might he think that?</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg" width="370" height="368.8787878787879" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1316,&quot;width&quot;:1320,&quot;resizeWidth&quot;:370,&quot;bytes&quot;:243143,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161512556?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65e30c6c-abb0-46e9-9699-cbe7c4211185_1320x1507.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47409a3c-004a-47f4-903a-adb6807684ae_1320x1316.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>First, a little context. Over the past couple of weeks, two new AI models, Gemini 2.5 Pro from Google and o3 from OpenAI were released. These models, along with a set of slightly less capable but faster and cheaper models (Gemini 2.5 Flash, o4-mini, and Grok-3-mini), represent a pretty</span><a href="https://epoch.ai/data/ai-benchmarking-dashboard" rel=""> large leap in benchmarks</a><span>. But benchmarks aren’t everything, as Tyler pointed out. For a real-world example of how much better these models have gotten, we can turn to </span><a href="https://a.co/d/2qRbAxA" rel="">my book</a><span>. To illustrate a chapter on how AIs can generate ideas, a little over a year ago I asked ChatGPT-4 to come up with marketing slogans for a new cheese shop:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png" width="389" height="304.7465437788018" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:510,&quot;width&quot;:651,&quot;resizeWidth&quot;:389,&quot;bytes&quot;:159134,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161510512?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b89b3d-85f2-426d-89be-424e88aebabf_651x510.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>Today I gave the latest successor to GPT-4, o3, an </span><em>ever so slightly</em><span> more involved version of the same prompt: “</span><strong>Come up with 20 clever ideas for marketing slogans for a new mail-order cheese shop. Develop criteria and select the best one. Then build a financial and marketing plan for the shop, revising as needed and analyzing competition. Then generate an appropriate logo using image generator and build a website for the shop as a mockup, making sure to carry 5-10 cheeses that fit the marketing plan.” </strong><span>With that single prompt, in less than two minutes, the AI not only provided a list of slogans, but ranked and selected an option, did web research, developed a logo, built marketing and financial plans, and launched a demo website for me to react to. The fact that my instructions were vague, and that common sense was required to make decisions about how to address them, was not a barrier.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png" width="1456" height="723" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:723,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2019800,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161510512?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b4aa8b2-65fb-479e-8776-5e552195f88b_4390x2179.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>In addition to being, presumably, a larger model than GPT-4, o3 also works as a </span><a href="https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37" rel="">Reasoner </a><span>- you can see its “thinking” in the initial response. It also is an agentic model, one that can use tools and decide how to accomplish complex goals. You can see how it took multiple actions with multiple tools, including web searches and coding, to come up with the extensive results that it did.</span></p><p><span>And this isn’t the only extraordinary examples, o3 can also do an impressive job guessing locations from photos if you just give it an image and prompt </span><strong>“be a geo-guesser”</strong><span> (with some quite profound privacy implications). Again, you can see the agentic nature of this model at work, as it zooms into parts of the picture, adds web searches, and does multi-step processes to get the right answer.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png" width="525" height="434.4951923076923" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1205,&quot;width&quot;:1456,&quot;resizeWidth&quot;:525,&quot;bytes&quot;:3215925,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161510512?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe91fa6e3-cf1d-4d85-bc99-564d5fc18fea_2062x1707.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Or I gave o3 a large dataset of historical machine learning systems as a spreadsheet and asked </span><strong>“figure out what this is and generate a report examining the implications statistically and give me a well-formatted PDF with graphs and details”</strong><span> and got a full analysis with a single prompt. (I did give it some feedback to make the PDF better, though, as you can see).</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png" width="1456" height="669" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:669,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:694441,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161512556?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e01ecd-26b6-4569-b5d2-86798bdc1102_3529x1622.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This is all pretty impressive stuff and you should experiment with these models on your own. </span><a href="https://gemini.google.com/u/1/app" rel="">Gemini 2.5 Pro</a><span> is free to use and as “smart” as o3, though it lacks the same full agentic ability. If you haven’t tried it or o3, take a few minutes to do it now. Try </span><a href="https://x.com/emollick/status/1910534521998487709" rel="">giving Gemini an academic paper and asking it to turn the paper into a game</a><span> or have it brainstorm with you for startup ideas, or just ask for the AI</span><a href="https://g.co/gemini/share/b2ce16d04017" rel=""> to impress you</a><span> (and then keep saying “more impressive”). Ask the Deep Research option to do a research report on your industry, or to research a purchase you are considering, or to </span><a href="https://bsky.app/profile/emollick.bsky.social/post/3lmdminw4m22o" rel="">develop a marketing plan for a new product</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png" width="374" height="253.2753623188406" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:514,&quot;width&quot;:759,&quot;resizeWidth&quot;:374,&quot;bytes&quot;:169048,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161512556?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43be9304-5824-4995-ae0d-1ea1514090ff_759x514.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You might find yourself “feeling the AGI” as well. Or maybe not. Maybe the AI failed you, even when you gave it the exact same prompt I used. If so, you just encountered the jagged frontier.</p><p><a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged" rel="">My co-authors and I coined the term “Jagged Frontier”</a><span> to describe the fact that AI has surprisingly uneven abilities. An AI may succeed at a task that would challenge a human expert but fail at something incredibly mundane. For example, consider this puzzle, a variation on a classic old brainteaser (a concept first explored by </span><a href="https://x.com/colin_fraser" rel="">Colin Fraser</a><span> and expanded by </span><a href="https://x.com/goodside/status/1790912819442974900" rel="">Riley Goodside</a><span>): </span><em>"A young boy who has been in a car accident is rushed to the emergency room. Upon seeing him, the surgeon says, "I can operate on this boy!" How is this possible?"</em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png" width="443" height="461.75132275132273" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a0b6c099-fc6c-42c2-b78b-380972895420_945x985.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:985,&quot;width&quot;:945,&quot;resizeWidth&quot;:443,&quot;bytes&quot;:66935,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161512556?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0b6c099-fc6c-42c2-b78b-380972895420_945x985.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span> o3 insists the answer is “the surgeon is the boy’s mother,” which is wrong, as a careful reading of the brainteaser will show. Why does the AI come up with this incorrect answer? Because that is the answer to the classic version of the riddle, meant to expose unconscious bias: </span><em>“A father and son are in a car crash, the father dies, and the son is rushed to the hospital. The surgeon says, 'I can't operate, that boy is my son,' who is the surgeon?”</em><span> The AI has “seen” this riddle in its training data so much that even the smart o3 model fails to generalize to the new problem, at least initially. And this is just one example of the kinds of issues and hallucinations that even advanced AIs can fall prey to, showing how jagged the frontier can be.</span></p><p><span>But the fact that the AI often messes up on this particular brainteaser does not take away from the fact that it can </span><a href="https://scale.com/leaderboard/enigma_eval" rel="">solve much harder brainteasers</a><span>, or that it can do the other impressive feats I have demonstrated above. That is the nature of the Jagged Frontier. In some tasks, AI is unreliable. In others, it is superhuman. You could, of course, say the same thing about calculators, but it is also clear that AI is different. It is already demonstrating general capabilities and performing a wide range of intellectual tasks, including those that it is not specifically trained on. Does that mean that o3 and Gemini 2.5 are AGI? Given the definitional problems, I really don’t know, but I do think they can be credibly seen as a form of “Jagged AGI” - superhuman in enough areas to result in real changes to how we work and live, but also unreliable enough that human expertise is often needed to figure out where AI works and where it doesn’t. Of course, models are likely to become smarter, and a good enough Jagged AGI may still beat humans at every task, including in ones the AI is weak in.</span></p><p><span>Returning to Tyler’s post, you will notice that, despite thinking we have achieved AGI, he doesn’t think that threshold </span><a href="https://marginalrevolution.com/marginalrevolution/2025/02/why-i-think-ai-take-off-is-relatively-slow.html" rel="">matters much to our lives in the near term</a><span>. That is because, as many people have pointed out, technologies do not instantly change the world, no matter how compelling or powerful they are. Social and organizational structures change much more slowly than technology, and technology itself takes time to diffuse. Even if we have AGI today, we have years of trying to figure out how to integrate it into our existing human world.</span></p><p><span>Of course, that assumes that AI acts like </span><a href="https://knightcolumbia.org/content/ai-as-normal-technology" rel="">a normal technology</a><span>, and one whose jaggedness will never be completely solved. There is the possibility that this may not be true. The agentic capabilities we're seeing in models like o3, like the ability to decompose complex goals, use tools, and execute multi-step plans independently, might actually accelerate diffusion dramatically compared to previous technologies. If and when AI can effectively navigate human systems on its own, rather than requiring integration, we might hit adoption thresholds much faster than historical precedent would suggest.</span></p><p>And there's a deeper uncertainty here: are there capability thresholds that, once crossed, fundamentally change how these systems integrate into society? Or is it all just gradual improvement? Or will models stop improving in the future as LLMs hit a wall? The honest answer is we don't know.</p><p><span>What's clear is that we continue to be in uncharted territory. The latest models represent something qualitatively different from what came before, whether or not we call it AGI. Their agentic properties, combined with their jagged capabilities, create a genuinely novel situation with few clear analogues. It may be that history continues to be the best guide, and that figuring out how to successfully apply AI in a way that shows up in the economic statistics may be a process measured in decades. Or it might be that we are on the edge of some sort of </span><a href="https://www.nytimes.com/2025/04/03/technology/ai-futures-project-ai-2027.html" rel="">faster take-off</a><span>, where AI-driven change sweeps our world suddenly. Either way, those who learn to navigate this jagged landscape now will be best positioned for what comes next… whatever that is.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png" width="349" height="219.13953488372093" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/afdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:864,&quot;width&quot;:1376,&quot;resizeWidth&quot;:349,&quot;bytes&quot;:2622025,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.oneusefulthing.org/i/161512556?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafdef6bb-e268-4abe-a2ed-53ae3a68d4f1_1376x864.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why on Earth is OpenAI buying Windsurf? (215 pts)]]></title>
            <link>https://theahura.substack.com/p/tech-things-openai-buys-windsurf</link>
            <guid>43743993</guid>
            <pubDate>Sun, 20 Apr 2025 14:28:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf">https://theahura.substack.com/p/tech-things-openai-buys-windsurf</a>, See on <a href="https://news.ycombinator.com/item?id=43743993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>The quiet news of the last few days was the leak/announcement of a $3 billion OpenAI acquisition of Windsurf. That's not the largest private acquisition ever made — that honor goes to Google's $30 billion acquisition of Wiz a few months prior</span><strong> </strong><span>— but man, it's up there! $3B is the kind of exit startup founders dream about. Especially for a startup that's been around for 2 years, </span><a href="https://news.ycombinator.com/item?id=42127882" rel="">with its current branding for about 5 months</a><span>.</span></p><p>I assume most people don't know what Windsurf is, which is fair because it has so few users that when you try to Google for that information you get data about the sport.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png" width="1040" height="409" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:409,&quot;width&quot;:1040,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:117182,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://theahura.substack.com/i/161689970?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff572743-5141-4eaf-918f-90c7f25aca6e_1040x409.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Thanks Gemini!</figcaption></figure></div><p><span>Maybe that’s unfair, supposedly the company </span><a href="https://www.latent.space/p/windsurf?open=false" rel="">has over a million users</a><span>. But I'm always a bit skeptical of numbers like that. A person who uses Windsurf every day is obviously in a different category than one that installed the tool to play around for five minutes and quickly discarded it. This slipperiness has always been one of the benefits of working in the world of privately held companies. Anecdotally I know only one person who uses Windsurf, and I only kinda sorta know that person because he's just a guy that I met at an </span><a href="https://theahura.substack.com/p/notes-from-the-sf-party-scene" rel="">SF house party</a><span>.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-1-161689970" target="_self" rel="">1</a></span></p><p>If you aren't familiar with Windsurf, you may know it by its previous name, Codeium. And if you aren't familiar with Codeium, you may know its primary competition, a company called Cursor. And if you don't know what Cursor is, a) you might know what GitHub Copilot is, and b) how did you find my blog?</p><p>All of these products are roughly in the same category of "AI tools for software engineers". They all have basically the same form factor too — they integrate AI models directly into your coding workflow. And traditionally they operate on three levels of granularity:</p><ul><li><p>Auto-complete. As you type the AI will suggest the rest of the line or function, which you can generally accept with a single button press.</p></li><li><p>Sidebar Q&amp;A. The code window itself will have an integrated sidebar where you can ask models to modify a few files. You'll get a diff, which you can then choose to apply or modify.</p></li><li><p>Agentic flows. The term "agent" is wildly underspecified, but in the AI coding space the term has generally come to mean "an AI model operates in a loop over an entire code base, often with a very vague or high level prompt as a starting point, and is equipped with tools to write, run, and otherwise analyze code and the computer system".</p></li></ul><p>Different companies aim to be best in class along different verticals. Some are better at the auto complete (Copilot), others at the agent flow (Claude Code). Some aim to be the best for non-technical people (Bolt or Replit), others for large enterprises (again, Copilot). Still, all of this "differentiation" ends up making a 1-2% difference in product. In fact, I can't stress enough how much the UX and core functionality of these tools is essentially identical. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png" width="1159" height="692" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:692,&quot;width&quot;:1159,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Cursor Download Free (Windows) - 0.48.9 | Softpedia&quot;,&quot;title&quot;:&quot;Cursor Download Free (Windows) - 0.48.9 | Softpedia&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="Cursor Download Free (Windows) - 0.48.9 | Softpedia" title="Cursor Download Free (Windows) - 0.48.9 | Softpedia" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd1fe08-4081-4353-8b9e-278709d03c08_1159x692.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A screencap of cursor. This has become the ‘canonical’ UX for vibe coding — a sidebar with integrated chat that is able to call out to tools and directly change code using diffs.</figcaption></figure></div><p>These all would have pejoratively been known as "GPT wrappers" just two years ago, because they do not actually compete on the model layer but rather allow users to choose and switch between any of the big LLM providers. To really emphasize how interchangeable these AI code assistants all are, I use an even lesser known tool called Avante, an entirely free and open source neovim plugin. It does the same things as all the other tools. I like it because I don't have to leave vim.</p><p><span>But the similarities of these tools does not take away from how game changing they are. Once you get used to a form of AI powered coding, you cannot go back. The real issue with all of these products is that they are</span><em> </em><span>too</span><em> </em><span>easily verticalized. Anyone who wants to spin up a version of Windsurf with one slight change that targets a tiny market segment can do so fairly easily — again, I'm on Avante entirely because it supports vim. That means the addressable market for any of these companies may actually go </span><em>down</em><span> over time as more competitors and free alternatives enter the market, even as the number of "programmers" goes up.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-2-161689970" target="_self" rel="">2</a></span><span> In point of fact, even though I love the ingenuity behind Cursor (which really spearheaded the current AI coding paradigm) I have openly said that their long term opportunities are slim. Even though Cursor had significant first mover advantage, they have no moat or stickiness. As with the rest of the AI market, switching cost remains extremely low, and there is simply no reason to use Cursor when you can use a free version or one with better enterprise support.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-3-161689970" target="_self" rel="">3</a></span><span> Cursor isn't even living on its own platform — it's a fork of VSCode. I am personally convinced that their only long term exit opportunity is an acquisition by Microsoft, and even that seems less and less likely as Satya puts more resources into the already-VSCode-native Copilot as a real competitor.</span></p><p><span>All of which makes the $3B price tag for Windsurf seem eye wateringly high. Compared to Cursor, Windsurf has fewer users, has been around for less time, has less brand recognition, and has diminishing prospects for future growth. It’s not as tied to VSCode, which is a plus, I guess. But it all begs the question: why on </span><em>earth</em><span> is OpenAI paying so much?</span></p><p><span>This is especially strange in the context of OpenAI's financial situation. </span><a href="https://www.thealgorithmicbridge.com/p/google-is-winning-on-every-ai-front" rel="">Smart</a><span> </span><a href="https://www.wired.com/story/google-openai-gemini-chatgpt-artificial-intelligence/" rel="">observers</a><span> </span><a href="https://www.reddit.com/r/singularity/comments/1hh03ri/google_is_winning_the_ai_race/" rel="">have</a><span> </span><a href="https://www.pymnts.com/news/artificial-intelligence/2025/google-debuts-touted-gemini-winner-take-all-ai-model-race" rel="">caught</a><span> </span><a href="https://medium.com/artificial-corner/how-google-quietly-took-the-lead-in-the-ai-race-with-gemini-2-5-c98dfb58b6a1" rel="">on</a><span> </span><a href="https://venturebeat.com/ai/from-catch-up-to-catch-us-how-google-quietly-took-the-lead-in-enterprise-ai/" rel="">to</a><span> Google's inherent advantages in the space, something that I first publicly called out as early as </span><a href="https://theahura.substack.com/p/tech-things-gpt-pro-and-the-state?" rel="">December</a><span> and more fully </span><a href="https://theahura.substack.com/p/tech-things-gemini-25-and-the-bull?utm_source=publication-search" rel="">two weeks ago</a><span>. OpenAI needs to shore up both its access to compute and its access to data in order to compete. But it's once-sterling relationship with its previous patron, Microsoft, has frayed significantly. This has essentially forced the company to go to SoftBank (yes, that SoftBank) for additional capital.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-4-161689970" target="_self" rel="">4</a></span><span> </span></p><p><span>It's true that OpenAI managed to get $40bn committed, and it's also true that this is the largest amount of capital ever raised by a privately held company. But they're going against </span><em>Google</em><span>, one of the most valuable companies in the entire world, and extremely profitable to boot. That's a hell of a war chest to compete with.</span></p><p><span>In that light, the decision to spend 3 out of 40 of those billions is even harder to rationalize.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-5-161689970" target="_self" rel="">5</a></span><span> Even worse, it's not yet clear OpenAI actually </span><em>has </em><span>$40bn to spend — so far they've only got $10bn actually lined up, with the rest being held by SoftBank contingent on OpenAI actually becoming a for-profit company by the end of the year.</span></p><p>It seems pretty obvious that Windsurf will not help OpenAI get more compute. Maybe Windsurf is providing OpenAI access to data? There's certainly some possibility that this is the case — though it makes me wonder just how bad OpenAI's relationship with Microsoft has gotten if they no longer have access to GitHub, which surely dwarfs any amount of code that Windsurf could provide.</p><p><span>The other possibility is that this is entirely a long term distribution play, akin to Facebook buying WhatsApp or Instagram. People criticized those deals for being overpriced too. OpenAI may think that Windsurf will be a crown jewel in how people access GPT models. There's some sense in this — OpenAI has also announced a social media project, likely also an attempt at maintaining lines to unique data sources while providing more native ways to improve distribution and "</span><a href="https://gwern.net/complement" rel="">commoditize their complement</a><span>".</span></p><p><span>But the issue that they will inevitably run into with Windsurf is that GPT just isn't the best in class for programming. Everyone who's using Windsurf is almost definitely using Claude or Gemini. Even though the "GPT wrapper" term was always meant as an insult, it is in practice a huge table stakes feature to be able to wrap around many different LLM providers. That flexibility is what allows a company like Windsurf to ride the machine learning wave, buoyed along by everyone else's investments. Cursor really only took off when Claude suddenly got really good at programming, after all. If Windsurf ends up being tied exclusively to GPT, many of its users may leave the platform simply because it is now a worse platform. But if there isn't any vendor lock in, we're back to square one — what is the </span><em>point</em><span>?</span></p><p>Personally, I don't get it. Maybe someone smarter than I am (or more connected than I am) can help me figure it out. But for now, I'm chalking this particular check size as a symptom of the AI market being way too hot right now.</p><p>The other quiet news of the last few days is the dawning realization of just how quiet it has been. The last two weeks saw the release of 3 new OpenAI models — o3, o4-mini, and GPT 4.1 — as well as the new Llama 4 model family from Meta and Grok-3 from Grok. And…nothing. It's just crickets. In past months, a release calendar like this would have had headlines blazing. The hype train should be chugging at ridiculous speeds. But compared to what I'd expect, there's nothing.</p><p>The reason is obvious: Google is still in the lead. Take a look at these two charts.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png" width="1456" height="529" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7e34249c-afab-4751-87ae-0932f234e111_1584x575.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:529,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:137731,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://theahura.substack.com/i/161689970?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e34249c-afab-4751-87ae-0932f234e111_1584x575.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg" width="1456" height="1067" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1067,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Imagen&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="Imagen" title="Imagen" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c4c230-9fa1-4333-8332-4e98419ba870_3080x2258.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Even though this chart is only two weeks old, it is already out of date. </figcaption></figure></div><p>The former is the current state of the LMSYS chatbot arena; the latter maps chatbot arena performance against price. The over under? There's no headlines because there's nothing to write about. "OpenAI takes second place" no one cares!</p><p><span>It’s still too early to write about ‘general consensus’ since the OpenAI models were released only a few days ago. And to their credit, those models </span><em>do </em><span>top many of the LLM benchmarks.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-6-161689970" target="_self" rel="">6</a></span><span> But so far, the </span><a href="https://www.reddit.com/r/ChatGPTCoding/comments/1k10ehv/openais_o3_and_o4mini_just_dethroned_gemini_25_pro/" rel="">reception has been extremely muted</a><span>, with many saying something like:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png" width="867" height="195" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:195,&quot;width&quot;:867,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37315,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://theahura.substack.com/i/161689970?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3874ceec-fd23-44dc-99cf-34c24c89851e_867x195.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Even though some of the new OpenAI models are quite powerful, they are simply too expensive and too slow for not enough extra juice. </p><p><span>I've already </span><a href="https://theahura.substack.com/p/tech-things-gemini-25-and-the-bull" rel="">written extensively about Google's Gemini 2.5 release</a><span>, which quickly became the go-to model for just about everything. What I didn't originally clock was just how much Google had shored up its model offerings all over the price/performance curve. Put bluntly: at every price point, the best model is a Google model.</span></p><p><span>That's not all. I mentioned rumors that Google has disallowed new publications; that is now confirmed as of </span><a href="https://arstechnica.com/ai/2025/04/deepmind-is-holding-back-release-of-ai-research-to-give-google-an-edge/" rel="">earlier this month</a><span>:</span></p><blockquote><p>Among the changes in the company’s publication policies is a six-month embargo before “strategic” papers related to generative AI are released. Researchers also often need to convince several staff members of the merits of publication, said two people with knowledge of the matter.</p></blockquote><p><span>Google has also apparently started offering </span><a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/google-accused-of-paying-employees-to-do-nothing-for-up-to-a-year-to-stifle-ai-talent-migration" rel="">extremely generous non-compete deals</a><span> to researchers, preferring to keep them on payroll doing nothing than have them go to competitors and leak secrets:</span></p><blockquote><p><a href="https://www.tomshardware.com/tag/google" rel="">Google</a><span> is making use of aggressive noncompete clauses and extended notice periods, contends former GoogDeepMinder Nando de Freitas in a recent post on X. In some cases, Google DeepMind’s employment contracts may lock an AI developer into doing nothing for as long as a year, notes </span><a href="https://www.businessinsider.com/google-deepmind-ai-talent-war-aggressive-noncompetes-2025-4" rel="">Business Insider</a><span>, to prevent its AI talent from moving to competing firms. That’s a long time away from working on the cutting edge in the rapidly developing world of AI.</span></p></blockquote><p>And finally, Google has continued to release and improve its TPU offerings on GCP, giving them yet another method to profit off the back of the AI boom — even if they don't win on the model, they can win by providing the underlying hardware.</p><p><span>With almost no fanfare, we all just woke up one day to a Google-dominated AI landscape. I have been </span><a href="https://theahura.substack.com/p/tech-things-eu-ai-act-biden-admin?utm_source=publication-search" rel="">critical of Sundar in the past</a><span>, but I have to hand it to him — sometimes the showmanship really is just a distraction from executing a slow but precise strategy.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-7-161689970" target="_self" rel="">7</a></span><span> Google is clearly now on a war footing. They are relentlessly poaching employees while trying to close up their shop as much as possible. The AI industry as a whole owes more to Google than any other organization. It's unclear how many other players in that industry will survive when cut off from Google's research. It's also unclear how much this will last in the face of a continuing DOJ antitrust suit. More on that in a different article, though.</span></p><p><span>One last thought. I've always been a staunch defender of capitalism and free markets, even though that's historically been an unpopular opinion in my particular social circle. Watching the LLM market, I can't help but feel extremely vindicated. Over the last 5 years, the cost per token has been driven down relentlessly even as model quality has skyrocketed. The brutal and bruising competition between the tech giants has left nothing but riches for the average consumer. There's an alternative world where all of this is priced so high that only the wealthiest businesses can justify a "GPT license", or where the government ends up keeping all the best AI technology for themselves. That world would objectively suck — not only would most people not be able to access the technology, there would also be significantly less interest in or ability to innovate. Just look at Google, which has finally risen like a beast from slumber to show the world what it means to innovate once more.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-8-161689970" target="_self" rel="">8</a></span><span> </span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-9-161689970" target="_self" rel="">9</a></span></p><p>Since we've been talking about things that didn't happen, I want to talk about one last notable absence: where the hell is Apple?</p><p><a href="https://theahura.substack.com/p/tech-things-gpt-pro-and-the-state" rel="">Something</a><span> </span><a href="https://theahura.substack.com/p/tech-things-deepseek-r1-and-the-arrival?utm_source=publication-search" rel="">I've</a><span> </span><a href="https://theahura.substack.com/p/tech-things-deepseek-but-make-it?utm_source=publication-search" rel="">said</a><span> </span><a href="https://theahura.substack.com/p/tech-things-gemini-25-and-the-bull?utm_source=publication-search" rel="">repeatedly</a><span> is that the LLM market has strong winner-take-all effects, and players in the market are heavily dependent on access to scientists, compute, and data. Apple is an extraordinarily wealthy company, so they have no problem getting access to scientists. But it seems like they have had a ton of issues on both of the latter two categories.</span></p><p><span>On the compute side, it seems like Apple sorta own goaled themselves? From the </span><a href="https://www.nytimes.com/2025/04/11/technology/apple-issues-trump-tariffs.html" rel="">NYT</a><span>:</span></p><blockquote><p>The A.I. stumble was set in motion in early 2023. Mr. Giannandrea, who was overseeing the effort, sought approval from the company’s chief executive, Tim Cook, to buy more A.I. chips, known as graphics processing units, or GPUs, five people with knowledge of the request said. The chips, which can perform hundreds of computations at the same time, are critical to building the neural networks of A.I. systems, like chatbots, that can answer questions or write software code.</p><p>At the time, Apple’s data centers had about 50,000 GPUs that were more than five years old — far fewer than the hundreds of thousands of chips being bought at the time by A.I. leaders like Microsoft, Amazon, Google and Meta, these people said.</p><p>Mr. Cook approved a plan to double the team’s chip budget, but Apple’s finance chief, Luca Maestri, reduced the increase to less than half that, the people said. Mr. Maestri encouraged the team to make the chips they had more efficient.</p><p>The lack of GPUs meant the team developing A.I. systems had to negotiate for data center computing power from its providers like Google and Amazon, two of the people said. The leading chips made by Nvidia were in such demand that Apple used alternative chips made by Google for some of its A.I. development.</p></blockquote><p><span>Well, that at least explains why they haven’t been putting out any decent models. Anecdotally, Apple obviously has data centers, but they aren't a cloud provider like Google/Microsoft/Amazon, which at various points have powered DeepMind/OpenAI/Anthropic directly. So Apple is starting way behind on the whole chip thing. Maybe it makes some kind of strategic sense to try and double down on their own unique chip capacity — maybe try to do what Google has done with TPUs — but that's really being extremely generous. The more obvious answer is the simple one: Apple cheaped out, and was penny wise pound foolish. As a result, the company that dominated the mobile wave is all but absent from the AI wave.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-10-161689970" href="https://theahura.substack.com/p/tech-things-openai-buys-windsurf#footnote-10-161689970" target="_self" rel="">10</a></span></p><p>On the data side, Apple definitely own goaled themselves. In an environment of data hoarders and open disregard for information safety, Apple struck out as an ardent defender of user privacy. They made a brand out of it! They ran ads on it!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e29cc1-c7dd-45d1-b4ec-385969d0ba8c_1600x900.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>That all made sense a few years ago, when the data itself was more questionably useful and Apple had full control of the hardware stack. Apple was able to poke fun at Google while </span><a href="https://www.businessinsider.com/facebook-blames-apple-10-billion-loss-ad-privacy-warning-2022-2" rel="">giving Meta a pretty serious black eye</a><span> over their ads policy.</span></p><p>But now, data is almost literally fuel for deep learning models. Worse, there's basically no way to avoid leaking data through the model! People have consistently been able to get models to directly reproduce training data! Google has more or less avoided using any training data because they can, they have the whole Internet already indexed. Meta, xAI, OpenAI, and Anthropic all train on public data — the former two from public posts on their social media platforms, and all four from extremely questionable flouting of copyright law. </p><p><span>Meanwhile, Apple is stuck with the same problem Google had </span><a href="https://theahura.substack.com/p/tech-things-openai-is-an-unaligned-590?utm_source=publication-search" rel="">when they got rid of their "Don't be evil" motto</a><span>. </span></p><blockquote><p><span>"Don't be evil" was a lot of things, and there were a lot of disagreeing interpretations about what it meant. One thing that no one disagreed about: it was hard to get rid of. Execs at Google ended up regretting the "Don't be evil" motto, because no matter what Google did they would get raked over the coals for doing it. "I thought you said you </span><em>wouldn't be evil</em><span>", internet commenters would snidely say. They even </span><a href="https://en.wikipedia.org/wiki/Don%27t_be_evil#Lawsuit" rel="">got sued over it</a><span>!</span></p></blockquote><p>Apple is in a similar boat. Either they use the user data they have and risk serious brand damage that the rest of FAANG is sure to capitalize on, or they handicap themselves in the AI race. Which, really, is less of a race and more of an all out brawl, one in which Apple is fighting with both hands behind its back.</p><p><span>So far, they've taken the "handicap" approach. They've tried to pay their way out of the data access problem by straight up </span><a href="https://www.inc.com/kit-eaton/apple-signs-deal-for-ai-training-data-from-image-service-shutterstock.html" rel="">buying the copyright licenses for data</a><span> they want to train on, but, come on, it's just not anywhere near enough training data.</span></p><p><span>The worst case scenario for Apple is they decide to use user data </span><em>late</em><span>. In that setting, Apple incurs the brand risk while also being miles behind everyone else. That increasingly seems like what will happen, though, because I just can't imagine Apple actually sitting the entire AI race out.</span></p><p>So yeah. All in all, a pretty quiet few weeks for AI.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Joy of Linux Theming in the Age of Bootable Containers (137 pts)]]></title>
            <link>https://blues.win/posts/joy-of-linux-theming/</link>
            <guid>43743784</guid>
            <pubDate>Sun, 20 Apr 2025 13:56:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blues.win/posts/joy-of-linux-theming/">https://blues.win/posts/joy-of-linux-theming/</a>, See on <a href="https://news.ycombinator.com/item?id=43743784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Having spent a couple of decades in the Linux world, I have always had an interest in Linux desktop environments and how they are themed.
I would often come across a post on <a href="https://reddit.com/r/unixporn">/r/unixporn</a> that inspired me to try to customize the look and feel of my desktop environment. So I would install Xfce, LXQt or Sway and try to recreate components that I like from other users or create my own. I would end up installing different kinds of panels, plugins, docks and launchers as well as random themes, fonts and sounds.</p>
<p>A portion of this process would be documented, initially as random shell scripts in my home directory, before graduating to Ansible playbooks – with a brief detour into Nix that I will not elaborate on. Some of the customizations would live in my home directory, but there were often system-wide modifications to <code>/usr</code> required.</p>
<p>Eventually, the constant churn and randomly broken desktop components such as a panel that mysteriously vanished or a non-functional dock led me to stick with the stock configuration of whatever desktop environment I was using at the time.
The major desktop environments, <a href="https://kde.org/">KDE Plasma</a> and <a href="https://www.gnome.org/">GNOME</a>, are both well polished and great out of the box. The desktop experience that they have delivered over the last few years has contributed to desktop Linux being the best it has ever been, in my opinion.</p>
<p>But the itch to customize and tweak my desktop environment in fun and interesting ways is still there. Eventually, I was introduced to the concept of bootable containers.</p>
<h2 id="bootc-as-a-themers-playground">Bootc As A Themer’s Playground<a href="#bootc-as-a-themers-playground" arialabel="Anchor">⌗</a> </h2>
<p>The <a href="https://github.com/bootc-dev/bootc">bootc</a> project, originally developed by <a href="https://www.redhat.com/">Red Hat</a> but now part of the <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>, is a core component of the <a href="https://containers.github.io/bootable/">Bootable Containers Initiative</a>. Conceptually, it allows you to define your operating system as a Containerfile:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>FROM quay.io/fedora/fedora-bootc:42
</span></span><span><span>RUN dnf install -y my-custom-theme my-custom-fonts my-custom-panel
</span></span></code></pre></div><p>Once written, you can build the container locally and instruct your bootc-aware system to use the new image.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>sudo podman build -f Containerfile -t my-fedora
</span></span><span><span>sudo bootc switch --transport containers-storage localhost/my-fedora:latest
</span></span></code></pre></div><p>After a reboot, the system’s deployment is defined by the new container.</p>
<p>With Fedora Atomic systems, <code>/usr</code> is mounted read-only and because your operating system is defined by an OCI container, it is incredibly easy to revert to a previous tag of that container. I can easily create a throwaway container where I test out ideas for a theme, reboot into the new deployment and test it out on bare-metal. I can roll back to the previous container if necessary or create a new container with follow-up modifications.</p>
<p>One downside is that this reboot-heavy workflow can obviously cause some friction. This can be mitigated somewhat by enabling “Development Mode” with <code>ostree admin unlock</code>, which creates a temporary writable overlayfs on top of <code>/usr</code>. I often find myself using this mode to temporarily install some package, theme or configuration in <code>/usr</code>. After verifying that it works as expected, I can add that functionality to the Containerfile. If it doesn’t work, I can either reboot to get rid of the changes, or (more likely) just forget about the change and it will remove itself whenever I reboot normally. The lack of cruft that accumulates over time in a typical Linux installation is one of the major advantages of this approach.</p>
<p>Of course, there are other ways to achieve similar results without using a bootable container model:</p>
<ul>
<li>You can write shell scripts or Ansible playbooks and hope that they accurately capture changes to the system so that they can be reliably undone. Typically, configuration drift that occurs as software gets updated is not addressed.</li>
<li>With <a href="https://www.freedesktop.org/software/systemd/man/latest/systemd-sysext.html">systemd-sysext(8)</a>, you can create a squashfs image of a filesystem containing your theming changes for <code>/usr</code> and overlay it on top of the root filesystem. An ecosystem around how these images should be created, maintained, deployed and updated has yet to emerge.</li>
<li>You can inscribe your custom theming as runes in an arcane and inscrutable functional language known only to the elders as N̸̘̏͑̕͝į̸̈́̂x̸͙̑̅̒.</li>
</ul>
<p>In my opinion, none of the alternatives provide the same level of flexibility and tooling support as writing a Dockerfile, nor can they achieve bootc’s level of safety and reliability by making it extremely difficult to bork your <code>/usr</code> directory. And if the <code>/usr</code> directory somehow gets borked anyway, rolling back to the previously deployed container is just a reboot away.</p>
<h2 id="what-is-a-distro">What Is A Distro?<a href="#what-is-a-distro" arialabel="Anchor">⌗</a> </h2>

<p>A few weeks ago, an OCI image based on Fedora Xfce Atomic that I made called <a href="https://github.com/winblues/blue95">Blue95</a> was posted to <a href="https://news.ycombinator.com/item?id=43524937">Hacker News</a>. For the most part, the reception was warm but there were some interesting questions that were raised, such as:</p>
<blockquote>
<p>Is it really necessary to spin up an entirely new distro for an XFCE+GTK theme?</p></blockquote>
<p>The original poster made me question the nature of the project I created: is it a distro? In the age of bootc, the distinction between what is considered a Linux distribution and what is simply a Containerfile + CI/CD is, in my opinion, murky at best. Historically, the barrier to entry for creating what has traditionally been called a Linux distribution was orders of magnitude higher than creating and publishing an OCI container. My nights-and-weekends side project of building a bootable container is a far cry from what I imagine a Linux distribution to be.</p>
<p><a href="https://blues.win/95">Blue95</a> is a collection of scripts and YAML files cobbled together to produce a Containerfile, which is built via GitHub Actions and published to the GitHub Container Registry. Which part of this process elevates the project to the status of a Linux distribution? What set of <code>RUN</code> commands in the Containerfile take the project from being merely a Fedora-based OCI image to a full-blown Linux distribution?</p>
<p>Popular bootc-based projects like <a href="https://projectbluefin.io/">Project Bluefin</a> and <a href="https://bazzite.gg/">Bazzite</a> are often labeled as Linux distributions, much to the consternation of their creators and maintainers. But if you’ve ever used Bazzite and booted directly into Steam’s Big Picture Mode, you might agree that it does indeed feel like its own Linux distribution; it is quite distinct from its twin bases of <a href="https://fedoraproject.org/atomic-desktops/silverblue/">Fedora Silverblue</a> and <a href="https://fedoraproject.org/atomic-desktops/kinoite/">Fedora Kinoite</a>.</p>
<p>Maybe the imprecision of the term “Linux distribution” is most evident when arguments arise over what is and isn’t a distro. It has always been problematic to define a distribution as simply a curated collection of software plus a Linux kernel -— but that definition is now especially lacking, as it could just as easily describe any Containerfile for a bootable container. Ultimately, “I know it when I see it” may be the best we can do when deciding whether a project deserves the label Linux distribution or not.</p>
<p>Finally, to address the original question about the necessity of spinning up a new distro just for a theme: creating a bootable container with a consistent visual design and curated set of applications can bring a bit of <strong>joy and levity</strong>. At this moment, my laptop is booted from a container that I have created myself. The operating system being used to draft these words is the product of my own artistic and creative expression – built on the work of countless other human beings. And that brings me joy.</p>
<hr>
<figure>
<a href="https://blues.win/images/ty4reading.png"><img src="https://blues.win/images/ty4reading.png"></a>
</figure>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemma 3 QAT Models: Bringing AI to Consumer GPUs (500 pts)]]></title>
            <link>https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/</link>
            <guid>43743337</guid>
            <pubDate>Sun, 20 Apr 2025 12:22:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/">https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/</a>, See on <a href="https://news.ycombinator.com/item?id=43743337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
      
    

    

    

    

    
    <div>
          

<div>
    <p data-block-key="sisye">Last month, we launched Gemma 3, our latest generation of open models. Delivering state-of-the-art performance, Gemma 3 quickly established itself as a leading model capable of running on a single high-end GPU like the NVIDIA H100 using its native BFloat16 (BF16) precision.</p><p data-block-key="4impe">To make Gemma 3 even more accessible, we are announcing new versions optimized with Quantization-Aware Training (QAT) that dramatically reduces memory requirements while maintaining high quality. This enables you to run powerful models like Gemma 3 27B locally on consumer-grade GPUs like the NVIDIA RTX 3090.</p>
</div>   

<div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3QuantizedChart_RD1_01_1_qlGnyVc.original.png" alt="Chatbot Arena Elo Score - Gemma 3 QAT"></p><p>
                    This chart ranks AI models by Chatbot Arena Elo scores; higher scores (top numbers) indicate greater user preference. Dots show estimated NVIDIA H100 GPU requirements.
                </p>
            
        
    </div>
  <div>
    <h2 data-block-key="sisye">Understanding performance, precision, and quantization</h2><p data-block-key="2a2jr">The chart above shows the performance (Elo score) of recently released large language models. Higher bars mean better performance in comparisons as rated by humans viewing side-by-side responses from two anonymous models. Below each bar, we indicate the estimated number of NVIDIA H100 GPUs needed to run that model using the BF16 data type.</p><p data-block-key="ae0co"><b><br>Why BFloat16 for this comparison?</b> BF16 is a common numerical format used during inference of many large models. It means that the model parameters are represented with 16 bits of precision. Using BF16 for all models helps us to make an apples-to-apples comparison of models in a common inference setup. This allows us to compare the inherent capabilities of the models themselves, removing variables like different hardware or optimization techniques like quantization, which we'll discuss next.</p><p data-block-key="3q45i">It's important to note that while this chart uses BF16 for a fair comparison, deploying the very largest models often involves using lower-precision formats like FP8 as a practical necessity to reduce immense hardware requirements (like the number of GPUs), potentially accepting a performance trade-off for feasibility.</p><h2 data-block-key="8r8jc"><b><br></b>The Need for Accessibility</h2><p data-block-key="dkjr0">While top performance on high-end hardware is great for cloud deployments and research, we heard you loud and clear: you want the power of Gemma 3 on the hardware you already own. We're committed to making powerful AI accessible, and that means enabling efficient performance on the consumer-grade GPUs found in desktops, laptops, and even phones.</p><h2 data-block-key="950c"><b><br></b>Performance Meets Accessibility with Quantization-Aware Training in Gemma 3</h2><p data-block-key="158md">This is where quantization comes in. In AI models, quantization reduces the precision of the numbers (the model's parameters) it stores and uses to calculate responses. Think of quantization like compressing an image by reducing the number of colors it uses. Instead of using 16 bits per number (BFloat16), we can use fewer bits, like 8 (int8) or even 4 (int4).</p><p data-block-key="3a7o0">Using int4 means each number is represented using only 4 bits – a 4x reduction in data size compared to BF16. Quantization can often lead to performance degradation, so we’re excited to release Gemma 3 models that are robust to quantization. We released several quantized variants for each Gemma 3 model to enable inference with your favorite inference engine, such as Q4_0 (a common quantization format) for Ollama, llama.cpp, and MLX.</p><p data-block-key="epsbi"><b><br>How do we maintain quality?</b> We use QAT. Instead of just quantizing the model after it's fully trained, QAT incorporates the quantization process during training. QAT simulates low-precision operations during training to allow quantization with less degradation afterwards for smaller, faster models while maintaining accuracy. Diving deeper, we applied QAT on ~5,000 steps using probabilities from the non-quantized checkpoint as targets. We reduce the perplexity drop by 54% (using llama.cpp perplexity evaluation) when quantizing down to Q4_0.</p><h2 data-block-key="eatdo"><b><br></b>See the Difference: Massive VRAM Savings</h2><p data-block-key="9f9so">The impact of int4 quantization is dramatic. Look at the VRAM (GPU memory) required just to load the model weights:</p><ul><li data-block-key="41cf1"><b>Gemma 3 27B:</b> Drops from 54 GB (BF16) to just <b>14.1 GB</b> (int4)</li></ul><ul><li data-block-key="5uebr"><b>Gemma 3 12B:</b> Shrinks from 24 GB (BF16) to only <b>6.6 GB</b> (int4)</li></ul><ul><li data-block-key="9d985"><b>Gemma 3 4B:</b> Reduces from 8 GB (BF16) to a lean <b>2.6 GB</b> (int4)</li></ul><ul><li data-block-key="bf7p"><b>Gemma 3 1B:</b> Goes from 2 GB (BF16) down to a tiny <b>0.5 GB</b> (int4)</li></ul>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3QuantizedChart_RD1_02.original.png" alt="Comparison chart of model weights showing VRAM required to load">
        
        
    </p>
</div>
  <div>
    <blockquote data-block-key="7ui9z"><b><sup>Note:</sup></b> <i><sup>This figure only represents the VRAM required to load the model weights. Running the model also requires additional VRAM for the KV cache, which stores information about the ongoing conversation and depends on the context length</sup></i></blockquote><h2 data-block-key="e1hmg"><b><br></b>Run Gemma 3 on Your Device</h2><p data-block-key="4jdc3">These dramatic reductions unlock the ability to run larger, powerful models on widely available consumer hardware:</p><ul><li data-block-key="bqsl5"><b>Gemma 3 27B (int4):</b> Now fits comfortably on a single desktop NVIDIA RTX 3090 (24GB VRAM) or similar card, allowing you to run our largest Gemma 3 variant locally.</li></ul><ul><li data-block-key="c4adc"><b>Gemma 3 12B (int4):</b> Runs efficiently on laptop GPUs like the NVIDIA RTX 4060 Laptop GPU (8GB VRAM), bringing powerful AI capabilities to portable machines.</li></ul><ul><li data-block-key="be3pr"><b>Smaller Models (4B, 1B):</b> Offer even greater accessibility for systems with more constrained resources, including phones and <a href="https://youtu.be/lgsD_wSZ0hI?si=pyQj23bOxNPLrxtL&amp;t=102">toasters</a> (if you have a good one).</li></ul><h2 data-block-key="7c8ds"><b><br></b>Easy Integration with Popular Tools</h2><p data-block-key="2324e">We want you to be able to use these models easily within your preferred workflow. Our official int4 and Q4_0 unquantized QAT models are available on Hugging Face and Kaggle. We’ve partnered with popular developer tools that enable seamlessly trying out the QAT-based quantized checkpoints:</p><ul><li data-block-key="avkt"><a href="https://ollama.com/library/gemma3"><b>Ollama</b></a><b>:</b> Get running quickly – all our Gemma 3 QAT models are natively supported starting today with a simple command.</li></ul><ul><li data-block-key="6sp3o"><a href="https://lmstudio.ai/model/gemma-3-12b-it-qat"><b>LM Studio</b></a><b>:</b> Easily download and run Gemma 3 QAT models on your desktop via its user-friendly interface.</li></ul><ul><li data-block-key="69oug"><a href="https://huggingface.co/collections/mlx-community/gemma-3-qat-68002674cd5afc6f9022a0ae"><b>MLX</b></a><b>:</b> Leverage MLX for efficient, optimized inference of Gemma 3 QAT models on Apple Silicon.</li></ul><ul><li data-block-key="19s6q"><a href="https://www.kaggle.com/models/google/gemma-3/gemmaCpp"><b>Gemma.cpp</b></a><b>:</b> Use our dedicated C++ implementation for highly efficient inference directly on the CPU.</li></ul><ul><li data-block-key="f05gl"><a href="https://huggingface.co/collections/google/gemma-3-qat-67ee61ccacbf2be4195c265b"><b>llama.cpp</b></a><b>:</b> Integrate easily into existing workflows thanks to native support for our GGUF-formatted QAT models.</li></ul><h2 data-block-key="c5073"><b><br></b>More Quantizations in the Gemmaverse</h2><p data-block-key="74vnv">Our official Quantization Aware Trained (QAT) models provide a high-quality baseline, but the vibrant <a href="https://ai.google.dev/gemma/gemmaverse">Gemmaverse</a> offers many alternatives. These often use Post-Training Quantization (PTQ), with significant contributions from members such as <a href="https://huggingface.co/bartowski/google_gemma-3-27b-it-GGUF">Bartowski</a>, <a href="https://huggingface.co/collections/unsloth/gemma-3-67d12b7e8816ec6efa7e4e5b">Unsloth</a>, and <a href="https://huggingface.co/collections/ggml-org/gemma-3-67d126315ac810df1ad9e913">GGML</a> readily available on Hugging Face. Exploring these community options provides a wider spectrum of size, speed, and quality trade-offs to fit specific needs.</p><h2 data-block-key="fnsl0"><b><br></b>Get Started Today</h2><p data-block-key="fdu54">Bringing state-of-the-art AI performance to accessible hardware is a key step in democratizing AI development. With Gemma 3 models, optimized through QAT, you can now leverage cutting-edge capabilities on your own desktop or laptop.</p><p data-block-key="179dk">Explore the quantized models and start building:</p><ul><li data-block-key="6uj07">Use on your PC with <a href="https://ollama.com/library/gemma3">Ollama</a></li></ul><ul><li data-block-key="741fu">Find the Models on <a href="https://huggingface.co/collections/google/gemma-3-qat-67ee61ccacbf2be4195c265b">Hugging Face</a> &amp; <a href="https://www.kaggle.com/models/google/gemma-3/transformers">Kaggle</a></li></ul><ul><li data-block-key="6069i">Run on your phone with <a href="https://developers.googleblog.com/en/gemma-3-on-mobile-and-web-with-google-ai-edge/">Google AI Edge</a></li></ul><p data-block-key="4j3l0">We can't wait to see what you build with Gemma 3 running locally!</p>
</div> 
      </div>
    

    

    
    
    
  </div></div>]]></description>
        </item>
    </channel>
</rss>