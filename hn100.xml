<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 09 Nov 2023 05:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[After a $1.8B verdict, the clock is ticking on the 6% realtor commission (125 pts)]]></title>
            <link>https://www.cnn.com/2023/11/05/homes/nar-verdict-real-estate-commission-fee/index.html</link>
            <guid>38200117</guid>
            <pubDate>Thu, 09 Nov 2023 02:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/11/05/homes/nar-verdict-real-estate-commission-fee/index.html">https://www.cnn.com/2023/11/05/homes/nar-verdict-real-estate-commission-fee/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38200117">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clohq7457001l3b6if8w5fmzc@published" data-name="homes neighborhood aerial ca 2023 RESTRICTED" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6663333333333333" data-original-height="1999" data-original-width="3000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/231103173441-homes-neighborhood-aerial-ca-2023-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="An aerial view of home in Rialto, California, on March 18, 2023." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1999" width="3000"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Washington, DC</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj2znuo00053b6ib22i9i60@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Using a travel agent to buy a plane ticket&nbsp;or a stockbroker to trade equities seem like relics of the past. And yet, every day, people across America hire a real estate agent to help them sell a home. It’s one of the few industries that has been able to largely avoid the disruption that has helped consumers cut costs in the Internet age.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000b3b6ied87parx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      And that is largely because of the power of the National Association of Realtors, the largest professional organization in America and a significant lobbying group for the real estate industry.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000c3b6im0np6nrp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      But the verdict handed down in a Missouri court on Tuesday that found NAR and two brokerage firms, Homeservices of America and Keller Williams Realty, were liable for $1.8 billion in damages for conspiring to keep commissions artificially high,&nbsp;may mark the beginning of the end of how homes are bought and sold.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000d3b6i4471zt24@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Two other firms initially named in the suits brought by home sellers – <a href="https://news.remax.com/remax-llc-settlement-agreement" target="_blank">Re/Max</a> and <a href="https://www.prnewswire.com/news-releases/anywhere-announces-terms-of-nationwide-settlement-agreement-in-burnett-and-moehrl-antitrust-class-actions-301949468.html" target="_blank">Anywhere Real estate</a>, formerly known as Realogy, which is the parent company of Coldwell Banker, Century 21, Sotheby’s International Realty and Corcoran — settled out of court for a combined $140 million. As a term of the settlement, they each announced a commitment to make changes in their business practices — including not requiring agents to be members of NAR.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000e3b6iwxxdmjny@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      While state governments license real estate agents, NAR has an extensive code of ethics it expects members to adhere to.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000f3b6i07ik0k5k@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      NAR and the brokerages have vowed to appeal the verdict, which means real estate commissions aren’t going anywhere immediately.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000g3b6ichqtcwbs@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      NAR has been fighting off US antitrust officials and litigation for years regarding anti-competitive practices and this verdict is the association’s biggest setback yet.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k00000h3b6i7bstpb4l@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      This verdict is just from one of several&nbsp;lawsuits currently filed against NAR, which is also facing scrutiny from the US Department of Justice.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000i3b6iwnvb9vmf@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      NAR has already faced a difficult year, setting aside the verdict and the troubled housing market.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000j3b6i1z9cadia@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In August, the NAR president, a member agent named Kenny Parcell,<a href="https://www.cnn.com/2023/08/29/homes/nar-president-resigns/index.html"> resigned amid sexual harassment allegations</a>. Last month <a href="https://www.redfin.com/news/redfin-is-leaving-nar/" target="_blank">Redfin, an internet real estate company, left the association</a>.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj57ah500033b6igh14zdyq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      On the commissions, NAR has said they will appeal the verdict and that the issue won’t be resolved for years.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000k3b6iabnl66no@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “This matter is not close to being final as we will appeal the jury’s verdict,” said Mantill Williams, NAR vice president of communications. “In the interim, we will ask the court to reduce the damages awarded by the jury.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000l3b6ijgiboaeh@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “This is not the end,” said Darryl Frost, spokesperson for Keller Williams.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000n3b6i2f9lj561@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The cornerstone of the plaintiff’s argument is that NAR is forcing homesellers to pay an inflated commission that is then split between their agent and the buyer’s agent.&nbsp;The homesellers argued commission sharing as a condition for access to the Multiple Listing Service was unfair and kept commissions artificially high.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000o3b6i4glbjvwx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Typically, when a home goes on the market for sale, the seller offers their broker a set commission. For decades, the commission has&nbsp;consistently been around 6% of the sale price, usually with a 3% split for the buyer’s and seller’s agent.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000q3b6i9zloguvw@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In a competitive market, the homesellers argue, the cost of the buyer’s agent’s commission would be paid not by the seller, but by the buyer who received the service. The sellers said that the buyers should be able to negotiate the fee with their agent, and that the sellers should not be on the hook for paying it.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000r3b6iliyvp2z9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      NAR and the other defendants argued in court that their commissions are always negotiable. They also said that the system of having the seller’s agent split the commission with the buyer’s agent allows buyers, who are already weighed down with expenses like a downpayment, closing costs, inspections and appraisals, to avoid the added expense of having to pay an agent as well.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000s3b6icozz7s7f@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Consumer advocates celebrated the verdict and hoped that plaintiffs would also receive their request for the judge to order changes to how commissions are structured in the industry.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000t3b6itcnvq1dj@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      While already large, the award could grow even more — to a total of $5 billion, depending on what the judge decides.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000u3b6i0ff6zy15@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The jury clearly saw the industry had restricted price competition to a point where it could ensure nearly uniform 5%-6% commissions, said Stephen Brobeck, a senior fellow at the Consumer Federation of America. Jurors made their decision quickly, he said, deliberating for only a few hours.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000v3b6iwgicpier@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “The extent of injunctive relief decided by the court will strongly influence whether a price competitive system develops that lowers consumer costs and increases quality of services,” Brobeck said. “We hope that the court will sever the ties between listing agent and buyer agent compensation, freeing sellers from the obligation and need to compensate buyer agents.”
  </p>

  <h2 data-editable="text" data-uri="cms.cnn.com/_components/subheader/instances/cloj3u5fb001a3b6igyf0n01f@published" data-component-name="subheader" id="impact-of-commissions-on-buyers-and-sellers" data-article-gutter="true">
    Impact of commissions on buyers and sellers
</h2>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000x3b6i2gcorkk9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Not much is expected to change in the near term with regard to how commissions are set, agents say.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000y3b6itao5b460@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The longer-term impact of the verdict may be that the pairing of buyer’s agent commission and seller’s agent commission will eventually be separated.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k01000z3b6iolilth6h@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Analysts from Keefe, Bruyette &amp; Woods, an investment banking firm, said in report released ahead of the verdict that the NAR litigation and related government action is likely to reshape the residential brokerage industry’s commission structure, by eliminating the buyer-broker commission rule, and eventually the practice of listing agents and sellers setting and paying buyer agent commissions.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k0100103b6ioezakcfk@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      And since the commission paid to an agent is typically baked into a home price, if they were reduced&nbsp;or were to become more negotiable, home prices could drop as well, they said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k0100113b6iksjfc8kw@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “Short term nothing changes,” said Jen Davis, a Keller Williams agent with Holt Homes Group, in Springfield, Missouri. “Commissions have always been negotiable. That will continue to be the case.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k0100123b6i69obvsne@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      But there could be unintended consequences if changes come about, she said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloj31k0100133b6i05cpnigs@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “There are buyers that aren’t going to know the steps to buy a home,” Davis said. “They have to pay for a down payment, closing costs, appraisals, inspections. If they also have to come up with money to pay for a buyer’s agent, some just won’t and they’ll get in over their heads or they won’t buy at all. Not having representation will make the market less inclusive.”
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zuckerberg personally rejected Meta's proposals to improve teen mental health (127 pts)]]></title>
            <link>https://www.cnn.com/2023/11/08/tech/meta-facebook-instagram-teen-safety/index.html</link>
            <guid>38199670</guid>
            <pubDate>Thu, 09 Nov 2023 01:17:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/11/08/tech/meta-facebook-instagram-teen-safety/index.html">https://www.cnn.com/2023/11/08/tech/meta-facebook-instagram-teen-safety/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38199670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cloq4c64800073b6h79betkhm@published" data-name="AP21050066648588.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6665" data-original-height="1333" data-original-width="2000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/ap21050066648588.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="In this Friday, Oct. 25, 2019, file photo, Facebook CEO Mark Zuckerberg speaks about &quot;News Tab&quot; at the Paley Center, in New York." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1333" width="2000"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq03von001k86p5g2waf8kd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Meta CEO Mark Zuckerberg has personally and repeatedly thwarted initiatives meant to improve the well-being of teens on Facebook and Instagram, at times directly overruling some of his most senior lieutenants, according to internal communications made public as part of an ongoing lawsuit against the company.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00013b6hf4hdiyde@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The newly unsealed communications in the lawsuit — filed <a href="https://www.mass.gov/news/ag-campbell-files-lawsuit-against-meta-instagram-for-unfair-and-deceptive-practices-that-harm-young-people" target="_blank">originally</a> by Massachusetts last month in a state court&nbsp;— allegedly show how Zuckerberg ignored or shut down top executives, including Instagram CEO Adam Mosseri and President of Global Affairs Nick Clegg, who had asked Zuckerberg to do more to protect the more than 30 million teens who use Instagram in the United States.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00023b6hudboud8g@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The disclosures highlight Zuckerberg’s sway over decisions at Meta that can affect billions of users. And they also shed light on tensions that have occasionally arisen between Zuckerberg and other Meta officials who have pushed to enhance user well-being.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00033b6h7402ksya@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Zuckerberg vetoed a 2019 proposal that would have disabled Instagram’s so-called “beauty filters,” a technology that digitally alters a user’s on-screen appearance and allegedly harms teens’ mental health by promoting unrealistic body image expectations, according to the unredacted version of the complaint filed this week by Massachusetts officials.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00043b6h072835z9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      After sitting on the proposal for months, Zuckerberg wrote to his deputies in April 2020 asserting that there was “demand” for the filters and that he had seen “no data” suggesting the filters were harmful, according to the complaint.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00053b6hpjjrc618@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Despite Zuckerberg’s conclusion, the proposal had enjoyed broad support, the lawsuit said, including from Mosseri; Instagram’s policy chief, Karina Newton; the head of Facebook, Fidji Simo, and Meta’s vice president of product design, Margaret Gould Stewart. (Simo and Mosseri had lamented at other times, according to the lawsuit, that a lack of investment in well-being initiatives meant Meta lacked “a roadmap of work that demonstrates we care about well-being.”)
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00063b6hqaby4ohv@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Stewart had first pitched the idea to disable beauty filters, citing recommendations by academics and Meta’s outside advisors, while Newton wrote an email adding it had strong backing from departments including “comms, marketing [and] policy,” the lawsuit said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00073b6h47kwpwl9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      But after Chief Technology Officer Andrew Bosworth brought the matter to Zuckerberg’s attention, Zuckerberg ultimately rejected the plan and the filters were allowed to remain, according to the complaint.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloqbhrdq00013b6hvk3y3s2d@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Stewart later wrote to Zuckerberg, fretting that his decision not to disable the filters could come back to haunt the company.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloqbio9v00033b6hataeed6a@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “I respect your call on this and I’ll support it,” Stewart wrote, according to a message cited in the complaint, “but want to just say for the record that I don’t think it’s the right call given the risks…. I just hope that years from now we will look back and feel good about the decision we made here.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00083b6hwpxye9t2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In response to the newly unsealed communications, Meta spokesman Andy Stone said such image filters are commonly used in the industry.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq521ck00013b6hetffleuc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “While filters exist across every major social platform and smartphone camera, Meta bans those that directly promote cosmetic surgery, changes in skin color or extreme weight loss,” Stone said. “We clearly note when a filter is being used and we work to proactively review effects against these rules before they go live.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq522un00033b6hpy57iihx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Stone added that Meta offers 30 tools to support teens and families, including the ability to set screen-time limits and the option to remove like counts from posts. (In the unredacted portions of the complaint, the Massachusetts suit alleges that the experiment to remove like counts from posts, codenamed Project Daisy, had originally been proposed as an app-wide default but was later downgraded to an opt-in feature that is rarely used.)
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq53mbv00053b6hxlr7zky7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      At the time of the original Massachusetts lawsuit, which was <a href="https://www.cnn.com/2023/10/24/tech/states-sue-instagram-parent-meta/index.html">one of several</a> filed on the same day by multiple state attorneys general, Meta had said it was committed “to providing teens with safe, positive experiences” and that it was disappointed that the states had not worked with Meta to develop industry standards.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku00093b6h1px4xe6b@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      A year after the beauty filter decision, in August 2021, Clegg pressed Zuckerberg to make “additional investment to strengthen our position on wellbeing across the company,” citing a staff recommendation to address issues of addiction, self-harm and bullying, according to the complaint. By this time, the company was just weeks away from being hit with Facebook whistleblower Frances Haugen’s bombshell <a href="https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739?mod=hp_lead_pos7" target="_blank">allegations</a> that Instagram knew its services could be harmful to teens.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000a3b6h9851e6q3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Haugen’s anonymous allegations in September jumpstarted intense scrutiny of Instagram. As Haugen <a href="https://www.cnn.com/2021/10/04/tech/facebook-whistleblower-frances-haugen-what-we-know/index.html">revealed her identity</a> in October, Mosseri wrote to another Meta product executive that same month in reference to Clegg’s proposal, the lawsuit said, saying he was “really worried” about well-being “but have made little progress.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000b3b6hr2fehv3n@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Zuckerberg allegedly remained silent on Clegg’s proposal throughout this time, prompting Clegg to reiterate his concerns to Zuckerberg in November. Finally, Zuckerberg appeared to respond through Meta’s chief financial officer, Susan Li, who “tersely respond[ed] that staffing was too ‘constrained’ to meet the request,” the lawsuit said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000c3b6hoztjx8ml@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Li responded similarly on Zuckerberg’s behalf after another product executive, David Ginsberg, emailed Zuckerberg in 2019 highlighting internal and external research suggesting that the company’s services were having a negative impact on people’s well-being. Ginsberg proposed hiring more engineers to build well-being tools to respond to addiction, social comparison and loneliness, but Li “responded that Meta’s leadership team declined to fund this initiative,” according to the complaint.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000d3b6hgvcijs01@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Zuckerberg’s rejection of opportunities to invest more heavily in well-being are reflective of his data-centric approach to management, said Arturo Bejar, the former Facebook engineering director and whistleblower who leveled his own allegations last week that Instagram has repeatedly ignored internal warnings about the app’s potential harms to teens.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000e3b6hctksefio@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Bejar, who <a href="https://www.cnn.com/2023/11/07/tech/meta-ignored-warnings-instagrams-harm/index.html">testified</a> to Instagram’s alleged risks before US lawmakers this week, told CNN on Wednesday he was not a part of the decision-making on beauty filters but had spoken to senior officials and others who had worked on internal research on the matter.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000f3b6h4cw8bt87@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “My understanding was that Mark needed causal data,” Bejar said, “for you to be able to demonstrate that because somebody was using a filter, that that would have an impact on how they perceive themselves.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042ku000g3b6h1ifxl0a4@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “All the people that I’ve talked to internally about this were like… Mark’s level of proof, in order to be able to take the work seriously and act on it, is too high,” Bejar added. “I think it’s an impossible standard to meet.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq561lf00073b6hb9jz6eav@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      On Wednesday, Stone added that Meta has a “robust central team overseeing youth well-being efforts across the company, and have built technology and teams that can move quickly and efficiently to implement new improvements across specific apps.”
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq5fsmo00093b6hxondleot@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Other newly unveiled allegations in the complaint accuse Meta of exploiting the psychology of adolescent brains and that Zuckerberg personally established goals for the company to increase the amount of time users spend on Instagram.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq5ou1g00063b6h5qzco6w2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      A 2020 internal presentation discussed in the complaint described how Instagram meets teenagers’ desire for “novelty seeking” with “a dopamine hit” through intermittent notifications about comments, follows and other bids for attention that can convey a sense of “approval and acceptance [that] are huge rewards for teens.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq5mubv00023b6hrue6shn3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Technology advocacy groups sharply criticized Zuckerberg on Wednesday after the internal communications came to light.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042kv000i3b6hh6l98vxq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “These unreacted documents prove that Mark Zuckerberg is not interested in protecting anyone’s privacy or safety. The rot goes all the way to the top,” said Sacha Haworth, executive director of the Tech Oversight Project.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042kv000j3b6han6z0cpi@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      And Zamaan Qureshi, co-chair of Design It For Us, a youth-led coalition pushing for product changes and regulation of social media, said the unsealed documents show that senior Meta executives sometimes confronted the same barriers that concerned rank-and-file employees did.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cloq042kv000k3b6hhem70cpa@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “Clegg’s comments follow a pattern and practice at Meta where employees repeatedly flagged under-investment in well-being tools, despite having the research,” Qureshi said. “Now we know not even senior leadership could get through to Zuckerberg.”
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omegle founder shuts down site forever? (800 pts)]]></title>
            <link>https://www.omegle.com/</link>
            <guid>38199355</guid>
            <pubDate>Thu, 09 Nov 2023 00:40:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.omegle.com/">https://www.omegle.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38199355">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><img src="https://www.omegle.com/static/gravestone.png" alt="" width="500" height="500"></p>
<p>“Of all tyrannies, a tyranny sincerely exercised for the good of its victims may be the most oppressive. It would be better to live under robber barons than under omnipotent moral busybodies. The robber baron's cruelty may sometimes sleep, his cupidity may at some point be satiated; but those who torment us for our own good will torment us without end for they do so with the approval of their own conscience.” — C.S. Lewis</p>
<p>“In the beginning the Universe was created. This has made a lot of people very angry and been widely regarded as a bad move.” — Douglas Adams</p>
<p>Dear strangers,</p>
<p>From the moment I discovered the Internet at a young age, it has been a magical place to me. Growing up in a small town, relatively isolated from the larger world, it was a revelation how much more there was to discover – how many interesting people and ideas the world had to offer.</p>
<p>As a young teenager, I couldn’t just waltz onto a college campus and tell a student: “Let’s debate moral philosophy!” I couldn’t walk up to a professor and say: “Tell me something interesting about microeconomics!” But online, I was able to meet those people, and have those conversations. I was also an avid Wikipedia editor; I contributed to open source software projects; and I often helped answer computer programming questions posed by people many years older than me.</p>
<p>In short, the Internet opened the door to a much larger, more diverse, and more vibrant world than I would have otherwise been able to experience; and enabled me to be an active participant in, and contributor to, that world. All of this helped me to learn, and to grow into a more well-rounded person.</p>
<p>Moreover, as a survivor of childhood rape, I was acutely aware that any time I interacted with someone in the physical world, I was risking my physical body. The Internet gave me a refuge from that fear. I was under no illusion that only good people used the Internet; but I knew that, if I said “no” to someone online, they couldn’t physically reach through the screen and hold a weapon to my head, or worse. I saw the miles of copper wires and fiber-optic cables between me and other people as a kind of shield – one that empowered me to be less isolated than my trauma and fear would have otherwise allowed.</p>
<p>I launched Omegle when I was 18 years old, and still living with my parents. It was meant to build on the things I loved about the Internet, while introducing a form of social spontaneity that I felt didn’t exist elsewhere. If the Internet is a manifestation of the “global village”, Omegle was meant to be a way of strolling down a street in that village, striking up conversations with the people you ran into along the way.</p>
<p>The premise was rather straightforward: when you used Omegle, it would randomly place you in a chat with someone else. These chats could be as long or as short as you chose. If you didn’t want to talk to a particular person, for whatever reason, you could simply end the chat and – if desired – move onto another chat with someone else. It was the idea of “meeting new people” distilled down to almost its platonic ideal.</p>
<p>Building on what I saw as the intrinsic safety benefits of the Internet, users were anonymous to each other by default. This made chats more self-contained, and made it less likely that a malicious person would be able to track someone else down off-site after their chat ended.</p>
<p>I didn’t really know what to expect when I launched Omegle. Would anyone even care about some Web site that an 18 year old kid made in his bedroom in his parents’ house in Vermont, with no marketing budget? But it became popular almost instantly after launch, and grew organically from there, reaching millions of daily users. I believe this had something to do with meeting new people being a basic human need, and with Omegle being among the best ways to fulfill that need. As the saying goes: “If you build a better mousetrap, the world will beat a path to your door.”</p>
<p>Over the years, people have used Omegle to explore foreign cultures; to get advice about their lives from impartial third parties; and to help alleviate feelings of loneliness and isolation. I’ve even heard stories of soulmates meeting on Omegle, and getting married. Those are only some of the highlights.</p>
<p>Unfortunately, there are also lowlights. Virtually every tool can be used for good or for evil, and that is especially true of communication tools, due to their innate flexibility. The telephone can be used to wish your grandmother “happy birthday”, but it can also be used to call in a bomb threat. There can be no honest accounting of Omegle without acknowledging that some people misused it, including to commit unspeakably heinous crimes.</p>
<p>I believe in a responsibility to be a “good Samaritan”, and to implement reasonable measures to fight crime and other misuse. That is exactly what Omegle did. In addition to the basic safety feature of anonymity, there was a great deal of moderation behind the scenes, including state-of-the-art AI operating in concert with a wonderful team of human moderators. Omegle punched above its weight in content moderation, and I’m proud of what we accomplished.</p>
<p>Omegle’s moderation even had a positive impact beyond the site. Omegle worked with law enforcement agencies, and the National Center for Missing and Exploited Children, to help put evildoers in prison where they belong. There are “people” rotting behind bars right now thanks in part to evidence that Omegle proactively collected against them, and tipped the authorities off to.</p>
<p>All that said, the fight against crime isn’t one that can ever truly be won. It’s a never-ending battle that must be fought and re-fought every day; and even if you do the very best job it is possible for you to do, you may make a sizable dent, but you won’t “win” in any absolute sense of that word. That’s heartbreaking, but it’s also a basic lesson of criminology, and one that I think the vast majority of people understand on some level. Even superheroes, the fictional characters that our culture imbues with special powers as a form of wish fulfillment in the fight against crime, don’t succeed at eliminating crime altogether.</p>
<p>In recent years, it seems like the whole world has become more ornery. Maybe that has something to do with the pandemic, or with political disagreements. Whatever the reason, people have become faster to attack, and slower to recognize each other’s shared humanity. One aspect of this has been a constant barrage of attacks on communication services, Omegle included, based on the behavior of a malicious subset of users.</p>
<p>To an extent, it is reasonable to question the policies and practices of any place where crime has occurred. I have always welcomed constructive feedback; and indeed, Omegle implemented a number of improvements based on such feedback over the years. However, the recent attacks have felt anything but constructive. The only way to please these people is to stop offering the service. Sometimes they say so, explicitly and avowedly; other times, it can be inferred from their act of setting standards that are not humanly achievable. Either way, the net result is the same.</p>
<p>Omegle is the direct target of these attacks, but their ultimate victim is <em>you</em>: all of you out there who have used, or would have used, Omegle to improve your lives, and the lives of others. When they say Omegle shouldn’t exist, they are really saying that you shouldn’t be allowed to use it; that you shouldn’t be allowed to meet random new people online. That idea is anathema to the ideals I cherish – specifically, to the bedrock principle of a free society that, when restrictions are imposed to prevent crime, the burden of those restrictions must not be targeted at innocent victims or potential victims of crime.</p>
<p>Consider the idea that society ought to force women to dress modestly in order to prevent rape. One counter-argument is that rapists don’t really target women based on their clothing; but a more powerful counter-argument is that, irrespective of what rapists do, women’s rights should remain intact. If society robs women of their rights to bodily autonomy and self-expression based on the actions of rapists – even if it does so with the best intentions in the world – then society is practically doing the work of rapists for them.</p>
<p>Fear can be a valuable tool, guiding us away from danger. However, fear can also be a mental cage that keeps us from all of the things that make life worth living. Individuals and families must be allowed to strike the right balance for themselves, based on their own unique circumstances and needs. A world of mandatory fear is a world ruled by fear – a dark place indeed.</p>
<p>I’ve done my best to weather the attacks, with the interests of Omegle’s users – and the broader principle – in mind. If something as simple as meeting random new people is forbidden, what’s next? That is far and away removed from anything that could be considered a reasonable compromise of the principle I outlined. Analogies are a limited tool, but a physical-world analogy might be shutting down Central Park because crime occurs there – or perhaps more provocatively, destroying the universe because it contains evil. A healthy, free society cannot endure when we are collectively afraid of each other to this extent.</p>
<p>Unfortunately, what is right doesn’t always prevail. As much as I wish circumstances were different, the stress and expense of this fight – coupled with the existing stress and expense of operating Omegle, and fighting its misuse – are simply too much. Operating Omegle is no longer sustainable, financially nor psychologically. Frankly, I don’t want to have a heart attack in my 30s.</p>
<p>The battle for Omegle has been lost, but the war against the Internet rages on. Virtually every online communication service has been subject to the same kinds of attack as Omegle; and while some of them are much larger companies with much greater resources, they all have their breaking point somewhere. I worry that, unless the tide turns soon, the Internet I fell in love with may cease to exist, and in its place, we will have something closer to a souped-up version of TV – focused largely on passive consumption, with much less opportunity for active participation and genuine human connection. If that sounds like a bad idea to you, please consider donating to the <a href="https://supporters.eff.org/donate/join-eff">Electronic Frontier Foundation</a>, an organization that fights for your rights online.</p>
<p>From the bottom of my heart, thank you to everyone who used Omegle for positive purposes, and to everyone who contributed to the site’s success in any way. I’m so sorry I couldn’t keep fighting for you.</p>
<p>Sincerely,<br>
Leif K-Brooks<br>
Founder, Omegle.com LLC</p>
<p id="contactpoints">To contact Omegle, please visit <a href="https://www.omegle.com/static/contactpoints.html">here</a> for more information.</p>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft won't let you close OneDrive on Windows until you explain yourself (150 pts)]]></title>
            <link>https://www.theverge.com/2023/11/8/23952878/microsoft-onedrive-windows-close-app-notification</link>
            <guid>38197715</guid>
            <pubDate>Wed, 08 Nov 2023 21:59:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/8/23952878/microsoft-onedrive-windows-close-app-notification">https://www.theverge.com/2023/11/8/23952878/microsoft-onedrive-windows-close-app-notification</a>, See on <a href="https://news.ycombinator.com/item?id=38197715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Microsoft now wants you to explain exactly <em>why </em>you’re attempting to close its OneDrive for Windows app before it allows you to do so. <a href="https://www.neowin.net/news/microsoft-wont-let-you-close-onedrive-in-windows-without-you-explaining-it-first/"><em>Neowin </em>has spotted</a> that the latest update to OneDrive now includes an annoying dialog box that asks you to select the reason why you’re closing the app every single time you attempt to close OneDrive from the taskbar.</p><p>Closing OneDrive is already buried away and not a simple task, with Microsoft hiding it under a “pause syncing” option when you right-click on OneDrive in the taskbar. But now, the quit option is grayed out until you select a reason for quitting OneDrive from a drop-down box. Here are the options:</p><div><ul><li>I don’t want OneDrive running all the time</li><li>I don’t know what OneDrive is</li><li>I don’t use OneDrive</li><li>I’m trying to fix a problem with OneDrive</li><li>I’m trying to speed up my computer</li><li>I get too many notifications</li><li>Other</li></ul></div><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A screenshot of The OneDrive poll that appears when you try and close the app." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/376x266/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/384x271/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/415x293/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/480x339/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/540x382/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/640x452/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/750x530/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/828x585/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/1080x763/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/1200x848/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/1440x1018/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/1920x1357/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/2048x1448/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/2400x1696/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1020x721/2400x1696/filters:focal(510x361:511x362):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25069130/vmxrdll.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><p><figcaption><em>The OneDrive poll that appears when you try and close the app.</em></figcaption></p></div><p>You’ll need to select one to close OneDrive, but Microsoft hasn’t included a “go away and let me close the damn application” option, unfortunately.</p><p>Microsoft has been pushing OneDrive in Windows for years, with it taking over the Documents and Pictures libraries in Windows 11 by default to sync files to Microsoft’s cloud-powered storage. There are also a variety of prompts throughout Windows if you haven’t set up OneDrive, including one that appears when you change a Windows desktop wallpaper.</p><p>This new behavior follows years of Microsoft’s demanding Edge prompts that appear if you dare to download Chrome or change your default browser. Last month, <a href="https://www.theverge.com/23930960/microsoft-edge-google-chrome-poll-why-try-another-browser">Microsoft even thirstily started injecting a poll</a> into the download page of Chrome asking why people were downloading an alternative browser. Now, Microsoft wants to know why you’re closing OneDrive.</p><p>What’s next? Hopefully, Microsoft won’t start injecting a poll at shutdown demanding to know why I’m turning my PC off for the day.</p><p>If you want to avoid this latest OneDrive nonsense, then feel free to open Task Manager, search for Microsoft OneDrive, and end that task the old-school way.</p><p><em>Screenshots by Tom Warren / The Verge</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interesting Bugs Caught by ESLint's no-constant-binary-expression (180 pts)]]></title>
            <link>https://eslint.org/blog/2022/07/interesting-bugs-caught-by-no-constant-binary-expression/</link>
            <guid>38196644</guid>
            <pubDate>Wed, 08 Nov 2023 20:41:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eslint.org/blog/2022/07/interesting-bugs-caught-by-no-constant-binary-expression/">https://eslint.org/blog/2022/07/interesting-bugs-caught-by-no-constant-binary-expression/</a>, See on <a href="https://news.ycombinator.com/item?id=38196644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>In <a href="https://eslint.org/blog/2022/04/eslint-v8.14.0-released">ESLint v8.14.0</a> I contributed a new core rule called <a href="https://eslint.org/docs/rules/no-constant-binary-expression">no-constant-binary-expression</a> which has surprised me with the wide variety of subtle and interesting bugs it has been able to detect.</p>
<p>In this post I’ll explain what the rule does and share some examples of real bugs it has detected in popular open source projects such as Material UI, Webpack, VS Code, and Firefox as well as a few interesting bugs that it found internally at Meta. I hope these examples will convince you to try enabling the rule in the projects you work on!</p>
<h2 id="what-does-no-constant-binary-expression-do%3F" tabindex="-1">What does <code>no-constant-binary-expression</code> do?</h2>
<p>The rule checks for comparisons (<code>==</code>, <code>!==</code>, etc) where the outcome cannot vary at runtime, and logical expressions (<code>&amp;&amp;</code>, <code>??</code>, <code>||</code>) which will either <em>always</em> or <em>never</em> short-circuit.</p>
<p>For example:</p>
<ul>
<li><code>+x == null</code> will always be false, because <code>+</code> will coerce <code>x</code> into a number, and a number is never nullish.</li>
<li><code>{ ...foo } || DEFAULT</code> will never return <code>DEFAULT</code> because objects are always truthy.</li>
</ul>
<p>Both of these are examples of expressions that <em>look</em> like they can affect the way the program evaluates, but in reality, do not.</p>
<p>This rule originally started as just an attempt to detect unnecessary null checks. However, as I worked on it, I realized useless null checks were just a special case of a broader category: useless code. Eventually it clicked for me: developers don’t intend to write useless code, and code that does not match the developer’s intent is by definition a bug. Therefore, any useless code you can detect is a bug.</p>
<p>This realization was confirmed for me when I ran the first version of the rule against our code base at Meta, and it detected a wide variety of subtle and interesting bugs which had made it through code review.</p>
<h2 id="real-world-bugs-found-with-no-constant-binary-expressions" tabindex="-1">Real world bugs found with <code>no-constant-binary-expressions</code></h2>
<p>In this section I’ll share a number of types of bugs that this rule can catch. Each includes at least one concrete example detected in a popular open source project. My choice to include real examples here is not to shame anyone or any project, but to drive home the fact that these are errors that any team can easily make.</p>
<h3 id="confusing-operator-precedence" tabindex="-1">Confusing operator precedence</h3>
<p>The most common class of bug the rule finds is places where developers misunderstood the precedence of operators, particularly unary operators like <code>!</code>, <code>+</code> and <code>typeof</code>.</p>
<pre><code><span><span>if</span> <span>(</span><span>!</span>whitelist<span>.</span><span>has</span><span>(</span>specifier<span>.</span>imported<span>.</span>name<span>)</span> <span>==</span> <span>null</span><span>)</span> <span>{</span></span><br><span>  <span>return</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p><em>From <a href="https://github.com/mui/material-ui/blob/60f02a7a6b48092eedd2c25b15a7f643168a001f/packages/mui-codemod/src/v5.0.0/top-level-imports.js#L73:L73">Material UI</a> (also: VS Code <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/workbench/contrib/timeline/browser/timelinePane.ts#L64">1</a>, <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/workbench/contrib/terminal/browser/terminalProfileResolverService.ts#L456:L456">2</a>, <a href="https://github.com/webpack/webpack/blob/3ad4fcac25a976277f2d9cceb37bc81602e96b13/lib/ExportsInfo.js#L468:L468">Webpack</a>, <a href="https://phabricator.services.mozilla.com/D145655">Mozilla</a>)</em></p>
<h3 id="confusing-%3F%3F-and-%7C%7C-precedence" tabindex="-1">Confusing <code>??</code> and <code>||</code> precedence</h3>
<p>When trying to define default values, people get confused with expressions like <code>a === b ?? c</code> and assume it will be parsed as <code>a === (b ?? c)</code>. When in actuality it will be parsed as <code>(a === b) ?? c</code>.</p>
<pre><code><span><span>shouldShowWelcome</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>this</span><span>.</span>viewModel<span>?.</span>welcomeExperience <span>===</span> WelcomeExperience<span>.</span>ForWorkspace <span>??</span> <span>true</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p><em>From <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/workbench/contrib/testing/browser/testingExplorerView.ts#L118:L118">VS Code</a></em></p>
<p><em>Aside: Observing how frequently developers get confused by operator precedence inspired me to experiment with <a href="https://jordaneldredge.com/blog/a-vs-code-extension-to-combat-js-precedence-confusion/">a VS Code extension</a> to visually clarify how precedence gets interpreted.</em></p>
<h3 id="expecting-objects-to-be-compared-by-value" tabindex="-1">Expecting objects to be compared by value</h3>
<p>Developers coming from other languages where structures are compared by value, rather than by reference, can easily fall into the trap of thinking they can do things like test if an object is empty by comparing with a newly created empty object. Or course in JavaScript, objects are compared by reference, and no value can ever be equal to a newly constructed object literal.</p>
<p>In this example, <code>hasData</code> will always be set to true because <code>data</code> can never be referentially equal to a newly created object.</p>
<pre><code><span>hasData <span>=</span> hasData <span>||</span> data <span>!==</span> <span>{</span><span>}</span><span>;</span></span></code></pre>
<p><em>From <a href="https://hg.mozilla.org/try/rev/0fe5678fb8b71f4eb26f0a153c52d0be45fc5ac1#l3.34">Firefox</a> (also: <a href="https://hg.mozilla.org/try/rev/0fe5678fb8b71f4eb26f0a153c52d0be45fc5ac1#l1.13">Firefox</a>)</em></p>
<h3 id="expecting-empty-objects-to-be-false-or-null" tabindex="-1">Expecting empty objects to be <code>false</code> or <code>null</code></h3>
<p>Another common categrory of JavaScript error is expecting empty objects to be nullish or falsy. This is likely an easy mistake to make for folks coming from a language like Python where empty lists and dictionaries are falsy.</p>
<pre><code><span><span>const</span> newConfigValue <span>=</span> <span>{</span> <span>...</span>configProfiles <span>}</span> <span>??</span> <span>{</span><span>}</span><span>;</span></span></code></pre>
<p><em>From <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/workbench/contrib/terminal/browser/terminalProfileQuickpick.ts#L126:L126">VS Code</a> (also: VS Code <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/platform/terminal/node/ptyService.ts#L369:L369">1</a>, <a href="https://github.com/captbaritone/vscode/blob/ab86e0229d6b4d0cb49cfd6747c92cafcd2bd4af/src/vs/workbench/contrib/terminal/browser/terminalProfileResolverService.ts#L484:L484">2</a>)</em></p>
<h3 id="is-it-%3E%3D-or-%3D%3E%3F" tabindex="-1">Is it <code>&gt;=</code> or <code>=&gt;</code>?</h3>
<p>I’ve only seen this particular typo once, but I wanted to include it because it’s a great example of the unexpected types of bugs this rule can catch.</p>
<p>Here, the developer meant to test if a value was greater than or equal to zero (<code>&gt;= 0</code>), but accidentally reversed the order of the characters and created an arrow function that returned <code>0 &amp;&amp; startWidth &lt;= 1</code>!</p>
<pre><code><span><span>assert</span><span>(</span><span>startWidth</span> <span>=&gt;</span> <span>0</span> <span>&amp;&amp;</span> startWidth <span>&lt;=</span> <span>1</span><span>)</span><span>;</span></span></code></pre>
<p><em>From <a href="https://phabricator.services.mozilla.com/rMOZILLACENTRAL925b8d1ad45f80faee052492b3b43f5120052405">Mozilla</a></em></p>
<h3 id="other-errors-caught-by-no-constant-binary-expression" tabindex="-1">Other errors caught by <code>no-constant-binary-expression</code></h3>
<p>The above five categories of errors are not exhaustive. When I originally ran the first version of this rule on our (very) large monorepo at Meta, it found over 500 issues. While many fell into the categories outlined above, there was also a long-tail of other interesting bugs. Some highlights include:</p>
<ul>
<li>Thinking <code>||</code> allows for set operations: <code>states.includes('VALID' || 'IN_PROGRESS')</code></li>
<li>Thinking primitive functions pass through nulls: <code>Number(x) == null</code></li>
<li>Not knowing primitive <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/Number">constructors</a> return boxed primitives: <code>new Number(x) === 10</code></li>
</ul>
<p>I never would have set out to lint for these specific issues individually, but by simply trying to identify anything “useless” we were able to find and correct them.</p>
<h2 id="conclusion" tabindex="-1">Conclusion</h2>
<p>As you’ve now seen <code>no-constant-binary-expression</code> is capable of detecting a variety of different types of bugs. The rule accomplishes this not because it’s programmed to look for those specific issues, but because all those bugs have one thing in common: they manifest as useless code. Because developers generally don’t intend to write useless code, detecting useless code generally results in detecting bugs.</p>
<p>If you’ve found these examples compelling, please consider enabling <a href="https://eslint.org/docs/rules/no-constant-binary-expression">no-constant-binary-expression</a> in your ESLint config:</p>
<pre><code><span><span>// eslintrc</span></span><br><span>module<span>.</span>exports <span>=</span> <span>{</span></span><br><span>  <span>rules</span><span>:</span> <span>{</span></span><br><span>    <span>// Requires eslint &gt;= v8.14.0</span></span><br><span>    <span>"no-constant-binary-expression"</span><span>:</span> <span>"error"</span></span><br><span>  <span>}</span></span><br><span><span>}</span></span></code></pre>
<p>If you do, and it finds bugs, I’d love to <a href="https://twitter.com/captbaritone">hear about them</a>!</p>
<p><em>Thanks to <a href="https://twitter.com/bradzacher">Brad Zacher</a> for the original observation which inspired this work and the suggestion to propose it as a new core rule. And thanks to <a href="https://github.com/mdjermanovic">Milos Djermanovic</a> for significant contributions during code review.</em></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why SciPy builds for Python 3.12 on Windows are a minor miracle (291 pts)]]></title>
            <link>https://labs.quansight.org/blog/building-scipy-with-flang</link>
            <guid>38196412</guid>
            <pubDate>Wed, 08 Nov 2023 20:24:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://labs.quansight.org/blog/building-scipy-with-flang">https://labs.quansight.org/blog/building-scipy-with-flang</a>, See on <a href="https://news.ycombinator.com/item?id=38196412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You've probably heard already that Python 3.12 was released recently.
For a while already, we've been getting new feature releases every year,
so perhaps this wasn't big news to you – though there's lots of interesting
stuff in there!</p>
<p>It would appear even more "ordinary" that key packages (think <code>pandas</code>,
<code>matplotlib</code> etc.) in the ecosystem would have a release compatible with the
new Python version shortly after<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>, and broadly speaking, you would be right.
Not that there isn't a huge amount of dedicated maintainers (mostly
volunteers!) working tirelessly behind the scenes to make that happen,
but overall, it's a pretty routine situation.</p>
<p>However, behind the ordinary-seeming "SciPy released builds compatible with
Python 3.12" hides an extraordinary story worth telling, because of how several
unrelated, multi-decade-long timelines happened to clash in a way that could
have very easily led to no Python 3.12-compatible releases for a long time.</p>
<p>To understand why this was such a lucky coincidence (though we tried our best
to tip the scales, <em>a lot</em> of luck was necessary), we need to zoom out a bit
and explore the big players involved in this situation.
Fair warning: In the interest of brevity, the following recap is going to be
incomplete and opinionated.
From our perch on the shoulders of giants, let's take a quick look at the
landscape.</p>
<p>We'll briefly shed some light on the following:</p>
<ul>
<li>Why is Fortran still used in so many places?</li>
<li>How is that relevant to Python?</li>
<li>Past struggles of NumPy/SciPy with vanilla Python packaging.</li>
<li>What role conda-forge plays in this context.</li>
</ul>
<p>If you feel you have a good-enough understanding of all this, or not much time,
<a href="#the-situation">skip</a> right past the background. 😉</p>
<h2 id="fortran">Fortran</h2>
<p>… is almost unfathomably old in our day and age.
Started in 1953, first appearing in 1958, it quickly became the most important
programming language of its time, in an age when computing made several
important evolutionary leaps. Most importantly for our story:</p>
<ul>
<li>A lot of scientific code was written in Fortran (meaning often: the
accumulated math knowledge of many decades got crystallised into code), and:</li>
<li>There was a huge number of Fortran compilers, and in the age before Open
Source Software, all of those were proprietary.</li>
</ul>
<h2 id="compilers">Compilers</h2>
<p>Depending on how far behind the curtains you've dared to venture, you've
probably at least heard of the concept of a compiler.
Basically, computers have an exceptionally limited amount of operations at
their disposal, and it's agonisingly painful to write anything in those
primitives directly.
The job of the compiler is to translate whatever the programmer is writing in a
given compiled language, and turn it into something the computer can execute.</p>
<p>In many ways they're the closest to the hardware, which is why they often were
hyper-specific to one CPU architecture, or one operating system – not least
because you cannot write an operating system without a compiler, so the two
were often tightly coupled.
For example, Microsoft, from very early on, used its own compiler to create
Windows and all the bits on top of it.</p>
<p>This coupling further compounded the tendencies towards closed source
compilers, because the compiler source code might not only reveal secrets of
the compiler itself, but also of the architecture or the operating system
built with it.
And since vendors were keen to capitalise on every advantage in an intensely
competitive market, there was no incentive to share sources at all.</p>
<p>The pioneer to break that mould was the GNU compiler collection (GCC), which
became one of the key pillars of the nascent Free &amp; Open-Source Software (FOSS)
movement in the 80s and 90s.
The coupling to the operating system still stayed – in this case various
flavours of Unix, most prominently Linux of course – but GCC became a truly
universal compiler when it came to CPU architectures.</p>
<p>Let's visualise this quickly – we have a matrix of Operating Systems (OS) vs.
CPU Architectures; often compilers were specific not just to one OS, but also
1-2 specific architectures (for a long time the most dominant architecture has
been x86, but that has been changing in recent times).
What GCC did was essentially cover an entire column of that matrix, rather than
just 1-2 cells.</p>
<div><table><thead><tr><th>👉 OS<br>👇CPU Arch.</th>
<th>Linux</th>
<th>Windows</th>
<th>macOS</th></tr></thead><tbody><tr><td>x86_32</td>
<td rowspan="6">GCC</td>
<td rowspan="2">MSVC</td>
<td rowspan="3">Apple Clang</td></tr><tr><td>x86_64</td></tr><tr><td>arm64</td>
<td>(added recently)</td></tr><tr><td>aarch64</td>
<td>➖</td>
<td>➖</td></tr><tr><td>ppc64le</td>
<td>➖</td>
<td>➖</td></tr><tr><td>...</td>
<td>➖</td>
<td>➖</td></tr></tbody></table></div>
<p>This matrix would be <em>a lot</em> larger if it included historical OSes and less
common architectures, where support with the respective compiler was often in
a 1:1 relationship (i.e. that combination would cover a single cell in the matrix).
The matrix also does not cover which programming languages a given compiler is
able to process, but for simplicity, you can picture C/C++ here.</p>
<p>Of course, GCC remains usable on macOS due to shared Unix roots, there are ways
to make it work on Windows (through cygwin or MinGW), and the whole truth is
way more <a href="https://www.flother.is/til/llvm-target-triple/">complicated</a> still.
But as a first-order approximation, this shouldn't raise too many eyebrows.</p>
<p>Alright, after a full page about compilers, we can hear you thinking:
"What does all this have to do with Python?!".
And you're right, but just one last thing:</p>
<p>Once a program in C/C++/Fortran/etc. has been compiled, there are <em>a lot</em> of
expectations built into that so-called "binary", which will expect very
explicitly-sized inputs, read things from – and load things into – very
specific CPU registers etc.
Basically, at this point, the training wheels come off, and if you use said
binary under even slightly different circumstances (different sized inputs,
changed order of function arguments, different in-memory layout of some
structure etc., much less another CPU type), you're going to have a bad time.
This is the so-called Application Binary Interface
(<a href="https://pypackaging-native.github.io/background/binary_interface">ABI</a>),
and any compiled program is subject to this.</p>
<h2 id="python">Python</h2>
<p>We won't bore you with the history here, but the immediate thing to note is:
you don't need a compiler to use Python. That's a blessing as well as a curse,
because on the one hand, it dramatically lowers the difficulty of using it,
and on the other hand, this makes Python slow compared to compiled languages.</p>
<p>Python's duck-typing means it will go through many layers of wrapping and
fall-backs, before anything actually is executed.
Sidenote: this process is taken care of by Python's interpreter, which – uh oh…
– has itself been compiled<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.
Unsurprisingly this approach is slower than a compiled program that will just
run with whatever instructions you've given it (and fail, if any part of the
ABI is violated).</p>
<p>This slow-down doesn't matter so much for prototyping, or general scripting,
but it becomes immensely limiting once there's medium-sized or larger amounts
of data involved.
The best-of-both-worlds solution to this problem was to have performant
compiled code under the hood, but a nice, pythonic "wrapper" around it as the
interface towards the programmer.</p>
<p>Remember all that scientific code that had been written in Fortran?
Things like BLAS and LAPACK were already well-established standards for dealing
with common problems in linear algebra, and so it was an obvious choice to
reuse that when libraries like NumPy and SciPy wanted to expose such
functionality to the Python world.
SciPy additionally also used Fortran code to provide special mathematical
functions and other mathematical tools like interpolation &amp; integration – it's
not like the basic math had changed since the 70s…</p>
<p>However, this came with a terrible price:
Users needed a compiler to install the package.
In the early Python days, when many people were on Linux distributions (which
comes with GCC pre-installed), this was less of an issue.
But it made it extraordinarily difficult to do this in a cross-platform way –
particularly on Windows, it's not common for users to have a compiler
installed, much less know how to use it.</p>
<p>It's even worse on the maintainer-side, because they suddenly need to become
experts in the vagaries of different compilers, linkers and runtime libraries
necessary on different platforms, and with sometimes wildly varying behaviour.</p>
<h2 id="python-packaging">Python packaging</h2>
<p>This situation also happens to be <em>the</em> fundamental problem in Python packaging.
There's so much complexity hiding under the surface, that actually dealing with
it in any kind of sane way is really difficult.
For example, the C &amp; C++ ecosystems never managed to standardise any sort of
build &amp; distribution mechanism, and since Python is wrapping around basically
any flavour of C &amp; C++ code, the problems in Python packaging are a <em>superset</em>
of what's already a hugely pressing issue in C/C++.</p>
<p>The packaging world in Python has had to continually reinvent itself in order
to solve these issues.
It's instructive to check out this
<a href="https://www.youtube.com/watch?v=AQsZsgJ30AE&amp;t=200s">historical</a>
overview, to get a feeling of the many iterations things have gone through.</p>
<p><img src="https://labs.quansight.org/posts/building-scipy-with-flang/ABI_meme.jpg" alt="'A meme about a difficult choice in Python packaging, with a cartoon man sweating under the stress of being unable to decide between two buttons labeled &quot;ABI Hell&quot; and &quot;Users need a compiler&quot;'"></p>
<p>One of the biggest problems over the course of this evolution has been
the question about the right way to distribute a package.
Letting users just download the sources is problematic, because:</p>
<ul>
<li>packages can take a lot of time to build.</li>
<li>if the packages is not just pure Python, the user needs a working compiler
setup (and the source code needs to be compatible with that setup!), which is
a huge usability hurdle.</li>
<li>there's no reliable metadata, because even something as fundamental as the
necessary third-party dependencies used to get populated only through running
<code>setup.py</code>.</li>
</ul>
<p>The alternative – distributing pre-compiled artefacts – is problematic for many
reasons too, and especially fragile in the face of the above-mentioned ABI.
Given the impact of breaking the ABI (random crashes, heisenbugs, etc.), doing
"binary" distribution haphazardly is not an option.</p>
<p>Eventually, a feasible approach for such distribution emerged in the form of
the "wheel" format, which essentially creates a bubble for each package that
brings along all the required libraries, but hides them from others through a
clever mechanism.
While wheels still have some downsides (especially on the maintainer-side),
they are a massive improvement over the situation that existed before, and
nowadays, most Python packages are installable through wheels from PyPI.</p>
<p>But wheels were not around yet at the time when the Scientific Python community
needed to solve some problems they were facing (as well as not versatile enough
conceptually for solving all the key issues involved).
This <a href="http://technicaldiscovery.blogspot.com/2013/12/why-i-promote-conda.html">blog post</a>
by one of the founding contributors of NumPy and SciPy is full of relevant
anecdotes:</p>
<blockquote>
<p>We in the scientific python community have had difficulty and a rocky history
with just waiting for the Python.org community to solve the [packaging]
problem. With <code>distutils</code> for example, we had to essentially re-write most of
it (as <code>numpy.distutils</code>) in order to support compilation of extensions that
needed Fortran-compiled libraries.</p>
</blockquote>
<p>Despite being the product of heroic efforts by many very bright people,
<code>numpy.distutils</code> is generally regarded as a bandaid, and has been in minimal
maintenance mode for years.
This is largely due to fundamental limitations inherent in only having a build
script (e.g. <code>setup.py</code>), without a way to precisely control in advance the
conditions under which a package gets built.
Again from that blog post:</p>
<blockquote>
<p>[...] <code>numpy.distutils</code> replaces most of the innards of <code>distutils</code> but is
still shackled by the architecture and imperative approach to what should
fundamentally be a declarative problem.</p>
</blockquote>
<p>In many ways, this is what led to the creation of conda:</p>
<blockquote>
<p>Therefore, you can't really address the problem of Python packaging without
addressing the core problems of trying to use <code>distutils</code> (at least for the
NumPy stack). The problems for us in the NumPy stack started there and have
to be rooted out there as well. This was confirmed for me at the first PyData
meetup at Google HQ, where several of us asked Guido [van Rossum; Python's
BDFL at the time] what we can do to fix Python packaging for the NumPy stack.
Guido's answer was to "solve the problem ourselves".</p>
</blockquote>
<h2 id="conda--conda-forge">conda &amp; conda-forge</h2>
<p>Conda was designed to take a more holistic view of all the things that are
required for packaging – including the non-Python bits – and unsurprisingly,
done in a declarative way. The basis for this is a "recipe" that explicitly
defines relevant quantities (e.g. what needs to be present in the build
environment), before the first line of any build script is ever run.</p>
<p>This introduced an unfortunate bifurcation in the Python world, because other
Python tools like pip cannot install conda-packages, yet what conda had done
did not easily fit into the standardisation-by-consensus model<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup>, primarily
because many things essential to conda were considered "out of scope" by the
wider Python packaging community.</p>
<p>However, for users and maintainers of packages that are affected by some of the
<a href="https://pypackaging-native.github.io/">deep-seated issues</a> in Python packaging,
it provided a much more powerful solution and got adopted widely – especially
in scientific computing, though by far not everywhere.
While the recipes conda uses are the basis for many key features (e.g. having
enough control to ensure that the ABI is kept consistent, or that packages are
recompiled where necessary), this means in turn that integrating a given
package into the conda world requires creating such a recipe in the first place.</p>
<p>Given the size of the ecosystem, not even a company like Anaconda<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup> could
hope to integrate everything that users wanted, and over time, the
community-driven conda-forge channel became <em>the</em> place to do this integration
work.
Anyone can <a href="https://github.com/conda-forge/staged-recipes/">submit</a> recipes
for a package that is missing, or provide fixes for those that are already
being built on so-called "feedstocks".</p>
<p>One of the things that complicates matters is that conda-forge – as a
philosophy – is aiming to support all common platforms, and even some less
common ones.
This multiplies the kind of problems a Linux distribution might have by at
least ~three, because very often a <em>different</em> set of problems will appear
for macOS and Windows.
To have any chance at success, conda-forge uses the platform defaults
(compiler, standard library, ABI, etc.) wherever possible.</p>
<p>Conda-forge is almost 100% volunteer-run, and dependent on public CI resources
like those provided by Azure Pipelines, as well as Anaconda footing the bill
for the hosting and download traffic of all the hosted artefacts.
On top of that, conda-forge cannot arbitrarily package things where the licence
does not allow it.
There is no hidden layer for build tools; anyone can download and install the
packages that the infrastructure is made of (or the underlying docker images),
and that means conda-forge cannot use proprietary compilers<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>, but must use
what's freely available.</p>
<p>Remember how we discussed above that all Fortran compilers are proprietary
(except gfortran as part of GCC), and how GCC is not directly usable on Windows?
This has been a huge issue for conda-forge, especially as the expectation of
general support on Windows became more and more wide-spread.
For a very long time, conda-forge was not able to build SciPy at all due to this.
Instead it had to rely on packages from the Anaconda channels<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup>, until some
particularly talented contributors hacked together an unholy amalgamation of
MSVC (c.f. the default ABI on Windows) and gfortran, first in SciPy
<a href="https://web.archive.org/web/20210616203153/https://pav.iki.fi/blog/2017-10-08/pywingfortran.html">itself</a>
and later on the
<a href="https://github.com/conda-forge/scipy-feedstock/pull/146">feedstock</a>
in conda-forge.</p>
<h2 id="the-situation">The situation</h2>
<p>To recap:</p>
<ul>
<li>SciPy uses a lot of Fortran code, having incorporated existing and standard
implementations (like BLAS &amp; LAPACK) for mathematical computations.</li>
<li>This did not play well with Python's native build tools, leading to the
creation of <code>numpy.distutils</code>, which is however considered a bandaid and in
minimal maintenance mode.</li>
<li>The Python packaging world has been continually reinventing itself to
overcome burning problems that are due to the immense complexity being
wrapped by Python packages.</li>
<li>A parallel ecosystem has arisen around conda &amp; conda-forge, for packages
and users that were underserved by the standard tools for Python packaging.</li>
</ul>
<p>This is where our story starts in earnest.
Going back for many years already, the situation around <code>distutils</code> and
<code>setuptools</code> had been a source of great pain in the Python packaging world.
The two (in close interaction) represented the de-facto standard way of
building Python packages, but changing anything about them was extremely hard
because of how many use-cases had to be considered, how much everything had
grown organically, and so on.</p>
<p>The next evolutionary step turned out to be the combination of PEP517 / PEP518,
which promised a level playing field between various possible build tools, and
a way to specify the required information through a new interface
(<code>pyproject.toml</code>).
This eventually gained enough traction that <code>distutils</code> got scheduled for
removal from the Python standard library per version 3.12.</p>
<p>However, this had far-reaching consequences for all the things in Python-land
which had grown around <code>distutils</code>, and even more so for things layered on top.
The maintainers of <code>numpy.distutils</code> took the decision that they're not going
to maintain this layer going forward – even though <code>setuptools</code> ingested much
of the <code>distutils</code> interface, it did so in ways that were subtly incompatible
with what <code>numpy.distutils</code> did, and ultimately no-one wanted to keep
maintaining this old pile of hacks any longer than absolutely necessary.</p>
<p>This kicked off a flurry of work – already years ago, because NumPy and SciPy
are under excellent stewardship – to find a better solution.
SciPy in particular took a long, hard look at the landscape, and
<a href="https://labs.quansight.org/blog/2021/07/moving-scipy-to-meson">decided</a>
to go with Meson as a build tool, which had a nice Python-style feel to it, and
less of the historic baggage or cumbersome DSL of CMake.
This was a far-reaching and forward-looking decision at the time, not least
because Meson did not yet support all the things that would be necessary to
pull things off.</p>
<p>To put this effort into context, all this required many, many engineering
months of highly talented people over the last ~2.5 years.
Unbeknownst to most, we are benefitting from the great foresight of the SciPy
and NumPy developers in tackling the issue this far in advance, rather than
having an "uh oh" moment once Python 3.12 is released.</p>
<p>It's necessary to note that Meson as a build tool has a much broader audience
than Python developers – it is used widely for C &amp; C++ projects for example<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup>.
As part of an overall design ideology to bring some much-needed sanity to this
space (and especially the world of C/C++ where no uniform solution exists),
Meson will not let you do things that are sure to go wrong in all but the most
expert hands.</p>
<p>In particular, Meson was going to refuse to accept the MSVC+gfortran
combination that was in use in conda-forge.
In fact, it looked like we were going to be completely boxed in.
As of Python 3.12:</p>
<ul>
<li><code>distutils</code> would be gone, and contemporary <code>setuptools</code> incompatible with
<code>numpy.distutils</code>.</li>
<li>Meson would refuse to work with the hack conda-forge was using.</li>
<li>There were no free (and ABI-compatible) Fortran compilers on Windows <em>at all</em>.</li>
</ul>
<h2 id="fortran-the-revival">Fortran, the revival</h2>
<p>While Fortran has long been the butt of the joke in IT departments the world
over, in a curious twist of fate, it has seen a dramatic resurgence over the
last few years.
While the reasons for this are not exactly obvious (at least to us!), a few
possible explanations are:</p>
<ul>
<li>It has relatively simple syntax, and maps well to the structure of
mathematical formulae.</li>
<li>It produces performant code, especially in combination with parallelisation
frameworks like OpenMP.</li>
<li>Due to the large amount of Fortran code in scientific computing, and the
promised performance gains through GPUs, it became an attractive target for
supporting GPU computations.</li>
</ul>
<p>As such, there was renewed vigour in the Fortran compiler space, and several
important developments happened in short succession.
For example, PGI / NVIDIA open sourced a version of their compiler called
pgfortran with a new backend based on LLVM (more on that below), which later
turned into what's now known as "classic" Flang.
In the process of trying to upstream this into LLVM itself, the compiler got
rewritten completely under the name f18, which later turned into "new" Flang
that eventually got merged into LLVM itself.
Pretty much at the
<a href="https://fortran-lang.discourse.group/t/what-is-the-exact-difference-between-llvm-flang-and-lfortran/901/17">same time</a>,
another group started developing a Fortran compiler based on LLVM: LFortran.</p>
<h2 id="llvm--clang">LLVM &amp; Clang</h2>
<p>Further up we had looked at a matrix of Operating Systems versus CPU
architectures, and how most compilers tended to only cover 1-2 "cells", whereas
GCC covered essentially all possible architectures on Linux – i.e. a whole
column of the matrix.</p>
<p>As it happened, the last dimension of universality was tackled by another large
project that grew from a research project into a fully cross-architecture and
cross-platform compiler infrastructure<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="true" aria-describedby="footnote-label">8</a></sup>: LLVM, and its flagship compiler Clang.
This was an absolutely massive undertaking, but due to its cross-platform
nature, permissive licensing, and modular infrastructure, has become <em>the</em>
focal point of efforts around all kinds of compiler development.</p>
<p>Without going into the technical details, LLVM provides several so-called
"Intermediate Representations" (IRs), which are somewhere in between machine
code and the code that most programmers write, but in a way that is
language-agnostic.
In particular, it would be possible to target the LLVM IRs from Fortran, and
then automatically benefit from all the "backends" that do most of the heavy
optimization work between the IRs and the actual CPU architecture.</p>
<p>This made LLVM an attractive foundation for these new Fortran compiler efforts,
and both incarnations of Flang as well as LFortran followed this approach,
though with different aims in what they built on top.</p>
<h2 id="compiler-bingo">Compiler bingo</h2>
<p>All of these FOSS Fortran compilers attracted great hope to unblock the general
situation regarding the lack of free Fortran compilers on Windows.
Classic Flang already had preliminary support for Windows, but this never fully
took off, not least as the lion's share of resources behind Flang was
refocussed on getting the rewritten version merged into LLVM itself.</p>
<p>But these were not the only changes happening in this space.
For example, Intel did a major overhaul of their Fortran compiler (also basing
it on LLVM), and started making it freely available, though not open source.
Unfortunately this precludes conda-forge from using it, unless Intel themselves
packages the compilers for us;
we <a href="https://github.com/conda-forge/intel-compiler-repack-feedstock/issues/15">asked</a>,
but there was no timeline.</p>
<p>Furthermore, through the Mingw-w64 project, it slowly started to become possible
to use gfortran with Microsoft's "Universal C Runtime" (UCRT), which is
essentially the biggest hurdle in achieving ABI-compatibility on Windows.
However, switching out the underlying C standard library would represent a
<a href="https://github.com/conda-forge/conda-forge.github.io/issues/1654">major</a>
overhaul in the MinGW stack for windows within conda-forge, and was also not
something we could count on to be ready in time.</p>
<p>For people on the sidelines like ourselves, this turned into something akin to
"Waiting for Godot" – a seemingly endless period as things kept stretching and
stretching and stretching out further into the future.
To give some perspective, things already seemed "not too far out" 3-4 years
<a href="https://github.com/conda-forge/conda-forge.github.io/issues/961#issuecomment-597094501">ago</a>.</p>
<p>At this point you may be asking yourself:
"wait a second… how did SciPy actually switch to Meson, if there are no Fortran
compilers for Windows?"</p>
<h2 id="how-upstream-scipy-does-it-for-now">How upstream SciPy does it (for now)</h2>
<p>While SciPy has some amount of funding through grants and such, and could
conceivably pay for a compiler licence to use for producing wheels, the
requirements of building things in CI regularly – to avoid the otherwise
inevitable bitrot – would cost a lot and not be a judicious use of the limited
funds available.</p>
<p>What ended up happening is that one lone developer managed to custom-build a
MinGW-based toolchain, carefully adapted to use the right-sized integers and to
conform to the MSVC ABI.
This is enough to pass through Meson's sanity checks (after all, GCC is a
consistent toolchain), however it is again subtly-yet-crucially different from
the requirements that would be necessary for wide-spread use in conda-forge.</p>
<h2 id="conda-forge-and-the-migration-problem">conda-forge and the migration problem</h2>
<p>One final aspect in the whole saga is that conda-forge has some additional
constraints in terms of how large-scale maintenance efforts work, e.g.
something like rolling out a new Python version.
Essentially, this means rebuilding all Python-related feedstocks in the order
how they depend on each other, and the only reasonable way to do it at scale is
to do all OSes and architectures at the same time, as they're all built
simultaneously per feedstock.</p>
<p>So it looked conceivable that we'd end up in a situation where:</p>
<ul>
<li>We have no Windows builds for SciPy, because there's no Fortran compiler
conda-forge can use.</li>
<li>Not being able to rebuild SciPy for Python 3.12 on Windows would either
hold up the migration for at least ~1000 packages that depend on SciPy on
all platforms, or we would have to drop Windows from the Python migration
completely, which would be similarly disruptive and a lot of effort to fix
later.</li>
</ul>
<h2 id="a-pious-hope">A pious hope</h2>
<p>So while the <code>distutils</code> removal was coming down the line like an oncoming
freight train, all we could try to do was cross our fingers that <em>one</em> Fortran
compiler would be ready in time (most likely either llvm-flang or LFortran), and
be as prepared as possible in terms of having all the other pieces ready to go.
LLVM is a big baby, and keeping all the pieces involved up-to-date is a
non-trivial exercise already<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref="true" aria-describedby="footnote-label">9</a></sup>, but we put extra effort into trying to
identify potential problems with Flang early on, both in our own
<a href="https://github.com/conda-forge/flang-feedstock/pull/27">infrastructure</a>,
<a href="https://github.com/llvm/llvm-project/issues/60730">as well as</a>
<a href="https://github.com/llvm/llvm-project/issues/63712">upstream</a>.</p>
<p>But no matter how motivated we were to pursue this, the iron-clad constraints
of FOSS remain at play: no-one can take care of everything, much less keep all
the required knowledge in their head.
That means we need other people's input &amp; feedback – and when everyone's a
volunteer<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="true" aria-describedby="footnote-label">10</a></sup>, things can take a while.</p>
<p>As it happened, the release of LLVM 17.0 was coming up, which would be the first
release where Flang had matured enough to remove the <code>-flang-experimental-exec</code>
flag, and was <a href="https://discourse.llvm.org/t/proposal-rename-flang-new-to-flang/69462/33">estimated</a>
to be roughly "0.8 level maturity".
As soon as we had the release candidates built in conda-forge, we tried to throw
it at SciPy, only to realise that Meson did not support the new Flang yet.</p>
<p>Even worse, it wasn't clear which ABI Flang was using (as mentioned above,
conda-forge uses the default ABI on Windows everywhere), not least because the
Clang driver which Flang uses under the hood can target both modes.
Unfortunately, it wasn't clear which mode was being chosen, and generally it
looked like Windows support was (as often happens in FOSS) the least mature
platform.</p>
<p>To top it off, there are also two different standard libraries, two different
runtime libraries and two different linkers to consider in all this – all of
which had the potential to lead to subtle breakage.
At this point, we still hadn't compiled more than a "Hello World!" example with
Flang, so it wasn't even clear that it could compile all of SciPy, much less
pass the test suite...</p>
<h2 id="eucatastrophe">Eucatastrophe</h2>
<p>The final push came once SciPy got <a href="https://github.com/scipy/scipy/pull/19317">ready</a>
to remove support for <code>setup.py</code>, the last link to the "old world" before the
removal of <code>distutils</code>.
With some kind hints from the Meson devs and a bit of persistence, we managed to
teach Meson to be able to handle llvm-flang just enough to compile something.
We eventually passed the first build, and after some more wrangling with Meson,
the first installation too.</p>
<p>What happened next felt like nothing short of magical – while we were expecting
test failures, hangs or even crashes, the test suite… just passed 100%?!</p>
<div><p><code><br><div><p><span> ........................................................................ [ 99%]</span></p></div><div><p><span> .................................................s.......                [100%]</span></p></div><div><p><span> = 54987 passed, 2866 skipped, 245 xfailed, 11 xpassed, 1 warning in 979.88s (0:16:19) =</span></p></div><div><p><span> Resource usage statistics from testing scipy-tests:</span></p></div><div><p><span>    Process count: 43</span></p></div><div><p><span>    CPU time: Sys=0:01:20.6, User=0:29:59.3</span></p></div><div><p><span>    Memory: 1.7G</span></p></div><div><p><span>    Disk usage: 1.8K</span></p></div><div><p><span>    Time elapsed: 0:16:24.6</span></p></div><br></code></p></div>
<p>55'000 tests, and not a single failure? When does that ever happen on the first
try after major surgery?</p>
<p>Somehow, armed only with a pre-release of a still-experimental compiler and a
hastily patched-up build system, we managed to dodge the freight train, and the
migration in conda-forge could progress past SciPy with no more than a few days
delay, rather than being stuck for months.
In the end, the respective SciPy builds in conda-forge were available two days
after the release of Python 3.12.0.</p>
<h2 id="epilogue">Epilogue</h2>
<p>At the end of this journey, we can only marvel at how long and winding the ways
have been that lead us here.
Depending on where you draw the line, hundreds or even thousands of person
years of effort went into the ingredients that were necessary for us to achieve
the final result (SciPy, Meson, Flang, LLVM, LAPACK etc.).
We cannot realistically thank everyone, but a few call-outs nevertheless:</p>
<ul>
<li>Ralf Gommers, for tirelessly positive support and for outstanding
stewardship of NumPy and SciPy, and driving the massive effort to move
SciPy to Meson.</li>
<li>Isuru Fernando, for building &amp; maintaining some of the trickiest pieces in
conda-forge, and consistently helping out with keeping them running or
building on top of them, as well as reviewing with incredible expertise.</li>
<li>The Meson developers, for a clean build system with a solid design philosophy.</li>
<li>The Flang developers, for providing the world with an open source Fortran
compiler that also works on Windows.</li>
</ul>
<p><em>We are also very grateful that this work was supported in part by a grant from
NASA to SciPy, scikit-learn, pandas and NumPy under the NASA ROSES 2020 program.</em></p>
<p>PS. In case you're still wondering what the "eu" in eucatastrophe
<a href="https://tolkiengateway.net/wiki/Eucatastrophe">means</a>, it's a neologism coined
by J. R. R. Tolkien from Greek ευ- "good" and καταστροφή "sudden turn".
Quoting from the link above: "In essence, a eucatastrophe is a massive turn in
fortune from a seemingly unconquerable situation to an unforeseen victory,
usually brought by grace rather than heroic effort.
Such a turn is catastrophic in the sense of its breadth and surprise and
positive in that a great evil or misfortune is averted."</p>
<hr>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1">
<p>or even before, based on Python release candidates! <a href="#user-content-fnref-1" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>and thus also has an ABI, if you want to speak to Python from another
compiled language. <a href="#user-content-fnref-2" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>coupled with fears (at least initially) that a single company would
"take over" such a critical piece of the ecosystem. <a href="#user-content-fnref-3" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>which grew around the needs conda addresses, and is the main driver
behind the tool. <a href="#user-content-fnref-4" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>because their licenses forbid redistribution – which conda-forge wouldn't
be able to prevent from happening. <a href="#user-content-fnref-5" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>Anaconda can afford to have their own build infrastructure, and is able
to enter into contracts with compiler vendors. <a href="#user-content-fnref-6" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>if you're on Linux, much of your graphics stack is being built with Meson
nowadays. <a href="#user-content-fnref-7" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>not least because Apple hired its founder, with the ostensible goal of
having a compiler that was not subject to GCC's license. <a href="#user-content-fnref-8" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-9">
<p>aside from the fact that conda-forge cannot build the whole enchilada in
one go within the 6h time limit on the relatively modest CI agents that Azure
provides for free, any substantial change in our LLVM setup needs a lot of care
due to the sheer number of packages that can be affected by something so deep
in the stack. <a href="#user-content-fnref-9" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-10">
<p>i.e. people who have lives and their own interests, or who're just plain
busy with other urgencies or things they care about more.
And even though there are people employed to work on some of these projects,
they almost always aren't paid to solve <em>your</em> problem. <a href="#user-content-fnref-10" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$200M gift propels scientific research in the search for life beyond earth (130 pts)]]></title>
            <link>https://www.seti.org/press-release/200m-gift-propels-scientific-research-search-life-beyond-earth</link>
            <guid>38195718</guid>
            <pubDate>Wed, 08 Nov 2023 19:32:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seti.org/press-release/200m-gift-propels-scientific-research-search-life-beyond-earth">https://www.seti.org/press-release/200m-gift-propels-scientific-research-search-life-beyond-earth</a>, See on <a href="https://news.ycombinator.com/item?id=38195718">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
            <a id="main-content" tabindex="-1"></a>
            <a></a>
              <div>
    <div id="block-subscribetoournewsletter"><p><a href="https://connect.seti.org/l/972893/2023-08-23/2hxnv">Subscribe</a> to receive SETI Institute news weekly in your inbox.</p>
</div>



<div id="block-mainpagecontent">
      
<article data-history-node-id="5532" role="article" about="/press-release/200m-gift-propels-scientific-research-search-life-beyond-earth" typeof="schema:Article">
  

<div>
  
  <h2>
    <span property="schema:name">$200m Gift Propels Scientific Research in the Search for Life Beyond Earth</span>

  </h2>  
  
  <div>
    
    <div>
                                  <p><img src="https://www.seti.org/sites/default/files/styles/original/public/2023-11/SETI-Institute-Logo-ATA-S-Steel.jpg?itok=f6UO2euW" alt="The Allen Telescope Array and SETI Institute Logo." typeof="foaf:Image">


                            <span>
      
  </span>
          </p></div>
    
    <div property="schema:text"><p>November 8, 2023, Mountain View, CA <strong><em>–</em></strong> <a href="https://www.seti.org/" rel="noreferrer" target="_blank">The SETI Institute</a>, a non-profit scientific research organization, announced today a philanthropic gift of $200m from the estate of Franklin Antonio, a visionary supporter and catalyst of the work of the SETI Institute for more than 12<strong> </strong>years. Co-founder of communications chip company, Qualcomm, Antonio passed away on May 13, 2022, leaving behind an extraordinary legacy to enable breakthrough science in the search for intelligent life beyond our world.&nbsp;</p>

<div><p>With more than 100 scientists actively conducting research across 173 separate programs, the SETI Institute explores six key science disciplines: Astronomy and Astrophysics; Exoplanets; Planetary Exploration; Astrobiology; Climate and bio-geoscience; and the Search for Extraterrestrial Intelligence (SETI).</p><p>
“Guided by our core mission and Franklin Antonio’s vision, we now have the opportunity to elevate and expedite our research and make new discoveries to benefit all humanity for generations to come,” said SETI Institutes President &amp; CEO Bill Diamond. “In his memory, the SETI Institute will continue its pursuit of one of the biggest and most profound questions in all of science, a question as old as humanity itself – are we alone in the universe?”</p><p>
This gift enables the SETI Institute to undertake more missions and expand research priorities to push the boundaries of human knowledge in exploring life beyond our planet and the origins of life here on Earth. Examples include:<strong> </strong></p></div>

<ul><li>Establish postdoctoral fellowships and internal grants for science and education programs</li>
	<li>Enable the SETI Institute’s research base to expand and extend its reach globally through new international collaborations</li>
	<li>Develop new educational programs and initiatives, particularly focused on reaching and engaging underserved communities</li>
	<li>Support the development of innovative observational technologies and analytical instruments</li>
</ul><div><p>“Not only was Franklin the primary benefactor of SETI research at the Allen Telescope Array (ATA), but he was an integral part of the technical team. His extraordinary knowledge of communications technology was invaluable in upgrading the ATA to the world-class radio telescope instrument it is today,” said Dr. Andrew Siemion, Bernard M. Oliver Chair of SETI Research at the SETI Institute and Director of SETI Research at the University of Oxford.</p><p>
Currently, SETI-focused projects are eligible for only limited federal funding through research grants and otherwise depend entirely on philanthropic support and private funding. As such, Antonio’s gift will also serve to permanently endow core SETI programs and foster new global partnerships.</p><p>
“This gift will impact all research domains of the SETI Institute,” said Dr. Nathalie Cabrol, Director of the Carl Sagan Center for Research. “It will provide our teams the freedom to pursue their own science priorities, and to examine the technological, philosophical and societal impact of their research on our daily lives here on Earth.”</p></div>

<p><strong>About The SETI Institute</strong><br>
Founded in 1984, the SETI Institute is a non-profit, multi-disciplinary research and education organization whose mission is to lead humanity's quest to understand the origins and prevalence of life and intelligence in the universe and share that knowledge with the world. Our research encompasses the physical and biological sciences and leverages data analytics, machine learning, and advanced signal detection technologies. The SETI Institute is a distinguished research partner for industry, academia, and government agencies, including NASA the Department of Energy and the National Science Foundation. <a href="https://www.seti.org/">https://www.seti.org/</a></p>

<p><strong>Contacts</strong><br>
Rebecca McDonald<br>
Director of Communications<br>
SETI Institute<br><a href="mailto:media@seti.org">media@seti.org</a></p>

<p>-OR-</p>

<p>Angelica DeLuccia Morrissey | <a href="mailto:angelica@griffincg.com">angelica@griffincg.com</a><br>
Sara Shell | <a href="mailto:sara@griffincg.com">sara@griffincg.com</a><br>
Griffin Communications Group</p>

<p><a href="https://www.calameo.com/read/004812363b02ccd15a148" rel="noreferrer" target="_blank"><strong>DOWNLOAD PRESS RELEASE</strong></a></p>




</div>
      </div>
</div>
</article>


    </div>
<div id="block-views-block-article-view-block-2">
  
      <h2>Recent Articles</h2>
    
      
  </div>

  </div>

            
          </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Voters Overwhelmingly Pass Car Right to Repair Law in Maine (251 pts)]]></title>
            <link>https://www.404media.co/voters-overwhelmingly-pass-car-right-to-repair-law-in-maine/</link>
            <guid>38195509</guid>
            <pubDate>Wed, 08 Nov 2023 19:20:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/voters-overwhelmingly-pass-car-right-to-repair-law-in-maine/">https://www.404media.co/voters-overwhelmingly-pass-car-right-to-repair-law-in-maine/</a>, See on <a href="https://news.ycombinator.com/item?id=38195509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

<!--kg-card-begin: html-->
  <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      
    </div>
  </div>

<!--kg-card-end: html-->
<p>Voters in Maine <a href="https://www.nytimes.com/interactive/2023/11/07/us/elections/results-maine-question-4-right-to-repair.html?ref=404media.co">overwhelmingly passed a ballot</a> measure Tuesday that enshrines the right to repair cars, a major win for consumers and a blow to auto manufacturers who have spent millions lobbying against similar legislation and fighting against it in the courts.</p><p>“Question 4,” which enshrines consumers’ data access to car diagnostics for the purposes of repair, <a href="https://ballotpedia.org/Maine_Question_4,_%22Right_to_Repair_Law%22_Vehicle_Data_Access_Requirement_Initiative_(2023)?ref=404media.co">passed by a margin of 84.3-15.7</a> in Tuesday’s election with 94 percent of the votes tallied. The yes/no question was simple: “Do you want to require vehicle manufacturers to standardize on-board diagnostic systems and provide remote access to those systems and mechanical data to owners and independent repair facilities?”&nbsp;</p><p>Maine’s vote shows yet again that right to repair in all of its forms is overwhelmingly popular with consumers, and that they are not swayed by fear mongering campaigns from manufacturers. A similar measure in 2020 passed in Massachusetts with 75 percent support from voters.&nbsp;</p><p>In Massachusetts, car manufacturers <a href="https://www.404media.co/biden-administration-changes-mind-says-car-companies-shouldnt-ignore-overwhelmingly-popular-car-repair-law-anymore/">spent tens of millions of dollars</a> on ads that said the law would be used by stalkers and hackers if it was passed. Auto manufacturers have been engaged in a three-year lawsuit there to prevent the law from going into effect. Proponents of the law say it is necessary because car manufacturers are moving toward systems where car diagnostics can only be read wirelessly by people who are authorized by the manufacturer to do so; on cars up to now, such data has been accessible through a wired port underneath the car’s steering wheel.</p><p>“Maine residents have won the right to control their destiny when it comes to car repairs,” Tommy Hickey, director of the Maine Automotive Right to Repair Coalition, told 404 Media. “There’s a new technology in cars, they’ve become computers on wheels, and with this law owners in Maine will be the gatekeepers of that information.” Hickey also worked on the Massachusetts law in 2020.</p><p>Hickey said that after getting crushed in Massachusetts, auto manufacturers didn’t lobby as hard against the Maine law as they did in Massachusetts: “They didn’t spend nearly as much money,” he said. “When you spend $30 million and you lose 75 percent of the vote, I think the writing is on the wall.”</p><p>Nathan Proctor, head of consumer rights group USPIRG’s right to repair project, told 404 Media that “right to Repair is incredibly popular because it’s common sense—at least to those who aren’t manufacturers. Society works best when we are empowered to fix our stuff.”</p><p>The Maine law is a big deal not just for people in Maine. In the past, when states have passed legislation like this, manufacturers have functionally had to make this data available in other states. An earlier law passed in Massachusetts became de-facto national legislation after manufacturers signed a “Memorandum of Understanding” in which they agreed to comply with the law throughout the country rather than face slightly varying laws in every state.</p><p>The CAR Coalition, which is pushing right to repair legislation throughout the country, told 404 Media that “Maine voters' overwhelming show of support for Question 4 adds momentum to the growing national push for right to repair protections. The CAR Coalition will continue this important fight at the federal level with bipartisan bills like the SMART and REPAIR Acts to ensure every American—no matter where they live—has the right to repair the car they own.”</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After luring customers with low prices, Amazon stuffs Fire TVs with ads (310 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/11/after-luring-customers-with-low-prices-amazon-stuffs-fire-tvs-with-ads/</link>
            <guid>38194818</guid>
            <pubDate>Wed, 08 Nov 2023 18:35:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/11/after-luring-customers-with-low-prices-amazon-stuffs-fire-tvs-with-ads/">https://arstechnica.com/gadgets/2023/11/after-luring-customers-with-low-prices-amazon-stuffs-fire-tvs-with-ads/</a>, See on <a href="https://news.ycombinator.com/item?id=38194818">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1340979935-800x533.jpg" alt="Close-up image of Smart Television screensaver of roaring , dancing flames from beach barbecue burning wood against night sky, domestic life concept">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1340979935.jpg" data-height="1414" data-width="2121">Enlarge</a> <span>/</span> A non-Amazon TV displaying a fire. </p></figcaption>  </figure>

  




<!-- cache hit 20:single/related:edde8a3657dad64086462be9b5ca5d1d --><!-- empty -->
<p>People who buy a Fire TV from Amazon are probably looking for a cheap and simple way to get an affordable 4K smart TV. When <a href="https://arstechnica.com/gadgets/2021/09/amazon-new-4k-tvs-fire-tv-stick-4k-max-announced/#:~:text=Amazon%20on%20Thursday%20announced%20its,Amazon's%20Fire%20TV%20operating%20system.">Amazon announced its first self-branded TVs</a> in September 2021, it touted them as being a "great value." But owners of the devices will soon be paying for some of those savings in the form of more prominently displayed advertisements.</p>
<p>Charlotte Maines, Amazon's director of Fire TV advertising, monetization, and engagement, detailed the new types of ads that Amazon is selling on Fire TVs. In a <a href="https://www.streamtvinsider.com/advertising/amazon-fire-tv-intros-new-options-advertisers-including-contextual-sponsored-tiles">StreamTV Insider</a> report from November 1, Amazon said the new ads will allow advertisers to reach an average of 155 million unique monthly viewers.</p>
<p>Some of the changes targeting advertisers, like connecting display placement ads with specific in-stream video ads, seem harmless enough. Others could jeopardize the TV-watching experience for owners.</p>
<h2>New ads tied to generative AI Alexa</h2>
<p>For example, Amazon is preparing to make <a href="https://arstechnica.com/gadgets/2023/09/amazons-generative-ai-powered-alexa-is-as-big-a-privacy-red-flag-as-old-alexa/">Alexa with generative AI</a> more useful for finding content on Fire TVs. This could help Alexa, which has struggled alongside other tech giants' voice assistants to <a href="https://arstechnica.com/gadgets/2022/11/amazon-alexa-is-a-colossal-failure-on-pace-to-lose-10-billion-this-year/">generate significant revenue</a>. Amazon gets money every time someone interacts with digital content through Alexa.</p>
<p>However, the company is double-dipping on this idea by also tying ads to generative AI on Fire TVs. When users ask Alexa to help them find media with queries such as "play the show with the guy who plays the lawyer in <em>Breaking Bad,"&nbsp;</em>they will see ads that are relevant to the search.</p>
<p>Amazon has discussed <a href="https://arstechnica.com/gadgets/2023/03/with-amazon-alexas-future-in-peril-fire-tvs-offer-a-glimmer-of-hope/">evolving Alexa</a> into a tool that can not only bring you to the right app for the show you want but that can also <em>recommend&nbsp;</em>specific shows based on prompts like the above. This has been one of the most promising potential futures for the voice assistant. But positioning the feature next to ads seems to prioritize advertisers over Fire TV customers.</p>                                            
                                                        
<p>Maines told StreamTV Insider that advertisers had been asking for a way to advertise against Fire TV searches. “It just makes sense to expand our existing sponsor tile offering to show advertisements on the search screen with no extra effort or cost for the advertiser,” she said.</p>
<p>Finally, Amazon is adding "contextual sponsored tiles" that use machine learning to show ads based on whatever content genre or search term the Fire TV user is browsing.</p>
<h2>“Persistent” ads</h2>
<p>Amazon Fire TV users will also start seeing banner ads on the device's home screen for things that have nothing to do with entertainment or media. This ad space was previously reserved for advertising media and entertainment, making the ads feel more relevant, at least. Amazon opening the ad space to more types of advertisers is similar to a move Google TV made <a href="https://www.flatpanelshd.com/news.php?subaction=showfull&amp;id=1674633052">early this year</a>.</p>
<p>The company seems to be aware of how dominating these types of advertisements can be. Maines emphasized to StreamTV Insider how the native ads are "right at the top of the Fire TV's home screen" and take "up half the screen."</p>
<p>Maines continued, telling StreamTV Insider:</p>
<blockquote><p>It’s persistent, so as a customer browses around the UI… they continue to see it.</p></blockquote>
<p>The banner ads will occupy the first slot in the rotating hero area, which Amazon believes is the first thing Fire TV users see. These users may have purchased a Fire TV primarily for streaming content from <a href="https://arstechnica.com/gadgets/2023/11/max-users-grandfathered-into-15-99-ad-free-plan-lose-4k-hdr-next-month/">ad-free subscriptions</a>, but Maines described how Fire TVs can still manage to force ads on these users.</p>
<p>StreamTV Insider reported:</p>
<blockquote><p>Maines explained how with on-device ads, even if viewers ultimately choose to watch something that’s not ad-supported, brand advertisers still have the opportunity to get their message in front of viewers and talk to them as they browse and decide what to watch.</p></blockquote>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Bulletpapers – ArXiv AI paper summarizer, won Anthropic Hackathon (122 pts)]]></title>
            <link>https://www.bulletpapers.ai</link>
            <guid>38194586</guid>
            <pubDate>Wed, 08 Nov 2023 18:20:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bulletpapers.ai">https://www.bulletpapers.ai</a>, See on <a href="https://news.ycombinator.com/item?id=38194586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.alfieranstead.com/" target="_blank">Alfie Ranstead</a><a href="" target="_blank">Matt Falconer</a><a href="" target="_blank">Cláudio Lemos</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texas produces twice as much methane as better regulated neighbor, study finds (238 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2023/nov/08/texas-methane-oil-and-gas-study-climate</link>
            <guid>38194359</guid>
            <pubDate>Wed, 08 Nov 2023 18:04:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2023/nov/08/texas-methane-oil-and-gas-study-climate">https://www.theguardian.com/us-news/2023/nov/08/texas-methane-oil-and-gas-study-climate</a>, See on <a href="https://news.ycombinator.com/item?id=38194359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Oil and gas production in Texas is spewing out double the rate of methane, a powerful greenhouse gas, than in the more regulated state of <a href="https://www.theguardian.com/us-news/newmexico" data-link-name="in body link" data-component="auto-linked-tag">New Mexico</a>, new satellite data shared with the Guardian shows, prompting calls for tougher curbs of “super-emitter” sites that risk tipping the world into climate breakdown.</p><p>Satellite imaging of methane leaks across the Permian basin, a vast geological feature at the heart of the US oil and gas drilling industry, show that sites in <a href="https://www.theguardian.com/us-news/texas" data-link-name="in body link" data-component="auto-linked-tag">Texas</a> have emitted double the amount of the gas than in New Mexico, per unit of production, since 2019.</p><figure id="dd1943dd-6eda-4877-9372-745386abad27" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/environment/2023/mar/06/us-methane-gas-leak-fracking-jackson-township-pennsylvania&quot;,&quot;text&quot;:&quot;‘We don’t feel safe’: US community in shock after record methane leak &quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;dd1943dd-6eda-4877-9372-745386abad27&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Methane is a potent planet-heating gas, around 80 times <a href="https://www.unep.org/news-and-stories/video/whats-deal-methane" data-link-name="in body link">more powerful</a> than carbon dioxide over a 20-year period, and is routinely released via leaks or intentionally vented and burned, in a process called flaring, by fossil fuel companies when drilling for oil and gas. <a href="https://www.theguardian.com/environment/2023/mar/06/revealed-1000-super-emitting-methane-leaks-risk-triggering-climate-tipping-points" data-link-name="in body link">Scientists have warned of a “scary” surge</a> in methane emissions in the past two decades, posing a major threat to efforts to contain dangerous global heating.</p><p>The new satellite data, gathered by <a href="https://www.kayrros.com/" data-link-name="in body link">Kayrros</a>, a French climate technology company, shows that methane is being leaked at a far higher rate from sites in Texas compared with neighboring New Mexico. Despite increasing its own oil production in recent years, New Mexico has no site with repeated methane leaks, unlike in Texas, which Kayrros said is likely due to a <a href="https://www.governor.state.nm.us/2022/07/28/new-mexicos-nationally-leading-oil-and-gas-emissions-rule-becomes-law/" data-link-name="in body link">2021 state law</a> aimed at curtailing methane emissions from industry.</p><p>“The effect that methane has on the global climate is devastating,” said Antoine Rostand, chief executive of Kayrros. “Good operators will re-inject the gas while others will vent it, which means it’s very easy to eliminate leaks of methane that would have a massive impact upon the climate.”</p><p>Rostand said the difference between visible leaks in Texas and New Mexico is “huge” and should spur governments in the US and other countries to crack down on this pollution. “It seems the regulation in New Mexico has had an impact without hurting business,” he said. “It’s a message of hope because it shows that if you have regulation it works. Governments need to take up their responsibilities with this.”</p><p>Methane is emitted from various activities, such as from the raising of <a href="https://www.theguardian.com/environment/2023/oct/06/feeding-seaweed-to-cows-can-cut-methane-emissions-says-swedish-report" data-link-name="in body link">livestock</a>, but oil and gas production is the biggest source of the pollutant in the US and emissions have surged amid a frenzy of new drilling, some of it for fossil fuels to be <a href="https://www.theguardian.com/us-news/2023/oct/23/louisiana-gas-export-hub-biden-climate-crisis" data-link-name="in body link">exported overseas</a>.</p><p>Texas, despite being at the epicenter of the oil industry, <a href="https://insideclimatenews.org/news/22012023/texas-epa-methane/" data-link-name="in body link">has scant measures</a> to prevent companies from dumping their unwanted methane into the shared atmosphere. It is “really frustrating that Texas continues to allow oil and gas companies to pollute with impunity when we’ve got a great solution staring us in the eye”, said Luke Metzger, executive director of Environment Texas. “Unfortunately it’s clear that Texas is not going to stand up to big oil and adopt sensible standards to cut methane.”</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-9">skip past newsletter promotion</a><p id="EmailSignup-skip-link-9" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><figure id="233f51d9-5cc8-44c0-8895-8ffcfdc2270b" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=380&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=380&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=300&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=300&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Repeated methane emissions from a Midland county, Texas, compressor station between 2019 and 2022." src="https://i.guim.co.uk/img/media/8dc98cde4b694b6eb4eea0031038321a31297a4d/0_0_790_757/master/790.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="426.4113924050633" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Repeated methane emissions from a Midland county, Texas, compressor station between 2019 and 2022.</span> Photograph: Kayrros</figcaption></figure><p>Environmentalists have pinned their hopes, therefore, on the US Environmental Protection Agency (EPA), which is finalizing a new federal rule for new and existing drilling sites <a href="https://www.epa.gov/system/files/documents/2022-11/OIl%20and%20Gas%20Supplemental.%20Overview%20Fact%20Sheet.pdf" data-link-name="in body link">that it says will slash methane emissions</a> from these sources by 87% by 2030, compared with 2005 levels. The regulation is expected to be unveiled later this month.</p><p>The oil and gas industry, and its political allies, have complained that new regulations would be too onerous and risk pushing up fuel costs. “The current administration has made its intentions clear – it is determined to target our flourishing oil and gas sector, despite its substantial progress in reducing methane emissions, irrespective of how it might impact American energy security, reliability, and consumer cost,” Senator Joe Manchin, a centrist Democrat and coal company owner, <a href="https://www.manchin.senate.gov/newsroom/press-releases/manchin-urges-epa-to-reconsider-proposed-methane-rules" data-link-name="in body link">wrote</a> to the EPA leadership recently.</p><p>But Rostand said that governments, set to gather at the <a href="https://www.theguardian.com/environment/cop28" data-link-name="in body link">Cop28</a> United Nations climate talks later this month, need to deliver quick and rapid cuts in methane if the world, on track to experience its hottest year ever recorded, is to act on the climate crisis.</p><p>“Cutting methane would have the same benefit to the climate as removing all cars and trucks from the road,” he said. “This really should be the ‘Cop of methane’. If the US and Europe, which is the largest importer of natural gas, act, then it will just be the best possible news for the climate.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is AI the Next Crypto? Insights from 2M HN Comments (207 pts)]]></title>
            <link>https://openpipe.ai/blog/hn-ai-crypto</link>
            <guid>38193978</guid>
            <pubDate>Wed, 08 Nov 2023 17:39:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openpipe.ai/blog/hn-ai-crypto">https://openpipe.ai/blog/hn-ai-crypto</a>, See on <a href="https://news.ycombinator.com/item?id=38193978">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p><a href="https://openpipe.ai/" target="_blank" rel="noopener"><em>OpenPipe</em></a><em> is a platform that makes it easy to convert your existing prompts and completions into a task-specific fine-tuned model. You can get started in a few minutes and the fine-tuned model is often cheaper, faster and often more accurate than the prompt you started with.</em></p><p><a href="https://www.wsj.com/articles/ai-silicon-valley-crypto-boom-blockchain-artificial-intelligence-59622e9c" rel="noopener">Plenty</a> <!-- --><a href="https://www.theatlantic.com/newsletters/archive/2023/01/ai-is-not-the-new-crypto/672746/" rel="noopener">of</a> <!-- --><a href="https://www.reuters.com/breakingviews/biden-ai-plan-is-one-step-avoiding-crypto-trap-2023-10-30/" rel="noopener">observers</a> have noted the similarities between crypto’s frothy history and the current boom in AI. Crypto seems to have busted, at least for the moment — is AI next?<!-- --></p><p>Just for fun, I decided to analyze some data on the question. Both crypto and AI have been heavily debated on <!-- --><a href="https://news.ycombinator.com/" rel="noopener">Hacker News</a>, with discussions going back years. By looking at trends in HN commenter opinions we might find interesting similarities and differences.<!-- --></p><h3>Gathering the data</h3><p><em>Note: if you want to follow along at home, I uploaded the public dataset of all HN posts and comments </em><a href="https://huggingface.co/datasets/OpenPipe/hacker-news" rel="noopener"><em>here</em></a><em>. I also included all the code used in this analysis</em> <!-- --><a href="https://github.com/corbt/hn-analysis" target="_blank" rel="noopener"><em>here</em></a><em>, but be warned, it's research grade at best!</em></p><p>To get started, I used the <!-- --><a href="https://github.com/HackerNews/API" rel="noopener">HN API</a> to pull all 38 million posts and comments in HN history. Using <!-- --><a href="https://www.pola.rs/" rel="noopener">Polars</a>, we can narrow the dataset to only include front-page stories since 2010:<!-- --></p><div><pre translate="no"><code><span>stories</span> = <!-- --><span>hn</span>.<!-- --><span>filter</span><span>(</span>
    <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"type"</span><span>)</span> == <!-- --><span>"story"</span><span>)</span>
    &amp; <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"text"</span><span>)</span>.<!-- --><span>is_null</span><span>(</span><span>)</span><span>)</span>
    &amp; <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"url"</span><span>)</span>.<!-- --><span>is_not_null</span><span>(</span><span>)</span><span>)</span>
    &amp; <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"score"</span><span>)</span> &gt;= <!-- --><span>30</span><span>)</span>
    &amp; <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"descendants"</span><span>)</span> &gt;= <!-- --><span>5</span><span>)</span>
    &amp; <!-- --><span>(</span><span>pl</span>.<!-- --><span>col</span><span>(</span><span>"time"</span><span>)</span> &gt;= <!-- --><span>datetime</span><span>(</span><span>2010</span><span>,</span> <!-- --><span>1</span><span>,</span> <!-- --><span>1</span><span>)</span><span>)</span>
<!-- --><span>)</span>
# -&gt; <!-- --><span>285</span><span>,</span><span>603</span> <!-- --><span>stories</span></code></pre></div><p>285K stories is still a lot to go through! A simple approach to sort these posts into categories might involve a keyword search for strings like “Bitcoin,” “Blockchain,” “Crypto”, etc. But that would produce a lot of false negatives — stories like <!-- --><a href="https://news.ycombinator.com/item?id=28142437" rel="noopener">Technical Analysis of the Poly Network Hack</a> and <!-- --><a href="https://news.ycombinator.com/item?id=30303903" rel="noopener">Kimchi: The latest update to Mina’s proof system</a> would easily get missed.<!-- --></p><h3>Throwing GPT-3.5 at the problem</h3><p>Instead of naive string matching, let’s use an LLM! I prepared a dataset of all 285K front-page stories along with the top comment on each, since sometimes the story title alone doesn’t provide enough information. Let’s roughly calculate the cost of classifying this dataset using GPT-3.5:</p><div><pre translate="no"><code><span>avg_chars</span> = <!-- --><span>(</span>
    <!-- --><span>stories</span><span>[</span><span>"top_comment"</span><span>]</span>.<!-- --><span>str</span>.<!-- --><span>len_chars</span><span>(</span><span>)</span>.<!-- --><span>mean</span><span>(</span><span>)</span>
    + <!-- --><span>stories</span><span>[</span><span>"title"</span><span>]</span>.<!-- --><span>str</span>.<!-- --><span>len_chars</span><span>(</span><span>)</span>.<!-- --><span>mean</span><span>(</span><span>)</span>
    + <!-- --><span>stories</span><span>[</span><span>"url"</span><span>]</span>.<!-- --><span>str</span>.<!-- --><span>len_chars</span><span>(</span><span>)</span>.<!-- --><span>mean</span><span>(</span><span>)</span>
<!-- --><span>)</span>

# <!-- --><span>A </span><span>token </span><span>averages </span><span>to </span><span>4</span>-<!-- --><span>5</span> <!-- --><span>chars</span> <!-- --><span>in</span> <!-- --><span>English</span>
<!-- --><span>avg_input_tokens</span> = <!-- --><span>avg_chars</span> * <!-- --><span>0.2</span>

# <!-- --><span>Add </span><span>extra </span><span>tokens </span><span>for</span> <!-- --><span>the </span><span>task </span><span>instructions</span>
<!-- --><span>avg_input_tokens</span> += <!-- --><span>100</span>

<!-- --><span>total_input_tokens</span> = <!-- --><span>avg_input_tokens</span> * <!-- --><span>len</span><span>(</span><span>stories</span><span>)</span>

# <!-- --><span>Simple </span><span>task </span><span>to </span><span>classify </span><span>across </span><span>both </span><span>categories</span><span>,</span> <!-- --><span>assume </span><span>20</span> <!-- --><span>output </span><span>tokens</span>
<!-- --><span>total_output_tokens</span> = <!-- --><span>20</span> * <!-- --><span>len</span><span>(</span><span>stories</span><span>)</span>

<!-- --><span>input_token_price</span> = <!-- --><span>0.001</span> / <!-- --><span>1000</span>
<!-- --><span>output_token_price</span> = <!-- --><span>0.002</span> / <!-- --><span>1000</span>

<!-- --><span>approx_cost</span> = <!-- --><span>(</span>
    <!-- --><span>total_input_tokens</span> * <!-- --><span>input_token_price</span> + <!-- --><span>total_output_tokens</span> * <!-- --><span>output_token_price</span>
<!-- --><span>)</span></code></pre></div><p>The total cost comes to $86 — not bad to classify every HN front page story for the last 13 years!</p><p>Once we’ve classified these stories, we can use Polars and <!-- --><a href="https://seaborn.pydata.org/" rel="noopener">Seaborn</a> to graph the popularity of AI and blockchain as fractions of all stories posted:<!-- --></p><p><img alt="" data-framer-asset="data:framer/asset-reference,ZWJydQFoH8oQBxdaI85imoaw.png" data-framer-height="678" data-framer-width="868" height="339" src="https://framerusercontent.com/images/ZWJydQFoH8oQBxdaI85imoaw.png" width="434"></p><p>Cool! I noticed a couple of surprises on this graph:</p><ul><li data-preset-tag="p"><p>With the exception of the initial 2013-2014 crypto wave, ML consistently occupied a larger fraction of front-page stories over the last 13 years.</p></li><li data-preset-tag="p"><p>There was a large, long-lived bump in AI/ML stories that peaked in 2018 and tailed off until 2022, when the current wave of LLM hype began.</p></li></ul><h3>Vibes-based commenting</h3><p>Ok, fraction of all posts is an interesting metric, but I’d love to know how HN commenters <!-- --><strong>feel</strong> about the topics… is there a way to answer that question (without breaking the bank)?<!-- --></p><p>First off, I prepared a dataset of all comments on stories that were classified as either crypto or AI-related. That gets me 2.1M comments. Classifying sentiment toward a particular <!-- --><em>topic</em> is probably too complex for a classical sentiment analysis model (someone could write an angry comment defending crypto), so let’s try GPT-3.5 again. To test, I uploaded 4000 comments to a dataset on <!-- --><a href="https://openpipe.ai/" rel="noopener">OpenPipe</a>*, labeled them with both GPT-3.5 and GPT-4 (you can see the prompt I used <!-- --><a href="https://github.com/corbt/hn-analysis/blob/main/generate-story-classification-training-data.ipynb" target="_blank" rel="noopener">here</a>), and used the evals page to compare the outputs side by side:<!-- --></p><p><img alt="" data-framer-asset="data:framer/asset-reference,pqiczRAkz0mCo1XVtT48rWOoK4.png" data-framer-height="1050" data-framer-width="2350" height="525" src="https://framerusercontent.com/images/pqiczRAkz0mCo1XVtT48rWOoK4.png" width="1175"></p><p>You can see at the top right that GPT-3.5 agrees with GPT-4 (labeled as “Original Output”) only 71.5% of the time. That’s not great, since there are only 3 possible classes. Using filters, I can quickly find the outputs that don’t match, and GPT-4’s answers are clearly better most of the time. Ok fine, how much would it cost to just use GPT-4 then? After all, OpenAI just released price cuts!</p><div><pre translate="no"><code># <!-- --><span>Found </span><span>on </span><span>OpenPipe</span>
<!-- --><span>average_input_tokens</span> = <!-- --><span>446</span>
<!-- --><span>average_output_tokens</span> = <!-- --><span>20</span>

<!-- --><span>input_token_price</span> = <!-- --><span>0.01</span> / <!-- --><span>1000</span>
<!-- --><span>output_token_cost</span> = <!-- --><span>0.03</span> / <!-- --><span>1000</span>

<!-- --><span>total_cost</span> = <!-- --><span>(</span>
    <!-- --><span>input_token_price</span> * <!-- --><span>average_input_tokens</span> + <!-- --><span>output_token_cost</span> * <!-- --><span>average_output_tokens</span>
<!-- --><span>)</span> * <!-- --><span>len</span><span>(</span><span>crypto_ai_comments</span><span>)</span></code></pre></div><p>Ok, GPT-4 can get the job done for… $10K. Hmm. We could stick with GPT-3.5, but its accuracy isn’t great. And it would still cost $1K, for less trustworthy results.</p><p>We do have another option though, which is to fine-tune our own model! By using fine tuning, we can get better accuracy with a much smaller model than we'd be able to with a general-purpose prompted model. Smaller models mean faster inference, and much lower prices. If you're interested in learning more or doing fine-tuning on your own, we created a guide that you can find <!-- --><a href="https://news.ycombinator.com/item?id=37484135" target="_blank" rel="noopener">here</a>. The OpenPipe platform also makes creating a fine-tuned model incredibly easy — it’s literally 2 clicks once your dataset is generated.<!-- --></p><p>In this case we'll fine-tune a <!-- --><a href="https://mistral.ai/news/announcing-mistral-7b/" rel="noopener">Mistral 7B</a> model on the dataset. Mistral 7B is one of the strongest LLMs in its size class right now, beating the similarly-sized Llama 2 variant on most benchmarks.<!-- --></p><p><img alt="" data-framer-asset="data:framer/asset-reference,VYvRqfqaORUyzMf7EZHffJQo33Y.png" data-framer-height="636" data-framer-width="1362" height="318" src="https://framerusercontent.com/images/VYvRqfqaORUyzMf7EZHffJQo33Y.png" width="681"></p><p>I went ahead and did that fine-tune, and added it to the evals page. And since it’s using the same dataset as before, we can compare it head to head with the GPT-3.5 prompt from earlier. We’ve improved our match rate with GPT-4 from 71.5% to 87.8% — not bad!</p><p><img alt="" data-framer-asset="data:framer/asset-reference,byqF3DClm3THkzpjTDCpbSFx0zE.png" data-framer-height="552" data-framer-width="1978" height="276" src="https://framerusercontent.com/images/byqF3DClm3THkzpjTDCpbSFx0zE.png" width="989"></p><p>Of the 12.2% that our fine tune still got wrong, I quickly reviewed a few dozen. In many cases, there really are multiple “correct” answers — for example, GPT-4 classified <!-- --><a href="https://news.ycombinator.com/item?id=24384570" rel="noopener">this comment</a> as positive towards AI, and the fine-tune classified it as neutral. I think both answers are defensible.<!-- --></p><h3>Just the Facts</h3><p>Ok, let’s plot user sentiment over time! On this graph each negative comment counts for -1 and each positive comment is +1, and I compute a rolling average over a 6-month window.</p><p><img alt="" data-framer-asset="data:framer/asset-reference,cjyaYBc1dlrNPkRp2I9CEW0fIvs.png" data-framer-height="678" data-framer-width="868" height="339" src="https://framerusercontent.com/images/cjyaYBc1dlrNPkRp2I9CEW0fIvs.png" width="434"></p><p>Interesting! A couple of observations:</p><ul><li data-preset-tag="p"><p>While sentiment towards AI has always been higher than sentiment towards crypto, AI sentiment steadily dropped from 2010-2018 and has been hovering around neutral for the last 5 years.</p></li><li data-preset-tag="p"><p>Crypto sentiment has a much weaker correlation with the crypto hype cycle than I’d expected. Although it seems like right now not many commenters are popping up to defend FTX/SBF. 😂</p></li></ul><p>Ok so admittedly, we haven’t come away with a clean answer to the question in the title (although for the record, I think the answer is “no”). But we’ve found some interesting trends in the stories posted on the front page of HN, as well as the way the average commenter’s opinion has shifted over time. And hopefully we’ve also learned more about how modern LLM-based tools can solve problems in a few hours that only a couple years ago would have taken an ML team weeks!</p><h2>Addendum: HN Sentiment Overall</h2><p>HN user dragonwriter <!-- --><a href="https://news.ycombinator.com/item?id=38194850" target="_blank" rel="noopener">noted that</a> up until recently, sentiment towards crypto and AI was relatively strongly correlated, and wondered if that was an artifact of HN sentiment just getting more negative overall.<!-- --></p><p>I had actually already run the same analysis for Rust and remote work when preparing this post, and removed them in the interest of brevity. Here's the comment sentiment graph with those added back in:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,wU9wtdqeY6xL4fYqy5MgqB1Ag.png" data-framer-height="678" data-framer-width="868" height="339" src="https://framerusercontent.com/images/wU9wtdqeY6xL4fYqy5MgqB1Ag.png" width="434"></p><p>Interestingly, there is in fact a noticeable downward slope in average sentiment over time for those topics as well, although they both remain far more popular than either AI or crypto.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automerge-Repo: A "batteries-included" toolkit for local-first applications (166 pts)]]></title>
            <link>https://automerge.org/blog/2023/11/06/automerge-repo/</link>
            <guid>38193640</guid>
            <pubDate>Wed, 08 Nov 2023 17:19:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://automerge.org/blog/2023/11/06/automerge-repo/">https://automerge.org/blog/2023/11/06/automerge-repo/</a>, See on <a href="https://news.ycombinator.com/item?id=38193640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>Today we are announcing our new library, <a href="https://github.com/automerge/automerge-repo" target="_blank" rel="noopener noreferrer"><code>automerge-repo</code></a>, which makes it vastly easier to build local-first applications with Automerge. Take a look at our <a href="https://automerge.org/docs/quickstart/">quickstart guide</a> or read on for some background and examples.</p><p>For those new to this idea: local-first applications are a way of building software that allows both real-time collaboration (think Google Docs) and offline working (think Git). They work by storing the user's data locally, on their own device, and syncing it with collaborators in the background. You can read more about the motivation for local-first software <a href="https://inkandswitch.com/local-first/" target="_blank" rel="noopener noreferrer">in our essay</a>, or watch a <a href="https://www.youtube.com/watch?v=PHz17gwiOc8" target="_blank" rel="noopener noreferrer">talk introducing the idea</a>.</p><p>A challenge in local-first software is how to merge edits that were made independently on different devices, and <a href="https://crdt.tech/" target="_blank" rel="noopener noreferrer">CRDTs</a> were developed to solve this problem. Automerge is a fairly mature CRDT implementation. In fact, we wrote this blog post using it! The API is quite low-level though, and Automerge-Core has no opinion about how networking or storage should be done. Often, the first thing developers ask after discovering Automerge was how to connect it into an actual application.</p><p>Our new library, <code>automerge-repo</code>, extends the collaboration engine of Automerge-Core with networking and storage adapters, and provides integrations with React and other UI frameworks. You can get to building your app straight away by taking advantage of default implementations that solve common problems such as how to send binary data over a WebSocket, how often to send synchronization messages, what network format to use, or how to store data in places like the browser's IndexedDB or on the filesystem.</p><p>If you've been intimidated by the effort of integrating Automerge into your application because of these choices, this library is for you. Now you can simply create a repo, point it to a sync server, and get to work on your app.</p><h2 id="automerge-repo-a-simple-example"><code>automerge-repo</code>: a simple example<a href="#automerge-repo-a-simple-example" aria-label="Direct link to automerge-repo-a-simple-example" title="Direct link to automerge-repo-a-simple-example">​</a></h2><p>Let's start by taking a look at a simple example of how <code>automerge-repo</code> works. To begin, create and configure a repository for Automerge documents.</p><div><pre tabindex="0"><code><span><span>const repo = new Repo({</span><br></span><span><span>  storage: new IndexedDBStorageAdapter("automerge-demo"),</span><br></span><span><span>  network: [new WebsocketClientNetworkAdapter("wss://sync.automerge.org")]</span><br></span><span><span>})</span><br></span></code></pre></div><p>The code in the example above creates a repository and adds a storage and network adapter to it. It tells <code>automerge-repo</code> to store all changes in an IndexedDB table called <code>automerge-demo</code> and to synchronize documents with the WebSocket server at <code>sync.automerge.org</code>. The library is designed to support a wide variety of network transports, and we include a simple client/server WebSocket adapter out of the box. Members of the community are already adding support for other transports, such as WebRTC.</p><p>In this example we're connecting to the public test server hosted by the Automerge team, but you can also run your own sync server. In fact, our <a href="https://github.com/automerge/automerge-repo-sync-server" target="_blank" rel="noopener noreferrer">sync server</a> runs almost the same code as above, but with a different network and storage adapter.</p><div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</p><p>The Automerge project provides a public sync server for you to experiment with <code>sync.automerge.org</code>. This is not a private instance, and as an experimental service has no reliability or data safety guarantees. Basically, it's good for demos and prototyping, but run your own sync server for production uses.</p></div><p>Next, create a document and make some changes to it:</p><div><pre tabindex="0"><code><span><span>   &gt; const handle = repo.create()</span><br></span><span><span>   &gt; handle.change(doc =&gt; { doc.hello = "World." })</span><br></span><span><span>   &gt; console.log(handle.url)</span><br></span><span><span>   automerge:2j9knpCseyhnK8izDmLpGP5WMdZQ</span><br></span></code></pre></div><p>The code logs a URL to the document you created. On another computer, or in another browser, you could load this document using the same URL, as shown below:</p><div><pre tabindex="0"><code><span><span>   &gt; const handle = repo.find("automerge:2j9knpCseyhnK8izDmLpGP5WMdZQ")</span><br></span><span><span>   &gt; console.log(await handle.doc())</span><br></span><span><span>   // why don't you try it and find out?</span><br></span></code></pre></div><p>What's happening here to make all this work? <code>automerge-repo</code> wraps the core Automerge library and handles all the work of moving the bytes around to make your application function.</p><h2 id="key-concepts--basic-usage">Key Concepts &amp; Basic Usage<a href="#key-concepts--basic-usage" aria-label="Direct link to Key Concepts &amp; Basic Usage" title="Direct link to Key Concepts &amp; Basic Usage">​</a></h2><p>Let's go into a bit more detail. For full documentation please see <a href="https://automerge.org/docs/repositories/" target="_blank" rel="noopener noreferrer">the docs</a>.</p><h3 id="repo">Repo<a href="#repo" aria-label="Direct link to Repo" title="Direct link to Repo">​</a></h3><p>Create a repo by initializing it with an optional storage plugin and any number of network adapters. These are the options for initializing a repo:</p><div><pre tabindex="0"><code><span><span>export interface RepoConfig {</span><br></span><span><span>  // A unique identifier for this peer, the default is a random id</span><br></span><span><span>  peerId?: PeerId</span><br></span><span><span>  // Something which knows how to store and retrieve binary blobs</span><br></span><span><span>  storage?: StorageAdapter</span><br></span><span><span>  // Something which knows how to send and receive sync messages</span><br></span><span><span>  network: NetworkAdapter[]</span><br></span><span><span>  // A function which determines whether to share a document with a peer</span><br></span><span><span>  sharePolicy?: SharePolicy</span><br></span><span><span>}</span><br></span></code></pre></div><p>Don't let the usage of "peer" confuse you into thinking this is limited to peer to peer connectivity, <code>automerge-repo</code> works with both client-server and peer-to-peer network transports.</p><p>The main methods on Repo are <code>find(url)</code> and <code>create()</code>, both of which return a <code>DocHandle</code> you can work with.</p><h3 id="handle--automerge-urls">Handle &amp; Automerge URLs<a href="#handle--automerge-urls" aria-label="Direct link to Handle &amp; Automerge URLs" title="Direct link to Handle &amp; Automerge URLs">​</a></h3><p>A <code>DocHandle</code> is a reference to an Automerge document that a <code>Repo</code> syncs and stores . The <code>Repo</code> instance saves any changes you make to the document and syncs with connected peers. Likewise, you can listen over the network for to a <code>Repo</code> for any changes it received.</p><p>Each <code>DocHandle</code> has a <code>.url</code> property. This is a string which uniquely identifies a document in the form <code>automerge:&lt;base58 encoded bytes&gt;</code>. Once you have a URL you can use it to request the document from other peers.</p><h3 id="dochandledoc-and-dochandledocsync"><code>DocHandle.doc()</code> and <code>DocHandle.docSync()</code><a href="#dochandledoc-and-dochandledocsync" aria-label="Direct link to dochandledoc-and-dochandledocsync" title="Direct link to dochandledoc-and-dochandledocsync">​</a></h3><p>These two methods return the current state of the document. <code>doc()</code> is an asynchronous method that resolves when a repository loads the document from storage or retrieves it from a peer (whichever happens first), and <code>docSync()</code> is a synchronous method that assumes the document is already available.
The examples below illustrate asynchronously loading a document or synchronously loading a document and then interacting with it:</p><div><pre tabindex="0"><code><span><span>&gt; const handle = repo.find("automerge:2j9knpCseyhnK8izDmLpGP5WMdZQ")</span><br></span><span><span>&gt; const doc = await handle.doc()</span><br></span><span><span>&gt; console.log(doc)</span><br></span></code></pre></div><p>Or </p><div><pre tabindex="0"><code><span><span>&gt; const handle = repo.find("automerge:2j9knpCseyhnK8izDmLpGP5WMdZQ")</span><br></span><span><span>&gt; handle.whenReady().then(() =&gt; {</span><br></span><span><span>  console.log(handle.docSync())</span><br></span><span><span>})</span><br></span></code></pre></div><p>In this latter example we use <code>DocHandle.whenReady</code>, which returns a promise that the repository resolves when it loads a document from storage or fetches it from another peer in the network.</p><h3 id="change-and-onchange"><code>change()</code> and <code>on("change")</code><a href="#change-and-onchange" aria-label="Direct link to change-and-onchange" title="Direct link to change-and-onchange">​</a></h3><p>Use <code>DocHandle.change</code> when you modify a document.</p><div><pre tabindex="0"><code><span><span>&gt; const handle = repo.find("automerge:2j9knpCseyhnK8izDmLpGP5WMdZQ")</span><br></span><span><span>&gt; await handle.doc()</span><br></span><span><span>&gt; handle.change(d =&gt; d.foo = "bar")</span><br></span></code></pre></div><p>The <code>Repo</code> calls <code>DocHandle.on("change")</code> whenever the document is modified – either due to a local change or a sync message being received from another peer.</p><div><pre tabindex="0"><code><span><span>&gt; const handle = repo.find("automerge:4CkUej7mAYnaFMfVnffDipc4Mtvn")</span><br></span><span><span>&gt; await handle.doc()</span><br></span><span><span>&gt; handle.on("change", ({doc}) =&gt; {</span><br></span><span><span>  console.log("document changed")</span><br></span><span><span>  console.log("New content: ", doc)</span><br></span><span><span>})</span><br></span></code></pre></div><h2 id="integrations">Integrations<a href="#integrations" aria-label="Direct link to Integrations" title="Direct link to Integrations">​</a></h2><p><code>automerge-repo</code> provides a set of primitives that you can use to build a wide range of applications. To make this easier, we have built integrations with a few common UI frameworks. You can easily add further integrations and we welcome contributions which integrate with popular frameworks!</p><h3 id="react-integration">React Integration<a href="#react-integration" aria-label="Direct link to React Integration" title="Direct link to React Integration">​</a></h3><p><a href="https://www.npmjs.com/package/@automerge/automerge-repo-react-hooks" target="_blank" rel="noopener noreferrer"><code>@automerge/automerge-repo-react-hooks</code></a> makes it easy to use <code>automerge-repo</code> in a React application. Once you've constructed a <code>Repo</code> you can make it available to your React application using <a href="https://automerge.org/automerge-repo/variables/_automerge_automerge_repo_react_hooks.RepoContext.html" target="_blank" rel="noopener noreferrer"><code>RepoContext</code></a>. Once available, call <code>useHandle</code> to obtain a <code>DocHandle</code>:</p><div><pre tabindex="0"><code><span><span>function TodoList(listUrl: AutomergeUrl) {</span><br></span><span><span>    const handle = useHandle(listUrl)</span><br></span><span><span>    // render the todolist</span><br></span><span><span>}</span><br></span></code></pre></div><p>Note that when <code>Repo</code> receives changes over the network or registers local changes, the original Automerge document remains immutable, and any modified parts of the document get new objects. This means that React will only re-render the parts of the UI that depend on a part of the document that has changed.</p><h3 id="svelte-integration">Svelte Integration<a href="#svelte-integration" aria-label="Direct link to Svelte Integration" title="Direct link to Svelte Integration">​</a></h3><p><a href="https://www.npmjs.com/package/@automerge/automerge-repo-svelte-store" target="_blank" rel="noopener noreferrer"><code>@automerge/automerge-repo-svelte-store</code></a> provides <code>setContextRepo</code> to set the <code>Repo</code> which is used by the <code>document</code> store:</p><div><pre tabindex="0"><code><span><span>&lt;script lang="ts"&gt;</span><br></span><span><span>  import { document } from "@automerge/automerge-repo-svelte-store"</span><br></span><span><span>  import { type AutomergeUrl } from "@automerge/automerge-repo"</span><br></span><span><span></span><br></span><span><span>  export let documentUrl: AutomergeUrl</span><br></span><span><span></span><br></span><span><span>  // Doc is an automerge store with a `change` method which accepts</span><br></span><span><span>  // a standard automerge change function</span><br></span><span><span>  const doc = document&lt;HasCount&gt;(documentUrl)</span><br></span><span><span>  const increment = () =&gt; {</span><br></span><span><span>    doc.change((d: HasCount) =&gt; (d.count = (d.count || 0) + 1))</span><br></span><span><span>  }</span><br></span><span><span>&lt;/script&gt;</span><br></span><span><span></span><br></span><span><span>&lt;button on:click={increment}&gt;</span><br></span><span><span>  count is {$doc?.count || 0}</span><br></span><span><span>&lt;/button&gt;</span><br></span></code></pre></div><h2 id="what-about-x">What about <!-- -->&lt;<!-- -->X<!-- -->&gt;<!-- -->?<a href="#what-about-x" aria-label="Direct link to what-about-x" title="Direct link to what-about-x">​</a></h2><p>We'd love to help you make automerge work in your favorite development environment! Please reach out to us on GitHub or via <a href="https://join.slack.com/t/automerge/shared_invite/zt-e4p3760n-kKh7r3KRH1YwwNfiZM8ktw" target="_blank" rel="noopener noreferrer">our Slack</a>.</p><h2 id="extending-automerge-repo">Extending <code>automerge-repo</code><a href="#extending-automerge-repo" aria-label="Direct link to extending-automerge-repo" title="Direct link to extending-automerge-repo">​</a></h2><p>You can extend <code>automerge-repo</code> by writing new storage or network adapters.</p><h3 id="storage-adapters">Storage Adapters<a href="#storage-adapters" aria-label="Direct link to Storage Adapters" title="Direct link to Storage Adapters">​</a></h3><p>A storage adapter represents some kind of backend that stores the data in a repo. Storage adapters can be implemented for any key/value store that allows you to query a range of keys with a given prefix. There is no concurrency control required (that's implemented in <code>automerge-repo</code>) so you can safely have multiple repos pointing at the same storage. For example, you could implement an adapter on top of Redis.</p><p>The <code>automerge-repo</code> library provides storage adapters for IndexedDB and the file system (on Node).</p><h3 id="network-adapters">Network Adapters<a href="#network-adapters" aria-label="Direct link to Network Adapters" title="Direct link to Network Adapters">​</a></h3><p>A network adapter represents a way of connecting to other peers. Network adapters raise events when a new peer is discovered or when a message is recieved, and implement a <code>send</code> method for transmitting messages to another peer. <code>automerge-repo</code> assumes a reliable, in-order transport for each peer; as long as you can provide this (e.g. using a TCP connection), you can implement an adapter. You could implement an adapter for <a href="https://en.wikipedia.org/wiki/Bluetooth_Low_Energy" target="_blank" rel="noopener noreferrer">BLE</a>, for example.</p><p>The <code>automerge-repo</code> library provides network adapters for WebSocket, MessageChannel, and BroadcastChannel.</p><h3 id="other-languagesplatforms">Other languages/platforms<a href="#other-languagesplatforms" aria-label="Direct link to Other languages/platforms" title="Direct link to Other languages/platforms">​</a></h3><p>This release of <code>automerge-repo</code> is just for javascript. Automerge is a multi-language library though and there are efforts under way to implement <code>automerge-repo</code> on other platforms. The most mature of these is <a href="https://github.com/automerge/automerge-repo-rs" target="_blank" rel="noopener noreferrer"><code>automerge-repo-rs</code></a>. We welcome contributions and please reach out if you're starting to develop <code>automerge-repo</code> for a new platform.</p><h2 id="beta-quality">Beta Quality<a href="#beta-quality" aria-label="Direct link to Beta Quality" title="Direct link to Beta Quality">​</a></h2><p><code>automerge-repo</code> works pretty well – we're using it at <a href="https://www.inkandswitch.com/" target="_blank" rel="noopener noreferrer">Ink &amp; Switch</a> for a bunch of internal projects. The basic shape of the API is simple and useful, and not having to think about the plumbing makes it much, much faster to get a useful application off the ground. However, there are some performance problems we're working on:</p><ol><li>Documents with large histories (e.g. a collaboratively edited document with &gt;60,000 edits) can be slow to sync.</li><li>The sync protocol currently requires that a document it is syncing be loaded into memory. This means that a sync server can struggle to handle a lot of traffic on large documents.</li></ol><p>These two points mean that we're not ready to say this project is ready for production. </p><p>We're working hard on fixing the performance so that we <em>can</em> say this is ready for production. But if you are interested in experimenting with the library now, or if you are only going to be working with relatively small documents or low traffic sync servers then you are good to go!</p><p>(If you want us to get to production faster, or you have some specific requirements, please consider <a href="https://github.com/sponsors/automerge" target="_blank" rel="noopener noreferrer">sponsoring</a> Automerge development 🙂)</p><p>Finally, we don't want to give the impression that everything is smooth sailing. <code>automerge-repo</code> solves a bunch of the hard problems people were encountering around networking and storage. There are still plenty of other difficult problems in local first software where we don't have turnkey solutions: authentication and authorization, end-to-end encryption, schema changes, version control workflows etc. <code>automerge-repo</code> makes many things much easier, but it's a frontier out here.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Original photo from Led Zeppelin IV album cover discovered (118 pts)]]></title>
            <link>https://www.bbc.com/news/uk-england-wiltshire-67336495</link>
            <guid>38193494</guid>
            <pubDate>Wed, 08 Nov 2023 17:11:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/uk-england-wiltshire-67336495">https://www.bbc.com/news/uk-england-wiltshire-67336495</a>, See on <a href="https://news.ycombinator.com/item?id=38193494">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" data-testid="main-content"><article><header></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 240w, https://ichef.bbci.co.uk/news/320/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 320w, https://ichef.bbci.co.uk/news/480/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 480w, https://ichef.bbci.co.uk/news/624/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 624w, https://ichef.bbci.co.uk/news/800/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 800w, https://ichef.bbci.co.uk/news/976/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg.webp 976w" type="image/webp"><img alt="Black and white photo of a thatcher. He has a grey beard and weathered face and is stooping. His hands hold a pole supporting a bundle of hazel on his back." srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 240w, https://ichef.bbci.co.uk/news/320/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 320w, https://ichef.bbci.co.uk/news/480/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 480w, https://ichef.bbci.co.uk/news/624/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 624w, https://ichef.bbci.co.uk/news/800/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 800w, https://ichef.bbci.co.uk/news/976/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg 976w" src="https://ichef.bbci.co.uk/news/976/cpsprodpb/915E/production/_131641273_wiltshirethatcheredit.jpg" width="976" height="549" loading="eager"></picture></span><span role="text"><span>Image source, </span>Wiltshire Museum, Devizes</span></p><figcaption><span>Image caption, </span><p>The black and white picture was found in a Victorian photo album</p></figcaption></figure></div><div data-component="text-block"><p><b>A man depicted on the album cover of Led Zeppelin IV has been revealed as a 19th Century thatcher.</b></p></div><div data-component="text-block"><p>The figure is most likely Lot Long from Mere in Wiltshire, photographed by Ernest Farmer.</p></div><div data-component="text-block"><p>Brian Edwards, from the University of the West of England (UWE), found the original picture when looking through a photograph album for other research.</p></div><div data-component="text-block"><p>"I instantly recognised the man with the sticks - he's often called the stick man," he said.</p></div><div data-component="text-block"><p>A long-time fan of British rock band Led Zeppelin, he told <a href="https://www.bbc.co.uk/sounds/play/p0grhlnb">BBC Radio Wiltshire</a> "it was quite a revelation".  </p></div><div data-component="text-block"><p><a href="https://www.wiltshiremuseum.org.uk/">Wiltshire Museum</a> has since acquired the photograph and plans to include it in an exhibition next year.</p></div><div data-component="text-block"><p>Released in 1971, Led Zeppelin IV has sold more than 37 million copies worldwide and includes the huge hit Stairway to Heaven. </p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Steve Parsons/PA</span></p><figcaption><span>Image caption, </span><p>Robert Plant is said to have found a colourised version of the Victorian photo in an antiques shop</p></figcaption></figure></div><div data-component="text-block"><p>The cover art had previously been described as a photograph of a painting, which was reportedly discovered by the band's lead singer, Robert Plant, in an antique shop near guitarist Jimmy Page's house in Berkshire. </p></div><div data-component="text-block"><p>But the framed image which can be seen on the cover is actually a colourised photograph, the whereabouts of which is now unknown.</p></div><div data-component="text-block"><p>Mr Edwards - who is part of the regional history centre at UWE in Bristol - explained how he worked out the original photographer was Ernest Farmer, who died in 1944.</p></div><div data-component="text-block"><p>The only clue in the photo album was the photographer's name Ernest, but Mr Edwards discovered hundreds of Victorian photographers with that name. </p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Wiltshire Museum, Devizes</span></p><figcaption><span>Image caption, </span><p>Brian Edwards said he instantly recognised the thatcher</p></figcaption></figure></div><div data-component="text-block"><p>He said the quality of the photos suggested they were taken by a professional, and so he looked for chemists, as many of them were involved in photography.</p></div><div data-component="text-block"><p>Mr Edwards discovered a chemist working in Salisbury, close to where the picture was taken, who had a son called Ernest Farmer, and then found his handwriting online.</p></div><div data-component="text-block"><p>Mr Farmer was the first head of the school of photography at the then newly-renamed Polytechnic Regent Street, now the University of Westminster. </p></div><div data-component="text-block"><p>"Part of the signatures matches some of the handwriting in the album," he said. </p></div><div data-component="text-block"><p>"The black and white photograph has a thumbprint in the corner - it looks like it's the original," Mr Edwards added.</p></div><div data-component="text-block"><p>The photo album mostly contains views and architecture from south Wiltshire and Dorset.</p></div><div data-component="text-block"><p>It is titled Reminiscences of a visit to Shaftesbury. Whitsuntide 1892. A present to Auntie from Ernest.</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Wiltshire Museum, Devizes</span></p><figcaption><span>Image caption, </span><p>Ernest Farmer gave the photo album to his aunt</p></figcaption></figure></div><div data-component="text-block"><p>Mr Edwards then set about researching thatchers from that time period, and said his research suggested the man pictured was Lot Long, who died in 1893.</p></div><div data-component="text-block"><p>Wiltshire Museum's director, David Dawson, said the exhibition in spring next year will be called The Wiltshire Thatcher: a Photographic Journey through Victorian Wessex, and will celebrate Ernest Farmer's work.</p></div><div data-component="text-block"><p>"We will show how Farmer captured the spirit of people, villages and landscapes of Wiltshire and Dorset that were so much of a contrast to his life in London.</p></div><div data-component="text-block"><p>"It is fascinating to see how this theme of rural and urban contrasts was developed by Led Zeppelin and became the focus for this iconic album cover 70 years later," he said.</p></div><div data-component="text-block"><p><i>Follow BBC West on </i><a href="https://www.facebook.com/pointswest">Facebook</a><i>, </i><a href="https://twitter.com/bbcbristol">X</a><i> and </i><a href="https://www.instagram.com/bbcwest">Instagram</a><i>. Send your story ideas to: </i><a href="mailto:bristol@bbc.co.uk">bristol@bbc.co.uk </a></p></div><section data-component="links-block"><p><h2>More on this story</h2></p></section><section data-component="related-internet-links"><p><h2>Related Internet Links</h2></p><ul role="list" spacing="responsive"><li></li></ul><p>The BBC is not responsible for the content of external sites.</p></section></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Can Now Film in NYPD Precincts, Thanks to YouTuber's Lawsuit (238 pts)]]></title>
            <link>https://hellgatenyc.com/you-can-now-film-in-nypd-precincts-thanks-to-this-youtuber</link>
            <guid>38191972</guid>
            <pubDate>Wed, 08 Nov 2023 15:43:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hellgatenyc.com/you-can-now-film-in-nypd-precincts-thanks-to-this-youtuber">https://hellgatenyc.com/you-can-now-film-in-nypd-precincts-thanks-to-this-youtuber</a>, See on <a href="https://news.ycombinator.com/item?id=38191972">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On Friday, the metaphorical ink was still drying on a federal court order barring the NYPD from illegally telling people they can't film the police in the public parts of precinct stations, when SeanPaul Reyes, who had sued the police department after being arrested for doing just that, marched into the 75th Precinct station house in East New York, recording with his phone in one hand, a copy of the judge's order in the other hand.</p><p>"We the people did it," Reyes told his livestream audience in a <a href="https://www.youtube.com/watch?v=KYMUGQO9Sck" target="_blank" rel="noreferrer noopener">video broadcast</a> viewed more than 300,000 times so far. "We won." Sporting sunglasses, a neatly trimmed beard, and a baseball cap that read "We the People," Reyes held forth in the precinct lobby, celebrating the victory. A police employee poked her head into the lobby to find out what Reyes wanted. "I want to make a complaint against the NYPD as a whole," he told her. After several minutes, a police sergeant emerged and handed Reyes a complaint form. Reyes asked him for his name and badge number, then thanked him and the precinct for being in compliance with the federal injunction. "I appreciate you guys not being in contempt of court," he said. The sergeant dutifully nodded.</p><p>Reyes filed his lawsuit in July, after being arrested twice for filming in the public areas of NYPD precinct houses. An NYPD policy, announced in signage in every precinct in the city, forbids filming in station houses. To Reyes, who describes himself as a "First Amendment auditor," that rule was meant to be broken. "The police are there for accountability—if you do something wrong, they hold you accountable," Reyes told Hell Gate. "But how do the people hold the police accountable? There has to be some sort of transparency and accountability for how the police treat people on an everyday basis. That's why I record. I just want to show people how public employees treat people."</p><p>Reyes's <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.602637/gov.uscourts.nysd.602637.1.0.pdf" target="_blank" rel="noreferrer noopener">lawsuit</a> argued that the NYPD's policy is improper for three reasons: It violates the First Amendment's protections of free speech; it violates a state law and a New York City law, both known as the <a href="https://www.pubadvocate.nyc.gov/press/nyc-council-passes-right-record-police-transparency-legislation/" target="_blank" rel="noreferrer noopener">Right to Record Act</a>, which explicitly guarantee the right to record the police, anywhere and any time, so long as the person filming isn't interfering with police work or otherwise breaking the law; and the NYPD instituted its policy without following the Citywide Administrative Procedure Act, which specifies the steps a City agency must take before it can put a new rule in place.</p><p>Judge Jessica Clarke, who ordered the injunction last week, ruled that while the First Amendment claim might be a little more complicated, it seems pretty clear that the NYPD violated the state and municipal Right to Record Acts with its policy. "The Right to Record Acts do not carve out police precinct lobbies as places where individuals are not allowed to record," she wrote in her order. Consequently, according to Clarke, Reyes was "likely to succeed on his claims under the Right to Record Acts."</p><p>Based on that likelihood, Clarke issued a temporary injunction barring the NYPD from enforcing its rule and directing it to take down the signs in every police station that forbid filming.&nbsp;</p><p>That's not the end of Reyes's lawsuit—he is seeking a permanent injunction. With this provisional win under their belts, his legal team will now begin to pursue discovery, gathering information about how the NYPD made its rule in the first place and testing whether there's any evidence to support the NYPD's claim that its policy is necessary to protect the privacy of confidential informants and vulnerable victims of crimes who might be discussing delicate matters in the public spaces of precinct houses.</p><p>The YouTube genre of First Amendment auditors is fairly rich, and encompasses everything from kids filming themselves sassing back during traffic stops to steely-eyed libertarians being coolly intransigent at Border Patrol checkpoints deep in the desert. Reyes was a fan of the genre before he was a practitioner. "My brother-in-law, and as well as myself, we used to watch First Amendment audits and police interaction videos," he said. "Traffic stops, going into government agencies and seeing how they really treat members of the public on a daily basis, things of that nature. It always fascinated me how law enforcement and government officials got so upset about somebody recording them, you know? You would think that they would appreciate the transparency."</p><p>When COVID hit, Reyes, a Long Island resident, was furloughed from his job as a logistics director for a manufacturing company, and he found himself with some time on his hands. "I was like, might as well just pick up the camera," Reyes said. "Nobody really is doing it here at Suffolk County." Suffolk County police officers initially reacted very aggressively to Reyes's efforts to film them, he said, "But to their credit, they learned very quickly how to adapt and retrain their officers to allow filming in public areas," Reyes said. "So I branched out."</p><p>That branching out took Reyes all over the country, as tipsters pointed him to departments that were treating people poorly. Reyes says he distinguishes himself from some other First Amendment auditors by being unfailingly polite. He carries himself in his videos with a sort of jovial formality, conscientiously thanking officers for their time. That manner has built him a following—his <a href="https://www.youtube.com/@LongIslandAudit" target="_blank" rel="noreferrer noopener">YouTube channel </a>has more than 578,000 subscribers, and he says that across all his social media platforms, he has more than a quarter-billion views. Those views bring ad revenue, which Reyes now supports himself on, and he employs a team of colleagues as well. His manner has also earned him the respect of some police departments: He says he's been invited to give First Amendment trainings to departments in New Jersey and Ohio. Eventually, Reyes found his way to Brooklyn, where the NYPD's policy barring the public from recording how they are treated in police precincts seemed ripe for a challenge.</p><p>Reyes may be claiming victory against the NYPD, but—the meek welcome its officers offered Reyes on Friday notwithstanding—the department doesn't show any signs of giving up. It has filed notice that it is <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.602637/gov.uscourts.nysd.602637.30.0.pdf" target="_blank" rel="noreferrer noopener">appealing</a> the judge's order to the Second Circuit Court of Appeals. A ruling on that appeal could take years. In the meantime, the NYPD is also seeking a stay of the temporary injunction, allowing the department to continue to bar filming in the meantime.</p><p>Reyes's lawyer, Andrew Case of LatinoJustice PRLDF, said that the NYPD's dogged commitment to the dubiously legal policy is characteristic of how the department has approached the entire case. "The NYPD appears to be very resolute about defending the rule and seems to be unwilling to consider other alternatives, that wouldn't run afoul of the Right to Record law," Case said. The NYPD declined to comment on the order, referring questions to the New York City Law Department.&nbsp;</p><p>"The NYPD is committed to protecting the privacy of victims and keeping New Yorkers safe, particularly inside the public areas in precincts," a Law Department spokesperson told Hell Gate in a statement. "While we are disappointed with the court's ruling, we are encouraged by the court's indication that NYPD's policy has a legitimate basis. We are evaluating the City's legal options."</p><p>The NYPD is also continuing to fight another lawsuit brought over its ban on filming in police stations. Patricia Rodney, a grandmother who was <a href="https://hellgatenyc.com/grandmother-arrested-filming-police" target="_blank" rel="noreferrer noopener">arrested and had her arm broken</a> by police who thought she was filming them in the outer vestibule of the 62nd Precinct station in Dyker Heights, also has an open lawsuit in federal court. Public Advocate Jumaane Williams, who wrote the New York City Right to Record Act, has <a href="https://hellgatenyc.com/nyc-public-advocate-the-nypd-broke-the-law-arrested-grandmother" target="_blank" rel="noreferrer noopener">filed an amicus brief</a> in the case arguing that the NYPD's policy is illegal. The NYPD is seeking to dismiss that case, but the presiding judge has not yet ruled on that motion. The order in Reyes's case isn't binding precedent in Rodney's lawsuit, but it certainly doesn't bode well for the NYPD.&nbsp;</p><p>Back outside the 75th Precinct on Friday, Reyes was ebullient. "This is a major, major win for the people, ladies and gentlemen," he told the camera. "Make sure you guys are smashing that 'like' button and sharing this video so everyone in New York City can see this video and know what we the people can accomplish together. We can accomplish true change. This is just the battle that we won. We still have a war that we need to win."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quake Brutalist Jam II (302 pts)]]></title>
            <link>https://www.slipseer.com/index.php?resources/quake-brutalist-jam-2.278/</link>
            <guid>38191319</guid>
            <pubDate>Wed, 08 Nov 2023 15:02:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.slipseer.com/index.php?resources/quake-brutalist-jam-2.278/">https://www.slipseer.com/index.php?resources/quake-brutalist-jam-2.278/</a>, See on <a href="https://news.ycombinator.com/item?id=38191319">Hacker News</a></p>
Couldn't get https://www.slipseer.com/index.php?resources/quake-brutalist-jam-2.278/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Swedish unions strike: Blocks mail and package deliveries for Tesla (140 pts)]]></title>
            <link>https://www.seko.se/press-och-aktuellt/nyheter/2023/seko-stoppar-brev-och-paket-till-tesla/</link>
            <guid>38190645</guid>
            <pubDate>Wed, 08 Nov 2023 14:22:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seko.se/press-och-aktuellt/nyheter/2023/seko-stoppar-brev-och-paket-till-tesla/">https://www.seko.se/press-och-aktuellt/nyheter/2023/seko-stoppar-brev-och-paket-till-tesla/</a>, See on <a href="https://news.ycombinator.com/item?id=38190645">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




    <p><img src="https://www.seko.se/imagevault/publishedmedia/7jfa8njnq32rmzg59lfv/tesla_banner.png"></p>



            <div>
              
              


    <p>Sekos förbundsstyrelse (Service- och kommunikationsfacket) beslutade idag att varsla om sympatiåtgärder till stöd för IF Metalls konflikt med den globala biltillverkaren, Tesla. Skälet till konflikten är att Tesla och deras ägare Elon Musk vägrar att teckna kollektivtal och följa spelreglerna på den svenska arbetsmarknaden.</p>

              


              


    <div>
        <p>– IF Metalls kamp är även vår kamp. Genom att vägra förhålla sig till spelreglerna här i Sverige så försöker Tesla skaffa sig konkurrensfördelar genom att ge arbetarna sämre löner och villkor än de skulle haft med ett kollektivavtal. Det är givetvis helt oacceptabelt. Den strid som nu IF Metall tar är viktig för hela den svenska kollektivavtalsmodellen. Därför har vår förbundsstyrelse valt att lägga ett sympativarsel, säger Sekos förbundsordförande, Gabriella Lavecchia.</p>
<p>Sekos sympatiåtgärder innebär blockad mot utdelning, utlämning och avhämtning av försändelser, brev, paket och pall som görs av PostNord och CityMail till Teslas samtliga arbetsplatser på samtliga orter i Sverige. Detta innebär att exempelvis reservdelar och komponenter till verkstäderna inte kommer levereras av dessa logistikbolag. Blockaden innebär att sympatiåtgärderna kvarstår även om annat företag övertar blockerat arbete.</p>
<p>–&nbsp;Vi backar IF Metall till 100 procent i denna viktiga konflikt. Vi är inne i en viktig period för svensk fackföreningsrörelse och för den svenska modellen. Vi och våra medlemmar kommer att göra allt vi kan för att vi tillsammans ska gå segrande ur denna kamp för rättvisa villkor för Teslas anställda, säger Sekos avtalssekreterare, Ulrika Nilsson.</p>
<p>Sekos stridsåtgärder träder ikraft den <strong>20 november 2023 klockan 01:00</strong></p>
<p>Varsel om utvidgning av konfliktåtgärder kommer att vidtas för det fall åsidosättande av stridsåtgärderna förekommer.</p>
    </div>

              
              



              



            </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Workers in Sweden Will Expand Strike Against Tesla (120 pts)]]></title>
            <link>https://www.nytimes.com/2023/11/07/world/europe/sweden-tesla-strike.html</link>
            <guid>38190600</guid>
            <pubDate>Wed, 08 Nov 2023 14:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/11/07/world/europe/sweden-tesla-strike.html">https://www.nytimes.com/2023/11/07/world/europe/sweden-tesla-strike.html</a>, See on <a href="https://news.ycombinator.com/item?id=38190600">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/11/07/world/europe/sweden-tesla-strike.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Major Outage Across ChatGPT and API (463 pts)]]></title>
            <link>https://status.openai.com/incidents/00fpy0yxrx1q</link>
            <guid>38190401</guid>
            <pubDate>Wed, 08 Nov 2023 14:02:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://status.openai.com/incidents/00fpy0yxrx1q">https://status.openai.com/incidents/00fpy0yxrx1q</a>, See on <a href="https://news.ycombinator.com/item?id=38190401">Hacker News</a></p>
Couldn't get https://status.openai.com/incidents/00fpy0yxrx1q: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[US Smartphone Shipments Decline 19% in Q3 2023 as More Americans Delay Upgrade (117 pts)]]></title>
            <link>https://www.counterpointresearch.com/insights/us-smartphone-shipments-decline-19-yoy-in-q3-2023-as-more-americans-delay-smartphone-upgrade/</link>
            <guid>38190369</guid>
            <pubDate>Wed, 08 Nov 2023 14:00:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.counterpointresearch.com/insights/us-smartphone-shipments-decline-19-yoy-in-q3-2023-as-more-americans-delay-smartphone-upgrade/">https://www.counterpointresearch.com/insights/us-smartphone-shipments-decline-19-yoy-in-q3-2023-as-more-americans-delay-smartphone-upgrade/</a>, See on <a href="https://news.ycombinator.com/item?id=38190369">Hacker News</a></p>
Couldn't get https://www.counterpointresearch.com/insights/us-smartphone-shipments-decline-19-yoy-in-q3-2023-as-more-americans-delay-smartphone-upgrade/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Wikipedia Became the Last Good Place on the Internet (479 pts)]]></title>
            <link>https://www.cambridge.org/core/journals/american-political-science-review/article/rule-ambiguity-institutional-clashes-and-population-loss-how-wikipedia-became-the-last-good-place-on-the-internet/FC3F7B9CBF951DD30C2648E7DEFB65EE</link>
            <guid>38189878</guid>
            <pubDate>Wed, 08 Nov 2023 13:13:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cambridge.org/core/journals/american-political-science-review/article/rule-ambiguity-institutional-clashes-and-population-loss-how-wikipedia-became-the-last-good-place-on-the-internet/FC3F7B9CBF951DD30C2648E7DEFB65EE">https://www.cambridge.org/core/journals/american-political-science-review/article/rule-ambiguity-institutional-clashes-and-population-loss-how-wikipedia-became-the-last-good-place-on-the-internet/FC3F7B9CBF951DD30C2648E7DEFB65EE</a>, See on <a href="https://news.ycombinator.com/item?id=38189878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en" data-v-324b68a8="" id="sec0" data-v-cbbc8d8e=""><h2>Abstract</h2>  <div><p>Scholars usually portray institutions as stable, inviting a status quo bias in their theories. Change, when it is theorized, is frequently attributed to exogenous factors. This paper, by contrast, proposes that institutional change can occur endogenously through population loss, as institutional losers become demotivated and leave, whereas institutional winners remain. This paper provides a detailed demonstration of how this form of endogenous change occurred on the English Wikipedia. A qualitative content analysis shows that Wikipedia transformed from a dubious source of information in its early years to an increasingly reliable one over time. Process tracing shows that early outcomes of disputes over rule interpretations in different corners of the encyclopedia demobilized certain types of editors (while mobilizing others) and strengthened certain understandings of Wikipedia’s ambiguous rules (while weakening others). Over time, Wikipedians who supported fringe content departed or were ousted. Thus, population loss led to highly consequential institutional change.</p></div> </div><div id="content-container" data-v-cbbc8d8e=""><div>
<div>
<div data-magellan-destination="sec1" id="sec1">
<h2> INTRODUCTION</h2>
<p> Institutions theorists seek to explain institutional stability and change. However, most accounts have a status quo bias, as institutions are portrayed as stable. When change is observed, it is typically through alterations of the formal rules of the institution. These changes are frequently attributed to easily observable exogenous factors, such as external crises, influxes of new ideas, or alterations in actors’ power. However, endogenous processes may also create change and their neglect biases our accounts of institutions.</p>
<p> This paper advances a theory of endogenous institutional change whereby members of an institution react differently to the outcomes of disputes within institutions. Losers (or those who disagree with the outcomes of the disputes) may become demotivated and disempowered, whereas the winners (or those who agree with the outcomes of the disputes) may become galvanized and empowered. If the winners and losers belong to coherent camps with divergent interests and ideas about the institution, disproportionate exits by the losers can cause drastic institutional changes over time. The contribution of this paper is to show theoretically and empirically that consequential change <em>can occur solely endogenously</em> and that population loss can be the mechanism behind such change.<a href="#fn1"><span>Footnote </span>
<sup>1</sup></a></p>
<p> The paper provides a detailed demonstration of this occurring on the English Wikipedia. Beneath the hood of this popular website exists a large community of volunteers (Wikipedia editors) who collaboratively write all Wikipedia content. This population of volunteers comes together in deliberative and democratic fora where they adjudicate what kind of content belongs on the encyclopedia. This paper shows that the English Wikipedia transformed its content over time through a gradual reinterpretation of its ambiguous Neutral Point of View (NPOV) guideline, the core rule regarding content on Wikipedia. This had meaningful consequences, turning an organization that used to lend credence and false balance to pseudoscience, conspiracy theories, and extremism into a proactive debunker, fact-checker and identifier of fringe discourse. There are several steps to the transformation. First, Wikipedians disputed how to apply the NPOV rule in specific instances in various corners of the encyclopedia. Second, the earliest contentious disputes were resolved against Wikipedians who were more supportive of or lenient toward conspiracy theories, pseudoscience, and conservatism, and in favor of Wikipedians whose understandings of the NPOV guideline were decisively anti-fringe. Third, the resolutions of these disputes enhanced the institutional power of the latter Wikipedians, whereas it led to the demobilization and exit of the pro-fringe Wikipedians. A power imbalance early on deepened over time due to disproportionate exits of demotivated, unsuccessful pro-fringe Wikipedia editors. Fourth, this meant that the remaining Wikipedia editor population, freed from pushback, increasingly interpreted and implemented the NPOV guideline in an anti-fringe manner. This endogenous process led to a gradual but highly consequential reinterpretation of the NPOV guideline throughout the encyclopedia.</p>
<p> The paper demonstrates these processes through qualitative content analysis, archival research, and process tracing. First, to document a transformation in Wikipedia’s content, a qualitative content analysis was conducted on a sample of 63 representative articles. Content on the pages was analyzed across time with a predetermined coding scheme (see Boreus and Bergström <a href="#r6"><span>Reference Boreus and Bergström</span>2017</a>; Elkins, Spitzer, and Tallberg <a href="#r11"><span>Reference Elkins, Spitzer and Tallberg</span>2021</a>; Herrera and Braumoeller <a href="#r17"><span>Reference Herrera and Braumoeller</span>2004</a>). The analysis shows that the content changed over time from lending credence to fringe views to delegitimizing the fringe views. Second, to explain why these content changes occurred, the paper uses process tracing on Wikipedia’s archives, analyzing article talk page discussions about rule interpretations, related discussions on general noticeboards, arbitration rulings, and editor sanctions proceedings, as well as the histories of individual Wikipedia editors. Analyses of debates regarding individual articles lend strong support for the theory of endogenous institutional change. Article-by-article evidence is supplemented by an analysis of a sample of referenda where editors are asked to express their views about the NPOV rule’s application to fringe topics. The analysis shows that the disproportionate population loss is systematic across the encyclopedia, as editors who hold the pro-fringe view exit Wikipedia at a higher rate than anti-fringe editors.</p>
<p> These changes occurred despite structural biases in favor of stability. Even though the rules and content on Wikipedia are constantly subject to change, the organization’s decision-making procedures are biased to a conservative status quo. All changes on Wikipedia must be approved through consensus and editors who act contrary to consensus are punished. Furthermore, the transformation was neither an inevitability nor likely outcome of the original design of the institution. A comparison to other versions of Wikipedia demonstrates the contingent nature of the English Wikipedia’s trajectory. For example, even though the Croatian and English Wikipedia share the same core rules, content on the two versions of Wikipedia looks drastically different, as the Croatian Wikipedia lends credence to anti-LGBT rhetoric and pseudohistory (Sampson <a href="#r29"><span>Reference Sampson</span>2013</a>). These outcomes were not intended by Wikipedia’s founders, as shown by their own delineation of the rules in the early years, and in the case of Wikipedia’s co-founder, a complete disavowal of Wikipedia’s transformation.</p>
<p> This paper uses the understudied politics of Wikipedia as a lens through which to examine institutional theories of change. It has two major contributions. One is theoretical, demonstrating how population loss can be an endogenous mechanism of institutional change. Losses in institutional clashes can be demoralizing and inhibiting for the losers, leading them to abandon the institution and leaving the institution in the hands of their adversaries. The winners subsequently have freer rein to push for changes in the institution. This form of change may potentially have explanatory value regarding the trajectories of bureaucracies, political movements, political parties, and professions, as discontented losers within those institutions opt to leave their institution rather than fight an uphill battle against empowered and emboldened winners.</p>
<p> The other contribution is empirical, as the paper provides a comprehensive study of the politics of Wikipedia, a highly consequential organization in the online political information ecosystem. The paper documents a heretofore undocumented transformation in Wikipedia’s content over its life span. While scholars and commentators have remarked in recent years on Wikipedia’s status as a beacon of information in an online space plagued by misinformation, there is no comprehensive analysis of a transformation over Wikipedia’s life span.<a href="#fn2"><span>Footnote </span>
<sup>2</sup></a></p>
</div>
<div data-magellan-destination="sec2" id="sec2">
<h2> INSTITUTIONS AND ENDOGENOUS CHANGE</h2>
<p> Most scholarly works on institutions have a status quo bias, as the focus is on accounting for the persistence of institutional arrangements over time. To explain change, scholars tend to look for exogenous factors. For rational choice institutionalists, institutions reflect equilibrium solutions to problems of cooperation between different actors.<a href="#fn3"><span>Footnote </span>
<sup>3</sup></a> In most rationalist accounts of institutions, these equilibria do not become unstable unless the external circumstances change (e.g., through alterations in power), and the appearance of new problems that require new solutions. For sociological institutionalists, institutions reflect shared norms and understandings.<a href="#fn4"><span>Footnote </span>
<sup>4</sup></a> Actors that compose the membership of an institution exist in a social environment where institutional practices become taken for granted. Individual actors have limited agency to alter the existing institutional arrangements. These shared norms do not get altered unless by powerful external sources or through the appearance of norm entrepreneurs. For historical institutionalists, institutions reflect decision-making made at critical junctures, temporal sequencing, and path dependency. Past decision-making has a persistent impact on institutions, contributing to stability over time, even if the existing arrangements are suboptimal. The sources of change tend to be external crises or changes in the broader environment that alter the functions and purpose of institutions.<a href="#fn5"><span>Footnote </span>
<sup>5</sup></a></p>
<p> Recent comparative politics scholarship (particularly in the historical institutionalist tradition; see Bleich <a href="#r4"><span>Reference Bleich</span>2018</a>; Mahoney and Thelen <a href="#r25"><span>Reference Mahoney and Thelen</span>2009</a>; Streeck and Thelen <a href="#r34"><span>Reference Streeck and Thelen</span>2005</a>; Thelen <a href="#r35"><span>Reference Thelen</span>2004</a>) and international relations-oriented research on norm contestation (see Dietelhoff and Zimmermann <a href="#r10"><span>Reference Dietelhoff and Zimmermann</span>2020</a>; Sandholtz <a href="#r30"><span>Reference Sandholtz</span>2008</a>; Sandholtz and Stiles <a href="#r31"><span>Reference Sandholtz and Stiles</span>2009</a>; Wiener <a href="#r39"><span>Reference Wiener</span>2009</a>) have identified rule ambiguity and norm ambiguity, respectively, as promising plausible mechanisms for gradual endogenous change.<a href="#fn6"><span>Footnote </span>
<sup>6</sup></a> The seeds of change lie in the intrinsic inability of rules to apply clearly and unambiguously to most situations that confront members of complex institutions. This permits actors to reinterpret rules and norms through their application in specific instances. However, while this literature points to the plausibility of endogenous institutional change through ambiguity in rule application, many cases are prompted by exogenous causes, such as (i) the involvement of new actors, (ii) environmentally driven changes in the balance of power between actors, and (iii) the appearance of new problems that need solving. While these may be gradual processes of change, the underlying causes are frequently exogenous.<a href="#fn7"><span>Footnote </span>
<sup>7</sup></a></p>
<p> A prominent example of this kind of change in the comparative politics literature is Bleich’s (<a href="#r4"><span>Reference Bleich</span>2018</a>) study of the French High Court’s changing interpretation of hate crime laws over time. Bleich’s explanation for the shift in how the court applied the rules focuses on the entry and influence of new actors, as he delineates how activist organizations influenced how the French High Court interpreted hate crime laws. He also shows that the French High Court was influenced by the European Court of Human Rights. In the international relations literature, a prominent example of this kind of change is Sandholtz’s (<a href="#r30"><span>Reference Sandholtz</span>2008</a>) study on the rules regarding wartime plunder of artistic and cultural artifacts. In Sandholtz’s study, rules regarding wartime plunder were reinterpreted after major wars (the Napoleonic Wars and World War II), as the victims of large-scale plunder pressed to regain their property. In both cases, the rules in question (hate crime laws and rules of war) were broad and unspecified, allowing for different application of the rules in practice. In both Bleich (<a href="#r4"><span>Reference Bleich</span>2018</a>) and Sandholtz (<a href="#r30"><span>Reference Sandholtz</span>2008</a>), a lack of specificity in the wording of the rules permitted changes in application over time, but those changes were caused by exogenous factors (new actors or major wars).</p>
<p> My account of institutional change on Wikipedia contrasts with these other accounts in three ways. First, change was not caused by the entry of new actors, but rather the loss of actors. Whereas other approaches to the study of institutions tend to see the relevant population of an institution as being stable or increasing, my account shows that the loss of a particular population contributed to Wikipedia’s shift. Furthermore, other accounts see conflicts within institutions as resulting in winners and losers where the losers typically remain within the institution. As Conran and Thelen (<a href="#r8"><span>Reference Conran, Thelen, Fioretos, Falleti and Sheingate</span>2016</a>) note, losers remobilize and live to fight another day, which may lead them to change the institution in the future. However, the extent to which that is true depends on the nature of the institution, as well as the characteristics of the conflicts and the participants involved. Losses may entrench power advantages that entail feedback effects and are hard to rebalance, thus ensuring that losers cannot return the institution to the status quo. That was certainly the case on Wikipedia.</p>
<p> Second, power asymmetries are formed on Wikipedia. However, unlike many other studies of institutions, the power asymmetry was not due to broader environmental changes that altered the social or material sources of actors’ power. Rather, power asymmetries formed as actors gained power <em>within</em> the rubrics of the institution itself. In the case of Wikipedia, <em>experience</em> provided a potent source of power, which made victories in early disputes consequential. In other organizations, there may be other power dynamics that are made apparent and entrenched through wins and losses in institutional conflicts.</p>
<p> Third, reinterpretation of Wikipedia’s rules was not prompted by the appearance of new problems that required new solutions. Rather, the practical consequence of the rule reinterpretations on Wikipedia entailed fixing old problems (the presence of sources and content that legitimized fringe perspectives) that in large part stemmed from how the rules had been interpreted in the past.</p>
<p> In contrast to much of the existing literature, this paper argues that institutions which are otherwise portrayed as stable are in fact constantly subject to change from within. The change can occur entirely endogenously.<a href="#fn8"><span>Footnote </span>
<sup>8</sup></a> There are four steps to such change. First, consistent with some of the historical institutionalist and norm scholarship, the seeds of change are located in the intrinsic inability of rules and norms to apply clearly and unambiguously to most situations that confront members of the institution. Second, rule ambiguity creates openings for members to impose new meanings on the rules at the micro level, as the rules are applied to specific situations. Since institutions are composed of actors that have different interests and diverse views, rule interpretations can be a potent source of conflict. Third, the conflicts may be resolved, resulting in winners and losers. The resolutions of these conflicts in favor of actors with certain rule interpretations can alter the balance of power within the institution, as the losers of past conflicts get demobilized, sanctioned, or lose status, whereas the winners get mobilized, elevated, and gain institutional power. Fourth, if actors with similar and overlapping viewpoints and interests (coherent camps) win early and frequent victories across an institution, they may shape how the overarching rules of the institution are understood to work in practice.</p>
<p> For the process to play out in this manner, <em>camps with coherent interests and views</em> must exist (A and B in <a href="#fig1">Figure 1</a>). Otherwise, settlements in individual disputes lead to indeterminate long-term results. Additionally, for trajectories to form over time, victories must result in <em>power advantages.</em> In the absence of a meaningful power advantage, losers should be able to regroup and live to fight another day over the interpretation of the rules, with indeterminate long-term results. The relative ease with which actors can exit institutions affects the speed of change. Migrating from a country may entail considerable costs, whereas leaving a voluntary association may be relatively cost-free, which means that rapid change may be more likely in the latter case once a power asymmetry forms. Finally, for the process to play out in this specific manner, it presumes that <em>exogenous factors do not intervene with the process.</em> Both exogenous and endogenous factors can work in tandem, but the contribution of this paper is to show theoretically and empirically that consequential change <em>can occur solely endogenously.</em>
</p><div data-magellan-destination="fig1" id="fig1">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig1.png?pub-status=live" width="1507" height="442" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig1.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig1.png"></p>
<div><p><span>Figure 1.</span> How Do Rules Obtain New Meanings?<a href="#fn9"><span>Footnote </span>
<sup>9</sup></a></p>
</div></div>
<p> The remainder of this paper provides a detailed demonstration of how this process of endogenous change plays on the English Wikipedia. The paper explains what Wikipedia is, justifies why Wikipedia is a worthy case of inquiry, documents how Wikipedia’s content has transformed over its life span, and explains how this transformation happened. The penultimate section of the paper examines various alternative explanations, showing that they fail to account for Wikipedia’s transformation.</p>
</div>
<div data-magellan-destination="sec3" id="sec3">
<h2> WIKIPEDIA AS AN IMPORTANT PART OF THE POLITICAL INFORMATION ECOSYSTEM</h2>
<div data-magellan-destination="sec4" id="sec4">
<h3> The Structure of Wikipedia</h3>
<p> Wikipedia is a nonprofit, multilingual, open-access online encyclopedia started by Jimmy Wales and Larry Sanger in 2001. The encyclopedia is user-generated. Anyone is free to edit it. By May 2021, there were more than 40&nbsp;million registered users, of whom nearly 140,000 were active editors. Wikipedians generally edit pseudonymously, but extant data indicate that Wikipedians are disproportionately white males from the Global North. One in four Wikipedians primarily edit the English language version of Wikipedia (see Hill and Shaw <a href="#r18"><span>Reference Hill and Shaw</span>2013</a>; Wikipedia <a href="#r44">2021b</a>; Yasseri, Sumi, and Kertesz <a href="#r45"><span>Reference Yasseri, Sumi and Kertesz</span>2012b</a>).</p>
<p> Editors must comply with three core Wikipedia content guidelines:</p><ol>
<li>
<p><span>1.</span>
<strong>Neutral point of view (WP:NPOV):</strong> “representing fairly, proportionately, and, as far as possible, without editorial bias, all the significant views that have been published by reliable sources on a topic” (Wikipedia <a href="#r40">2020a</a>).</p>
</li>
<li>
<p><span>2.</span>
<strong>No original research (WP:NOR):</strong> “you must be able to cite reliable, published sources that are directly related to the topic of the article, and directly support the material being presented” (Wikipedia <a href="#r41">2020b</a>).</p>
</li>
<li>
<p><span>3.</span>
<strong>Verifiability (WP:V):</strong> “verifiability means other people using the encyclopedia can check that the information comes from a reliable source… All material in Wikipedia mainspace, including everything in articles, lists and captions, must be verifiable” (Wikipedia <a href="#r42">2020c</a>).</p>
</li>
</ol><p>WP:NPOV is the guideline at the heart of most disputes on the encyclopedia. The NPOV guideline affects whether something should be covered, the weight of the coverage, and whether the cited sources are reliable. On subjects where there are diverse and incompatible views, “edit wars” frequently arise. These are situations when a change is made to an article (e.g., removal of text, addition of text, and rewording of text), and the change gets reverted, leading to an unstable cycle of additions and reverts of the same content (see Jemielniak <a href="#r20"><span>Reference Jemielniak</span>2014</a>; Tkacz <a href="#r36"><span>Reference Tkacz</span>2015</a>; Yasseri et al. <a href="#r46"><span>Reference Yasseri, Sumi, Rung, Kornai and Kertesz</span>2012</a>).</p>
<p> How does the encyclopedia deal with disputes like these? One might think that such disputes would lead to an inconsistent product where articles look drastically different from day to day, but Wikipedia produces a very stable and consistent product. This is because there are multilayered dispute settlement mechanisms and elaborate norms regarding editor behavior. Wikipedia’s community reaches decisions about rules and content through a combination of deliberative discussions and referenda. These democratic processes have the goal of determining whether content has “consensus.” If a proposed change does not have consensus, the article experiencing edit wars will be returned to the status quo.</p>
<p> A typical edit war will be resolved in the following manner: an editor makes changes to a page. Other editors disapprove of the change and revert the change. The status quo ante is established until a consensus for inclusion can be found on the talk page of the article. Editors may be able to work out mutually acceptable compromises. If they are not able to work out acceptable compromises among the small subset that are engaged with a single article, they can subject the dispute to input from the broader Wikipedia community. For example, if the editors who edit the Margaret Thatcher page are having a dispute that they cannot resolve among themselves, they may take the dispute to noticeboards that are frequented by large numbers of Wikipedians who do not frequent the Thatcher page.</p>
<p> However, these procedures are not always sufficient to establish stability on a page. This is particularly the case on large high-profile articles with stable and coherent camps of editors, frequent editing, and multiple controversial aspects. When articles experience extraordinary levels of edit-warring, editors may request dispute settlement before administrators on the “Administrators Noticeboard” or arbitrators on the “Arbitration Committee.” These bodies primarily adjudicate behavioral problems among Wikipedians rather than adjudicate content directly (that is something for Wikipedia’s deliberative democratic processes to resolve). The bodies tend to sanction the most active and raucous editors on the dysfunctional pages.</p>
<p> Administrators and arbitrators are elected by the Wikipedia userbase. To become an administrator, an editor goes through the “Request for Adminship” process, which is essentially an election on the suitability of an editor to become an administrator. Any experienced editor can make a request for a position as administrator.<a href="#fn10"><span>Footnote </span>
<sup>10</sup></a> The request is unlikely to be granted unless they have a well-established history as a contributor on the encyclopedia and have demonstrated an ability to get along with other editors. The threshold to become an administrator is high, as editors generally require support by 75% of voters. Editors who are new and who behave in divisive ways are unlikely to get the support needed to become administrators.<a href="#fn11"><span>Footnote </span>
<sup>11</sup></a> The English Wikipedia has approximately one thousand administrators.</p>
<p> The Arbitration Committee is vastly smaller, with membership oscillating between 13 and 18 members. Elections to the Arbitration Committee are more formal and eventful processes than the requests for adminship, as the elections occur annually, eligible registered editors are notified about the elections on their user talk page, and cast secret ballots.<a href="#fn12"><span>Footnote </span>
<sup>12</sup></a> Experienced editors who are not divisive are better poised to garner the votes to become arbitrators.</p>
</div>
<div data-magellan-destination="sec5" id="sec5">
<h3> Case Selection Justification</h3>
<p> There are several motivating factors in choosing the English Wikipedia as a case to study institutional change: (i) it is an important case; (ii) it is an understudied case; (iii) it could be construed as a least-likely case for institutional change; and (iv) it has unique availability of data, which makes it possible to observe slow, gradual, endogenous processes that result in consequential drastic change over time.</p>
<p> First, Wikipedia is an important institution. One that is worthwhile to study in its own right. <em>Wikipedia.org</em> is one of the most popular websites in the world. The English Wikipedia is frequently at the top or near the top of Google searches for a known person or event in the English language (e.g., Vincent and Hecht <a href="#r37"><span>Reference Vincent and Hecht</span>2021</a>). Wikipedia is also widely perceived as a trustworthy and reliable source of information (e.g., Bruckman <a href="#r7"><span>Reference Bruckman</span>2022</a>), giving it considerable power in public discourse and ideational diffusion. Wikipedia’s influence is also boosted by the fact that Wikipedia pages, unlike other forms of content (such as news reports and scholarship), are often written in summary style and in layman’s terms, thus making the information in Wikipedia articles more accessible to readers. Furthermore, tech giants, such as YouTube, Facebook, Google, and Twitter, have incorporated Wikipedia into their own platforms.</p>
<p> Due to its popularity and perceived trustworthiness, Wikipedia has the power to legitimize and delegitimize subjects. This is a website that can declare whether something is a pseudoscience, a falsehood, a conspiracy theory, or bigotry. World leaders can be described as dictators, perpetrators of violence can be identified, and the effects of implementing certain public policies can be characterized as positive or negative. Additionally, in many cases, it seems clear that actors who are covered by Wikipedia believe that Wikipedia matters, as politicians have on many occasions been exposed as having edited their own Wikipedia pages, and authoritarian regimes have blocked Wikipedia in parts or in its entirety.</p>
<p> Wikipedia’s salience has increased over time, as scholars express concern over the intersection of the Internet and politics. The Internet has displaced traditional gatekeepers, and contributed to the wide diffusion of conspiracy theories, pseudoscience, and extremist rhetoric. Whereas the other major online platforms have been criticized for their role in monetizing, inculcating, and diffusing extremism and misinformation, Wikipedia has often been hailed as an exception: a distinctly positive actor in the online political ecosystem,<a href="#fn13"><span>Footnote </span>
<sup>13</sup></a> an actor that serves a proactive gatekeeping role where it outright debunks, fact-checks, and highlights the errors and fringe nature of the very same discourses popularized on the other platforms.</p>
<p> Second, Wikipedia is an understudied institution in an understudied organizational environment. Aside from its importance in politics, there are several things about Wikipedia as an organization that political scientists and organizational scholars should find intriguing. It is an enormous organization that is based on the open-source or commons-based peer production organizational model (e.g., Benkler <a href="#r2"><span>Reference Benkler</span>2002</a>; Reagle <a href="#r27"><span>Reference Reagle</span>2010</a>; Tkacz <a href="#r36"><span>Reference Tkacz</span>2015</a>). Unlike traditional organizations, such as firms and bureaucracies, Wikipedia is characterized by a lack of “formal hierarchy.” Editors on Wikipedia are not managed and instructed by “managers,” but rather self-assign tasks to do. Editors are not motivated by monetary rewards, unlike members of traditional organizations.</p>
<p> Decision-making on Wikipedia is deliberative and democratic. The rules of Wikipedia are always subject to change, which effectively makes all rules, norms, and content on Wikipedia subject to constant plebiscites. Consequently, Wikipedia both reflects and accentuates processes that are analogous to those in other organizations. Scholars have consequentially used Wikipedia to study collaboration, conflict, polarization, and partisanship, as well as politics and organizational dynamics more broadly (Greenstein, Gu, and Zhu <a href="#r14"><span>Reference Greenstein, Gu and Zhu</span>2021</a>; Heaberlin and DeDeo <a href="#r16"><span>Reference Heaberlin and DeDeo</span>2016</a>; Jemielniak <a href="#r20"><span>Reference Jemielniak</span>2014</a>; Konieczsny 2009; Lerner and Lomi <a href="#r24"><span>Reference Lerner and Lomi</span>2019</a>; Reagle <a href="#r27"><span>Reference Reagle</span>2010</a>; Shi et al. <a href="#r33"><span>Reference Shi, Teplitskiy, Duede and Evans</span>2019</a>; Tkacz <a href="#r36"><span>Reference Tkacz</span>2015</a>; Yasseri et al. <a href="#r46"><span>Reference Yasseri, Sumi, Rung, Kornai and Kertesz</span>2012</a>; Yasseri, Sumi, and Kertesz <a href="#r45"><span>Reference Yasseri, Sumi and Kertesz</span>2012</a>). While Wikipedia has been the subject of study by computer scientists, physicists, information scientists, and sociologists, it has been neglected by political scientists.</p>
<p> Third, Wikipedia could be construed as a least-likely case for institutional change and most-likely case for organizational stability, as the organization has several structural biases in favor of stability and the status quo. The requirement that there needs to be a “consensus” among editors in favor of both addition of content and rule changes should make it hard to enact substantial changes.<a href="#fn14"><span>Footnote </span>
<sup>14</sup></a> In the event of disputes, the guiding rule is to retain the status quo unless a consensus can be established for any change. A minority of editors can therefore block controversial changes. Furthermore, the presence of a large and diverse userbase means that ideational changes among individuals and small groups should not result in frequent or sudden changes over time. Wikipedia also strongly enforces compliance with the rules, which means that large-scale rule violations will not be a likely source of change over time (see Piskorski and Gorbatai <a href="#r26"><span>Reference Piskorski and Gorbatai</span>2017</a>). The strong enforcement leads editors to edit within accepted boundaries and within consensuses. Given these institutional characteristics, one might expect Wikipedia to have a conservative status quo bias.<a href="#fn15"><span>Footnote </span>
<sup>15</sup></a></p>
<p> Furthermore, the founders of Wikipedia have not intervened to cause new interpretations of the guidelines among the userbase. Sanger, who crafted the core NPOV rule, has condemned the interpretations of the guideline that emerged over time.<a href="#fn16"><span>Footnote </span>
<sup>16</sup></a> Wales has held a more agnostic view of change on Wikipedia over time, saying in 2006, “One of the great things about NPOV is that it is a term of art and a community fills it with meaning over time” (Reason <a href="#r28">2006</a>).</p>
<p> Fourth, Wikipedia has a unique availability of data. A major problem in most case-specific accounts of institutional change is the inaccessibility of comprehensive data to evaluate causes and effects. Scholars must rely on a sliver of data that are available to piece together what the preferences of various actors might be, what actions these actors took, and how the preferences and actions of these actors led to institutional change or stability. What adds to the problem is that the publicly available data may fail to reflect the actual processes that led to change. For example, debates may take place in front of cameras and voting may be logged into records, but the meaningful negotiations occur behind closed doors.</p>
<p> In comparison with other institutions, Wikipedia has several advantages in terms of studying institutional change. In other largescale institutions, it is not feasible to identify and collect data on every participant, and to track the behavior of every participant over time. Scholars are often forced to fill gaps with theory or by making assumptions. There is a risk that unobserved variables have a significant impact on outcomes, which makes it hard to make robust claims about the causes of institutional change. On Wikipedia, on the other hand, virtually all edits and comments are logged and open to public viewing. This means that it is possible to trace each input in every debate, as well as to sift through the editing history of each Wikipedia editor. Thus, there is an enormity of relevant data on which to test, refine, and build theories of institutional change.</p>
</div>
</div>
<div data-magellan-destination="sec6" id="sec6">
<h2> RESEARCH DESIGN</h2>
<p> The research design of the paper has two components. First, the paper codes content in the lead of Wikipedia articles, showing a pro-to-anti-fringe shift in content. Second, the paper does process-tracing of trends within Wikipedia’s governance to show how this shift happened (George and Bennett <a href="#r12"><span>Reference George and Bennett</span>2005</a>). In terms of analyzing changes in the content of Wikipedia articles, the paper uses nonautomated qualitative content analysis to classify whether Wikipedia pages use language that legitimizes or delegitimizes fringe positions and entities. An advantage of qualitative content analysis is that it permits analysts to observe subtle, yet meaningful nuances in meaning.<a href="#fn17"><span>Footnote </span>
<sup>17</sup></a> It entails human coding and interpretation of textual sources according to structured and systematic coding schemes (see Boreus and Bergström <a href="#r6"><span>Reference Boreus and Bergström</span>2017</a>; Elkins, Spitzer, and Tallberg <a href="#r11"><span>Reference Elkins, Spitzer and Tallberg</span>2021</a>; Herrera and Braumoeller <a href="#r17"><span>Reference Herrera and Braumoeller</span>2004</a>). More specifically, the paper systematically classified a sample of 63 article leads with a predetermined coding scheme.<a href="#fn18"><span>Footnote </span>
<sup>18</sup></a> The 63 pages were chosen because they are representative of the population of relevant cases: all the pages are on topics that have been linked to pseudoscience, conspiracy theories, extremism, and fringe rhetoric in public discourse.</p>
<p> Within the relevant population, the chosen pages reflect diverse topic areas (health, climate, gender, sexuality, race, abortion, religion, politics, international relations, and history). The pages also vary in terms of the time of creation (some pages were created early and others later), and temporal prominence (the topics covered in the pages were more prominent during different time periods). The pages include biographies (which have more restrictive standards for inclusion of pejorative content) and nonbiographies.</p>
<p> The contents of the chosen Wikipedia pages were classified according to a five-category coding scheme. These categories reflect varying degrees of neutrality. On one end of the spectrum, the language lends credence and legitimacy to fringe views. On the other end, the language firmly delegitimizes the fringe views:</p><ol>
<li>
<p><span>1.</span>
<strong>Fringe normalization:</strong> The fringe position/entity is normalized and legitimized. There is an absence of criticism.</p>
</li>
<li>
<p><span>2.</span>
<strong>Teach the controversy:</strong> The fringe position/entity is presented as a matter of active scientific or political dispute (A says X, B says Y).</p>
</li>
<li>
<p><span>3.</span>
<strong>False balance:</strong> The lead places emphasis on the expertise, credibility, evidence, and arguments of the anti-fringe side (e.g., “some scientists say,” “some medical organizations say”), but the pro-fringe side still gets space to rebut.</p>
</li>
<li>
<p><span>4.</span>
<strong>Identification of the fringe view:</strong> The lead places emphasis on the legitimacy and the overwhelming numbers that compose the anti-fringe side (e.g., “scientific consensus,” “the scientific community”), but space is still given to the pro-fringe side.</p>
</li>
<li>
<p><span>5.</span>
<strong>Proactive fringe-busting:</strong> Space is only given to the anti-fringe side whose position is stated as fact in Wikipedia’s own voice.<a href="#fn19"><span>Footnote </span>
<sup>19</sup></a> The evidence that supports the anti-fringe position is presented, whereas the flaws of the pro-fringe perspective are outlined.</p>
</li>
</ol><p>The paper uses a cross-temporal analysis of each article’s lead, thus tracking changes over time. A stable version of each article was analyzed at the end of each year. Articles were checked more frequently if the pages had frequent and erratic editing patterns. Changes on Wikipedia articles can be accessed through archives that show each change, thus making the study replicable. <a href="#tab1">Table 1</a> and the Supplementary Material include examples of language from each article’s lead. Due to space constraints, changes in nine representative article leads are shown in <a href="#tab1">Table 1</a>, whereas 54 additional articles are in the Supplementary Material.</p><div data-magellan-destination="tab1" id="tab1">
<p><span>Table 1.</span> The Lead to Controversial Science- and Politics-Related Wikipedia Pages, January 2001 to June 2020</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab1.png?pub-status=live" width="2765" height="4745" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab1.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab1.png"></p>
</span>
</p></div>
<div data-magellan-destination="tab2" id="tab2">
<p><span>Table 2.</span> Wikipedia’s List of Deprecated Websites, as of September 4, 2021<a href="#fn23"><span>Footnote </span>
<sup>23</sup></a></p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab2.png?pub-status=live" width="924" height="1803" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab2.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab2.png"></p>
</span>
</p></div>
<div data-magellan-destination="tab3" id="tab3">
<p><span>Table 3.</span> Referenda and Subsequent Exits</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab3.png?pub-status=live" width="923" height="1057" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab3.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_tab3.png"></p>
</span>
</p></div>
<p> Per the analysis (see <a href="#tab1">Table 1</a> and the Supplementary Material), content on the English Wikipedia shows a clear trend from language that legitimizes fringe positions to language that delegitimizes fringe positions. Newer articles tend to adopt language from the anti-fringe categories at their creation, whereas older articles tend to adopt language that is more fringe-normalizing at their creation. None of the articles move in a direction where they become more fringe-normalizing.</p>
<p> The analysis shows that in its early years, the English Wikipedia adhered to a “strict” NPOV approach whereby Wikipedia content was open to a diversity of opinions and sources, and where Wikipedians could not state contested views as facts in Wikipedia’s own voice. Thus, a typical page on a subject related to pseudoscience and contested science would adopt a “Some say X, others say Y” style, even on topics where mainstream scientific opinion overwhelmingly favored X.</p>
</div>
<div data-magellan-destination="sec7" id="sec7">
<h2> ENDOGENOUS CHANGE ON WIKIPEDIA</h2>
<div data-magellan-destination="sec8" id="sec8">
<h3> Explaining the Findings</h3>
<p> The paper has demonstrated that English Wikipedia content changed over time. This section seeks to explain <em>why</em> the content changed. In doing so, the paper uses process tracing. The paper systematically analyzes the internal Wikipedia discussion forums where editors duked out content. More specially, the paper analyzes the archived talk pages of the 63 articles and relevant discussions about article content on general noticeboards.<a href="#fn20"><span>Footnote </span>
<sup>20</sup></a> To classify editors into the Anti-Fringe camp (AF) and the Pro-Fringe camp (PF), the paper uses a variety of data sources: the viewpoints expressed by editors on the article talk pages themselves, the views expressed by editors brought up for sanctioning on the Administrators’ noticeboard or the “Requests for Enforcement” page before the Arbitration Committee, and lists of editors brought up in arbitration committee rulings.</p>
<p> These data sources provide article-by-article evidence about relevant individual editors on the pages in question. However, to assess systematically what happens to AF and PF editors across the English Wikipedia (not just the 63 articles), the paper uses a sample of referenda where editors are implicitly asked whether they support a pro- or anti-fringe interpretation of the NPOV guideline. The user histories of the participants in the referenda are then analyzed to uncover whether they are still active or whether they have voluntarily left Wikipedia, substantially reduced their number of contributions, been banned from the relevant topics, or blocked from Wikipedia in its entirety.</p>
<p> The evidence is broadly consistent with the observable implications of the paper’s theory of endogenous institutional change (the processes of the theory are outlined in <a href="#fig2">Figure 2</a>).<a href="#fn21"><span>Footnote </span>
<sup>21</sup></a>
</p><div data-magellan-destination="fig2" id="fig2">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig2.png?pub-status=live" width="1758" height="1185" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig2.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230308104251995-0268:S0003055423000138:S0003055423000138_fig2.png"></p>
<div><p><span>Figure 2.</span> How Did the NPOV Rule Change?</p>
</div></div>
<p> The key piece of evidence is that PF members disappear over time in the wake of losses, both voluntarily and involuntarily. PF members are those who vote affirmatively for policies that normalize or lend credence to fringe viewpoints, who edit such content into articles, and who vote to defend fellow members of PF when there are debates as to whether they engaged in wrongdoing. Members of AF do the opposite.</p>
<p> The causal mechanism for the gradual disappearance is that early losses demotivated members from PF or led to their sanctioning, whereas members of AF were empowered by early victories. As exits of PF members mount across the encyclopedia, the community increasingly adopts AF’s viewpoints as the way that the NPOV guideline should be understood.</p>
<div data-magellan-destination="sec9" id="sec9">
<h4> Step 1: Rule Ambiguity</h4>
<p> The NPOV rule of Wikipedia is ambiguous in its specific application. During the early period of Wikipedia, Wikipedia’s NPOV rule was understood as indicating a “describe-the-controversy” approach to disputes between sources: Wikipedia should not take sides on contested issues, and Wikipedia should be open to a diverse array of sources. Thus, the policy allowed for inclusion of lower-quality sources, so long as they were attributed. This meant that if sources disagreed in terms of how they covered the topic of homeopathy, the Wikipedia article on homeopathy would present both sides of the issue and avoid taking a firm stance. The Wikipedia page on homeopathy included text that effectively said “Advocates for homeopathy say…” and “Critics of homeopathy say…,” whereas it was frowned upon among early Wikipedians to state decisively in Wikipedia’s own voice that “Homeopathy is a pseudoscientific system of alternative medicine” (as the first line of the Wikipedia page stated in 2020). This was largely in line with Larry Sanger’s intentions when he crafted the NPOV rule (ArsTechnica <a href="#r1">2014</a>).</p>
</div>
<div data-magellan-destination="sec10" id="sec10">
<h4> Step 2: Clashes between Camps over Rule Interpretations</h4>
<p> On contentious topics (e.g., American politics, conspiracy theories, and pseudoscience), editors had vast differences in terms of how they understood the application of Wikipedia’s rules. Editors who were anti-conspiracy theories, anti-pseudoscience, and liberal (the AF camp) pushed understandings of NPOV that took a firm anti-conspiracy-theory and anti-pseudoscience stance. Thus, they argued for reliance on strong sources (such as studies and highly reputable mainstream news outlets), nonuse of lower-quality sources (such as partisan outlets and disreputable outlets), stating claims from strong sources in Wikipedia’s own voice (rather than attributing them as a source’s opinion), firmly stating that minority views are fringe, and stating that falsehoods are falsehoods.</p>
<p> Editors who were more supportive of conspiracy theories, pseudoscience, and conservatism (the PF camp) argued for reliance on sources across a broad range of reliability (in part, because they perceived academics and newspapers of record to be biased), stating claims from sources as if they were always an attributed POV, and avoiding firm stances on the state of a controversy.</p>
<p> On the homeopathy page, this meant that PF members raised questions about relying on reporting by the <em>New York Times</em> and <em>Washington Post</em>, insisted that studies skeptical of homeopathy’s efficacy be phrased as opinion, and sought to include rebuttals by pro-homeopathy organizations and pseudoscientists. AF members held the opposite view, as they sought to phrase skeptical content in Wikipedia’s own voice and strongly opposed content sourced to pro-homeopathy organizations.</p>
</div>
<div data-magellan-destination="sec11" id="sec11">
<h4> Step 3: Formation of a Power Asymmetry</h4>
<p> Over the course of years, AF successfully shaped how to understand the practical application of Wikipedia’s NPOV guideline. These early victories gave AF an upper hand in editing disputes on pages related to conspiracy theories, pseudoscience, and American politics. There was no single critical juncture. Rather, there were many gradual mutually reinforcing steps across several spheres of Wikipedia.</p>
<p> One type of change that was important early in Wikipedia’s development was intervention into content disputes by arbitrators on highly dysfunctional pages. Highly dysfunctional pages are those characterized by edit-warring among a multitude of editors to the point that the pages are unstable over extended periods of time, and editors cannot even agree on the status quo version of the pages.</p>
<p> Two particularly important early arbitration rulings in the early years were the arbitration committee cases on climate change (2005) and pseudoscience (2006), which largely reaffirmed some viewpoints held by AF in those specific disputes and led to sanctions that primarily targeted prolific PF editors (although some AF editors were also targeted) for behavioral wrongdoing. The disputes were at their core about edit-warring between different camps as to whether climate change articles should reflect the scientific consensus on climate change or lend weight to those who dispute the scientific consensus, and broadly about how pseudoscientific ideas and minority scientific perspectives should be framed.</p>
<p> A second type of important changes involve the writing of guidelines to supplement the existing NPOV guideline and clarify how the NPOV guideline should be applied. This includes the creation of the Reliable Sources guideline (2005), which introduced a basic framework for evaluating the reliability of sources, the Fringe Theory guideline (2007), which introduced a basic framework for evaluating minority views and fringe views, and the Reliable Sources (Medicine) guideline (2008), which set a higher quality threshold for sources on medicine-related topics out of a concern that poorly sourced content could cause harm to readers.</p>
<p> These guidelines were crafted by a relatively small set of experienced editors, including many from AF who were involved in active content disputes on topics that related to these rules. All editors can participate in processes to change rules and add supplements to rules. These changes must go through the normal Wikipedia consensus decision-making process. While these particular rules were not written to specifically address content in those disputes, the enactment of these rules as supplemental modifications to the NPOV guideline would prove useful in those disputes. Furthermore, discussions related to those rules showed that editors wanted to privilege science and academic expertise in terms of identifying what is fringe, but the Reliable Sources and Fringe Theory guidelines were broad enough in scope that they could also be used to identify fringe discourse and beliefs outside of science, such as with conspiracy theories and extremist rhetoric in politics.</p>
</div>
<div data-magellan-destination="sec12" id="sec12">
<h4> Step 4: Reinterpretation of Wikipedia’s Rules</h4>
<p> The early victories and selective departures had positive feedback effects for three reasons: (i) they enhanced the value of experience, (ii) they created a numerical advantage, and (iii) they spurred a sourcing bias. Consequently, AF editors experienced greater success in editing, whereas PF editors did not, which led to lopsided exits over time. Together, these factors led AF to increasingly get what it wanted and sway the broader Wikipedia userbase to see one interpretation of the rules as the undisputed accurate interpretation of the rules.</p>
<p> First, experience matters a great deal on Wikipedia, which makes disproportionate exits early on highly consequential. Since Wikipedia is notoriously complicated for new editors to maneuver, experienced editors have a decisive advantage in content disputes (Jemielniak <a href="#r20"><span>Reference Jemielniak</span>2014</a>). Experience helps in understanding the rules, norms, and processes of Wikipedia. This leads to greater success in content disputes and edit wars, as well as makes experienced editors able to drive disruptive “newcomers” away from Wikipedia and instill in newcomers’ certain understandings of how rules should be interpreted. Experience also raises the likelihood of becoming an administrator, thereby gaining the power to enforce the rules and sanction editors.<a href="#fn22"><span>Footnote </span>
<sup>22</sup></a> Additionally, experience increases the likelihood of participation in general noticeboard discussions where sanctions of individual editors and specific rule interpretations are discussed in detail. Experienced editors also become aware of administrator elections and arbitration committee elections, which are important levers of power on Wikipedia.</p>
<p> Second, there is power in numbers. It is easier for PF members to fall afoul of the rules if they are frequently at a numerical disadvantage in editing disputes. It makes them less likely to win content disputes (which are often determined by numbers), forces them to spend more time to advance their views, and makes them more likely to have to edit war (make frequent reverts of AF editors). Whereas multiple AF editors can share the burden of doing reverts of PF’s edits and not violate any edit-warring restrictions, a PF editor may be forced to do multiple reverts, thus risking sanction.</p>
<p> Third, the gradual development of a sourcing hierarchy—whereby some sources were deemed reliable, and others were deemed unreliable—created advantages for AF editors. The culmination of a long, gradual conflict over the use of sources on Wikipedia was the 2017 vote to deprecate (ban) the <em>Daily Mail</em>, a British tabloid, from being used as a source for statements of fact. Over the next 4&nbsp;years, 38 additional sources were deprecated.</p>
<p> The gradual development of the sourcing hierarchy reflects how the Wikipedia community shifted its understanding of reliability over time, facilitated by the experience and numerical advantage of AF. An examination of pages in the early years of Wikipedia shows that Wikipedians had very lax standards for sourcing. By the mid-2000s, momentum had formed to privilege scientific publications. This did not mean that other sources were unusable, but that priority and prominence should be afforded to scientific publications. During these early years, Wikipedians did not appear to distinguish between news sources in terms of reliability in any clear manner. Articles into the 2010s show considerable usage of sources that would ultimately by the mid-2010s be deemed unreliable, including sources that were deprecated from 2017 onward.<a href="#fn24"><span>Footnote </span>
<sup>24</sup></a> Discussions about these sources in the previous years had not concluded with support to prohibit them, demonstrating a change in how the community looked at them. The key difference is that the ranks of PF editors who blocked previous attempts to ban sources had been thinned out considerably by 2017.</p>
<p> This hierarchy of sources has implications both for what kind of content can be added to Wikipedia and how it will be phrased. For example, if the <em>New York Times</em> (a source that Wikipedia editors came to recognize as highly reliable) describes something as a conspiracy theory, whereas the <em>New York Post</em> (a source that Wikipedia editors have determined to be unreliable) differs from that description, then Wikipedia content can be added that firmly states in Wikipedia’s voice that something is a conspiracy theory. Under a previous collective understanding of Wikipedia’s rules, Wikipedia’s content would not give a firm statement in Wikipedia’s voice but would rather attribute particular claims to the <em>Times</em> and attribute rebuttal claims to the <em>Post.</em> Thus, over time, Wikipedia has accepted the use of contested labels and taken sides on contested subjects, ultimately producing a type of content that is distinctly anti-pseudoscience and anti-conspiracy theories, and which has the perception of a liberal bent in U.S. politics.</p>
<p> Each shift in policy further weakened the position of PF in editing disputes and made the editing experience less rewarding for those editors because they ended up on the losing end of content disputes. Over time, PF editors responded in three ways<a href="#fn25"><span>Footnote </span>
<sup>25</sup></a>:</p><ol>
<li>
<p><span>1.</span>
<strong>Fight back:</strong> By increasingly editing against consensus and in violation of new interpretations of Wikipedia policy. These editors were subsequently banned.</p>
</li>
<li>
<p><span>2.</span>
<strong>Withdraw:</strong> By leaving Wikipedia or reducing their contributions.</p>
</li>
<li>
<p><span>3.</span>
<strong>Acquiesce:</strong> By gradually adapting to the new interpretations of Wikipedia policy.</p>
</li>
</ol>
<p> Article-by-article evidence substantiates these patterns, with prominent PF editors getting banned, retiring, or adjusting to new interpretations of Wikipedia guidelines.<a href="#fn26"><span>Footnote </span>
<sup>26</sup></a> In explaining their departure on their talk page, retired PF editors frequently decried what they perceived as Wikipedia’s increased bias, hostile editing environment, and the pointlessness of fighting against what they described as a cabal.<a href="#fn27"><span>Footnote </span>
<sup>27</sup></a> This stands in contrast to the explanations offered by non-PF members for retiring. Some PF editors proved more flexible to Wikipedia’s changing environment, acquiescing to new interpretations of Wikipedia policy. For example, a PF editor might affirm the new standards in Wikipedia’s sourcing policy by insisting that content from a source like the <em>New York Times</em> should be stated in Wikipedia’s own voice when a <em>Times</em> story criticizes a left-leaning politician or left-leaning cause. However, in doing so, those PF editors help enshrine the emerging new interpretations of Wikipedia guidelines.</p>
<p> In addition to article-by-article evidence of departures of Wikipedia editors, the paper uses a sample of hotly contested referenda (where editors are asked to express their views about the NPOV rule’s application to fringe topics) to gage whether the disappearance of PF editors (measured by their support or opposition for a fringe position) is systemic across the encyclopedia. This is a unique and useful data source that shows that the relative disappearance of PF editors is systemic.</p>
<p> The raw numbers undersell the importance of those who have departed the encyclopedia. Many of the departees were highly prolific experienced editors from PF, whereas many of the editors who sided with AF and disappeared over time were not highly prolific editors in the first place. These disproportionate exits meant that over time, understandings in line with AF’s interpretation of Wikipedia policy become taken for granted as the way the rules should be interpreted, causing gradual institutional changes that amount to a drastic institutional change over a nearly 20-year period.</p>
</div>
</div>
</div>
<div data-magellan-destination="sec13" id="sec13">
<h2> ALTERNATIVE EXPLANATIONS</h2>
<p> This paper has sought to explain why content on the English Wikipedia transformed drastically over time. The explanation hinges on endogenous factors related to early victories, feedback effects, and population loss. In this section, the paper examines two key alternative explanations, finding that they are inapplicable and generally inconsistent with the data (three additional alternative explanations are addressed in the Supplementary Material).<a href="#fn28"><span>Footnote </span>
<sup>28</sup></a></p>
<div data-magellan-destination="sec14" id="sec14">
<h3> External Events and Processes</h3>
<p> One alternative hypothesis is that external events caused ideational change among Wikipedians. For example, Donald Trump’s 2016 election, the 2016 Brexit referendum, and the emergence of “fake news” websites may have caused Wikipedians to re-evaluate how they understand the rules of Wikipedia and the role of Wikipedia in society. However, as the paper documented, the transformation on Wikipedia has been gradual over time, preceding prominent shocks from 2016. Furthermore, the emergence of “fake news” websites does not fit neatly with Wikipedians’ decision to deprecate long-standing traditional news sources, such as the <em>Daily Mail.</em> The events of 2015 and 2016 did not bring source reliability to the fore in a new way on Wikipedia. Rather, Wikipedians had intensely debated the reliability of sources for nearly a decade prior. It took Wikipedians until 2017 to start deprecating sources because the editors that previously vetoed such attempts were no longer active on the encyclopedia.<a href="#fn29"><span>Footnote </span>
<sup>29</sup></a></p>
<p> Another version of this hypothesis is that slow exogenous processes led Wikipedians to re-evaluate their own attitudes toward the guidelines. For example, Wikipedians may have increasingly come to hold more pro-LGBT views, stronger anti-racism views, and pro-science attitudes. While attitudinal change can certainly be documented among certain Wikipedians, they have remained very stable among many of those belonging to AF and PF, as they vote consistently for and against certain items in predictable ways over long time periods. If a disproportionate number of PF editors had not disappeared over time, they would have been able to block drastic changes.</p>
<p> A third version of this hypothesis is that the sources that Wikipedia relies on for content changed how they cover pseudoscience, conspiracy theories, and extremism. In other words, the news media and the scientific community changed, not Wikipedia. While it is true that Wikipedia is necessarily a reflection of what sources say, it is not correct that news sources and studies have uniformly moved in the same direction on all the subject matters listed in <a href="#tab1">Table 1</a> and the Supplementary Material. Even on subject matters where coverage has changed, such as climate change, climate change denial sources have changed tactics in how they argue against climate change. Rather than deny that any warming has occurred, they dispute the precise role of human activity, emphasize how “alarmist” mainstream climate scientists are, and highlight events that purportedly contradict the scientific consensus. Rather than reflect these updates to climate change denialism in mainstream sources, Wikipedians have simply excluded or debunked climate change denial rhetoric in articles. Furthermore, the particular sources that continued to promote pseudoscience, conspiracy theories, and extremism were over time ultimately deemed unreliable on Wikipedia.</p>
</div>
<div data-magellan-destination="sec15" id="sec15">
<h3> Influx of New Editors</h3>
<p> Anyone can create a Wikipedia account and edit. It is therefore reasonable to query whether Wikipedia experienced an influx of new editors with new ideas, thus causing the transformation over time. This would mean that the old guard of Wikipedia editors were simply replaced or outmaneuvered by a new breed of editors. There are several reasons why this is unlikely to have caused the transformation. Wikipedia has a very rigid and complex structure of rules and norms. New editors that edit in ways that older editors disapprove of often find themselves in trouble. As highlighted above, experience is a source of power of Wikipedia that makes it easier for the old guard to shape the encyclopedia, both by sanctioning disruptive newcomers and by indoctrinating newcomers into a “correct” way of editing. Newcomers, therefore, find themselves forced to assimilate or be booted off the platform. It is also unlikely that the later generation of Wikipedia editors tended to be more likely to be experts and predisposed to mainstream science than the first movers on Wikipedia. Judging by self-described descriptions of themselves, many of the earliest Wikipedians were scientists or had advanced degrees, in particular among editors on pages related to pseudoscience.</p>
</div>
</div>
<div data-magellan-destination="sec16" id="sec16">
<h2> CONCLUSION</h2>
<p> Since its inception in 2001, Wikipedia has transformed from an encyclopedia that adopted a strict “teach the controversy” approach (whereby a diversity of opinions and sources were reflected in articles) to one where Wikipedia takes firm sides on contested subjects. Whereas Wikipedia used to normalize and lend credence to pseudoscience, conspiracy theories, and fringe rhetoric, it has over time become firmly anti-pseudoscience and anti-conspiracy theories.</p>
<p> This transformation occurred through endogenous processes that were ultimately rooted in rule ambiguity, early dispute outcomes, and population loss. The resolution of early disputes in several areas of the encyclopedia demobilized certain types of editors (while mobilizing others) and strengthened certain understandings of Wikipedia’s ambiguous rules (while weakening other understandings of Wikipedia rules). Change occurred endogenously and gradually, as shared meanings from within Wikipedia’s collective about the rules got altered through a combination of compulsory power (sanctioning of dissenters by elite actors) and productive power (collective delegitimization of certain rule interpretations).</p>
<p> This explanation for institutional change on Wikipedia can plausibly help to explain institutional change in other contexts. We might observe in other institutions that institutional change happens as losers become demotivated and sanctioned, and winners become motivated and rewarded. For example, career bureaucrats might leave public service when the bureaucracy shifts toward policies that they disagree with. The bureaucrats could stay in the bureaucracy and make it harder for opponents to transform the bureaucracy, but they might instead leave the bureaucracy because they find it demotivating to fight uphill against other bureaucrats. Rather than obstruct change, the population loss of dissident bureaucrats can propel change.</p>
<p> Within political movements and parties, we can also see how establishment figures who are out of step with newly dominant ideas choose voluntarily to retire rather than obstruct change within the movement. This can plausibly be seen in the Republican Party, as Trump critics have opted to retire rather than use their position to steer the movement in a direction that they find more palatable. Similarly, victories for one side within a movement may energize winners and encourage like-minded actors to jump on the bandwagon in support of that side. This may help to explain how the Tea Party cemented its control of the Republican Party (Blum <a href="#r5"><span>Reference Blum</span>2020</a>). It may also help to explain how the conservative legal movement gradually accepted the legal theory behind the unconstitutionality of the Affordable Care Act (ACA), which was considered fringe and weak in 2010, but grew in support as conservative justices in lower courts ruled the ACA unconstitutional, ultimately almost leading the Supreme Court to rule that the ACA was unconstitutional in 2012 (a narrow 5-4 decision upheld the law while hobbling aspects of it). It may also explain why certain police department cultures form, as some police are driven out of the organization, while others get boosted. It has also been posited that the stability and strength of illiberal regimes within the European Union have gradually been strengthened as dissatisfied citizens migrate from authoritarian states to liberal states (Kelemen <a href="#r22"><span>Reference Kelemen</span>2020</a>). However, more research is needed to assess the generalizability of this endogenous mechanism for institutional change.</p>
</div>
</div>
<div>

<div data-magellan-destination="sec18" id="sec18">
<h2> DATA AVAILABILITY STATEMENT</h2>
<p> Research documentation and data that support the findings of this study are openly available in the American Political Science Review Dataverse at <a href="https://doi.org/10.7910/DVN/JZLTQR">https://doi.org/10.7910/DVN/JZLTQR</a>.</p>
</div>
<div>
<h2> ACKNOWLEDGMENTS</h2>
<p> I am grateful for elaborate feedback from Martha Finnemore and Henry Farrell on earlier versions of the manuscript. This article also benefited from comments by Bit Meehan, Eric Grynaviski, Kendrick Kuo, Michael Miller, Natalie Thompson, Yonatan Lupu, participants at the GWU Political Science Department Graduate Caucus workshop, and three anonymous reviewers in the GWU Political Science Department, as well as the editors and four anonymous reviewers at the <em>APSR.</em></p>
</div>
<div data-magellan-destination="sec19" id="sec19">
<h2> CONFLICT OF INTEREST</h2>
<p> The author declares no ethical issues or conflicts of interest in this research.</p>
</div>
<div data-magellan-destination="sec20" id="sec20">
<h2> ETHICAL STANDARDS</h2>
<p> The author affirms this research did not involve human subjects.</p>
</div>
</div>
</div>    <div id="references-list"><h2>References</h2> <div id="r2" aria-flowto="reference-3-content reference-3-button"><p><span><span>Benkler</span>, <span>Yochai</span></span>. <span>2002</span>. “<span>Coase’s Penguin or, Linux and ‘The Nature of the Firm.’</span>” <span>Yale Law Journal</span> <span>12</span>: <span>369</span>–<span>446</span>.<a target="_blank" aria-label="CrossRef link for Coase’s Penguin or, Linux and ‘The Nature of the Firm.’" href="https://dx.doi.org/10.2307/1562247">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Coase’s Penguin or, Linux and ‘The Nature of the Firm.’" href="https://scholar.google.com/scholar_lookup?title=Coase%E2%80%99s+Penguin+or%2C+Linux+and+%E2%80%98The+Nature+of+the+Firm.%E2%80%99&amp;author=Benkler+Yochai&amp;publication+year=2002&amp;journal=Yale+Law+Journal&amp;volume=12&amp;doi=10.2307%2F1562247&amp;pages=369-446">Google Scholar</a></p></div><div id="r3" aria-flowto="reference-4-content reference-4-button"><p><span><span>Bennett</span>, <span>Andrew</span></span>. <span>2008</span>. “<span>Process Tracing: A Bayesian Perspective</span>.” In <span>The Oxford Handbook of Political Methodology</span>, eds. <span><span>Box-Steffensmeier</span>, <span>Janet</span></span>, <span><span>Brady</span>, <span>Henry</span></span>, and <span><span>Collier</span>, <span>David</span></span>, <span>702</span>–21. <span>New York</span>: <span>Oxford University Press</span>.<a target="_blank" aria-label="Google Scholar link for The Oxford Handbook of Political Methodology" href="https://scholar.google.com/scholar_lookup?title=The+Oxford+Handbook+of+Political+Methodology&amp;author=Bennett+Andrew&amp;author=Box-Steffensmeier+Janet&amp;author=Brady+Henry&amp;author=Collier+David&amp;publication+year=2008">Google Scholar</a></p></div><div id="r4" aria-flowto="reference-5-content reference-5-button"><p><span><span>Bleich</span>, <span>Erik</span></span>. <span>2018</span>. “<span>Historical Institutionalism and Judicial Decision-Making: Ideas, Institutions, and Actors in French High Court Hate Speech Rulings</span>.” <span>World Politics</span> <span>70</span> (<span>1</span>): <span>53</span>–<span>85</span>.<a target="_blank" aria-label="CrossRef link for Historical Institutionalism and Judicial Decision-Making: Ideas, Institutions, and Actors in French High Court Hate Speech Rulings" href="https://dx.doi.org/10.1017/S0043887117000272">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Historical Institutionalism and Judicial Decision-Making: Ideas, Institutions, and Actors in French High Court Hate Speech Rulings" href="https://scholar.google.com/scholar_lookup?title=Historical+Institutionalism+and+Judicial+Decision-Making%3A+Ideas%2C+Institutions%2C+and+Actors+in+French+High+Court+Hate+Speech+Rulings&amp;author=Bleich+Erik&amp;publication+year=2018&amp;journal=World+Politics&amp;volume=70&amp;doi=10.1017%2FS0043887117000272&amp;pages=53-85">Google Scholar</a></p></div><div id="r5" aria-flowto="reference-6-content reference-6-button"><p><span><span>Blum</span>, <span>Rachel</span></span>. <span>2020</span>. <span>How the Tea Party Captured the GOP</span>. Chicago, IL: <span>University of Chicago Press</span>.<a target="_blank" aria-label="CrossRef link for How the Tea Party Captured the GOP" href="https://dx.doi.org/10.7208/chicago/9780226687667.001.0001">CrossRef</a><a target="_blank" aria-label="Google Scholar link for How the Tea Party Captured the GOP" href="https://scholar.google.com/scholar_lookup?title=How+the+Tea+Party+Captured+the+GOP&amp;author=Blum+Rachel&amp;publication+year=2020">Google Scholar</a></p></div><div id="r6" aria-flowto="reference-7-content reference-7-button"><p><span><span>Boreus</span>, <span>Kristina</span></span>, and <span><span>Bergström</span>, <span>Göran</span></span>. <span>2017</span>. <span>Analyzing Text and Discourse</span>. <span>Thousand Oaks, CA</span>: <span>SAGE</span>.<a target="_blank" aria-label="Google Scholar link for Analyzing Text and Discourse" href="https://scholar.google.com/scholar_lookup?title=Analyzing+Text+and+Discourse&amp;author=Boreus+Kristina&amp;author=Bergstr%C3%B6m+G%C3%B6ran&amp;publication+year=2017">Google Scholar</a></p></div><div id="r7" aria-flowto="reference-8-content reference-8-button"><p><span><span>Bruckman</span>, <span>Amy</span></span>. <span>2022</span>. <span>Should You Believe Wikipedia?</span> <span>New York</span>: <span>Cambridge University Press</span>.<a target="_blank" aria-label="CrossRef link for Should You Believe Wikipedia?" href="https://dx.doi.org/10.1017/9781108780704">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Should You Believe Wikipedia?" href="https://scholar.google.com/scholar_lookup?title=Should+You+Believe+Wikipedia%3F&amp;author=Bruckman+Amy&amp;publication+year=2022">Google Scholar</a></p></div><div id="r8" aria-flowto="reference-9-content reference-9-button"><p><span><span>Conran</span>, <span>James</span></span>, and <span><span>Thelen</span>, <span>Kathleen</span></span>. <span>2016</span>. “<span>Institutional Change</span>.” In <span>The Oxford Handbook of Historical Institutionalism</span>, eds. <span><span>Fioretos</span>, <span>Orfeo</span></span>, <span><span>Falleti</span>, <span>Tulia</span></span>, and <span><span>Sheingate</span>, <span>Adam</span></span>, <span>51</span>–<span>70</span>. <span>Oxford</span>: <span>Oxford University Press</span>.<a target="_blank" aria-label="Google Scholar link for The Oxford Handbook of Historical Institutionalism" href="https://scholar.google.com/scholar_lookup?title=The+Oxford+Handbook+of+Historical+Institutionalism&amp;author=Conran+James&amp;author=Thelen+Kathleen&amp;author=Fioretos+Orfeo&amp;author=Falleti+Tulia&amp;author=Sheingate+Adam&amp;publication+year=2016&amp;pages=51-70">Google Scholar</a></p></div><div id="r10" aria-flowto="reference-11-content reference-11-button"><p><span><span>Dietelhoff</span>, <span>Nicole</span></span>, and <span><span>Zimmermann</span>, <span>Lisbeth</span></span>. <span>2020</span>. “<span>Things We Lost in the Fire: How Different Types of Contestation Affect the Robustness of International Norms</span>.” <span>International Studies Review</span> <span>22</span> (<span>1</span>): <span>51</span>–<span>76</span>.<a target="_blank" aria-label="Google Scholar link for Things We Lost in the Fire: How Different Types of Contestation Affect the Robustness of International Norms" href="https://scholar.google.com/scholar_lookup?title=Things+We+Lost+in+the+Fire%3A+How+Different+Types+of+Contestation+Affect+the+Robustness+of+International+Norms&amp;author=Dietelhoff+Nicole&amp;author=Zimmermann+Lisbeth&amp;publication+year=2020&amp;journal=International+Studies+Review&amp;volume=22&amp;pages=51-76">Google Scholar</a></p></div><div id="r11" aria-flowto="reference-12-content reference-12-button"><p><span><span>Elkins</span>, <span>Zachary</span></span>, <span><span>Spitzer</span>, <span>Scott</span></span>, and <span><span>Tallberg</span>, <span>Jonas</span></span>. <span>2021</span>. “<span>Non-Automated Content Analysis</span>.” <span>Perspectives on Politics</span> 19 (1): 198–9. In “The Qualitative Transparency Deliberations: Insights and Implications,” by Alan M. Jacobs, Tim Büthe, Ana Arjona, Leonardo R. Arriola, Eva Bellin, Andrew Bennett, Lisa Björkman, et al. <em>Perspectives on Politics</em> 19 (1): 171–208.<a target="_blank" aria-label="Google Scholar link for Non-Automated Content Analysis" href="https://scholar.google.com/scholar_lookup?title=Non-Automated+Content+Analysis&amp;author=Elkins+Zachary&amp;author=Spitzer+Scott&amp;author=Tallberg+Jonas&amp;publication+year=2021">Google Scholar</a></p></div><div id="r12" aria-flowto="reference-13-content reference-13-button"><p><span><span>George</span>, <span>Alexander</span></span>, and <span><span>Bennett</span>, <span>Andrew</span></span>. <span>2005</span>. <span>Case Studies and Theory Development in the Social Sciences</span>. <span>Cambridge, MA</span>: <span>MIT Press</span>.<a target="_blank" aria-label="Google Scholar link for Case Studies and Theory Development in the Social Sciences" href="https://scholar.google.com/scholar_lookup?title=Case+Studies+and+Theory+Development+in+the+Social+Sciences&amp;author=George+Alexander&amp;author=Bennett+Andrew&amp;publication+year=2005">Google Scholar</a></p></div><div id="r13" aria-flowto="reference-14-content reference-14-button"><p><span><span>Gerschewski</span>, <span>Johannes</span></span>. <span>2021</span>. “<span>Explanations of Institutional Change: Reflecting on a ‘Missing Diagonal.’</span>” <span>American Political Science Review</span> <span>115</span> (<span>1</span>): <span>218</span>–33.<a target="_blank" aria-label="CrossRef link for Explanations of Institutional Change: Reflecting on a ‘Missing Diagonal.’" href="https://dx.doi.org/10.1017/S0003055420000751">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Explanations of Institutional Change: Reflecting on a ‘Missing Diagonal.’" href="https://scholar.google.com/scholar_lookup?title=Explanations+of+Institutional+Change%3A+Reflecting+on+a+%E2%80%98Missing+Diagonal.%E2%80%99&amp;author=Gerschewski+Johannes&amp;publication+year=2021&amp;journal=American+Political+Science+Review&amp;volume=115&amp;doi=10.1017%2FS0003055420000751">Google Scholar</a></p></div><div id="r14" aria-flowto="reference-15-content reference-15-button"><p><span><span>Greenstein</span>, <span>Shane</span></span>, <span><span>Gu</span>, <span>Grace</span></span>, and <span><span>Zhu</span>, <span>Feng</span></span>. <span>2021</span>. “<span>Ideology and Composition Among an Online Crowd: Evidence from Wikipedians</span>.” <span>Management Science</span> <span>67</span> (<span>5</span>): <span>3067</span>–86.<a target="_blank" aria-label="CrossRef link for Ideology and Composition Among an Online Crowd: Evidence from Wikipedians" href="https://dx.doi.org/10.1287/mnsc.2020.3661">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Ideology and Composition Among an Online Crowd: Evidence from Wikipedians" href="https://scholar.google.com/scholar_lookup?title=Ideology+and+Composition+Among+an+Online+Crowd%3A+Evidence+from+Wikipedians&amp;author=Greenstein+Shane&amp;author=Gu+Grace&amp;author=Zhu+Feng&amp;publication+year=2021&amp;journal=Management+Science&amp;volume=67&amp;doi=10.1287%2Fmnsc.2020.3661">Google Scholar</a></p></div><div id="r15" aria-flowto="reference-16-content reference-16-button"><p><span><span>Hannan</span>, <span>Michael</span></span>, and <span><span>Freeman</span>, <span>John</span></span>. <span>1977</span>. “<span>The Population Ecology of Organizations</span>.” <span>American Journal of Sociology</span> <span>82</span> (<span>5</span>): <span>929</span>–64.<a target="_blank" aria-label="CrossRef link for The Population Ecology of Organizations" href="https://dx.doi.org/10.1086/226424">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The Population Ecology of Organizations" href="https://scholar.google.com/scholar_lookup?title=The+Population+Ecology+of+Organizations&amp;author=Hannan+Michael&amp;author=Freeman+John&amp;publication+year=1977&amp;journal=American+Journal+of+Sociology&amp;volume=82&amp;doi=10.1086%2F226424">Google Scholar</a></p></div><div id="r17" aria-flowto="reference-18-content reference-18-button"><p><span><span>Herrera</span>, <span>Yoshiko</span></span>, and <span><span>Braumoeller</span>, <span>Bear</span></span>. <span>2004</span>. “<span>Symposium: Discourse and Content Analysis</span>.” <span>Qualitative Methods</span> <span>2</span> (<span>1</span>): <span>15</span>–<span>19</span>.<a target="_blank" aria-label="Google Scholar link for Symposium: Discourse and Content Analysis" href="https://scholar.google.com/scholar_lookup?title=Symposium%3A+Discourse+and+Content+Analysis&amp;author=Herrera+Yoshiko&amp;author=Braumoeller+Bear&amp;publication+year=2004&amp;journal=Qualitative+Methods&amp;volume=2&amp;pages=15-19">Google Scholar</a></p></div><div id="r19" aria-flowto="reference-20-content reference-20-button"><p><span><span>Hirschman</span>, <span>Albert</span></span>. <span>1970</span>. <span>Exit, Voice, and Loyalty</span>. <span>Cambridge, MA</span>: <span>Harvard University Press</span>.<a target="_blank" aria-label="Google Scholar link for Exit, Voice, and Loyalty" href="https://scholar.google.com/scholar_lookup?title=Exit%2C+Voice%2C+and+Loyalty&amp;author=Hirschman+Albert&amp;publication+year=1970">Google Scholar</a></p></div><div id="r20" aria-flowto="reference-21-content reference-21-button"><p><span><span>Jemielniak</span>, <span>Dariusz</span></span>. <span>2014</span>. <span>Common Knowledge?: An Ethnography of Wikipedia</span>. <span>Redwood City, CA</span>: <span>Stanford University Press</span>.<a target="_blank" aria-label="Google Scholar link for Common Knowledge?: An Ethnography of Wikipedia" href="https://scholar.google.com/scholar_lookup?title=Common+Knowledge%3F%3A+An+Ethnography+of+Wikipedia&amp;author=Jemielniak+Dariusz&amp;publication+year=2014">Google Scholar</a></p></div><div id="r21" aria-flowto="reference-22-content reference-22-button"><p><span><span>Jepperson</span>, <span>Ronald</span></span>, and <span><span>Meyer</span>, <span>John</span></span>. <span>2021</span>. <span>Institutional Theory</span>. <span>New York</span>: <span>Cambridge University Press</span>.<a target="_blank" aria-label="CrossRef link for Institutional Theory" href="https://dx.doi.org/10.1017/9781139939744">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Institutional Theory" href="https://scholar.google.com/scholar_lookup?title=Institutional+Theory&amp;author=Jepperson+Ronald&amp;author=Meyer+John&amp;publication+year=2021">Google Scholar</a></p></div><div id="r22" aria-flowto="reference-23-content reference-23-button"><p><span><span>Kelemen</span>, <span>R. Daniel</span></span>. <span>2020</span>. “<span>The European Union’s Authoritarian Equilibrium</span>.” <span>Journal of European Public Policy</span> <span>27</span> (<span>3</span>): <span>481</span>–99.<a target="_blank" aria-label="CrossRef link for The European Union’s Authoritarian Equilibrium" href="https://dx.doi.org/10.1080/13501763.2020.1712455">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The European Union’s Authoritarian Equilibrium" href="https://scholar.google.com/scholar_lookup?title=The+European+Union%E2%80%99s+Authoritarian+Equilibrium&amp;author=Kelemen+R.+Daniel&amp;publication+year=2020&amp;journal=Journal+of+European+Public+Policy&amp;volume=27&amp;doi=10.1080%2F13501763.2020.1712455">Google Scholar</a></p></div><div id="r25" aria-flowto="reference-25-content reference-25-button"><p><span><span>Mahoney</span>, <span>James</span></span>, and <span><span>Thelen</span>, <span>Kathleen</span></span>, eds. <span>2009</span>. <span>Explaining Institutional Change</span>. <span>New York</span>: <span>Cambridge University Press</span>.<a target="_blank" aria-label="CrossRef link for Explaining Institutional Change" href="https://dx.doi.org/10.1017/CBO9780511806414">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Explaining Institutional Change" href="https://scholar.google.com/scholar_lookup?title=Explaining+Institutional+Change&amp;author=Mahoney+James&amp;author=Thelen+Kathleen&amp;publication+year=2009">Google Scholar</a></p></div><div id="r26" aria-flowto="reference-26-content reference-26-button"><p><span><span>Piskorski</span>, <span>Mikolaj Jan</span></span>, and <span><span>Gorbatai</span>, <span>Sndreea</span></span>. <span>2017</span>. “<span>Testing Coleman’s Social-Norm Enforcement Mechanism: Evidence from Wikipedia</span>.” <span>American Journal of Sociology</span> <span>122</span> (<span>4</span>): <span>1183</span>–222.<a target="_blank" aria-label="CrossRef link for Testing Coleman’s Social-Norm Enforcement Mechanism: Evidence from Wikipedia" href="https://dx.doi.org/10.1086/689816">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Testing Coleman’s Social-Norm Enforcement Mechanism: Evidence from Wikipedia" href="https://scholar.google.com/scholar_lookup?title=Testing+Coleman%E2%80%99s+Social-Norm+Enforcement+Mechanism%3A+Evidence+from+Wikipedia&amp;author=Piskorski+Mikolaj+Jan&amp;author=Gorbatai+Sndreea&amp;publication+year=2017&amp;journal=American+Journal+of+Sociology&amp;volume=122&amp;doi=10.1086%2F689816">Google Scholar</a></p></div><div id="r27" aria-flowto="reference-27-content reference-27-button"><p><span><span>Reagle</span>, <span>Joseph</span></span>. <span>2010</span>. <span>Good Faith Collaboration: The Culture of Wikipedia</span>. <span>Cambridge, MA</span>: <span>MIT Press</span>.<a target="_blank" aria-label="CrossRef link for Good Faith Collaboration: The Culture of Wikipedia" href="https://dx.doi.org/10.7551/mitpress/8051.001.0001">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Good Faith Collaboration: The Culture of Wikipedia" href="https://scholar.google.com/scholar_lookup?title=Good+Faith+Collaboration%3A+The+Culture+of+Wikipedia&amp;author=Reagle+Joseph&amp;publication+year=2010">Google Scholar</a></p></div><div id="r30" aria-flowto="reference-30-content reference-30-button"><p><span><span>Sandholtz</span>, <span>Wayne</span></span>. <span>2008</span>. “<span>Dynamics of International Norm Change: Rules Against Wartime Plunder</span>.” <span>European Journal of International Relations</span> <span>14</span> (<span>1</span>): <span>101</span>–31.<a target="_blank" aria-label="CrossRef link for Dynamics of International Norm Change: Rules Against Wartime Plunder" href="https://dx.doi.org/10.1177/1354066107087766">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Dynamics of International Norm Change: Rules Against Wartime Plunder" href="https://scholar.google.com/scholar_lookup?title=Dynamics+of+International+Norm+Change%3A+Rules+Against+Wartime+Plunder&amp;author=Sandholtz+Wayne&amp;publication+year=2008&amp;journal=European+Journal+of+International+Relations&amp;volume=14&amp;doi=10.1177%2F1354066107087766">Google Scholar</a></p></div><div id="r31" aria-flowto="reference-31-content reference-31-button"><p><span><span>Sandholtz</span>, <span>Wayne</span></span>, and <span><span>Stiles</span>, <span>Kendall</span></span>. <span>2009</span>. <span>International Norms and Cycles of Change</span>. <span>Oxford</span>: <span>Oxford University Press</span>.<a target="_blank" aria-label="Google Scholar link for International Norms and Cycles of Change" href="https://scholar.google.com/scholar_lookup?title=International+Norms+and+Cycles+of+Change&amp;author=Sandholtz+Wayne&amp;author=Stiles+Kendall&amp;publication+year=2009">Google Scholar</a></p></div><div id="r33" aria-flowto="reference-33-content reference-33-button"><p><span><span>Shi</span>, <span>Feng</span></span>, <span><span>Teplitskiy</span>, <span>Misha</span></span>, <span><span>Duede</span>, <span>Eamon</span></span>, and <span><span>Evans</span>, <span>James A.</span></span>. <span>2019</span>. “<span>The Wisdom of Polarized Crowds</span>.” <span>Nature Human Behavior</span> <span>3</span>: <span>329</span>–36.<a target="_blank" aria-label="CrossRef link for The Wisdom of Polarized Crowds" href="https://dx.doi.org/10.1038/s41562-019-0541-6">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The Wisdom of Polarized Crowds" href="https://scholar.google.com/scholar_lookup?title=The+Wisdom+of+Polarized+Crowds&amp;author=Shi+Feng&amp;author=Teplitskiy+Misha&amp;author=Duede+Eamon&amp;author=Evans+James+A.&amp;publication+year=2019&amp;journal=Nature+Human+Behavior&amp;volume=3&amp;doi=10.1038%2Fs41562-019-0541-6">Google Scholar</a><a target="_blank" aria-label="PubMed link for The Wisdom of Polarized Crowds" href="https://www.ncbi.nlm.nih.gov/pubmed/30971793">PubMed</a></p></div><div id="r34" aria-flowto="reference-35-content reference-35-button"><p><span><span>Streeck</span>, <span>Wolfgang</span></span>, and <span><span>Thelen</span>, <span>Kathleen</span></span>. <span>2005</span>. <span>Beyond Continuity</span>. <span>Oxford</span>: <span>Oxford University Press</span>.<a target="_blank" aria-label="Google Scholar link for Beyond Continuity" href="https://scholar.google.com/scholar_lookup?title=Beyond+Continuity&amp;author=Streeck+Wolfgang&amp;author=Thelen+Kathleen&amp;publication+year=2005">Google Scholar</a></p></div><div id="r36" aria-flowto="reference-37-content reference-37-button"><p><span><span>Tkacz</span>, <span>Nathaniel</span></span>. <span>2015</span>. <span>Wikipedia and the Politics of Openness</span>. <span>Chicago, IL</span>: <span>University of Chicago Press</span>.<a target="_blank" aria-label="Google Scholar link for Wikipedia and the Politics of Openness" href="https://scholar.google.com/scholar_lookup?title=Wikipedia+and+the+Politics+of+Openness&amp;author=Tkacz+Nathaniel&amp;publication+year=2015">Google Scholar</a></p></div><div id="r38" aria-flowto="reference-39-content reference-39-button"><p><span><span>Voeten</span>, <span>Erik</span></span>. <span>2020</span>. “<span>Making Sense of the Design of International Institutions</span>.” <span>Annual Review of Political Science</span> <span>22</span>: <span>147</span>–63.<a target="_blank" aria-label="CrossRef link for Making Sense of the Design of International Institutions" href="https://dx.doi.org/10.1146/annurev-polisci-041916-021108">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Making Sense of the Design of International Institutions" href="https://scholar.google.com/scholar_lookup?title=Making+Sense+of+the+Design+of+International+Institutions&amp;author=Voeten+Erik&amp;publication+year=2020&amp;journal=Annual+Review+of+Political+Science&amp;volume=22&amp;doi=10.1146%2Fannurev-polisci-041916-021108">Google Scholar</a></p></div><div id="r39" aria-flowto="reference-40-content reference-40-button"><p><span><span>Wiener</span>, <span>Antje</span></span>. <span>2009</span>. “<span>Enacting Meaning-in-Use: Qualitative Research on Norms and International Relations</span>.” <span>Review of International Studies</span> <span>35</span> (<span>1</span>): <span>175</span>–93.<a target="_blank" aria-label="CrossRef link for Enacting Meaning-in-Use: Qualitative Research on Norms and International Relations" href="https://dx.doi.org/10.1017/S0260210509008377">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Enacting Meaning-in-Use: Qualitative Research on Norms and International Relations" href="https://scholar.google.com/scholar_lookup?title=Enacting+Meaning-in-Use%3A+Qualitative+Research+on+Norms+and+International+Relations&amp;author=Wiener+Antje&amp;publication+year=2009&amp;journal=Review+of+International+Studies&amp;volume=35&amp;doi=10.1017%2FS0260210509008377">Google Scholar</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spain lives in flats: why we have built our cities vertically (439 pts)]]></title>
            <link>https://especiales.eldiario.es/spain-lives-in-flats/</link>
            <guid>38189840</guid>
            <pubDate>Wed, 08 Nov 2023 13:08:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://especiales.eldiario.es/spain-lives-in-flats/">https://especiales.eldiario.es/spain-lives-in-flats/</a>, See on <a href="https://news.ycombinator.com/item?id=38189840">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>This is the Torre Hercón (Hercón Tower) in A Coruña. It has 31 floors, 24 of which are dwelling units. It was inaugurated in 1975 and is the tallest building in Galicia🏙️</p><p id="inicio-navbar">It was developed by a publicly 'protected' (subsidised) housing cooperative. The architect convinced them to build high-rise and that the flats should be large, well-ventilated and well-lit☀️</p><p>Tall buildings allow for more people to live in less space. A Coruña is the city with the largest average building height in Spain and some of its square kilometres are the most densely populated in the entire country.</p><div id="step" data-step="5"><p>Let's look at the map, which shows all the buildings constructed in the capital of the Galician province according to their height. The ones in pink are the <span>tallest buildings</span> and the ones in green are the ones with <span>the fewest floors.</span></p><p><img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/leyenda-edificio-en.svg" width="250px"></p></div><p>In A Coruña, as in all big Spanish cities, people live in apartments🏢</p><div id="step" data-step="7"><p>Spain is one of the countries with the highest percentages of apartment dwellers in the world, according to data from the OECD.</p><p>The concentration of population in a small spaces is even greater than in countries such as Switzerland, Germany or Italy. Only in South Korea more people live in collective dwellings than in Spain.</p><p>Percentage (%) of population living in collective dwellings, as opposed to single-family houses and townhouses</p><table><tbody><tr><th>Country</th><th>% living in apartments</th></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/kr.png" width="20px"> South Korea</td><td><div><p>74%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/es.png" width="20px"> Spain</td><td><div><p>65%</p></div></td></tr><tr></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/ch.png" width="20px"> Switzerland</td><td><div><p>62%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/gr.png" width="20px"> Greece</td><td><div><p>59%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/de.png" width="20px"> Germany</td><td><div><p>56%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/it.png" width="20px"> Italy</td><td><div><p>53%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/se.png" width="20px"> Sweden</td><td><div><p>47%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/pt.png" width="20px"> Portugal</td><td><div><p>45%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/jp.png" width="20px"> Japan</td><td><div><p>44%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/eu.png" width="20px"> EU</td><td><div><p>41%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/fr.png" width="20px"> France</td><td><div><p>34%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/ca.png" width="20px"> Canada</td><td><div><p>33%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/us.png" width="20px"> USA</td><td><div><p>26%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/be.png" width="20px"> Belgium</td><td><div><p>22%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/nl.png" width="20px"> Netherlands</td><td><div><p>21%</p></div></td></tr><tr><td><img src="https://raw.githubusercontent.com/hampusborgos/country-flags/main/png100px/gb.png" width="20px"> UK</td><td><div><p>15%</p></div></td></tr></tbody></table><p>Source: OCDE</p><p>Why and how did we get here? Join us on this historical tour and we'll show you.</p></div><p>Let's travel to Barcelona's old town: the Ciutat Vella district. These narrow streets were enclosed by a wall 🏰 until 1854.</p><div id="step" data-step="9"><p>The population density was high. It was believed that diseases🦠 were spread in the form of poisonous air through miasmas. This is how cholera was depicted in the 19th century 👇</p><p><img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/colera-imagen.jfif" width="100%"></p></div><p>Ildefons Cerdà wanted to demonstrate that the high population density was deadly. With his design of the Eixample, influenced by the hygienist movement, his proposed planning for the city lowered population density and regenerated the air.</p><p>Cerdà thought of open blocks with interior gardens🌳. Speculation truncated his plan. In the end, some areas of the Eixample became denser than the Ciutat Vella.</p><p>Today, Barcelona is one of the tallest and densest cities in the country. So are the municipalities on its periphery, such as L'Hospitalet or Santa Coloma, which grew from the 1950s onwards, as a result of the rural exodus👨🌾.</p><div id="step" data-step="13"><p>Data from the Spanish Cadastre (not includign Euskadi and Navarra) shows this relationship in most Spanish cities. <span>The taller</span> the constructions in the cities are, the higher its population density. In addition to the Barcelona metropolitan area, other urban areas such as Cádiz and Valencia are among the densest and tallest so far.</p><div id="contenedor-circulos-altura-municipios"><p>Comparison between population density and average height of cities with more than 20,000 inhabitants<img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/dedo.png" alt="scroll"></p><p>Source: Spanish Cadastre, INE (Spanish Statistical Office)</p></div></div><p>Between 1950 and 1975, thousands of Spaniards migrated from the countryside🚜to the city🌆. Franco's dictatorship Ministry of Housing promoted the construction of high-rise housing estates to accommodate them.</p><p>This is the "Antonio Rueda" housing group, consisting of 1,002 low-income social housing units. This type of development was influenced by the modern movement.</p><div id="step" data-step="16"><p>During the 60's and 70's more dwellings were built in Spain, and these were higher than ever. Thus, the first 'metropolitan crowns' were created, surrounding the historic nuclei and the 'ensanches' (widenings) of the beginning of the century. 👇</p><p>Buildings with 5 or more stories per decade</p><div><p><img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/grafico-evolucion-mas5plantas.svg" width="100%"></p><p>Source: Spanish Cadastre</p></div></div><div id="step" data-step="17"><p>Housing blocks built under Francoist developmentalism started with four stories because there was no money for elevators. Then came the H-shaped blocks, which incorporated an elevator and more stories so as to make it profitable. The distribution of dwellings in each city according to the number of floors in the building shows this phenomenon.</p><p>For example, most of the industrial belts within large cities concentrate their housing in 5-story buildings. Also developed in the 1970s, other industrial estates such as Fuenlabrada, Alcorcón and L'Hospitalet condense most of their housing in buildings with seven, eight or more floors.</p><div id="contenedor-alturas-grupos-viviendas"><p>Distribution of dwellings in each municipality according to the number of floors of the building<img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/dedo.png" alt="scroll"></p><p>Source: Spanish Cadastre</p></div></div><p>An example of these H-shaped polygon developments is in Móstoles, on the outskirts of Madrid.</p><p>From the 1980s onwards, the rural exodus slowed down. At the same time, the 'urban sprawl'🏡, inspired by American suburbs, arrived in Spain.</p><p>Municipalities such as Sant Cugat del Vallès (Barcelona), Godella (Valencia) or Pozuelo (Madrid) are good examples of urban sprawl.</p><p>The housing is single-family🏠. The population density is very low, which increases the cost of public services.</p><p>But such real estate is a luxury and does not reach many people. Urban sprawl would continue in the form of townhouses🏘️, especially during the 1990s, and housing blocks.</p><p>In Santa Marta de Tormes, in the metropolitan area of Salamanca, there are several developments of townhouses, also called 'pearl necklaces'.</p><div id="step" data-step="24"><p>This change is clearly shown in the evolution of housing built in each decade in Spain. While buildings of five or more floors were in the majority during the first development boom in the 1960s and 1970s, during the real-estate bubble mainly low-rise dwellings were built.</p><div id="contenedor-alturas-evolucion-decadas"><p>Evolution of the number of dwellings built in each decade, according to the number of floors of the building<img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/dedo.png" alt="scroll"></p><p>Source: Spanish Cadastre</p></div></div><p>Parallel to the townhouse fever, and after the polygons and H-blocks, came the next generation of housing blocks: the perimeter block, which would predominate from the 1990s until the bursting of the real-estate bubble and after the recovery.</p><p>Parque Venecia, a neighborhood in Zaragoza, is a prime example of a new neighborhood with perimeter blocks. It was planned in the middle of the bubble and its urbanization began in 2008. Its 7,000 residents, young families with children, <span><a href="https://www.heraldo.es/noticias/aragon/zaragoza/2021/06/27/parque-venecia-cumple-diez-anos-con-el-80-de-los-pisos-ejecutados-y-a-la-espera-de-mas-servicios-en-zaragoza-1502452.html" target="_blank">have denounced the lack of public services. </a></span>.</p><p>These new 'ensanches' offer more affordable housing than the consolidated city and attract the middle classes. They tend to be sparse and disconnected from the city.</p><div id="step" data-step="28"><p>City centers rised in value before the outbreak of COVID-19. After the pandemic, the demand for single-family homes and apartments in the metropolitan areas has increased.</p><p>Evolution of the percentage (%) of single-family home sales and purchases</p><div><p><img src="https://especiales.eldiario.es/spain-lives-in-flats/assets/grafico-evolucion-unifamiliares.svg" width="100%"></p><p>Source: Bank of Spain</p></div></div><p>But contemporary urban planning trends point in another direction: compact, complex and cohesive cities.</p><p>What is the appropriate height for a city? And what is the appropiate density? Where is Spanish urban planning heading and where should it be heading?</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intermittent fasting more effective than calorie restriction (210 pts)]]></title>
            <link>https://pubmed.ncbi.nlm.nih.gov/37889487/</link>
            <guid>38189838</guid>
            <pubDate>Wed, 08 Nov 2023 13:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pubmed.ncbi.nlm.nih.gov/37889487/">https://pubmed.ncbi.nlm.nih.gov/37889487/</a>, See on <a href="https://news.ycombinator.com/item?id=38189838">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-page" data-article-pmid="37889487">
    

    <main id="article-details">
  
  
<!-- "Filters applied" shows only when page is redirected from search -->
<!-- because search found one result -->

  

  

  

  



  


<header id="heading">
  
    
      <div id="full-view-heading">
        
          <div>
            
  <p>Randomized Controlled Trial</p>


            
  
    <div>
      
<p><span>. </span><span>2023 Oct 2;6(10):e2339337.</span>

    </p></div>
  
  
    
      <p><span>
        doi: 10.1001/jamanetworkopen.2023.39337.
      </span>
    
    
    
    
  


          </p></div>
          



          

          <div>
    <p><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Cienfuegos+S&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Sofia Cienfuegos">Sofia Cienfuegos</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Lin+S&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Shuhao Lin">Shuhao Lin</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Ezpeleta+M&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Mark Ezpeleta">Mark Ezpeleta</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Ready+K&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Kathleen Ready">Kathleen Ready</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Corapi+S&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Sarah Corapi">Sarah Corapi</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Wu+J&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Jackie Wu">Jackie Wu</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Lopez+J&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Jason Lopez">Jason Lopez</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Gabel+K&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Kelsey Gabel">Kelsey Gabel</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Tussing-Humphreys+L&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Lisa Tussing-Humphreys">Lisa Tussing-Humphreys</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a><span>&nbsp;</span><a title="University of Illinois Cancer Center, University of Illinois Chicago." href="#full-view-affiliation-2" ref="linksrc=author_aff">
                2
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Oddo+VM&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Vanessa M Oddo">Vanessa M Oddo</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Alexandria+SJ&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Shaina J Alexandria">Shaina J Alexandria</a><sup><span>&nbsp;</span><a title="Department of Preventative Medicine (Biostatistics), Northwestern University, Chicago, Illinois." href="#full-view-affiliation-3" ref="linksrc=author_aff">
                3
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Sanchez+J&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Julienne Sanchez">Julienne Sanchez</a><sup><span>&nbsp;</span><a title="College of Medicine (Endocrinology), University of Illinois Chicago." href="#full-view-affiliation-4" ref="linksrc=author_aff">
                4
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Unterman+T&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Terry Unterman">Terry Unterman</a><sup><span>&nbsp;</span><a title="College of Medicine (Endocrinology), University of Illinois Chicago." href="#full-view-affiliation-4" ref="linksrc=author_aff">
                4
              </a><span>&nbsp;</span><a title="Department of Endocrinology, Jesse Brown Veterans Affairs Medical Center, Chicago, Illinois." href="#full-view-affiliation-5" ref="linksrc=author_aff">
                5
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Chow+LS&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Lisa S Chow">Lisa S Chow</a><sup><span>&nbsp;</span><a title="Division of Diabetes, Endocrinology and Metabolism, Department of Medicine, University of Minnesota, Minneapolis." href="#full-view-affiliation-6" ref="linksrc=author_aff">
                6
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Vidmar+AP&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Alaina P Vidmar">Alaina P Vidmar</a><sup><span>&nbsp;</span><a title="Center for Endocrinology, Diabetes and Metabolism, Department of Pediatrics, Children's Hospital Los Angeles and Keck School of Medicine of the University of Southern California, Los Angeles." href="#full-view-affiliation-7" ref="linksrc=author_aff">
                7
              </a></sup><span>,&nbsp;</span></span><span><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Varady+KA&amp;cauthor_id=37889487" ref="linksrc=author_name_link" data-ga-category="search" data-ga-action="author_link" data-ga-label="Krista A Varady">Krista A Varady</a><sup><span>&nbsp;</span><a title="Department of Kinesiology and Nutrition, University of Illinois Chicago." href="#full-view-affiliation-1" ref="linksrc=author_aff">
                1
              </a><span>&nbsp;</span><a title="University of Illinois Cancer Center, University of Illinois Chicago." href="#full-view-affiliation-2" ref="linksrc=author_aff">
                2
              </a></sup></span>
  </p></div>

        
        
          <p>
  

  
    Affiliations
  

  
    
  
</p>
        
        
          
        
        
  
    <ul id="full-view-identifiers">
      
        <li>
          <span>
  <span>
    
      PMID:
    
  </span>

  
    <strong title="PubMed ID">37889487</strong>
  

  
</span>

        </li>
      
        <li>
          <span>
  <span>
    
      PMCID:
    
  </span>

  
    <a target="_blank" rel="noopener" ref="linksrc=article_id_link&amp;article_id=PMC10611992&amp;id_type=PMC" href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc10611992/" data-ga-category="full_text" data-ga-action="PMCID">
      PMC10611992
    </a>
  

  
</span>

        </li>
      
        <li>
          <span>
  <span>
    
      DOI:
    
  </span>

  
    <a target="_blank" rel="noopener" ref="linksrc=article_id_link&amp;article_id=10.1001/jamanetworkopen.2023.39337&amp;id_type=DOI" href="https://doi.org/10.1001/jamanetworkopen.2023.39337" data-ga-category="full_text" data-ga-action="DOI">
      10.1001/jamanetworkopen.2023.39337
    </a>
  

  
</span>

        </li>
      
    </ul>
  


        
  <p><span>Free PMC article</span></p>
      </div>
      <div id="short-view-heading">
        
  <p>Randomized Controlled Trial</p>


        

<h2>
  
    
    
    
    
      
  Effect of Time-Restricted Eating on Weight Loss in Adults With Type 2 Diabetes: A Randomized Clinical Trial


    
  
</h2>

        

        <p><span>
    
      
        <span><span>Vasiliki Pavlou</span><span>&nbsp;et al.</span></span>
      
    
  </span>
  
    
      <span>
        JAMA Netw Open<span>.</span>
      </span>
      
        <span>
          <time datetime="2023">2023</time><span>.</span>
        </span>
      
    
  
</p>

        
  <p><span>Free PMC article</span></p>
        
      </div>
    
  
</header>

  



  

  



  <div id="abstract">
    
      <h2>
        Abstract
        
      </h2>
      
        
          
            <div id="eng-abstract">
              
                


  
    <p>
      
        <strong>
          Importance:
        </strong>
      
      Time-restricted eating (TRE) has become increasingly popular, yet longer-term randomized clinical trials have not evaluated its efficacy and safety in patients with type 2 diabetes (T2D).
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Objective:
        </strong>
      
      To determine whether TRE is more effective for weight reduction and glycemic control than daily calorie restriction (CR) or a control condition in adults with T2D.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Design, setting, and participants:
        </strong>
      
      This 6-month, parallel-group, randomized clinical trial was performed between January 25, 2022, and April 1, 2023, at the University of Illinois Chicago. Participants were aged 18 to 80 years with obesity and T2D. Data analysis was based on intention to treat.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Interventions:
        </strong>
      
      Participants were randomized to 1 of 3 groups: 8-hour TRE (eating 12 to 8 pm only, without calorie counting), CR (25% energy restriction daily), or control.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Main outcomes and measures:
        </strong>
      
      The primary outcome measure was change in body weight by month 6. Secondary outcomes included changes in hemoglobin A1c (HbA1c) levels and metabolic risk factors.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Results:
        </strong>
      
      Seventy-five participants were enrolled with a mean (SD) age of 55 (12) years. The mean (SD) body mass index (calculated as weight in kilograms divided by height in meters squared) was 39 (7) and the mean (SD) HbA1c level was 8.1% (1.6%). A total of 53 participants (71%) were women. One participant (1%) was Asian, 30 (40%) were Hispanic White, 40 (53%) were non-Hispanic Black, and 4 (5%) were non-Hispanic White. Participants in the TRE group were adherent with their eating window on a mean (SD) of 6.1 (0.8) days per week, and 17 (68%) in the CR group were adherent with their prescribed calorie goals over 6 months. The mean (SD) reduction in energy intake was -313 (509) kcal/d for TRE, -197 (426) kcal/d for CR, and -16 (439) kcal/d for controls. By month 6, body weight decreased significantly in the TRE group (-3.56% [95% CI, -5.92% to -1.20%]; P = .004) but not the CR group (-1.78% [95% CI, -3.67% to 0.11%]; P = .06), relative to controls. Levels of HbA1c decreased in the TRE (-0.91% [95% CI, -1.61% to -0.20%]) and CR (-0.94% [95% CI, -1.59% to -0.30%]) groups, relative to controls, with no differences between the TRE and CR groups. Time in euglycemic range, medication effect score, blood pressure, and plasma lipid levels did not differ among groups. No serious adverse events were reported.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Conclusions and relevance:
        </strong>
      
      This randomized clinical trial found that a TRE diet strategy without calorie counting was effective for weight loss and lowering of HbA1c levels compared with daily calorie counting in a sample of adults with T2D. These findings will need to be confirmed by larger RCTs with longer follow-up.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Trial registration:
        </strong>
      
      ClinicalTrials.gov Identifier: <a href="http://clinicaltrials.gov/show/NCT05225337" title="See in ClinicalTrials.gov">NCT05225337</a>.
    </p>
  

  


              
            </div>
          
        
      

      
    

    

    

  </div>


  
  



  <p id="disclaimer">
  <a href="https://pubmed.ncbi.nlm.nih.gov/disclaimer/" target="_blank" ga_category="literature_resources" ga_action="disclaimer_link" ga_label="under_abstract">PubMed Disclaimer</a>
</p>
  
  <div id="conflict-of-interest">
    <h2>
      Conflict of interest statement
    </h2>

    <p xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:p1="http://pubmed.gov/pub-one"><bold>Conflict of Interest Disclosures:</bold> Ms Ready reported being a member of the Certified Diabetes Care and Education Specialist for the Academy of Nutrition and Dietetics and being employed as a clinician at Ascension Medical Group Weight Loss Solutions and Diabetes Education outside the submitted work. Dr Chow reported receiving nonfinancial support from DexCom Inc outside the submitted work. Dr Vidmar reported receiving consulting fees from Rhythm Pharmaceuticals Inc, Hippo Technologies Inc, and Guidepoint Inc and grant funding from DexCom Inc, outside the submitted work. Dr Varady reported receiving grant funding from the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) of the National Institutes of Health (NIH) during the conduct of the study; receiving personal fees from the NIH for serving on the data and safety monitoring boards for the Health, Aging and Later-Life Outcomes and Dial Health studies; receiving author fees from Pan MacMillan for <italic>The Fastest Diet</italic>; and serving as the associate editor for nutrition reviews from Elsevier outside the submitted work. No other disclosures were reported.</p>
  </div>


  
  
  
    
      <div id="figures">
        <h2>
          Figures
        </h2>

        <div id="slides-container" itemscope="" itemtype="http://schema.org/ImageGallery">
          
            <figure itemscope="" itemtype="http://schema.org/ImageObject" itemprop="associatedMedia" data-slide-index="0" data-label-slug="figure-1">
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/10611992/bin/jamanetwopen-e2339337-g001.jpg" itemprop="contentUrl" aria-describedby="figure-caption-0" role="button" data-image-width="780" data-image-height="472" data-image-alt="Figure 1." data-pmc-id="PMC10611992" data-figure-id="zoi231147f1">
                <img itemprop="thumbnail" id="article-image-0" src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/10611992/bin/jamanetwopen-e2339337-g001.gif" alt="Figure 1.">
              </a>

              <meta itemprop="width" itemtype="http://schema.org/ImageObject" content="780">
              <meta itemprop="height" itemtype="http://schema.org/ImageObject" content="472">

              
                

                

                <figcaption id="figure-caption-0" itemtype="http://schema.org/ImageObject" itemprop="description">
                  
                  



  
    <strong>
      Figure 1.. Study Flowchart
    </strong>
  

  



                </figcaption>
              

            </figure>
          
            <figure itemscope="" itemtype="http://schema.org/ImageObject" itemprop="associatedMedia" data-slide-index="1" data-label-slug="figure-2">
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/10611992/bin/jamanetwopen-e2339337-g002.jpg" itemprop="contentUrl" aria-describedby="figure-caption-1" role="button" data-image-width="783" data-image-height="853" data-image-alt="Figure 2." data-pmc-id="PMC10611992" data-figure-id="zoi231147f2">
                <img itemprop="thumbnail" id="article-image-1" src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/10611992/bin/jamanetwopen-e2339337-g002.gif" alt="Figure 2.">
              </a>

              <meta itemprop="width" itemtype="http://schema.org/ImageObject" content="783">
              <meta itemprop="height" itemtype="http://schema.org/ImageObject" content="853">

              
                

                

                <figcaption id="figure-caption-1" itemtype="http://schema.org/ImageObject" itemprop="description">
                  
                  



  
    <strong>
      Figure 2.. Change in Body Composition and Glycemic Control in the Study Groups
    </strong>
  

  
    <p>Data were included for 75 participants; means were estimated using an intention-to-treat analysis using a linear mixed model. Error bars indicate 95% CIs for each parameter from baseline by diet group. CR indicates calorie restriction; TRE, time-restricted eating.</p>
  



                </figcaption>
              

            </figure>
          
        </div>

        

        <!-- Root element of PhotoSwipe. Must have class pswp. -->




      </div>
    
  


  

  

  



  
  <div id="references">
    <h2>
      References
    </h2>
    <div id="top-references-list">

  

  
    
      <ol id="top-references-list-1">
        




  <li>
    <ol>
      
        <li value="1">
          
            Centers for Disease Control and Prevention . Type 2 diabetes. Reviewed April 18, 2023. Accessed April 18, 2023. <a href="https://www.cdc.gov/diabetes/basics/type2.html" rel="noopener nofollow" target="_blank" title="External link: https://www.cdc.gov/diabetes/basics/type2.html">https://www.cdc.gov/diabetes/basics/type2.html</a>
            
          
        </li>
      
    </ol>
  </li>

  <li>
    <ol>
      
        <li value="1">
          
            Evert AB, Dennison M, Gardner CD, et al. . Nutrition therapy for adults with diabetes or prediabetes: a consensus report. Diabetes Care. 2019;42(5):731-754. doi:10.2337/dci19-0014
            
              
                
                  -
                  <a href="https://doi.org/10.2337/dci19-0014" ref="linksrc=references_link&amp;ordinalpos=1" data-ga-category="reference" data-ga-action="10.2337/dci19-0014">
                    DOI
                  </a>
                
              
            
              
                
                  -
                  <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc7011201/" ref="linksrc=references_link&amp;ordinalpos=2" data-ga-category="reference" data-ga-action="PMC7011201">
                    PMC
                  </a>
                
              
            
              
                
                  -
                  <a href="https://pubmed.ncbi.nlm.nih.gov/31000505/" ref="linksrc=references_link&amp;ordinalpos=3" data-ga-category="reference" data-ga-action="31000505">
                    PubMed
                  </a>
                
              
            
          
        </li>
      
    </ol>
  </li>

  <li>
    <ol>
      
        <li value="1">
          
            Wilkinson MJ, Manoogian ENC, Zadourian A, et al. . Ten-hour time-restricted eating reduces weight, blood pressure, and atherogenic lipids in patients with metabolic syndrome. Cell Metab. 2020;31(1):92-104.e5. doi:10.1016/j.cmet.2019.11.004
            
              
                
                  -
                  <a href="https://doi.org/10.1016/j.cmet.2019.11.004" ref="linksrc=references_link&amp;ordinalpos=1" data-ga-category="reference" data-ga-action="10.1016/j.cmet.2019.11.004">
                    DOI
                  </a>
                
              
            
              
                
                  -
                  <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc6953486/" ref="linksrc=references_link&amp;ordinalpos=2" data-ga-category="reference" data-ga-action="PMC6953486">
                    PMC
                  </a>
                
              
            
              
                
                  -
                  <a href="https://pubmed.ncbi.nlm.nih.gov/31813824/" ref="linksrc=references_link&amp;ordinalpos=3" data-ga-category="reference" data-ga-action="31813824">
                    PubMed
                  </a>
                
              
            
          
        </li>
      
    </ol>
  </li>

  <li>
    <ol>
      
        <li value="1">
          
            Cienfuegos S, Gabel K, Kalam F, et al. . Effects of 4- and 6-h time-restricted feeding on weight and cardiometabolic health: a randomized controlled trial in adults with obesity. Cell Metab. 2020;32(3):366-378.e3. doi:10.1016/j.cmet.2020.06.018
            
              
                
                  -
                  <a href="https://doi.org/10.1016/j.cmet.2020.06.018" ref="linksrc=references_link&amp;ordinalpos=1" data-ga-category="reference" data-ga-action="10.1016/j.cmet.2020.06.018">
                    DOI
                  </a>
                
              
            
              
                
                  -
                  <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc9407646/" ref="linksrc=references_link&amp;ordinalpos=2" data-ga-category="reference" data-ga-action="PMC9407646">
                    PMC
                  </a>
                
              
            
              
                
                  -
                  <a href="https://pubmed.ncbi.nlm.nih.gov/32673591/" ref="linksrc=references_link&amp;ordinalpos=3" data-ga-category="reference" data-ga-action="32673591">
                    PubMed
                  </a>
                
              
            
          
        </li>
      
    </ol>
  </li>

  <li>
    <ol>
      
        <li value="1">
          
            Gabel K, Hoddy KK, Haggerty N, et al. . Effects of 8-hour time restricted feeding on body weight and metabolic disease risk factors in obese adults: a pilot study. Nutr Healthy Aging. 2018;4(4):345-353. doi:10.3233/NHA-170036
            
              
                
                  -
                  <a href="https://doi.org/10.3233/nha-170036" ref="linksrc=references_link&amp;ordinalpos=1" data-ga-category="reference" data-ga-action="10.3233/NHA-170036">
                    DOI
                  </a>
                
              
            
              
                
                  -
                  <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc6004924/" ref="linksrc=references_link&amp;ordinalpos=2" data-ga-category="reference" data-ga-action="PMC6004924">
                    PMC
                  </a>
                
              
            
              
                
                  -
                  <a href="https://pubmed.ncbi.nlm.nih.gov/29951594/" ref="linksrc=references_link&amp;ordinalpos=3" data-ga-category="reference" data-ga-action="29951594">
                    PubMed
                  </a>
                
              
            
          
        </li>
      
    </ol>
  </li>


      </ol>
      
        
        

      
    
  

  
    
  

</div>
  </div>

  
  
    <div id="publication-types">
      <h2>
        Publication types
      </h2>

      <ul><li></li><li></li><li></li></ul>
    </div>
  


  
  
    <div id="mesh-terms">
      <h2>
        MeSH terms
      </h2>

      <ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul>
    </div>
  


  
  
    <div id="substances">
      <h2>
        Substances
      </h2>

      <ul><li></li></ul>
    </div>
  


  

  

  


  


  
  

  


  
    
  


  
  <div id="linkout">
    <h2>
      LinkOut - more resources
    </h2>

    <ul><li><h3>Full Text Sources</h3><ul><li><a href="https://europepmc.org/abstract/MED/37889487" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=6082&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Europe PubMed Central">
                    Europe PubMed Central
                  </a></li><li><a href="http://ovidsp.ovid.com/ovidweb.cgi?T=JS&amp;PAGE=linkout&amp;SEARCH=37889487.ui" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3682&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Ovid Technologies, Inc.">
                    Ovid Technologies, Inc.
                  </a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/37889487/" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3494&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="PubMed Central">
                    PubMed Central
                  </a></li><li><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2023.39337" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=7898&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Silverchair Information Systems">
                    Silverchair Information Systems
                  </a></li></ul></li><li><h3>Medical</h3><ul><li><a href="https://www.diseaseinfosearch.org/result/2243" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=6412&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Medical" data-ga-label="Genetic Alliance">
                    Genetic Alliance
                  </a></li><li><a href="https://medlineplus.gov/diabetestype2.html" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3162&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Medical" data-ga-label="MedlinePlus Health Information">
                    MedlinePlus Health Information
                  </a></li></ul></li><li><h3>Miscellaneous</h3><ul><li><a href="https://assays.cancer.gov/CPTAC-1595" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=8855&amp;uid=37889487&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=101729235" data-ga-category="link_out" data-ga-action="Miscellaneous" data-ga-label="NCI CPTAC Assay Portal">
                    NCI CPTAC Assay Portal
                  </a></li></ul></li></ul>
  </div>


</main>

    
  


    

    

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU's concealment of secret 'expert list' on CSAM regulation is maladministration (345 pts)]]></title>
            <link>https://www.iccl.ie/news/ombudsman-european-commissions-concealment-of-secret-expert-list-on-csam-regulation-constitutes-maladministration/</link>
            <guid>38189790</guid>
            <pubDate>Wed, 08 Nov 2023 13:00:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iccl.ie/news/ombudsman-european-commissions-concealment-of-secret-expert-list-on-csam-regulation-constitutes-maladministration/">https://www.iccl.ie/news/ombudsman-european-commissions-concealment-of-secret-expert-list-on-csam-regulation-constitutes-maladministration/</a>, See on <a href="https://news.ycombinator.com/item?id=38189790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>6 November 2023&nbsp;</strong></p>
<p><b><span data-contrast="auto">In response to a request for documents pertaining to the decision-making behind the proposed CSAM regulation, the European Commission failed to disclose a list of companies who were consulted about the technical feasibility of detecting CSAM without undermining encryption. This list “clearly fell within the scope” of the Irish Council for Civil Liberties’ request.</span></b><span data-ccp-props="{&quot;134233117&quot;:true,&quot;134233118&quot;:true,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><b><span data-contrast="auto">The European Ombudsman has now held that the Commission’s failure to disclose the existence of this list constituted “maladministration”.</span></b><span data-ccp-props="{&quot;134233117&quot;:true,&quot;134233118&quot;:true,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><b><span data-contrast="auto">The technical feasibility question is a major sticking point in the EU negotiations around this file.</span></b><span data-ccp-props="{&quot;134233117&quot;:true,&quot;134233118&quot;:true,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="auto">Numerous experts have warned that it is not technically feasible. Public </span><a href="https://cdt.org/wp-content/uploads/2023/05/2023-05-16-Letter-from-Public-Interest-Technologists.pdf"><span data-contrast="auto">interest technologists</span></a><span data-contrast="auto"> and more than </span><a href="https://docs.google.com/document/d/13Aeex72MtFBjKhExRTooVMWN9TC-pbH-5LEaAbMF91Y/edit"><span data-contrast="auto">450 academics</span></a><span data-contrast="auto"> have warned in public that “technology to detect CSAM in encrypted content is currently not mature and will not be mature in the next two to five years.”[1]</span><span data-contrast="auto"> This is in stark contrast to the views put forward by experts relied upon by the Commission, whose names the Commission is refusing to reveal.</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;134233118&quot;:true,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="auto">In December 2022, ICCL filed complaints with the European Ombudsman against the European Commission’s refusal to provide a list of experts who helped the Commission draft the </span><a href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=SWD:2022:209:FIN&amp;from=EN"><span data-contrast="none">text</span></a><span data-contrast="auto"> related to potential solutions to detect child sexual abuse material in end-to-end encrypted communications.</span><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="auto">After the Commission acknowledged to the EU Ombudsman that it, in fact, had such a list, but failed to disclose its existence to Dr Kris Shrishak, the Ombudsman held the Commission’s behaviour constituted “maladministration”.&nbsp;</span><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="auto">The Ombudsman held: “[</span><span data-contrast="none">t]he Commission did not identify the list of experts as falling within the scope of the complainant’s request. This means that the complainant did not have the opportunity to challenge (the reasons for) the institution’s refusal to disclose the document. This constitutes maladministration.”</span><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="none">The proposed regulation on </span><span data-contrast="auto">child sexual abuse material has been hugely controversial. In addition to concerns about mass surveillance and undermining encryption, further concerns have been raised about the</span><span data-contrast="none"> incompatibility with existing EU laws which prohibit general and indiscriminate monitoring of people’s communications. These concerns have been raised by </span><a href="https://edri.org/our-work/most-criticised-eu-law-of-all-time/"><span data-contrast="none">many bodies</span></a><span data-contrast="none">, including the European Council’s own legal service, the </span><a href="https://cdn.netzpolitik.org/wp-upload/2023/04/2023-04-05_EPRS_CSAM_Complementary-Impact-Assessment_DRAFT.pdf"><span data-contrast="none">European Parliamentary Research Service</span></a><span data-contrast="auto">,</span><span data-contrast="none"> the </span><a href="https://www.ohchr.org/en/press-releases/2022/09/spyware-and-surveillance-threats-privacy-and-human-rights-growing-un-report"><span data-contrast="none">United Nations High Commissioner for Human Rights</span></a><span data-contrast="none">; and the </span><a href="https://edps.europa.eu/system/files/2022-07/22-07-28_edpb-edps-joint-opinion-csam_en.pdf"><span data-contrast="none">European Data Protection Board and Supervisor</span></a><span data-contrast="auto">.</span><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>
<p><span data-contrast="auto">“</span><i><span data-contrast="auto">In light of these concerns, the lack of transparency from the Commission regarding external experts is deeply worrying, more so considering alleged close links between the Commission and lobbyists in the preparation of the regulation</span></i><span data-contrast="auto">”, said </span><span data-contrast="auto">Dr Kris Shrishak, Senior Fellow at ICCL.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The Ombudsman’s decision can be read in full </span><a href="https://www.ombudsman.europa.eu/en/decision/en/176658"><span data-contrast="none">here</span></a><span data-contrast="auto">.</span><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">&nbsp;</span></p>

<p><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200}">[1] <span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="footnote text">See 10:08:00 onwards in the presentation of Complementary impact assessment of CSAM proposal at Committee on Civil Liberties,&nbsp;</span><span data-ccp-parastyle="footnote text">Justice</span><span data-ccp-parastyle="footnote text">&nbsp;and Home Affairs. 13 April 2023. URL:&nbsp;</span></span><a href="https://multimedia.europarl.europa.eu/en/webstreaming/committee-on-civil-liberties-justice-and-home-affairs_20230413-0900-COMMITTEE-LIBE" target="_blank" rel="noreferrer noopener"><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span data-ccp-charstyle="Hyperlink">https://multimedia.europarl.europa.eu/en/webstreaming/committee-on-civil-liberties-justice-and-home-affairs_20230413-0900-COMMITTEE-LIBE</span></span></a><span data-ccp-props="{&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:0}">&nbsp;</span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Banning E2EE is stupid (201 pts)]]></title>
            <link>https://github.com/davidchisnall/banning-e2ee-is-stupid</link>
            <guid>38188938</guid>
            <pubDate>Wed, 08 Nov 2023 11:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/davidchisnall/banning-e2ee-is-stupid">https://github.com/davidchisnall/banning-e2ee-is-stupid</a>, See on <a href="https://news.ycombinator.com/item?id=38188938">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-banning-end-to-end-encryption-is-stupid" dir="auto"><a href="#banning-end-to-end-encryption-is-stupid">Banning End-to-End Encryption is Stupid</a></h2>
<p dir="auto">Various lawmakers in different countries are proposing to require messaging services to provide a mechanism for law enforcement to decrypt end-to-end encrypted messages.
This kind of legislation fundamentally misunderstands how easy it is for bad people to build their own end-to-end encryption layers on top of other messaging systems.</p>
<p dir="auto">Requiring Signal, WhatsApp, and so on to introduce vulnerabilities into their products does not make life much harder for criminals.
Criminals can easily build or buy an extra layer of encryption on top and exchange messages that can't be decrypted.</p>
<p dir="auto">It does make everyone else less safe.
If a backdoor exists and is usable by authorised people, it will eventually be exploited and used by malicious people.</p>
<p dir="auto">This repository contains a trivial demonstration of this.
It builds a simple tool that allows sending end-to-end encrypted messages over any messaging service, including plain old SMS (though message-length limits may cause problems there).
It is 186 lines of code (and depends on a load of off-the-shelf open-source libraries) and took about an hour to write.</p>
<p dir="auto">Imagine that Alice wants to send a message to Bob, as she often does in cryptography texts.
She needs a secret passphrase, which will be used to derive some keys:</p>
<div data-snippet-clipboard-copy-content="$ cat pass 
Alice has a totally secret passphrase."><pre><code>$ cat pass 
Alice has a totally secret passphrase.
</code></pre></div>
<p dir="auto">This is the only thing that we need to keep secret to be able to build end-to-end encrypted messaging.
Don't worry about how it's used, just remember that this is some secret that no one should be able to guess.</p>
<p dir="auto">She then runs the following command:</p>
<div data-snippet-clipboard-copy-content="$ banning-e2ee-is-stupid -k pass -u bob"><pre><code>$ banning-e2ee-is-stupid -k pass -u bob
</code></pre></div>
<p dir="auto">The program notices that this is the first time that Alice has sent a message to Bob and so asks for his public key and asks Alice to send Bob her public key.
These are written out as a set of English words:</p>
<div data-snippet-clipboard-copy-content="You have not exchanged keys with this user.  You must send them your public key:
celan fiona tasmanian bloomer terminological elca glamis fenceposts troilus ramapo premeditation meth chairpersons addictiveness bergman beauregard 
Please enter their key:"><pre><code>You have not exchanged keys with this user.  You must send them your public key:
celan fiona tasmanian bloomer terminological elca glamis fenceposts troilus ramapo premeditation meth chairpersons addictiveness bergman beauregard 
Please enter their key:
</code></pre></div>
<p dir="auto">At the same time, Bob is preparing to receive his first message from Alice and so ensures that he has a completely unguessable key phrase and runs the tool to decrypt a message:</p>
<div data-snippet-clipboard-copy-content="$ cat pass 
Bob also has a completely unguessable passphrase
$ ../banning-e2ee-is-stupid -k pass -u alice -d
You have not exchanged keys with this user.  You must send them your public key:
luxuriantly hensel soper chinny kilts esai downpours dissimulation adroitly widmann striven breastbone clonmel forecastle abascal barstools 
Please enter their key:"><pre><code>$ cat pass 
Bob also has a completely unguessable passphrase
$ ../banning-e2ee-is-stupid -k pass -u alice -d
You have not exchanged keys with this user.  You must send them your public key:
luxuriantly hensel soper chinny kilts esai downpours dissimulation adroitly widmann striven breastbone clonmel forecastle abascal barstools 
Please enter their key:
</code></pre></div>
<p dir="auto">Alice and Bob must now send each other their public keys.
The easiest way to do this is to send it as a text message or email and then have a phone call where they read it out.
This isn't secret: it doesn't matter if someone else reads the key (you can put it on your website, Facebook profile, whatever), only if they are able to tamper with it.</p>
<p dir="auto">This key-exchange process is handled by apps like Signal automatically.
Doing it well is the hard part of building an end-to-end encrypted messaging app.
Once Alice and Bob have both pasted each others' public key, they can start exchanging messages.
They won't be asked for keys again.
Alice now sees something like this:</p>
<div data-snippet-clipboard-copy-content="Please enter the message to encrypt:
Hi Bob!

Send the following message to the other person:
anomaly forceful amongst ralphie gia ponds scandalous movies ungracious candidate absolution honan lima lambent cutaways embroider locos computers disqualify boehm naik brimming schrieber glebe "><pre><code>Please enter the message to encrypt:
Hi Bob!

Send the following message to the other person:
anomaly forceful amongst ralphie gia ponds scandalous movies ungracious candidate absolution honan lima lambent cutaways embroider locos computers disqualify boehm naik brimming schrieber glebe 
</code></pre></div>
<p dir="auto">This message is now encrypted in such a way that Bob (and only Bob) can decrypt it.
Alice can now send this message in email, or in her favourite messaging program.
She can even paste it into something public like a GitHub Gist or a Pastebin.
No one else can decrypt it and Bob can detect if it's tampered with.
In fact, Alice can paste a load of random messages in different places and Bob can try decrypting them all to find the one that's intended for him.</p>
<p dir="auto">Bob just needs to paste the message from Alice into the program:</p>
<div data-snippet-clipboard-copy-content="Please enter the message to decrypt:
anomaly forceful amongst ralphie gia ponds scandalous movies ungracious candidate absolution honan lima lambent cutaways embroider locos computers disqualify boehm naik brimming schrieber glebe

Decrypted message:
Hi Bob! "><pre><code>Please enter the message to decrypt:
anomaly forceful amongst ralphie gia ponds scandalous movies ungracious candidate absolution honan lima lambent cutaways embroider locos computers disqualify boehm naik brimming schrieber glebe

Decrypted message:
Hi Bob! 
</code></pre></div>
<p dir="auto">This will report 'Decryption failed' if the message has been tampered with, was not from Alice, or was not intended for Bob (these three conditions are indistinguishable).</p>
<p dir="auto">With this simple program (remember, about an hour's quick coding), it is possible for Alice and Bob to exchange messages over any insecure channel.</p>
<p dir="auto">This is intended as a toy demonstration of how simple it is to build encrypted messaging over an unencrypted messaging service.
Over a decade ago, <a href="https://en.wikipedia.org/wiki/TextSecure" rel="nofollow">TextSecure</a> built a product that did this (using much more clever crypto!) that gave a polished user interface.
Even before this, <a href="https://en.wikipedia.org/wiki/Off-the-record_messaging" rel="nofollow">OTR</a> provided plugins for third-party clients for various unencrypted IM networks that allowed end-to-end encryption (again, with stronger security properties than this demo).
These were polished clients that provided secure end-to-end encrypted messaging used an existing messaging network as an insecure transport.</p>
<h2 tabindex="-1" id="user-content-frequently-asked-questions" dir="auto"><a href="#frequently-asked-questions">Frequently asked questions</a></h2>
<p dir="auto"><em>How do I build this thing?</em></p>
<p dir="auto">You probably shouldn't (see disclaimers below).
If you really want to, run:</p>
<div data-snippet-clipboard-copy-content="$ mkdir build
$ cd build
$ cmake .. -G Ninja
$ ninja"><pre><code>$ mkdir build
$ cd build
$ cmake .. -G Ninja
$ ninja
</code></pre></div>
<p dir="auto">This will give you a program called <code>banning-e2ee-is-stupid</code>.
This will store public keys in a database in the directory that you run it from.</p>
<p dir="auto"><em>Isn't this too complex for end users to use?  It requires using a command line and stuff.</em></p>
<p dir="auto">I wrote this in about an hour, much of which was spent learning how to use libraries.
It is absolutely not a polished end-user product.
Something with a half decent UI, better key storage, and so on, would probably be a whole afternoon's effort.</p>
<p dir="auto"><em>What happens if someone intercepts the key-exchange messages?</em></p>
<p dir="auto">Nothing bad.
Each message is encrypted using both the sender's secret key and the receiver's public key.
Decrypting it requires the sender's public key and the receiver's secret key.
Both encrypting and decrypting a message require that you have a secret key, and these are never sent anywhere.</p>
<p dir="auto"><em>What happens if an attacker uses the attack from <a href="https://xkcd.com/538/" rel="nofollow">XKCD 538</a>?</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e16f7a16fecacb8421126bd8f244d27765f967429a1c09bdbec966078c14be25/68747470733a2f2f696d67732e786b63642e636f6d2f636f6d6963732f73656375726974792e706e67"><img src="https://camo.githubusercontent.com/e16f7a16fecacb8421126bd8f244d27765f967429a1c09bdbec966078c14be25/68747470733a2f2f696d67732e786b63642e636f6d2f636f6d6963732f73656375726974792e706e67" alt="XKCD 538" data-canonical-src="https://imgs.xkcd.com/comics/security.png"></a></p>
<p dir="auto">They get your messages.
Sorry.</p>
<p dir="auto"><em>Isn't it easy to spot messages like "aggarwal ashwell kalter stephenville compounders carleton somatic bks sanada airspaces brees lamb's fossilization wadsworth composit downey's arkansans advanta diffferent hewlitt henne rowed airlifts corba fortune's"?</em></p>
<p dir="auto">Yes.
This doesn't apply any <a href="https://en.wikipedia.org/wiki/Steganography" rel="nofollow">Steganography</a> to the output and so traffic analysis (including scanning in the client device) would probably find it easily.
That said, if your heuristic is 'words used in strange ways' then you will get false positives from all teenagers.</p>
<p dir="auto"><em>Where do all of these words come from?</em></p>
<p dir="auto">The encrypted message is pile of binary data.
A lot of messaging apps will be unhappy if you try to send raw binary data and break it in annoying ways.
This program uses one of <a href="https://www.keithv.com/software/wlist/" rel="nofollow">Keith Vertanen's big word lists</a>, truncated to 2^16 entries.
This means that for every two bytes of binary data, we have one word.
The words are all in the top 84K most commonly used English words and so totally indistinguishable from the kind of piffle that might be generated by the kind of politician that thinks banning encryption is remotely feasible.</p>
<p dir="auto"><em>What does this use?</em></p>
<p dir="auto">This uses libsodium for all of the cryptography.
The passhprase hashed using Argon2id, which is intended to be slow (this is where the startup pause comes from) for a brute force attacker.
The encryption uses libsodium's crypto box construction, which uses X25519, XSalsa20, and Poly1305.
If you know what these are, you understand enough about cryptography to not need to read this page.
If you do not know what these are, you should not be voting on legislation about cryptography without talking to an expert.</p>
<h2 tabindex="-1" id="user-content-do-not-use-this" dir="auto"><a href="#do-not-use-this"><strong>DO NOT USE THIS</strong></a></h2>
<p dir="auto">This code is intended to show that it's easy to write something that does end-to-end encryption without the cooperation of the underlying messaging service.
As such, it is intentionally brief.
It does not follow best practices for encryption, in a number of ways:</p>
<ul dir="auto">
<li>It does not try to make the pass phrase storage secure.
Good code would use the operating system's key storage APIs.</li>
<li>It does not provide a mechanism for rolling over keys.
A good system would periodically re-key to handle cases where the key is leaked.</li>
<li>It does not provide forward security.
If your key is leaked, an attacker can impersonate you and can read all messages that you've received.</li>
<li>It does not protect keys in memory.
Keys may show up in core dumps, swap, and so on.</li>
<li>No one has reviewed the use of crypto.
I am not a cryptographer, I probably did something stupid.</li>
<li>It uses random dependencies.
The SQLite and libsodium wrappers were chosen because they were the first results in a DuckDuckGo search.
This is not how you do supply-chain security.</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Opusmodus: Common Lisp Music Composition System (151 pts)]]></title>
            <link>https://opusmodus.com/</link>
            <guid>38188788</guid>
            <pubDate>Wed, 08 Nov 2023 10:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opusmodus.com/">https://opusmodus.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38188788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<!-- navbar -->

<!-- navbar END -->

<!-- bloc-2 -->
<div id="bloc-2">
				
				<h2>
					Music Composition System
				</h2>
				
				<h3>
							<br>Opusmodus revolutionizes music composition,<br>fuses traditional notation with modern concepts,<br>and streamlines the path to a finalized score.<br>
						</h3>
			</div>
<!-- bloc-2 END -->

<!-- bloc-2 -->

<!-- bloc-2 END -->

<!-- bloc-3 -->
<div id="bloc-3">
					<picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/sale2.webp"><img src="https://opusmodus.com/img/sale2.png" data-src="img/sale2.png" alt="sale2" width="358" height="113"></picture>
					
				</div>
<!-- bloc-3 END -->

<!-- bloc-3 -->
<div id="bloc-3">
				<h2>
					Welcome to Opusmodus<br>
				</h2>
				<h3>
					Introduction to the Opusmodus system
				</h3>
				<p>
					<iframe src="img/lazyload-ph.png" data-src="https://www.youtube.com/embed/BMoHE96rh7w" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
					</iframe>
				</p>
			</div>
<!-- bloc-3 END -->

<!-- bloc-4 -->
<div id="bloc-4">
				<h2>
					Opusmodus and SuperCollider<br>
				</h2>
				<h3>
					A short OM score to SC - Notstand<br>
				</h3>
				<p>
					<iframe src="img/lazyload-ph.png" data-src="https://www.youtube.com/embed/L-0E7P9kVrE?si=W8FJfer1hiFz_Lgx" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
					</iframe>
				</p>
			</div>
<!-- bloc-4 END -->

<!-- made-in-opusmodus -->
<div id="made-in-opusmodus">
		<div>
				<h2>
					Made in Opusmodus<br>
				</h2>
				<div>
					<div>
						<p>
							<iframe src="img/lazyload-ph.png" data-src="https://www.youtube-nocookie.com/embed/mhQuHPzxSTo" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="">
							</iframe>
						</p>
					</div>
					<div>
						<p>
							<iframe src="img/lazyload-ph.png" data-src="https://www.youtube-nocookie.com/embed/BfuqA2U1WvQ" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="">
							</iframe>
						</p>
					</div>
				</div>
				<div>
					<p>
							<br>Live Coding Instrument improvisation by Janusz Podrazik, for FM8, Reaktor, Absynth, Vienna Imperial and Prepared Pianos with five workspaces.<br>
						</p>
					<p>
							<br>Quantization. Composition by Yuichi Yamamoto.
						</p>
				</div>
			</div>
		<div>
							<div><p>
									Brin D'or by Stéphane Boussuge. Short piece for violin solo and Strings ensemble with Fibonacci based harmony.</p></div>
							<p>
									Parataxis for Ensemble by Robert Scott Thompson. A septet…&nbsp;Alto Flute, Clarinet, Trombone, Viola, Violoncello, Piano, Percussion.&nbsp;This is a live recording from the premiere at the Trieste Prima Festival and is by Ensemble MD7 conducted by Steven Loy.<br>
								</p>
						</div>
	</div>
<!-- made-in-opusmodus END -->

<!-- omn -->
<div id="omn">
				<h2>
					Everyone Can Code
				</h2>
				<h3>
					Coding opens up a wealth of possibilities for exploring<br>new kinds of musical structures and ideas<br>
				</h3>
				<p>
					OMN is designed as a scripting language for musical events. It’s not about sounds themselves, it is about their control and organisation in a musical composition. As a linear script rather than a graphic stave, musical events can be transformed, extended, reorganised by powerful computer algorithms. Some sequencers and score writers provide basic algorithms, but they do not represent the way composers now think about the process of music composition. Composing has become such a multi-faceted process and takes ideas about structure and content from many disciplines: mathematics, astronomy, literature, the visual arts. As such it requires extensive mental resources and experience from the composer. Much of this is still done by hand and eye and brain because although computer systems do exist to help the process along they don’t provide what has become known as the composing continuum.
				</p><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet1.webp"><img src="https://opusmodus.com/img/snippet1.png" data-src="img/snippet1.png" alt="snippet1" width="542" height="73"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet-mxml1.webp"><img src="https://opusmodus.com/img/snippet-mxml1.png" data-src="img/snippet-mxml1.png" alt="snippet mxml1" width="475" height="76"></picture>
				<h6>
					I. Strawinsky, Petruschka, 1911/21
				</h6><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet2.webp"><img src="https://opusmodus.com/img/snippet2.png" data-src="img/snippet2.png" alt="snippet2 1" width="448" height="36"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet-mxml2.webp"><img src="https://opusmodus.com/img/snippet-mxml2.png" data-src="img/snippet-mxml2.png" alt="snippet mxml2-1" width="446" height="74"></picture>
				<h6>
					W. A. Mozart, Variation KV 265
				</h6><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet3.webp"><img src="https://opusmodus.com/img/snippet3.png" data-src="img/snippet3.png" alt="snippet3" width="576" height="54"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet-mxml3.webp"><img src="https://opusmodus.com/img/snippet-mxml3.png" data-src="img/snippet-mxml3.png" alt="snippet mxml3" width="752" height="103"></picture>
				<h6>
					A. Webern, Sechs Bagatellen für Streichquartett, op. 9, III, 1913
				</h6><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet4.webp"><img src="https://opusmodus.com/img/snippet4.png" data-src="img/snippet4.png" alt="snippet4" width="508" height="87"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/snippet-mxml4.webp"><img src="https://opusmodus.com/img/snippet-mxml4.png" data-src="img/snippet-mxml4.png" alt="snippet mxml4" width="792" height="64"></picture>
				<h6>
					J. S. Bach, Goldberg-Variationen, Aria, 1741
				</h6>
			</div>
<!-- omn END -->

<!-- microtonality -->
<div id="microtonality">
				<h2>
					Microtonality
				</h2>
				<p>
					Microtonal music or microtonality is the use in music of microtones—intervals smaller than a semitone, also called "microintervals". It may also be extended to include any music using intervals not found in the customary Western tuning of twelve equal intervals per octave. In other words, a microtone may be thought of as a note that falls between the keys of a piano tuned in equal temperament.
				</p><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/micro1.webp"><img src="https://opusmodus.com/img/micro1.png" data-src="img/micro1.png" alt="micro1" width="567" height="178"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/micro-mxml1.webp"><img src="https://opusmodus.com/img/micro-mxml1.png" data-src="img/micro-mxml1.png" alt="micro mxml1" width="723" height="505"></picture>
				<p><audio controls="true">
						<source type="audio/mpeg" src="https://opusmodus.com/audio/microtonality.mp3">Your browser does not support the audio element.
					</audio>
				</p>
				<h6>
					Luigi Nono, Fragmente-Stille, An Diotima, Violin 1 (fragement, 1979-1980)
				</h6>
			</div>
<!-- microtonality END -->

<!-- tonnetz -->
<div id="tonnetz">
				<h2>
					Tonnetz
				</h2>
				<div><p>
					In musical tuning and harmony, the Tonnetz (German: tone-network) is a conceptual lattice diagram representing tonal space (net) first described by Leonhard Euler in 1739. Various visual representations of the Tonnetz can be used to show traditional harmonic relationships in European classical music.</p><p>In Opusmodus there are 12 Tonnetz structures labelled by a number and by an intervallic content of the composite chord. The intervallic content is a number of semitones associated with the different interval axis.</p></div><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/tonnetz-11.webp"><img src="https://opusmodus.com/img/tonnetz-11.png" data-src="img/tonnetz-11.png" alt="snippet mxml2-1" width="361" height="350"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/tonnetz1.webp"><img src="https://opusmodus.com/img/tonnetz1.png" data-src="img/tonnetz1.png" alt="micro1" width="534" height="140"></picture><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/tonnetz1-notation.webp"><img src="https://opusmodus.com/img/tonnetz1-notation.png" data-src="img/tonnetz1-notation.png" alt="micro mxml1" width="684" height="307"></picture>
				<p><audio controls="true">
						<source type="audio/mpeg" src="https://opusmodus.com/audio/tonnetz1.mp3">Your browser does not support the audio element.
					</audio>
				</p>
				<h6>
					Tonnetz space 11
				</h6>
			</div>
<!-- tonnetz END -->

<!-- counterpoint -->
<div id="counterpoint">
				<h2>
					Counterpoint
				</h2>
				<div><p>
					In Opusmodus the COUNTERPOINT function designates patterns to a number of voices with defined methods for each voice.</p><p>Bruno Maderna - Serenata Per un Satellite (1969)<br>Durata: da un minimo di 4' - a 12'<br>Tempo Generale 42, 92, 132 ca.</p></div><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/maderna2.webp"><img src="https://opusmodus.com/img/maderna2.png" data-src="img/maderna2.png" alt="micro1" width="723" height="1167"></picture>
				<p><audio controls="true">
						<source type="audio/mpeg" src="https://opusmodus.com/audio/maderna.mp3">Your browser does not support the audio element.
					</audio>
				</p>
				<h6>
					Bruno Maderna, Serenata Per un Satellite (1969)
				</h6>
			</div>
<!-- counterpoint END -->

<!-- micropolyphony -->
<div id="micropolyphony">
				<h2>
					Micropolyphony
				</h2>
				<p>
					Micropolyphony is a polyphonic musical texture developed by György Ligeti which consists of many lines of dense canons moving at different tempos or rhythms, thus resulting in tone clusters vertically. According to David Cope, "micropolyphony resembles cluster chords, but differs in its use of moving rather than static lines"; it is "a simultaneity of different lines, rhythms, and timbres".<br>
				</p><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/micropolyphony.webp"><img src="https://opusmodus.com/img/micropolyphony.png" data-src="img/micropolyphony.png" alt="micro1" width="550" height="929"></picture>
				<p><audio controls="true">
						<source type="audio/mpeg" src="https://opusmodus.com/audio/micropolyphony.mp3">Your browser does not support the audio element.
					</audio>
				</p>
				<h6>
					Micropolyphony example for two choirs
				</h6>
			</div>
<!-- micropolyphony END -->

<!-- bloc-10 -->
<div id="bloc-10">
				<h2>
					Graphs
				</h2>
				<p>
					Making 2-D visualisations of musical parameters offer a new way of conceptualisation. Opusmodus graphical tools can plot pitch, rhythms, duration, dynamics and orchestration and there's a host of different display paradigms available. The composer can now view the interaction of multiple streams of parametric data, a perfect way to take in complex algorithmically-generated material. Composers often use such visualisations in the early stages of a project before precise pitches or rhythms are decided upon.<br>
				</p>
				
			</div>
<!-- bloc-10 END -->

<!-- bloc-2 -->
<div id="bloc-2">
			<div>
				<picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/lesson-sb.webp"><img src="https://opusmodus.com/img/lesson-sb.png" data-src="img/lesson-sb.png" alt="lesson sb" width="560" height="373"></picture>
			</div>
			<div>
				<h2>
					Composer Workshop<br>
				</h2>
				<h4>
					with Stéphane Boussuge
				</h4>
				<p>
					Courses and private lessons to students and professionals interested in composing music with Opusmodus. Composer Workshop provide lessons for beginners and advanced users with or without programming knowledge, online or on site.<br>
				</p><p><a href="https://www.composerworkshop.com/" target="_blank">More Info</a>
			</p></div>
		</div>
<!-- bloc-2 END -->

<!-- bloc-12 -->
<div id="bloc-12">
			<div>
				<a href="https://diastemastudiericerche.org/product/marco-giommoni-janusz-podrazik-fundamentals-of-composition-with-opusmodus-book-1/" target="_blank"><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/Urania-Marco-Giommoni-Janusz-Podrazik-Fundamentals-of-composition-with-Opusmodus-book-1-diastema-studi-e-ricerche-1.webp"><img src="https://opusmodus.com/img/Urania-Marco-Giommoni-Janusz-Podrazik-Fundamentals-of-composition-with-Opusmodus-book-1-diastema-studi-e-ricerche-1.jpg" data-src="img/Urania-Marco-Giommoni-Janusz-Podrazik-Fundamentals-of-composition-with-Opusmodus-book-1-diastema-studi-e-ricerche-1.jpg" alt="libro" width="381" height="547"></picture></a>
			</div>
			<div>
				<h2>
					Fundamentals of composition<br>with Opusmodus<br>
				</h2>
				<h4>
					Marco Giommoni – Janusz Podrazik
				</h4>
				<div><p>
					This is the first volume of a series of publications specifically dedicated to composition and analysis of music using the Opusmodus system. This volume focuses on the basic elements of the system and on the “fundamental" strategies in defining symbolic expressions in a text-code i.e. generation and transformation of musical material to create a score. In this book, a few pages were dedicated to the history of musical theory, with particular reference to the relationship between numbers and music in the second half of the 20th century. The purpose of the book is therefore to demonstrate that the use of Opusmodus system is simple, linear, easy to learn and within the reach of every musician, and is by no means part of a universe reserved only for the few.</p><p>ISBN 9791280270078</p></div><p><a href="https://diastemastudiericerche.org/product/marco-giommoni-janusz-podrazik-fundamentals-of-composition-with-opusmodus-book-1/" target="_blank">More Info</a>
			</p></div>
		</div>
<!-- bloc-12 END -->

<!-- bloc-13 -->
<div id="bloc-13">
			<div>
				<picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/Janusz-Podrazik-1.webp"><img src="https://opusmodus.com/img/Janusz-Podrazik-1.jpg" data-src="img/Janusz-Podrazik-1.jpg" alt="Stéphane Boussuge01" width="570" height="380"></picture>
				<h6>
					Photo © Emanuel A. Klempa
				</h6>
			</div>
			<div>
				<h2>
					Janusz Podrazik
				</h2>
				<h4>
					Founder and creator of the Opusmodus System, Composer and Programmer
				</h4>
				<p>
					The Opusmodus Music Composition System was developed by Janusz Podrazik and team to take music into new directions and to contribute to unique outcomes.<br>
				</p>
			</div>
		</div>
<!-- bloc-13 END -->

<!-- bloc-14 -->
<div id="bloc-14">
			<p>
				<h2>
					Programmers
				</h2>
				<h5>
					Bill St. Clair<br>Ernst van Waning<br>Gail Zacharias<br>Greg Pfeil<br>Janusz Podrazik<br>Martin Simmons<br>Matthew Emerson<br>Yehouda Harpez<br>Zachary Beane<br>
				</h5>
			</p>
			<p>
				<h2>
					Documentation
				</h2>
				<h5>
					Dietmar Mondon<br>Dominik Šedivý<br>Janusz Podrazik<br>Marco Giommoni<br>Nigel Morgan<br>Phil Legard<br>Stéphane Boussuge<br>
				</h5>
			</p>
			<p>
				<h2>
					Contributors
				</h2>
				<h5>
					Achim Bornhoeft<br>Alain Jacomet Forte<br>André Meier<br>Didier Debril<br>Fabio De Sanctis De Benedictis<br>Gioia Meller Marcovicz<br>James Sutton<br>Jesper Elén<br>Jor van der Poel<br>Julio Herrlein<br>Marco Giommoni<br>Nigel Morgan<br>Patrick Mimran<br>Rangarajan Krishnamoorthy<br>Sungmin Park<br>Stéphane Boussuge<br>Torsten Anders<br>
				</h5>
			</p>
		</div>
<!-- bloc-14 END -->

<!-- testimonial -->
<div id="testimonial">
				<h2>
					Testimonial
				</h2><a href="https://www.moz.ac.at/people.php?p=51903&amp;l=en" target="_blank"><picture><source type="image/webp" srcset="https://opusmodus.com/img/lazyload-ph.png" data-srcset="img/mozarteum-logo.webp"><img src="https://opusmodus.com/img/mozarteum-logo.jpg" data-src="img/mozarteum-logo.jpg" alt="mozarteum logo" width="160" height="160"></picture></a>
				<p>
						Opusmodus is currently the most advanced software for computer-assisted composition available. It comes with the highest development potential to fulfil the aesthetical and technical requirements for contemporary composers. At the University Mozarteum, Salzburg Opusmodus is already part of the compositional education and will be the preferred production environment in the future.
					</p>
				<h5>
					Univ. Prof. Achim Bornhoeft <br>Head of Studio for Electronic Music,&nbsp;Head of Institute for New Music<br>
				</h5>
			</div>
<!-- testimonial END -->

<!-- ScrollToTop Button -->
<!-- ScrollToTop Button END-->


<!-- copyright -->
<div id="copyright">
				
				<p>
					<br>Copyright © MMXXIII Opusmodus™ Ltd. All rights reserved.<br>Product features, specifications, system requirements and availability&nbsp;are subject to change without notice.<br>Opusmodus, the Opusmodus logo, and other Opusmodus trademarks are either registered trademarks or trademarks of Opusmodus Ltd.<br>All other trademarks contained herein are the property of their respective owners.<br>
				</p>
			</div>
<!-- copyright END -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Officially Qualified – Ferrocene (266 pts)]]></title>
            <link>https://ferrous-systems.com/blog/officially-qualified-ferrocene/</link>
            <guid>38188734</guid>
            <pubDate>Wed, 08 Nov 2023 10:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ferrous-systems.com/blog/officially-qualified-ferrocene/">https://ferrous-systems.com/blog/officially-qualified-ferrocene/</a>, See on <a href="https://news.ycombinator.com/item?id=38188734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
    <p><img src="https://ferrous-systems.com/images/ferrocene_logo_blue.svg" alt="Ferrocene icon"></p><p>Ferrocene</p>
  <p>A Rust compiler toolchain for safety- and mission-critical environments.</p>
  

  <!-- Display sponsor link -->
</div>


        <div id="sidebar-sticky">
          <ul id="contentnav"></ul>

          <div>
            <p>Do you need help with coding?</p>
            
          </div>
        </div>
      </div><div>
        <div><p><img src="https://ferrous-systems.com/images/blog/Z1_en-3D_N.png" height="200em" alt="Mark of approval called `TÜV SÜD Mark P`"></p></div>

<p><strong>It’s official: Ferrocene is ISO 26262 and IEC 61508 qualified!</strong></p>

<p>You can even find the <a href="https://www.tuvsud.com/de-de/dienstleistungen/produktpruefung-und-produktzertifizierung/zertifikatsdatenbank?q=Z10+123030+0001+Rev.+00" target="_blank">certificate in TÜV SÜDs certificate
database</a>.</p>

<p>This means we achieved qualification for the open source Ferrocene toolchain.
Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical
environments.</p>

<p>Early last month, Ferrocene’s source code <a href="https://github.com/ferrocene/ferrocene">was open sourced on GitHub</a>.</p>

<p>After going through a couple rounds of dotting the i’s and crossing the t’s,
TÜV SÜD officially sent over the certification on Monday October 29. This is
the first qualification of a Rust compiler.</p>

<p>With these qualifications, Rust can now be used to develop software for
electronic systems in series production road vehicles. We’ve qualified
Ferrocene for use in systems up to ASIL D – the highest classification of
initial hazard as defined by this standard. This standard provides automakers
with guidelines that make the software being used to develop, produce, operate
and service the automotive sectors safe to use.</p>

<p>Beyond the automotive, Ferrocene can also be used in electronic programmable
systems in the industrial sector. Here the focus is on developing products or
applications that carry out safety functions. Like the automotive
certification, we’ve also gone for the highest level of risk reduction and
qualified it at SIL4.</p>

<p>“Ferrocene is a major achievement both for Rust and safety in automotive,” says
<a href="https://www.linkedin.com/in/floriangilcher/" target="_blank">Florian</a>. “It shows that Rust software can
be used in all critical environments. The process was challenging but matched
what we’ve come to expect from Rust: It enables building correct software at a
much lower cost.”</p>

<p>With this step, we can start rolling out the sales process on Ferrocene.  Our
initial availability is limited to a minimum order of 10 license seats for 12
months, starting at €2.400,00 (€240 each) for the quality managed licenses.</p>

<p>We’ve also got an overview of the reasons for Ferrocene on our YouTube
channel:</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/i06djj0KvB8?si=1OK9W85yFUkLqEIh&amp;start=218" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>And if your organization is interested in purchasing licenses, then <a href="https://ferrous-systems.com/contact#ferrocene">reach out
to us</a>.</p>

<p>We’ll be rolling out an individual purchase option at €25 per seat per month or
€240 per seat per year in early 2024.</p>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hard-to-swallow truths they won't tell you about software engineer job (664 pts)]]></title>
            <link>https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/</link>
            <guid>38188689</guid>
            <pubDate>Wed, 08 Nov 2023 10:41:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/">https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/</a>, See on <a href="https://news.ycombinator.com/item?id=38188689">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>Last weekend I had a chance to talk with some students who just got their degree. They are pursuing their first software engineer job. In conversation with them, I learned that they have a pretty wrong perception of this job.</p><p>This is because the reality for these new kids is so skewed. They only see good pay, remote work, team building, and pizza parties. </p><p>These are all good perks, but no one is talking to them about the real things that we do in this job. </p><p>As someone who spent a lot of years in this industry, I gave them a slap of reality in the face. I told them good things but also some hard-to-swallow truths. </p><p>After reading this article, some people will say I am talking overly negatively about it. but my opinion is that these things go together with the job and you have to accept it.</p><h2 id="1-college-will-not-prepare-you-for-the-job">1) College will not prepare you for the job</h2><p>This is the first thing I explained to these guys. </p><p>To precisely describe how college will prepare you for the job imagine that you are learning how to swim. </p><p>Your instructor spends a huge amount of time to describe you all the moves you need to make. He makes you recite all those moves, asks you questions about it and you have exams about it. But you never touch the water.</p><p>After 5 years, you get a piece of paper that proves your swimming skills. Then the day comes, and you have to swim now. The guys in the swimming place just kick you into the water.</p><p>You have a hard time breathing, you fight for your life. Maybe you will drown, maybe you will manage to swim.</p><p>That's what the first 6 months look like for a freshly graduated student in a software engineer job.</p><p>The college will prepare you for some basics, but what most of the colleges teach is so far away from day-to-day jobs. Most of the professors who teach at universities are not good software engineers. </p><p>Only a small percentage of them even worked as software engineers. Also, the university curriculums are heavily outdated. They trot years behind the software development market needs.</p><p>You have to put in extra work while you are in college. Code more projects besides homework and seminars. Do some volunteering. Learn about business domains to prepare for the job that awaits you. </p><p>Most of the students don't do that. They wait until they get their diploma to start working on their portfolio.</p><h2 id="2-you-will-rarely-get-greenfield-projects">2) You will rarely get greenfield projects</h2><p>In college or boot camps, you get a lot of smaller assignments that you write from scratch. Total freedom to express yourself. You can implement all the fancy stuff you learn, like algorithms or design patterns. </p><p>The time you spend on those assignments is at most a few weeks, but mostly a couple of days of work. Typically those assignments contain at most 500 lines of code.</p><p>In day to day job you are working with projects that contain multiple layers and thousands of lines of code. Multiple people work at the same time on those projects. You have limited freedom, you have to adapt to the project. The time you spend on projects is usually half a year to a couple of years.</p><p>Sometimes you spend a whole week fixing the nasty bug. The fix is just a couple of lines of code. You talk with your colleagues. You exchange information about the project. You collaborate with them to get approval for your solution.</p><p>New projects are rare, and most of the time you work on existing projects. You can consider yourself lucky if you get the normal project and not some old legacy project.</p><figure><img src="https://www.mensurdurakovic.com/content/images/2023/10/image-2-1.png" alt="" loading="lazy" width="768" height="6088" srcset="https://www.mensurdurakovic.com/content/images/size/w600/2023/10/image-2-1.png 600w, https://www.mensurdurakovic.com/content/images/2023/10/image-2-1.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="3-nobody-gives-a-f-about-your-clean-code">3) Nobody gives a f*** about your clean code</h2><p>You can forget that your boss will tell you: "Congratulations on writing this elegant and clean code, I am gonna give you a raise!". Quite the opposite, nobody cares about your clean code. </p><p>Don't get me wrong, people will expect you to write good and clean code. Still, you will rarely get any praise for it. Except sometimes from your colleagues who will review your code.</p><p>This may be a shock for some new folks, but it makes perfect sense. As a software engineer, your primary task is to generate value for users. Writing code is just a step that accomplishes that goal. </p><p>You can think of it as the following cycle:</p><ul><li>software engineer writes code</li><li>users get new features</li><li>more users use your products</li><li>company profits from products</li></ul><p>So code is just a tool to get profit. </p><p>I have seen so many graveyards of projects, with horrible legacy codebases. Still, these projects are successful as they have fancy landing pages and solve user's problems. So users are happy to pay for using them.</p><p>The user doesn't know how the codebase looks. The user just sees what features that product is offering. So don't get overly attached to your clean and elegant code. Focus on shipping the feature on time and bug-free.</p><h2 id="4-you-will-sometimes-work-with-incompetent-people">4) You will sometimes work with incompetent people</h2><p>People have prejudices that only smart and competent people work in the IT industry. Especially the software development branch. But this is far from the truth. </p><p>As in every job, you will sometimes have incompetent people in your environment. Working with them is very frustrating. They waste so much time and create a toxic environment. On top of that, they are extremely unproductive. All this reflects on deadlines and produces delays. This costs companies money and resources.</p><p>Unfortunately, I also had experience working with those kinds of people. I have to say, they tested my nerves so well that I spent a good amount of time thinking of ways to get around their incompetence.  </p><p>Here are some advice:</p><ul><li>try to be efficient and productive as much as you can, focus on yourself and not on them</li><li>try other options/solutions that don't involve that person in the process</li><li>document everything you do. If things go wrong, you will have proof of their incompetence</li><li>if you have a blocker because that person didn't do their job, try to ask someone else to unblock you  (if it's possible)</li><li>talk directly to them, be professional but not mean, and tell them what and how they can improve</li></ul><p>Remember that there is no need to be a jerk to them. </p><p>Sometimes you don't know the whole story. I have seen some cases where a person just can't do their job properly. They are burdened with tons of tasks and doing work for 2 people.</p><h2 id="5-get-used-to-being-in-meetings-for-hours">5) Get used to being in meetings for hours </h2><p>Meetings are an important part of the software development job. Some of them are good, but some of them are just time wasters. </p><p>There are recurring meetings scheduled on a daily or weekly basis. Most of these are not productive. The majority of them are forced by a person who is organizing them because that's the only "work" that that person is doing. </p><p>It's just an empty protocol to prove their purpose of existence in the company.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/UDpKWVuBNQE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Meeting | MonkeyUser 5SP Animation"></iframe></figure><p>On the other hand, there are productive meetings. Those meetings ensure information exchange between team members or different teams. </p><p>The majority of software engineers hate meetings. But remember that your job is also to communicate about things openly and proactively. </p><p>Sharing information is crucial for projects to move forward. When you share information it can help other teams to better understand what you are doing and the opposite. </p><h2 id="6-they-will-ask-you-for-estimates-a-lot-of-times">6) They will ask you for estimates a lot of times</h2><p>Business revolves around numbers. Every project has its cost, and to calculate the cost, management needs to estimate how long it will take to build a certain feature.</p><p>Then, it goes down to software engineers to estimate their work. Usually, estimates are time-based, but sometimes they also ask for complexity estimates. </p><p>In a lot of situations, you will have no clue how long it will take to build something. You read requirements, do some research and you give a number. </p><figure><img src="https://www.mensurdurakovic.com/content/images/2023/10/image-6.png" alt="" loading="lazy" width="1600" height="987" srcset="https://www.mensurdurakovic.com/content/images/size/w600/2023/10/image-6.png 600w, https://www.mensurdurakovic.com/content/images/size/w1000/2023/10/image-6.png 1000w, https://www.mensurdurakovic.com/content/images/2023/10/image-6.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Later, when you start to work on that feature, you encounter many problems that you weren't aware of when you gave time estimates. Then you need to compensate for the wasted and hope not to break the deadline.</p><p>That's why it's always good to underpromise but overdeliver. </p><p>For example, when your project manager asks you to implement feature X by Friday, you won't say "Oh, I can finish it by Tuesday". Instead, you will say: "Sure, no problem". </p><p>Why?</p><p>Because if you promise to deliver it by Tuesday and you run into some problems, you won't be able to fulfill the promise. Instead, if you accept Friday as a deadline, and you finish it by Wednesday, you can deliver it 2 days earlier. </p><p>There are a lot of formulas on how to do estimates, and everyone has their own rules. I also have my own rules. </p><p>If I need to deliver some feature, and I think it will take 2 days, I add roughly 40% more time to it, just to be safe. So, in this case, the estimate will be 3 days. Later, if I am done in 2 days, I can just deliver it earlier.</p><h2 id="7-bugs-will-be-your-arch-enemy-for-life">7) Bugs will be your arch-enemy for life</h2><p>The more you code, the more you are aware that bugs in the code are everywhere. When you are just starting with programming, you think you will code something, it will work fine and it's the end of the story.</p><p>But in reality, it's a different story. There are countless things that can produce bugs:</p><ul><li>your own code - humans make mistakes, and you should not trust that code is working perfectly. You can write tests, but bugs can occur after that due to various reasons that you aren't even aware of.</li><li>3rd party libraries - those libraries are also written by software engineers like you and me. Always watch for activity and how frequently those libraries are updated.</li><li>hardware failure - software relies on hardware. Mark Hanna explained what your software is without hardware in his quote: "It's fugayzi, fugazi. It's a whazy. It's a woozie. It's fairy dust. It doesn't exist. It's never landed. It is no matter. It's not on the elemental chart. It's not f***ing real."</li></ul><figure><img src="https://media.tenor.com/Zbfjs-GE8p0AAAAC/rookie-numbers.gif" alt="" loading="lazy" width="498" height="289"></figure><ul><li>electricity - yep, hardware needs electric power to run, without it, it's useless. I worked on one project with Raspberry Pi. The client had constant problems with the device turning off at random times. After days of investigation, we finally found out the issue. He used a different power supply than the original one provided. Because of that device was turning off at random times.</li></ul><p>So the truth is you should assume that everything has bugs. That's why experienced devs never trust their code if it runs successfully on the first try. Even if the QA engineer reports a bug, assume that the bug ticket has a "bug" and check for everything.</p><h2 id="8-uncertainty-will-be-your-toxic-friend">8) Uncertainty will be your toxic friend</h2><p>In this job, you will feel uncertainty almost all the time. </p><p>I already explained the estimates example above. That's just one example where you feel uncertainty. You give your best shot but you are not 100% sure you can finish the work in that estimate.</p><p>Besides that, there are countless other things that are uncertain. Here are some examples:</p><ul><li>implementing something in your project you never worked with, eg. 3rd party API - how are you going to implement something you aren't familiar with</li><li>transfer to a new project, with new technologies - you will think about how you are going to be efficient and productive with something you need to learn</li><li>move to a new company - you are unsure how you are going to settle in and vibe with new people</li><li>bug report on the day you need to finish the work - you fear that you are gonna break the deadline</li><li>job security - economic situations, pandemics, wars, and other factors heavily affect this industry which results in layoffs</li><li>the evolution of technology - you are never sure if tomorrow you are gonna be replaced by some new technologies like AI</li></ul><p>The good thing about uncertainty is that drives you to be a better software engineer. It demands improvements and learning if you want to stay in the game.</p><h2 id="9-it-will-be-almost-impossible-to-disconnect-from-your-job">9) It will be almost impossible to disconnect from your job</h2><p>From time to time, I catch myself thinking about my job, problems, and bugs. Or things I have to do tomorrow when I should relax and chill. </p><p>Sometimes, cold water in the shower wakes me up from my thinking about how I am gonna fix the nasty bug I worked on yesterday. I had countless squabbles with my girlfriend about why I am on Slack when we are on the beach. </p><p>So I publicly admit, that I have a hard time disconnecting from work. </p><p>It's especially hard to disconnect when you are working from home. If your laptop is on, you can always check emails or Slack messages.</p><p>So to avoid all this:</p><ul><li>I turn off my laptop after I am done with the work,</li><li>I put quiet hours on my mobile phone for my business emails</li><li>I pause Slack notifications after working hours. I disable them on weekends.</li><li>When my mind gets into this "think about work" loop, I try to immediately cut it out. I remind myself that rest and relaxation are important to be productive. </li><li>I take long walks after work. On some days I do sports like padel or football. </li><li>I try to engage socially as much as I can, avoiding screen time after work.</li></ul><p>Still, with all these steps I do every day, I fail a lot of times.</p><h2 id="10-you-will-profit-more-from-good-soft-skills-than-from-good-technical-skills">10) You will profit more from good soft skills than from good technical skills</h2><p>Technical skills are the ones you can learn easily. With different projects, you can understand a particular programming language. You can learn its syntax, pros and cons. It's just a matter of practice.</p><p>On the other hand, soft skills are much harder to improve. Improvement takes a lot of mental strength. You must do things you are not comfortable with. </p><p>You have to put yourself in situations where you can improve or practice particular soft skills.</p><p>For example, communication is one soft skill that people always talk about. Let's say you suck at public speaking. You have to force yourself into situations where you can practice some public speaking.</p><p>It's very hard to intentionally put yourself into situations where you know you will suck at. Your mind will do everything to avoid those situations. It will bring hundreds of excuses and it's easy to give up.</p><p>Besides communication, there are other <a href="https://www.mensurdurakovic.com/boost-your-career-with-top-ten-soft-skills/" rel="noreferrer">soft skills</a>:</p><ul><li>teamwork</li><li>learning mindset</li><li>organization/time management</li><li>emotional intelligence/empathy</li><li>approachability</li><li>persistence/patience</li><li>confidence</li></ul><p>I have met a lot of folks who are good with technical skills but awful to work with.</p><p>For example, one colleague would ask me for help a lot of times. I helped him a couple of times. Then, I noticed after we fixed his problems, he would come back to me and blame me for messing up other things on the project. Then I had to spend more time with him fixing stuff I wasn't even aware of. And because he was blaming me with such a bad tone, I stopped helping him. I would say that I have a lot on my plate to do, so I can help him tomorrow. </p><p>Another example, I was the new guy on the project. A colleague (let's call him George) was assigned to help me with anything I needed. I set up the project pretty much by myself, but there was one error I was getting when I tried to run the project. I asked George for help. He spent maybe 2 minutes with me in total to solve a problem and said that he didn't know the solution. I thanked him anyway, tried to solve the error on my own but finally succeded with the help of colleague Michael. On daily standup, George said that he spent his whole day supporting me. I never asked George for help, after that. </p><p>One more example, there was one colleague who was the main man on the project. Still, the whole team hated him (other devs, project managers, QA, designers, etc). He was a good software engineer, but a real jerk. Extremely rude in communication with everyone. He never wanted to admit he was wrong or accept constructive criticism of his code. Management tolerated him as he was always the loudest one in the room. When he finally resigned, the whole team was celebrating. </p><p>With good soft skills, people will like you more and you have a better chance of getting a raise or promotion. If you are technically gifted but hard to work with, your chances are slightly reduced.</p><p>Also, with good soft skills, people who know you will spread a good word behind your back. They can recommend you for the job, without even you knowing about it.</p><h2 id="conclusion">Conclusion</h2><p>Software development is not a dream job. </p><p>Working in software engineering often means long working hours. Most of the time, you are glued to a computer screen, with little work-life balance. </p><p>The job demands an online presence, sometimes even after work hours. This often leads to stress and limited personal time. </p><p>Additionally, job satisfaction is frequently hindered by tedious tasks. Depending on the situation you have limited career growth prospects. There is also potential isolation in remote work.  And there is always a threat of job insecurity due to rapidly evolving technology.</p><p>But, there is also positive stuff.</p><p>Software development nurtures continuous innovation. Software engineers can create attractive applications and solve interesting problems.</p><p>The global demand for software solutions across diverse industries is big. This means there is always a demand for good software engineers. Software development careers provide flexibility with remote work options. </p><p>It's one big blessing to work from any location. Flexibility allows you to sleep in the morning without an alarm. You can work from your home in comfy pajamas. Also, you don't waste your precious time and money on commuting.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chamberlain blocks smart garage door opener from working with smart homes (426 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/11/chamberlain-blocks-smart-garage-door-opener-from-working-with-smart-homes/</link>
            <guid>38188614</guid>
            <pubDate>Wed, 08 Nov 2023 10:25:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/11/chamberlain-blocks-smart-garage-door-opener-from-working-with-smart-homes/">https://arstechnica.com/gadgets/2023/11/chamberlain-blocks-smart-garage-door-opener-from-working-with-smart-homes/</a>, See on <a href="https://news.ycombinator.com/item?id=38188614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Your phone is our billboard    —
</h4>
            
            <h2 itemprop="description">Chamberlain packed its app with ads while disabling third-party access. </h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/2019myQ-LM-Ware233-800x389.jpg" alt="A photo of the myQ app from LiftMaster's website.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/2019myQ-LM-Ware233.jpg" data-height="700" data-width="1440">Enlarge</a> <span>/</span> A photo of the myQ app from LiftMaster's website.</p><p>Liftmaster</p></figcaption>  </figure>

  




<!-- cache hit 679:single/related:6e3ba8fc03d651b12cdeb85680d92238 --><!-- empty -->
<p>Chamberlain Group—the owner of <a href="https://www.lakewoodgaragedoor.biz/blog/the-history-of-garage-door-openers">most</a> of the garage door opener brands like LiftMaster, Chamberlain, Merlin, and Grifco—would like its customers to stop doing smart home things with its "myQ" smart garage door openers. The company recently issued a <a href="https://chamberlaingroup.com/press/a-message-about-our-decision-to-prevent-unauthorized-usage-of-myq">statement</a> decrying "unauthorized usage" of its smart garage door openers. That's "unauthorized usage" by <em>the people who bought the garage door opener</em>, by the way. Basically, Chamberlain's customers want to trigger the garage door and see its status through third-party smart home apps, and Chamberlain doesn't want that.</p>
<p>Here's the statement:</p>
<blockquote><p>Chamberlain Group recently made the decision to prevent unauthorized usage of our myQ ecosystem through third-party apps.</p>
<p>This decision was made so that we can continue to provide the best possible experience for our 10 million+ users, as well as our authorized partners who put their trust in us. We understand that this impacts a small percentage of users, but ultimately this will improve the performance and reliability of myQ, benefiting all of our users.</p>
<p>We encourage those who were impacted to check out our authorized partners here: <a href="https://www.myq.com/works-with-myq" target="_blank" rel="noopener">https://www.myq.com/works-with-myq</a>.</p></blockquote>
<p>We caught wind of this statement through the Home Assistant blog, a popular open source smart home platform. The myQ integration is being stripped from the project because it doesn't work anymore. Allegedly, Chamberlain has been sabotaging Home Assistant support for a while now, with the integration maintainer, Lash-L, telling the Home Assistant blog, "We are playing a game of cat and mouse with MyQ and right now it looks like the cat is winning."</p>
<p>Our immediate question is <em>why</em> would any garage opener company care about customers using its garage door opener. You sell garage door openers—isn't usage the goal? A quick perusal through the app store reviews reveals what's going on. The iOS app is sitting pretty at 4.8 stars, but the Android app has suffered a wave of one-star reviews starting in October.</p>
<p>"Sadly, this app now displays advertisement at the very top and I cannot find a way to disable it," writes one Play Store reviewer (Google doesn't provide links to reviews). "This is very disturbing and on top of it, it moves my garage opening button out of the visible part of the screen. So to use it I now have to first look at the ads, then scroll down and hope to find my button." Another user writes, "I don't want ads in an app that I have already paid for the companion product." Other one-star reviews mention things like, "I clicked door open/close event and it popped up the video storage subscription dialog to ask me to subscribe," and, "Most of the app is dedicated to trying to upsell you on services and devices you don't need."</p>                                            
                                                        
<p><em>Ah</em>, now it makes sense. Your garage door opener app isn't here only to open your garage door; it's here to display ads and upsell you on services. Using third-party apps would get around Chamberlain's hardware-app-as-ad-platform strategy, so they are now banned. Another part of this is probably the plug at the end of Chamberlain's statement to "check out our authorized partners," which includes companies like Amazon and Alarm.com.</p>
<figure><img alt="The logo of the Chamberlain Group, which owns over 60 percent of the garage door market." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/Chamberlain_Group_Logo.jpg" width="800" height="243"><figcaption><p>The logo of the Chamberlain Group, which owns over 60 percent of the garage door market.</p><p>Chamberlain Group</p></figcaption></figure>
<p>Presumably, these "authorized partners" are paying a fee to work with garage door openers that have already been sold to customers. Home Assistant's founder, Paulus Schoutsen, writes that while Chamberlain Group has never responded to Home Assistant's requests to work together, the open source project "cannot pay a partnership fee. Not only is this financially not viable, it also goes against our values." The integration is being removed in next month's release, though Schoutsen says, "We would happily welcome this integration back if Chamberlain Group would work with us for the good of their customers."</p>
<p>For users stuck with a Chamberlain garage door opener, Home Assistant recommends a little circuit board called a "<a href="https://paulwieland.github.io/ratgdo/">ratgdo</a>," which is specifically meant to hack into Chamberlain/LiftMaster garage door openers. This connects the garage door button wires to your Wi-Fi—something Chamberlain presumably can't break on purpose—and freely communicates with everything. It can even "report back the actual status of the door (closed, opening, open, closing)" somehow.</p>
<p>We'll leave you with some consumer advocacy from Schoutsen and the Home Assistant team: "Once a company decides to be hostile to its customers, the only way we can win is by not playing their game at all. Do not buy products or services from companies that treat their customers this way. Tell your friends not to deal with companies that treat their customers this way. Buy products that work locally and won’t stop functioning when management wants an additional revenue stream."</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't disable buttons (146 pts)]]></title>
            <link>https://gomakethings.com/dont-disable-buttons/</link>
            <guid>38188182</guid>
            <pubDate>Wed, 08 Nov 2023 09:07:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gomakethings.com/dont-disable-buttons/">https://gomakethings.com/dont-disable-buttons/</a>, See on <a href="https://news.ycombinator.com/item?id=38188182">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

		<header>

			

			

		</header>

		

<p>One of the most common accessibility issues I find (and fix) <a href="https://gomakethings.com/consulting">on client projects</a> is dynamically disabled form buttons when a form is being submitted.</p>

<p>Today I want to talk about why developers do it, why it’s bad, and what you can do instead. Let’s dig in!</p>

<h2 id="why-developers-disable-buttons">Why developers disable buttons</h2>

<p>Typically, I see the pattern used to prevent a form from being submitted a second time while waiting for the form is processed.</p>

<p>Often, you’re waiting for an API response that may take a few moments, and you don’t want the user to submit the form again until the original response is processed.</p>
<div><pre><code data-lang="js"><span>form</span><span>.</span><span>addEventListener</span><span>(</span><span>'submit'</span><span>,</span> <span>function</span> <span>(</span><span>event</span><span>)</span> <span>{</span>

	<span>// Don't let the form reload the page
</span><span></span>	<span>event</span><span>.</span><span>preventDefault</span><span>();</span>

	<span>// Get the submit button and disable it
</span><span></span>	<span>let</span> <span>btn</span> <span>=</span> <span>form</span><span>.</span><span>querySelector</span><span>(</span><span>'button'</span><span>);</span>
	<span>btn</span><span>.</span><span>addAttribute</span><span>(</span><span>'disabled'</span><span>,</span> <span>''</span><span>);</span>

	<span>// Do more form stuff...
</span><span></span>
	<span>// re-enable the button after the API responds
</span><span></span>	<span>btn</span><span>.</span><span>removeAttribute</span><span>(</span><span>'disabled'</span><span>);</span>

<span>});</span>
</code></pre></div>
<p>With the <code>button</code> disabled, it cannot be clicked again.</p>

<h2 id="why-this-pattern-is-bad">Why this pattern is bad</h2>

<p>For starters, it doesn’t really do what you want it to.</p>

<p>Just because the <code>button</code> is <code>disabled</code> doesn’t mean the form can’t be submitted. Someone could focus on one of the form fields, then press the <code>enter</code> or <code>return</code> key, and the form would submit.</p>

<p>But it’s also horrible for accessibility.</p>

<p>Elements with the <code>disabled</code> attribute cannot receive focus, which creates confusing situations for screen reader users and people who <a href="https://gomakethings.com/navigating-the-web-with-a-keyboard/">navigate the web with a keyboard</a>.</p>

<p>If the <code>button</code> is the current item in focus when you add the <code>disabled</code> attribute (for example, if someone just pressed it to submit the form), the element actually loses focus, which shifts to the <code>document</code> element.</p>

<p>For a screen reader user, this is particularly jarring, as now you’re in a totally different place on the page.</p>

<p>So to recap, it doesn’t do what you actually want it to <em>and</em> it breaks your application for a segment of your users.</p>

<h2 id="a-better-way">A better way</h2>

<p>So, what should you do instead?</p>

<p>I personally prefer to add an attribute to the <code>form</code> as its being submitted, and remove it after all of the form actions are done. Whenever a <code>submit</code> event happens, I check for that attribute first. If it exists, I end the event handler early to prevent multiple form submissions.</p>
<div><pre><code data-lang="js"><span>form</span><span>.</span><span>addEventListener</span><span>(</span><span>'submit'</span><span>,</span> <span>function</span> <span>(</span><span>event</span><span>)</span> <span>{</span>

	<span>// Don't let the form reload the page
</span><span></span>	<span>event</span><span>.</span><span>preventDefault</span><span>();</span>

	<span>// If the form is already submitting, do nothing
</span><span></span>	<span>if</span> <span>(</span><span>form</span><span>.</span><span>hasAttribute</span><span>(</span><span>'data-submitting'</span><span>))</span> <span>return</span><span>;</span>

	<span>// Add the [data-submitting] attribute to stop multiple submissions
</span><span></span>	<span>form</span><span>.</span><span>setAttribute</span><span>(</span><span>'data-submitting'</span><span>,</span> <span>''</span><span>);</span>

	<span>// Do more form stuff...
</span><span></span>
	<span>// Remove the [data-submitting] attribute
</span><span></span>	<span>form</span><span>.</span><span>removeAttribute</span><span>(</span><span>'data-submitting'</span><span>);</span>

<span>});</span>
</code></pre></div>
<p>This preserves focus on your form elements and avoids any weird accessibility issues, prevents duplication form submissions, and also prevents keyboard actions on other form fields from submitting the form.</p>

<p>You can also style form elements to “appear” disabled using the <code>[data-submitting]</code> CSS selector…</p>
<div><pre><code data-lang="css"><span>[</span><span>data-submitting</span><span>]</span> <span>button</span> <span>{</span>
	<span>opacity</span><span>:</span> <span>0.8</span><span>;</span>
<span>}</span></code></pre></div>
<p>Don’t forget to also include <a href="https://gomakethings.com/how-and-why-to-use-aria-live/">an ARIA live region</a> and display form status messages throughout the process.</p>

<h2 id="need-help-with-stuff-like-this">Need help with stuff like this?</h2>

<p>I offer <a href="https://gomakethings.com/consulting">consulting services</a>, and can help your organization ship faster, reduce costs, and simplify web development.</p>

<p>If you’re a solo developer and just wish you had someone to ask questions about stuff like this, I also offer private coaching. <a href="https://gomakethings.com/about">Send me an email to learn more.</a>.</p>

<p>I’ve advised and written code for organizations like Apple, Harvard Business School, Adidas, Chobani, and more. I’d love to work with you and your team.</p>


	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Home Assistant blocked from integrating with Garage Door opener API (847 pts)]]></title>
            <link>https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/</link>
            <guid>38188162</guid>
            <pubDate>Wed, 08 Nov 2023 09:04:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/">https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/</a>, See on <a href="https://news.ycombinator.com/item?id=38188162">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
<header>


</header>
<p><strong>TL;DR:</strong> The MyQ integration will be removed from Home Assistant in release 2023.12 on December 6, 2023. Chamberlain Group, the owners of MyQ, have released a public statement saying they will continue blocking access to third-party apps, like the MyQ integration. For current MyQ users we recommend <a href="https://paulwieland.github.io/ratgdo/" rel="external nofollow">ratgdo</a>, a device that physically connects to your MyQ garage door opener and allows you to control it locally.</p>
<p>If you own a garage door opener from Chamberlain or Liftmaster, you are probably familiar with MyQ. It’s a cloud-based smart home brand owned by Chamberlain Group, best known for its smart garage devices. MyQ is also currently one of the most problematic integrations for Home Assistant users. The MyQ garage door opener integration has, for the past months, been in a state of <a href="https://community.home-assistant.io/t/the-current-state-of-myq-from-the-codeowner/630623">constant repair</a> as the integration breaks, is fixed, and then breaks again. This is a direct result of actions taken by MyQ to block access from third parties.</p>
<a name="read-more"></a>
<p>Last month, Chamberlain Group put out a <a href="https://chamberlaingroup.com/press/a-message-about-our-decision-to-prevent-unauthorized-usage-of-myq" rel="external nofollow">statement</a> by their CTO, Dan Phillips, on this matter:</p>
<blockquote>
<p>Chamberlain Group recently made the decision to prevent unauthorized usage of our myQ ecosystem through third-party apps. This decision was made so that we can continue to provide the best possible experience for our 10 million+ users, as well as our authorized partners who put their trust in us. We understand that this impacts a small percentage of users, but ultimately this will improve the performance and reliability of myQ, benefiting all of our users.</p>
</blockquote>
<p>This <em>‘unauthorized usage’</em> appears to refer to the MyQ integration for Home Assistant which was added to Home Assistant in February, 2017. We have reached out to Chamberlain Group in several ways to see if we can come to an understanding, but we have not received an official response. We can only assume that this means Chamberlain Group has made its decision and will force customers to use only the MyQ app or those of their authorized partners.</p>
<p>You may wonder if Home Assistant could become an authorized partner. In their partner program, the partner companies pay Chamberlain Group for the privilege of letting MyQ owners control their own garage doors. We are open to working together with Chamberlain Group, but as Home Assistant is an open-source project, we cannot pay a partnership fee. Not only is this financially not viable, it also goes against our values. MyQ users should be able to access the devices they paid for and the data they own in any way they want, without a third party having to pay an additional fee.</p>
<p>So, to quote the maintainer of the MyQ integration, <a href="https://github.com/Lash-L" rel="external nofollow">Lash-L</a>:</p>
<blockquote>
<p>We are playing a game of cat and mouse with MyQ and right now it looks like the cat is winning.</p>
</blockquote>
<p>Once a company decides to be hostile to its customers, the only way we can win is by not playing their game at all. Do not buy products or services from companies that treat their customers this way. Tell your friends not to deal with companies that treat their customers this way. Buy products that work locally and won’t stop functioning when management wants an additional revenue stream.</p>
<p>Because we cannot continue to work around Chamberlain Group if they keep blocking access to third parties, the MyQ integration will be removed from Home Assistant in the upcoming 2023.12 release on December 6, 2023. We are very disappointed that it has come to this and sincerely hope that Chamberlain Group is willing to reconsider its position. We would happily welcome this integration back if Chamberlain Group would work with us for the good of their customers.</p>
<p>For now, if you are a MyQ owner, we’re afraid you are in the ‘small percentage of users’ Chamberlain Group refuses to serve. We recommend buying <a href="https://paulwieland.github.io/ratgdo/" rel="external nofollow">ratgdo</a>.</p>
<p>Ratgdo is a fully local, ESPHome-based, solution that is compatible with MyQ’s security+ protocol and can be installed on an existing MyQ system by connecting three wires. It offers the same garage door controls that MyQ does and even adds features that MyQ does not have, like motion events, controlling the light, and locking out wired remotes.</p>
</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Most Video Game Artwork Will Never Be Seen (112 pts)]]></title>
            <link>https://aftermath.site/most-video-game-artwork-will-never-be-seen</link>
            <guid>38187972</guid>
            <pubDate>Wed, 08 Nov 2023 08:27:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/most-video-game-artwork-will-never-be-seen">https://aftermath.site/most-video-game-artwork-will-never-be-seen</a>, See on <a href="https://news.ycombinator.com/item?id=38187972">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Artists do some of the most important work in video games, as it's artists who define the look of the worlds we inhabit and the characters we fall in love with. One of my greatest pleasures working around video games is getting to <em>see </em>that work, and one of the greatest injustices is the way we rarely get to see--and artists rarely get to show--that much of it.</p><p>We see <em>some</em>, of course. Publishers tease games with a piece or two of uncredited key art, they might release some wallpaper during development, then afterwards dump a gallery on Artstation and sell a hardcover art book and some prints. But there's so much more that goes into a game's development than the polished pieces we see after it's already done, and there are countless artists whose portfolios have giant holes in them because of the strict rules governing the crediting and ownership of the works they create.</p><p>While <em>some </em>of the commercial reasons for keeping game art under wraps make sense, many artists working in the video game industry say they're subject to a power imbalance, even in full-time studio positions, that sees the bulk of their work locked away in vaults, where not only can fans never see them but where artists can't share them either, not even in professional settings like job applications or portfolios.</p><p>It's a situation that calls into question what ideas like creation and ownership even mean in an industry like this, and is an intersection at the junction of "what is right?" and "well, this is how it's always been done" that, as a long-time concept/development art freak, has always fascinated me. In an effort to better understand this alleged imbalance, then, I spoke with a number of working video game artists, some at big AAA studios, others working the indie freelance beat (and many in between) to understand what's keeping their work locked away, and what they'd like to see changed in the future.</p><p>It's important to note here that these artists are all what you would <em>broadly </em>consider "concept artists". The folks painting landscapes and designing outfits and drawing weapon sketches. They're not animators or 3D artists or texture artists or lighting specialists, whose own challenges and issues in the modern workplace would require their own separate features. </p><p>Let's meet them! These aren't their real names, of course; given the NDA-breaking subject matter at hand I've protected their identities. <strong>Frank </strong>has worked for over 15 years across multiple console generations, AAA and indie. <strong>Heidi</strong> has primarily worked as a contractor for various indie games studios. <strong>Brian </strong>has AAA experience at some of the world's biggest publishers, and has done some Hollywood movie work as well. After working eight years in studios, <strong>Sally</strong> has since gone freelance, working on everything from mobile to indie to AAA. And <strong>Daisy </strong>is a AAA veteran who has since moved into independent development.</p><p><strong>Luke Plunkett</strong>: <em>What do the rules around sharing your artwork currently look like? How strict is the average NDA you're asked to sign in 2023?</em></p><p><strong>Brian</strong>: Typically you are not allowed to share work until you’ve received permission from your boss at a studio. They are also not always on the same page about this. I have shared work that I was told was okay only to get an upset email from another higher-level employee that wasn't aware I got permission.</p><p>Most studio work I’ve done has NDAs that are effective in perpetuity. This is not typically something I agree to these days unless the company has a good track record of letting artists share their work eventually.</p><p><strong>Frank</strong>: Working with a small indie team I have a lot of freedom. In the past at big studios, having started my career in the early 2000's, there was zero expectation I had any personal freedom to share my work outside of a folio once a title had shipped.&nbsp;</p><p>Over the years there was more of a pushback on that though, particularly as more opportunities to share emerged online and interest in the art tended to grow beyond those of us making it. Stuff like art dumps meant there was more of a desire for our art to be showcased on a personal level, but that was still only for shipped games, not cancelled ones.</p><p>Contracting I have found to be very studio-dependent, with smaller teams pretty willing to let you negotiate. Many smaller projects tend to be very open about development, from announcement onwards, so lots of work-in-progress stuff is encouraged as a form of promo.</p><p><strong>Heidi</strong>: When I was in a studio it was pretty strict. Everything we made was under tight lock and key, and with my work as a 2D artist doing concept art, if we wanted to show anything it had to be approved first, and had to be done through official channels. The studio was often credited rather than myself. Game development is a team sport, so being credited as a team doesn't necessarily bother me, and when it's studio work there's an understanding that it's for the studio 'brand' rather than me the artist. But it is a strange situation, especially when the murky waters of 'who did what' start happening. I was credited explicitly only when it could be seen that me, as a very online developer and artists, could be publicly and positively associated with the project. This isn't the case for everyone or at all studios though.</p><p>No two NDA's I've signed are the same. I wish they were, it'd make my life SO MUCH EASIER. Some are TREMENDOUSLY strict, and others really do not care when and how you show the work. Some are very okay with me sharing whatever work whenever as a means of guerrilla marketing (I don't necessarily recommend this approach as you can find yourself in weird 'manage players expectations' territory). Others don't want me to share or acknowledge I've been working on a project until it is announced or has even been released, and even then I often have to check in with management to make sure it aligns with brand messaging. In most cases once the project is released I'm able to share approved or publicly-available pieces I've created on my website. The biggest common thread I can think of is that you can only show explicit work of stuff that made it into the finished game, there are exceptions to this of course, but generally, so you don't accidentally wake up to a million clickbait 'INSERT GAME HERE&nbsp; was going to have FEATURE I CONCEPTED AND LIKED HOW IT LOOKED SO I CHUCKED IT ON MY WEBSITE' articles. I also find that there is an unspoken (and sometimes spoken) rule of 'ask before you post stuff'. Additionally, marketing sometimes has a plan for certain pieces and you don't want to disrupt stuff like that.</p><p><strong>Daisy</strong>: Being an employee at a game studio - contract fulltime, freelance or fulltime - means waiting until the studio gives the greenlight at an unspecified time, usually a few to several months, after the release of a game. Sometimes this waiting period <a href="https://magazine.artstation.com/category/inspiration/art-blast/" target="_blank" rel="noreferrer noopener">revolves around artblasts on Artstation</a>, artbook releases and other PR-related things on social media. With film and animation, waiting around for the studio greenlight could take several years and they are far more judicious with people who break NDA (if they are caught). The general point of this level of scrutiny is to prevent leaks.</p><p>Being a contractor depends if the job is onsite or remote. NDAs are still generally pretty strict on both. Updating public-facing portfolios with project materials even after a product has been made public knowledge is still implicitly a no without studio approval, this information is often done through department heads or relayed through an outsource manager or agency contact. Not all contracts are made equal, some last around a month or three while others are renewed yearly. Because remote freelancers in particular are always in a state of feast or famine, some prefer to upload NDA materials on their portfolio through a password-protected page, or have private pdfs, or have said materials ready only during interviews so long as they're not being recorded.</p><figure><blockquote><p>...the implicit expectation is that a studio will own the work you make forever. One particularly hostile contract stated they would own my work in perpetuity for the rest of my life, or my children's lives. Not sure if that one will hold up in court.</p></blockquote></figure><p><strong>LP</strong>: <em>How much work have you been able to share publicly over the course of your career?</em></p><p><strong>Brian</strong>: In the last five years I’d say I’ve only been allowed to show maybe 5% of my professional output. I have had an unfortunate string of projects get cancelled and the work just gets locked away forever after that.</p><p><strong>Frank</strong>: Over my career I have worked on 12 projects but shipped only four titles and two pieces of DLC.</p><p>Those cancelled projects tend to not get as far in development, so not as much final art, but there at least tend to be art bibles and vertical slice examples at a minimum. Some get pretty far along though.&nbsp;</p><p>Only one cancelled project have I been able to publicly show, and that was because it was developed internally at a big studio, but based on our creative director's personal pitch and development was agreed only on the condition that if it didn't continue development the IP was still owned by the creative director, so he granted us permission.</p><p><strong>Heidi</strong>: Every weekday, 9-5 I am drawing for games, so naturally loads of art ends up on the cutting floor. There's also the pre-production stuff you do where you're figuring out ideas that will never make it into games. For every piece of art I've made for games, there's at least six or more thumbnails (or four or more dirty nasty sketches) I've done just to figure things out. I also try and write documents for stuff so that clients have a paper-trail for my work process with their in-house art teams (or if it's just me, it's for me so I don't lose my marbles trying to remember why I spent two hours researching something). Games are also just funny beasts when they're in development, I've concepted out whole features only for them to be scratched, sometimes a library of icons you've built is no longer relevant because a feature iterates, things are constantly changing, and sometimes the nature of the beast means that we kill the darlings.</p><p>I will also take this question to clear up a big bugbear of mine (sorry it's soapbox time): most concept art never leaves the studio. It's used to communicate ideas and well, concepts, to other team members and stakeholders. Because of it's very nature this means that it's often not the sexiest looking thing and is done in a small amount of time. Concept art is VERY RARELY that big beautiful gorgeous splash art we trot out for marketing purposes. I really wish as an industry we would learn to manage expectations there, because it's damaging junior artists. Because that stunning splash art marketing departments call 'concept art' is often art that's done after tons of concept art work and is created as key art, or it is art that has been created for marketing purposes. This isn't to say that actual concept art isn't stunning and incredible to look at, it just means that my producer is probably gonna be really mad at me if I take 3 weeks to paint key art to communicate one idea to the rest of the team, rather than work efficiently in the time we have to communicate several ideas.&nbsp;</p><p>TLDR: Most things get left on the cutting floor, I'd say about 65-75% depending on the project and what stage of development we are in.</p><p><strong>Sally</strong>: With the exception of work I lost due to a hard drive failure on my end, my studio work is all public at this point. I’ve been a freelancer since the end of 2018 and that contains a lot more locked away NDA stuff, mostly due to the projects I was contracted on being pitches which aren’t necessarily projects which make it to full development or funding. Overall I’ve been weirdly lucky, I’ve had a game I’ve worked on release for almost every year of my career and the amount stuck behind NDA is not much more than a couple of year's worth of work – but a couple of years when I already have the skills and experience for that not to be too much of a sting.</p><p><strong>Daisy</strong>: Over 90% of the studio work I've made over my career is locked away forever, through studio closures, liquidating assets after acquisitions, extremely nosy IT guys who don't like people using USB ports, and just really binding NDA clauses. This is why personal work tends to show up more in some portfolios and public-facing artist profiles.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/11/archives2.gif"><figcaption><a href="https://www.youtube.com/watch?v=QNN2LFe_iD8" target="_blank" rel="noreferrer noopener">Tate</a></figcaption></figure><p><strong>LP</strong>: <em>There seem to be lots of written (and unwritten) rules around when and how much work an artist can share from a project they worked on. Is there, like, a statute of limitations regarding this stuff? A point where you just think, you know what, fuck it, I'll just post this art and see if I get asked to take it down or not?</em></p><p><strong>Brian</strong>: God I wish. This is not a typical thing to ever get in a contract from a bigger client and those that do usually have to fight for it.</p><p><strong>Frank</strong>: &nbsp;I have never had timeframes in a contract for this stuff. There tends to be a bit of an understanding that maybe a console generation later or if the project isn't being developed in another fashion or the original studio is dead, then risk of showing stuff is low if you were able to smuggle it out.&nbsp;</p><p><strong>Heidi</strong>: Yes. I have mixed feelings about it. But I've had some contracts where the wait time is AGES but others where it's 'mate, just wait until it's out and then let us know when you're posting'. This is for many reasons, one that I hear a lot from non-artist people (CEO's, lawyers, marketing, etc.) is that 'if we post too early it could have people steal our IP'. For some studios, the reason relates to marketing, and for others that use contractors to supplement in-house teams, it's about letting that art team having their moment in the sun first. Some only ever let you show work if it's behind a password-protected part of your portfolio, and others NEVER consent to contractors showing stuff.</p><p><strong>Sally</strong>: I’ve not seen anything on paper that stood out – I tend to just wait until the game has released and then ask if it’s OK to post things. If the game has been out for three years I’ll just…post things anyways to be honest, I’m not a big name artist so me dropping some development concepts for a project onto my personal portfolio website isn’t going to make the front page of Kotaku, but I know larger artists don’t have that freedom.</p><p><strong>Daisy</strong>: There is never an official statue of limitations because the implicit expectation is a studio will own the work you make forever. One particularly hostile contract stated they would own my work in perpetuity for the rest of my life, or my children's lives. Not sure if that one will hold up in court.</p><p><strong>LP</strong>: <em>How do you personally feel about all this? The restrictions, the vaults, the contracts?</em></p><p><strong>Frank</strong>: &nbsp;I started this job expecting it was all a secret sealed vault, I guess I expected fewer cancellations though.</p><p>I understand certain aspects of secrecy as it can be important for the marketing process and wider businesses of a studio but I would like clearer request options or ways for studios to kind of let ex-employees know they can show stuff, though that doesn't help much if you don't have access to the media.&nbsp;</p><p>It also is harder for some departments, concept can just grab stills but props, animation, etc need to take time out to do renders or specifically showcase their work, which often you just don't get a chance to do.&nbsp;</p><p><strong>Heidi</strong>: I accept it as part of the job. When i crack open a cold one with the boys* (*I sit at my desk and open Affinity and Procreate before listening to history podcasts while I draw), I'm no longer 'Heidi the artist', but instead I'm 'Heidi the artist who is creating work for X'. I have been hired for my talent, skills, and taste and how I apply that to this client or studio's IP, NOT so I can draw what I want for me. This is the trade-off you make being a professional artist, you're collaborating and making visual loveliness for others, not necessarily yourself.&nbsp; You're contributing to a commercial project, not creating your own art.&nbsp;</p><p>Because of this attitude, I accept from the get-go that a bunch of my stuff will never leave the workplace. What I do take issue with is that studios often like to try and restrict what artists can show after the project is done and the artist leaves a studio. All artists should be able to show work from a project once it's released as part of a folio and resume. Not letting an artist do so hinders their employment opportunities and disrespects their time on a project. When you give years or months to a project, it can be a real sucker punch when all of a sudden people tell you that you must never share that you worked on the project and never share your work. Be nice to your artists. Let them share stuff after a period of time so they can get more work and you get more publicity, it's a win-win.</p><p><strong>Sally</strong>: I find it slightly&nbsp; frustrating that I can’t show some of my pitch concept work, as it represents work that I don’t have time to replicate in my own time. But I’m not bitter about it, it is how it is.</p><p>Ultimately I’m here to work on cool projects with a team not like...be a rockstar, so the idea of having people on social media not see a thing I made doesn’t bother me so much.&nbsp; The idea of potential future employers not see something I’ve made that might align with a project they’re hiring for is more of a sting, you can put things behind a password wall or whatever, but an art director browsing Artstation isn’t going to know to ask for that.</p><p><strong>Daisy</strong>: This had and still does bother me, and it makes me wary about sharing my best ideas on a project. I accept it as part of my job, since clients don't always choose the more interesting ideas anyway, and it would be fantastic if artists as a whole were given far more leeway.</p><figure><blockquote><p>I think its brazenly immoral to revoke portfolio usage rights from the artist for all time. Like yeah you can own the pictures, man, but you shouldn't be allowed to keep us from using our labor to secure future jobs.</p></blockquote></figure><p><strong>LP</strong>: <em>What are your thoughts on the ownership of your work? You're getting paid to create things for a company, by a company, but also...you still created them. </em></p><p><strong>Frank</strong>: Ownership of work produced at a studio is theirs, which for me has been fine and makes sense.&nbsp;</p><p>Some studios have extended that to anything you make during employment, but I think that is seen as a huge overreach now, so it's less common, or at least potential to negotiate out of a contract.&nbsp;</p><p>Even the big AAA studios tend to have declarations for personal projects or work that exists outside of your job that are yours, you just can't commercialize it during your employment.&nbsp;</p><p>At least in indie I see some audio folk retaining all rights though, and they're able to profit from those soundtracks, and frankly I would appreciate similar opportunities for visual artists to have potential future revenue through official print sales or merch, but it does get complicated when it may overlap with a studio's core business.</p><p><strong>Heidi</strong>: Yes and no. As a freelancer I have to pop on my lawyer hat sometimes and read my contracts to make sure that nobody tries to be sneaky and own ALL THE WORK I produce during my time on a project. I've had some people try (intentionally and unintentionally), but usually once you point out that work that I'm doing in my spare time is unrelated to <em>work</em>, and cannot be owned by the company, they change things pretty quickly. Work that I do for clients and studios though belongs to them. I'm working on someone's IP, and even if I am helping them create that IP, it belongs to the company and not to me. It's the reality of how the sausage gets made, which is something that can frustrate artists. It comes back to that 'not creating for myself, but creating for a big team-wide project and IP' separation of church and state.</p><p>I would like to see parts of this change however, I'd love to see a residuals or royalties situation (that much more intelligent people than me can create) come into affect for artists who do, say, create a beloved IP staple character for a franchise.&nbsp; Ultimately at the end of the day, the artist has created one of the most marketable (if not THE most marketable) aspects of the character and should be compensated fairly for that work and the success it brought the studio. But I have no idea if this could actually happen (once again, smarter folks than I could probably tell you, I went to art school for a reason).</p><p>When working in a commercial video games setting, it can also be a nightmare to show people the really rough parts of the visual journey. Art Literacy is so garbage in the games industry, and nowhere is this more frustrating and apparent than when you're pitching to stakeholders, legal, etc. If you show the messy development work (eg. the post-it's i've scrawled nonsense on, initial sketches, thumbnails, etc.) it can lead to bogged-down discussions and unhelpful feedback, because we don't teach folks how to look at and appreciate art and develop those literacy skills. It can also be really difficult to manage expectations of people with low art literacy who don't value diverse art styles. If I show someone something that looks rough and explain where it's going, they can draw an incorrect conclusion. You can be the best communicator in the room and this can still happen if the other party doesn't grasp the visualization AND doesn't have strong art literacy skills.</p><p>Because of those two factors it does mean that things like my aforementioned nasty post-its, sketchbooks, writings, sketches, and other stuff, doesn't get released. You have to break through the hurdle of 'this is disposable and ugly' and corporate overlords giving you approval to share, and that tends to mean that it doesn't get shared to the public.&nbsp;</p><p>This is also before I even touch the idea of 'sharing rough art from a cut feature'. That doesn't get shared in my experience because the headache of dealing with 200 Twitter or Reddit commentators saying that 'GAME WAS GONNA HAVE THIS AND IT GOT CUT!!', and then blaming anything and everything, when in reality it was because we just didn't have time or it didn't work with the project the way we thought, is incredibly draining.&nbsp;</p><p><strong>Brian</strong>: The general terms for artists from bigger clients grant all rights to them. I think it's brazenly immoral to revoke portfolio usage rights from the artist for all time. Like yeah you can own the pictures, man, but you shouldn't be allowed to keep us from using our labor to secure future jobs.</p><p><strong>Daisy</strong>: Artists in videogames, film or animation have no rights to the work we make for clients or studios. Unless we have a more friendly contract and/or specific details are negotiated before the work begins, and that might count against some artists being hired again for new projects because they are perceived as being "difficult". With clients this depends on our professional relationship being amiable enough to navigate some leniencies.&nbsp; Our agency is often stripped from us in the name of realizing someone else's vision, to be diplomatic. The studio or the client still have the power to do whatever they want to the work after the fact and sometimes they make some unfortunate, undesirable choices. It's one thing if it's just one project, but over time it gets seriously depressing.</p><p><strong>LP</strong>:<em> OK, we've talked about how things are, but how would you like things to be? In a hypothetically perfect world for games artists, what would control and crediting and ownership over the things you've created look like?</em></p><p><strong>Frank</strong>: In the ideal world I would still understand, and want control over the work-in-progress pieces released on a game. Thinking of it as a creative director or lead, we all have suffered one time or another with the very first in-progress screenshot being used in articles to promote the game five years later, and you certainly want to clear early art.&nbsp;</p><p>Later in production, or for shipped titles, having at least public folios of the work should be standard. It does get complicated if projects are still being developed though, and you could negatively impact the project for those remaining on a team. Though I will also say I have seen plenty of NDA-breaking work in folios as people tend to take the risk on stuff they deem safe.&nbsp;</p><p>Definitely my biggest regrets about old art on projects was just not capturing or taking as much of my work during development, with my focus being on shipping the game.&nbsp;It has been funny recently hearing lots of stories of publishers reaching out to devs hoping they 'stole' development work for use in HD remasters when the publisher lost all of the original development data.</p><figure><blockquote><p>...the artist has created one of the most marketable (if not THE most marketable) aspects of the character and should be compensated fairly for that work and the success it brought the studio.</p></blockquote></figure><p><strong>Brian</strong>: I am staunchly in favor of NDA term limits for work done. There is no world where it feels just to legally restrict artists from showing their work five years removed from doing it. If your project still isn't done in five years, that is a failure of management, not the artists.</p><p>I think all artists on a project should be allowed to show work done on the project two weeks after release. Should a project get cancelled publicly, artists should be allowed to post art done for the project immediately following that announcement. If it gets cancelled privately, artists should be allowed to show that work no later than one year after cancellation. In a perfect world at least. Rules like this would force corporations to be much more careful in their project development. They often don’t want cancelled artwork out there because of the idea that they may use it down the line, but they never do.</p><p><strong>Sally</strong>: Just between us, I just show things anyways; ask forgiveness, not permission. I know I'm not the only one who does that, I was encouraged to do it by other artists.</p><p>I don't have a moral problem not showing things from projects from smaller indues, there's an urge not to screw the little guy over, you know? But if I worked on a big IP,  and publishers can be weird about that, I'm putting the work in my portfolio anyways and being vague about where it's from if I have to.</p><p>Cancelled projects I think should be fair game, we should be able to show that. Another factor going on here is that as a concept artist my work is literally made to be disposable, you make a lot of options and the ones that don't make it get thrown in the bin, it's just part of the process. I would perhaps feel differently about a polished asset I spent three months on never seeing the light of day.</p><p>I'm not sure what rules I'd want in an ideal world, because I find that it depends on the client and the project. I can't yet show any work from the project I'm currently on, that I've been on for two years, but I also wouldn't WANT to, not until the project is done. It kinda makes you feel like a secret agent when the project is huge, and even if it means I've not been able to show any of the work for two years, I wouldn't want to spoil the surprise.</p><p><strong>Daisy</strong>: I think ideally every artist deserves credit on what they've contributed to the project, and should never be denied being able to show off what they've made after a few months - or eight - of a product's launch. I even think they should be allowed to sell 2D renders of their work within a limited amount and profit ceiling. The recession is rough out here, and laying off people in the cold with no way to market themselves and their talent is horrible. </p><p>With acquisitions, if and when things fall like with Embracer, people who've worked on materials and technology to support projects should get them back hassle-free so when they <em>do </em>try to start over, they're not doing it from scratch. I hope companies are far more vigilant about protecting their IP from exploitative technologies like generative AI, and their employees as well. And one final thing, I wish companies were far better at organizing and archiving their projects, because it seriously sucks to see gigs and terabytes worth of work go down the drain because no one bothered with proper backups and decent storage.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When Linux Spooked Microsoft: Remembering 1998's Leaked 'Halloween Documents' (178 pts)]]></title>
            <link>https://linux.slashdot.org/story/23/11/05/046247/when-linux-spooked-microsoft-remembering-1998s-leaked-halloween-documents</link>
            <guid>38187614</guid>
            <pubDate>Wed, 08 Nov 2023 07:23:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linux.slashdot.org/story/23/11/05/046247/when-linux-spooked-microsoft-remembering-1998s-leaked-halloween-documents">https://linux.slashdot.org/story/23/11/05/046247/when-linux-spooked-microsoft-remembering-1998s-leaked-halloween-documents</a>, See on <a href="https://news.ycombinator.com/item?id=38187614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="fhbody-172173040"><p>
			
		 	
				It happened a quarter of a century ago.   The <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/11/biztech/articles/03memo.html"> <em>New York Times</em> wrote</a> that "An <a href="http://www.catb.org/~esr/halloween/halloween1.html">internal memorandum</a> reflecting the views of some of Microsoft's top executives and software development managers reveals deep concern about the threat of free software and proposes a number of strategies for competing against free programs that have recently been gaining in popularity."

<i> The memo warns that the quality of free software can meet or exceed that of commercial programs and describes it as a potentially serious threat to Microsoft.   The document was sent anonymously last week to Eric Raymond, a key figure in a loosely knit group of software developers who collaboratively create and distribute free programs ranging from operating systems to Web browsers.   Microsoft executives acknowledged that the document was authentic...<p> 

In addition to acknowledging that free programs can compete with commercial software in terms of quality, the memorandum calls the free software movement a "long-term credible" threat and warns that employing a traditional Microsoft marketing strategy known as "FUD," an acronym for "fear, uncertainty and doubt," will not succeed against the developers of free software.   The memorandum also voices concern that Linux is rapidly becoming the dominant version of Unix for computers powered by Intel microprocessors. </p><p> 
 The competitive issues, the note warns, go beyond the fact that the software is free. It is also part of the open-source software, or O.S.S., movement, which encourages widespread, rapid development efforts by making the source code — that is, the original lines of code written by programmers — readily available to anyone. This enables programmers the world over to continually write or suggest improvements or to warn of bugs that need to be fixed.  The memorandum notes that open software presents a threat because of its ability to mobilize thousands of programmers.  "The ability of the O.S.S. process to collect and harness the collective I.Q. of thousands of individuals across the Internet is simply amazing," the memo states. "More importantly, O.S.S. evangelization scales with the size of the Internet much faster than our own evangelization efforts appear to scale."</p></i> <br>


Back in 1998, Slashdot's CmdrTaco <a href="https://slashdot.org/story/98/11/07/1259212/ms-ponders-fighting-linux-with-the-law">covered the whole brouhaha</a> — including <a href="http://www.cnn.com/TECH/computing/9811/06/linux.threat.idg/">this CNN article</a>:

<i>A second internal Microsoft memo on the threat Linux poses to Windows NT calls the operating system "a best-of-breed Unix" and wonders aloud if the open-source operating system's momentum could be slowed in the courts.<p> 

 As with the first "Halloween Document," the memo — written by product manager Vinod Valloppillil and another Microsoft employee, Josh Cohen — was obtained by Linux developer Eric Raymond and posted on the Internet. In it, Cohen and Valloppillil, who also authored the first "Halloween Document," appear to suggest that Microsoft could slow the open-source development of Linux with legal battles.  "The effect of patents and copyright in combating Linux remains to be investigated," the duo wrote.</p></i> <br>

Microsoft's slogain in 1998 was "Where do you want to go today?"  So Eric Raymond published the documents on his web site under the headline  "Where will Microsoft try to drag you today? Do you really want to go there?" </p><p> 

25 years later, and it's all still up there and preserved for posterity on Raymond's web page — a collection of <a href="http://www.catb.org/~esr/halloween/index.html">leaked Microsoft documents and related materials</a> known collectively as "<a href="https://en.wikipedia.org/wiki/Halloween_documents">the Halloween documents</a>." And Raymond made a point of thanking the writers of the documents, "for authoring such remarkable and effective testimonials to the excellence of Linux and open-source software in general."</p><p> 
<em>Thanks to long-time Slashdot reader <a href="https://www.slashdot.org/~mtaht">mtaht</a> for remembering the documents' 25th anniversary...</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The bash book to rule them all (110 pts)]]></title>
            <link>https://fabiensanglard.net/bash/index.html</link>
            <guid>38187450</guid>
            <pubDate>Wed, 08 Nov 2023 06:44:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabiensanglard.net/bash/index.html">https://fabiensanglard.net/bash/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38187450">Hacker News</a></p>
<div id="readability-page-1" class="page"><br><center>
    
</center><p>
Nov 8, 2023</p>
<p>The bash book to rule them all</p><hr>


<p>
I <span>♥</span> to <code>/bin/bash</code> and last week I came around the one bash <a href="https://amzn.to/3u7kM8L">book</a> to rule them all.</p>

<img loading="lazy" src="https://fabiensanglard.net/bash/book.webp" width="2305" height="1658"><span><i><small>Efficient Linux at the Command Line by Daniel J. Barrett.</small></i></span>

<p>Why it is good</p><hr><p>"I learned a lot" does not help since you don't know where I started from anyway. So here is a curated list of questions you can ask yourself to decide if this book is for you.</p>

<p>You want to understand why <code>cd</code> is not an executable but a builtin?</p>

<p>You want a pretty book with a beautiful Saker falcon illustration on the cover?</p>

<p>You want to know why this redirect does not work?</p>
<pre><b>$</b> sudo echo "New log file" &gt; /var/log/custom.log
<span>bash: /var/log/custom.log: Permission denied</span></pre>

<p>You want to demystify the fallacy of "global variables" and understand what <code>export</code> means?</p>

<p>You want to understand how job control works, and how it is all a shell construct?</p>

<p>You want to know what this error message means and how to avoid it?</p>
<pre><b>$</b> rm *.txt
<span>-bash: /bin/rm: Argument list too long</span></pre>

<p>You want to learn tricks that will spare your fingers like using <code>|&amp;</code> instead of <code>2&gt;&amp;1 |</code>?</p>

<p>You want to be reminded of the treasure of tools available such as <code>wc</code>, <code>cat</code>, <code>head</code>, <code>cut</code>, <code>grep</code>, <code>sort</code>, <code>uniq</code>, <code>ssh</code>, <code>date</code>, <code>seq</code>, <code>yes</code>, <code>xargs</code>, <code>find</code>, <code>awk</code>,<code>tac</code>, <code>paste</code>, <code>diff</code>, <code>tr</code>, <code>rev</code>, <code>curl</code>, <code>wget</code>, <code>man</code>, <code>rsync</code>, <code>tee</code>, <code>less</code>, and <code>more</code>?</p>

<p>You want to finally understand the differences between <code>.bashrc</code> and <code>.bash_profile</code>?</p>

<p>You want to learn eleven (11!) ways to run a command?</p>

<p>You want to know the difference between using <code>"</code> and <code>'</code>?</p>

<p>You want to understand the differences between a child shell and a sub-shell?</p>

<p>Happy Reading!</p><hr><img loading="lazy" src="https://fabiensanglard.net/bash/marks.webp" width="2287" height="764"> <hr>
 <center>*</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop making every conversation about yourself (164 pts)]]></title>
            <link>https://thoguhts.substack.com/p/stop-making-every-conversation-about</link>
            <guid>38187430</guid>
            <pubDate>Wed, 08 Nov 2023 06:39:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoguhts.substack.com/p/stop-making-every-conversation-about">https://thoguhts.substack.com/p/stop-making-every-conversation-about</a>, See on <a href="https://news.ycombinator.com/item?id=38187430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:4000,&quot;width&quot;:6000,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;man in black jacket standing beside body of water during sunset&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="man in black jacket standing beside body of water during sunset" title="man in black jacket standing beside body of water during sunset" srcset="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption></figcaption></figure></div><p>I realized about a year ago, that I’d picked up a trait from my mother, wherein I would not be present in conversations. Instead, I’d be trying to find a way to agree/disagree with the person about a point, and then direct the conversation towards being about MY experience of said thing.</p><p>It’s been hard, like rewiring my brain, but I hope I’ve become more stoic and thoughtful. I was an obnoxious extrovert who had no privacy, shared everything online, and never thought before I spoke.</p><p>This post is actually just me talking about me, but I guess it’s good to share these things. </p><p>If you think you’re too ‘much’ sometimes, it could be because you are seeking approval from external things.&nbsp;</p><p>Whereas true happiness comes from finding the quiet calm, the ‘home’ within you. Once you find this place, you’ll see that your friend list is narrowed down. </p><p>You’ll seek only true friends who align with your values, and experiences that bring you purpose and fulfillment and you’ll find a calm quiet center within&nbsp;:)</p><p><strong>Something extra</strong><span>:</span></p><p>Well, it is important to share information with others, especially those who care about you. However, you should equally give importance to being mindful of how, when, and what you share. If someone shares something with you, Showing empathy or responding with a related story can be a great way to connect. </p><p>Anyhow, it can be offensive and create a negative impression if you overshare or try to one-up the other person’s story. </p><p>Thus, it’s important to strike a balance and be mindful of the impact your words may have on others.</p></div></div>]]></description>
        </item>
    </channel>
</rss>