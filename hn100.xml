<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 18 Dec 2024 13:30:14 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How We Centralized and Structured Error Handling in Golang (101 pts)]]></title>
            <link>https://olivernguyen.io/w/namespace.error/</link>
            <guid>42447762</guid>
            <pubDate>Wed, 18 Dec 2024 03:04:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olivernguyen.io/w/namespace.error/">https://olivernguyen.io/w/namespace.error/</a>, See on <a href="https://news.ycombinator.com/item?id=42447762">Hacker News</a></p>
Couldn't get https://olivernguyen.io/w/namespace.error/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ergo Chat – A modern IRC server written in Go (187 pts)]]></title>
            <link>https://github.com/ergochat/ergo</link>
            <guid>42447071</guid>
            <pubDate>Wed, 18 Dec 2024 00:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ergochat/ergo">https://github.com/ergochat/ergo</a>, See on <a href="https://news.ycombinator.com/item?id=42447071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ergochat/ergo/blob/master/docs/logo.png"><img src="https://github.com/ergochat/ergo/raw/master/docs/logo.png" alt="Ergo logo"></a></p>
<p dir="auto">Ergo (formerly known as Oragono) is a modern IRC server written in Go. Its core design principles are:</p>
<ul dir="auto">
<li>Being simple to set up and use</li>
<li>Combining the features of an ircd, a services framework, and a bouncer (integrated account management, history storage, and bouncer functionality)</li>
<li>Bleeding-edge <a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a>, suitable for use as an IRCv3 reference implementation</li>
<li>High customizability via a rehashable (i.e., reloadable at runtime) YAML config</li>
</ul>
<p dir="auto">Ergo is a fork of the <a href="https://github.com/jlatt/ergonomadic">Ergonomadic</a> IRC daemon &lt;3</p>
<hr>
<p dir="auto"><a href="https://goreportcard.com/report/github.com/ergochat/ergo" rel="nofollow"><img src="https://camo.githubusercontent.com/715dca1ef407679efd095c0f7e6bb84af1a4f3578777ba0e6fee876767360a3b/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6572676f636861742f6572676f" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/ergochat/ergo"></a>
<a href="https://github.com/ergochat/ergo/actions/workflows/build.yml"><img src="https://github.com/ergochat/ergo/actions/workflows/build.yml/badge.svg" alt="build"></a>
<a href="https://github.com/ergochat/ergo/releases/latest"><img src="https://camo.githubusercontent.com/a7f0ce32dfcb5a49fb515fc9f9c17fbf695f17c1f9453ae88ded4f7be1e45a32/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f6164732d6c617465737425323072656c656173652d677265656e2e737667" alt="Download Latest Release" data-canonical-src="https://img.shields.io/badge/downloads-latest%20release-green.svg"></a>
<a href="https://crowdin.com/project/ergochat" rel="nofollow"><img src="https://camo.githubusercontent.com/1b32d58517ce51950670a25e3273d77513044ac8c502648e76d0afe7e1b8b7d2/68747470733a2f2f64333232637174353834626f346f2e636c6f756466726f6e742e6e65742f6572676f636861742f6c6f63616c697a65642e737667" alt="Crowdin" data-canonical-src="https://d322cqt584bo4o.cloudfront.net/ergochat/localized.svg"></a></p>
<p dir="auto">If you want to take a look at a running Ergo instance or test some client code, feel free to play with <a href="https://testnet.ergo.chat/" rel="nofollow">testnet.ergo.chat</a> (TLS on port 6697 or plaintext on port 6667).</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>integrated services: NickServ for user accounts, ChanServ for channel registration, and HostServ for vanity hosts</li>
<li>bouncer-like features: storing and replaying history, allowing multiple clients to use the same nickname</li>
<li>native TLS/SSL support, including support for client certificates</li>
<li><a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a></li>
<li><a href="https://yaml.org/" rel="nofollow">yaml</a> configuration</li>
<li>updating server config and TLS certificates on-the-fly (rehashing)</li>
<li>SASL authentication</li>
<li><a href="https://github.com/ergochat/ergo-ldap">LDAP support</a></li>
<li>supports <a href="https://crowdin.com/project/ergochat" rel="nofollow">multiple languages</a> (you can also set a default language for your network)</li>
<li>optional support for UTF-8 nick and channel names with RFC 8265 (PRECIS)</li>
<li>advanced security and privacy features (support for requiring SASL for all logins, cloaking IPs, and running as a Tor hidden service)</li>
<li>an extensible privilege system for IRC operators</li>
<li>ident lookups for usernames</li>
<li>automated client connection limits</li>
<li>passwords stored with <a href="https://godoc.org/golang.org/x/crypto" rel="nofollow">bcrypt</a></li>
<li><code>UBAN</code>, a unified ban system that can target IPs, networks, masks, and registered accounts (<code>KLINE</code> and <code>DLINE</code> are also supported)</li>
<li>a focus on developing with <a href="https://ergo.chat/specs.html" rel="nofollow">specifications</a></li>
</ul>
<p dir="auto">For more detailed information on Ergo's functionality, see:</p>
<ul dir="auto">
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md">MANUAL.md, the operator manual</a></li>
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/USERGUIDE.md">USERGUIDE.md, the guide for end users</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start guide</h2><a id="user-content-quick-start-guide" aria-label="Permalink: Quick start guide" href="#quick-start-guide"></a></p>
<p dir="auto">Download the latest release from this page: <a href="https://github.com/ergochat/ergo/releases/latest">https://github.com/ergochat/ergo/releases/latest</a></p>
<p dir="auto">Extract it into a folder, then run the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cp default.yaml ircd.yaml
vim ircd.yaml  # modify the config file to your liking
./ergo mkcerts
./ergo run     # server should be ready to go!"><pre>cp default.yaml ircd.yaml
vim ircd.yaml  <span><span>#</span> modify the config file to your liking</span>
./ergo mkcerts
./ergo run     <span><span>#</span> server should be ready to go!</span></pre></div>
<p dir="auto"><strong>Note:</strong> See the <a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md#productionizing-with-systemd">productionizing guide in our manual</a> for recommendations on how to run a production network, including obtaining valid TLS certificates.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Platform Packages</h3><a id="user-content-platform-packages" aria-label="Permalink: Platform Packages" href="#platform-packages"></a></p>
<p dir="auto">Some platforms/distros also have Ergo packages maintained for them:</p>
<ul dir="auto">
<li>Arch Linux <a href="https://aur.archlinux.org/packages/ergochat/" rel="nofollow">AUR</a> - Maintained by <a href="https://github.com/vith">Jason Papakostas (@vith)</a>.</li>
<li><a href="https://packages.gentoo.org/packages/net-irc/ergo" rel="nofollow">Gentoo Linux</a> - Maintained by <a href="https://github.com/thesamesam">Sam James (@thesamesam)</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Docker</h3><a id="user-content-using-docker" aria-label="Permalink: Using Docker" href="#using-docker"></a></p>
<p dir="auto">A Dockerfile and example docker-compose recipe are available in the <code>distrib/docker</code> directory. Ergo is automatically published
to the GitHub Container Registry at <a href="https://ghcr.io/ergochat/ergo" rel="nofollow">ghcr.io/ergochat/ergo</a>. For more information, see the distrib/docker
<a href="https://github.com/ergochat/ergo/blob/master/distrib/docker/README.md">README file</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Source</h3><a id="user-content-from-source" aria-label="Permalink: From Source" href="#from-source"></a></p>
<p dir="auto">You can also clone this repository and build from source. Typical deployments should use the <code>stable</code> branch, which points to the latest stable release. In general, <code>stable</code> should coincide with the latest published tag that is not designated as a beta or release candidate (for example, <code>v2.7.0-rc1</code> was an unstable release candidate and <code>v2.7.0</code> was the corresponding stable release), so you can also identify the latest stable release tag on the <a href="https://github.com/ergochat/ergo/releases">releases page</a> and build that.</p>
<p dir="auto">The <code>master</code> branch is not recommended for production use since it may contain bugs, and because the forwards compatibility guarantees for the config file and the database that apply to releases do not apply to master. That is to say, running master may result in changes to your database that end up being incompatible with future versions of Ergo.</p>
<p dir="auto">For information on contributing to Ergo, see <a href="https://github.com/ergochat/ergo/blob/master/DEVELOPING.md">DEVELOPING.md</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Building</h4><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">You'll need an <a href="https://golang.org/dl/" rel="nofollow">up-to-date distribution of the Go language for your OS and architecture</a>. Once that's installed (check the output of <code>go version</code>), just check out your desired branch or tag and run <code>make</code>. This will produce an executable binary named <code>ergo</code> in the base directory of the project. (Ergo vendors all its dependencies, so you will not need to fetch any dependencies remotely.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">The default config file <a href="https://github.com/ergochat/ergo/blob/master/default.yaml"><code>default.yaml</code></a> helps walk you through what each option means and changes.</p>
<p dir="auto">You can use the <code>--conf</code> parameter when launching Ergo to control where it looks for the config file. For instance: <code>ergo run --conf /path/to/ircd.yaml</code>. The configuration file also stores where the log, database, certificate, and other files are opened. Normally, all these files use relative paths, but you can change them to be absolute (such as <code>/var/log/ircd.log</code>) when running Ergo as a service.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Logs</h3><a id="user-content-logs" aria-label="Permalink: Logs" href="#logs"></a></p>
<p dir="auto">By default, logs go to stderr only. They can be configured to go to a file, or you can use systemd to direct the stderr to the system journal (see the manual for details). The configuration format of logs is designed to be easily pluggable, and is inspired by the logging config provided by InspIRCd.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passwords</h3><a id="user-content-passwords" aria-label="Permalink: Passwords" href="#passwords"></a></p>
<p dir="auto">Passwords (for both <code>PASS</code> and oper logins) are stored using bcrypt. To generate encrypted strings for use in the config, use the <code>genpasswd</code> subcommand as such:</p>

<p dir="auto">With this, you receive a blob of text which you can plug into your configuration file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nickname and channel registration</h3><a id="user-content-nickname-and-channel-registration" aria-label="Permalink: Nickname and channel registration" href="#nickname-and-channel-registration"></a></p>
<p dir="auto">Ergo relies heavily on user accounts to enable its distinctive features (such as allowing multiple clients per nickname). As a user, you can register your current nickname as an account using <code>/msg NickServ register &lt;password&gt;</code>. Once you have done so, you should <a href="https://libera.chat/guides/sasl" rel="nofollow">enable SASL in your clients</a>, ensuring that you will be automatically logged into your account on each connection. This will prevent <a href="https://github.com/ergochat/ergo/blob/master/docs/MANUAL.md#nick-equals-account">problems claiming your registered nickname</a>.</p>
<p dir="auto">Once you have registered your nickname, you can use it to register channels:</p>
<ol dir="auto">
<li>Join the channel with <code>/join #channel</code></li>
<li>Register the channel with <code>/CS REGISTER #channel</code></li>
</ol>
<p dir="auto">After this, your channel will remember the fact that you're the owner, the topic, and any modes set on it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Jeremy Latt (2012-2014)</li>
<li>Edmund Huber (2014-2015)</li>
<li>Daniel Oaks (2016-present)</li>
<li>Shivaram Lingamneni (2017-present)</li>
<li><a href="https://github.com/ergochat/ergo/blob/master/CHANGELOG.md">Many other contributors and friends of the project &lt;3</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The XOR Texture (2004) (155 pts)]]></title>
            <link>https://lodev.org/cgtutor/xortexture.html</link>
            <guid>42447053</guid>
            <pubDate>Wed, 18 Dec 2024 00:43:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lodev.org/cgtutor/xortexture.html">https://lodev.org/cgtutor/xortexture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42447053">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Lode's Computer Graphics Tutorial</h2>

<h2>Table of Contents</h2>
<ul>
<li><a href="#Introduction_">Introduction</a></li>
<li><a href="#The_XOR_Texture">The XOR Texture</a></li>
<li><a href="#Colors">Colors</a></li>
<li><a href="#AND_and_OR">AND and OR</a></li>
<li><a href="#Conclusion">Conclusion</a><br></li>
</ul>
<a href="https://lodev.org/cgtutor/index.html">Back to index</a><br>
<h2><a name="Introduction_" id="Introduction_"></a>Introduction<br></h2>
The XOR texture is a very easy to generate texture that looks fine.
However, it's so overused that it's not a good choice to use in in
a demo or intro release. It isn't useful for games either, unless
you want some fancy floor tiles. What it's useful for, is for
testing a texture mapper you just wrote, in case you want to
quickly test out a pattern without having to load an image file or
write more complex texture generation code.<p>

This is an extremely small article, but the XOR Texture just
couldn't be left out in a series of texture generation
articles.</p><h2><a name="The_XOR_Texture" id="The_XOR_Texture"></a>The XOR
Texture</h2>
The XOR texture is simply generated by xor-ing the x and y
coordinate of the current pixel. The '^' operator in C++ is the XOR
operator.<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = x ^ y;
    pset(x, y, ColorRGB(c, c, c));
  }

  redraw();
  sleep();
  return 0;
}</span></pre>
</div>
</center>
<br>
That's it, if you run it, you see the XOR texture:<p>

<img alt="The XOR Texture" src="https://lodev.org/cgtutor/images/xortexture.gif"></p><p>

There are 3 things you should keep in mind though:</p><p>

<b>1)</b> The sizes of the texture should be a power of two, if
they aren't, the texture doesn't look as good:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturesize.gif"></p><p>

<b>2)</b> Color component values range from 0 to 255. The maximum
color value generated by the XOR operation is the same as the
dimensions of the texture if its size is a power of two. So if the
size of your XOR pattern is smaller than 256, for example only 64,
it'll be too dark (image on the left). Multiply the color with 4 to
make it bright again (image on the right):</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturedark.gif"> <img alt="" src="https://lodev.org/cgtutor/images/xortexturebright.gif"></p><p>

<b>3)</b> On the other hand, if the size is larger than 256, for
example 512, you have to make sure the color is limited to a
maximum value of 256. You can either modulo divide it through 256,
but then it isn't a real XOR pattern anymore. Better is to divide
it through 2. In any case, using a XOR texture larger than 256x256
doesn't increase the quality because there aren't enough distinct
color values, unless you're using a color mode that allows more
bits per channel. But who'd want to generate a 1024x1024 XOR
texture anyway.</p><p>

The XOR operator takes the binary values of both integers, and does
a binary XOR on every two corresponding bits. XOR or eXclusive OR
returns 1 if both bits are different, and returns 0 if both bits
are the same: "Bit a is 1 OR bit 2 is 1, but <i>not</i> both". In
other words, it applies the following truth table to every two
corresponding bits:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
This is done on every bit of the integer, creating the many
possible resulting values.<p>

For example, 5 XOR 13 = 8, because in binary 0101 XOR 1101 =
1000.</p><h2><a name="Colors" id="Colors"></a>Colors</h2>
You can also try the XOR texture with different colors, by using
different value for R, G and B. For example:<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color.r = 255 - c;
    color.g = c;
    color.b = c % 128;
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturecolor.gif"><p>

You can even use the xor value as hue for the HSVtoRGB
function...</p><center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color = HSVtoRGB(ColorHSV(c, 255, 255));
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturehsv.gif"><h2><a name="AND_and_OR" id="AND_and_OR"></a>AND and OR</h2>
The AND and the OR operator also generate a similar texture.<p>

The XOR operator returns 1 if both bits are different:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
The AND operator, only returns 1 if both bits are 1 (bit a AND bit
b are true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>AND</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The OR operator returns 1 if any or both of the bits are 1 (bit a
OR bit b is true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>OR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The AND operator is denoted '&amp;' in C++, and the OR operator
'|', replace the '^' operator with those to use the new operators.
Here's the result of XOR, AND and OR respectively:<p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexture.gif"> <img alt="" src="https://lodev.org/cgtutor/images/andtexture.gif">
<img alt="" src="https://lodev.org/cgtutor/images/ortexture.gif"></p><p>

It makes sense that the AND texture is darker, because it returns 1
only in a single case. The OR texture is brighter, because it
returns 1 very often. The sum of the XOR texture and the AND
texture is the OR texture.</p><h2><a name="Conclusion" id="Conclusion"></a>Conclusion</h2>
It was shown how easy it is to create a XOR texture, which makes
the XOR texture useful to test if a texture renderer is working.
However, it's not suitable for applications such as art or
games.<p>

Here, the XOR pattern was used as a 3D texture (x ^ y ^ z) to test
if a planet texture renderer was working correctly:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xorplanet.gif"></p><hr>
Last edited: 2004
<p>
Copyright (c) 2004-2007 by Lode Vandevenne. All rights reserved.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Design Token-Based UI Architecture (115 pts)]]></title>
            <link>https://martinfowler.com/articles/design-token-based-ui-architecture.html</link>
            <guid>42445834</guid>
            <pubDate>Tue, 17 Dec 2024 22:04:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martinfowler.com/articles/design-token-based-ui-architecture.html">https://martinfowler.com/articles/design-token-based-ui-architecture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Design tokens, or “tokens” are fundamental design decisions represented
    as data. They are the foundational building blocks of design systems.</p>

<p>Since the release of the <a href="https://second-editors-draft.tr.designtokens.org/format/">second editor’s
    draft</a> of the
    design token specification in 2022 and the <a href="https://www.w3.org/community/design-tokens/2022/06/14/call-to-implement-the-second-editors-draft-and-share-feedback/">call for tool
    makers</a>
    to start implementing and providing feedback, the landscape of design token
    tools has evolved rapidly. Tools like code generators, documentation
    systems, and UI design software are now better equipped to support design
    tokens, underscoring their growing importance in modern UI architecture.</p>

<p>In this article, I'll explain what design tokens are, when they are useful and how to apply
    them effectively. We'll focus on key architectural decisions that are often difficult to change later, including:</p>

<ol>
<li>How to organize design tokens in layers to balance scalability, maintainability and developer experience.</li>

<li>Whether all tokens should be made available to product teams or just a subset.</li>

<li>How to automate the distribution process of tokens across teams.</li>
</ol>

<section id="RoleOfDesignTokens">
<h2>Role of design tokens</h2>

<p>Around 2017, I was involved in a large project that used the <a href="https://martinfowler.com/articles/micro-frontends.html">Micro
      Frontend
      Architecture</a> to
      scale development teams. In this setup, different teams were responsible
      for different parts of the user interface, which could be even on the same
      page. Each team could deploy its micro-frontend independently.</p>

<p>There were various cases where components would be displayed on top of
      each other (such as dialogs or toasts appearing on top of content areas),
      which were not part of the same micro frontend. Teams used the CSS
      property <code>z-index</code> to control the stacking order, often relying on magic
      numbers—arbitrary values that weren’t documented or standardized. This approach
      did not scale as the project grew. It led to issues that took effort to
      fix, as cross-team collaboration was needed.</p>

<p>The issue was eventually addressed with design tokens and I think makes
      a good example to introduce the concept. The respective token file might
      have looked similar to this:</p>

<pre>{
  "z-index": {
    "$type": "number",
    "default": {
      "$value": 1
    },
    "sticky": {
      "$value": 100
    },
    "navigation": {
      "$value": 200
    },
    "spinner": {
      "$value": 300
    },
    "toast": {
      "$value": 400
    },
    "modal": {
      "$value": 500
    }
  }
}
</pre>

<p>The design tokens above represent the set of <code>z-index</code> values that can
      be used in the application and the name gives developers a good idea of
      where to use them. A token file like this can be integrated into the
      designers’ workflow and also be used to generate code, in a format that
      each team requires. For example, in this case, the token file might have
      been used to generate CSS or SCSS variables:</p>

<div>
<div>
<p>css
</p>

<pre>  :root {
    --z-index-default: 1;
    --z-index-sticky: 100;
    --z-index-navigation: 200;
    --z-index-spinner: 300;
    --z-index-toast: 400;
    --z-index-modal: 500;
  }</pre>
</div>

<div>
<p>scss
</p>

<pre>  
  $z-index-default: 1;
  $z-index-sticky: 100;
  $z-index-navigation: 200;
  $z-index-spinner: 300;
  $z-index-toast: 400;
  $z-index-modal: 500;</pre>
</div>
</div>

<section id="WhatAreDesignTokens">
<h3>What are design tokens?</h3>

<p>Salesforce <a href="https://www.smashingmagazine.com/2019/11/smashing-podcast-episode-3/">originally introduced design tokens</a> to streamline design
      updates to multiple
      platforms.</p>

<p>The Design Tokens Community Group <a href="https://second-editors-draft.tr.designtokens.org/format/#introduction">describes design tokens</a> as “a
      methodology for expressing design decisions in a platform-agnostic way so
      that they can be shared across different <b>disciplines</b>, <b>tools</b>, and
      <b>technologies</b></p>

<p>Let’s break this down:</p>

<ul>
<li><b>Cross-Disciplinary Collaboration:</b> Design tokens act as a common language
        that aligns designers, developers, product managers, and other disciplines. By
        offering a single source of truth for design decisions, they ensure that
        everyone involved in the product life cycle is on the same page, leading to more
        efficient workflows.</li>

<li><b>Tool integration:</b> Design tokens can be integrated into various design
        and development tools, including UI design software, token editors, translation
        tools (code generators), and documentation systems. This enables design updates
        to be quickly reflected in the code base and are synchronized across teams.</li>

<li><b>Technology adaptability:</b> Design tokens can be translated into different
        technologies like CSS, SASS, and JavaScript for the web, and even used on native
        platforms like Android and iOS. This flexibility enables design consistency
        across a variety of platforms and devices.</li>
</ul>
</section>
</section>

<section id="EstablishingASingleSourceOfTruth">
<h2>Establishing a single source of truth</h2>

<p>A key benefit of design tokens is their ability to serve as a single
      source of truth for both design and engineering teams. This ensures that
      multiple products or services maintain visual and functional
      consistency.</p>

<p>A <a href="https://tr.designtokens.org/format/#translation-tool">translation
      tool</a> takes one or
      more design token files as input and generates platform-specific code as
      output. Some translation tools can also produce documentation for the
      design tokens in the form of HTML. At the time of writing, popular
      translation tools include ﻿<a href="https://styledictionary.com/">Style
      Dictionary</a>,
      ﻿<a href="https://github.com/salesforce-ux/theo">Theo</a>, ﻿<a href="https://diez.org/">Diez</a>
      or ﻿<a href="https://specifyapp.com/">Specify App</a>.</p>




</section>

<section id="AutomatedDesignTokenDistribution">
<h2>Automated design token distribution</h2>

<p>In this section, we’ll explore how to automate the distribution of
      design tokens to product teams.</p>

<p>Let’s assume our goal is to provide teams with updated, tech-specific
      design tokens immediately after a designer makes a change. To achieve
      this, we can automate the translation and distribution process using a
      deployment pipeline for design tokens. Besides platform-specific code
      artifacts (like CSS for the web, XML for Android etc.), the pipeline might
      also deploy the documentation for the design tokens.</p>

<p>One crucial requirement is keeping design tokens under version control.
      Thankfully, plugins for popular design tools like Figma already integrate
      with Git providers like GitHub. It's considered best practice to use the
      Git repository as the single source of truth for design tokens—not the
      design tool itself. However, this requires the plugin to support syncing
      both ways between the repository and the design tool, which not all
      plugins do. As of now, Tokens Studio is a plugin that offers this
      bidirectional syncing. For detailed guidance on integrating Tokens Studio
      with different Git providers, please refer to their
      <a href="https://docs.tokens.studio/token-storage-and-sync/sync-provider-overview">documentation</a>.
      The tool enables you to configure a target branch and supports a
      trunk-based as well as a pull-request-based workflow.</p>

<p>Once the tokens are under version control, we can set up a deployment
      pipeline to build and deploy the artifacts needed by the product teams,
      which include platform-specific source code and documentation. The source
      code is typically packaged as a library and distributed via an artifact
      registry. This approach gives product teams control over the upgrade
      cycle. They can adopt updated styles by simply updating their
      dependencies. These updates may also be applied indirectly through updates of component
      libraries that use the token-based styles.</p>

<div id="token-distribution.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/token-distribution.svg"></p><p>Figure 2: Automated design token distribution</p>
</div>



<p>This overall setup has allowed teams at Thoughtworks to roll out
      smaller design changes across multiple front-ends and teams in a single
      day.</p>

<section id="FullyAutomatedPipeline">
<h3>Fully automated pipeline</h3>

<p>The most straightforward way to design the pipeline would be a
          fully automated trunk-based workflow. In this setup, all changes
          pushed to the main branch will be immediately deployed as long as they
          pass the automated quality gates.</p>

<p>Such a pipeline might consist of the following jobs:</p>

<ol>
<li><b>Check:</b> Validate the design token files using a design token validator
            or a JSON validator.</li>

<li><b>Build:</b> Use a translation tool like <a href="https://styledictionary.com/">Style
            Dictionary</a> to convert design token files into
            platform-specific formats. This job might also build the docs using the
            translation tool or by integrating a dedicated documentation tool.</li>

<li><b>Test:</b> This job is highly dependent on the testing strategy. Although
            some tests can be done using the design token file directly (like checking the
            color contrast), a common approach is to test the generated code using a
            documentation tool such as Storybook. Storybook has excellent <a href="https://storybook.js.org/docs/writing-tests">test
            support</a> for visual regression
            tests, accessibility tests, interaction tests, and other test types.</li>

<li><b>Publish:</b> Publish updated tokens to a package manager (for example,
            npm). The release process and versioning can be fully automated with a package
            publishing tool that is based on <a href="https://www.conventionalcommits.org/">Conventional
            Commits</a> like
            <a href="https://github.com/semantic-release/semantic-release">semantic-release</a>.
            semantic-release also allows the deployment of packages to multiple platforms.
            The publish job might also deploy documentation for the design tokens.</li>

<li><b>Notify:</b> Inform teams of the new token version via email or chat, so
            that they can update their dependencies.</li>
</ol>

<div id="pipeline-fully-automated.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-fully-automated.svg"></p><p>Figure 3: Fully automated deployment pipeline</p>
</div>


</section>

<section id="PipelineIncludingManualApproval">
<h3>Pipeline including manual approval</h3>

<p>Sometimes fully automated quality gates are not sufficient. If a
          manual review is required before publishing, a common approach is to
          deploy an updated version of the documentation with the latest design
          token to a preview environment (a temporary environment).</p>

<p>If a tool like Storybook is used, this preview might contain not
          only the design tokens but also show them integrated with the
          components used in the application.</p>

<p>An approval process can be implemented via a pull-request workflow.
          Or, it can be a manual approval / deployment step in the pipeline.</p>

<div id="pipeline-incl-review.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-incl-review.svg"></p><p>Figure 4: Deployment pipeline with manual approval</p>
</div>


</section>
</section>

<section id="OrganizingTokensInLayers">
<h2>Organizing tokens in layers</h2>

<p>As discussed earlier, design tokens represent design decisions as data.
      However, not all decisions operate at the same level of detail. Instead,
      ideally, general design decisions guide more specific ones. Organizing
      tokens (or design decisions) into layers allows designers to make
      decisions at the right level of abstraction, supporting consistency and
      scalability.</p>

<p>For instance, making individual color choices for every new component isn’t practical.
      Instead, it’s more efficient to define a foundational color palette and then
      decide how and where those colors are applied. This approach reduces the
      number of decisions while maintaining a consistent look and feel.</p>

<p>There are three key types of design decisions for which design tokens
      are used. They build on top of one another:</p>

<ul>
<li><b>What</b> design options are available to use?</li>

<li><b>How</b> are those styles applied across the user interface?</li>

<li><b>Where</b> exactly are those styles applied (in which components)?</li>
</ul>

<p>There are various names for these three types of tokens (as usual,
      naming is the hard part). In this article, we’ll use the terms <a href="https://samiamdesigns.substack.com/p/a-new-approach-to-naming-design-tokens">proposed
      by Samantha
      Gordashko</a>:
      option tokens, decision tokens and component tokens.</p>

<p>Let’s use our color example to illustrate how design tokens can
      answer the three questions above.</p>

<section id="OptionTokensDefiningWhatDesignOptionsAreProvided">
<h3>Option tokens: defining what design options are provided</h3>

<p><i>Option tokens</i> (also called <i>primitive tokens</i>, <i>base tokens</i>, <i>core
      tokens</i>, <i>foundation tokens</i> or <i>reference tokens</i>) define <b>what</b>
      styles can be used in the application. They define things like color
      palettes, spacing/sizing scales or font families. Not all of them are
      necessarily used in the application, but they present reasonable
      options.</p>

<p>Using our example, let’s assume we have a color palette with 9 shades for each color,
      ranging from very light to highly saturated. Below, we define the blue tones and grey tones as option-tokens:</p>

<pre>{
  "color": {
    "$type": "color",
    "options": {
      "blue-100": {"$value": "#e0f2ff"},
      "blue-200": {"$value": "#cae8ff"},
      "blue-300": {"$value": "#b5deff"},
      "blue-400": {"$value": "#96cefd"},
      "blue-500": {"$value": "#78bbfa"},
      "blue-600": {"$value": "#59a7f6"},
      "blue-700": {"$value": "#3892f3"},
      "blue-800": {"$value": "#147af3"},
      "blue-900": {"$value": "#0265dc"},
      "grey-100": {"$value": "#f8f8f8"},
      "grey-200": {"$value": "#e6e6e6"},
      "grey-300": {"$value": "#d5d5d5"},
      "grey-400": {"$value": "#b1b1b1"},
      "grey-500": {"$value": "#909090"},
      "grey-600": {"$value": "#6d6d6d"},
      "grey-700": {"$value": "#464646"},
      "grey-800": {"$value": "#222222"},
      "grey-900": {"$value": "#000000"},
      "white": {"$value": "#ffffff"}
    }
  }
}</pre>

<p>Although it’s highly useful to have reasonable options, option tokens fall short
      of being sufficient for guiding developers on how and where to apply them.</p>
</section>

<section id="DecisionTokensDefiningHowStylesAreApplied">
<h3>Decision tokens: defining how styles are applied</h3>

<p><i>Decision tokens</i> (also called <i>semantic tokens</i> or <i>system tokens</i>)
      specify <b>how</b> those style options should be applied contextually across
      the UI.</p>

<p>In the context of our color example, they might include decisions like the following:</p>

<ul>
<li>grey-100 is used as a surface color.</li>

<li>grey-200 is used for the background of disabled elements.</li>

<li>grey-400 is used for the text of disabled elements.</li>

<li>grey-900 is used as a default color for text.</li>

<li>blue-900 is used as an accent color.</li>

<li>white is used for text on accent color backgrounds.</li>
</ul>

<p>The corresponding decision token file would look like this:</p>

<pre>{
  "color": {
    "$type": "color",
    "decisions": {
      "surface": {
        "$value": "{color.options.grey-100}",
        "description": "Used as a surface color."
      },
      "background-disabled": {
        "$value": "{color.options.grey-200}",
        "description":"Used for the background of disabled elements."
      },
      "text-disabled": {
        "$value": "{color.options.grey-400}",
        "description": "Used for the text of disabled elements."
      },
      "text": {
        "$value": "{color.options.grey-900}",
        "description": "Used as default text color."
      },
      "accent": {
        "$value": "{color.options.blue-900}",
        "description": "Used as an accent color."
      },
      "text-on-accent": {
        "$value": "{color.options.white}",
        "description": "Used for text on accent color backgrounds."
      }
    }
  }
}</pre>

<p>As a developer, I would mostly be interested in the decisions, not the
      options. For example, color tokens typically contain a long list of options (a
      color palette), while very few of those options are actually used in
      the application. The tokens that are actually relevant when deciding which
      styles to apply, would be usually the decision tokens.</p>

<p>Decision tokens use
      <a href="https://tr.designtokens.org/format/#alias-reference">references</a> to the
      option tokens. I think of organizing tokens this way as a layered
      architecture. In other articles, I have often seen the term <i>tier</i> being
      used, but I think <i>layer</i> is the better word, as there is no physical
      separation implied. The diagram below visualizes the two layers we talked
      about so far:</p>

<div id="2-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/2-layer.svg"></p><p>Figure 5: 2-layer pattern</p>
</div>


</section>

<section id="ComponentTokensDefiningWhereStylesAreApplied">
<h3>Component tokens: defining where styles are applied</h3>

<p><i>Component tokens</i> (or <i>component-specific tokens</i>) map the <i>decision
      tokens</i> to specific parts of the UI. They show <b>where</b> styles are
      applied.</p>

<p>The term <i>component</i> in the context of design tokens does not always
      map to the technical term component. For example, a button might be
      implemented as a UI component in some applications, while other
      applications just use the <code>button</code> HTML element instead. <i>Component
      tokens</i> could be used in both cases.</p>

<p>Component tokens can be organised in a <a href="https://tr.designtokens.org/format/#group"><i>group</i></a> referencing multiple decision tokens. In our example, this references
      might include text- and background-colors for different variants of the button (primary, secondary) as well as disabled buttons.
      They might also include references to tokens of other types (spacing/sizing, borders etc.) which I'll omit in the
      following example:</p>

<pre>{
  "button": {
    "primary": {
      "background": {
        "$value": "{color.decisions.accent}"
      },
      "text": {
        "$value": "{color.decisions.text-on-accent}"
      }
    },
    "secondary": {
      "background": {
        "$value": "{color.decisions.surface}"
      },
      "text": {
        "$value": "{color.decisions.text}"
      }
    },
    "background-disabled": {
      "$value": "{color.decisions.background-disabled}"
    },
    "text-disabled": {
      "$value": "{color.decisions.text-disabled}"
    }
  }
}</pre>

<p>To some degree, component tokens are simply the result of applying
      decisions to specific components. However, as this
      example shows, this process isn’t always straightforward—especially for
      developers without design experience. While decision tokens can offer a
      general sense of which styles to use in a given context, component tokens
      provide additional clarity.</p>

<div id="3-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/3-layer.svg"></p><p>Figure 6: 3-layer pattern</p>
</div>



<p><b>Note:</b> there may be “snowflake” situations where layers are skipped.
      For example, it might not be possible to define a general decision for
      every single component token, or those decisions might not have been made
      yet (for example at the beginning of a project).</p>
</section>


</section>

<section id="TokenScope">
<h2>Token scope</h2>

<p>I already mentioned that while option tokens are very helpful to
    designers, they might not be relevant for application developers using the
    platform-specific code artifacts. Application developers will typically be
    more interested in the decision/component tokens.</p>

<p>Although token scope is not yet included in the design token
    spec, some design
    systems already separate tokens into private (also called <i>internal</i>) and
    public (also called <i>global</i>) tokens. For example, the Salesforce Lightning
    Design System introduced <a href="https://www.lightningdesignsystem.com/design-tokens/">a flag for each
    token</a>. There are
    various reasons why this can be a good idea:</p>

<ul>
<li>it guides developers on which tokens to use</li>

<li>fewer options provide a better developer experience</li>

<li>it reduces the file size as not all tokens need to be included</li>

<li>private/internal tokens can be changed or removed without breaking
      changes</li>
</ul>

<p>A downside of making option tokens private is that developers would rely
    on designers to always make those styles available as decision or component
    tokens. This could become an issue in case of limited availability of the
    designers or if not all decisions are available, for example at the start of
    a project.</p>

<p>Unfortunately, there is no standardized solution yet for implementing
    scope for design tokens. So the approach depends on the tool-chain of the
    project and will most likely need some custom code.</p>

<section id="File-basedScope">
<h3>File-based scope</h3>

<p>Using Style Dictionary, we can use a
      <a href="https://styledictionary.com/reference/hooks/filters/"><i>filter</i></a> to
      expose only public tokens. The most straightforward approach would be to
      filter on the file ending. If we use different file endings for component,
      decision and option tokens, we can use a filter on the file path, for
      example, to make the option tokens layer private.</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": token =&gt; !token.filePath.endsWith('options.json'),</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>The resulting CSS variables would contain
      only these decision tokens, and not the option tokens.</p>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>
</section>

<section id="AMoreFlexibleApproach">
<h3>A more flexible approach</h3>

<p>If more flexibility is needed, it might be preferable to add a scope
      flag to each token and to filter based on this flag:</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": {
              "public": true
            },</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>If we then add the flag to the decision tokens, the resulting CSS would
      be the same as above:</p>

<p>Tokens with scope flag
</p>

<pre>  {
    "color": {
      "$type": "color",
      "decisions": {
        "surface": {
          "$value": "{color.options.grey-100}",
          "description": "Used as a surface color.",
<span>          "public": true</span>
        },
        "background-disabled": {
          "$value": "{color.options.grey-200}",
          "description":"Used for the background of disabled elements.",
<span>          "public": true</span>
        },
        "text-disabled": {
          "$value": "{color.options.grey-400}",
          "description": "Used for the text of disabled elements.",
<span>          "public": true</span>
        },
        "text": {
          "$value": "{color.options.grey-900}",
          "description": "Used as default text color.",
<span>          "public": true</span>
        },
        "accent": {
          "$value": "{color.options.blue-900}",
          "description": "Used as an accent color.",
<span>          "public": true</span>
        },
        "text-on-accent": {
          "$value": "{color.options.white}",
          "description": "Used for text on accent color backgrounds.",
<span>          "public": true</span>
        }
      }
    }
  }</pre>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>

<p>Such flags can now also be set <a href="https://help.figma.com/hc/en-us/articles/360039238193-Hide-styles-components-and-variables-when-publishing#h_01HD20M7HS9044NHB2YBJNE9C2">through the Figma
      UI</a>
      (if using Figma variables as a source of truth for design tokens). It is
      available as
      <a href="https://www.figma.com/plugin-docs/api/properties/Variable-hiddenfrompublishing/"><code>hiddenFromPublishing</code></a>
      flag via the Plugins API.</p>
</section>
</section>

<section id="ShouldIUseDesignTokens">
<h2>Should I use design tokens?</h2>

<p>Design tokens offer significant benefits for modern UI architecture,
      but they may not be the right fit for every project.</p>

<div>
<div>
<p><b>Benefits</b> include:</p>

<ul>
<li>Improved lead time for design changes</li>

<li>Consistent design language and UI architecture across platforms and
            technologies</li>

<li>Design tokens being relatively lightweight from an implementation point of
            view</li>
</ul>
</div>

<div>
<p><b>Drawbacks</b> include:</p>

<ul>
<li>Initial effort for automation</li>

<li>Designers might have to (to some degree) interact with Git</li>

<li>Standardization is still in progress</li>
</ul>
</div>
</div>

<p>Consider the following when deciding whether to adopt design
      tokens:</p>

<section id="WhenToUseDesignTokens">
<h3>When to use design tokens</h3>

<ol>
<li><b>Multi-Platform or Multi-Application Environments:</b> When working across
          multiple platforms (web, iOS, Android…) or maintaining several applications or
          frontends, design tokens ensure a consistent design language across all of
          them.</li>

<li><b>Frequent Design Changes</b>: For environments with regular design
          updates, design tokens provide a structured way to manage and propagate changes
          efficiently.</li>

<li><b>Large Teams</b>: For teams with many designers and developers, design
          tokens facilitate collaboration.</li>

<li><b>Automated Workflows</b>: If you’re familiar with CI/CD pipelines, the
          effort to add a design token pipeline is relatively low. There are also
          commercial offerings.</li>
</ol>
</section>

<section id="WhenDesignTokensMightNotBeNecessary">
<h3>When design tokens might not be necessary</h3>

<ol>
<li><b>Small projects:</b> For smaller projects with limited scope and minimal
          design complexity, the overhead of managing design tokens might not be worth the
          effort.</li>

<li><b>No issue with design changes:</b> If the speed of design changes,
          consistency and collaboration between design and engineering are not an issue,
          then you might also not need design tokens.</li>
</ol>
</section>
</section>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Includeable minimal operating system for C++ (149 pts)]]></title>
            <link>https://www.includeos.org/</link>
            <guid>42445508</guid>
            <pubDate>Tue, 17 Dec 2024 21:29:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.includeos.org/">https://www.includeos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42445508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content"><p>IncludeOS allows you to run your application in the cloud without an operating system. IncludeOS adds operating system functionality to your application allowing you to create performant, secure and resource efficient virtual machines.</p>

<p>IncludeOS applications boot in tens of milliseconds and require only a few megabytes of disk and memory.</p>

<p><a href="https://github.com/includeos/IncludeOS">[View on Github]</a>
<a href="https://join.slack.com/t/includeos/shared_invite/zt-5z7ts29z-_AX0kZNiUNE7eIMUP60GmQ">[Chat on Slack]</a>
<a href="https://www.includeos.org/technology.html">[Tell me more]</a></p>

<p>To run a service with IncludeOS on Linux or macOS you do not need to install IncludeOS, however you need to install a few dependencies depending on the service you will run. You can start by trying out our simplest hello_world service. For this service you will need the following dependencies.</p>

<ul>
  <li>Conan package manager</li>
  <li>cmake, make, nasm</li>
  <li>clang, or alternatively gcc on linux. Prebuilt packages are available for clang 6.0 and gcc 7.3</li>
  <li>qemu</li>
  <li>python3 packages: psutil, jsonschema</li>
</ul>

<p>With the above dependencies you should be able to build an application within minutes.</p>
<p><a target="_blank" href="https://buffett.online/">buffett.online</a><a target="_blank" href="https://songdonkey.ai/">songdonkey.ai</a></p>
<div><pre><code><span>$ </span>conan config <span>install </span>https://github.com/includeos/conan_config.git
<span>$ </span>git clone https://github.com/includeos/hello_world.git
<span>$ </span><span>mkdir </span>build_hello_world
<span>$ </span><span>cd </span>build_hello_world
<span>$ </span>conan <span>install</span> ../hello_world <span>-pr</span> 
<span>$ </span><span>source</span> ./activate.sh
<span>$ </span>cmake ../hello_world
<span>$ </span>cmake <span>--build</span> <span>.</span>
<span>$ </span>boot hello
</code></pre></div>

<p>The hello world booted service should look like this:</p>

<div><pre><code>================================================================================
 IncludeOS 0.14.1-1093 (x86_64 / 64-bit)
 +--&gt; Running [ Hello world - OS included ]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hello world
    [ main ] returned with status 0
</code></pre></div>

<p>For detailed instructions see the <a href="https://github.com/includeos/IncludeOS/blob/master/README.md">GitHub README</a>. Once installed we suggest looking at and booting a few of the demo-examples to familarize yourself with the system.</p>

<p>We strive to make it easy to create fast and useful services. The below code will set up a simple TCP echo service and happily talk to anyone connecting.</p>

<div><pre><code><span>#include &lt;os&gt;
#include &lt;iostream&gt;
#include &lt;net/interfaces&gt;
</span>
<span>void</span> <span>Service</span><span>::</span><span>start</span><span>()</span>
<span>{</span>
  <span>// Get the IP stack thats already been automatically configured</span>
  <span>auto</span><span>&amp;</span> <span>inet</span> <span>=</span> <span>net</span><span>::</span><span>Interfaces</span><span>::</span><span>get</span><span>(</span><span>0</span><span>);</span>
  <span>// Setup a TCP echo server on port 7 (echo port)</span>
  <span>auto</span><span>&amp;</span> <span>server</span> <span>=</span> <span>inet</span><span>.</span><span>tcp</span><span>().</span><span>listen</span><span>(</span><span>7</span><span>);</span>

  <span>server</span><span>.</span><span>on_connect</span><span>([]</span> <span>(</span><span>auto</span> <span>conn</span><span>)</span> <span>{</span>
    <span>// Log incomming connections on the console:</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Connection "</span> <span>&lt;&lt;</span> <span>conn</span><span>-&gt;</span><span>to_string</span><span>()</span> <span>&lt;&lt;</span> <span>" established</span><span>\n</span><span>"</span><span>;</span>
    <span>// When data is received, echo back</span>
    <span>conn</span><span>-&gt;</span><span>on_read</span><span>(</span><span>1024</span><span>,</span> <span>[</span><span>conn</span><span>]</span> <span>(</span><span>auto</span> <span>buf</span><span>)</span> <span>{</span>
      <span>conn</span><span>-&gt;</span><span>write</span><span>(</span><span>buf</span><span>);</span>
    <span>});</span>
  <span>});</span>
<span>}</span>
</code></pre></div>

<p>The network configuration of the virtual machine can reside in a JSON file, named config.json, placed in the same folder. It should look something like this, depending on your need:</p>
<div><pre><code><span>{</span><span>
  </span><span>"net"</span><span> </span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"iface"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
      </span><span>"config"</span><span>:</span><span> </span><span>"dhcp-with-fallback"</span><span>,</span><span>
      </span><span>"address"</span><span>:</span><span> </span><span>"10.0.0.42"</span><span>,</span><span>
      </span><span>"netmask"</span><span>:</span><span> </span><span>"255.255.255.0"</span><span>,</span><span>
      </span><span>"gateway"</span><span>:</span><span> </span><span>"10.0.0.1"</span><span>
    </span><span>}</span><span>
  </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div>

<h2 id="security">Security</h2>

<p>For security related inquires please send email to security@includeos.org. You can use our <a href="https://pgp.mit.edu/pks/lookup?search=security@includeos.org&amp;op=index">PGP key</a> to encrypt the email.</p>

<p>This project is maintained by Alfred Bratterud.</p>

<h2>Recommendations</h2>

<p>4K Download regularly updates their app named <a href="https://www.4kdownload.com/products/youtubetomp3/6">YouTube to MP3</a>. We strongly recommend it if you need to download audio from YouTube.</p>


 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FastVideo: a lightweight framework for accelerating large video diffusion models (101 pts)]]></title>
            <link>https://github.com/hao-ai-lab/FastVideo</link>
            <guid>42445239</guid>
            <pubDate>Tue, 17 Dec 2024 20:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hao-ai-lab/FastVideo">https://github.com/hao-ai-lab/FastVideo</a>, See on <a href="https://news.ycombinator.com/item?id=42445239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/hao-ai-lab/FastVideo/blob/main/assets/logo.jpg"><img src="https://github.com/hao-ai-lab/FastVideo/raw/main/assets/logo.jpg" width="30%"></a>
</p>
<p dir="auto">FastVideo is a lightweight framework for accelerating large video diffusion models.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastMochi-Demo.mp4">FastMochi-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">
    🤗 <a href="https://huggingface.co/FastVideo/FastMochi-diffusers" rel="nofollow">FastMochi</a> | 🤗 <a href="https://huggingface.co/FastVideo/FastHunyuan" rel="nofollow">FastHunyuan</a>  | 🔍 <a href="https://discord.gg/REBzDQTWWt" rel="nofollow"> Discord </a>
</p> 
<p dir="auto">FastVideo currently offers: (with more to come)</p>
<ul dir="auto">
<li>FastHunyuan and FastMochi: consistency distilled video diffusion models for 8x inference speedup.</li>
<li>First open distillation recipes for video DiT, based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>.</li>
<li>Support distilling/finetuning/inferencing state-of-the-art open video DiTs: 1. Mochi 2. Hunyuan.</li>
<li>Scalable training with FSDP, sequence parallelism, and selective activation checkpointing, with near linear scaling to 64 GPUs.</li>
<li>Memory efficient finetuning with LoRA, precomputed latent, and precomputed text embeddings.</li>
</ul>
<p dir="auto">Dev in progress and highly experimental.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎥 More Demos</h2><a id="user-content--more-demos" aria-label="Permalink: 🎥 More Demos" href="#-more-demos"></a></p>
<p dir="auto">Fast-Hunyuan comparison with original Hunyuan, achieving an 8X diffusion speed boost with the FastVideo framework.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastHunyuan-Demo.mp4">FastHunyuan-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Comparison between OpenAI Sora, original Hunyuan and FastHunyuan</p>
<details open="">
  <summary>
    
    <span aria-label="Video description sora-verse-fasthunyuan.mp4.mp4">sora-verse-fasthunyuan.mp4.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Change Log</h2><a id="user-content-change-log" aria-label="Permalink: Change Log" href="#change-log"></a></p>
<ul dir="auto">
<li><code>2024/12/17</code>: <code>FastVideo</code> v0.1 is released.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🔧 Installation" href="#-installation"></a></p>
<p dir="auto">The code is tested on Python 3.10.0, CUDA 12.1 and H100.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Inference</h2><a id="user-content--inference" aria-label="Permalink: 🚀 Inference" href="#-inference"></a></p>
<p dir="auto">We recommend using a GPU with 80GB of memory. To run the inference, use the following command:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastHunyuan</h3><a id="user-content-fasthunyuan" aria-label="Permalink: FastHunyuan" href="#fasthunyuan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
# CLI inference
sh scripts/inference/inference_hunyuan.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
<span><span>#</span> CLI inference</span>
sh scripts/inference/inference_hunyuan.sh</pre></div>
<p dir="auto">You can also inference FastHunyuan in the <a href="https://github.com/Tencent/HunyuanVideo">official Hunyuan github</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastMochi</h3><a id="user-content-fastmochi" aria-label="Permalink: FastMochi" href="#fastmochi"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
# CLI inference
bash scripts/inference/inference_mochi_sp.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
<span><span>#</span> CLI inference</span>
bash scripts/inference/inference_mochi_sp.sh</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Distill</h2><a id="user-content--distill" aria-label="Permalink: 🎯 Distill" href="#-distill"></a></p>
<p dir="auto">Our distillation recipe is based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">Phased Consistency Model</a>. We did not find significant improvement using multi-phase distillation, so we keep the one phase setup similar to the original latent consistency model's recipe.
We use the <a href="https://huggingface.co/datasets/LanguageBind/Open-Sora-Plan-v1.1.0/tree/main/all_mixkit" rel="nofollow">MixKit</a> dataset for distillation. To avoid running the text encoder and VAE during training, we preprocess all data to generate text embeddings and VAE latents.
Preprocessing instructions can be found <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide preprocessed data that can be downloaded directly using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset</pre></div>
<p dir="auto">Next, download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">To launch the distillation process, use the following commands:</p>
<div data-snippet-clipboard-copy-content="bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan"><pre><code>bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan
</code></pre></div>
<p dir="auto">We also provide an optional script for distillation with adversarial loss, located at <code>fastvideo/distill_adv.py</code>. Although we tried adversarial loss, we did not observe significant improvements.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Finetune</h2><a id="user-content-finetune" aria-label="Permalink: Finetune" href="#finetune"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Full Finetune</h3><a id="user-content--full-finetune" aria-label="Permalink: ⚡ Full Finetune" href="#-full-finetune"></a></p>
<p dir="auto">Ensure your data is prepared and preprocessed in the format specified in <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide a mochi preprocessed Black Myth Wukong data that can be downloaded directly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset</pre></div>
<p dir="auto">Download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">Then you can run the finetune with:</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi.sh # for mochi"><pre><code>bash scripts/finetune/finetune_mochi.sh # for mochi
</code></pre></div>
<p dir="auto"><strong>Note that for finetuning, we did not tune the hyperparameters in the provided script</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Lora Finetune</h3><a id="user-content--lora-finetune" aria-label="Permalink: ⚡ Lora Finetune" href="#-lora-finetune"></a></p>
<p dir="auto">Currently, we only provide Lora Finetune for Mochi model, the command for Lora Finetune is</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi_lora.sh"><pre><code>bash scripts/finetune/finetune_mochi_lora.sh
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Minimum Hardware Requirement</h3><a id="user-content-minimum-hardware-requirement" aria-label="Permalink: Minimum Hardware Requirement" href="#minimum-hardware-requirement"></a></p>
<ul dir="auto">
<li>40 GB GPU memory each for 2 GPUs with lora</li>
<li>30 GB GPU memory each for 2 GPUs with CPU offload and lora.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Finetune with Both Image and Video</h3><a id="user-content-finetune-with-both-image-and-video" aria-label="Permalink: Finetune with Both Image and Video" href="#finetune-with-both-image-and-video"></a></p>
<p dir="auto">Our codebase support finetuning with both image and video.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh"><pre>bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh</pre></div>
<p dir="auto">For Image-Video Mixture Fine-tuning, make sure to enable the --group_frame option in your script.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📑 Development Plan</h2><a id="user-content--development-plan" aria-label="Permalink: 📑 Development Plan" href="#-development-plan"></a></p>
<ul dir="auto">
<li>More distillation methods
<ul>
<li> Add Distribution Matching Distillation</li>
</ul>
</li>
<li>More models support
<ul>
<li> Add CogvideoX model</li>
</ul>
</li>
<li>Code update
<ul>
<li> fp8 support</li>
<li> faster load model and save model support</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">We learned and reused code from the following projects: <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>, <a href="https://github.com/huggingface/diffusers">diffusers</a>, <a href="https://github.com/PKU-YuanGroup/Open-Sora-Plan">OpenSoraPlan</a>, and <a href="https://github.com/xdit-project/xDiT">xDiT</a>.</p>
<p dir="auto">We thank MBZUAI and Anyscale for their support throughout this project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC bans hidden junk fees in hotel, event ticket prices (391 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</link>
            <guid>42445037</guid>
            <pubDate>Tue, 17 Dec 2024 20:36:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html">https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107257869" data-test="InlineImage"><p>U.S. President Joe Biden delivers remarks on protecting consumers from hidden junk fees during an event at the South Court Auditorium at Eisenhower Executive Office Building on June 15, 2023 in Washington, DC.</p><p>Alex Wong | Getty Images</p></div><div><p>The U.S. Federal Trade Commission passed a rule on Tuesday requiring ticket sellers, hotels and vacation rental sites to disclose total prices, including fees upfront, prohibiting them from concealing add-on charges until the last minute.</p><p>The rule is one of the final pieces of President Joe Biden's wide-ranging crackdown on junk fees that drive up consumer costs without providing visible benefits.</p><p>"We all know the experience of encountering a hidden fee at the very last stage of checkout — these junk fees sneak onto your bill and companies end up making you pay more because they can. Those fees add up, taking real money out of the pockets of Americans," Biden said in a statement.</p><p>President-elect Donald Trump could seek to withdraw the rule for further review, and Republicans who will have control of Congress could seek to vacate it by law.</p><p>The rule would require service fees, resort fees, and other charges commonly added to bookings to be included in advertised prices. The rule is narrower than what the FTC proposed in 2023 that would have broadly banned hidden and deceptive fees regardless of industry.</p><p>"I urge enforcers to continue cracking down on these unlawful fees and encourage state and federal policymakers to build on this success with legislation that bans unfair and deceptive junk fees across the economy," FTC Chair Lina Khan said in a statement.</p><p>The FTC estimates the rule would save U.S. consumers 53 million hours per year they would not have to spend sleuthing out total costs before making purchases.</p><p>Biden's regulators have taken aim at inflated and hidden fees, though their efforts have met with lawsuits by businesses and corporate interest groups.</p><p>A judge in Texas blocked a rule that would cap credit card late fees, and an appeals court in New Orleans blocked a requirement that airlines disclose baggage and other fees upfront. The cases are ongoing.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A pilot crashed a full passenger jet into the bay, didn't lose his job (2021) (105 pts)]]></title>
            <link>https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</link>
            <guid>42443987</guid>
            <pubDate>Tue, 17 Dec 2024 18:40:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php">https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</a>, See on <a href="https://news.ycombinator.com/item?id=42443987">Hacker News</a></p>
Couldn't get https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Inside the War Against Headlight Brightness (157 pts)]]></title>
            <link>https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents</link>
            <guid>42443406</guid>
            <pubDate>Tue, 17 Dec 2024 17:43:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents">https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents</a>, See on <a href="https://news.ycombinator.com/item?id=42443406">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure data-sentry-component="ArticleHero" data-sentry-source-file="article-hero.tsx"><figcaption><span>Getty Images/Ringer illustration</span></figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The sun had already set in Newfoundland, Canada, and Paul Gatto was working late to give me a presentation on headlights. This, it should be said, is not his job. Not even close, really. Gatto, 28, is a front-end developer by day, working for a weather application that’s used by the majority of Canadian meteorologists, he told me on a video call, occasionally hitting his e-cig or sipping on a Miller Lite. As to how he ended up as one of the primary forces in the movement to make car headlights less bright—a movement that’s become surprisingly robust in recent years—even Gatto can’t really explain.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It is fucking weird,” he said. “I need something else to do with my spare time. This takes a lot of it.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto is the founder of the subreddit <a href="http://reddit.com/r/fuckyourheadlights/">r/FuckYourHeadlights</a>, the internet’s central hub for those at their wits’ end with the current state of headlights. The posts consist of a mishmash of venting, meme-ing, and community organizing. A common entry is a photo taken from inside the car of someone being blasted with headlights as bright as an atomic bomb, and a caption along the lines of <a href="http://reddit.com/r/fuckyourheadlights/comments/10s3rmy/how_is_this_fucking_legal/">“How is this fucking legal?!”</a> Or users will joke about going back in time and <a href="http://reddit.com/r/fuckyourheadlights/comments/1d4nthv/whats_the_poblem_with_their_headlights/">Skynet-style</a> killing the Audi lighting engineer who first rolled out LED headlights. Or they’ll discuss ways to write to their congresspeople, like Mike Thompson, House Democrat of California, who <a href="http://reddit.com/r/fuckyourheadlights/comments/1axtnfy/congress_gets_involved/">recently expressed support</a> for the cause.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">At its worst, the forum resembles Grampa Simpson writing a letter to the president to say that there are <a href="https://www.youtube.com/watch?v=O5dmxBUbzBU">too many states</a>. (“I am <em>not</em> a crackpot,” Grampa adds.) But at its best, it feels like a balm for those of us who have been pushed to optical-induced madness on the roads. For those who feel like, as headlights get brighter, it’s actually becoming harder to see.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">After I <a href="https://x.com/Nate_Rgrs/status/1662241673043116036">posted</a> about the subreddit on X last year, Gatto emailed me, and it wasn’t long before we were on a video call and he was giving a PowerPoint presentation he’d made the night before. It was titled “The Internet-Focused History of FuckYourHeadlights, or: How I Learned to Stop Worrying About Headlights and Start Worrying About Society Itself.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“First, I’d like to teach you some words,” Gatto said, priming me for a conversation about the minutiae of government policy and auto engineering. There was “obfuscation” (the intentional act of making something hard to understand), “mutual recursion” (when two things are defined in terms of each other, creating a loop), and “Ouroboros” (the snake eating its tail). Around this point, Victor Morgan, who was also on the call, cut in. “Paul,” he said, “where are you going with this, bud?”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Morgan does this kind of thing from time to time. The two are partners—moderating the subreddit together and working in tandem to research headlight arcana—but it’s a good cop–bad cop dynamic. Neatly dressed and carefully spoken, Morgan, 41, is a mechanical engineer and lives far from Gatto, in Greenville, South Carolina. One of the first times the two spoke, it was because Morgan wanted to tell Gatto he didn’t like the subreddit’s name. They’ve since become good friends.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto is the one focused on the bigger picture: digging up publicly available information, refining the messaging of their cause, optimizing the subreddit for search engines (he’s <a href="https://x.com/BarneyRetina/status/1836228891175784570">proud</a> of how high up the subreddit appears if you google “bright headlights”). Morgan is the one who sees their ideas through with measurements and engineering: He’s created a device for your rear windshield that pops up a reflective surface when someone’s lights are glaring at you from behind (<a href="https://www.owmyeyes.com/products/owmyeyes-light-the-road-not-my-face">$70, homemade</a>, questionably legal), and he’s gone to car dealerships to measure the brightness of different headlights. (According to Morgan’s numbers, Teslas and Hondas are among the brightest.)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">If you want Rust Cohle–worthy lines about how it’s all connected, you go to Gatto. (“The automakers and the insurers can all be classified as the same financial entity back at this point,” he told me. “They will doctor what they need to, as far as I can see.”) If you want an engineer-worthy dose of hard-nosed practicality, you go to Morgan. (He has a cat whom he just calls “Cat.”) They’re an unlikely pair, but they are <em>not</em> crackpots.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Headlight brightness might almost seem like too random a subject for anyone to be as invested in as they are. But as it turns out, that’s kind of the point. “There’s a lot of issues that I care about,” Morgan said. “This is one that I think is niche enough that I can have an influence on.” Gatto’s motivation comes from the experience of watching his partner, Liz, struggle to recover from being hit by a cab while walking across the street. He sees headlights as “a realistic and tangible attack surface on the current trend toward antihuman design in our world, primarily guided by the auto industry.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">But deep down, what motivates them is the same twitch in the eye that brought me to the subreddit in the first place. “I’m not a very rageful person,” Gatto said, “but for some reason, these lights brought it out of me. And I kind of realized that’s why I had to do something about it. Because no one’s going to come help us.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">There appear to be two types of drivers in North America these days: those who think about headlights only when one of theirs goes out, and those who fixate on them every time they drive at night. If you’re in the first camp, consider yourself lucky. Those in the second camp—aggravated by the excess glare produced in this new era of light-emitting diode headlights—are riled up enough that the National Highway Traffic Safety Administration receives more consumer complaints about headlights than any other topic, several insiders told me.&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><br>According to numbers we pulled from the Insurance Institute for Highway Safety’s publicly available data,&nbsp;headlight brightness has roughly doubled since 2015.</figcaption></figure></figure><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><br>And at the same time, the number of demerits issued for lack of brightness have dropped precipitously. In other words: It’s not just your imagination. Headlights are brighter.</figcaption></figure></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">It’s not just in the aggrieved drivers’ imaginations. Going by the publicly available data of the&nbsp;Insurance Institute for Highway Safety, headlight brightness has roughly doubled in the past 10 years—although you probably don’t need convincing if you’ve been paying attention over that span. Something <em>happened </em>out there, and a zap of light causing you to grimace behind the wheel suddenly went from a rarity to a routine occurrence.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">As opposed to the sepia-toned halogen lights we had mostly been using for generations of vehicles, LED lights—which are now used for the vast majority of new cars—come out blazing white or blue, like an omnipresent police flashlight shining at you during a traffic stop. And in what can be seen as a flawed attempt to match LED capabilities on other vehicles, it’s also become not uncommon, anecdotally speaking, for people to have their high beams on even on crowded highways and streets—something that’s technically illegal because it’s deemed to be a danger to other drivers. The strange thing is, though, I can’t say I notice much of a difference between one car’s high beams and another’s low beams anymore.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">John D. Bullough, a program director at the Mount Sinai Light and Health Research Center, has been studying light and its ramifications on health for the past 30 years, and he’ll tell you that the difference between older light sources and LEDs is night and day. “The first 20 years or so, [lighting] technology was very stable,” he told me over the phone. “In other words, you had incandescent light bulbs at home, and you had fluorescent lights in your office and sodium lights on the streets, and nothing really changed very much. And then, suddenly, the last 10 years of that 30 years have been a whirlwind because of LEDs. I mean, they’ve changed everything. Everything is LED. There essentially aren’t light bulbs anymore.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">LEDs offer benefits over older light sources, which is why they’ve been fast-tracked into near-universal use <a href="https://www.vox.com/science/2023/8/12/23827110/light-bulb-incandescent-led-energy-efficiency-ban-explained">via government-mandated performance standards</a>. They last longer and require less energy, making them more environmentally friendly, and are more customizable, making them suited for endless purposes. But LEDs are fundamentally different from what came before them—the light can be carefully aimed as opposed to emitted in all directions—and they’re vastly more powerful. And as they were rolled out en masse at a rapid pace, any <a href="https://nymag.com/strategist/article/led-light-bulbs-investigation.html">potential repercussions</a> would have to be discovered on the fly.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“We’re all like human experiments,” said Mark Baker, when I called him to talk about his nonprofit, the Soft Lights Foundation, the mission of which is to advocate “for the protection of people and the environment from the harms of visible light radiation emitted by products that use light-emitting diodes.” Baker’s concern is with the broader integration of LEDs in society, but he shows up regularly in the headlight world, having recently organized a <a href="https://www.softlights.org/wp-content/uploads/2024/03/NHTSA-Petition-to-Limit-Headlight-Intensity.pdf">petition</a> that gathered nearly 60,000 signatures demanding that NHTSA limit headlight intensity. Unlike Morgan and Gatto, however, this isn’t a nights and weekends gig for him.&nbsp;&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Baker was working as a middle school math teacher in Northern California and thought of himself “as a regular person” before the mass implementation of LEDs. Then the world shifted while he was in traffic one day around 2016. He remembers looking at a Cadillac that had daytime-running LEDs—the non-primary headlights that run at all times on many modern vehicles—and “when my brain saw this light, I couldn’t look away,” he said. “Even though it was intense, I was drawn to it, and I started to feel a presence I’ve never felt, like evil.” As LEDs became more common, Baker became overwhelmed and had a mental breakdown, ending up in the hospital. He was diagnosed with mild autism spectrum disorder—which he says explains his hyper-fixation on bright lights—and couldn’t go back to work because of the LEDs in his classroom.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">When I spoke to Baker, 59, he was living in a sparsely lit rural area that he moved to with his partner, where he had been focusing on the Soft Lights Foundation since founding it in 2021. Baker told me he’s heard from a variety of people with various diagnoses—epilepsy, photophobia, migraines, lupus, autism—who struggle with LEDs. “I’ve got a guy that calls me from time to time wanting to commit suicide because of these LED lights in the Blue Ridge [Mountains],” he said. “We know that individuals are highly individualized. Each of us is going to react differently.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Baker is among a group of people who feel that NHTSA, which is responsible for regulating automotive safety, should have adjusted the rule book to accommodate LEDs before they were allowed in new cars. This was how NHTSA approached previous fundamental changes to headlight technology, Baker points out. As headlights went from circular to rectangular and from sealed beams to replaceable bulbs, the rules and accommodations changed with them. “Well, when LED headlights came out,” Baker said, “they skipped all that. They just started selling cars with the LED headlights.”&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>The differences between blue-toned and sepia-toned headlights can be seen on a darkened street in Kyiv, Ukraine.</figcaption></figure><figcaption>Metin Aktas/Anadolu Agency via Getty Images</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">It is certainly true that Federal Motor Vehicle Safety Standard No. 108—NHTSA’s regulation covering all forms of vehicle lighting, conceived in 1968—has not been adjusted to create new restrictions for LEDs. That’s easy to tell because the requirements in the standard haven’t been adjusted <em>at all</em> since 1986. One person I spoke to, who previously worked at NHTSA and discussed their former employer on the condition of anonymity, described 108 as being among the biggest entries in the book, yet also “probably one of the least updated.” (In response to an interview request for this story, NHTSA asked that questions be emailed; in response to the questions, NHTSA provided a broad statement that did not answer specific questions, such as ones about the nature of updating 108. “Although headlighting technology has changed over the years,” the statement read, “NHTSA’s lighting standard has remained constant in limiting the amount of glaring light directed toward oncoming and preceding traffic.”)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Several people I spoke to insisted that the main issue with 108’s guidelines when applied to LEDs is that there’s no maximum brightness for certain areas of a headlight. The guidelines set limits on areas of bulb emissions that tend to cause glare problems for other drivers, but those areas were determined based on the light output of older bulbs. LEDs’ output and maneuverability changed the game. Think of an LED headlight more like a pixelated television or computer screen rather than a light bulb. Because of that design, the luminosity of precise areas of the headlight can be limited while the overall brightness is pushed up, up, up.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Chris Trechter, a lighting-focused engineer who used to work for Magna International, the largest automobile parts manufacturer in North America, told me the company would adhere to 108 in making headlights for clients like General Motors but that the rule is “archaic.” “It does not account for LEDs,” he said, “and there are giant loopholes that allow you to throw basically unlimited light as long as you meet all the other aspects of 108.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">On a recent episode of the<em> Carmudgeon Show</em> podcast, auto journalist Jason Cammisa <a href="https://youtu.be/MkwjMV2of_8?t=697">described</a> a phenomenon occurring with some LED headlights in which there are observable minor spots of dimness among an otherwise bright field of light. “With complex arrays of LEDs and of optics,” he said, “car companies realized they can engineer in a dark spot where it’s being measured, but the rest of the field is vastly over-illuminated. And I’ve had now two car companies’ engineers, when I played stupid and said, ‘What’s the dark spot?’ … And the lighting engineers are all fucking proud of themselves: ‘That’s where they measure the fucking thing!’ And I’m like, ‘You assholes, you’re the reason that every fucking new car is blinding the shit out of everyone.’”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Cammisa, who did not respond to an interview request, compared this situation to the massive dieselgate scandal, in which Volkswagen was caught rigging emissions tests. (Fines levied against VW ended up costing the company <a href="https://www.reuters.com/article/legal/vws-dieselgate-bill-hits-30-bln-after-another-charge-idUSKCN1C4270/">around $30 billion</a>.) To Cammisa, deliberately darkening specific areas of LEDs to bypass the testing system demonstrates a craven approach similar to cheating on emissions tests. He’s called it lightinggate. Or headlightgate. He’s workshopping the name.&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>This 2016 Mercedes-Benz ad campaign touting the power of the carmaker’s headlights has become notorious among anti-brightness activists.</figcaption></figure><figcaption>Mercedes-Benz</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I reached out to over a dozen car companies for this story, and only one provided an interview: Audi. In subsequently talking to Audi spokesperson Mark Dahnke, I relayed Cammisa’s description of how LED headlights were being deceptively engineered, and Dahnke told me he was “not aware of anything like that.” But Trechter, the former auto lighting engineer, told me Cammisa’s account was “100 percent real.”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">So why go through all this trouble just for more light? Cammisa believes it’s an <a href="https://youtu.be/MkwjMV2of_8?t=799">“arms race”</a>—part of a battle between automakers to make their cars seem as state of the art as possible. “‘I get into my <a href="https://lucidmotors.com/air">Lucid Air</a>, and I have great lighting in every direction,’” he said, taking on the theoretical perspective of a new customer. “‘Oh, my headlights are <em>great</em>!’” Consider it something like <a href="https://en.wikipedia.org/wiki/Loudness_war">the loudness war</a> in music, in which albums were being mixed at increasing volumes, particularly in the 2000s, to make the music more attention grabbing, at the cost of quality. The brightness war, if you will.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Another possible explanation comes via a nongovernmental entity that has become a major force in the automotive world: the IIHS, a nonprofit funded by insurance companies with the goal of limiting loss. In the absence of any real NHTSA presence in the modern headlight conversation, the IIHS’s headlight safety rating has become a North Star for auto manufacturers, ostensibly for advertising reasons.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It made our life hell to try and make light that bright,” said Trechter. “But GM wanted it for that safety rating, and that’s it.” According to Trechter, the way to get the best safety rating is to exploit the lack of intensity limits on certain areas of the headlight and make the light shine as far down the road as possible. “They would push us to get as much down-road punch as they could get,” he said, in reference to the automakers.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Matthew Brumbelow, a senior research engineer at the IIHS, explained the headlight safety rating in a more nuanced way. While “you can’t get a good rating and have super high glare,” he said, “you also can’t get a good rating and have a dim headlight that doesn’t glare anyone but also is too dim to help people avoid crashes on the road.” Brumbelow said both factors play into their rating but admitted it’s the brightness that they weigh more heavily. “That’s what we’ve seen,” he said. “A huge reduction in crash rates based on more light reaching the road.”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The “brighter is better” mentality is the ultimate thorn in the side of activists like Gatto and Morgan, who view it almost as an insult to their intelligence. Brumbelow pointed to a <a href="https://www.iihs.org/news/detail/good-iihs-headlight-ratings-linked-to-lower-crash-rates#:~:text=Controlling%20for%20differences%20in%20miles%20traveled%2C%20driver%2Drelated,single%2Dvehicle%20crash%20rate%2C%20compared%20with%20poor%2Drated%20ones.">2021 IIHS study</a> that demonstrated a 19 percent reduction in nighttime single-vehicle crashes for cars with good headlight safety ratings, but Morgan sees a major issue with that study. “Basically,” Morgan said, “it means that assholes with bright headlights are in less single-car accidents than the people that they blind.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">One logical solution to this debate would be to factor in crashes that have occurred due to excessive glare, but this has proved to be a challenge out of the reach of the IIHS and other headlight experts. If a car is in an accident due to another car’s excessive glare, for instance, the offending vehicle that caused the situation would likely never know it and just keep driving.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The inability to clinically prove the dangers of headlight glare is at the heart of the issue. “You cannot mandate or prohibit something in the U.S. system without meeting a stringent cost-benefit requirement,” said Daniel Stern, chief editor of Driving Vision News and one of the foremost authorities in headlights and headlight policy.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Stern told me about a conversation he once had in the late 2000s with Richard Van Iderstine, then a recently retired automotive safety standards engineer at NHTSA with great rulemaking authority over headlights. Stern and Van Iderstine had met for lunch and continued talking into dinner, duking it out over the finer points of headlight philosophy. Two giants of the headlight world, going head to head. Stern remembers Van Iderstine telling him, “Look, I’m not stupid. I know what good lighting is, and I know what lousy lighting is. … Does glare cause crashes? Of course glare causes crashes. But I couldn’t prove it.” (Van Iderstine could not be reached for comment.)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Finding a way to empirically measure the danger that glare presents to drivers is one problem. Another is that people can’t seem to agree on what the <em>cause</em> of excessive glare actually is. Stern, for his part, noted that the situation is “very, very complex” and “doesn’t have an answer that sounds like yes or no or 42.” That said, he told me he did recently finish a 38,000-word report on headlight glare for a non-U.S. government (he could not say which one) and is adamant that the biggest factor “by far” is headlight alignment—which is to say, quite literally, how accurately one’s headlights are pointed.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">This is the second-biggest thorn in Gatto and Morgan’s side. Headlight aim is important—no one is denying that. If any headlight, no matter how bright, is misaligned even slightly upward, it will cause glare for other drivers—and many headlights are poorly aligned out of the factory or become misaligned after an accident or installation error. But to someone like Morgan, alignment is only one part of the equation when headlights have become as intense as they have. “It’s a half-truth,” Morgan said, “without really saying that there’s other solutions here and that if you didn’t have laser-beam headlights, this issue would be less severe.” In his PowerPoint presentation, Gatto had drawn a penis on an image of Stern’s head. “That just kind of appeared there, sorry,” Gatto said.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Headlight alignment is certainly Stern’s primary foe—and he is not a fan of the likes of Baker and Morgan, either, whom he described in an email as having a fervor that “greatly outstrips their topical expertise and understanding, and likely qualifies them for IRS classification as religious entities.” But Stern does list other causes of glare as well. There’s headlight <em>condition</em> (a dirty lens can cause the light to refract in chaotic ways), headlight <em>size</em> (as LEDs become smaller, the “density” of the light increases, making it more intense), and headlight <em>color </em>(the eye is more sensitive to blue and white light, making glare seem more significant in modern LEDs, which are generally made in that color field).&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Vehicle size is another issue that comes up regularly, since NHTSA regulations for headlights don’t include a standardized mounting height, even as cars have <a href="https://www.vox.com/future-perfect/24139147/suvs-trucks-popularity-federal-policy-pollution">ballooned in size</a> in recent years. This means a perfectly aligned headlight in a larger car can still wreak havoc on a smaller car: “Where the [midsize] Civic might not give you glare,” Trechter, the former lighting engineer, said, “that F-350 [truck], if you’re sitting in a [sport-size] Miata, is gonna absolutely wreck your eyeballs.”</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>LED headlight bulbs can be seen in a showroom in Osram's headquarters.</figcaption></figure><figcaption>Matthias Balk/picture alliance via Getty Images</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">In NHTSA’s brief statement to me, the only issue the organization brought up directly was aftermarket “LED conversion kits”—when headlight systems designed for halogen lights are swapped with LEDs—which it said are a “major contributor to excessive glare.” Due to the lack of data on what causes glare incidents on the road, it’s difficult to guess how much of a factor aftermarket LEDs are, but one thing’s for sure: They are illegal.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">By pointing to aftermarket LEDs, then, NHTSA essentially passes the buck to law enforcement. This is, perhaps not coincidentally, at the same time that traffic violations nationwide are in substantial decline; <a href="https://www.nytimes.com/interactive/2024/07/29/upshot/traffic-enforcement-dwindled.html">a <em>New York Times</em> study</a> reported a more than 50 percent reduction in traffic stops in many U.S. cities since the pandemic.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The result of the hydra-headed headlight problem appears to be general paralysis; with numerous routes available to potentially improve the situation, none are really being pursued by automakers or regulators. “In engineering,” Gatto told me, “we talk about fail state. What happens when [a system] fails? Does it fail well, or does it fail horribly?” He added, “If you’re planning for multiple of these fail states all the time, maybe consider what the true impact of this is. … You have to kind of go against the whole ethos in order to actually evaluate: Are these too bright?”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">There is one path that certain automakers would like to take to improve headlights—but first it has to make it through NHTSA regulations. Adaptive driving beam technology takes advantage of LED capabilities to adjust the spray of light away from other cars and objects while maintaining high-capacity light on the road. When I got on the phone with the Audi representative, Mark Dahnke, to discuss headlight brightness, it quickly became clear that he was mainly taking the call in the interest of hyping ADB.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It basically puts other drivers in the shadow of your full high-beam light,” Dahnke explained, “such that they are not blinded while providing not just you with more light but everyone with more light.” Dahnke pointed out that ADB has been rolled out in Europe for some time now and is not in the U.S. solely due to NHTSA restrictions. In February 2022, NHTSA belatedly published a rule to allow ADB, but because of the contradictory way the rule is written, no car company has yet been able to find an engineering formula to make it work. “We’re now three different generations of lighting behind the rest of the world in the U.S.,” Dahnke said, exasperated.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto and Morgan, unsurprisingly, are not fans of ADB. They point out that with the way the technology currently works, the light being strategically dimmed is the <em>high beam</em>, meaning that the low beam will stay as bright as ever. “The adaptive high beam is only going to put more light on the road,” Morgan said, adding that people from Europe post in the subreddit about hating the headlight situation there, too. (In a <a href="https://unece.org/sites/default/files/2024-04/GRE-90-20e-reduced.pdf">2024 European study</a> conducted by the Federation Internationale de l’Automobile, 81 percent of respondents said headlight glare needed to be reduced via regulation.) ADB, Morgan insisted, is a corporate over-solution to a simple problem. “That’s their panacea,” he said, “and it’s baloney.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">In the course of automotive history, technology has saved countless lives, taking car accidents from a peak of 30.8 deaths per 100,000 people in 1937 to 13.8 per 100,000 in 2022—a 55 percent improvement. That makes it difficult to dismiss the idea that something <em>like</em> ADB could be the solution to the headlight problem. But Gatto feels that he’s dealing with a “philosophical enemy” in the techno-optimist idea that we can innovate our way out of this. “They want to insert this technology to have a maximum amount of trust in it,” he said, “and they believe that any bit of convenience outweighs any drawback they could get from it.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Paris Marx, a tech critic who focuses on transportation and hosts the <em>Tech Won’t Save Us </em>podcast, is all too familiar with the trickiness of this conversation. LED headlight technology, when viewed through the same lens as evolving tech like self-driving cars, presents a vision of a world in which corporations are asking for perpetual forgiveness rather than permission.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“In general,” Marx told me, “we think about the positive outcomes that can be the result of adopting these things, but then thinking about the negative impacts only comes quite a bit later.” Assessing the notion that something as simple as a headlight could get this out of control, he said, “As usual, we’re trying to play catch-up and figure out how we’re going to address the problems that have been created by this thing that we thought was a solution.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The most compelling argument I heard in defense of brighter lights is that, while glare is clearly a hazard, it may not be as <em>much</em> of a hazard as limited vision on the road. That is to say, brighter headlights—which could illuminate something like a deer on a dark, rural highway from farther away than ever before—may be preventing more accidents than they cause by shining in other drivers’ eyes. You’ll notice every overly bright light searing your brain, but you likely won’t really appreciate the accident you never had.</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><p>Despite the increase in headlight brightness, data from the National Highway Traffic Safety Administration shows that fatal crashes in dark conditions remain relatively stable. In fact, crashes on lighted roads have risen slightly over the past two decades. It raises the question: Is all this extra brightness actually doing anything?</p>
</figcaption></figure><figcaption>NHTSA</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“Is it a problem for people, including myself,” said Brumbelow, the IIHS engineer, “to be on the road and have bright headlights in my eyes and feel like I can’t see? Yes, that’s a problem. But the bigger follow-up question is: Is that my feeling, or is it a reality that I’m at an increased risk of crashing? And that’s really what we’re talking about.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Still, without concrete numbers indicating one way or another, this argument remains philosophical, and the stalemate continues. Morgan, anyway, is eager to figure this out from an engineering perspective, and he has the pie-in-the-sky idea of setting up some kind of nighttime traffic checkpoint, perhaps with the assistance of police, to assess high-glare events in everyday vehicles. “These are surmountable problems,” he said. “This is not like trying to determine divine intervention. These are problems made by men. We can figure this out. It just requires a little bit of effort.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">But he and Gatto know what they think the solution to all this is, and it’s admittedly the simplest proposal anyone has provided: Make the lights less bright. That’s it. “I’m just at: There’s too much glare in my eyes,” Morgan said, “and I want it to stop.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">At a certain point, I found myself more confused than when I started. There was name calling and corporate-interest lobbying and statistic volleying—often all at the same time. I needed a voice of reason. So I reached out to Ray Magliozzi.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Ray and his brother, Tom Magliozzi, hosted the radio show <em>Car Talk</em> for 35 years, from 1977 to 2012, serving as gurus of the car world and seasoning their advice with appropriately saucy New England–style banter and good humor. Tom died in 2014, but Ray still runs an auto mechanic shop in Cambridge and answers car questions via a blog. I decided to call the question line and ask Ray if he had any wisdom to share about headlights, not really expecting to get a reply.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">A few days later my phone started buzzing with a call from a New England area code, and there he was: the wonderful voice from the radio. I told Ray I was shocked to be talking to him, and he didn’t miss a beat: “You called <em>me</em>!”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Magliozzi, 75, is actually fine with the brightness of modern headlights—when they work. Alignment, he noted, is extra important with lights like these, and he abhors the aftermarket LEDs and light bars that people attach to their cars in case “they’re going to encounter a moose or something.” But more than anything else, what bothers Magliozzi about the state of headlights is the increasing number of people who drive with high beams on all the time at night. “I think it’s selfishness to a large degree,” Magliozzi said.</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I had talked about this with many people in the headlight sphere: the possibility that the power of LEDs, supposed to be a bastion of safety, was actually contributing to an “I’ve got mine” mentality on the roads, which has become largely identifiable across the driving realm. It’s impossible to prove a causal relationship, but the rise of LEDs has directly coincided with <a href="https://www.nytimes.com/2024/01/10/magazine/dangerous-driving.html">the rise of reckless driving and road rage, as well as a new surge of fatal accidents</a>. “It seems like there’s an anti-collectivist vibe,” was how Gatto put it. “It’s a behavior that’s emerging.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Some may genuinely not know they’re driving with their high beams on—digital car dashboards have gotten more complex and less intuitive in recent years—but it’s difficult to believe that most permanent high-beam users aren’t doing it deliberately, in an anti-collectivist kind of way. Magliozzi was bummed out about it. “When I learned to drive, 1,001 years ago,” he said, “we were taught to be courteous and polite. And I think we need to get back there.” Maybe that return toward courteousness has to start with automakers and regulatory bodies, however they decide to move forward with the LED headlight dilemma.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The first time I heard Baker, the founder of the Soft Lights Foundation, tell his story about having to essentially drop out of society, I suddenly felt guilty. I may be the type to squint angrily at headlight glare, but at the end of the day, I install the light bulbs available to me and move on with my life. For certain people, it’s clearly a much worse relationship.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I asked Baker what kind of lighting he uses in his day-to-day, and he said he does use LEDs—it’s almost impossible not to at this point—and that he’s found some he’s happy with, like gentle, amber-colored, 300-lumen bulbs for the bedroom. That’s the beauty of LED lights: They can be made for any design or purpose. Sometimes they just have to be adjusted until they’re right.</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“But my favorite light is one that I replaced over the dining room table,” Baker said. His partner bought a chandelier-style fixture, and they put an incandescent bulb in it from a stockpiled supply. “It’s great,” Baker said. “I will go over and turn the switch on just to enjoy that light.”</p><div data-sentry-component="SingleCreator" data-sentry-source-file="article-creator-block.tsx"><div><p><a data-sentry-element="Link" data-sentry-source-file="creator.tsx" href="https://www.theringer.com/creator/nate-rogers"><img alt="" data-sentry-element="Image" data-sentry-source-file="creator.tsx" loading="lazy" decoding="async" data-nimg="fill" src="https://www.theringer.com/avatar-dark.svg"></a></p></div><div><a data-sentry-element="Link" data-sentry-source-file="creator.tsx" href="https://www.theringer.com/creator/nate-rogers"><p>Nate Rogers</p></a><p><span>Nate Rogers is a writer in Los Angeles. His writing has appeared in The New York Times, Los Angeles Times, Stereogum, and elsewhere.</span></p></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moon (2391 pts)]]></title>
            <link>https://ciechanow.ski/moon/</link>
            <guid>42443229</guid>
            <pubDate>Tue, 17 Dec 2024 17:26:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ciechanow.ski/moon/">https://ciechanow.ski/moon/</a>, See on <a href="https://news.ycombinator.com/item?id=42443229">Hacker News</a></p>
Couldn't get https://ciechanow.ski/moon/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an open-source data pipeline tool in Go (177 pts)]]></title>
            <link>https://github.com/bruin-data/bruin</link>
            <guid>42442812</guid>
            <pubDate>Tue, 17 Dec 2024 16:40:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bruin-data/bruin">https://github.com/bruin-data/bruin</a>, See on <a href="https://news.ycombinator.com/item?id=42442812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/bruin-data/bruin/blob/main/resources/logo-horizontal.svg"><img src="https://github.com/bruin-data/bruin/raw/main/resources/logo-horizontal.svg" width="500"></a>
</p>
<p dir="auto">Bruin is a data pipeline tool that brings together data ingestion, data transformation with SQL &amp; Python, and data quality into a single framework. It works with all the major data platforms and runs on your local machine, an EC2 instance, or GitHub Actions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/bruin-data/bruin/blob/main/resources/demo.gif"><img alt="Bruin CLI - Demo" src="https://github.com/bruin-data/bruin/raw/main/resources/demo.gif" width="1200" data-animated-image=""></a></p>
<p dir="auto">Bruin is packed with features:</p>
<ul dir="auto">
<li>📥 ingest data with <a href="https://github.com/bruin-data/ingestr">ingestr</a> / Python</li>
<li>✨ run SQL &amp; Python transformations on <a href="https://bruin-data.github.io/bruin/#supported-platforms" rel="nofollow">many platforms</a></li>
<li>📐 table/view <a href="https://bruin-data.github.io/bruin/assets/materialization.html" rel="nofollow">materializations</a>, incremental tables</li>
<li>🐍 run Python in isolated environments using <a href="https://github.com/astral-sh/uv">uv</a></li>
<li>💅 built-in data quality checks</li>
<li>🚀 Jinja templating to avoid repetition</li>
<li>✅ validate pipelines end-to-end via dry-run</li>
<li>👷 run on your local machine, an EC2 instance, or <a href="https://bruin-data.github.io/bruin/cicd/github-action.html" rel="nofollow">GitHub Actions</a></li>
<li>🔒 secrets injection via environment variables</li>
<li><a href="https://bruin-data.github.io/bruin/vscode-extension/overview.html" rel="nofollow">VS Code extension</a> for a better developer experience</li>
<li>⚡ written in Golang</li>
<li>📦 <a href="https://bruin-data.github.io/bruin/getting-started/introduction/installation.html" rel="nofollow">easy to install</a> and use</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Please see the installation instructions <a href="https://bruin-data.github.io/bruin/getting-started/introduction/installation.html" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">Join our Slack community <a href="https://join.slack.com/t/bruindatacommunity/shared_invite/zt-2dl2i8foy-bVsuMUauHeN9M2laVm3ZVg" rel="nofollow">here</a>.</p>
<p><a href="https://join.slack.com/t/bruindatacommunity/shared_invite/zt-2dl2i8foy-bVsuMUauHeN9M2laVm3ZVg" rel="nofollow">
    <img src="https://camo.githubusercontent.com/4949d95434f014372a1af298fc7abda4e9c80b49da84c6477034a26345edc094/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a6f696e2d646c742e7376673f636f6c6f723d643935663566266c6f676f3d736c61636b" data-canonical-src="https://img.shields.io/badge/slack-join-dlt.svg?color=d95f5f&amp;logo=slack">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Take a look at our quickstart guide <a href="https://bruin-data.github.io/bruin/getting-started/introduction/quickstart.html" rel="nofollow">here</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting to Two Million Users as a One Woman Dev Team (666 pts)]]></title>
            <link>https://brightonruby.com/2024/getting-to-2-million-users-as-a-one-woman-dev-team/</link>
            <guid>42441333</guid>
            <pubDate>Tue, 17 Dec 2024 13:53:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brightonruby.com/2024/getting-to-2-million-users-as-a-one-woman-dev-team/">https://brightonruby.com/2024/getting-to-2-million-users-as-a-one-woman-dev-team/</a>, See on <a href="https://news.ycombinator.com/item?id=42441333">Hacker News</a></p>
<div id="readability-page-1" class="page">

  

  <!--
  <div class="font-bold block w-100 text-white bg-red-800 hover:bg-red-600 focus:outline-none focus:border-red-600">
    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
      class="w-6 h-6">
      <path stroke-linecap="round" stroke-linejoin="round"
        d="M9 6.75V15m6-6v8.25m.503 3.498 4.875-2.437c.381-.19.622-.58.622-1.006V4.82c0-.836-.88-1.38-1.628-1.006l-3.869 1.934c-.317.159-.69.159-1.006 0L9.503 3.252a1.125 1.125 0 0 0-1.006 0L3.622 5.689C3.24 5.88 3 6.27 3 6.695V19.18c0 .836.88 1.38 1.628 1.006l3.869-1.934c.317-.159.69-.159 1.006 0l4.994 2.497c.317.158.69.158 1.006 0Z" />
    </svg>

    <a href="https://maps.apple.com/?address=Brighton,%20BN1%201UE,%20England&auid=15913380656425988054&ll=50.823661,-0.138391&lsp=9902&q=Brighton%20Dome"
      focus:shadow-outline-red active:bg-red-600 transition ease-in-out duration-150">
      Apple
    </a>

    <a href="https://goo.gl/maps/o5YdP27AZ8jNWdGT7" class=" font-bold block w-100 text-white bg-red-800 hover:bg-red-600 focus:outline-none focus:border-red-600
                focus:shadow-outline-red active:bg-red-600 transition ease-in-out duration-150">
      Google
    </a>
  </div>
  -->

  <main>
    <a href="https://ti.to/goodscary/brightonruby-2025">
  <p>
    Buy Tickets
    <span>for 2025</span>
    
  </p>
</a>


    <article>
  
  
    <p>
      <video preload="metadata" controls="" autopictureinpicture="" poster="">
        <source src="https://videos.brightonruby.com/videos/2024/nadia-odunayo-getting-to-two-million-users-as-a-one-woman-dev-team.mp4" type="video/mp4">
        <!-- <track label="English" kind="subtitles" srclang="en-us" src="JAWS-aria-errors.vtt" default=""> -->
        Sorry, your browser doesn’t support embedded videos, but don’t worry, you can
        <a href="https://videos.brightonruby.com/videos/2024/nadia-odunayo-getting-to-two-million-users-as-a-one-woman-dev-team.mp4">download it</a>.
        <!--
          The <a href="JAWS-aria-errors.vtt">caption file</a> is also available in case your video player can import it.
        -->
      </video>
    </p>
  

  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
      
    
  

  <div>
      <p>Nadia Odunayo has been so often the smiling face on the door of this event, but did you know she’s the founder and (more impressively!) one woman development team behind <a href="https://thestorygraph.com/">The StoryGraph</a>, a reading community of over a million book lovers. Her story is one of grit, insight and technical insights into what it takes to execute on the “one person framework”.</p>


      

      <hr>

      <p>Nadia Odunayo is the founder and CEO of The StoryGraph, the app that helps you to track your reading and choose which book to read next based on your mood and favorite topics and themes. She previously worked at Pivotal Labs as a software engineer and originally learnt to code at Makers Academy in London. In her spare time she loves to take dance class and, naturally, read!</p>

    </div>
</article>

  </main>

  

  <!-- Fathom - beautiful, simple website analytics -->
  
  <!-- / Fathom -->



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Langfuse (YC W23) – OSS Tracing and Workflows to Improve LLM Apps (200 pts)]]></title>
            <link>https://github.com/langfuse/langfuse</link>
            <guid>42441258</guid>
            <pubDate>Tue, 17 Dec 2024 13:43:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/langfuse/langfuse">https://github.com/langfuse/langfuse</a>, See on <a href="https://news.ycombinator.com/item?id=42441258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/121163007/322221679-6035f0f3-d691-4963-b5d0-10cf506e9d42.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ0NjQxMDIsIm5iZiI6MTczNDQ2MzgwMiwicGF0aCI6Ii8xMjExNjMwMDcvMzIyMjIxNjc5LTYwMzVmMGYzLWQ2OTEtNDk2My1iNWQwLTEwY2Y1MDZlOWQ0Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxN1QxOTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NzUzYmYxZDYyZDk5N2U4YjlmMTBlYmQxMDM1ZDI0ZmQzYzAzODhjMDFjNzA4YmJlZTkzZmE4NzVhODRhMmQ0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.tA0rZUga9VSDhkjjyUP5lL7Ea7fgYWPFO4czrVqPmuQ"><img src="https://private-user-images.githubusercontent.com/121163007/322221679-6035f0f3-d691-4963-b5d0-10cf506e9d42.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ0NjQxMDIsIm5iZiI6MTczNDQ2MzgwMiwicGF0aCI6Ii8xMjExNjMwMDcvMzIyMjIxNjc5LTYwMzVmMGYzLWQ2OTEtNDk2My1iNWQwLTEwY2Y1MDZlOWQ0Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxN1QxOTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NzUzYmYxZDYyZDk5N2U4YjlmMTBlYmQxMDM1ZDI0ZmQzYzAzODhjMDFjNzA4YmJlZTkzZmE4NzVhODRhMmQ0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.tA0rZUga9VSDhkjjyUP5lL7Ea7fgYWPFO4czrVqPmuQ" alt="Langfuse GitHub Banner"></a></p>
<div dir="auto"><p dir="auto"><h2 tabindex="-1" dir="auto">Langfuse: Open Source LLM Engineering Platform</h2><a id="user-content-langfuse-open-source-llm-engineering-platform" aria-label="Permalink: Langfuse: Open Source LLM Engineering Platform" href="#langfuse-open-source-llm-engineering-platform"></a></p></div>
<div dir="auto"><p dir="auto"><h4 tabindex="-1" dir="auto">LLM Observability, Prompt Management, LLM Evaluations,<br>Datasets, LLM Metrics, and Prompt Playground</h4><a id="user-content-llm-observability-prompt-management-llm-evaluationsdatasets-llm-metrics-and-prompt-playground" aria-label="Permalink: LLM Observability, Prompt Management, LLM Evaluations,Datasets, LLM Metrics, and Prompt Playground" href="#llm-observability-prompt-management-llm-evaluationsdatasets-llm-metrics-and-prompt-playground"></a></p></div>
<div dir="auto">
   
   
   <p><span>Langfuse uses <a href="https://github.com/orgs/langfuse/discussions"><strong>Github Discussions</strong></a>  for Support and Feature Requests.</span>
   <br>
   <span>We're hiring. <a href="https://langfuse.com/careers" rel="nofollow"><strong>Join us</strong></a> in Product Engineering and Developer Relations.</span></p><p><a href="https://github.com/langfuse/langfuse/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/fcbbdcda9497833f606f4465f122fce4c5e9b1c2ce4a6da561d8fe5afb0f507e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d7265642e7376673f7374796c653d666c61742d737175617265" alt="MIT License" data-canonical-src="https://img.shields.io/badge/License-MIT-red.svg?style=flat-square"></a>
      <a href="https://www.ycombinator.com/companies/langfuse" rel="nofollow"><img src="https://camo.githubusercontent.com/e1e0029e353d103690da84a20e88b7051eebbcdede2a1b35d9d1b78b0b0295cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5732332d6f72616e67653f7374796c653d666c61742d737175617265" alt="Y Combinator W23" data-canonical-src="https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square"></a>
      <a href="https://github.com/langfuse/langfuse/pkgs/container/langfuse"><img alt="Docker Image" src="https://camo.githubusercontent.com/0b0c3a9f26ebd1d035e726c23742147403771bafe84a8eeb4d77f44d3fa699bd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f636b65722d6c616e67667573652d626c75653f6c6f676f3d446f636b6572266c6f676f436f6c6f723d7768697465267374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/docker-langfuse-blue?logo=Docker&amp;logoColor=white&amp;style=flat-square"></a>
      <a href="https://pypi.python.org/pypi/langfuse" rel="nofollow"><img src="https://camo.githubusercontent.com/32bdb8ed067c141aa9b6935d039a8ad35e57cedaa7439d2aa554d5ce3cabaa8b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6c616e67667573653f7374796c653d666c61742d737175617265266c6f676f3d707974686f6e266c6f676f436f6c6f723d7768697465266c6162656c3d707970692532306c616e676675736526636f6c6f723d626c7565" alt="langfuse Python package on PyPi" data-canonical-src="https://img.shields.io/pypi/dm/langfuse?style=flat-square&amp;logo=python&amp;logoColor=white&amp;label=pypi%20langfuse&amp;color=blue"></a>
      <a href="https://www.npmjs.com/package/langfuse" rel="nofollow"><img src="https://camo.githubusercontent.com/d1c1236c9ea644243ec3e13287c02ee8b0ca42797dd42ba0630e71f3399b6614/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f6c616e67667573653f7374796c653d666c61742d737175617265266c6f676f3d6e706d266c6f676f436f6c6f723d7768697465266c6162656c3d6e706d2532306c616e676675736526636f6c6f723d626c7565" alt="langfuse npm package" data-canonical-src="https://img.shields.io/npm/dm/langfuse?style=flat-square&amp;logo=npm&amp;logoColor=white&amp;label=npm%20langfuse&amp;color=blue"></a>
   </p>
</div>

<p dir="auto"><h2 tabindex="-1" dir="auto">Langfuse Overview</h2><a id="user-content-langfuse-overview" aria-label="Permalink: Langfuse Overview" href="#langfuse-overview"></a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=2E8iTvGo9Hs" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/2834609/396482950-3926b288-ff61-4b95-8aa1-45d041c70866.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ0NjQxMDIsIm5iZiI6MTczNDQ2MzgwMiwicGF0aCI6Ii8yODM0NjA5LzM5NjQ4Mjk1MC0zOTI2YjI4OC1mZjYxLTRiOTUtOGFhMS00NWQwNDFjNzA4NjYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIxNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMTdUMTkzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjBjMTQyMWE2OWY4MzI1NzJlMzZjNjQwZTNiZDU3YjVjMGFmOWQ1MTU4ZGQzOTkyYTRhYjFmMDU3NmM1OTBjZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.oHeaFLKEhOIlaxdLGPwSV6NwJ3-S0At1qrW7mQ7KmJ0" alt="Langfuse Overview Video" secured-asset-link=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Develop</h3><a id="user-content-develop" aria-label="Permalink: Develop" href="#develop"></a></p>
<ul dir="auto">
<li><strong>LLM Observability:</strong> Instrument your app and start ingesting traces to Langfuse (<a href="https://langfuse.com/docs/get-started" rel="nofollow">Quickstart</a>, <a href="https://langfuse.com/docs/integrations" rel="nofollow">Integrations</a> <a href="https://langfuse.com/docs/tracing" rel="nofollow">Tracing</a>)</li>
<li><strong>Langfuse UI:</strong> Inspect and debug complex logs (<a href="https://langfuse.com/docs/demo" rel="nofollow">Demo</a>, <a href="https://langfuse.com/docs/tracing" rel="nofollow">Tracing</a>)</li>
<li><strong>Prompt Management:</strong> Manage, version and deploy prompts from within Langfuse (<a href="https://langfuse.com/docs/prompts/get-started" rel="nofollow">Prompt Management</a>)</li>
<li><strong>Prompt Engineering:</strong> Test and iterate on your prompts with the <a href="https://langfuse.com/docs/playground" rel="nofollow">LLM Playground</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Monitor</h3><a id="user-content-monitor" aria-label="Permalink: Monitor" href="#monitor"></a></p>
<ul dir="auto">
<li><strong>LLM Analytics:</strong> Track metrics (cost, latency, quality) and gain insights from dashboards &amp; data exports (<a href="https://langfuse.com/docs/analytics" rel="nofollow">Analytics</a>)</li>
<li><strong>LLM Evaluations:</strong> Collect and calculate scores for your LLM completions (<a href="https://langfuse.com/docs/scores" rel="nofollow">Scores &amp; Evaluations</a>)
<ul dir="auto">
<li>Run (<a href="https://langfuse.com/docs/scores/model-based-evals" rel="nofollow">Model-based evaluations</a>) and LLM-as-a-Judge within Langfuse</li>
<li>Collect user feedback (<a href="https://langfuse.com/docs/scores/user-feedback" rel="nofollow">User Feedback</a>)</li>
<li>Manually score LLM outputs in Langfuse (<a href="https://langfuse.com/docs/scores/manually" rel="nofollow">Manual Scores</a>)</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test</h3><a id="user-content-test" aria-label="Permalink: Test" href="#test"></a></p>
<ul dir="auto">
<li><strong>Experiments:</strong> Track and test app behaviour before deploying a new version
<ul dir="auto">
<li>Datasets let you test expected in and output pairs and benchmark performance before deploying (<a href="https://langfuse.com/docs/datasets" rel="nofollow">Datasets</a>)</li>
<li>Track versions and releases in your application (<a href="https://langfuse.com/docs/experimentation" rel="nofollow">Experimentation</a>, <a href="https://langfuse.com/docs/prompts" rel="nofollow">Prompt Management</a>)</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get started</h2><a id="user-content-get-started" aria-label="Permalink: Get started" href="#get-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Langfuse Cloud</h3><a id="user-content-langfuse-cloud" aria-label="Permalink: Langfuse Cloud" href="#langfuse-cloud"></a></p>
<p dir="auto">Managed deployment by the Langfuse team, generous free-tier (hobby plan), no credit card required.</p>
<p dir="auto"><strong><a href="https://cloud.langfuse.com/" rel="nofollow">» Langfuse Cloud</a></strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Self-Hosting Open Source LLM Observability with Langfuse</h2><a id="user-content-self-hosting-open-source-llm-observability-with-langfuse" aria-label="Permalink: Self-Hosting Open Source LLM Observability with Langfuse" href="#self-hosting-open-source-llm-observability-with-langfuse"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Localhost (docker)</h3><a id="user-content-localhost-docker" aria-label="Permalink: Localhost (docker)" href="#localhost-docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/langfuse/langfuse.git
cd langfuse

# Run server and database
docker compose up -d"><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/langfuse/langfuse.git
<span>cd</span> langfuse

<span><span>#</span> Run server and database</span>
docker compose up -d</pre></div>
<p dir="auto"><a href="https://langfuse.com/docs/deployment/local" rel="nofollow">→ Learn more about deploying locally</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-host (docker)</h3><a id="user-content-self-host-docker" aria-label="Permalink: Self-host (docker)" href="#self-host-docker"></a></p>
<p dir="auto">Langfuse is simple to self-host and keep updated. It currently requires only a single docker container and a postgres database.
<a href="https://langfuse.com/docs/deployment/self-host" rel="nofollow">→ Self Hosting Instructions</a></p>
<p dir="auto">Templated deployments: <a href="https://langfuse.com/docs/deployment/self-host#platform-specific-information" rel="nofollow">Railway, GCP, AWS, Azure, Kubernetes and others</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started-1" aria-label="Permalink: Get Started" href="#get-started-1"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">API Keys</h3><a id="user-content-api-keys" aria-label="Permalink: API Keys" href="#api-keys"></a></p>
<p dir="auto">You need a Langfuse public and secret key to get started. Sign up <a href="https://cloud.langfuse.com/" rel="nofollow">here</a> and find them in your project settings.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ingesting Data · Instrumenting Your Application · LLM Observability with Langfuse</h3><a id="user-content-ingesting-data--instrumenting-your-application--llm-observability-with-langfuse" aria-label="Permalink: Ingesting Data · Instrumenting Your Application · LLM Observability with Langfuse" href="#ingesting-data--instrumenting-your-application--llm-observability-with-langfuse"></a></p>
<p dir="auto">Note: We recommend using our fully async, typed <a href="https://langfuse.com/docs/sdk" rel="nofollow">SDKs</a> that allow you to instrument any LLM application with any underlying model. They are available in <a href="https://langfuse.com/docs/sdk/python" rel="nofollow">Python (Decorators)</a> &amp; <a href="https://langfuse.com/docs/sdk/typescript" rel="nofollow">JS/TS</a>. The SDKs will always be the most fully featured and stable way to ingest data into Langfuse.</p>
<p dir="auto">See the <a href="https://langfuse.com/docs/get-started" rel="nofollow">→ Quickstart</a> to integrate Langfuse.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LLM Observability Integrations</h3><a id="user-content-llm-observability-integrations" aria-label="Permalink: LLM Observability Integrations" href="#llm-observability-integrations"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Integration</th>
<th>Supports</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://langfuse.com/docs/sdk" rel="nofollow">SDK</a></td>
<td>Python, JS/TS</td>
<td>Manual instrumentation using the SDKs for full flexibility.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/openai" rel="nofollow">OpenAI</a></td>
<td>Python, JS/TS</td>
<td>Automated instrumentation using drop-in replacement of OpenAI SDK.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/langchain" rel="nofollow">Langchain</a></td>
<td>Python, JS/TS</td>
<td>Automated instrumentation by passing callback handler to Langchain application.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/llama-index/get-started" rel="nofollow">LlamaIndex</a></td>
<td>Python</td>
<td>Automated instrumentation via LlamaIndex callback system.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/haystack" rel="nofollow">Haystack</a></td>
<td>Python</td>
<td>Automated instrumentation via Haystack content tracing system.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/litellm" rel="nofollow">LiteLLM</a></td>
<td>Python, JS/TS (proxy only)</td>
<td>Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs).</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/vercel-ai-sdk" rel="nofollow">Vercel AI SDK</a></td>
<td>JS/TS</td>
<td>TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/api" rel="nofollow">API</a></td>
<td></td>
<td>Directly call the public API. OpenAPI spec available.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Packages integrated with Langfuse:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://langfuse.com/docs/integrations/instructor" rel="nofollow">Instructor</a></td>
<td>Library to get structured LLM outputs (JSON, Pydantic)</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/dify" rel="nofollow">Dify</a></td>
<td>Open source LLM app development platform with no-code builder.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/ollama" rel="nofollow">Ollama</a></td>
<td>Easily run open source LLMs on your own machine.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/mirascope" rel="nofollow">Mirascope</a></td>
<td>Python toolkit for building LLM applications.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/flowise" rel="nofollow">Flowise</a></td>
<td>JS/TS no-code builder for customized LLM flows.</td>
</tr>
<tr>
<td><a href="https://langfuse.com/docs/integrations/langflow" rel="nofollow">Langflow</a></td>
<td>Python-based UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Questions and feedback</h2><a id="user-content-questions-and-feedback" aria-label="Permalink: Questions and feedback" href="#questions-and-feedback"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ideas and roadmap</h3><a id="user-content-ideas-and-roadmap" aria-label="Permalink: Ideas and roadmap" href="#ideas-and-roadmap"></a></p>
<ul dir="auto">
<li><a href="https://langfuse.com/roadmap" rel="nofollow">Roadmap</a></li>
<li><a href="https://github.com/orgs/langfuse/discussions">GitHub Discussions</a></li>
<li><a href="https://langfuse.com/ideas" rel="nofollow">Feature Requests</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Support and feedback</h3><a id="user-content-support-and-feedback" aria-label="Permalink: Support and feedback" href="#support-and-feedback"></a></p>
<p dir="auto">In order of preference the best way to communicate with us:</p>
<ul dir="auto">
<li><a href="https://github.com/orgs/langfuse/discussions">GitHub Discussions</a> (preferred): Contribute <a href="https://langfuse.com/ideas" rel="nofollow">ideas</a>, <a href="https://langfuse.com/gh-support" rel="nofollow">support requests</a> and <a href="https://langfuse.com/issues" rel="nofollow">report bugs</a></li>
<li><a href="https://langfuse.com/discord" rel="nofollow">Discord</a>: community support</li>
<li>Privately: contact at langfuse dot com</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing to Langfuse</h2><a id="user-content-contributing-to-langfuse" aria-label="Permalink: Contributing to Langfuse" href="#contributing-to-langfuse"></a></p>
<ul dir="auto">
<li>Vote on <a href="https://github.com/orgs/langfuse/discussions/categories/ideas">Ideas</a></li>
<li>Raise and comment on <a href="https://github.com/langfuse/langfuse/issues">Issues</a></li>
<li>Open a PR - see <a href="https://github.com/langfuse/langfuse/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details on how to setup a development environment.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This repository is MIT licensed, except for the <code>ee</code> folders. See <a href="https://github.com/langfuse/langfuse/blob/main/LICENSE">LICENSE</a> and <a href="https://langfuse.com/docs/open-source" rel="nofollow">docs</a> for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Misc</h2><a id="user-content-misc" aria-label="Permalink: Misc" href="#misc"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">GET API to export your data</h3><a id="user-content-get-api-to-export-your-data" aria-label="Permalink: GET API to export your data" href="#get-api-to-export-your-data"></a></p>
<p dir="auto"><a href="https://langfuse.com/docs/integrations/api" rel="nofollow"><strong>GET routes</strong></a> to use data in downstream applications (e.g. embedded analytics). You can also access them conveniently via the SDKs (<a href="https://langfuse.com/docs/query-traces" rel="nofollow">docs</a>).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security &amp; Privacy</h3><a id="user-content-security--privacy" aria-label="Permalink: Security &amp; Privacy" href="#security--privacy"></a></p>
<p dir="auto">We take data security and privacy seriously. Please refer to our <a href="https://langfuse.com/security" rel="nofollow">Security and Privacy</a> page for more information.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Telemetry</h3><a id="user-content-telemetry" aria-label="Permalink: Telemetry" href="#telemetry"></a></p>
<p dir="auto">By default, Langfuse automatically reports basic usage statistics of self-hosted instances to a centralized server (PostHog).</p>
<p dir="auto">This helps us to:</p>
<ol dir="auto">
<li>Understand how Langfuse is used and improve the most relevant features.</li>
<li>Track overall usage for internal and external (e.g. fundraising) reporting.</li>
</ol>
<p dir="auto">None of the data is shared with third parties and does not include any sensitive information. We want to be super transparent about this and you can find the exact data we collect <a href="https://github.com/langfuse/langfuse/blob/main/web/src/features/telemetry/index.ts">here</a>.</p>
<p dir="auto">You can opt-out by setting <code>TELEMETRY_ENABLED=false</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Star History</h3><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<a href="https://star-history.com/#langfuse/langfuse&amp;Date" rel="nofollow">
 <themed-picture data-catalyst-inline="true"><picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://camo.githubusercontent.com/3e5cc364f471d385fc43aad9438960abfd5f1d444f397b7dd1011eec0ed0ed61/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c616e67667573652f6c616e676675736526747970653d44617465267468656d653d6461726b" data-canonical-src="https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date&amp;theme=dark">
   <source media="(prefers-color-scheme: light)" srcset="https://camo.githubusercontent.com/69cd0e8abd538d9a5267856d84d067cc5313da4e9cb1bb2746f1e6f96dd93bc1/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c616e67667573652f6c616e676675736526747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date">
   <img alt="Star History Chart" src="https://camo.githubusercontent.com/69cd0e8abd538d9a5267856d84d067cc5313da4e9cb1bb2746f1e6f96dd93bc1/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c616e67667573652f6c616e676675736526747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date">
 </picture></themed-picture>
</a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Open Source Projects Using Langfuse</h3><a id="user-content-open-source-projects-using-langfuse" aria-label="Permalink: Open Source Projects Using Langfuse" href="#open-source-projects-using-langfuse"></a></p>
<p dir="auto">Top open-source Python projects that use Langfuse, ranked by stars (<a href="https://github.com/langfuse/langfuse-docs/blob/main/components-mdx/dependents">Source</a>):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Stars</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/127165244?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/127165244?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/langgenius">langgenius</a> / <a href="https://github.com/langgenius/dify">dify</a></td>
<td>54865</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/158137808?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/158137808?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/open-webui">open-webui</a> / <a href="https://github.com/open-webui/open-webui">open-webui</a></td>
<td>51531</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/131470832?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/131470832?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/lobehub">lobehub</a> / <a href="https://github.com/lobehub/lobe-chat">lobe-chat</a></td>
<td>49003</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/85702467?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/85702467?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/langflow-ai">langflow-ai</a> / <a href="https://github.com/langflow-ai/langflow">langflow</a></td>
<td>39093</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/130722866?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/130722866?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/run-llama">run-llama</a> / <a href="https://github.com/run-llama/llama_index">llama_index</a></td>
<td>37368</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/139558948?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/139558948?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/chatchat-space">chatchat-space</a> / <a href="https://github.com/chatchat-space/Langchain-Chatchat">Langchain-Chatchat</a></td>
<td>32486</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/128289781?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/128289781?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/FlowiseAI">FlowiseAI</a> / <a href="https://github.com/FlowiseAI/Flowise">Flowise</a></td>
<td>32448</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/31035808?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/31035808?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/mindsdb">mindsdb</a> / <a href="https://github.com/mindsdb/mindsdb">mindsdb</a></td>
<td>26931</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/119600397?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/119600397?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/twentyhq">twentyhq</a> / <a href="https://github.com/twentyhq/twenty">twenty</a></td>
<td>24195</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/60330232?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/60330232?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/PostHog">PostHog</a> / <a href="https://github.com/PostHog/posthog">posthog</a></td>
<td>22618</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/121462774?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/121462774?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/BerriAI">BerriAI</a> / <a href="https://github.com/BerriAI/litellm">litellm</a></td>
<td>15151</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/179202840?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/179202840?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/mediar-ai">mediar-ai</a> / <a href="https://github.com/mediar-ai/screenpipe">screenpipe</a></td>
<td>11037</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/105877416?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/105877416?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/formbricks">formbricks</a> / <a href="https://github.com/formbricks/formbricks">formbricks</a></td>
<td>9386</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/76263028?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/76263028?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/anthropics">anthropics</a> / <a href="https://github.com/anthropics/courses">courses</a></td>
<td>8385</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/78410652?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/78410652?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/GreyDGL">GreyDGL</a> / <a href="https://github.com/GreyDGL/PentestGPT">PentestGPT</a></td>
<td>7374</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/152537519?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/152537519?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/superagent-ai">superagent-ai</a> / <a href="https://github.com/superagent-ai/superagent">superagent</a></td>
<td>5391</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/137907881?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/137907881?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/promptfoo">promptfoo</a> / <a href="https://github.com/promptfoo/promptfoo">promptfoo</a></td>
<td>4976</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/157326433?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/157326433?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/onlook-dev">onlook-dev</a> / <a href="https://github.com/onlook-dev/onlook">onlook</a></td>
<td>4141</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/7250217?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/7250217?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/Canner">Canner</a> / <a href="https://github.com/Canner/WrenAI">WrenAI</a></td>
<td>2526</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/11855343?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/11855343?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/pingcap">pingcap</a> / <a href="https://github.com/pingcap/autoflow">autoflow</a></td>
<td>2061</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/85268109?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/85268109?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/MLSysOps">MLSysOps</a> / <a href="https://github.com/MLSysOps/MLE-agent">MLE-agent</a></td>
<td>1161</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/158137808?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/158137808?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/open-webui">open-webui</a> / <a href="https://github.com/open-webui/pipelines">pipelines</a></td>
<td>1100</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/18422723?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/18422723?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/alishobeiri">alishobeiri</a> / <a href="https://github.com/alishobeiri/thread">thread</a></td>
<td>1074</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/125468716?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/125468716?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/topoteretes">topoteretes</a> / <a href="https://github.com/topoteretes/cognee">cognee</a></td>
<td>971</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/188657705?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/188657705?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/bRAGAI">bRAGAI</a> / <a href="https://github.com/bRAGAI/bRAG-langchain">bRAG-langchain</a></td>
<td>823</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/169500408?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/169500408?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/opslane">opslane</a> / <a href="https://github.com/opslane/opslane">opslane</a></td>
<td>677</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/151867818?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/151867818?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/dynamiq-ai">dynamiq-ai</a> / <a href="https://github.com/dynamiq-ai/dynamiq">dynamiq</a></td>
<td>639</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/48585267?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/48585267?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/theopenconversationkit">theopenconversationkit</a> / <a href="https://github.com/theopenconversationkit/tock">tock</a></td>
<td>514</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/20493493?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/20493493?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/andysingal">andysingal</a> / <a href="https://github.com/andysingal/llm-course">llm-course</a></td>
<td>394</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/132396805?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/132396805?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/phospho-app">phospho-app</a> / <a href="https://github.com/phospho-app/phospho">phospho</a></td>
<td>384</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/178644984?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/178644984?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/sentient-engineering">sentient-engineering</a> / <a href="https://github.com/sentient-engineering/agent-q">agent-q</a></td>
<td>370</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/168552753?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/168552753?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/sql-agi">sql-agi</a> / <a href="https://github.com/sql-agi/DB-GPT">DB-GPT</a></td>
<td>324</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/60330232?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/60330232?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/PostHog">PostHog</a> / <a href="https://github.com/PostHog/posthog-foss">posthog-foss</a></td>
<td>305</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/154247157?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/154247157?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/vespperhq">vespperhq</a> / <a href="https://github.com/vespperhq/vespper">vespper</a></td>
<td>304</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/185116535?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/185116535?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/block">block</a> / <a href="https://github.com/block/goose">goose</a></td>
<td>295</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/609489?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/609489?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/aorwall">aorwall</a> / <a href="https://github.com/aorwall/moatless-tools">moatless-tools</a></td>
<td>291</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/2357342?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/2357342?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/dmayboroda">dmayboroda</a> / <a href="https://github.com/dmayboroda/minima">minima</a></td>
<td>221</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/66303003?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/66303003?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/RobotecAI">RobotecAI</a> / <a href="https://github.com/RobotecAI/rai">rai</a></td>
<td>172</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/148684274?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/148684274?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/i-am-alice">i-am-alice</a> / <a href="https://github.com/i-am-alice/3rd-devs">3rd-devs</a></td>
<td>148</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/171735272?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/171735272?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/8090-inc">8090-inc</a> / <a href="https://github.com/8090-inc/xrx-sample-apps">xrx-sample-apps</a></td>
<td>138</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/104478511?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/104478511?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/babelcloud">babelcloud</a> / <a href="https://github.com/babelcloud/LLM-RGB">LLM-RGB</a></td>
<td>135</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/15125613?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/15125613?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/souzatharsis">souzatharsis</a> / <a href="https://github.com/souzatharsis/tamingLLMs">tamingLLMs</a></td>
<td>129</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/169401942?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/169401942?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/LibreChat-AI">LibreChat-AI</a> / <a href="https://github.com/LibreChat-AI/librechat.ai">librechat.ai</a></td>
<td>128</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/51827949?s=40&amp;v=4"><img src="https://avatars.githubusercontent.com/u/51827949?s=40&amp;v=4" width="20" height="20" alt=""></a> &nbsp; <a href="https://github.com/deepset-ai">deepset-ai</a> / <a href="https://github.com/deepset-ai/haystack-core-integrations">haystack-core-integrations</a></td>
<td>126</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>