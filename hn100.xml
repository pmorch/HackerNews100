<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 23 May 2025 18:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Find Your People (106 pts)]]></title>
            <link>https://foundersatwork.posthaven.com/find-your-people</link>
            <guid>44074017</guid>
            <pubDate>Fri, 23 May 2025 16:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://foundersatwork.posthaven.com/find-your-people">https://foundersatwork.posthaven.com/find-your-people</a>, See on <a href="https://news.ycombinator.com/item?id=44074017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_body_2199368"><p><i>Thank you to Bucknell University for inviting me to be this year's commencement speaker. And congratulations to the Class of 2025!&nbsp;</i></p><div id="posthaven_gallery[2222810]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/medium_25Commencement019.JPG" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/medium_25Commencement019.JPG" data-medium-width="800" data-medium-height="533" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/large_25Commencement019.JPG" data-large-width="1200" data-large-height="800" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/thumb_25Commencement019.JPG" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/xlarge_25Commencement019.JPG" data-xlarge-width="2400" data-xlarge-height="1600" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3318815/xb3-DdPynP_pezHq8MyP_5ETaks/25Commencement019.JPG" data-orig-width="5251" data-orig-height="3501" data-posthaven-id="3318815">
        </p>
          
        </div>
<p><a href="https://www.youtube.com/watch?v=thb8Fz4pCiA" target="_blank">Watch the speech on YouTube</a>.</p><p>Thirty-two years ago I was sitting where you are now. At least, I assume I was. I can't really remember anything about my own graduation. I was too hung over.&nbsp;</p><p>The main thing I remember from that time in my life is that I had no plan. I had a degree in English, no job, and no idea what I even wanted to do. I would have liked to work hard on something I cared about. But I didn't have anything I cared about, and it took me a decade to find one.</p><p>Maybe I can help you do that faster. Maybe I can help you figure out what to work on.&nbsp;</p><p>You fall into three groups. Some of you already have all kinds of ambitious plans. You're already admitted to med school for the fall, or whatever. Others of you have no ambitious plans and no desire to have any. You just want to have a happy life, and that's cool. But in the middle, there's a group who wish they had ambitious plans, but don't. This speech is for you. I'm going to tell you how to get ambitious plans.</p><p>The first step is to realize that the subway stops here. Up to this point in life, most of you have been rolling on train tracks. Elementary school, middle school, high school, college—it was always clear what the next stop was. In the process you've been trained to believe something that’s not true: that <i>all</i> of life is train tracks. And there are some jobs where you can make it stay like train tracks if you want, but really today is the last stop.</p><p>This fact is so terrifying that a lot of people try to remain in denial about it. (I certainly did.) But it's also exciting. You can go in any direction now.</p><p>I didn't realize that, so I looked for more tracks. I looked for a job at a big, well-known company that I hoped would train me to do something, but I didn't know or care what, really, just so long as I was on some new set of tracks. The fall after graduation I was on the night shift at Fidelity Investments customer service, answering people's questions about why the value of their mutual fund went down.&nbsp;</p><p>This wasn't fun or interesting to me. So why did I do it? Two reasons: I didn't know any better, and I didn't think I had any particular aptitude for any kind of work, so I was delighted that anyone would pay me to do anything.</p><p>So I'm going to tell you about a trick you can pull right here at the point where the train tracks end. You can reinvent yourself. I wish I’d known I could do that. I was lazy in college and got bad grades. But the real problem was that I believed them: I believed that mediocre grades meant I was a mediocre person. And that stuck with me for years. I'm sure most of you have done better in school than I did, but maybe there are some of you who are feeling a little unsure of yourself. But here's the thing: you don't have to tell people that. <i>They</i> don't know. So if you want to, you can just decide to shift gears at this point, and no one's going to tell you you can't. You can just decide to be more curious, or more responsible, or more energetic, and no one's going to go look up your college grades and say, "Hey, wait a minute, this person's supposed to be a slacker."&nbsp;</p><p>If I'd known then what I know now, I'd have realized that there are many different kinds of jobs you can get after college, some much more interesting than others. And if I'd known I could be more ambitious, I would have tried to get one of the more interesting ones.</p><p>The truth is there are thousands of different places you could go work, and you have to consider them all and figure out which is the best. But that sounds impossible, right? You only had to choose between 60 different majors, and now you have to choose between thousands of different jobs? How do you even do that? The first step, is to acknowledge that you have to. You can't just drift into the open mouth of Fidelity, like I did.</p><p>Ok, then what? How do you search through thousands of options? To be honest, you can’t. You have to use some kind of trick for narrowing them down. My favorite trick is people. Talk to people. Get introduced to new people. Find the people that you think are interesting, and then ask what they're working on. And if you find yourself working at a place where you don't like the people, get out.</p><p>That was how I finally figured out what to work on. I found the <i>startup people</i>, and I realized that startups were what I was interested in. Once I did, I got more ambitious. I decided to write a book about startups. And having my own project made me even more ambitious. Finally I was working on something of my own! But most people I told about this project didn't get it. I wasn't an author or a startup person. How could I be writing a book about startups?&nbsp;</p><p>Which leads me to my final point about getting ambitious plans: you have to be immune to rejection. People are going to dismiss you at first. If that's enough to stop you, you're doomed. So you have to learn to ignore it. And that's harder than it sounds—social pressure is so powerful. But everyone who does ambitious things has to learn how to resist it.</p><p>If you have ambitious plans, a lot of people will be skeptical. You'll seem like you're getting above yourself, except perhaps to your parents. And even they will usually be too conservative. Plus, most ambitious ideas seem wrong at first. If a new idea was obviously good, someone else would have already done it.&nbsp;</p><p>When <a href="https://foundersatwork.posthaven.com/grow-the-puzzle-around-you" target="_blank">we started Y Combinator</a>, everyone treated it as a joke. We were funding kids right out of college and only giving them small amounts of money. How could these startups ever succeed? Now everyone knows it's a good idea to fund young founders, but twenty years ago, it just seemed lame. But we didn't care what people thought of us. We knew we were onto something. In fact it was good that we seemed lame, because that meant it took several years before people started to copy us.</p><p>I’ll admit I wasn’t then as immune to rejection as I've become now. It's something I've learned from lots of practice. But I've gotten good at it now. So I'm proof that you can learn not to care what other people think.</p><p>Now I have some good news: I'm almost done. I hate long speeches and I bet you do too. And frankly, if you can remember what I've told you so far, that will be enough. So let me remind you what I've told you: you've been able to go through life so far without steering much. If you want to, you can become more ambitious now, but to do that you have to start steering. You can't just drift. There’re a huge number of options, and you have to actively figure out which is the best for you. And the best way to do that is people. Find the interesting people.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PostgreSQL IDE in VS Code (311 pts)]]></title>
            <link>https://techcommunity.microsoft.com/blog/adforpostgresql/announcing-a-new-ide-for-postgresql-in-vs-code-from-microsoft/4414648</link>
            <guid>44073588</guid>
            <pubDate>Fri, 23 May 2025 15:12:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcommunity.microsoft.com/blog/adforpostgresql/announcing-a-new-ide-for-postgresql-in-vs-code-from-microsoft/4414648">https://techcommunity.microsoft.com/blog/adforpostgresql/announcing-a-new-ide-for-postgresql-in-vs-code-from-microsoft/4414648</a>, See on <a href="https://news.ycombinator.com/item?id=44073588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are excited to announce the public preview of the brand-new PostgreSQL extension for Visual Studio Code (VS Code), designed to simplify PostgreSQL database management and development workflows. With this extension, you can now manage database objects, draft queries with intelligent assistance from context-aware IntelliSense and our ‘@pgsql’ GitHub Copilot agent—all without ever leaving your favorite code editor.</p>

<p>Many of you face hurdles in managing time effectively, with 41% of developers struggling with task-switching, according to the <a href="https://survey.stackoverflow.co/2024/" target="_blank" rel="noopener nofollow noreferrer">2024 StackOverflow Developer Survey</a>. Additionally, the <a href="https://stripe.com/files/reports/the-developer-coefficient.pdf" target="_blank" rel="noopener nofollow noreferrer">2024 Stripe Developer Coefficient Report</a> reveals that developers spend up to 50% of their time debugging and troubleshooting code and databases. These inefficiencies are further compounded by the absence of integrated tools that unify database management and application development.</p>
<p>The PostgreSQL extension for VS Code addresses these challenges head-on by integrating Postgres database tools and the @pgsql GitHub Copilot agent, providing a unified application development and database management experience. By integrating robust features such as Entra ID authentication for centralized identity management and deep Azure Database for PostgreSQL integration, this extension empowers you to focus on building innovative applications rather than wrestling with fragmented workflows.</p>

<p>The public preview release of the PostgreSQL extension for VS Code introduces a suite of powerful new capabilities that enhance productivity and streamline development for application developers working with Postgres.</p>

<p>Schema visualization is a breeze with our ‘right-click’ context menu options.</p>
<p>o&nbsp;&nbsp; Right-click on the database entry in the Object Explorer and select “Visualize Schema”</p>

<p><span data-image-alt=""><span id="hvMjHN_caption">Figure 1: Right-click on the database entry in the Object Explorer and select “Visualize Schema”<br>Single click to expand.<br></span></span></p>
<ul>
<li>AI assistance directly within VS Code providing PostgreSQL database context reduces the PostgreSQL learning curve and improves developer productivity​.</li>
<li>Simplified interaction with PostgreSQL databases and development tools using natural language.</li>
<li>Commands such as "@pgsql" enable you to query databases, optimize schemas, and execute SQL operations with ease.</li>
<li>Context menus, such as “Rewrite Query”, “Explain Query”, “Analyze Query Performance” provide AI Intelligence inside the query editor window.</li>
<li>Real-time, expert-level guidance to help keep PostgreSQL databases performant and secure and improve code quality​.</li>
</ul>

<p><span data-image-alt=""><span id="dAS6Yc_caption">Figure 2: Screenshot of the PostgreSQL Copilot Context Menu.<br>Single click to expand.</span></span></p><p>Using the PostgreSQL Copilot Context Menu,&nbsp;</p>
<p><span data-image-alt=""><span id="bBmUvl_caption">Figure 3: PostgreSQL Copilot Explain Query Context Menu in action.<br>Single click to expand.<br></span></span></p>
<p>GitHub Copilot Chat agent mode provides a database context aware intelligent assistant that can perform multi-stage tasks, moving beyond the question-and-answer chat experience. Agent mode allows the Copilot to bring in additional context from your workspace and, with permission, it can write and debug code on its own. Agent mode transforms PostgreSQL development by providing real-time, AI-driven guidance that simplifies complex tasks like app prototyping, debugging, schema optimization, and performance tuning. &nbsp;</p>
<p>In this example, we’ll ask the agent to create a new database on a specific server in my Saved Connections and enable the PostGIS extension.</p>
<p><span data-image-alt=""><span id="yaGWdg_caption">Figure 4: Using the @pgsql GitHub Copilot Chat in agent mode to create a new database from a natural language prompt.<br>Single click to expand.</span></span></p><p>The @pgsql agent begins by listing the server connections, connecting to the server ‘postgis’, drafts the script to modify the database and waits for permission to continue before making changes. Database modifications require explicit permission from the user.</p>

<ul>
<li>Simplified connection management for local and cloud-hosted PostgreSQL instances.</li>
<li>Support for multiple connection profiles and connection string parsing for easy setup.</li>
<li>Direct browsing and filtering of Azure Database for PostgreSQL deployments.</li>
<li>Integration with Entra ID for centralized security and identity management.</li>
</ul>
<p><br>Connect with ease to your existing Azure Database for PostgreSQL deployments with the “Browse Azure” option in the “Add New Connection” menu.</p>
<p><span data-image-alt=""><span id="xuwFXK_caption">Figure 5: Connecting to an Azure Database for PostgreSQL instance using the Browse Azure option with Entra ID authentication.<br>Single click to expand.<br></span></span></p>
<p>Connect to local Docker deployments with the Parameters or Connection String option.</p>
<p><span data-image-alt=""><span id="I4WU4K_caption">Figure 6: Connect to PostgreSQL in a local Docker deployment.<br>Single click to expand.<br></span></span></p>
<ul>
<li><strong>Streamlined Authentication:</strong> Eliminates the need for manual login, offering a seamless integration experience for you.</li>
<li><strong>Automatic Token Refresh:</strong> Ensures uninterrupted connectivity and minimizes the risk of authentication timeouts during development.</li>
<li><strong>Enhanced Security:</strong> Provides robust protection by leveraging Entra-ID's secure authentication protocols.</li>
<li><strong>Time Efficiency:</strong> Reduces overhead by automating token management, allowing you to focus on coding rather than administrative tasks.</li>
<li><strong>Enterprise Compatibility:</strong> Aligns with corporate security standards and simplifies access to PostgreSQL databases in enterprise environments.</li>
<li><strong>User Consistency: </strong>You can use your existing Entra-ID credentials, avoiding the need to manage separate accounts.</li>
</ul>

<ul>
<li>Provides a structured view of database objects such as schemas, tables, and functions.</li>
<li>Enables creation, modification, and deletion of database objects.</li>
</ul>
<p><span data-image-alt=""><span id="P6AkPz_caption">Figure 7: View, manage, and query database objects within the Database Explorer.<br>Single click to expand.<br></span></span></p>
<p>Session query history is available below the Object Explorer. This allows you to quickly review previously run queries for reuse.&nbsp;</p>

<p><span data-image-alt=""><span id="5SGWfP_caption">Figure 8: Query History context menu detail.<br>Single click to expand.<br></span></span></p>
<ul>
<li>Context-aware IntelliSense for auto-completion of SQL keywords, table names, and functions.</li>
<li>Syntax highlighting and auto-formatting for improved query readability.</li>
<li>Query history tracking for reusing previously executed queries.</li>
</ul>
<p><span data-image-alt=""><span id="hBMjBs_caption">Figure 9: Query editing with database context-aware IntelliSense.<br>Single click to expand.<br></span></span></p>
<p>The PostgreSQL extension for VS Code stands out in the crowded landscape of developer database management tools due to its unparalleled functionality and intuitive design. Here’s what makes it special:</p>
<ul>
<li><strong>Enhanced Productivity:</strong> Features like context-aware IntelliSense and SQL formatting save time and minimize errors.</li>
<li><strong>pgsql GitHub Copilot Chat agent:</strong> Database and workspace context awareness, enabling smarter and more contextually relevant assistance for developers – combined with the ability to perform multi-step tasks.</li>
<li><strong>Streamlined Onboarding:</strong> The Connection Manager ensures you can get started within minutes.</li>
<li><strong>Improved Security:</strong> Entra ID integration provides robust access control and centralized identity management, including the ability to browse your Azure Database for PostgreSQL instances.&nbsp;</li>
<li><strong>Comprehensive Toolset:</strong> You can manage database objects, execute queries, and deploy instances all within VS Code.</li>
<li><strong>Seamless Cloud Integration:</strong> Deep integration with Azure Database for PostgreSQL simplifies cloud database management.</li>
</ul>

<p><strong>Installing the PostgreSQL extension for VS Code is simple:</strong></p>
<ol>
<li>Open the Extensions view in VS Code.</li>
<li>Search for "PostgreSQL" in the Extensions Marketplace.</li>
<li>Select and install the Preview PostgreSQL extension with the blue elephant seen in the screenshot below.&nbsp;</li>
</ol>
<p><span data-image-alt=""><span id="1B8con_caption">Figure 10: PostgreSQL extension available in the Marketplace. E<span data-teams="true">xtension ID: (ms-ossdata.vscode-pgsql)<br></span></span></span></p><p>Also available in the online <a href="https://marketplace.visualstudio.com/items?itemName=ms-ossdata.vscode-pgsql" target="_blank" rel="noopener noreferrer">Visual Studio Code Marketplace.&nbsp;</a></p>

<p>You will need the GitHub Copilot and GitHub Copilot chat extensions installed in VS Code to be able to log into their GitHub Account and use "@pgsql" in the chat interface to interact with their PostgreSQL database.</p>

<p>We value your insights. Use the built-in feedback tool in VS Code to share your thoughts and report issues. Your feedback will help us refine the extension and ensure it meets the needs of the developer community.</p>

<p>The PostgreSQL extension for VS Code offers significant enhancements to development efficiency and productivity. We encourage you to explore the public preview today and experience improved workflows with PostgreSQL databases.</p>
<p>To learn more and get started, visit: <a href="https://aka.ms/pg-vscode-docs" target="_blank" rel="noopener noreferrer">https://aka.ms/pg-vscode-docs</a></p>

<p><em>Special thanks to <a href="https://www.linkedin.com/in/jjfrost" target="_blank" rel="noopener nofollow noreferrer">Jonathon Frost, Principal PM</a> for all of his work on the @pgsql GitHub Copilot.&nbsp;</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I ended up flying for Yemen's national airline – and survived (114 pts)]]></title>
            <link>https://www.pprune.org/terms-endearment/653181-yemenia-expat-contract-full-info.html</link>
            <guid>44072971</guid>
            <pubDate>Fri, 23 May 2025 14:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pprune.org/terms-endearment/653181-yemenia-expat-contract-full-info.html">https://www.pprune.org/terms-endearment/653181-yemenia-expat-contract-full-info.html</a>, See on <a href="https://news.ycombinator.com/item?id=44072971">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_message_11450527">
						
						<p><span>A carrier which is very rarely mentioned on here, I�m going to give you an insight into what it is like to work for them under one of those famous expat contracts that have floated about here and there in the past. I understand 99% of you will see the advert and simply move on, perhaps with an amused exhale while you scroll down to the flag carrier DEC jobs, but for the 1% of you looking for answers, here you go! </span></p><p>

<span>I�ll start from the beginning:</span></p><p>

<span><u><b>Background</b></u>:</span><br>
<span>So, you made some silly choices in your aviation career, and have found yourself fallen into the contractor bubble, jumping between contracts with various contractors. You don�t see your family as often as you�d like, and it�s far from stable, but the money is great and there is a large variety of flying. </span></p><p>

<span>Your previous contract blew up after just a few weeks and you find yourself now unemployed, bills to pay and a family to look after, when by miracle, a contractor rolls across your path offering a starting-6 month contracting role with Yemenia, LHS of the 320, a high roller 6 figure salary, accommodation, a joining bonus, and all the addons one might expect from this sort of contract. You know that when things seem too good to be true, they usually are, but hindsight is always 20/20, and you reassure yourself at the time that it is a reputable contractor, so don�t think twice about it. </span></p><p>

<span><u><b>Application</b></u>:</span><br>
<span>You throw in a fairly straightforward application, not really expecting to hear back. As with all of these types of contracts, they often die out before they start, and the ones that do get up and running with high salaries are often competitive, so you don�t expect to hear anything back. A few weeks pass, and you�re invited to a few unsociably timed zoom interviews which take place with cameras off and audio that sounds like a 2007 era Call of Duty microphone. The interview process was inexplicably easy, with questions more evolving toward �when can you start� than anything more bus or career specific. Red flags, but it�s all good, you�ve crossed these bridges before when you joined other random carriers in the past and they turned out OK. Eventually they contact you and send you flight details for a trip to Cairo to complete an assessment, no say in the dates, they�ve already made the bookings. Your journey to Cairo involves 2 stops via Frankfurt and Istanbul on an Economy Basic ticket, not exactly an Emirates Suite, but you are grateful that they pick up the tab. They whisk you into the Sofitel Cairo with a blank cheque to drown your sorrows, and where you can socialize with the other 7 expats here for the job, 2 Americans, a Brit, and a handful of continental Europeans, a few faces you�ve seen before too which is always reassuring. </span></p><p>

<span>The sim follows the usual rigmarole, and everybody passes with flying colours, in part due to the Egyption �assessor� not paying attention for 90% of it. A tick in the box, a shake of the hand and you�re sent packing back to Europe with nothing but a verbal promise of being contacted. A few weeks pass by, and eventually you are contacted once again, this time offering you a training start date in just a matter of days, once again taking place in Cairo. Alongside this wonderful news, they will essentially ask you to share a generations worth of info with them, from your stamped logbook pages, to bank statements. Odd, but what do you know. Still no word on signing a contract though, so you hope that will be completed in training, and head on your merry way.</span></p><p>

<span><u><b>Training</b></u>:</span><br>
<span>You kiss the wife and kids goodbye and tell them you�ll see them when you�re back from Yemen in 6 months time. Painful, but it�ll be worth it when you come back with pockets full of cash eh? </span></p><p>

<span>Not best pleased, at least the better half knows you�ll not get up to any funny business in that part of the world. </span></p><p>

<span>So you arrive in Cairo, alongside the other 7 expats who managed to navigate the gruelling selection process and sim assessment, and tuck into a few weeks of training. </span></p><p>

<span>Now, you are reminded of the fatal Yemenia Flight 626 crash back in �09, where the investigation blamed poor crew training, inappropriate actions, and training programmes �riddled with gaps and flaws� for the loss of 152 souls, and reassure yourself that they will have modified their training appropriately.</span></p><p>

<span>Ha! </span></p><p>

<span>What I can only describe as a serious box ticking exercise, interspersed with Death by Powerpoint in what I can only assume was English that had been smashed through Google Translate 6 or 7 times before being released. A few courses that should have been completed at the Yemenia Training Centre in Sana�a are completed virtually due to security reasons, and eventually you finish the course having learned next to nothing, in fact you are convinced you have left with less knowledge than you arrived with, you get some shiny gold wings stamped to your chest, and sent packing to the ancient city of Aden, your new home for the next 6 months. Contract remains non-existent. </span></p><p>

<span><u><b>Relocating</b></u>:</span><br>
<span>Now the fun begins. </span></p><p>

<span>As we haven�t signed contracts yet, we cannot be loaded onto a GENDEC or be provided with company tickets, so they ask you to purchase your own ticket to Aden and it will be reimbursed in your first salary. Oh well, seems like bs but you�ve got this far, how much could it hurt. </span></p><p>

<span>So $130USD later, you find yourself sitting on the 2R Cabin Crew jumpseat of an overbooked 17 year old A320, the inop APU means you are really getting a sweat on in your fancy new uniform which you were forced to wear during the unexplained 5 hour ground delay, and the all male cabin crew who refuse to acknowledge you prefer to smoke Camels in the back galley than do anything productive, thus adding to the already wonderful ambiance. </span></p><p>

<span>Overbooked you say? Wow, they must be doing quite well! No, there are 45 seats with INOP taped on them. No explanation though. </span></p><p>

<span>You peer into the open flight deck to say hello and try to get an understanding on the delay, but the local crew don�t acknowledge you and continue to dab out their cigarette ends into a Coke can jammed in front of the engine master switches. Oh well, must be a bad crew today. </span></p><p>

<span>Eventually though, you land in the historic city of Aden a few hours later than expected. </span></p><p>

<span>Now, Yemen is a country that nearly ALL countries advise against travel too, hell, even the Taliban recommend Afghan nationals don�t travel to Yemen right now. Oh well, the armoured G Wagon that will pick you up from the airport will keep you safe. </span></p><p>

<span>Ha! </span></p><p>

<span>They don�t provide transport, only for duties, so you hail a local 1980�s Toyota Landcruiser and the driver fleeces you for $50USD to drive you 15 minutes to your luxury accommodation. The technology of SAP Concur hasn�t reached these parts yet, so you convince yourself that you�ll talk to somebody in the office about claiming it back.</span></p><p>

<span>You arrive at the accommodation and realise the ##### sandwich you�ve got yourself into. </span></p><p>

<span>Oh and by the way, you�ve still not signed a contract, so as far as anybody is concerned you�re just a random bloke going for a jolly to a war zone. Nothing like a bit of war tourism to boost the local economy. </span></p><p>

<span><u><b>Accommodation</b></u>:</span><br>
<i>�<span>Luxury accommodation, with fully functioning Air Conditioning, a pool, plentiful local attractions and amenities, and 24/7 Private Military Contractors providing security for your safety�. </span></i></p><p>

<span>Now you see they are really playing fast and loose on the word luxury. 10 expats now reside in this 10 room compound out in the middle of nowhere to the NW of the city. High walls and a single gate for entry, it looks like something out of Ross Kemps ventures into Helmand Province. </span></p><p>

<span>But oh well, you crack on anyway, and you�re shown to your room by the first Yemenia rep you�ve met throughout this whole process. Your room consists of a very small single bed, with an old CRT Television propped on a wooden shelf and a mirror on the wall. A single square window with a net protects you from the elements. The washrooms are located in a separate building, as is the kitchen. There�s a single plug socket in the room which is used to power the TV, so you must decide between Yemeni MTV or charging your phone. The kitchen is at least well equipped, and is restocked 3 times per week with all kinds of western goods, like the fridge full of �Orange Mirinda� and �Shani�. There were even a few cans of Budweiser hidden in there, although whether these were officially provided, or sourced by a few of the more experienced expats, you�re not sure. </span></p><p>

<span>Copious amounts of bottled water were provided too, gratefully. </span></p><p>

<span>The washrooms were basic, a few cubicled bogs with a shared shower, alongside a couple of sinks to shave or have a wh*res wash in, very similar to something you�d find at some old relic summer camp. There is a pool, but it�s empty. You come to the conclusion that they didn�t lie, they never said it would be full of water, so they can have the benefit of the doubt on that one. </span></p><p>

<span>There were security guards too, but the term Private Military Contractors has you thinking of the high speed, low drag door kickers whose past lives had them on 22 SAS or one of the SEAL teams. That, they were not. They were the 2002 Manchester United shirt, jeans and flip flops with an AK47 slung over the shoulder kind of contractors. Oh well, they are there, sleeping and high on khat at the gate, but there nonetheless. </span></p><p>

<span>Now for those local attractions and amenities, you soon realise that the nearest civilisation is a petrol station, around 20 minutes walk away, or a 5 minutes drive. </span></p><p>

<span>Since you don�t have a car, your only way of getting anywhere is on foot, and given the dirty civil war waging sporadically in the region, you decide it�s best to forfeit your Chocolate Bar given the risk that you might end up in an orange jumpsuit on Al Jazeera just trying to get it. </span><br>
<span>Contracts:</span></p><p>

<span>After your guided tour of the Love Island villa, the Yemenia rep brings you into a room where he chucks a contract and a biro at you. Once again, the backwards English throws you off, but you see the numbers add up to what was promised and you sign. </span></p><p>

<span>Your 13,500 joining bonus is on the way mister captain. They don�t tell you that it�s 13500 Yemeni Rial, the equivalent of about $50USD though. </span></p><p>

<span>But at least the important figures, salary and duty pay, are clearly in $USD on the contract. </span></p><p>

<span>Oh well! Payday is on the 2nd of each month, so only a week left. </span></p><p>

<span><u><b>How Yemenia Works</b></u>:</span><br>
<span>So there is a 320 crew base in Aden, and one in Seiyun, in addition to a 330 skeleton crew based in Sana�a. </span></p><p>

<span>Aden is the largest base, and the only one with an expat community, this includes cabin crew who are drafted from places such as the Philippines, Venezuela, Ukraine, Cambodia, and other random parts of the world. </span></p><p>

<span>The head office of Yemenia is in the city of Sana�a, which is essentially off limits at the moment due to an escalation in the conflict. This includes the Operations Control Centre and all other relevant teams. In Seiyun there is no Yemenia hard presence, and in Aden there isn't either, but there is a ground team and a station manager. </span></p><p>

<span>The postal system is entirely unreliable in Yemen, so anything that needs to come from Sana�a is generally delivered in person, this includes stuff that could be sent by email because the internet here is also incredibly unreliable. Unfortunately, this does come with risks, one of the couriers had his car blown to bits by a Saudi drone a few weeks back. </span></p><p>

<span>Financially, the company is a bit of mess, nobody really knows where it sits, it hasn�t updated any technology for many centuries, ground staff often need to be negotiated with at outstations to get them to service the aircraft, but the airline say they want to buy some new Airbus�, so who knows. </span></p><p>

<span><b><u>Rostering</u></b>:</span><br>
<span>Like many airlines, Yemenia use one of the major rostering apps, and rosters release 15 days before the end of the month. Even despite the rocket attacks, car bombs, mortars, and intermittent electricity and wifi, they do still manage to get the roster out on time, which is more than I can say for the few European carriers I worked for. </span></p><p>

<span>For expats, the roster is 5/2/5/3, however with regular lengthy delays, you�ll often find yourself flying into your days off with no extra cash or days off in lieu offered. Flying is a mix of 2 and 4 sector days, rarely you�ll get a 3 sector with a stop in Seiyun, but more often than not it�ll be 2 sectors. Becoming AOG is a daily occurrence, but AOG nightstops </span><span>are not</span><span> a thing here, you�ll fly back to Aden regardless of duty hours completed, and you�ll be expected to give up your min rest on occasions where you return late. Your 2000 check out and 0800 report will often become a 2300 check out and an 0800 report because Crew Control/Ops don�t have the facilities to make changes. Sometimes, they won�t even know you�ve arrived, and you�ll be woken up at 0130 to a phone call from Ops asking if you�ve landed in Aden, a duty you completed at 1700. </span></p><p>

<span>Roster changes are regular, however, you don�t often actually see any changes because either Crew Control don�t have any internet or electricity to update your roster, or you�ve not got the internet to receive it. Given the situation in Sana�a, the OCC is generally unreliable, and so major flight info such as delays will often be sent by text from the Aden station manager. </span></p><p>

<span>There is no bidding system of course, and expats are strictly forbidden from flying with each other unless it�s for the purpose of line training. No no, we get to fly with the locals and the EagleJet p2f goons. Don�t get me wrong, some of the locals are really good at their jobs, especially some of the younger FOs who trained abroad, but they are more the exception than the rule. </span></p><p>

<span>If you need to call sick, you try Crew Control, but you�ll likely not get through, so you phone the Aden station manager and just arrange yourself with another pilot to take your place. </span></p><p>

<span><u><b>Aden</b></u>:</span><br>
<span>The safer of the 3 major cities in Yemen, Aden is still home to sporadic fighting. While currently �peaceful�, this isn�t the definition you would find in the West, it�s certainly peaceful compared to 2 years ago, but I wouldn�t say peaceful. The click-clacking of AKs and explosions can still be heard rolling across the city on some days. The city is riddled with checkpoints from various factions. To get to work, your driver takes you on a longer route so you pass only through police and military checkpoints where you�re essentially granted a free pass as you work for Yemenia. Other checkpoints especially heading North, or into the centre of town are less friendly, with different militias setting up their own, and as an employee of Yemenia, and therefore a representative of the Yemeni Government and a Yemeni flag flyer, you�ll quickly be hooded and scooped up for a fun interrogation. Like most towns in these parts of the world, 80% of the locals are lovely people who just want to get on with their lives, some of the older women will treat you as one of their own while you�re so far from home, but despite that there is still a very present and serious danger if you decide to venture out without protection. The airport, the port and Little Aden and At-Tawah which guard the mouth to the port have a heavy military presence which seems, recently, to be working. If you�re in uniform, the police and military will leave you alone, sometimes even escort you where you need to go, if you�re out of uniform, expect some potentially heavy handed questioning. </span></p><p>

<span>There are no consular services from any nation available in Yemen, Sana�a was once home to various embassies including the U.S. and U.K., but these are now closed and operate remotely from Djibouti. If you need consular support, you lose your passport or something, well, quite frankly, you�re f*cked. </span><br>
<span><u><b>Life outside of flying</b></u>:</span><br>
<span>There isn�t much of one. You can�t really venture out of the compound so you find the best spot in the compound for wifi, crack open a few beers and sit in the 40 degree sun doing nothing for 3 days. Sounds good, and it is at first, but the novelty soon wears off. The expat cabin crew compound is about 25 minutes away and they regularly find their way here, since we have the cold amber nectar they desire. </span></p><p>

<span>Some people try and get home for their 3 days off but it is seemingly next to impossible, largely because trying to get on flights out of Aden is like trying to get blood out of a stone, and if you manage, it�ll cost you an arm and a leg. There�s no ID90 around here, just crisp USD that must be dished out to multiple people before you get your ass on a crew jumpseat. Some days you might get lucky, if it�s an expat captain, we all have a gentleman�s agreement that we will let fellow expats jumpseat in the flight deck if they�re on their way to/from home to save any hassle. There�s only way out of Aden for most, and that�s to take a company flight to Cairo and travel onwards from there, alternatively you can fly into Jeddah and go onward from there, but factor in a few extra hours into your connection for a very uncomfortable interrogation in a bright white room about your time in Yemen. Royal Jordanian previously operated an E190 down here but it stopped due to security reasons. Be aware, everytime you leave Yemen, you�ll need an �exit visa�, this is relatively straightforward to obtain though, if you carry your Yemenia ID with you, if all else fails, the Aden station manager will sort you out. While straight forward, it can be a painstakingly long process lasting a few hours sometimes, so consider this before making your way to the airport.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I no longer have an old-school cert on my HTTPS site (131 pts)]]></title>
            <link>https://rachelbythebay.com/w/2025/05/22/ssl/</link>
            <guid>44071690</guid>
            <pubDate>Fri, 23 May 2025 10:56:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2025/05/22/ssl/">https://rachelbythebay.com/w/2025/05/22/ssl/</a>, See on <a href="https://news.ycombinator.com/item?id=44071690">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2025/05/22/ssl/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI: Scaling PostgreSQL to the Next Level (160 pts)]]></title>
            <link>https://www.pixelstech.net/article/1747708863-openai%3a-scaling-postgresql-to-the-next-level</link>
            <guid>44071418</guid>
            <pubDate>Fri, 23 May 2025 09:54:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pixelstech.net/article/1747708863-openai%3a-scaling-postgresql-to-the-next-level">https://www.pixelstech.net/article/1747708863-openai%3a-scaling-postgresql-to-the-next-level</a>, See on <a href="https://news.ycombinator.com/item?id=44071418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article_content_panel">
		<article>
         	<p>At the <a href="https://2025.pgconf.dev/">PGConf.dev 2025</a> Global Developer Conference, <a href="https://bohanzhang.me/#talks">Bohan Zhang</a> from OpenAI shared OpenAI’s best practices with PostgreSQL, offering a glimpse into the database usage of one of the most prominent unicorn companies.</p>
<blockquote>At OpenAI, we utilize an unsharded architecture with one writer and multiple readers, demonstrating that PostgreSQL can scale gracefully under massive read loads.<br>— PGConf.dev 2025, Bohan Zhang from OpenAI</blockquote>
<p><img src="https://www.pixelstech.net/article/images/introduction.png" alt="introduction.png"></p>
<p>Bohan Zhang is a member of OpenAI’s Infrastructure team. He studied under Professor <a href="https://www.cs.cmu.edu/~pavlo/">Andy Pavlo</a> at Carnegie Mellon University and co-founded <a href="https://ottertune.com/">OtterTune</a> with him.</p>
<h3>Background</h3>
<p>PostgreSQL serves as the core database supporting the majority of OpenAI’s critical systems. If PostgreSQL experiences downtime, many of OpenAI’s key services would be directly affected. There have been several instances in the past where issues related to PostgreSQL have led to outages of ChatGPT.</p>
<p><img src="https://www.pixelstech.net/article/images/background.png" alt="background.png"></p>
<p>OpenAI utilizes managed databases on Azure, employing a classic PostgreSQL primary-replica replication architecture without sharding. This setup consists of one primary database and over forty replicas. For a service like OpenAI, which boasts 500 million active users, scalability is a significant concern.</p>
<h3>Challenges</h3>
<p>In OpenAI’s primary-replica PostgreSQL architecture, read scalability is excellent. However, “write requests” have become a major bottleneck. OpenAI has implemented numerous optimizations in this area, such as offloading write loads wherever possible and avoiding the addition of new services to the primary database.</p>
<p><img src="https://www.pixelstech.net/article/images/challenges.png" alt="challenges.png"></p>
<p>PostgreSQL’s Multi-Version Concurrency Control (MVCC) design presents some known issues, including table and index bloat. Tuning automatic garbage collection (vacuuming) can be complex, as each write operation generates a complete new version, and index access may require additional visibility checks. These design aspects pose challenges when scaling read replicas: for example, increased Write-Ahead Logging (WAL) can lead to greater replication lag, and as the number of replicas grows significantly, network bandwidth may become a new bottleneck.</p>
<h3>Measures</h3>
<p>To address these issues, we have undertaken efforts on multiple fronts:</p>
<h4>Controlling Primary Database Load</h4>
<p>The first optimization involves smoothing out write spikes on the primary database to minimize its load. For example:</p>
<ul>
<li>Offloading all possible write operations.</li>
<li>Avoiding unnecessary writes at the application level.</li>
<li>Using lazy writes to smooth out write bursts.</li>
<li>Controlling the frequency during data backfilling.</li>
</ul>
<p>Additionally, OpenAI strives to offload as many read requests as possible to replicas. For read requests that cannot be removed from the primary database due to being part of read-write transactions, high efficiency is required.</p>
<p><img src="https://www.pixelstech.net/article/images/control-loading.png" alt="control-loading.png"></p>
<h4>Query Optimization</h4>
<p>The second optimization focuses on the query layer. Since long transactions can hinder garbage collection and consume resources, timeouts are configured to avoid long “Idle in Transaction” sessions, with timeouts set at the session, statement, and client levels. Furthermore, complex multi-join queries (e.g., joining 12 tables at once) have been optimized. The presentation also specifically mentioned that using ORM can easily lead to inefficient queries and should be used cautiously.</p>
<p><img src="https://www.pixelstech.net/article/images/query_optimization.png" alt="query_optimization.png"></p>
<h4>Addressing Single Points of Failure</h4>
<p>The primary database is a single point of failure; if it goes down, write operations cannot proceed. In contrast, we have many read-only replicas; if one fails, applications can still read from others. In fact, many critical requests are read-only, so even if the primary database fails, they can continue to read from it.</p>
<p>Moreover, we differentiate between low-priority and high-priority requests. For high-priority requests, OpenAI allocates dedicated read-only replicas to prevent them from being affected by low-priority requests.</p>
<p><img src="https://www.pixelstech.net/article/images/single_point_failure.png" alt="single_point_failure.png"></p>
<h4>Schema Management</h4>
<p>The fourth measure is to only allow lightweight schema changes on this cluster. This means:</p>
<ul>
<li>Creating new tables or introducing new workloads is not permitted.</li>
<li>Adding or removing columns is allowed (with a 5-second timeout), but any operation requiring a full table rewrite is not allowed.</li>
<li>Creating or removing indexes is permitted but must use the CONCURRENTLY option.</li>
</ul>
<p>Another issue mentioned is that long-running queries (&gt;1s) during operation can continuously block schema changes, ultimately causing them to fail. The solution is to have the application optimize or offload these slow queries.</p>
<h3>Results</h3>
<ul>
<li>Scaled Azure-hosted PostgreSQL to handle over one million QPS (combined read and write) across the entire cluster, supporting OpenAI’s critical services.</li>
<li>Added dozens of replicas (approximately 40) without increasing replication lag.</li>
<li>Deployed read-only replicas across different geographic regions while maintaining low latency.</li>
<li>Experienced only one PostgreSQL-related SEV0 incident in the past nine months.</li>
<li>Reserved ample capacity for future growth.</li>
</ul>
<h3>Incident Cases</h3>
<p>OpenAI also shared several case studies of issues encountered:</p>
<ul>
<li>The first case involved a cache failure leading to a cascading effect. <br><img src="https://www.pixelstech.net/article/images/1st-incident.png" alt="1st-incident.png"></li>
<li>
<p>The second incident was particularly interesting: under extremely high CPU usage, a bug was triggered where, even after CPU levels normalized, the WALSender process continued spinning in a loop instead of properly sending WAL logs to replicas, resulting in increased replication lag.<br><img src="https://www.pixelstech.net/article/images/2nd-incident.png" alt="2nd-incident.png"></p>
</li>
</ul>
<h3>Feature Requests</h3>
<p>Finally, Bohan presented several issues and feature requests to the PostgreSQL developer community:</p>
<ol>
<li>
<p>Regarding index management: unused indexes can lead to write amplification and additional maintenance overhead. OpenAI wishes to remove unnecessary indexes but, to minimize risk, they propose a “Disable” feature for indexes. This would allow monitoring performance metrics to ensure stability before permanently dropping the index.</p>
</li>
<li>
<p>On observability: currently, <code>pg_stat_statements</code> provides only average response times per query type, lacking direct access to p95 and p99 latency metrics. They hope for more metrics akin to histograms and percentile latencies.</p>
</li>
<li>
<p>Concerning schema changes: they desire PostgreSQL to record a history of schema change events, such as adding or removing columns and other DDL operations.</p>
</li>
<li>
<p>Monitoring view semantics: they observed a session with <code>state = Active</code> and <code>wait_event = ClientRead</code> persisting for over two hours. This indicates a connection remained active for an extended period post-QueryStart, and such connections cannot be terminated by <code>idle_in_transaction</code> timeouts. They seek to understand if this is a bug and how to address it.</p>
</li>
<li>
<p>Lastly, they suggest optimizing PostgreSQL’s default parameters, noting that the current default values are overly conservative. They inquire whether better defaults or heuristic-based settings could be implemented.</p>
</li>
</ol>
<h3>Lao Feng’s Comments</h3>
<p>Although PGConf.Dev 2025 primarily focuses on development, there are often user-side use case shares as well—like OpenAI’s scalability practices with PostgreSQL. Topics like this are actually quite interesting to core developers, since many of them have no concept of how PostgreSQL is used in extreme real-world scenarios.</p>
<p>Since the end of 2017, Lao Feng managed dozens of PostgreSQL clusters at Tantan, which was one of the largest and most complex deployments in China’s internet sector at the time: dozens of PostgreSQL clusters handling around 2.5 million QPS. Back then, their largest core cluster used a master with 33 replicas and carried around 400,000 QPS. The bottleneck was also on single-node write performance, which they eventually addressed through database and table sharding on the application side.</p>
<p>You could say that the issues encountered and the solutions applied in OpenAI’s talk were all things they’ve dealt with before. Of course, what’s different now is that today’s top-tier hardware is way more powerful than it was eight years ago. That allows a startup like OpenAI to use a single PostgreSQL cluster—without sharding or partitioning—to serve their entire business. This undoubtedly serves as another strong piece of evidence for the idea that “distributed databases are a false need.”</p>
<p>OpenAI uses managed PostgreSQL on Azure, with top-tier server specs. The number of replicas reaches over 40, including some cross-region replicas. This massive cluster handles around 1 million QPS (read + write) in total. They use Datadog for monitoring, and their services access the RDS cluster through application-side PgBouncer connection pooling from within Kubernetes.</p>
<p>Since OpenAI is a strategic-level customer, the Azure PostgreSQL team provides very hands-on support. But clearly, even with top-tier cloud database services, users still need strong awareness and capabilities on the application and operations side. Even with the brainpower of OpenAI, they still run into pitfalls in PostgreSQL operations in practice.</p>
<p>High availability wasn’t discussed in this talk, so we can assume that’s handled by Azure PostgreSQL RDS. Meanwhile, monitoring is critical for system ops. OpenAI uses Datadog to monitor PostgreSQL—and even with OpenAI’s financial resources, they still feel that Datadog is ridiculously expensive.</p>
<p>After the conference, during the evening social event, Lao Feng had a long chat into the early hours with Bohan and two other database founders. The private conversation was very engaging, though Lao Feng couldn’t reveal more details—haha.</p>
<p><img src="https://www.pixelstech.net/article/images/social.png" alt="social.png"></p>
<h3>Lao Feng Q&amp;A</h3>
<p>Regarding the issues and feature requests raised by Bohan, Lao Feng offers some answers here. In fact, most of the functionality OpenAI is looking for already exists within the PostgreSQL ecosystem—it just might not be available in the core PostgreSQL or on Azure RDS.</p>
<h4>On Disabling Indexes</h4>
<p>PostgreSQL actually does have a feature to disable indexes. You can simply set the indisvalid field to false in the pg_index system catalog. This makes the planner ignore the index, although it will still be maintained during DML operations. From a technical standpoint, this is totally fine—this is the same mechanism used during concurrent index creation via the isready and isvalid flags. It’s not black magic.</p>
<p>That said, it’s understandable why OpenAI can’t use this method—RDS doesn’t grant superuser permissions, so you can’t modify system catalogs directly to achieve this.</p>
<p>But going back to the original goal—avoiding accidental deletion of indexes—there’s a simpler solution: just confirm via monitoring views that the index is not being used on either primary or replicas. If it hasn’t been accessed for a long time, it’s safe to delete.</p>
<p>Using the Pigsty monitoring system, you can observe the process of live index switching for PGSQL tables.</p>
<p><img src="https://www.pixelstech.net/article/images/monitoring.png" alt="monitoring.png"></p>
<pre><code>CREATE UNIQUE INDEX CONCURRENTLY pgbench_accounts_pkey2
ON pgbench_accounts USING BTREE(aid);

-- Mark the original index as invalid (won’t be used) but still maintained
UPDATE pg_index SET indisvalid = false
WHERE indexrelid = 'pgbench_accounts_pkey'::regclass;</code></pre>
<h4>On Observability</h4>
<p>pg_stat_statements likely won’t provide P95 or P99 percentile metrics anytime soon, as this would drastically increase the memory footprint of the extension—maybe dozens of times. While modern servers could handle it, extremely conservative environments might not. I asked the maintainer of pg_stat_statements about this and it’s unlikely to happen. I also asked Jelte, the maintainer of pgbouncer, and such functionality is also unlikely in the short term.</p>
<p>But the issue can be addressed. First, the pg_stat_monitor extension does provide detailed percentile latency (RT) metrics and would certainly work, though you’ll need to consider the performance overhead of collecting such metrics. A second option is using eBPF to passively collect RT metrics, and of course, the simplest way is to add query latency monitoring directly in the application’s data access layer (DAL).</p>
<p>The most elegant solution might be eBPF-based side-channel collection, but since they’re using Azure’s managed PostgreSQL without server access, this option is probably off the table.</p>
<h4>On Schema Change History</h4>
<p>Actually, PostgreSQL logs already offer this capability—just set log_statement to ddl (or more verbosely, mod or all), and all DDL statements will be logged. The pgaudit extension provides similar capabilities.</p>
<p>But I suspect what they really want is not logs, but a system view that can be queried via SQL. In that case, another option is to use CREATE EVENT TRIGGER to log DDL events directly into a data table. The pg_ddl_historization extension provides a much easier way to do this, and I’ve already compiled and packaged this extension.</p>
<p>However, creating event triggers also requires superuser privileges. AWS RDS has some special handling that makes this possible, but Azure’s PostgreSQL doesn’t seem to support it.</p>
<h4>On the Semantics of Monitoring Views</h4>
<p>In OpenAI’s example, State = Active means the backend process is still within the lifecycle of a single SQL statement—it hasn’t sent a ReadyForQuery message to the frontend yet, so PostgreSQL still considers the statement “not yet finished.” As a result, resources like row locks, buffer pins, snapshots, and file handles are still considered “in use.” WaitEvent = ClientRead means the process is waiting for input from the client. When both appear together, a typical case is an idle COPY FROM STDIN, but it could also be due to TCP blocking or being stuck between BIND and EXECUTE. So it’s hard to say definitively whether it’s a bug—it depends on what the connection is actually doing.</p>
<p>Some might argue that waiting for client I/O should count as “idle” from a CPU perspective. But State tracks the execution state of the statement, not whether the process is actively using the CPU. A query can be in the Active state while not running on CPU (when WaitEvent is NULL), or it can be looping on CPU waiting for client input (i.e., ClientRead).</p>
<p>Back to the core issue—there are ways to address it. For example, in Pigsty, when PostgreSQL is accessed via HAProxy, the primary service has a maximum connection lifespan (e.g., 24 hours) set at the load balancer level. In more stringent environments, this can be as short as one hour. This means connections exceeding the lifespan are terminated. Ideally, though, the client-side connection pool should proactively enforce connection lifetimes instead of being forcibly disconnected. For offline, read-only services, this timeout isn’t needed—allowing for long-running queries that may last for days. This approach provides a safety net for cases where a connection is Active but waiting on I/O.</p>
<p>That said, it’s unclear whether Azure PostgreSQL offers this kind of control.</p>
<h4>On Default Parameters</h4>
<p>PostgreSQL’s default parameters are extremely conservative. For example, it defaults to just 256 MB of memory (and can be set as low as 256 KB!). The upside is that PostgreSQL can start and run in virtually any environment. The downside? I’ve seen a production setup with 1 TB of physical memory still running with the default 256 MB configuration… (Thanks to double buffering, it actually ran for quite a while.)</p>
<p>Overall, I think conservative defaults aren’t a bad thing. This issue can be solved with more flexible dynamic configuration. Services like RDS and Pigsty offer well-designed heuristics for initial parameter tuning, which already solves this problem quite well. That said, this feature could still be built into PostgreSQL command-line tools—e.g., during initdb, the tool could auto-detect CPU, memory, disk size and type, and set sensible defaults accordingly.</p>
<h4>Self-Hosting?</h4>
<p>The real challenges in OpenAI’s setup don’t stem from PostgreSQL itself, but rather the limitations of using managed PostgreSQL on Azure. One solution would be to bypass those restrictions by using Azure or another cloud’s IaaS layer to deploy self-hosted PostgreSQL clusters on local NVMe SSD instances.</p>
<p>In fact, <a href="https://pigsty.io/">Pigsty</a> was built by Lao Feng specifically to address PostgreSQL challenges at this scale—it’s essentially a self-hosted RDS solution, and it scales well. Many of the problems OpenAI has encountered—or will encounter—already have solutions implemented in Pigsty, which is open-source and free.</p>
<p>If OpenAI is interested, I’d be happy to offer some help. That said, when a company is scaling as fast as they are, tweaking database infrastructure might not be a top priority. Fortunately, they’ve got some excellent PostgreSQL DBAs who can keep pushing forward and exploring these paths.</p>
<p><strong>The article is authorized by <a href="https://x.com/RonVonng">Lao Feng</a> to translate and republish here. the original link is at </strong><a href="https://mp.weixin.qq.com/s/ykrasJ2UeKZAMtHCmtG93Q"><strong>https://mp.weixin.qq.com/s/ykrasJ2UeKZAMtHCmtG93Q</strong></a></p>		 </article>
     </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Carmack talk at Upper Bound 2025 – slides and notes (393 pts)]]></title>
            <link>https://twitter.com/ID_AA_Carmack/status/1925710474366034326</link>
            <guid>44070042</guid>
            <pubDate>Fri, 23 May 2025 05:14:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ID_AA_Carmack/status/1925710474366034326">https://twitter.com/ID_AA_Carmack/status/1925710474366034326</a>, See on <a href="https://news.ycombinator.com/item?id=44070042">Hacker News</a></p>
Couldn't get https://twitter.com/ID_AA_Carmack/status/1925710474366034326: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[The Copilot Delusion (244 pts)]]></title>
            <link>https://deplet.ing/the-copilot-delusion/</link>
            <guid>44068525</guid>
            <pubDate>Fri, 23 May 2025 00:15:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deplet.ing/the-copilot-delusion/">https://deplet.ing/the-copilot-delusion/</a>, See on <a href="https://news.ycombinator.com/item?id=44068525">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        
<h3 id="chapter-1-my-coworker-the-programmer">Chapter 1: My Coworker, The Programmer</h3>
<p>A shell of a man—more of a parrot than a person. My boss, a true believer in the sacred rite of Pair Programming, chained myself and this "programmer"-colleague together like conjoined twins from different planets. We shared a keyboard, but not a brain. Lord, not even close.</p>
<p>"Hold up. I’ve got an idea. Gimme the keyboard real quick."</p>
<p>An idea. Yes. The same way a toddler has “an idea” to stick a fork in a wall socket. I was halfway through constructing something beautiful—a lean, elegant piece of logic that sliced through complexity like a blade through butter—and here he comes, pounding the keyboard like it owes him money, pasting in code he <em>Frankensteined</em> from a stack overflow comment written by an Uncle Bob disciple in 2014.</p>
<p>Did he know what our system did? No.<br>Did he read the ticket? <em>Absolutely fucking not</em>.<br>Did he feel confident mutating global state with reckless abandon? <em>He absolutely fucking did</em>.</p>
<hr>
<p>I’m doing some refactoring. Tightening the bolts, cleaning up component trees, re-aligning the chakras of the system.</p>
<p>Suddenly:<br>"Hey, I added a <code>useEffect</code> that refetches everything when <em>anything</em> changes. Cool, right?"</p>
<p>"Why?" I ask, blinking like a hostage on a tape sent home from a military operation gone wrong.</p>
<p>"It fixed the thing," he says. "Where the thing wasn’t working. It's a working thing now."</p>
<p>A chaos monkey disguised as a teammate. No tests. No profiling. No understanding of side effects or performance impact. Just blind clicking and tapping and typing. The programming equivalent of punching your TV to make the static stop.</p>
<p>And he did this with <em>everyone</em>. A one-man bug factory. Whispering half-formed solutions into the ears of juniors like a sick, twisted full-stack Rasputin. Apparently, friendly fire will be tolerated.</p>
<hr>
<p>The system explodes. Nothing deploys. The UI is frozen like the vegetables in my freezer I was supposed to defrost 8 years ago. And where is my dear co-pilot?</p>
<p>Nowhere.</p>
<p>He’s vanished—probably reading about a shiny new JS framework he’ll try to shove down my throat next week. Meanwhile, I’m left spelunking through callback hell with a flashlight made of regret.</p>
<p>My boss corners me.<br>"Why aren’t you pairing more with him? He types <em>twice</em> as fast as you."</p>
<p>Of course he does. So does a cat having a seizure on a mechanical keyboard. But that doesn’t mean it should be writing production code.</p>
<hr>
<p>I kept pushing myself—learning infrastructure, refining my mental models, sweating over trade-offs. And him? He googled. He skimmed. He pasted. Occasionally he’d show off a clever trick—half-correct, contextless—and the team would ooh and aah like cavemen discovering fire.</p>
<p>And I got lazy. Of course I did. When the system forces you to code with a hallucinating clown, eventually you stop resisting. You let him type. You let him be "productive." You check out. You surrender your brain to the noise and just float.</p>
<hr>
<p><strong>Captain Obvious is here to Save the Day.</strong><br>I wasn’t talking about a programmer. I was describing GitHub Copilot. Or Claude Codex. Or OpenAI lmnop6.5 ultra watermelon.</p>
<p>This isn’t about tools or productivity or acceleration. It’s about the <em>illusion</em> of progress. Because if that programmer—if that <em>thing, that CREATURE</em>—walked into your stand-up in human form, typing half-correct garbage into your codebase while ignoring your architecture and disappearing during cleanup, you’d fire them before they could say "no blockers".</p>
<p>But slap Microsoft's marketing label on it and plug it into the IDE of every developer in the org? Now <em>that’s innovation. Science. Progress. Profit.</em></p>
<p>A real copilot, on a commercial airline? They know the plane. The systems. They’ve done the simulations. They go through recertification. When they speak, it’s to <em>enhance</em> the pilot—not to shotgun random advice into the cockpit and eject themselves mid-flight.</p>
<p>Copilot isn’t that. It’s just the ghost of a thousand blog posts and cocky stack-overflow posts whispering, "<em>Hey, I saw this once. With my eyes. Which means it's good code. Let’s deploy it."</em> Then vanishing when the app hits production and the landing gear won’t come down.</p>
<p>If you let that ghost fly the plane, you deserve the ball of flames you go up in.</p>

<h3 id="chapter-2-the-props">Chapter 2: The Props</h3>
<p>Let’s get one thing straight before I resume torching this synthoid hellspawn with the fury of the sun: <strong>it ain’t all bad</strong>.</p>
<p>Even the grifter at the poker table with a booze lobotomy occasionally hits a flush. And Copilot? Well, sometimes it knows a thing or two.</p>
<p>You’re young. You’ve never touched C++. You’re staring at the syntax like it’s some Martian cave painting. You ask the oracle for help and boom—there it is. Templates, smart pointers, range-based for-loops—syntactically pristine, like it slithered straight out of Bjarne’s brain and onto your screen.</p>
<p>Of course, it doesn’t know the edge cases. It won’t whisper, "Hey—<code>shared_ptr</code> might leak if you get clever and toss raw pointers into the mix like a maniac." It doesn’t point you to the holy scrolls where veterans debate exception guarantees like theologians dissecting scripture. But if you already know what you want and just need the incantation, it’s a better, quicker scribe than most human interns—and it doesn’t complain when you ask it to write template metaprogramming code at 3 a.m.</p>
<hr>
<p>Now let’s say you’re doing <em>real programming work</em>—system design. Big-boy decisions. Infrastructure. The kind of thing that requires a spine and an encyclopedic knowledge of the ByteByteGo YouTube channel. You lay out your plan like a general before a war: here’s the ingress, here’s the queue, here’s the cache invalidation policy that might just kill us all.</p>
<p>Then you ask Copilot, "Hey, what’s going to break?"</p>
<p>Suddenly, it’s rattling off weaknesses like a security auditor. Maybe half of them are dumb. Maybe some are duplicated. But it dumped the brainstorm faster than your junior ever could, and now you’ve got the ammo to write a spec that makes you look like you crank your hog with Martin Kleppmann himself.</p>
<hr>
<p>Sometimes you’re just tired. Not mentally dead, but running low—your brain’s in "turning-object-into-a-string" mode. You don’t <em>need</em> help. You just don’t want to rotate the matrix in your skull like you’re solving a Rubik’s Cube made of jelly.</p>
<p>So you say, "Hey, I’ve got this C# object and I want a LINQ query that groups it by field X, sums Y, and filters Z."</p>
<p>Copilot answers like a weird little gremlin slave creature with a clipboard: <em>"Done, boss."</em></p>
<p>You don’t trust it. You check it line by line. But still—you didn’t have to juggle twenty method chains in your head, and that buys you time to think about actual problems.</p>
<hr>
<p>Maybe you’re reading some dense mathematical whitepaper, the kind written by deranged mathematicians with PhDs and no regard for human sanity. You don’t have the energy to transmute this LaTeX-laden elder scroll into code. Copilot takes a swing and gives you a half-baked pseudocode scaffold. Garbage? Maybe. But garbage you can build on. You handle the performance tuning, the SIMD, the low-level grit. It just gave you the scaffolding to stack explosives on.</p>
<hr>
<p>Maybe you inherited someone else’s codebase. A minefield of nested closures, half-commented hacks, and variable names like <code>d</code> and <code>foo</code>. A mess of complex OOPisms, where you have to traverse 18 files just to follow a single behaviour. You don’t have all day. You need a flyover—an aerial view of the warzone before you land and start disarming traps.</p>
<p>Ask Copilot: "<em>What’s this code doing?"</em><br>It won’t be poetry. It won’t necessarily provide a full picture. But it’ll be <em>close enough</em> to orient yourself before diving into the guts.</p>
<hr>
<p>So—props where props are due<strong>.</strong> Copilot is like a greasy, high-functioning but practically poor intern:</p>
<ul><li>Great with syntax memory.</li><li>Surprisingly quick at listing out your blind spots.</li><li>Good at building scaffolding if you feed it the exact right words.</li><li>Horrible at nuance.</li><li>Useless without supervision.</li><li>Will absolutely kill you in production if left alone for 30 seconds.</li></ul>
<p>Now, let’s go back to setting it on fire.</p>

<h3 id="chapter-3-you-as-a-programmer">Chapter 3: You as a Programmer</h3>
<div><p>First things first: I like to code. Not supervise. Not hover over a synthetic lobotomized chatbot like some drooling silicon intern trying to remember what <code>std::move</code> actually <em>does</em>. I don’t want to be the meatbag middle-manager reviewing some neural net’s fever dream of a <code>switch</code> statement. I want to build shit. Real shit. Weird shit. Systems that are *on fire* type shit.</p><p>"But I just use AI for boilerplate!" you whimper, clutching your Co-Pilot subscription. Listen to yourself. If you’re writing the same boilerplate every day like some industrial-age cog monkey, automate it <em>yourself</em>. Write a library. Invent a macro. Reclaim some dignity. If AI’s doing your "boring parts", what exactly is <em>left</em> for you to do? Fidget with sliders? Paint by numbers while the inference works it's magic?</p></div>
<p>And let’s not ignore the FOMO goblins. I see you. Pounding Monster energy at 2 A.M., telling yourself you’re "building the future" while you slap together some Frankenstein CRUD app with a bot spoon-feeding you syntax it scraped from 2016 GitHub. It's buggy. It's ugly. You didn't even give it a once over before you posted that video to Twitter. "I’m just moving fast!" you say. Yeah—straight off a cliff, like a lemming. AI isn’t helping you build something novel. It can’t. It only knows what’s been done before. It’s autocomplete with a superiority complex.</p>
<p>You want real connection to code? You <em>earn</em> that. You dig in. You wrestle with segfaults at 3 in the morning. You pace your apartment muttering about pointer arithmetic. You burn through Handmade Hero until you <em>get it</em>. You write your own damn notes instead of snapping lecture slides and pretending it counts. When you outsource the thinking, you outsource the learning. You become a conduit for a mechanical bird regurgitating it's hunt directly into your baby-bird mouth. You don’t <em>know</em> your code. You’re babysitting it.</p>
<p>Let’s talk about the quality of your code, too—because it ain’t getting better. Most engineers already write bloated, abstracted, glacial code that burns CPU cycles like a California wildfire. Clean code? Ha! You’re writing for <em>other programmers’</em> academic circlejerk, not the hardware. You’ve forgotten that the machine matters. AI has no concept of memory locality. No intuition for cache misses. It won’t unroll a loop or spot the false sharing in your atomic struct. It’s trained on code that’s already an insult to silicon.</p>
<p>The problem isn’t just laziness. It’s <em>degradation</em>. Engineers stop exploring. Stop improving. Stop <em>caring</em>. One more layer of abstraction. One more lazy fetch call inside a render loop. Eventually, you’re living in a cathedral of technical debt, and every user pays—milliseconds at a time, each click a tax on your apathy.</p>
<p>And the "copilot" branding. A real copilot? That’s a peer. That’s a certified operator who can fly the bird if you pass out from bad taco bell. They train. They practice. They review checklists <em>with you</em>. GitHub Copilot is more like some guy who played Arma 3 for 200 hours and thinks he can land a 747. He read the manual once. In Mandarin. Backwards. And now he’s shouting over your shoulder, "Let me code that bit real quick, I saw it in a Slashdot comment!"</p>
<p>At that point, you’re not working with a copilot. You’re playing Russian roulette with a loaded dependency graph.</p>
<p>You want to be a real programmer? Use your head. Respect the machine. Or get out of the cockpit.</p>
<h3 id="chapter-4-the-computer-as-a-machine"><br>Chapter 4: The Computer as a Machine</h3>

<p>Listen. You’re human. Soft flesh, rotting teeth, synapses pissing electrical signals at each other motivated by caffeine and spite. But <em>you</em>—at your most frazzled, sleep-deprived, raccoon-eyed best—you can <em>try</em>. You can squint at the layers of abstraction and <em>see through them</em>. Peel back the nice ergonomic type-safe, pure, lazy, immutable syntactic sugar and imagine the mess of assembly the compiler pukes up. You can <em>feel</em> the cache lines like a sixth sense. You know where the data wants to be. And where the silicon gets angry when you screw that up.</p>
<p>The machine is real. The silicon is real. The DRAM, the L1, the false sharing, the branch predictor flipping a coin—it’s all real. And if you care, you <em>can</em> work with it. You can make your programs slither through memory like a steel serpent with little to no overhead. You can tee up prefetches with finesse. You can hand-roll an allocation strategy that makes malloc look like child's play. You can know—actually <em>know</em>—when it’s time to crack your knuckles and write a few lines of filthy, yet beautiful inline assembly to directly inject steroids into your program's shiny cheeks.</p>
<p>But the bot? The <em>bot</em>? The bot has no clue.</p>
<p>The bot has <em>zero</em> understanding. It can’t tell a page fault from a paper cut. It’ll hallucinate a memory model like I hallucinate after 2 days of no sleep. It can’t profile. It can’t understand a flamegraph. It can’t feel the cold burn of wasted CPU cycles on a hot loop. It’ll copy the advice of a sweaty stranger from an ‘08 StackOverflow thread who was benchmarking on a Pentium 4 with 512MB of RAM and a dream. It will say, "This is optimal", like it knows anything. Like it’s <em>seen</em> a cache miss. It hasn’t. You have.</p>
<p>The thing will feed you trash. It’ll feed you fake wisdom from fake people and beg you to trust it. But if you want to make a fast, beautiful system—if you want to sculpt the kind of software that gets embedded in pacemakers and missile guidance systems and M1 tanks—you better throw that bot out the airlock and <em>learn</em>.</p>
<p>You build taste by <em>doing</em>. By hurting. By shaving nanoseconds with surgical tools. By writing a routine on Monday, rewriting it Tuesday, and realizing Wednesday it still sucks. You don’t build taste by asking the MS Clippy of 2025 how to do your job.</p>
<p>We are, in the long arc of computing history, still covered in dirt, yanking our bits around with ploughs. We ride <em>horses</em>. But some of us—the ones with blown-out eyeballs and scorched keyboards—some of us know how to build the next thing. Trains. Speedboats. Hypersonic jets of pure code.</p>
<p>And the ones who keep using AI like it’s a divine oracle? They’ll be out there trying to duct-tape horses to an engine block, wondering why it doesn’t fly. Saying, "Hey. It's still not flying. ... ... ... Still not flying. ... ... ... Still doesn't fly fix it please.".</p>
<h3 id="chapter-5-conclusion"><br>Chapter 5: Conclusion</h3>
<p><br>The thing I hate the most about AI and it's ease of access; the slow, painful death of the hacker soul—brought not by war or scarcity, but by convenience. By <em>buttons</em>. By bots.</p>
<p>The real horror isn’t that AI will take our jobs—it’s that it will <em>let</em> people in who never wanted the job to begin with. Vampires with SaaS dreams and Web3 in their LinkedIn bio. Empty husks who see the terminal not as a frontier, but as a shovel for digging up VC money. They’ll drool over their GitHub Copilot like it’s the holy spirit of productivity, pumping out React CRUD like it’s oxygen. They'll fork VS Code yet again, just to sell the same dream to a similarly deluded kid.</p>
<p>There was once magic here. There was once <em>madness</em>.</p>
<p>Kids would stay up all night on IRC with bloodshot eyes, trying to render a cube in OpenGL without segfaulting their future. They <em>cared</em>. They would install Gentoo on a toaster just to see if it’d boot. They knew the smell of burnt voltage regulators and the <em>exact</em> line of assembly where Doom hit 10 FPS on their calculator. These were *artists*. They wrote code like jazz musicians—full of rage, precision, and divine chaos.</p>
<p>Now? We’re building a world where that curiosity gets lobotomized at the door. Some poor bastard—born to be great—is going to get told to "review this AI-generated patchset" for eight hours a day, until all that wonder calcifies into apathy. The terminal will become a spreadsheet. The debugger a coffin.</p>
<p>Because <em>you don’t know what you don’t know</em>. That’s the cruel joke. We’ll fill this industry with people who <em>think</em> they’re good, because their bot passed CI. They'll float through, confident, while the real ones—the hungry ones—get chewed up by a system that doesn’t value understanding anymore. Just output. Just tokens per second.</p>
<p>And what’s worse, we’ll normalize this mediocrity. Cement it in tooling. Turn it into a best practice. We'll enshrine this current bloated, sluggish, over-abstracted hellscape as the <em>pinnacle</em> of software—and the idea of squeezing every last drop of performance out of a system, or building something lean and wild and precise, will sound like <em>folklore</em>.</p>
<p>If that happens? If the last real programmers are drowned in a sea of button-clicking career-chasers—then I pity the smart outsider kids to come after me.</p>
<p>Defer your thinking to the bot, and we all rot.</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of Flatpak (280 pts)]]></title>
            <link>https://lwn.net/Articles/1020571/</link>
            <guid>44068400</guid>
            <pubDate>Thu, 22 May 2025 23:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1020571/">https://lwn.net/Articles/1020571/</a>, See on <a href="https://news.ycombinator.com/item?id=44068400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="https://lwn.net/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</p></blockquote>

<p>At the <a href="https://linuxappsummit.org/">Linux Application
Summit</a> (LAS) in April, Sebastian Wick said that, by many metrics, <a href="https://flatpak.org/">Flatpak</a> is doing great. The Flatpak
application-packaging format is popular with upstream developers, and
with many users. More and more applications are being published in the
<a href="https://flathub.org/">Flathub</a> application store, and the
format is even being adopted by Linux distributions like
Fedora. However, he worried that work on the Flatpak project itself
had stagnated, and that there were too few developers able to review
and merge code beyond basic maintenance.</p>

<p>I was not able to attend LAS in person or watch it live-streamed,
so I watched the YouTube <a href="https://www.youtube.com/watch?v=3HkYJ7M119I">video</a> of the
talk. The slides are available from the <a href="https://conf.linuxappsummit.org/event/7/contributions/219/">talk
page</a>. Wick is a member of the GNOME Project and a Red Hat employee
who works on "<q>all kinds of desktop plumbing</q>", including Flatpak
and <a href="https://flatpak.github.io/xdg-desktop-portal/">desktop
portals</a>.</p>

<h4>Flatpak basics</h4>

<p>Flatpak was <a href="https://github.com/flatpak/flatpak/wiki/Flatpak%27s-History">originally
developed</a> by Alexander Larsson, who had been working on similar
projects stretching back to 2007. The <a href="https://help.gnome.org/misc/release-notes/3.18/developers.html.en#:~:text=Sandboxed%20Applications">first
release</a> was as XDG-App in 2015. It was renamed to Flatpak in 2016,
a nod to IKEA's "<a href="https://www.ikea.com/ph/en/this-is-ikea/about-us/the-story-of-ikea-flatpacks-puba710ccb0/">flatpacks</a>"
for delivering furniture.</p>

<p>The Flatpak project provides <a href="https://docs.flatpak.org/en/latest/flatpak-command-reference.html#flatpak">command-line
tools</a> for managing and running Flatpak applications, tools for <a href="https://docs.flatpak.org/en/latest/flatpak-builder-command-reference.html">building
Flatpak bundles</a>, and <a href="https://docs.flatpak.org/en/latest/available-runtimes.html">runtimes</a>
that provide components for Flatpak applications. The project uses <a href="https://lwn.net/Articles/603762/">control groups</a>, <a href="https://lwn.net/Articles/531114/">namespaces</a>,
<a href="https://lwn.net/Articles/281157/">bind mounts</a>, <a href="https://lwn.net/Articles/332974/">seccomp</a>, and <a href="https://github.com/containers/bubblewrap?tab=readme-ov-file#bubblewrap">Bubblewrap</a>
to provide application isolation ("sandboxing"). Flatpak content is 
primarily delivered using <a href="https://ostreedev.github.io/ostree/introduction/">OSTree</a>,
though support for using <a href="https://github.com/opencontainers/distribution-spec/">Open
Container Initiative (OCI) images</a> has been <a href="https://opencontainers.org/posts/blog/2018-11-07-bringing-oci-images-to-the-desktop-with-flatpak/">available</a>
since 2018 and is used by Fedora for its Flatpak applications. The "<a href="https://docs.flatpak.org/en/latest/under-the-hood.html">Under
the Hood</a>" page from Flatpak's documentation provides a good
overview of how the pieces fit together.</p>

<h4>Slowing development</h4>

<p>Wick started his talk by saying that it looks like everything is
great with the Flatpak project, but if one looks deeper, "<q>you will
notice that it's not being actively developed anymore</q>". There are
people who maintain the code base and fix security issues, for
example, but "<q>bigger changes are not really happening
anymore</q>". He said that there are a bunch of merge requests for new
features, but no one feels responsible for reviewing them, and that is
kind of problematic.</p>

<!-- middle-ad -->

<p>The reason for the lack of reviewers is that key people, such as
Larsson, have left the project. Every now and then, Wick said, Larsson
may get involved if it's necessary, but he is basically not part of
the day-to-day development of the project. Wick said that it is hard
to get new Flatpak contributors involved because it can take months to
get feedback on major changes, and then more months to get another
review. "<q>This is really not a great way to get someone up to speed,
and it's not a great situation to be in</q>."</p>

<p>"<q>Maybe I'm complaining about something that is actually not that
much of an issue</q>", he said. Flatpak works; it does its job, and
"<q>we just use it and don't think about it much</q>". In that sense,
the project is in a good spot. But he has still been thinking
about how the project is "<q>living with constraints</q>" because
contributors do not have the opportunity to go in and make bigger
changes.</p>

<p>As an example, Wick said that Red Hat has been doing work that
would allow Flatpaks to be installed as part of a base
installation. The vendor or administrator could specify the
applications to be installed, and a program called
<tt>flatpak-preinstall</tt> would take care of the rest. The feature
has been implemented and is planned for inclusion in Red Hat
Enterprise Linux (RHEL) 10. The work was <a href="https://github.com/flatpak/flatpak/pull/5832">started</a> by
Kalev Lember and Owen Taylor last June, but the original pull request
was <a href="https://github.com/flatpak/flatpak/pull/5832#issuecomment-2630695788">closed</a>
by Lember in February as he was leaving Red Hat and would not be
working on it anymore. It was picked up by Wick in February as a <a href="https://github.com/flatpak/flatpak/pull/6116">new request</a>
but wasn't reviewed until early May.</p>

<h4>OSTree and OCI</h4>

<p>Wick's next topic was OCI support in Flatpak. While OSTree has been
a success in some ways, and it is still being maintained, it is not
undergoing active development. He noted that developers have a
"<q>very narrow set of tools</q>" for working with OSTree, so building
Flatpaks that use OSTree requires non-standard and bespoke tools, but
there is a whole range of utilities available for working with OCI
images. Even better, tools for working with OCI images "<q>are all
developed by people other than us, which means we don't actually have
to do the work if we just embrace them</q>".</p>

<p>Unfortunately, there are a number of OCI-related improvements that,
again, are waiting on review to be merged into Flatpak. For example,
Wick mentioned that the OCI container standard has added <a href="https://github.com/containers/storage/blob/main/docs/containers-storage-zstd-chunked.md"><tt>zstd:chunked</tt></a>
support. Instead of the original OCI image format that uses gzipped
tarballs, the <tt>zstd:chunked</tt> images are compressed with <a href="https://datatracker.ietf.org/doc/html/rfc8478">zstd</a> and have
<a href="https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md#skippable-frames">skippable
frames</a> that include additional metadata—such as a table of
contents—which allows file-level deduplication. In short,
zstd:chunked allows pulling only those files that have changed since
the last update, rather than an entire OCI layer, when updating a
container image or a Flatpak.</p>

<p>There is a <a href="https://github.com/flatpak/flatpak/pull/5540">pull request</a>
from Taylor, submitted in September&nbsp;2023, that would add support
to Flatpak for zstd-compressed layers. It has received little
attention since then and "<q>it's just sitting there,
currently</q>".</p>

<h4>Narrowing permissions</h4>

<p>One of the key functions of Flatpak is to sandbox applications and
limit their access to the system. Wick said that the project has added
features to "<q>narrow down</q>" the sandboxes and provide more
restricted permissions. As an example, Flatpak now has
<tt>--device=input</tt> to allow an application to access input
devices without having access to all devices.</p>

<p>One problem with this, he said, is that a system's installation of
Flatpak may not support the newer features. A user's Linux
distribution may still be providing an older version of Flatpak that
does not have support for <tt>--device=input</tt>, or whatever new
feature that a Flatpak developer may wish to use. Wick said there
needs to be a way for applications to use the new permissions by
default, but fall back to the older permission models if used on a
system with an older version of Flatpak.</p>

<p>This isn't an entirely new situation, he said. "<q>We had this
before with Wayland and X11</q>", where if a system is running
Wayland, then Flatpak should not bind-mount an X11 socket. Now, there is a
similar scenario with the <a href="https://flatpak.github.io/xdg-desktop-portal/docs/doc-org.freedesktop.portal.Usb.html">xdg-desktop portal
for USB access</a>, which was <a href="https://github.com/flatpak/xdg-desktop-portal/pull/559">added</a>
to the xdg-desktop-project in 2021. Support for that portal was <a href="https://github.com/flatpak/flatpak/issues/4405">merged</a> into
Flatpak in 2024 after several iterations. What is missing is the
ability to specify backward-compatible permissions so that a Flatpak
application can be given USB access (<tt>--device=usb</tt>) with newer
versions of Flatpak but retain the <tt>--device=all</tt> permissions
if necessary. Once again, there is a <a href="https://github.com/flatpak/flatpak/issues/5681">pull request</a>
(from Hubert Figuière) that implements this, but Wick said that
"<q>it's also just sitting there</q>".</p>

<p>Wick would also like to improve the way that Flatpak handles access
to audio. Currently, Flatpak still uses <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/">PulseAudio</a>
even if a host system uses <a href="https://pipewire.org/">PipeWire</a>. The problem with that is
that PulseAudio bundles together access to speakers and
microphones—you can have access to both, or neither, but not just one. So
if an application has access to play sound, it also has access to
capture audio, which Wick said, with a bit of understatement, is
"<q>not great</q>". He would like to be able to use PipeWire, which
can expose restricted access to speakers only.</p>

<p>One thing that has been a bit of a pain point, Wick said, is that
nested sandboxing does not work in Flatpak. For instance, an
application cannot use Bubblewrap inside Flatpak. Many applications,
such as web browsers, make heavy use of sandboxing.</p>

<blockquote>
They really like to put their tabs into their own sandboxes because it
turns out that if one of those tabs is running some code that
manages to exploit and break out of the process there, at
least it's contained and doesn't spread to the rest of the
browser.
</blockquote>

<p>What Flatpak does instead, currently, is to have a kind of side
sandbox that applications can call to and spawn another Flatpak
instance that can be restricted even further. "<q>So, in that sense,
that is a solution to the problem, but it is also kind of fragile</q>."
There have been issues with this approach for quite a while, he said,
but no one knows quite how to solve them.</p>

<p>Ideally, Flatpak would simply support nested namespacing and nested
sandboxes, but currently it does not. Flatpak uses seccomp to prevent
applications in a sandbox from having direct access to user
namespaces. There is an API that can be used to create a sub-sandbox,
but it is more restrictive. He said that the restrictions to user
namespaces are outdated: "<q>for a long time it wasn't really a good
idea to expose user namespacing because it exposed a big kernel API to
user space that could be exploited</q>". Wick feels that user
namespaces are, nowadays, a well-tested and a much-used interface. He
does not think that there is much of a good argument against user
namespaces anymore.</p>

<h4>xdg-dbus-proxy</h4>

<p>Flatpak applications do not talk directly to D-Bus. Instead,
<tt>flatpak-run</tt> spawns an <a href="https://man.archlinux.org/man/xdg-dbus-proxy.1.en">xdg-dbus-proxy</a>
for every Flatpak instance that is "<q>not exactly in the same
sandbox, it's just on the side, basically</q>". The proxy is
responsible for setting up filtering according to rules that are
processed when <tt>flatpak-run</tt> is used to start an
application. When setting up the proxy, Flatpak starts with a
<tt>deny-all</tt> state and then adds specific connections that are
allowed. This is so that applications do not expose things that other
applications are not supposed to use.</p>

<p>Wick said that he would like to move filtering from xdg-dbus-proxy
directly to the D-Bus message brokers and provide policy based on a
cgroups path. This is not something that has been implemented
already, but he said he planned to work on a prototype in <a href="https://github.com/dbus2/busd?tab=readme-ov-file#busd">busd</a>,
which is a D-Bus broker implementation in Rust.</p>

<p>That would also allow for a more dynamic policy, which would allow
applications to export services to other applications on the
fly. Currently, the policy is set when a Flatpak is run, and can't be
modified afterward.</p>

<p>As a side note, that means that Flatpak applications cannot
talk to one another over D-Bus. They can still communicate
with other applications; for example, Wick said that applications can
communicate over the host's shared network namespace, "<q>which means
you can use HTTP or whatever, there are like thousands of side
channels you could use if you wanted to</q>".</p>

<p>Flatpak's network namespacing is "<q>kind of ugly, and I don't 
really have a good solution here</q>", Wick said, but he wanted to
point out that it is something the project should take a look
at. "<q>Like, you bind something on localhost and suddenly all
applications can just poke at it</q>". He gave the example of <a href="https://flathub.org/apps/de.bund.ausweisapp.ausweisapp2">AusweisApp</a>,
which is an official authentication app for German IDs 
that can be used to authenticate with government web sites. It
exposes a service on the local host, which makes it available to all
Flatpak applications on the system.</p>

<blockquote>
<p>This is some of the stuff that I feel like we really need to take a
look at. I'm not sure if this is like directly exploitable, but at the
very least it's kind of scary.</p>
</blockquote>

<p>Wick said that the project needs to create a network namespace for
Flatpak applications, "<q>but we don't really have any networking
experts around, which is kind of awkward, we really have to find a
solution here</q>".</p>

<p>Another awkward spot the project finds itself in, he said, is with
NVIDIA drivers. The project has to build multiple versions of NVIDIA
drivers for multiple runtimes that are supported, and that translates
to a great deal of network overhead for users who have to download
each of those versions—even if they don't need all of the
drivers. (<a href="https://forums.linuxmint.com/viewtopic.php?t=399518">This
complaint</a> on the Linux Mint forum illustrates the problem
nicely.) It also means that games packaged as Flatpaks need to be
continually updated against new runtimes, or they will eventually stop
working because their drivers stop being updated and the games will
not support current GPUs.</p>

<p>Wick's suggestion is to take a cue from Valve Software. He said
that Valve uses a model similar to Flatpak to run its games, but it
uses the drivers from the host system and loads all of the driver's
dependencies in the sandbox for the game. Valve uses the <a href="https://gitlab.collabora.com/vivek/libcapsule">libcapsule</a>
library to do this, which is "<q>kind of fragile</q>" and difficult to make
sure that it works well. Instead of using libcapsule, he would like to
statically compile drivers and share them between all Flatpak
applications. This is just in the idea stage at the moment, but
Wick said he would like to solve the driver problem eventually.</p>

<h4>Portals</h4>

<p>Portals are D-Bus interfaces that provide APIs for things like file
access, printing, opening URLs, and more. Flatpak can grant sandboxed
applications access to portals to make D-Bus calls. Wick noted
that portals are not part of the Flatpak project but they are crucial
to it. "<q>Whatever we do with portals just directly improves
Flatpak, and there are a bunch of portal things we need to
improve</q>".</p>

<p>He gave the example of the <a href="https://flatpak.github.io/xdg-desktop-portal/docs/doc-org.freedesktop.portal.Documents.html">Documents</a>
portal, which makes files outside the sandbox available to Flatpak
applications. The Documents portal is great for sharing single files,
but it is too fine-grained and restrictive for other applications,
such as Blender, GIMP, or music applications, that may need to access
an entire library of files. "<q>You want a more coarse-grained
permission model for files at some point</q>". There are some
possibilities, he said, such as bind mounting user-selected host
locations into the sandbox.</p>

<p>Wick had a number of ideas that he would like to see implemented
for portals, such as support for autofilling passwords, Fast Identity
Online (FIDO) security keys, speech synthesis, and more. He
acknowledged that it's "<q>kind of hard to write</q>" code for portals
right now, but there is work to make it easier by using <a href="https://gitlab.gnome.org/GNOME/libdex">libdex</a>. (See
Christian Hergert's <a href="https://blogs.gnome.org/chergert/2025/03/27/fiber-cancellation-in-libdex/">blog
post</a> on libdex for a short look at this.) It might even make sense
to rewrite things in Rust, he said.</p>

<h4>Flatpak-next</h4>

<p>Assume that it's ten years in the future, Wick said, and no one is
working on Flatpak anymore. "<q>What would you do with Flatpak if you
could just rewrite it? I think the vision where we should go is OCI
for almost everything.</q>" Larsson's choices in creating Flatpak
were good and sound technical decisions at the time, but they
ended up being "<q>not the thing that everyone else has</q>". That is
an issue because only a few people understand what Flatpak does, and
the project has to do everything itself.</p>

<p>But, he said, if the project did "<q>everything OCI</q>", it would
get a lot of things for free, such as OCI registries and tooling. Then
it just comes down to what <tt>flatpak-run</tt> has to do, and that
would not be very much. Rethinking Flatpak with modern container tools
and aligning with the wider container ecosystem, he said, would make
everything easier and is worth exploring. Once again, he floated the
idea of using Rust for a rewrite.</p>

<h4>Q&amp;A</h4>

<p>There was a little time for questions at the end of Wick's
session. The first was about what happens to existing Flatpaks if the
project moves to OCI tooling. "<q>Would I need to just throw away
[applications] and download again, or is that too much in the future,
and you haven't thought about that?</q>" Wick said that it would be an
issue on the client side, but Flathub (for example) has all of the
build instructions for its Flatpaks and could simply rebuild them.</p>

<p>Another audience member was concerned about using container
infrastructure. They said that OCI registries that store images are
missing indexing and metadata that is consumed by applications like
GNOME Software for Flatpaks. What would be the way forward to ensure
that they could preserve the same user experience? Wick said that
there is now a standard for storing non-images in OCI registries,
which would allow storing "<q>the same things we're currently
storing</q>" for Flatpak, but writing the code to do it and getting it
merged would be the hard part.</p>

<p>The final question was whether there was anything concrete planned
about using PipeWire directly with Flatpak rather than the PulseAudio
routing. Wick said that he had been talking with Wim Taymans, the
creator of PipeWire, about how to add support for it within
Flatpak. It is mostly about "<q>adding PipeWire policy to do the right
thing when it knows that it is a Flatpak instance</q>", he said.</p>

<br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/ConferenceIndex/">Conference</a></td><td><a href="https://lwn.net/Archives/ConferenceIndex/#Linux_Application_Summit-2025">Linux Application Summit/2025</a></td></tr>
            </tbody></table><br clear="all">
<hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sketchy Calendar (136 pts)]]></title>
            <link>https://www.inkandswitch.com/ink/notes/sketchy-calendar/</link>
            <guid>44068204</guid>
            <pubDate>Thu, 22 May 2025 23:19:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inkandswitch.com/ink/notes/sketchy-calendar/">https://www.inkandswitch.com/ink/notes/sketchy-calendar/</a>, See on <a href="https://news.ycombinator.com/item?id=44068204">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<dl>
<p><dt>title</dt><dd>Sketchy Calendar</dd></p>
<p><dt>dated</dt><dd>Q2 2025</dd></p>

<p><dt>related</dt><dd><a href="https://www.inkandswitch.com/ink/notes/sketchy-feel">Sketchy Feel</a></dd></p></dl>

<p>When it comes to calendars, you can choose between using a digital calendar app or getting a paper calendar. They both allow you to keep track of things like doctor appointments, work meetings or birthdays, so you can keep a clear head and be sure that you won’t forget anything. But while the two approaches may seem similar on the surface, they’re radically different in the kinds of trade-offs they make.</p>
<p>In this project, we’re exploring what it would mean to have a calendar that combines the convenience of a digital calendar with the simplicity and expressivity you get from pen &amp; paper.</p>
<h2>Calendar apps</h2>
<p>On the one hand, calendar apps like Google Calendar offer many convenient features. You can easily switch between different (daily, weekly and monthly) views. All your events are synced across your devices. You can send calendar invites and even create shared calendars with other people, so when you plan something that affects others, you can check their availability.</p>
<p><img src="https://www.inkandswitch.com/ink/notes/sketchy-calendar/google-calendar.png" alt="Weekly calendar of the author"></p>
<p>While powerful, Google Calendar’s design imposes a strict view of what a calendar event is. If you have tentative plans like “lunch with a friend sometime next week” there is no obvious way to add this to your calendar in a way that differentiates it from an important appointment that can’t be missed.</p>
<p>Calendar apps can also feel very sterile and impersonal. All events are visually uniform, regardless of importance, even across different contexts. Events on my company calendar (which I only need to see for coordination) exist alongside my personal commitments with no visual hierarchy.</p>
<p>A calendar app <em>could</em> be a deeply personal place for collecting memories, which allows users to reflect on how they are spending their time. In practice, calendar apps are primarily a tool for scheduling meetings.</p>
<h2>Paper calendars</h2>
<p>In contrast, using pen &amp; paper is much more flexible. You can get calendars that offer varying degrees of structure, from completely blank notebooks with no imposed format to more structured planners that have preprinted pages for months, weeks, and days with dedicated sections for things like tasks and timelines. The preprinted structure acts more like a guideline than a requirement. It is easy to ignore: Users can draw arrows, doodle, and mark rough timeframes for activities, without being forced to fit a predetermined schema.</p>
<p><img src="https://www.inkandswitch.com/ink/notes/sketchy-calendar/physical-notebook.jpg" alt="Different notebooks offer different structures"></p>
<p>This versatility extends way beyond scheduling events—the same pages can accommodate things like meeting notes, meal plans, to-dos, and habit tracking.
Unlike apps that can only capture events, paper calendars grow naturally into personal spaces, capable of capturing the various aspects of daily life, like meal plans, to-do lists or habit trackers.</p>
<p><img src="https://www.inkandswitch.com/ink/notes/sketchy-calendar/usecases-physical-notebook.jpg" alt="People use notebooks to create meal plans, to-do lists and habit trackers"></p>
<h2>Can we combine both worlds?</h2>
<p>What if you could have a digital calendar that combined the strengths of both the paper and the digital world?</p>
<p>Some calendar apps have attempted to address this question by <em>adding more features</em>. <a href="https://www.hey.com/calendar/">Hey Calendar</a>, for example, allows users to personalize their calendar by assigning titles or background images to days. Beyond events, users can also add unscheduled to-dos and track daily habits.</p>
<p><img src="https://www.inkandswitch.com/ink/notes/sketchy-calendar/hey-calendar.png" alt="Hey calendar, a calendar app with habit tracking todo list and other customization features"></p>
<p>While certainly an improvement over regular calendar apps, they remain constrained to the limits of the ‘app’ paradigm: users cannot customize their experience in ways the developers didn’t anticipate, they’re stuck with workarounds or feature requests that — if implemented — will inevitably lead to feature creep, which will add complexity for all users.</p>
<p>Instead, we’re interested in taking the paper calendar as a starting point. Pen &amp; paper, straight out of the box, affords a level of customization and personalization that we rarely see in the world of software. But its unstructured nature also makes it difficult to add any of the convenient functionalities that we get when we digitize information. This project explores this trade-off. How far can we get by taking a simple digital notebook (iPad &amp; pencil) and adding a small amount of structure?</p>
<p>These are some of the questions we intend to explore:</p>
<ul>
<li>Is it possible to create interconnected daily, weekly and monthly views like a traditional calendar app?</li>
<li>How might sketched annotations meaningfully interact with formal calendar events?</li>
<li>How would shared calendars or calendar invites work in such a semi-structured system?</li>
<li>How can users personalize their calendars by adding custom dynamic behavior? For example, how might I add a habit tracker or a time tracker, all while preserving the sketchy, personal quality?</li>
</ul>
<p>Here is a little sneak preview of what a sketchy calendar could look like. We will soon
share more about how this works and what we’ve learned building it.</p>
<p><img src="https://www.inkandswitch.com/ink/notes/sketchy-calendar/sketchy-calendar.png" alt="Screenshot of digital notebook with calendar"></p>
<hr>
<p><em>Image Credits:</em></p>
<ul>
<li>
<p><a href="https://flickr.com/photos/y0mbo/26107340073/in/photolist-FM1WCZ-FM1WXB-U5MFEX-251Mf86-sqfAs1-2cGESYr-PzUwJo-PzUxA3-NpJ6ev-GRshJ9-2aGtrJ6-2jiLvV4-PNJnvv-RWoDe5-QHvm1h-Rqmukw-5MW23a-2k8D9m4-QHvmxQ-HQSgY2-RLqCEm-2oixdEb-2mPYpDT-2q4DvuX-2qednDM-dyf4U-jG1RyF-b61x2Z-dUWyW6-2dXVDgi-TkRtvC-8EHB3j-rQHPNG-ZF7GRu-2c87We7-4YtcTx-2qknDrM-2b7ENYD-2q7rhSJ-2iGacJ9-2pMERXY-XmhpmZ-Xypxvc-2kw5Wan-2npGwJF-2pJwSXn">meal plan</a></p>
</li>
<li>
<p><a href="https://flickr.com/photos/sixmilliondollardan/50899796627/in/photolist-2kxQLdt-2iEEi5A-cdJdE7-fXxw7x-TKnRsk-7zxaf1-5c57BW-rzKddE-2m5MdWL-8Z6NkM-A8zQK-2pnWC3P-aFPqJa-2pkq56p-2iwE23X-N9z6RV-hHWY5-D5ZvX5-jEtYpH-oiorGx-9mgpVL-dGf5bW-aZiN5H-W8f5kG-ikyvZR-2nDmv7m-jEwR8o-otfQ3-ikyEMj-6uri3r-ikyu83-9f71Se-ikyXAD-ikyZrn-ikyADF-ikyfqV-ikyCLL-ikyvoS-ikyGtq-ikytVv-FwgCnP-5vWFhP-pQPKRb-cZKDbL-xqvJQy-cMBUuu-aFPqF6-2nDgpFv-BRt1Wr-5V458b">habit tracker</a></p>
</li>
<li>
<p><a href="https://flickr.com/photos/y0mbo/26107341583/in/photolist-FM1WCZ-FM1WXB-FM1X62-U5MFEX-251Mf86-sqfAs1-2cGESYr-PzUywS-PzUwJo-PD7eCr-PzUxA3-NpJ6ev-GRshJ9-2mxkUro-2jiLvV4-PNJnvv-RWoDe5-QHvm1h-Rqmukw-5MW23a-2k8D9m4-QHvmxQ-HQSgY2-QHvmrh-RLqCEm-2oixdEb-2mPYpDT-2q4DvuX-2qednDM-dyf4U-jG1RyF-b61x2Z-dUWyW6-2dXVDgi-TkRtvC-8EHB3j-rQHPNG-ZF7GRu-2c87We7-4YtcTx-2qknDrM-2b7ENYD-2q7rhSJ-2iGacJ9-2pMERXY-XmhpmZ-Xypxvc-2npGwJF-2pJwSXn-2kw5W9f">Weekly planner</a></p>
</li>
<li>
<p><a href="https://flickr.com/photos/stephen_oldham/17339719324/in/photolist-FM1WCZ-FM1WXB-FM1X62-U5MFEX-251Mf86-sqfAs1-2cGESYr-PzUywS-PzUwJo-PD7eCr-PzUxA3-NpJ6ev-GRshJ9-2mxkUro-2jiLvV4-PNJnvv-RWoDe5-QHvm1h-Rqmukw-5MW23a-2k8D9m4-QHvmxQ-HQSgY2-QHvmrh-RLqCEm-2oixdEb-2mPYpDT-2q4DvuX-2qednDM-dyf4U-jG1RyF-b61x2Z-dUWyW6-2dXVDgi-TkRtvC-8EHB3j-rQHPNG-ZF7GRu-2c87We7-4YtcTx-2qknDrM-2b7ENYD-2q7rhSJ-2iGacJ9-2pMERXY-XmhpmZ-Xypxvc-2npGwJF-2pJwSXn-2kw5W9f">Todo list</a></p>
</li>
</ul>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[32 bits that changed microprocessor design (119 pts)]]></title>
            <link>https://spectrum.ieee.org/bellmac-32-ieee-milestone</link>
            <guid>44068197</guid>
            <pubDate>Thu, 22 May 2025 23:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/bellmac-32-ieee-milestone">https://spectrum.ieee.org/bellmac-32-ieee-milestone</a>, See on <a href="https://news.ycombinator.com/item?id=44068197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="32 Bits That Changed Microprocessor Design"><p>In the late 1970s, a time when 8-bit <a href="https://spectrum.ieee.org/tag/processors">processors</a> were state of the art and <a href="https://spectrum.ieee.org/cmos-2" target="_self">CMOS</a> was the underdog of semiconductor technology, engineers at <a href="https://en.wikipedia.org/wiki/AT%26T" rel="noopener noreferrer" target="_blank">AT&amp;T</a>’s <a href="https://spectrum.ieee.org/bell-labs-100-birthday" target="_self">Bell Labs</a> took a bold leap into the future. They made a high-stakes bet to outpace <a href="https://www.ibm.com/us-en?utm_content=SRCWW&amp;p1=Search&amp;p4=43700081194960546&amp;p5=e&amp;p9=58700008820162789&amp;gad_source=1&amp;gbraid=0AAAAAD-_QsRlt1t7v0Hn1Z_4D12I3-wXM&amp;gclid=CjwKCAjwn6LABhBSEiwAsNJrjvYbHPm7g7FQqgduEW9KqMEQA9ckxWBTqGSbA3rmffcQpTGNM1ke_RoCeRgQAvD_BwE&amp;gclsrc=aw.ds" rel="noopener noreferrer" target="_blank">IBM</a>, <a href="https://www.intel.com/content/www/us/en/homepage.html" rel="noopener noreferrer" target="_blank">Intel</a>, and<a href="https://www.ibm.com/us-en?utm_content=SRCWW&amp;p1=Search&amp;p4=43700081194960546&amp;p5=e&amp;p9=58700008820162789&amp;gad_source=1&amp;gbraid=0AAAAAD-_QsRlt1t7v0Hn1Z_4D12I3-wXM&amp;gclid=CjwKCAjwn6LABhBSEiwAsNJrjvYbHPm7g7FQqgduEW9KqMEQA9ckxWBTqGSbA3rmffcQpTGNM1ke_RoCeRgQAvD_BwE&amp;gclsrc=aw.ds" rel="noopener noreferrer" target="_blank"></a>other competitors in chip performance by combining cutting-edge 3.5-micron <a href="https://spectrum.ieee.org/tag/cmos">CMOS</a> fabrication with a novel 32-bit processor architecture.</p><p>Although their creation—the<a href="https://ethw.org/First-Hand:The_AT%26T_BELLMAC-32_Microprocessor_Development" rel="noopener noreferrer" target="_blank"> Bellmac-32</a> microprocessor—never achieved the commercial fame of earlier ones such as <a href="https://en.wikipedia.org/wiki/Intel_4004" rel="noopener noreferrer" target="_blank">Intel’s 4004</a> (released in 1971), its influence has proven far more enduring. Virtually every chip in <a href="https://spectrum.ieee.org/tag/smartphones">smartphones</a>, <a href="https://spectrum.ieee.org/tag/laptops">laptops</a>, and tablets today relies on the complementary metal-oxide semiconductor principles that the Bellmac-32 pioneered.</p><p>As the 1980s approached, <a href="https://en.wikipedia.org/wiki/AT%26T" rel="noopener noreferrer" target="_blank">AT&amp;T</a> was grappling with transformation. For decades, the telecom giant—nicknamed “Ma Bell”—had dominated American voice communications, with its <a href="https://en.wikipedia.org/wiki/Western_Electric" rel="noopener noreferrer" target="_blank">Western Electric</a> subsidiary manufacturing nearly every telephone found in U.S. homes and offices. The U.S. federal government was pressing for <a href="https://spectrum.ieee.org/the-end-of-att" target="_self">antitrust-driven divestiture</a>, but AT&amp;T was granted an opening to expand into computing.</p><p>With computing firms already entrenched in the market, AT&amp;T couldn’t afford to play catch-up; its strategy was to leap ahead, and the Bellmac-32 was its springboard.</p><p>The Bellmac-32 chip series has now been honored with an<a href="https://ieeemilestones.ethw.org/Main_Page" rel="noopener noreferrer" target="_blank"> IEEE Milestone</a>. Dedication ceremonies are slated to be held this year at the <a href="https://www.nokia.com/" rel="noopener noreferrer" target="_blank">Nokia</a>&nbsp;<a href="https://spectrum.ieee.org/bell-labs-100-birthday" target="_self">Bell Labs’ campus</a> in Murray Hill, N.J., and at the <a href="https://computerhistory.org/" rel="noopener noreferrer" target="_blank">Computer History Museum</a> in Mountain View, Calif.</p><h2>A chip like no other</h2><p>Rather than emulate the industry standard of 8-bit chips, AT&amp;T executives challenged their <a href="https://spectrum.ieee.org/tag/bell-labs">Bell Labs</a> engineers to deliver something revolutionary: the first commercially viable <a href="https://spectrum.ieee.org/tag/microprocessor">microprocessor</a> capable of moving 32 bits in one clock cycle. It would require not just a new chip but also an entirely novel architecture—one that could handle telecommunications switching and serve as the backbone for future computing systems.</p><p>“We weren’t just building a faster chip,” says <a href="https://www.condry.org/" target="_blank">Michael Condry</a>, who led the architecture team at Bell Labs’ Holmdel facility in New Jersey. “We were trying to design something that could carry both voice and computation into the future.”</p><p data-rm-resized-container="25%"><img alt="Illustration of Bell Laboratories\u2019 32 DBO with MMU." data-rm-shortcode-id="c1d7fde0ab88911873b1b9689c60e23e" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/illustration-of-bell-laboratories-u2019-32-dbo-with-mmu.jpg?id=60303752&amp;width=980" height="2470" id="4aae9" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/illustration-of-bell-laboratories-u2019-32-dbo-with-mmu.jpg?id=60303752&amp;width=980" width="3294"><small placeholder="Add Photo Caption...">This configuration of the Bellmac-32 microprocessor had an integrated memory management unit optimized for Unix-like <a href="https://spectrum.ieee.org/tag/operating-systems">operating systems</a>.</small><small placeholder="Add Photo Credit...">AT&amp;T Archives and History Center</small></p><p>At the time, CMOS technology was seen as a promising—but risky—alternative to the <a href="https://anysilicon.com/introduction-to-nmos-and-pmos-transistors/" rel="noopener noreferrer" target="_blank">NMOS and PMOS</a> designs then in use. <a href="https://spectrum.ieee.org/tag/nmos">NMOS</a> chips, which relied solely on N-type <a href="https://spectrum.ieee.org/tag/transistors">transistors</a>, were fast but power-hungry. PMOS chips, which depend on the movement of positively-charged holes, were too slow. CMOS, with its hybrid design, offered the potential for both speed and energy savings. The benefits were so compelling that the industry soon saw that the need for double the number of transistors (NMOS and PMOS for each gate) was worth the tradeoff.</p><p>As transistor sizes shrank along with the rapid advancement of semiconductor technology described by <a href="https://spectrum.ieee.org/five-things-you-might-not-know-about-moores-law" target="_self">Moore’s Law</a>, the cost of doubling up the transistor density soon became manageable and eventually became negligible. But when Bell Labs took its high-stakes gamble, large-scale CMOS fabrication was still unproven and looked to be comparatively costly.</p><p>That didn’t deter Bell Labs. By tapping expertise from its campuses in Holmdel and Murray Hill as well as in Naperville, Ill., the company assembled a dream team of semiconductor engineers. The team included Condry;<a href="https://nisl.soe.ucsc.edu/" rel="noopener noreferrer" target="_blank"> Sung-Mo “Steve” Kang</a>, a rising star in <a href="https://spectrum.ieee.org/tag/chip-design">chip design</a>;  <a href="https://sagetechnologyresources.com/?team=victor-huang" rel="noopener noreferrer" target="_blank">Victor Huang</a>, another microprocessor chip designer, and dozens of AT&amp;T Bell Labs employees. They set out in 1978 to master a new CMOS process and create a 32-bit microprocessor from scratch.</p><h2>Designing the architecture</h2><p>The architecture group led by Condry, an IEEE Life Fellow who would later become Intel’s CTO, focused on building a system that would natively support the <a href="https://www.techtarget.com/searchdatacenter/definition/Unix" rel="noopener noreferrer" target="_blank">Unix</a>&nbsp;<a href="https://spectrum.ieee.org/tag/operating-system">operating system</a> and the <a href="https://en.wikipedia.org/wiki/C_(programming_language)" rel="noopener noreferrer" target="_blank">C programming language</a>. Both were in their infancy but destined for dominance. To cope with the era’s memory limitations—kilobytes were precious—they introduced a complex instruction set that required fewer steps to carry out and could be executed in a single clock cycle.</p><p>The engineers also built the chip to support the <a href="https://www.vita.com/VMEbus-FAQ" rel="noopener noreferrer" target="_blank">VersaModule Eurocard (VME) parallel bus</a>, enabling <a href="https://spectrum.ieee.org/tag/distributed-computing">distributed computing</a> so several nodes could handle data processing in parallel. Making the chip VME-enabled also allowed it to be used for real-time control.</p><p>The group wrote its own version of <a href="https://spectrum.ieee.org/tag/unix">Unix</a>, with real-time capabilities to ensure that the new chip design was compatible with <a href="https://spectrum.ieee.org/tag/industrial-automation">industrial automation</a> and similar applications. The Bell Labs engineers also invented<a href="https://en.wikipedia.org/wiki/Domino_logic" target="_blank"> domino logic</a>, which ramped up processing speed by reducing delays in complex <a href="https://spectrum.ieee.org/tag/logic-gates">logic gates</a>.</p><p>Additional testing and verification techniques were developed and introduced via the Bellmac-32 Module, a sophisticated multi-chipset verification and testing project led by Huang that allowed the complex <a href="https://spectrum.ieee.org/tag/chip-fabrication">chip fabrication</a> to have zero or near-zero errors. This was the first of its kind in <a href="https://spectrum.ieee.org/tag/vlsi">VLSI</a> testing. The Bell Labs engineers’ systematic plan for double- and triple-checking their colleagues’ work ultimately made the total design of the multiple chipset family work together seamlessly as a complete microcomputer system.</p><p>Then came the hardest part: actually building the chip.</p><h2>Floor maps and colored pencils</h2><p>“The technology for layout, testing, and high-yield fabrication just wasn’t there,” recalls Kang, an IEEE Life Fellow who later became president of the <a href="https://www.kaist.ac.kr/en/" rel="noopener noreferrer" target="_blank">Korea Advanced Institute of Science and Technology</a> (<a href="https://spectrum.ieee.org/tag/kaist">KAIST</a>) in Daejeon, <a href="https://spectrum.ieee.org/tag/south-korea">South Korea</a>. With no <a href="https://spectrum.ieee.org/tag/cad">CAD</a> tools available for full-chip verification, Kang says, the team resorted to printing oversize <a href="https://en.wikipedia.org/wiki/Calcomp" rel="noopener noreferrer" target="_blank">Calcomp</a> plots. The schematics showed how the transistors, circuit lines, and <a href="https://spectrum.ieee.org/tag/interconnects">interconnects</a> should be arranged inside the chip to provide the desired outputs. The team assembled them on the floor with adhesive tape to create a massive square map more than 6 meters on a side. Kang and his colleagues traced every circuit by hand with colored pencils, searching for breaks, overlaps, or mishandled interconnects.</p><h2>Getting it made</h2><p>Once the physical design was locked in, the team faced another obstacle: manufacturing. The chips were fabricated at a <a href="https://spectrum.ieee.org/tag/western-electric">Western Electric</a> facility in Allentown, Pa., but Kang recalls that the yield rates (the percentage of chips on a <a href="https://spectrum.ieee.org/tag/silicon-wafer">silicon wafer</a> that meet performance and quality standards) were dismal.</p><p>To address that, Kang and his colleagues drove from New Jersey to the plant each day, rolled up their sleeves, and did whatever it took, including sweeping floors and calibrating test equipment, to build camaraderie and instill confidence that the most complicated product the plant workers had ever attempted to produce could indeed be made there.</p><p>“We weren’t just building a faster chip. We were trying to design something that could carry both voice and computation into the future.” <strong>—Michael Condry, Bellmac-32 architecture team lead</strong></p><p>“The team-building worked out well,” Kang says. “After several months, Western Electric was able to produce more than the required number of good chips.”</p><p>The first version of the Bellmac-32, which was ready by 1980, fell short of expectations. Instead of hitting a 4-megahertz performance target, it ran at just 2 MHz. The engineers discovered that the state-of-the-art <a href="https://www.chiphistory.org/143-takeda-riken-reliability-drives-growth" rel="noopener noreferrer" target="_blank">Takeda Riken</a> testing equipment they were using was flawed, with transmission-line effects between the probe and the test head leading to inaccurate measurements, so they worked with a Takeda <a href="https://spectrum.ieee.org/tag/riken">Riken</a> team to develop correction tables that rectified the measurement errors.</p><p>The second generation of Bellmac chips had <a href="https://spectrum.ieee.org/tag/clock-speeds">clock speeds</a> that exceeded 6.2 MHz, sometimes reaching 9. That was blazing fast for its time. The 16-bit <a href="https://spectrum.ieee.org/tag/intel">Intel</a> 8088 processor inside IBM’s original PC released in 1981 <a href="https://americanhistory.si.edu/collections/object/nmah_713506#:~:text=Intel%208088.,4.77%20MHz%20and%2064K%20Memory." rel="noopener noreferrer" target="_blank">ran at 4.77 MHz</a>.</p><h2>Why Bellmac-32 didn’t go mainstream</h2><p>Despite its technical promise, the Bellmac-32 did not find wide commercial use. According to Condry, AT&amp;T’s pivot toward acquiring equipment manufacturer<a href="https://en.wikipedia.org/wiki/NCR_Voyix" rel="noopener noreferrer" target="_blank"> NCR</a>, which it began eyeing in the late 1980s, meant the company chose to back a different line of chips. But by then, the Bellmac-32’s legacy was already growing.</p><p>“Before Bellmac-32, NMOS was dominant,” Condry says. “But CMOS changed the market because it was shown to be a more effective implementation in the fab.”</p><p>In time, that realization reshaped the semiconductor landscape. CMOS would become the foundation for modern <a href="https://spectrum.ieee.org/tag/microprocessors">microprocessors</a>, powering the digital revolution in desktops, smartphones, and more.</p><p>The audacity of Bell Labs’ bet—to take an untested fabrication process and leapfrog an entire generation of chip architecture—stands as a landmark moment in technological history.</p><p>As Kang puts it: “We were on the frontier of what was possible. We didn’t just follow the path—we made a new one.” Huang, an IEEE Life Fellow who later became deputy director of the<a href="https://www.a-star.edu.sg/ime" rel="noopener noreferrer" target="_blank"> Institute of Microelectronics, Singapore</a>, adds: “This included not only chip architecture and design, but also large-scale chip verification—with CAD but without today’s digital simulation tools or even breadboarding [which is the standard method for checking whether a <a href="https://spectrum.ieee.org/tag/circuit-design">circuit design</a> for an electronic system that uses chips works before making permanent connections by <a href="https://spectrum.ieee.org/tag/soldering">soldering</a> the circuit elements together].” </p><p>Condry, Kang, and Huang look back fondly on that period and express their admiration for the many AT&amp;T employees whose skill and dedication made the Bellmac-32 chip series possible.</p><p>Administered by the <a href="https://www.ieee.org/about/history-center/" rel="noopener noreferrer" target="_blank">IEEE History Center</a> and supported by donors, the Milestone program recognizes outstanding technical developments around the world. The <a href="https://r1.ieee.org/northjersey/" rel="noopener noreferrer" target="_blank">IEEE North Jersey Section</a> sponsored the nomination.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Defuddle, an HTML-to-Markdown alternative to Readability (363 pts)]]></title>
            <link>https://github.com/kepano/defuddle</link>
            <guid>44067409</guid>
            <pubDate>Thu, 22 May 2025 21:40:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kepano/defuddle">https://github.com/kepano/defuddle</a>, See on <a href="https://news.ycombinator.com/item?id=44067409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><blockquote>
<p dir="auto">de·​fud·dle /diˈfʌdl/ <em>transitive verb</em><br>
to remove unnecessary elements from a web page, and make it easily readable.</p>
</blockquote>
<p dir="auto"><strong>Beware! Defuddle is very much a work in progress!</strong></p>
<p dir="auto">Defuddle extracts the main content from web pages. It cleans up web pages by removing clutter like comments, sidebars, headers, footers, and other non-essential elements, leaving only the primary content.</p>
<p dir="auto"><a href="https://kepano.github.io/defuddle/" rel="nofollow">Try the Defuddle Playground →</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Defuddle aims to output clean and consistent HTML documents. It was written for <a href="https://github.com/obsidianmd/obsidian-clipper">Obsidian Web Clipper</a> with the goal of creating a more useful input for HTML-to-Markdown converters like <a href="https://github.com/mixmark-io/turndown">Turndown</a>.</p>
<p dir="auto">Defuddle can be used as a replacement for <a href="https://github.com/mozilla/readability">Mozilla Readability</a> with a few differences:</p>
<ul dir="auto">
<li>More forgiving, removes fewer uncertain elements.</li>
<li>Provides a consistent output for footnotes, math, code blocks, etc.</li>
<li>Uses a page's mobile styles to guess at unnecessary elements.</li>
<li>Extracts more metadata from the page, including schema.org data.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">For Node.js usage, you'll also need to install JSDOM:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser</h3><a id="user-content-browser" aria-label="Permalink: Browser" href="#browser"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Defuddle } from 'defuddle';

// Parse the current document
const defuddle = new Defuddle(document);
const result = defuddle.parse();

// Access the content and metadata
console.log(result.content);
console.log(result.title);
console.log(result.author);"><pre><span>import</span> <span>{</span> <span>Defuddle</span> <span>}</span> <span>from</span> <span>'defuddle'</span><span>;</span>

<span>// Parse the current document</span>
<span>const</span> <span>defuddle</span> <span>=</span> <span>new</span> <span>Defuddle</span><span>(</span><span>document</span><span>)</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>defuddle</span><span>.</span><span>parse</span><span>(</span><span>)</span><span>;</span>

<span>// Access the content and metadata</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>content</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>title</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>author</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Node.js</h3><a id="user-content-nodejs" aria-label="Permalink: Node.js" href="#nodejs"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { JSDOM } from 'jsdom';
import { Defuddle } from 'defuddle/node';

// Parse HTML from a string
const html = '<html><body><article>...</article></body></html>';
const result = await Defuddle(html);

// Parse HTML from a URL
const dom = await JSDOM.fromURL('https://example.com/article');
const result = await Defuddle(dom);

// With options
const result = await Defuddle(dom, {
  debug: true, // Enable debug mode for verbose logging
  markdown: true, // Convert content to markdown
  url: 'https://example.com/article' // Original URL of the page
});

// Access the content and metadata
console.log(result.content);
console.log(result.title);
console.log(result.author);"><pre><span>import</span> <span>{</span> <span>JSDOM</span> <span>}</span> <span>from</span> <span>'jsdom'</span><span>;</span>
<span>import</span> <span>{</span> <span>Defuddle</span> <span>}</span> <span>from</span> <span>'defuddle/node'</span><span>;</span>

<span>// Parse HTML from a string</span>
<span>const</span> <span>html</span> <span>=</span> <span>'&lt;html&gt;&lt;body&gt;&lt;article&gt;...&lt;/article&gt;&lt;/body&gt;&lt;/html&gt;'</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>html</span><span>)</span><span>;</span>

<span>// Parse HTML from a URL</span>
<span>const</span> <span>dom</span> <span>=</span> <span>await</span> <span>JSDOM</span><span>.</span><span>fromURL</span><span>(</span><span>'https://example.com/article'</span><span>)</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>dom</span><span>)</span><span>;</span>

<span>// With options</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>dom</span><span>,</span> <span>{</span>
  <span>debug</span>: <span>true</span><span>,</span> <span>// Enable debug mode for verbose logging</span>
  <span>markdown</span>: <span>true</span><span>,</span> <span>// Convert content to markdown</span>
  <span>url</span>: <span>'https://example.com/article'</span> <span>// Original URL of the page</span>
<span>}</span><span>)</span><span>;</span>

<span>// Access the content and metadata</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>content</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>title</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>author</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><em>Note: for <code>defuddle/node</code> to import properly, the module format in your <code>package.json</code> has to be set to <code>{ "type": "module" }</code></em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Response</h2><a id="user-content-response" aria-label="Permalink: Response" href="#response"></a></p>
<p dir="auto">Defuddle returns an object with the following properties:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>author</code></td>
<td>string</td>
<td>Author of the article</td>
</tr>
<tr>
<td><code>content</code></td>
<td>string</td>
<td>Cleaned up string of the extracted content</td>
</tr>
<tr>
<td><code>description</code></td>
<td>string</td>
<td>Description or summary of the article</td>
</tr>
<tr>
<td><code>domain</code></td>
<td>string</td>
<td>Domain name of the website</td>
</tr>
<tr>
<td><code>favicon</code></td>
<td>string</td>
<td>URL of the website's favicon</td>
</tr>
<tr>
<td><code>image</code></td>
<td>string</td>
<td>URL of the article's main image</td>
</tr>
<tr>
<td><code>metaTags</code></td>
<td>object</td>
<td>Meta tags</td>
</tr>
<tr>
<td><code>parseTime</code></td>
<td>number</td>
<td>Time taken to parse the page in milliseconds</td>
</tr>
<tr>
<td><code>published</code></td>
<td>string</td>
<td>Publication date of the article</td>
</tr>
<tr>
<td><code>site</code></td>
<td>string</td>
<td>Name of the website</td>
</tr>
<tr>
<td><code>schemaOrgData</code></td>
<td>object</td>
<td>Raw schema.org data extracted from the page</td>
</tr>
<tr>
<td><code>title</code></td>
<td>string</td>
<td>Title of the article</td>
</tr>
<tr>
<td><code>wordCount</code></td>
<td>number</td>
<td>Total number of words in the extracted content</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bundles</h2><a id="user-content-bundles" aria-label="Permalink: Bundles" href="#bundles"></a></p>
<p dir="auto">Defuddle is available in three different bundles:</p>
<ol dir="auto">
<li>Core bundle (<code>defuddle</code>): The main bundle for browser usage. No dependencies.</li>
<li>Full bundle (<code>defuddle/full</code>): Includes additional features for math equation parsing.</li>
<li>Node.js bundle (<code>defuddle/node</code>): Optimized for Node.js environments using JSDOM. Includes full capabilities for math and Markdown conversion.</li>
</ol>
<p dir="auto">The core bundle is recommended for most use cases. It still handles math content, but doesn't include fallbacks for converting between MathML and LaTeX formats. The full bundle adds the ability to create reliable <code>&lt;math&gt;</code> elements using <code>mathml-to-latex</code> and <code>temml</code> libraries.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>debug</code></td>
<td>boolean</td>
<td>Enable debug logging</td>
</tr>
<tr>
<td><code>url</code></td>
<td>string</td>
<td>URL of the page being parsed</td>
</tr>
<tr>
<td><code>markdown</code></td>
<td>boolean</td>
<td>Convert <code>content</code> to Markdown</td>
</tr>
<tr>
<td><code>separateMarkdown</code></td>
<td>boolean</td>
<td>Keep <code>content</code> as HTML and return <code>contentMarkdown</code> as Markdown</td>
</tr>
<tr>
<td><code>removeExactSelectors</code></td>
<td>boolean</td>
<td>Whether to remove elements matching exact selectors like ads, social buttons, etc. Defaults to true.</td>
</tr>
<tr>
<td><code>removePartialSelectors</code></td>
<td>boolean</td>
<td>Whether to remove elements matching partial selectors like ads, social buttons, etc. Defaults to true.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debug mode</h3><a id="user-content-debug-mode" aria-label="Permalink: Debug mode" href="#debug-mode"></a></p>
<p dir="auto">You can enable debug mode by passing an options object when creating a new Defuddle instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const article = new Defuddle(document, { debug: true }).parse();"><pre><span>const</span> <span>article</span> <span>=</span> <span>new</span> <span>Defuddle</span><span>(</span><span>document</span><span>,</span> <span>{</span> <span>debug</span>: <span>true</span> <span>}</span><span>)</span><span>.</span><span>parse</span><span>(</span><span>)</span><span>;</span></pre></div>
<ul dir="auto">
<li>More verbose console logging about the parsing process</li>
<li>Preserves HTML class and id attributes that are normally stripped</li>
<li>Retains all data-* attributes</li>
<li>Skips div flattening to preserve document structure</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">HTML standardization</h2><a id="user-content-html-standardization" aria-label="Permalink: HTML standardization" href="#html-standardization"></a></p>
<p dir="auto">Defuddle attempts to standardize HTML elements to provide a consistent input for subsequent manipulation such as conversion to Markdown.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Headings</h3><a id="user-content-headings" aria-label="Permalink: Headings" href="#headings"></a></p>
<ul dir="auto">
<li>The first H1 or H2 heading is removed if it matches the title.</li>
<li>H1s are converted to H2s.</li>
<li>Anchor links in H1 to H6 elements are removed and become plain headings.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code blocks</h3><a id="user-content-code-blocks" aria-label="Permalink: Code blocks" href="#code-blocks"></a></p>
<p dir="auto">Code block are standardized. If present, line numbers and syntax highlighting are removed, but the language is retained and added as a data attribute and class.</p>
<div dir="auto" data-snippet-clipboard-copy-content="<pre>
  <code data-lang=&quot;js&quot; class=&quot;language-js&quot;>
    // code
  </code>
</pre>"><pre><span>&lt;</span><span>pre</span><span>&gt;</span>
  <span>&lt;</span><span>code</span> <span>data-lang</span>="<span>js</span>" <span>class</span>="<span>language-js</span>"<span>&gt;</span>
    // code
  <span>&lt;/</span><span>code</span><span>&gt;</span>
<span>&lt;/</span><span>pre</span><span>&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Footnotes</h3><a id="user-content-footnotes" aria-label="Permalink: Footnotes" href="#footnotes"></a></p>
<p dir="auto">Inline references and footnotes are converted to a standard format:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Inline reference<sup id=&quot;fnref:1&quot;><a href=&quot;#fn:1&quot;>1</a></sup>.

<div id=&quot;footnotes&quot;>
  <ol>
    <li class=&quot;footnote&quot; id=&quot;fn:1&quot;>
      <p>
        Footnote content.&amp;nbsp;<a href=&quot;#fnref:1&quot; class=&quot;footnote-backref&quot;>↩</a>
      </p>
    </li>
    </ol>
</div>"><pre>Inline reference<span>&lt;</span><span>sup</span> <span>id</span>="<span>fnref:1</span>"<span>&gt;</span><span>&lt;</span><span>a</span> <span>href</span>="<span>#fn:1</span>"<span>&gt;</span>1<span>&lt;/</span><span>a</span><span>&gt;</span><span>&lt;/</span><span>sup</span><span>&gt;</span>.

<span>&lt;</span><span>div</span> <span>id</span>="<span>footnotes</span>"<span>&gt;</span>
  <span>&lt;</span><span>ol</span><span>&gt;</span>
    <span>&lt;</span><span>li</span> <span>class</span>="<span>footnote</span>" <span>id</span>="<span>fn:1</span>"<span>&gt;</span>
      <span>&lt;</span><span>p</span><span>&gt;</span>
        Footnote content.&amp;nbsp;<span>&lt;</span><span>a</span> <span>href</span>="<span>#fnref:1</span>" <span>class</span>="<span>footnote-backref</span>"<span>&gt;</span>↩<span>&lt;/</span><span>a</span><span>&gt;</span>
      <span>&lt;/</span><span>p</span><span>&gt;</span>
    <span>&lt;/</span><span>li</span><span>&gt;</span>
    <span>&lt;/</span><span>ol</span><span>&gt;</span>
<span>&lt;/</span><span>div</span><span>&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Math</h3><a id="user-content-math" aria-label="Permalink: Math" href="#math"></a></p>
<p dir="auto">Math elements, including MathJax and KaTeX, are converted to standard MathML:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;inline&quot; data-latex=&quot;a \neq 0&quot;>
  <mi>a</mi>
  <mo>≠</mo>
  <mn>0</mn>
</math>"><pre><span>&lt;</span><span>math</span> <span>xmlns</span>="<span>http://www.w3.org/1998/Math/MathML</span>" <span>display</span>="<span>inline</span>" <span>data-latex</span>="<span>a \neq 0</span>"<span>&gt;</span>
  <span>&lt;</span><span>mi</span><span>&gt;</span>a<span>&lt;/</span><span>mi</span><span>&gt;</span>
  <span>&lt;</span><span>mo</span><span>&gt;</span>≠<span>&lt;/</span><span>mo</span><span>&gt;</span>
  <span>&lt;</span><span>mn</span><span>&gt;</span>0<span>&lt;/</span><span>mn</span><span>&gt;</span>
<span>&lt;/</span><span>math</span><span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build</h3><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto">To build the package, you'll need Node.js and npm installed. Then run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install

# Clean and build
npm run build"><pre><span><span>#</span> Install dependencies</span>
npm install

<span><span>#</span> Clean and build</span>
npm run build</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1,145 pull requests per day (107 pts)]]></title>
            <link>https://saile.it/1145-pull-requests-per-day/</link>
            <guid>44065680</guid>
            <pubDate>Thu, 22 May 2025 19:16:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://saile.it/1145-pull-requests-per-day/">https://saile.it/1145-pull-requests-per-day/</a>, See on <a href="https://news.ycombinator.com/item?id=44065680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>

                <section>
                    <figure><img src="https://saile.it/content/images/2025/05/stripe-sessions-2025---1145-pull-requests-per-day.png" alt="" loading="lazy" width="1250" height="658" srcset="https://saile.it/content/images/size/w600/2025/05/stripe-sessions-2025---1145-pull-requests-per-day.png 600w, https://saile.it/content/images/size/w1000/2025/05/stripe-sessions-2025---1145-pull-requests-per-day.png 1000w, https://saile.it/content/images/2025/05/stripe-sessions-2025---1145-pull-requests-per-day.png 1250w" sizes="(min-width: 720px) 720px"><figcaption><span>Slide from opening keynote of Stripe Sessions 2025</span></figcaption></figure><p>There is a <a href="https://youtu.be/ONIexChUpuw?t=426&amp;ref=saile.it">recent video</a> of Patrick Collison at Stripe Sessions 2025 stating that in 2024 Stripe did on average <strong>1,145 pull requests per day</strong>. Not just creating them, but actually finishing them; "<strong>fully shipped into production</strong>". All whilst having less than a minute of API unreliability for the entire year.</p><p>Stripe has roughly 8,500 employees (<a href="https://www.businessinsider.com/stripe-layoffs-staff-payments-memo-2025-1?international=true&amp;r=US&amp;IR=T&amp;ref=saile.it#:~:text=Stripe%20had%208%2C500%20employees">BI, 2025</a>). 40% or so in engineering (<a href="https://www.forbes.com/sites/alexkonrad/2022/05/26/stripe-exclusive-interview-collison-brothers-95-billion-plan-to-stay-on-top/?ref=saile.it#:~:text=more%20than%2040%25%20of%20the%20company%20is%20still%20engineers">Forbes, 2022</a>). With some napkin math assuming a similar distribution today, that would mean on average each engineer ships at least 1 change to production every 3 days. That is pretty incredible for the scale at which Stripe operates ($1.4 trillion(!) payment volume <a href="https://assets.stripeassets.com/fzn2n1nzq965/2pt3yIHthraqR1KwXgr98U/b6301040587a62d5b6ef7b76c904032d/Stripe-annual-letter-2024.pdf?ref=saile.it">in 2024</a>).</p><p>Though Stripe is well-known for their strong engineering culture, a number like that really puts things into perspective. According to <a href="https://dora.dev/research/2024/dora-report/?ref=saile.it">DORA 2024</a> (research by Google on software delivery &amp; operations) elite software delivery performance does "multiple deploys per day" with a 5% failure rate. It's probably not a stretch to say Stripe is in the top 1% of elite performers by these measurements alone. </p><h2 id="one-thousand-one-hundred-forty-five-deployments-to-production-per-day">One thousand one hundred forty-five deployments to production. Per day.</h2><p>To achieve that kind of delivery performance with that many people is honestly amazing. On its own, the "1 change to production every 3 days" per engineer might get mixed reactions. "We did 5 production deploys in one day at company XYZ!". But did they do it consistently for an entire year? With less than a minute of downtime?</p><p>It's not impossible but just thinking about the throughput really says something about how the ship is being run. Shipping safely at this velocity and scale implies heavy investment in automated tests, deployments, rollbacks, observability, code ownership and so forth. All those things pop-up in your favorite flavor of devops survey but you rarely see it operationalized at this level.</p><p>There are quite a few nuggets scattered on the internet regarding how Stripe does things (ex. <a href="https://www.kalzumeus.com/2020/10/09/four-years-at-stripe/?ref=saile.it">#1</a>, <a href="https://samgerstenzang.substack.com/p/operating-well-what-i-learned-at?ref=saile.it">#2</a>, <a href="https://every.to/p/what-i-miss-about-working-at-stripe?ref=saile.it">#3</a>) and in general the conclusion is that they have a very demanding but very advanced engineering culture.</p><blockquote>[...] what I learned at Stripe was nothing like I had experienced in more than 20 years in the industry.<br><a href="https://steinkamp.us/posts/2022-11-10-what-i-learned-at-stripe?ref=saile.it">What I Learned At Stripe (Steinkamp, 2022)</a></blockquote><p>Few companies operate at Stripe's scale, intensity and mission-critical level. But that shouldn't be a deterrence for aspiring to this kind of clarity, confidence, and velocity in engineering. It's a reflection of engineering culture done right; trusting changes, the tooling necessary to do that, autonomy of engineers and a relentless focus on continuously shipping value for users.</p><p>The goal is not 1,145 deployments per day. It's removing the friction that makes that pace impossible. What's really stopping you from rapidly shipping value to users?</p>
<!--kg-card-begin: html-->
<div>
    <h3>Want more content like this?</h3>
    <p>Hi! I sporadically write about tech &amp; business. If you want an email when something new comes out, feel free to subscribe. It's free and I hate spam as much as you do.</p>
<p>
    your@email.com
                            <span>Subscribe</span>
                        </p>
</div>
<!--kg-card-end: html-->

                        <header>
                            
                        </header>
                    
                </section>


                
            </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does Earth have two high-tide bulges on opposite sides? (2014) (277 pts)]]></title>
            <link>http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides</link>
            <guid>44065458</guid>
            <pubDate>Thu, 22 May 2025 18:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides">http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides</a>, See on <a href="https://news.ycombinator.com/item?id=44065458">Hacker News</a></p>
Couldn't get http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>