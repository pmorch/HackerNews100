<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 28 Oct 2023 04:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Large Balloon Reflector: a potentially game-changing antenna design (108 pts)]]></title>
            <link>https://www.nasa.gov/directorates/stmd/nasa-tech-breathes-life-into-potentially-game-changing-antenna-design/</link>
            <guid>38043955</guid>
            <pubDate>Fri, 27 Oct 2023 21:08:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nasa.gov/directorates/stmd/nasa-tech-breathes-life-into-potentially-game-changing-antenna-design/">https://www.nasa.gov/directorates/stmd/nasa-tech-breathes-life-into-potentially-game-changing-antenna-design/</a>, See on <a href="https://news.ycombinator.com/item?id=38043955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Some 30 years ago, a young engineer named Christopher Walker was home in the evening making chocolate pudding when he got what turned out to be a very serendipitous call from his mother.</p>
<p>Taking the call, he shut off the stove and stretched plastic wrap over the pot to keep the pudding fresh. By the time he returned, the cooling air in the pot had drawn the wrap into a concave shape, and in that warped plastic, he saw something – the magnified reflection of an overhead lightbulb – that gave him an idea that could revolutionize space-based sensing and communications.</p>
<p>That idea became the Large Balloon Reflector (LBR), an inflatable device that creates wide collection apertures that weigh a fraction of today’s deployable antennas. Now, with an assist from <a href="https://www.nasa.gov/stmd-the-nasa-innovative-advanced-concepts-niac/">NASA’s Innovative Advanced Concepts</a> (NIAC) program, funded by the agency’s Space Technology Mission Directorate, which supports visionary innovations from diverse sources, Walker’s decades-old vision is coming to fruition.</p>
<p>The concept turns part of the inside surface of an inflated sphere into a parabolic antenna. A section comprising about a third of the balloon’s interior surface is aluminized, giving it reflective properties.</p>
<p>With NIAC funding, and a grant from the U.S. Naval Research Laboratory, Walker was able to develop and demonstrate technologies for a 33-foot-diameter (10 meters) LBR that was carried to the stratosphere by a giant balloon. For comparison, the aperture of NASA’s massive <a href="https://webb.nasa.gov/" rel="noopener">James Webb Space Telescope</a> is over 21 feet (6.5 meters) in diameter.</p>
<p>“There was no place other than NIAC within NASA to get this off the ground,” says Walker, now a astronomy and optical engineering professor at the University of Arizona in Tucson. “At first, I was afraid to share the idea with colleagues because it sounded so crazy. You need a program within NASA that will actually look at the radical ideas, and NIAC is it.”</p>
<p>Parabolic dish antennas use their concave shape to capture and concentrate electromagnetic radiation. The larger the antenna’s diameter, or aperture, the more effective it is for capturing light or radio waves and transmitting radio signals over great distances.</p>
<p>In astronomy, there is a tremendous advantage to placing telescopes above the Earth’s atmosphere, which tends to distort or degrade signals coming from space. The challenge is that traditional large reflector antennas are heavy, unwieldy, and difficult to stow, leading to launch constraints and risky in-space deployment schemes.</p>
<p>The LBR design solves both problems. Made of a thin film structure, it inflates like a beachball, providing a stable parabolic-dish shape without the need for bulky and complex deployable hardware, and can fold into a tiny volume. &nbsp;</p>
<p>In 2018, Freefall Aerospace, a company co-founded by Walker to develop and market the technology, demonstrated the LBR’s potential aboard NASA’s stadium-sized stratospheric balloon, which carried a 3.28-foot scale model to an altitude of 159,000 feet.</p>
<figure>
<p>
<iframe title="CatSat | Student-led CubeSat Project" width="640" height="360" src="https://www.youtube.com/embed/Z4OQG4ABJ_k?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p>
</figure>
<p>Next up for the technology is a high-speed communications demonstration in low Earth orbit aboard a 6-unit CubeSat, about the size of a shoebox, called CatSat. It was selected for flight in 2019 as part of NASA’s CubeSat Launch Initiative. It is a joint effort involving NASA, Freefall Aerospace, the University of Arizona, and Rincon Research Corporation in Tucson, Arizona.</p>
<p>After reaching low-Earth orbit, CatSat’s inflatable antenna deployment system will deploy from its container, inflate to a diameter of about one-and-a-half feet, and begin transmitting back high-definition Earth photos. The mission is slated for launch with several other CubeSats on Firefly Aerospace’s Alpha rocket as part of the Educational Launch of Nanosatellites (ELaNa) 43 mission.</p>
<p>A more ambitious lunar mission concept is also being explored. NASA’s Goddard Space Flight Center in Greenbelt, Maryland, would use the inflatable antenna in tandem with a new instrument called Terahertz Spectrometer for In-Situ Resource Utilization, a miniature, high-power laser precisely calibrated to detect water, a critical exploration resource.</p>
<p>“The technology demonstrated by CatSat opens the door to the possibility of future lunar, planetary and deep-space missions using CubeSats,” said Walker.</p>
<p>It might be difficult to believe this all started because a young engineer’s idea of dinner one evening was what most would consider dessert. Then again, one could say the proof was in the pudding.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android 14's user-profile data bug (131 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/10/android-14s-ransomware-data-storage-bug-locks-out-users-remains-unfixed/</link>
            <guid>38043574</guid>
            <pubDate>Fri, 27 Oct 2023 20:35:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/10/android-14s-ransomware-data-storage-bug-locks-out-users-remains-unfixed/">https://arstechnica.com/gadgets/2023/10/android-14s-ransomware-data-storage-bug-locks-out-users-remains-unfixed/</a>, See on <a href="https://news.ycombinator.com/item?id=38043574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Back up your data!    —
</h4>
            
            <h2 itemprop="description">Users with multiple profiles are getting locked out of local storage and losing data.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2013/10/android-lockup.jpg" alt="Android 14’s user-profile data bug seems indistinguishable from ransomware">
      <figcaption><p>Aurich Lawson</p></figcaption>  </figure>

  




<!-- cache hit 188:single/related:e6e51722ea3a7db761540f225f7d54d6 --><!-- empty -->
<p>Android 14 has a nasty storage bug that seems to be affecting users of the "multiple profiles" feature. The bug is about as bad as you can get, with users having "unusable" devices due to getting locked out of device storage. A few users are <a href="https://issuetracker.google.com/issues/305766503#comment284">likening</a> the experience to getting hit with "ransomware."</p>
<p><a href="https://www.theverge.com/2023/10/16/23919957/pixel-6-android-14-upgrade-bugs-multiple-user-profiles">Earlier reports</a> had this bug limited to the Pixel 6, but Google seemed to ignore those reports, and now with a wider rollout, this does not seem device-specific. Everything upgrading to Android 14 this early seems to be affected: <a href="https://issuetracker.google.com/issues/305766503?pli=1">Pixel 6</a>, <a href="https://issuetracker.google.com/issues/305766503#comment122">6a</a>, <a href="https://issuetracker.google.com/issues/305766503#comment7">7</a>, <a href="https://issuetracker.google.com/issues/305766503#comment104">7a</a>, <a href="https://issuetracker.google.com/issues/305766503#comment121">Pixel Fold</a>, and <a href="https://issuetracker.google.com/issues/305766503#comment353">Pixel Tablet.</a></p>
<p>The Google <a href="https://issuetracker.google.com/issues/305766503?pli=1">issue tracker</a> for this is now up to over 350 replies and has had no response from Google. The bug is languishing at only the medium "P2" priority (P0 is the highest) and remains "unassigned," meaning, assuming the tracker is up to date, no one is looking into it.</p>
<p>Some users have <a href="https://issuetracker.google.com/issues/305766503#comment45">helpfully posted</a> log files full of worrying messages, like, "Failed to open directory /data/media/0: Structure needs cleaning." Being locked out of your own device's data partition causes all sorts of bizarre issues. Some users are boot looping, others are stuck on a "Pixel is starting..." message, while others can get into the phone. If your phone tries to continue trucking with no local storage, you'll be inundated with all sorts of error messages. The camera app claims to be "<a href="https://issuetracker.google.com/issues/305766503#comment38">out of storage</a>," and you can't take screenshots because there's nowhere to store the screenshots. The file manager lists <a href="https://issuetracker.google.com/issues/305766503#comment38">0 bytes</a> for every type of file and empty folder, and the files also aren't viewable from a PC over USB. The System UI and Settings also keep crashing. Basically, computers need storage to function!</p>
<p>Android's user-profile system allows for both multiple users on a single device (which is good for tablets) and splitting up <a href="https://arstechnica.com/information-technology/2015/03/a-review-of-android-for-work-dual-persona-support-comes-to-android/">"home" and "work" profiles</a> to keep your work data separate from your personal data, via duplicate apps. It sounds like the bug is only hitting users who take advantage of this rarely used feature, with lots of reports that the primary profile—that's usually the important one—gets locked out.</p>                                            
                                                        
<p>Several users are complaining about the data lost from all of this, so it's a good time to remind people to always have a backup of everything on their phones. Even straight out of the box, Android has options for Google Photos automatic backups, Play Games storage of your game data, and a million other cloud-based data features (it would be nice if Android phones had a comprehensive whole-phone backup feature, though). While it is totally reasonable to expect your OS to keep running after an update, phones are uniquely vulnerable to getting lost/stolen/damaged, so having everything get stored somewhere else is a great idea. Shockingly, <a href="https://www.reddit.com/r/GooglePixel/comments/178jj3i/need_help_pixel_7_stuck_on_phone_is_starting/">several users</a> report the phone is<a href="https://issuetracker.google.com/issues/305766503#comment43"><em> automatically</em></a> doing a factory reset, which deletes all your data, shutting down any possibility of data recovery. This feature should probably not exist, but it's another sign that phones are not a reliable storage medium for critical data.</p>
<p>What's so strange about how Google is handling this bug is that the company <em>has tools</em> to deal with this. Google delivers software on a slow and often frustrating "roll out" strategy, where a small percentage of users will get an update at first, and as the days pass, more and more users opt in to the update. Google does this to see if any problems pop up via its extensive Android analytics system, and if a problem is detected, the update rollout can be halted, limiting the problem to as few people as possible.</p>
<p>Why didn't that happen here? Surely, a bug where people are locked out of their phones and possibly lose data is worth halting a rollout, but it never happened. Google's entire response to this problem has been lacking. To our knowledge, no one from Google has officially addressed the issue in the 10-ish days it has been around. It hasn't issued statements to the several sites that have already reported on this. No one is replying to the bug tracker, and the issue is unassigned. What's up, Google?</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Images from the 2023 Nikon Small World Photomicrography Competition (148 pts)]]></title>
            <link>https://www.nikonsmallworld.com/galleries/2023-photomicrography-competition</link>
            <guid>38043127</guid>
            <pubDate>Fri, 27 Oct 2023 19:54:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nikonsmallworld.com/galleries/2023-photomicrography-competition">https://www.nikonsmallworld.com/galleries/2023-photomicrography-competition</a>, See on <a href="https://news.ycombinator.com/item?id=38043127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <section id="galleryapp" v-touch:swipe.left="pageNext" v-touch:swipe.right="pagePrev">

            <section id="winner_gallery">
    <h2>Top 20</h2>
        
        <hr>
    
        
              </section>
              <section id="honorable-mention_gallery">
    <h2>Honorable Mentions</h2>
        
        <hr>
        
    
        
              </section>
              <section id="image-of-distinction_gallery">
    <h2>Images of Distinction</h2>
        
        <hr>
        
    
            
          </section>
      <section id="judges">
    <h2>Judges</h2>
  <div>
                      <div>
          <h3>Dr. Clare Waterman</h3>
          <p><em>Cell Biologist and Member of the National Academy of Sciences</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Clare-Waterman.jpg" width="120"></p><p>Clare Waterman graduated from Mount Holyoke College with a B.A. in biochemistry in 1989. From there, she received an M.S. in exercise science in 1991 from the <a href="https://www.nikonsmallworld.com/organizations/university-of-massachusetts-boston">University of Massachusetts</a>, and her Ph.D. in cell biology from the <a href="https://www.nikonsmallworld.com/organizations/university-of-pennsylvania">University of Pennsylvania</a> in 1995. She then spent nine years as a professor in the Department of Cell Biology at <a href="https://www.nikonsmallworld.com/organizations/the-scripps-research-institute">The Scripps Research Institute</a> in La Jolla, California. Dr. Waterman has received numerous awards and honors for her work, including election to the National Academy of Sciences and the Arthur S. Flemming Award for Public Service in Basic Science. Dr. Waterman has made fundamental advances in the understanding of cell migration and has authored or co-authored more than 150 papers. She currently serves on the editorial boards of <em>Current Biology</em> and <em>Journal of Microscopy</em>. Dr. Waterman is a member of the American Society for Cell Biology, Royal Microscopical Society, Biophysical Society, and is a Council Member of Gordon Research Conferences Organization.</p>
        </div>
                      <div>
          <h3>James Cutmore</h3>
          <p><em>Picture Editor at BBC Science Focus Magazine</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/James-Cutmore.jpg" width="120"></p><p>James Cutmore has worked for BBC’s science and technology publication <em><a href="https://www.sciencefocus.com/" target="_blank" rel="noreferrer noopener">BBC Science Focus</a></em> since 2004, telling compelling science stories through stunning science imagery. He holds a bachelor’s degree in fine art from the University of West England and was highly commended in 2020, having been nominated for the British Society of Magazine Editors Talent Awards. He is passionate about sourcing images that not only illustrate a range of difficult and complex concepts but highlight positive technology and the natural world. For many years he was a judge for the Wellcome Trust’s image competition, as well as the Royal Photographic Society.</p>
        </div>
                      <div>
          <h3>Ed Cara</h3>
          <p><em>Science and Health Reporter at Gizmodo</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Ed-Cara.jpg" width="120"></p><p>Born and raised in New York City, Ed Cara currently covers the public health and science beat at <em><a href="https://gizmodo.com/author/edcara" target="_blank" rel="noreferrer noopener">Gizmodo</a></em>. His past feature and investigative reporting can be seen in <em>The Atlantic</em>, <em>Pacific Standar</em>d and <em>Undark Magazine</em>.</p>
        </div>
                      <div>
          <h3><a href="https://www.nikonsmallworld.com/people/dr.-igor-siwanowicz">Dr. Igor Siwanowicz</a></h3>
          <p><em>Research Scientist at Howard Hughes Medical Institute</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Igor-Siwanowicz.jpg" width="120"></p><p><a href="https://www.nikonsmallworld.com/people/dr.-igor-siwanowicz">Igor Siwanowicz</a> began his career in biochemistry, but his love for animals and nature, and a desire to see the bigger picture, drove him to refocus his scientific discipline on neurobiology. This transition was facilitated by his expertise in invertebrate morphology, which he developed through macro photography. A confocal microscope became his key tool of trade, allowing for even more intimate insight into natural forms than a macro lens. Dr. Siwanowicz’s images have placed a total of <a href="https://www.nikonsmallworld.com/people/dr.-igor-siwanowicz">25 times in the Nikon Small World</a> and other scientific imaging competitions. In 2020, he received an award from the Royal Photographic Society for scientific imaging. For the past 10 years, Dr. Siwanowicz has been studying the anatomy and biomechanics of movement in invertebrates at the <a href="https://www.nikonsmallworld.com/organizations/howard-hughes-medical-institute-hhmi">Janelia Research Campus of Howard Hughes Medical Institute</a> in Ashburn, Virginia.</p>
        </div>
                      <div>
          <h3>Dr. Gary Laevsky</h3>
          <p><em>Director of the Confocal Imaging Facility at Princeton University</em><br><a href="https://www.nikonsmallworld.com/organizations/princeton-university"></a></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Gary-Laevsky.jpg" width="120"></p><p>Gary Laevsky received his Ph.D. in Cell Biology from the University of Connecticut in 2003 and completed his post-doctoral research at <a href="https://www.nikonsmallworld.com/organizations/the-scripps-research-institute">The Scripps Research Institute</a> in La Jolla, California. Prior to joining the Department of Molecular Biology at <a href="https://www.nikonsmallworld.com/organizations/princeton-university">Princeton University</a>, he was the Product Manager for Olympus, a Senior Biosystems Applications Manager for Nikon, and an Imaging Applications Specialist for Andor Technology. Since joining Princeton University in 2013 as Director of the Confocal Imaging Facility, he has achieved the title of Senior Professional Specialist, the highest non-faculty level position that can be achieved. He has also been selected to sit on the Committee on Appointments and Advancement for Professional Researchers and Professional Specialists. Dr. Laevsky is a co-founder of the North Atlantic Microscopy Society (NAMS), Course Laboratory Director for the Analytical and Quantitative Light Microscopy (AQLM) course at the <a href="https://www.nikonsmallworld.com/organizations/marine-biological-laboratory">Marine Biological Laboratory (MBL)</a>, and co-founder of the Light-Sheet Fluorescence Microscopy (LSFM) Conference and Workshop, also at MBL.</p>
        </div>
          </div>
    
      </section>
  </section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shadow: New browser engine made almost entirely in JavaScript (320 pts)]]></title>
            <link>https://goose.icu/introducing-shadow/</link>
            <guid>38043033</guid>
            <pubDate>Fri, 27 Oct 2023 19:46:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://goose.icu/introducing-shadow/">https://goose.icu/introducing-shadow/</a>, See on <a href="https://news.ycombinator.com/item?id=38043033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h3>&lt;shadow&gt; is a new novel browser engine made almost entirely in JS</h3></p></div><section><p>So I started making a browser engine (for fun) a few days ago, it felt kind of inevitable so here we are. Here’s a short rundown. <a href="https://github.com/canadahonk/shadow" target="_blank" rel="noopener">Source code too!</a></p><h2 id="try-it-in-your-browserhttpsshadowgooseicu"><a href="https://shadow.goose.icu/" target="_blank" rel="noopener">Try it in your browser!</a></h2><h4 id="screenshot-of-ltshadowgts-welcome-page-running-inside-ltshadowgt-as-of-writing">Screenshot of <em><strong>&lt;shadow&gt;</strong></em>’s welcome page running inside <em><strong>&lt;shadow&gt;</strong></em> (as of writing)</h4><p><img src="https://github.com/CanadaHonk/shadow/assets/19228318/9431b624-94aa-4209-87c9-60d2478badf6" alt="Screenshot of shadow&amp;rsquo;s welcome page in shadow"></p><h3 id="what">What?</h3><p>A browser(/web) engine essentially takes in a URL(/etc) and gives you it rendered into a window for you to view and interact with. <em><strong>&lt;shadow&gt;</strong></em> does this too, almost entirely from scratch, made in JS. It runs in your browser! Node backend soon™ too? The host browser(/etc) is only used for networking (<code>fetch</code>) and renderer backend (<code>&lt;canvas&gt;</code>).</p><h4 id="components-of-ltshadowgt">Components of <em><strong>&lt;shadow&gt;</strong></em></h4><p><img src="https://mermaid.ink/svg/pako:eNpVkT1vhDAMhv8KygxVaTuB1Kljp96axSLukQtJUByK0N399zogFJAyOI_f1x_yXXReoWjENcDYF98_rXRF0YH7A6peqs_eU0zEYZx9MNpdj5R6UH6uGEQ7jBAIwwlnV8LKW2YdUVZmH2c4vzbfBYwGWPwUszn_t4hRQKcwbOX2-KQ8wG2vBGcgmzahUXPSemdwOXKjkXDIjR9-jJV2j9vqvlEed42TTbp1Lu3MJS4DFq9lXdb83gqKwRtsAqr2LKnfy_pjT_MFllaUwvI8oBXf5J7UUsQeLUrRcKggGCmke7IOpugvi-tEE8OEpZhGBRG_NHAhK5pfGAif_zYlpas?bgColor=101418" alt="Component flowchart">
(red = external/not me)</p><h3 id="why-make-it">Why make it?</h3><p>It’s just for fun, no really. Learning too. It will probably never work with 90% of websites, and that’s okay. <del>Also it’s funny to see people react in many forms of “wtf?"</del></p><h3 id="screenshot-of-serenityosorg-running-inside-ltshadowgt-left-vs-firefox-right">Screenshot of serenityos.org running inside <em><strong>&lt;shadow&gt;</strong></em> (left) vs Firefox (right)</h3><p>Pretty spot on! No list markers yet. Colors are different as UA/browser defined.</p><h3 id="name">Name</h3><p>As with all my recent projects, the name is because I thought it was kind of funny at the time. <em><strong>&lt;shadow&gt;</strong></em> is named after the defunct &lt;shadow&gt; element. I mostly stole this idea from Blink (was it intentional to name it after a dead HTML element at the time?). Also it sounds spooky and mysterious so that’s a bonus I guess? (It’s also stylized as <em><strong>&lt;shadow&gt;</strong></em> because of this.)</p><h3 id="it-supports-javascript">It supports JavaScript??!</h3><p>Yes, kind of. This is quite complicated (as you can probably imagine), so I’ll do it in a separate future dedicated post if you’re interested (DM/reply me on twitter).</p><h3 id="why-publish-it">Why publish it?</h3><p>Why not? If someone can learn something or just find what I make fun/interesting, that makes me happy :)</p><h3 id="but-making-a-new-browser-engine-is-impossible">But making a new browser engine is impossible!</h3><p><a href="https://ladybird.dev/" target="_blank" rel="noopener">No</a>. <a href="https://servo.org/" target="_blank" rel="noopener">It</a>. <a href="https://www.ekioh.com/flow-browser/" target="_blank" rel="noopener">Isn’t</a>! <em>(Also I don’t really care how possible/feasible something is.)</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft is failing to deliver emails that mention newclimate.org (154 pts)]]></title>
            <link>https://newclimate.org/news/microsoft-error-or-external-attack-causing-disruption-to-email-communication-across-the</link>
            <guid>38042114</guid>
            <pubDate>Fri, 27 Oct 2023 18:30:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newclimate.org/news/microsoft-error-or-external-attack-causing-disruption-to-email-communication-across-the">https://newclimate.org/news/microsoft-error-or-external-attack-causing-disruption-to-email-communication-across-the</a>, See on <a href="https://news.ycombinator.com/item?id=38042114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                            <center>
<p><em>(in case you share a link to this page by email, please use this bit.ly link <a href="https://bit.ly/NewClimate_MicrosoftStatement">https://bit.ly/NewClimate_MicrosoftStatement</a> to ensure delivery)</em></p>
</center>

<p>Since 17 October, to our knowledge any email with the NewClimate URL (newclimate dot org) in the email body, link, signature, reply header or contained anywhere in an attachment is unjustifiably quarantined by Microsoft email servers without any notice, regardless of who sends or receives the email.</p>

<p>That our own email flow is disrupted is the least of our problems: all Microsoft tenants are afflicted by the same issue when this URL appears in their emails, or any attachments they share, even when we are not a party to the communications.</p>

<p><strong>Hundreds of governmental and non-governmental organisations working on climate change appear to be experiencing disruption to email communication when their communications contain any reference to the NewClimate URL. </strong></p>

<p>For example, as per our understanding:</p>

<ul><li>No organisation using Microsoft email services can currently send the <strong>IPCC Sixth Assessment Report of Working Group 3 </strong>as an attachment to anyone else (newclimate dot org URL appears 11 times in the report). The same applies to <strong>hundreds of other relevant scientific papers and reports </strong>from any organisations, where NewClimate URLs appear on the reference lists.</li>
	<li>Any <strong>multi-organisation email chain</strong> where <em>any </em>of the participants uses Microsoft email services is breaking down in the case that NewClimate URLs are included. This could arise either because a NewClimate colleague is on the mailing list in the chat history, or if a NewClimate publication is linked to, in the email or the chat history.</li>
	<li>Even <strong>a link to this article on the NewClimate website cannot be spread by email </strong>if the sender or recipient uses Microsoft as email service.</li>
</ul><p>We understand that the majority of our partner organisations within the climate community use Microsoft email services, including the United Nations Framework Convention for Climate Change (UNFCCC) and the Intergovernmental Panel on Climate Change (IPCC).</p>

<p>It came as a surprise to us that this is even possible. It remains unclear whether this is the result of a targeted attack on Microsoft’s infrastructure against NewClimate, or simply a highly unfortunate error on the part of Microsoft. In our consultations with Microsoft and a number of independent IT experts, we have confirmed that we are not on any blacklist and our website is also free of malware.</p>

<p>We are fully dependent on Microsoft to prioritise and solve the issue, but Microsoft support agents have been difficult to engage and – to our understanding – disinclined to prioritise the issue. It is not clear whether Microsoft is aware of the inconvenience and disruption beyond our own organisation.</p>

<p>Beyond being an existential threat to our own organisation, this issue could significantly disrupt communication within the climate community at a time when it is most critical in the run up to COP28 in at the end of 2023 in Dubai. <strong>We greatly appreciate any support to bring this issue to the attention of Microsoft’s senior management so that it can be prioritised and resolved.</strong></p>

<p>This is extremely unfortunate and we apologise for any inconvenience that this may cause or may have caused.</p>

<p>We understand that partner organisations who use Microsoft email exchange services and that are experiencing email deliverability problems because of this issue may be able to apply a band-aid fix for email flow, by reporting to Microsoft that the NewClimate URL should not be blocked (see ‘Submission form for reporting false positives for Microsoft’s URL detonation policy’, available in the Microsoft admin center). This may help individual organisations to improve issues with their own incoming and outgoing email flow, but it does not help to resolve communication issues with other organisations that use Microsoft.</p>

<p>Emails are only quarantined when the text “newclimate(dot)org” appears in the email and not if a diverted link to the NewClimate website through e.g. tinyurl is included instead.</p>

                                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google paid $26.3B in 2021 to be the default search engine everywhere (166 pts)]]></title>
            <link>https://www.theverge.com/2023/10/27/23934961/google-antitrust-trial-defaults-search-deal-26-3-billion</link>
            <guid>38041335</guid>
            <pubDate>Fri, 27 Oct 2023 17:26:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/10/27/23934961/google-antitrust-trial-defaults-search-deal-26-3-billion">https://www.theverge.com/2023/10/27/23934961/google-antitrust-trial-defaults-search-deal-26-3-billion</a>, See on <a href="https://news.ycombinator.com/item?id=38041335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The <a href="https://www.theverge.com/23869483/us-v-google-search-antitrust-case-updates"><em>US v. Google</em> antitrust trial</a> is about many things, but more than anything, it’s about the power of defaults. Even if it’s easy to switch browsers or platforms or search engines, the one that appears when you turn it on matters a lot. Google obviously agrees and has paid a staggering amount to make sure it is the default: testimony in the trial revealed that Google spent a total of $26.3 billion in 2021 to be the default search engine in multiple browsers, phones, and platforms.</p><p>That number, the sum total of all of Google’s search distribution deals, came out during the Justice Department’s cross-examination of Google’s search head, Prabhakar Raghavan. It was made public after a debate earlier in the week between the two sides and Judge Amit Mehta over whether the figure should be redacted. Mehta has begun to push for more openness in the trial in general, and this was one of the most significant new pieces of information to be shared openly.</p><p>Just to put that $26.3 billion in context: Alphabet, Google’s parent company, announced in <a href="https://www.theverge.com/2023/10/24/23929496/google-alphabet-q3-2023-earnings-ads-ai-sge">its recent earnings report</a> that Google Search ad business brought in about $44 billion over the last three months and about $165 billion in the last year. Its entire ad business — which also includes YouTube ads — made a bit under $90 billion in profit. This is all back-of-the-napkin math, but essentially, Google is giving up about 16 percent of its search revenue and about 29 percent of its profit to those distribution deals. </p><div><p>Google is giving up about 16 percent of its search revenue and about 29 percent of its profit to those distribution deals</p></div><p>Most of that money, of course, goes to Apple. <em>The New York Times</em> recently reported that Google’s deal to be the default search engine in Safari across Google products cost the company <a href="https://www.theverge.com/2023/10/26/23933206/google-apple-search-deal-safari-18-billion">about $18 billion</a> in 2021. (Apple’s outsize percentage of the total is why that particular deal <a href="https://www.theverge.com/2023/10/11/23913287/us-v-google-apple-search-deal">has been such a focus</a> of the first weeks of the trial.) In addition, Google pays Mozilla for default placement in Firefox; it pays Samsung for the same on its devices; and it has deals with many device makers, wireless carriers, and other platforms to be the default as well.</p><p>Until now, these numbers have been closely held secrets, leaving competitors and analysts to speculate about exactly what it’s worth to Google to be the near-universal default choice. The information also comes as Google is beginning its defense portion of the trial, which started with Raghavan testifying that Google is at perpetual risk of losing its cool — and its users — to platforms like TikTok and ChatGPT. Raghavan said that some users call his search engine “Grandpa Google.” (Raghavan has been <a href="https://www.theverge.com/23365101/tiktok-search-google-replacement">saying stuff like this</a> for a while now.) He also said that he sees Yelp and Amazon as competitors and that, in such a hot market, Google has to do everything it can to stay relevant and compete. The Justice Department, on the other hand, is making the case that spending $26.3 billion on securing default status everywhere is actually a way to make sure the market <em>isn’t</em> competitive. After a few more weeks of testimony, Mehta will have to decide who’s right.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generate images in one second on your Mac using a latent consistency model (190 pts)]]></title>
            <link>https://replicate.com/blog/run-latent-consistency-model-on-mac</link>
            <guid>38040702</guid>
            <pubDate>Fri, 27 Oct 2023 16:37:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://replicate.com/blog/run-latent-consistency-model-on-mac">https://replicate.com/blog/run-latent-consistency-model-on-mac</a>, See on <a href="https://news.ycombinator.com/item?id=38040702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Latent consistency models (LCMs) are based on Stable Diffusion, but they can generate images much faster, needing only 4 to 8 steps for a good image (compared to 25 to 50 steps). By running an LCM on your M1 or M2 Mac you can generate 512x512 images at a rate of one per second.</p>
<p><a href="https://arxiv.org/abs/2310.04378">Simian Luo et al</a> released the first Stable Diffusion distilled model. It’s distilled from the Dreamshaper fine-tune by incorporating classifier-free guidance into the model’s input. Only one model has been distilled so far, but more will be released. Stable Diffusion 2.1 and SDXL are being worked on by the paper authors.</p>
<p>You can run the first <a href="https://replicate.com/luosiallen/latent-consistency-model">latent consistency model in the cloud on Replicate</a>, but it’s also possible to run it locally. As well as generating predictions, you can hack on it, modify it, and build new things.</p>
<p>We’ve written this guide to help you get started.</p>
<video autoplay="" controls="" loop="" src="https://replicate.com/static/blog/run-latent-consistency-model-on-mac/output.mp4"></video>

<h2 id="prerequisites">Prerequisites</h2>
<p>You’ll need:</p>
<ul>
<li>a Mac with an M1 or M2 chip</li>
<li>16GB RAM or more</li>
<li>macOS 12.3 or higher</li>
<li>Python 3.10 or above</li>
</ul>
<p>We’ve found that an M1 Max or M2 with 32GB RAM can generate images in 1 second. An M1 Pro with 16GB RAM can generate images in 2 to 4 seconds. Please <a href="https://github.com/replicate/latent-consistency-model">share your benchmarks with us on our Github repository</a>.</p>
<h2 id="set-up-python">Set up Python</h2>
<p>You need Python 3.10 or above. Run <code>python -V</code> to see what Python version you have installed:</p>
<pre><code>$ python3 -V
Python 3.10.6
</code></pre>
<p>If it’s 3.10 or above, like here, you’re good to go! Skip on over to the next step.</p>
<p>Otherwise, you’ll need to install Python 3.10. The easiest way to do that is with Homebrew. First, <a href="https://brew.sh/">install Homebrew</a> if you haven’t already.</p>
<p>Then, install the latest version of Python:</p>
<pre><code>brew update
brew install python
</code></pre>
<p>Now if you run <code>python3 -V</code> you should have 3.10 or above. You might need to reopen your console to make it work.</p>
<h2 id="clone-the-repository-and-install-the-dependencies">Clone the repository and install the dependencies</h2>
<p>Run this to <a href="https://github.com/replicate/latent-consistency-model">clone the LCM script from Github</a>:</p>
<pre><code>git clone https://github.com/replicate/latent-consistency-model.git
cd latent-consistency-model
</code></pre>
<p>Then, set up a virtualenv to install the dependencies:</p>
<pre><code>python3 -m pip install virtualenv
python3 -m virtualenv venv
</code></pre>
<p>Activate the virtualenv:</p>
<pre><code>source venv/bin/activate
</code></pre>
<p>(You’ll need to run this command again any time you want to run the script.)</p>
<p>Then, install the dependencies:</p>
<pre><code>pip install -r requirements.txt
</code></pre>
<h2 id="run-it">Run it!</h2>
<p>Now, you can run your latent consistency model. The script will automatically download the <a href="https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7"><code>SimianLuo/LCM_Dreamshaper_v7</code></a> (3.44 GB) and <a href="https://huggingface.co/CompVis/stable-diffusion-safety-checker">safety checker</a> (1.22 GB) models from HuggingFace.</p>
<pre><code>python main.py \
  "a beautiful apple floating in outer space, like a planet" \
  --steps 4 --width 512 --height 512
</code></pre>
<p>You’ll see an output like this:</p>
<pre><code>Output image saved to: output/out-20231026-144506.png
Using seed: 48404
100%|███████████████████████████| 4/4 [00:00&lt;00:00,  5.54it/s]
</code></pre>
<p>We’ve also added a <code>--continous</code> flag, so you can keep on generating image after image until your harddrive is full. Generations after the first one will run a bit faster too.</p>
<pre><code>python main.py \
  "a beautiful apple floating in outer space, like a planet" \
  --steps 4 --width 512 --height 512 --continuous
</code></pre>
<p>That’s it!</p>
<p><img alt="Latent consistency model generation of a beautiful apple floating in outer space, like a planet" src="https://replicate.com/static/blog/run-latent-consistency-model-on-mac/output.webp"></p>
<h2 id="next-steps">Next steps</h2>
<ul>
<li>If you’re struggling to get this set up, or you aren’t getting fast speeds, <a href="https://discord.gg/replicate">ask in our Discord for some help</a>. Or take a look at <a href="https://github.com/replicate/latent-consistency-model">our Github repository</a>.</li>
<li>You can <a href="https://replicate.com/docs/guides/push-a-model">push custom models to Replicate</a> if you want to host your creations.</li>
<li><a href="https://replicate.com/fofr/latent-consistency-model">Try out a latent consistency model with img2img support</a> on Replicate</li>
<li><a href="https://x.com/replicate">Follow @replicate on X</a>.</li>
</ul>
<p>Happy hacking!</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Biblos – Semantic Bible Embedded Vector Search and Claude LLM (103 pts)]]></title>
            <link>https://github.com/dssjon/biblos</link>
            <guid>38040591</guid>
            <pubDate>Fri, 27 Oct 2023 16:28:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dssjon/biblos">https://github.com/dssjon/biblos</a>, See on <a href="https://news.ycombinator.com/item?id=38040591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-biblos---bible-exploration-with-vector-search-and-summarization" dir="auto"><a href="#biblos---bible-exploration-with-vector-search-and-summarization">Biblos - Bible Exploration with Vector Search and Summarization</a></h2>
<p dir="auto">Biblos allows semantic search and summarization of Bible passages using state-of-the-art NLP techniques:</p>
<ul dir="auto">
<li>Vector search over the entire Bible text using <a href="https://github.com/chroma-core/chroma">Chroma</a> and BAAI BGE embeddings</li>
<li>Summarization of search results using <a href="https://www.anthropic.com/" rel="nofollow">Anthropic's Claude</a> large language model</li>
</ul>
<p dir="auto">This enables powerful semantic search over biblical texts to find related passages, along with high quality summaries of the relationships between verses on a given topic.</p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<ul dir="auto">
<li>Semantic search over the entire Bible text</li>
<li>Summarization of search results using Claude LLM</li>
<li>Web UI built with Streamlit for easy exploration</li>
<li>Leverages Chroma for vector search over BAAI BGE embeddings</li>
<li>Modular design allowing swapping of components like DB, embeddings, LLM etc.</li>
</ul>
<h2 tabindex="-1" id="user-content-architecture" dir="auto"><a href="#architecture">Architecture</a></h2>
<p dir="auto">Biblos follows a RAG (Retrieval Augmented Generation) architecture:</p>
<ol dir="auto">
<li>Bible text is indexed in a Chroma vector database using BGE sentence embeddings</li>
<li>User searches for a topic, and relevant passages are retrieved by semantic similarity</li>
<li>Top results are collated and passed to Claude to generate a summarization</li>
</ol>
<p dir="auto">This enables combining the strengths of dense vector search for retrieval with a powerful LLM for summarization.</p>
<p dir="auto">The UI is built using Streamlit for easy exploration, with Python code modularized for maintainability.</p>
<h2 tabindex="-1" id="user-content-running-biblos" dir="auto"><a href="#running-biblos">Running Biblos</a></h2>
<p dir="auto">To run Biblos locally:</p>
<ol dir="auto">
<li>Install requirements</li>
<li>Download and preprocess Bible text into a Chroma database</li>
<li>Launch the Streamlit app:</li>
</ol>
<div data-snippet-clipboard-copy-content="pip install -r requirements.txt

python create_db.py

streamlit run app.py"><pre><code>pip install -r requirements.txt

python create_db.py

streamlit run app.py
</code></pre></div>
<h2 tabindex="-1" id="user-content-credits" dir="auto"><a href="#credits">Credits</a></h2>
<p dir="auto">Biblos leverages the following open source projects:</p>
<ul dir="auto">
<li><a href="https://github.com/langchain-ai/langchain">Langchain</a> - Building LLMs through composability</li>
<li><a href="https://github.com/chroma-core/chroma">Chroma</a> - Vector similarity search</li>
<li><a href="https://www.anthropic.com/" rel="nofollow">Anthropic</a> - Claude summarization model</li>
<li><a href="https://huggingface.co/BAAI/bge-large-en-v1.5" rel="nofollow">BAAI BGE Embeddings</a> - Text embeddings</li>
<li><a href="https://streamlit.io/" rel="nofollow">Streamlit</a> - Web UI</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Not of faculty quality': How Penn mistreated Nobel Prize-winning researcher (427 pts)]]></title>
            <link>https://www.thedp.com/article/2023/10/penn-katalin-kariko-university-relationship-mistreatment</link>
            <guid>38040468</guid>
            <pubDate>Fri, 27 Oct 2023 16:16:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedp.com/article/2023/10/penn-katalin-kariko-university-relationship-mistreatment">https://www.thedp.com/article/2023/10/penn-katalin-kariko-university-relationship-mistreatment</a>, See on <a href="https://news.ycombinator.com/item?id=38040468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
        <p>Three weeks ago, Penn hosted a <a href="https://www.thedp.com/article/2023/10/penn-nobel-prize-winners-flash-mob" target="_blank">flash mob</a> for Katalin Karikó after she won the 2023 Nobel Prize in Medicine. But the celebration masked a tumultuous, decades-long relationship between Karikó and the University.</p>
<p>Karikó, an adjunct professor of neurosurgery at the Perelman School of Medicine, won the <a href="https://www.thedp.com/article/2023/10/penn-medicine-kariko-weissman-scientists-nobel-prize-mrna-covid-technology" target="_blank">Nobel Prize in Medicine</a> for her past research into mRNA technology alongside co-laureate and Roberts Family Professor in Vaccine Research at the Medical School Drew Weissman. Karikó and Weissman's research was critical for the development of the COVID-19 vaccines — from <a href="https://www.thedp.com/article/2023/04/penn-licensing-revenue-first-national-universities" target="_blank">which Penn has earned around $1.2 billion</a>.</p>
<p>"At a University built around [a] Franklin spirit, there are no better exemplars of these character traits than our Nobel laureates, Dr. Kati Karikó and Dr. Drew Weissman," Penn President Liz Magill <a href="https://www.thedp.com/article/2023/10/penn-medicine-kariko-weissman-scientists-nobel-prize-mrna-covid-technology" target="_blank">said</a> at a press conference the day the prize was named.</p>
<p>However, eight current and former colleagues of Karikó told The Daily Pennsylvanian that — over the course of three decades — the University repeatedly shunned Karikó and her research, despite its groundbreaking potential.&nbsp;</p>
<p>The colleagues told a story of a researcher whose work ethic helped her succeed against all odds — including doubtful administrators, language barriers, and a system that cuts costs by demoting researchers who fail to earn grant funding.</p>
<p>"We acknowledge and are grateful for the valuable contributions Dr. Karikó has made to science and to Penn throughout her time with the University," a University spokesperson wrote in a statement to the DP.</p>
<p>In 1989, four years after she arrived in the United States, Karikó was appointed an adjunct professor at the Medical School. She worked on mRNA research under cardiologist Elliot Barnathan until his departure in 1997.</p>
<p>From the very beginning of her time at Penn, Karikó's research was overlooked by medical school executives, she wrote in her recently published memoir, "Breaking Through: My Life in Science." These executives included Jim Wilson, the director of Penn’s <a href="https://www.thedp.com/article/2022/04/upenn-gene-therapy-program-jim-wilson-corrupt-investigation-toxic-workplace" target="_blank">embattled Gene Therapy Program</a>, and Judith Swain, chief of cardiovascular medicine. Wilson remains a member of Penn's faculty.</p>
<p>Wilson did not respond to a request for comment.&nbsp;</p>
<p>“[Jim] Wilson never seemed interested in mRNA or my research," Karikó wrote. "He barely glanced my way; on the rare occasions he did, it always felt as if he were looking right through me."</p>
<p>After Karikó unsuccessfully appealed to Wilson for her research to be included in an upcoming grant, Swain requested that Karikó not attend similar meetings in the future — and asked Karikó to stop speaking to her Hungarian colleague in their native language.</p>
        
        <hr>
<!-- gryphon/ads/rectangle.tpl -->

<hr>

        <p>"She told me 'people' were complaining about me, saying that I was too difficult," Karikó wrote of a time she was called to Swain's office.</p>
<p>During these early years, Karikó wrote that Penn prevented her from having access to basic lab supplies, such as deionized water. All of her grant applications for future research, directed at private and government agencies and the University Research Foundation, were also denied.</p>
<p>Five years into her tenure at Penn, Karikó was informed that she would not be promoted to the position of research associate professor, the typical stepping stone for researchers with her level of experience. In 1997, Barnathan, her supervisor, left the University, leaving Karikó without a clear path forward.&nbsp;</p>
<p>"[I had] no grants, no funding, [and] no respect from anyone with any formal power,” she wrote.</p>
<figure>
    <img src="https://snworksceo.imgix.net/dpn/a9ac37d2-2c61-4d59-b602-9171cced0e1c.sized-1000x1000.JPG?w=1000">
    <figcaption>
      <small>
                (Photo courtesy of Hamna Shahnawaz).
      </small>
    </figcaption>
</figure>
<p>After Barnathan left, Karikó was helped by a colleague, David Langer — now the chair of neurosurgery at New York’s Lenox Hill Hospital. Langer convinced the chair of Penn's neurosurgery department to hire Karikó as the department's senior head of research.</p>
<p>“If she wasn’t hired, there may not have been a COVID vaccine," Langer said.</p>
<p>Even at that early point in her career, Langer said he was confident that Karikó would make substantial strides in the field of mRNA.</p>
<p>“She is incredibly hardworking, just insane,” Langer said. "And she’s a genius, so eventually she was going to solve this problem, whether with me or with someone else.”</p>
<p>Not long after, Karikó met Drew Weissman, her future research partner and co-Nobel Prize laureate, during a chance encounter at a copy machine. Karikó and Weissman began to cooperate on research into mRNA technology.</p>
<p>2001 College graduate David Scales — now an assistant professor of medicine at Weill Cornell Medicine — worked in Karikó and Weissman’s lab as an undergraduate student at Penn. Scales said that he was surprised by the funding challenges faced by Karikó and other talented scientists.</p>

        <hr>
<!-- gryphon/ads/rectangle_2.tpl -->

<hr>

        <p>“It was weird to me to see this idea that they’re only going to fund you for a short amount of time, and if you’re not able to get external grants, then they’re going to wash their hands with you and say good luck," he said.</p>
<p>In 1999, Sean Grady — now the chair of the neurosurgery department — arrived at Penn and immediately sought to revisit the department's existing allocation of resources.</p>
<p>“Not long after arriving, Sean sat me down,” Karikó wrote. “He observed that I’d had some publications in reputable, if small, journals. But, he said, he was under tremendous budgetary pressure and was concerned about my lack of funding.”&nbsp;</p>
<p>Over the following years, Grady repeatedly critiqued Karikó — paying minimal attention to her research in favor of the metrics used by Penn to evaluate her success, such as publication records, citations, and funding.</p>
<p>“Unless something changes, this isn’t going to go well," Grady told Karikó, according to her memoir.</p>
<p>Grady and others within Penn Medicine aimed to maximize the returns on their investments in individual researchers, Langer said.&nbsp;</p>
<p>To Grady, $35,000 spent on Karikó was "$35,000 that could be spent supporting a new scientist who may make a discovery," Langer added.</p>
<p>In 2005, Karikó and Weissman jointly made the discovery that would later win them the Nobel Prize, receiving minimal recognition from the academic community at the time.</p>
<figure>
    <img src="https://snworksceo.imgix.net/dpn/9faead5e-a33d-45ae-b58b-d2135c3e2d34.sized-1000x1000.jpg?w=1000">
    <figcaption>
      <small>
                (Photo courtesy of Robert Sobol).
      </small>
    </figcaption>
</figure>
<p>Robert Sobol, a professor who worked with Karikó at Temple University before she moved to Penn, said that the development was "groundbreaking" in retrospect.</p>
<p>“Karikó and I started investigating RNA in the late 1990s, and we figured out what made it so inflammatory and how to get rid of the inflammation. We published that research in 2005,” Weissman <a href="https://www.thedp.com/article/2021/01/covid-19-vaccine-rollout-penn-health-system-staff-researchers-pennsylvania" target="_blank">previously told the DP</a>. “That is when people, at least academics, started to get interested in its potential, and companies started to get interested in it around 2010.”</p>

        <hr>
<!-- gryphon/ads/rectangle_3.tpl -->

<hr>

        <p>Karikó told the DP in 2020, as the <a href="https://www.thedp.com/article/2021/01/covid-19-vaccine-rollout-penn-health-system-staff-researchers-pennsylvania" target="_blank">first COVID-19 vaccines became available to Penn Med's frontline health workers and researchers</a>, that she knew the the discovery in 2005 would lead to major developments in the future.</p>
<p>“When I discovered the potential of the RNA, I had a feeling that it could be anything,” Karikó told the DP. “But nobody believed, so I couldn’t release that feeling.”</p>
<p>Her former colleague Norbert Pardi, who is now an assistant professor in Penn’s Department of Microbiology, said that Karikó and Weissman's work ethic motivated the entire lab to work harder.</p>
<p>Penn was eventually awarded a patent for the modified RNA developed by Karikó and Weissman, enabling the University to have the final say in how the patent would be licensed. To control the direction of future research, Karikó and Weissman sought to purchase the patent themselves — but it was sold in its entirety to a different company.&nbsp;</p>
<p>Karikó requested to be reinstated to a faculty position at Penn in 2010 but was initially rejected. Karikó wrote that administrators told her that she was "not of faculty quality" — citing how individuals who have previously been demoted can not be promoted back to the faculty track.</p>
<p>After Karikó appealed the decision and rejoined the faculty, colleagues said that Grady continued to undermine Karikó. But it was the removal of her lab space that pushed Karikó to leave Penn, according to an employee close to Karikó who requested anonymity due to fear of retaliation from the University.</p>
<p>“She was kicked out of her lab so many times, but she made something good out of all of these failures," Éva Remenyik, a Hungarian dermatologist close to Karikó, said.&nbsp;</p>
<p>In 2013, Karikó said she returned to her lab after spending time away to find all of her belongings having been packed, moved, and misplaced at Grady's direction. Karikó then left Penn's campus to work at BioNTech, a German company that focuses on mRNA-based technologies later that year.</p>
<p>Langer told the DP that many of Karikó’s superiors may not have recognized the impacts of her research and potential successes.</p>
<p>“People didn't necessarily see her as who she was going to become,” Langer said. “Michael Jordan was overlooked by two teams and is the greatest basketball player of all time, [and] Tom Brady was drafted 199th. The value and the ultimate success of somebody is not always readily apparent, even when it’s right in front of your eyes.”</p>
<p>Scales also said that Penn's approach of giving minimal funds to Karikó followed a similar model to most peer institutions. He said many research institutions provide some degree of startup funds, and the expectation is for researchers to acquire external grants otherwise.</p>
<p>All of those interviewed commended Karikó for winning the Nobel Prize alongside Weissman.</p>
<p>“I think it’s a testament to her fortitude,” Sobol said. “Now that you look back on the calendar, you see that she was 20 years ahead of where everyone is now.”</p>
<p>Scales said he hopes that Karikó's win will prompt changes to funding allocations in research.</p>
<p>“I do hope that it causes Penn and a bunch of other institutions that fund science this way to reflect a little bit on what the chances are that some scientists who do not get funding, and wind up leaving, end up being like Katalin Karikó,” Scales said.&nbsp;</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[18-year-old built a computer monitor that doesn't strain your eyes (156 pts)]]></title>
            <link>https://www.fastcompany.com/90971739/this-18-year-old-built-a-better-computer-monitor-that-doesnt-strain-your-eyes</link>
            <guid>38040164</guid>
            <pubDate>Fri, 27 Oct 2023 15:54:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastcompany.com/90971739/this-18-year-old-built-a-better-computer-monitor-that-doesnt-strain-your-eyes">https://www.fastcompany.com/90971739/this-18-year-old-built-a-better-computer-monitor-that-doesnt-strain-your-eyes</a>, See on <a href="https://news.ycombinator.com/item?id=38040164">Hacker News</a></p>
Couldn't get https://www.fastcompany.com/90971739/this-18-year-old-built-a-better-computer-monitor-that-doesnt-strain-your-eyes: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD: Removing syscall(2) from libc and kernel (122 pts)]]></title>
            <link>https://marc.info/?l=openbsd-tech&amp;m=169841790407370&amp;w=2</link>
            <guid>38039689</guid>
            <pubDate>Fri, 27 Oct 2023 15:23:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marc.info/?l=openbsd-tech&#x26;m=169841790407370&#x26;w=2">https://marc.info/?l=openbsd-tech&#x26;m=169841790407370&#x26;w=2</a>, See on <a href="https://news.ycombinator.com/item?id=38039689">Hacker News</a></p>
<div id="readability-page-1" class="page">
<pre><b>[<a href="https://marc.info/?l=openbsd-tech&amp;m=169840739832111&amp;w=2">prev in list</a>] [<a href="https://marc.info/?l=openbsd-tech&amp;m=169842095809570&amp;w=2">next in list</a>] [<span color="#c0c0c0">prev in thread</span>] [<a href="https://marc.info/?l=openbsd-tech&amp;m=169842095809570&amp;w=2">next in thread</a>] </b>
<b><span size="+1">
List:       <a href="https://marc.info/?l=openbsd-tech&amp;r=1&amp;w=2">openbsd-tech</a>
Subject:    <a href="https://marc.info/?t=169841803800006&amp;r=1&amp;w=2">Removing syscall(2) from libc and kernel</a>
From:       <a href="https://marc.info/?a=146809448200002&amp;r=1&amp;w=2">"Theo de Raadt" &lt;deraadt () openbsd ! org&gt;</a>
Date:       <a href="https://marc.info/?l=openbsd-tech&amp;r=1&amp;w=2&amp;b=202310">2023-10-27 14:45:41</a>
Message-ID: <a href="https://marc.info/?i=69276.1698417941%20()%20cvs%20!%20openbsd%20!%20org">69276.1698417941 () cvs ! openbsd ! org</a></span>
[Download RAW <a href="https://marc.info/?l=openbsd-tech&amp;m=169841790407370&amp;q=mbox">message</a> or <a href="https://marc.info/?l=openbsd-tech&amp;m=169841790407370&amp;q=raw">body</a>]</b>

Piece by piece, I've been trying to remove the easiest of the
terminal-actions that exploit code uses (ie. getting to execve, or performing
other system calls, etc).

I recognize we can never completely remove all mechanisms they
use. However, I hope I am forcing attack coders into using increasingly
more complicated methods. Same time, it means fewer methods are
available.  Other methods make exploitation more fragile.  This is
pushing success rates into "low-percent statistical" success. If we
teach more software stacks to "fail hard, don't try to recover", that is
an improvement in security.

I already made it difficult to call execve() directly in a few ways.
The kernel must be entered via the exact syscall instruction, inside the
libc syscall stub.  Immediately before that syscall instruction, the
SYS_execve instruction is loaded into a register.  On some
architectures, the PLT-reachable stub performs a retguard check, which
can be triggered by a few methods.  Stack pivots are also mostly
prevented because of other checks.  It is not possible to enter via
the SYS_syscall (syscall register = 0) case either.

Attack code can try to do perform other system calls, to create
filesystem damage or network communication.  They could still load other
syscall numbers and jump to a found syscall instruction, if they are
able to cheat the retguard epilogue (It is a bit unfortunate that libc
syscall stubs tend to use the same save register, but at least the
compare offset is chosen random at compile time).  Or, they could know
where all the system calls are from a pre-read libc, which requires them
to be on the machine before performing an online or offline attack (libc
is random relinked, but still readable in the filesystem).  It's
difficult to discover code-locations online only, because most
architectures also have xonly code now.  Some methods can use PLT
entries (which also vary based upon random relink), but I've not seem
much methodology using PLT entry + offset.

Anyways, everyone of these things I mention, and the ones I don't mention,
tend to be more difficult than the previous methods.  I'm trying to remove
simple methods, and force attackers into more and more complex methods.
I promise that I will circle back and damage the more complex methods in
the future.


So in this next step, I'm going to take away the ability to perform syscall #0
(SYS_syscall), with the first argument being the real system call.

This library interface, and all the pieces below it, will be going away:

    <a href="https://man.openbsd.org/syscall.2" rel="nofollow">https://man.openbsd.org/syscall.2</a>

There's going to be some fallout which takes time to fix, especially in the
"go" ecosystem.

Snapshots for some architectures now contain kernel diffs which reject
syscall(2).  The symbol still remains libc.

I'm including a piece of this diff.




Index: sys/arch/alpha/alpha/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/alpha/alpha/trap.c,v
diff -u -p -u -r1.108 trap.c
--- sys/arch/alpha/alpha/trap.c	8 Mar 2023 04:43:07 -0000	1.108
+++ sys/arch/alpha/alpha/trap.c	27 Oct 2023 03:26:49 -0000
@@ -497,17 +497,15 @@ dopanic:
  * a3, and v0 from the frame before returning to the user process.
  */
 void
-syscall(code, framep)
-	u_int64_t code;
-	struct trapframe *framep;
+syscall(u_int64_t code, struct trapframe *framep)
 {
-	const struct sysent *callp;
+	const struct sysent *callp = sysent;
 	struct proc *p;
-	int error, indirect = -1;
+	int error;
 	u_int64_t opc;
 	u_long rval<a name="-2"></a><a href="#2">[2]</a>;
 	u_long args<a name="-10"></a><a href="#10">[10]</a>;					/* XXX */
-	u_int hidden, nargs;
+	u_int nargs;
 
 	atomic_add_int(&amp;uvmexp.syscalls, 1);
 	p = curproc;
@@ -515,24 +513,11 @@ syscall(code, framep)
 	framep-&gt;tf_regs[FRAME_SP] = alpha_pal_rdusp();
 	opc = framep-&gt;tf_regs[FRAME_PC] - 4;
 
-	switch(code) {
-	case SYS_syscall:
-		indirect = code;
-		code = framep-&gt;tf_regs[FRAME_A0];
-		hidden = 1;
-		break;
-	default:
-		hidden = 0;
-	}
-
-	error = 0;
-	callp = sysent;
-	if (code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
-	nargs = callp-&gt;sy_narg + hidden;
+	nargs = callp-&gt;sy_narg;
 	switch (nargs) {
 	default:
 		if (nargs &gt; 10)		/* XXX */
@@ -559,7 +544,7 @@ syscall(code, framep)
 	rval<a name="-0"></a><a href="#0">[0]</a> = 0;
 	rval<a name="-1"></a><a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, args + hidden, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
Index: sys/arch/amd64/amd64/locore.S
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/locore.S,v
diff -u -p -u -r1.141 locore.S
--- sys/arch/amd64/amd64/locore.S	24 Oct 2023 13:20:09 -0000	1.141
+++ sys/arch/amd64/amd64/locore.S	27 Oct 2023 03:26:49 -0000
@@ -508,6 +508,7 @@ ENTRY(savectx)
 	lfence
 END(savectx)
 
+// XXX this should not behave like a nop
 IDTVEC(syscall32)
 	sysret		/* go away please */
 END(Xsyscall32)
Index: sys/arch/amd64/amd64/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/trap.c,v
diff -u -p -u -r1.101 trap.c
--- sys/arch/amd64/amd64/trap.c	5 Jul 2023 12:58:55 -0000	1.101
+++ sys/arch/amd64/amd64/trap.c	27 Oct 2023 03:26:49 -0000
@@ -553,7 +553,7 @@ syscall(struct trapframe *frame)
 	caddr_t params;
 	const struct sysent *callp;
 	struct proc *p;
-	int error, indirect = -1;
+	int error = ENOSYS;
 	size_t argsize, argoff;
 	register_t code, args<a name="-9"></a><a href="#9">[9]</a>, rval<a href="#2">[2]</a>, *argp;
 
@@ -570,26 +570,9 @@ syscall(struct trapframe *frame)
 	argp = &amp;args<a href="#0">[0]</a>;
 	argoff = 0;
 
-	switch (code) {
-	case SYS_syscall:
-		/*
-		 * Code is first argument, followed by actual args.
-		 */
-		indirect = code;
-		code = frame-&gt;tf_rdi;
-		argp = &amp;args<a href="#1">[1]</a>;
-		argoff = 1;
-		break;
-	default:
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
-
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp = sysent + code;
 	argsize = (callp-&gt;sy_argsize &gt;&gt; 3) + argoff;
 	if (argsize) {
 		switch (MIN(argsize, 6)) {
@@ -620,7 +603,7 @@ syscall(struct trapframe *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, argp, rval);
+	error = mi_syscall(p, code, callp, argp, rval);
 
 	switch (error) {
 	case 0:
Index: sys/arch/arm/arm/syscall.c
===================================================================
RCS file: /cvs/src/sys/arch/arm/arm/syscall.c,v
diff -u -p -u -r1.26 syscall.c
--- sys/arch/arm/arm/syscall.c	11 Feb 2023 23:07:26 -0000	1.26
+++ sys/arch/arm/arm/syscall.c	27 Oct 2023 03:26:49 -0000
@@ -93,8 +93,8 @@ void
 swi_handler(trapframe_t *frame)
 {
 	struct proc *p = curproc;
-	const struct sysent *callp;
-	int code, error, indirect = -1;
+	const struct sysent *callp = sysent;
+	int code, error;
 	u_int nap = 4, nargs;
 	register_t *ap, *args, copyargs[MAXARGS], rval<a href="#2">[2]</a>;
 
@@ -103,32 +103,19 @@ swi_handler(trapframe_t *frame)
 	/* Before enabling interrupts, save FPU state */
 	vfp_save();
 
-	/* Re-enable interrupts if they were enabled previously */
-	if (__predict_true((frame-&gt;tf_spsr &amp; PSR_I) == 0))
-		enable_interrupts(PSR_I);
+	enable_interrupts(PSR_I);
 
 	p-&gt;p_addr-&gt;u_pcb.pcb_tf = frame;
 
 	/* Skip over speculation-blocking barrier. */
 	frame-&gt;tf_pc += 8;
 
-	code = frame-&gt;tf_r12;
-
 	ap = &amp;frame-&gt;tf_r0;
 
-	switch (code) {	
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	code = frame-&gt;tf_r12;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
 	nargs = callp-&gt;sy_argsize / sizeof(register_t);
 	if (nargs &lt;= nap) {
@@ -145,27 +132,23 @@ swi_handler(trapframe_t *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = frame-&gt;tf_r1;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
 		frame-&gt;tf_r0 = rval<a href="#0">[0]</a>;
 		frame-&gt;tf_r1 = rval<a href="#1">[1]</a>;
-
 		frame-&gt;tf_spsr &amp;= ~PSR_C;	/* carry bit */
 		break;
-
 	case ERESTART:
 		/*
 		 * Reconstruct the pc to point at the swi.
 		 */
 		frame-&gt;tf_pc -= 12;
 		break;
-
 	case EJUSTRETURN:
 		/* nothing to do */
 		break;
-
 	default:
 	bad:
 		frame-&gt;tf_r0 = error;
Index: sys/arch/arm64/arm64/syscall.c
===================================================================
RCS file: /cvs/src/sys/arch/arm64/arm64/syscall.c,v
diff -u -p -u -r1.14 syscall.c
--- sys/arch/arm64/arm64/syscall.c	13 Apr 2023 02:19:04 -0000	1.14
+++ sys/arch/arm64/arm64/syscall.c	27 Oct 2023 03:26:49 -0000
@@ -33,7 +33,7 @@ svc_handler(trapframe_t *frame)
 {
 	struct proc *p = curproc;
 	const struct sysent *callp;
-	int code, error, indirect = -1;
+	int code, error = ENOSYS;
 	u_int nap = 8, nargs;
 	register_t *ap, *args, copyargs[MAXARGS], rval<a href="#2">[2]</a>;
 
@@ -50,19 +50,9 @@ svc_handler(trapframe_t *frame)
 
 	ap = &amp;frame-&gt;tf_x<a href="#0">[0]</a>;
 
-	switch (code) {	
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp = sysent + code;
 
 	nargs = callp-&gt;sy_argsize / sizeof(register_t);
 	if (nargs &lt;= nap) {
@@ -79,25 +69,22 @@ svc_handler(trapframe_t *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
 		frame-&gt;tf_x<a href="#0">[0]</a> = rval<a href="#0">[0]</a>;
 		frame-&gt;tf_spsr &amp;= ~PSR_C;	/* carry bit */
 		break;
-
 	case ERESTART:
 		/*
 		 * Reconstruct the pc to point at the svc.
 		 */
 		frame-&gt;tf_elr -= 12;
 		break;
-
 	case EJUSTRETURN:
 		/* nothing to do */
 		break;
-
 	default:
 	bad:
 		frame-&gt;tf_x<a href="#0">[0]</a> = error;
Index: sys/arch/hppa/hppa/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/hppa/hppa/trap.c,v
diff -u -p -u -r1.161 trap.c
--- sys/arch/hppa/hppa/trap.c	11 Feb 2023 23:07:26 -0000	1.161
+++ sys/arch/hppa/hppa/trap.c	27 Oct 2023 03:26:49 -0000
@@ -764,8 +764,8 @@ void
 syscall(struct trapframe *frame)
 {
 	struct proc *p = curproc;
-	const struct sysent *callp;
-	int retq, code, argsize, argoff, error, indirect = -1;
+	const struct sysent *callp = sysent;
+	int code, argsize, argoff, error;
 	register_t args<a name="-8"></a><a href="#8">[8]</a>, rval<a href="#2">[2]</a>;
 #ifdef DIAGNOSTIC
 	int oldcpl = curcpu()-&gt;ci_cpl;
@@ -778,29 +778,16 @@ syscall(struct trapframe *frame)
 
 	p-&gt;p_md.md_regs = frame;
 
-	argoff = 4; retq = 0;
-	switch (code = frame-&gt;tf_t1) {
-	case SYS_syscall:
-		indirect = code;
-		code = frame-&gt;tf_arg0;
-		args<a href="#0">[0]</a> = frame-&gt;tf_arg1;
-		args<a href="#1">[1]</a> = frame-&gt;tf_arg2;
-		args<a href="#2">[2]</a> = frame-&gt;tf_arg3;
-		argoff = 3;
-		break;
-	default:
-		args<a href="#0">[0]</a> = frame-&gt;tf_arg0;
-		args<a href="#1">[1]</a> = frame-&gt;tf_arg1;
-		args<a href="#2">[2]</a> = frame-&gt;tf_arg2;
-		args<a name="-3"></a><a href="#3">[3]</a> = frame-&gt;tf_arg3;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	argoff = 4;
+	code = frame-&gt;tf_t1;
+	args<a href="#0">[0]</a> = frame-&gt;tf_arg0;
+	args<a href="#1">[1]</a> = frame-&gt;tf_arg1;
+	args<a href="#2">[2]</a> = frame-&gt;tf_arg2;
+	args<a href="#3">[3]</a> = frame-&gt;tf_arg3;
+
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
 	if ((argsize = callp-&gt;sy_argsize)) {
 		register_t *s, *e, t;
@@ -830,7 +817,7 @@ syscall(struct trapframe *frame)
 		 */
 		i = 0;
 		switch (code) {
-		case SYS_lseek:		retq = 0;
+		case SYS_lseek:
 		case SYS_truncate:
 		case SYS_ftruncate:	i = 2;	break;
 		case SYS_preadv:
@@ -851,12 +838,12 @@ syscall(struct trapframe *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = frame-&gt;tf_ret1;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
 		frame-&gt;tf_ret0 = rval<a href="#0">[0]</a>;
-		frame-&gt;tf_ret1 = rval[!retq];
+		frame-&gt;tf_ret1 = rval<a href="#1">[1]</a>;
 		frame-&gt;tf_t1 = 0;
 		break;
 	case ERESTART:
@@ -872,7 +859,7 @@ syscall(struct trapframe *frame)
 		break;
 	}
 
-	ast(p);
+	ast(p);		// XXX why?
 
 	mi_syscall_return(p, code, error, rval);
 
Index: sys/arch/i386/i386/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/i386/i386/trap.c,v
diff -u -p -u -r1.162 trap.c
--- sys/arch/i386/i386/trap.c	16 Apr 2023 06:43:49 -0000	1.162
+++ sys/arch/i386/i386/trap.c	27 Oct 2023 03:26:49 -0000
@@ -516,9 +516,9 @@ void
 syscall(struct trapframe *frame)
 {
 	caddr_t params;
-	const struct sysent *callp;
-	struct proc *p;
-	int error, indirect = -1;
+	const struct sysent *callp = sysent;
+	struct proc *p = curproc;
+	int error;
 	register_t code, args<a href="#8">[8]</a>, rval<a href="#2">[2]</a>;
 #ifdef DIAGNOSTIC
 	int ocpl = lapic_tpr;
@@ -540,38 +540,22 @@ syscall(struct trapframe *frame)
 	}
 #endif
 
-	p = curproc;
 	p-&gt;p_md.md_regs = frame;
-	code = frame-&gt;tf_eax;
-
-	params = (caddr_t)frame-&gt;tf_esp + sizeof(int);
 
-	switch (code) {
-	case SYS_syscall:
-		/*
-		 * Code is first argument, followed by actual args.
-		 */
-		indirect = code;
-		copyin(params, &amp;code, sizeof(int));
-		params += sizeof(int);
-		break;
-	default:
-		break;
-	}
+	code = frame-&gt;tf_eax;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
 	argsize = callp-&gt;sy_argsize;
+	params = (caddr_t)frame-&gt;tf_esp + sizeof(int);
 	if (argsize &amp;&amp; (error = copyin(params, args, argsize)))
 		goto bad;
 
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = frame-&gt;tf_edx;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
Index: sys/arch/m88k/m88k/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/m88k/m88k/trap.c,v
diff -u -p -u -r1.128 trap.c
--- sys/arch/m88k/m88k/trap.c	2 Aug 2023 06:14:46 -0000	1.128
+++ sys/arch/m88k/m88k/trap.c	27 Oct 2023 03:26:49 -0000
@@ -1153,9 +1153,9 @@ void
 m88100_syscall(register_t code, struct trapframe *tf)
 {
 	int i, nap;
-	const struct sysent *callp;
+	const struct sysent *callp = sysent;
 	struct proc *p = curproc;
-	int error, indirect = -1;
+	int error;
 	register_t args<a href="#8">[8]</a> __aligned(8);
 	register_t rval<a href="#2">[2]</a> __aligned(8);
 	register_t *ap;
@@ -1172,19 +1172,9 @@ m88100_syscall(register_t code, struct t
 	ap = &amp;tf-&gt;tf_r<a href="#2">[2]</a>;
 	nap = 8; /* r2-r9 */
 
-	switch (code) {
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
 	i = callp-&gt;sy_argsize / sizeof(register_t);
 	if (i &gt; sizeof(args) / sizeof(register_t))
@@ -1200,7 +1190,7 @@ m88100_syscall(register_t code, struct t
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = tf-&gt;tf_r<a href="#3">[3]</a>;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	/*
 	 * system call will look like:
@@ -1266,7 +1256,7 @@ void
 m88110_syscall(register_t code, struct trapframe *tf)
 {
 	int i, nap;
-	const struct sysent *callp;
+	const struct sysent *callp = sysent;
 	struct proc *p = curproc;
 	int error;
 	register_t args<a href="#8">[8]</a> __aligned(8);
@@ -1285,17 +1275,8 @@ m88110_syscall(register_t code, struct t
 	ap = &amp;tf-&gt;tf_r<a href="#2">[2]</a>;
 	nap = 8;	/* r2-r9 */
 
-	switch (code) {
-	case SYS_syscall:
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
+	// XXX out of range stays on syscall0, which we assume is enosys
+	if (code &gt;= 0 || code &lt;= SYS_MAXSYSCALL)
 		callp += code;
 
 	i = callp-&gt;sy_argsize / sizeof(register_t);
Index: sys/arch/mips64/mips64/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/mips64/mips64/trap.c,v
diff -u -p -u -r1.167 trap.c
--- sys/arch/mips64/mips64/trap.c	26 Apr 2023 16:53:59 -0000	1.167
+++ sys/arch/mips64/mips64/trap.c	27 Oct 2023 03:26:49 -0000
@@ -396,14 +396,12 @@ fault_common_no_miss:
 	case T_SYSCALL+T_USER:
 	    {
 		struct trapframe *locr0 = p-&gt;p_md.md_regs;
-		const struct sysent *callp;
-		unsigned int code, indirect = -1;
+		const struct sysent *callp = sysent;
+		unsigned int code;
 		register_t tpc;
 		uint32_t branch = 0;
 		int error, numarg;
-		struct args {
-			register_t i<a href="#8">[8]</a>;
-		} args;
+		register_t args<a href="#8">[8]</a>;
 		register_t rval<a href="#2">[2]</a>;
 
 		atomic_inc_int(&amp;uvmexp.syscalls);
@@ -422,51 +420,22 @@ fault_common_no_miss:
 			    trapframe-&gt;pc, 0, branch);
 		} else
 			locr0-&gt;pc += 4;
-		callp = sysent;
 		code = locr0-&gt;v0;
-		switch (code) {
-		case SYS_syscall:
-			/*
-			 * Code is first argument, followed by actual args.
-			 */
-			indirect = code;
-			code = locr0-&gt;a0;
-			if (code &gt;= SYS_MAXSYSCALL)
-				callp += SYS_syscall;
-			else
-				callp += code;
-			numarg = callp-&gt;sy_argsize / sizeof(register_t);
-			args.i<a href="#0">[0]</a> = locr0-&gt;a1;
-			args.i<a href="#1">[1]</a> = locr0-&gt;a2;
-			args.i<a href="#2">[2]</a> = locr0-&gt;a3;
-			if (numarg &gt; 3) {
-				args.i<a href="#3">[3]</a> = locr0-&gt;a4;
-				args.i<a name="-4"></a><a href="#4">[4]</a> = locr0-&gt;a5;
-				args.i<a name="-5"></a><a href="#5">[5]</a> = locr0-&gt;a6;
-				args.i<a name="-6"></a><a href="#6">[6]</a> = locr0-&gt;a7;
-				if (numarg &gt; 7)
-					if ((error = copyin((void *)locr0-&gt;sp,
-					    &amp;args.i<a name="-7"></a><a href="#7">[7]</a>, sizeof(register_t))))
-						goto bad;
-			}
-			break;
-		default:
-			if (code &gt;= SYS_MAXSYSCALL)
-				callp += SYS_syscall;
-			else
-				callp += code;
-
-			numarg = callp-&gt;sy_narg;
-			args.i<a href="#0">[0]</a> = locr0-&gt;a0;
-			args.i<a href="#1">[1]</a> = locr0-&gt;a1;
-			args.i<a href="#2">[2]</a> = locr0-&gt;a2;
-			args.i<a href="#3">[3]</a> = locr0-&gt;a3;
-			if (numarg &gt; 4) {
-				args.i<a href="#4">[4]</a> = locr0-&gt;a4;
-				args.i<a href="#5">[5]</a> = locr0-&gt;a5;
-				args.i<a href="#6">[6]</a> = locr0-&gt;a6;
-				args.i<a href="#7">[7]</a> = locr0-&gt;a7;
-			}
+
+		if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+			goto bad;
+		callp += code;
+
+		numarg = callp-&gt;sy_narg;
+		args<a href="#0">[0]</a> = locr0-&gt;a0;
+		args<a href="#1">[1]</a> = locr0-&gt;a1;
+		args<a href="#2">[2]</a> = locr0-&gt;a2;
+		args<a href="#3">[3]</a> = locr0-&gt;a3;
+		if (numarg &gt; 4) {
+			args<a href="#4">[4]</a> = locr0-&gt;a4;
+			args<a href="#5">[5]</a> = locr0-&gt;a5;
+			args<a href="#6">[6]</a> = locr0-&gt;a6;
+			args<a href="#7">[7]</a> = locr0-&gt;a7;
 		}
 
 		rval<a href="#0">[0]</a> = 0;
@@ -477,29 +446,24 @@ fault_common_no_miss:
 		    TRAPSIZE : trppos[ci-&gt;ci_cpuid]) - 1].code = code;
 #endif
 
-		error = mi_syscall(p, code, indirect, callp, args.i, rval);
+		error = mi_syscall(p, code, callp, args, rval);
 
 		switch (error) {
 		case 0:
 			locr0-&gt;v0 = rval<a href="#0">[0]</a>;
 			locr0-&gt;a3 = 0;
 			break;
-
 		case ERESTART:
 			locr0-&gt;pc = tpc;
 			break;
-
 		case EJUSTRETURN:
 			break;	/* nothing to do */
-
 		default:
-		bad:
 			locr0-&gt;v0 = error;
 			locr0-&gt;a3 = 1;
 		}
 
 		mi_syscall_return(p, code, error, rval);
-
 		return;
 	    }
 
Index: sys/arch/powerpc/powerpc/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/powerpc/powerpc/trap.c,v
diff -u -p -u -r1.131 trap.c
--- sys/arch/powerpc/powerpc/trap.c	11 Feb 2023 23:07:27 -0000	1.131
+++ sys/arch/powerpc/powerpc/trap.c	27 Oct 2023 03:26:49 -0000
@@ -239,11 +239,11 @@ trap(struct trapframe *frame)
 	struct vm_map *map;
 	vaddr_t va;
 	int access_type;
-	const struct sysent *callp;
+	const struct sysent *callp = sysent;
 	size_t argsize;
 	register_t code, error;
 	register_t *params, rval<a href="#2">[2]</a>, args<a href="#10">[10]</a>;
-	int n, indirect = -1;
+	int n;
 
 	if (frame-&gt;srr1 &amp; PSL_PR) {
 		type |= EXC_USER;
@@ -360,27 +360,13 @@ trap(struct trapframe *frame)
 	case EXC_SC|EXC_USER:
 		uvmexp.syscalls++;
 
-		code = frame-&gt;fixreg<a href="#0">[0]</a>;
 		params = frame-&gt;fixreg + FIRSTARG;
 
-		switch (code) {
-		case SYS_syscall:
-			/*
-			 * code is first argument,
-			 * followed by actual args.
-			 */
-			indirect = code;
-			code = *params++;
-			break;
-		default:
-			break;
-		}
+		code = frame-&gt;fixreg<a href="#0">[0]</a>;
+	        if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+			goto bad;
+                callp += code;
 
-		callp = sysent;
-		if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-			callp += SYS_syscall;
-		else
-			callp += code;
 		argsize = callp-&gt;sy_argsize;
 		n = NARGREG - (params - (frame-&gt;fixreg + FIRSTARG));
 		if (argsize &gt; n * sizeof(register_t)) {
@@ -395,7 +381,7 @@ trap(struct trapframe *frame)
 		rval<a href="#0">[0]</a> = 0;
 		rval<a href="#1">[1]</a> = frame-&gt;fixreg[FIRSTARG + 1];
 
-		error = mi_syscall(p, code, indirect, callp, params, rval);
+		error = mi_syscall(p, code, callp, params, rval);
 
 		switch (error) {
 		case 0:
Index: sys/arch/powerpc64/powerpc64/syscall.c
===================================================================
RCS file: /cvs/src/sys/arch/powerpc64/powerpc64/syscall.c,v
diff -u -p -u -r1.11 syscall.c
--- sys/arch/powerpc64/powerpc64/syscall.c	11 Feb 2023 23:07:27 -0000	1.11
+++ sys/arch/powerpc64/powerpc64/syscall.c	27 Oct 2023 03:26:49 -0000
@@ -30,27 +30,17 @@ void
 syscall(struct trapframe *frame)
 {
 	struct proc *p = curproc;
-	const struct sysent *callp;
-	int code, error, indirect = -1;
+	const struct sysent *callp = sysent;
+	int code, error;
 	int nap = 8, nargs;
 	register_t *ap, *args, copyargs[MAXARGS], rval<a href="#2">[2]</a>;
 
-	code = frame-&gt;fixreg<a href="#0">[0]</a>;
 	ap = &amp;frame-&gt;fixreg<a href="#3">[3]</a>;
+	code = frame-&gt;fixreg<a href="#0">[0]</a>;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
-	switch (code) {
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
 	nargs = callp-&gt;sy_argsize / sizeof(register_t);
 	if (nargs &lt;= nap) {
 		args = ap;
@@ -66,7 +56,7 @@ syscall(struct trapframe *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
@@ -74,15 +64,12 @@ syscall(struct trapframe *frame)
 		frame-&gt;fixreg<a href="#3">[3]</a> = rval<a href="#0">[0]</a>;
 		frame-&gt;cr &amp;= ~0x10000000;
 		break;
-
 	case ERESTART:
 		frame-&gt;srr0 -= 4;
 		break;
-
 	case EJUSTRETURN:
 		/* nothing to do */
 		break;
-
 	default:
 	bad:
 		frame-&gt;fixreg<a href="#0">[0]</a> = error;
Index: sys/arch/riscv64/riscv64/syscall.c
===================================================================
RCS file: /cvs/src/sys/arch/riscv64/riscv64/syscall.c,v
diff -u -p -u -r1.16 syscall.c
--- sys/arch/riscv64/riscv64/syscall.c	13 Apr 2023 02:19:05 -0000	1.16
+++ sys/arch/riscv64/riscv64/syscall.c	27 Oct 2023 03:26:49 -0000
@@ -39,33 +39,20 @@ void
 svc_handler(trapframe_t *frame)
 {
 	struct proc *p = curproc;
-	const struct sysent *callp;
-	int code, error, indirect = -1;
+	const struct sysent *callp = sysent;
+	int code, error;
 	u_int nap = 8, nargs;
 	register_t *ap, *args, copyargs[MAXARGS], rval<a href="#2">[2]</a>;
 
 	uvmexp.syscalls++;
 
-	/* Re-enable interrupts if they were enabled previously */
-	if (__predict_true(frame-&gt;tf_scause &amp; EXCP_INTR))
-		intr_enable();
-
 	ap = &amp;frame-&gt;tf_a<a href="#0">[0]</a>;
 	code = frame-&gt;tf_t<a href="#0">[0]</a>;
 
-	switch (code) {
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp += code;
 
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
 	nargs = callp-&gt;sy_argsize / sizeof(register_t);
 	if (nargs &lt;= nap) {
 		args = ap;
@@ -81,21 +68,18 @@ svc_handler(trapframe_t *frame)
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
 		frame-&gt;tf_a<a href="#0">[0]</a> = rval<a href="#0">[0]</a>;
 		frame-&gt;tf_t<a href="#0">[0]</a> = 0;		/* syscall succeeded */
 		break;
-
 	case ERESTART:
 		frame-&gt;tf_sepc -= 4;		/* prev instruction */
 		break;
-
 	case EJUSTRETURN:
 		break;
-
 	default:
 	bad:
 		frame-&gt;tf_a<a href="#0">[0]</a> = error;
Index: sys/arch/sh/sh/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/sh/sh/trap.c,v
diff -u -p -u -r1.54 trap.c
--- sys/arch/sh/sh/trap.c	11 Feb 2023 23:07:27 -0000	1.54
+++ sys/arch/sh/sh/trap.c	27 Oct 2023 03:26:49 -0000
@@ -516,44 +516,20 @@ syscall(struct proc *p, struct trapframe
 {
 	caddr_t params;
 	const struct sysent *callp;
-	int error, opc, indirect = -1;
-	int argoff, argsize;
+	int error, opc;
+	int argsize;
 	register_t code, args<a href="#8">[8]</a>, rval<a href="#2">[2]</a>;
 
 	uvmexp.syscalls++;
 
 	opc = tf-&gt;tf_spc;
 	code = tf-&gt;tf_r0;
-
 	params = (caddr_t)tf-&gt;tf_r15;
 
-	switch (code) {
-	case SYS_syscall:
-		/*
-		 * Code is first argument, followed by actual args.
-		 */
-		indirect = code;
-	        code = tf-&gt;tf_r4;
-		argoff = 1;
-		break;
-	default:
-		argoff = 0;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else
-		callp += code;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp = sysent + code;
 	argsize = callp-&gt;sy_argsize;
-#ifdef DIAGNOSTIC
-	if (argsize &gt; sizeof args) {
-		callp += SYS_syscall - code;
-		argsize = callp-&gt;sy_argsize;
-	}
-#endif
-
 	if (argsize) {
 		register_t *ap;
 		int off_t_arg;
@@ -570,19 +546,16 @@ syscall(struct proc *p, struct trapframe
 		}
 
 		ap = args;
-		switch (argoff) {
-		case 0:	*ap++ = tf-&gt;tf_r4; argsize -= sizeof(int);
-		case 1:	*ap++ = tf-&gt;tf_r5; argsize -= sizeof(int);
-		case 2: *ap++ = tf-&gt;tf_r6; argsize -= sizeof(int);
-			/*
-			 * off_t args aren't split between register
-			 * and stack, but rather r7 is skipped and
-			 * the entire off_t is on the stack.
-			 */
-			if (argoff + off_t_arg == 3)
-				break;
+		*ap++ = tf-&gt;tf_r4; argsize -= sizeof(int);
+		*ap++ = tf-&gt;tf_r5; argsize -= sizeof(int);
+		*ap++ = tf-&gt;tf_r6; argsize -= sizeof(int);
+		/*
+		 * off_t args aren't split between register
+		 * and stack, but rather r7 is skipped and
+		 * the entire off_t is on the stack.
+		 */
+		if (off_t_arg != 3) {
 			*ap++ = tf-&gt;tf_r7; argsize -= sizeof(int);
-			break;
 		}
 
 		if (argsize &gt; 0) {
@@ -594,7 +567,7 @@ syscall(struct proc *p, struct trapframe
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = tf-&gt;tf_r1;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 	case 0:
Index: sys/arch/sparc64/sparc64/trap.c
===================================================================
RCS file: /cvs/src/sys/arch/sparc64/sparc64/trap.c,v
diff -u -p -u -r1.115 trap.c
--- sys/arch/sparc64/sparc64/trap.c	11 Feb 2023 23:07:28 -0000	1.115
+++ sys/arch/sparc64/sparc64/trap.c	27 Oct 2023 03:26:49 -0000
@@ -1109,9 +1109,10 @@ syscall(struct trapframe *tf, register_t
 	int64_t *ap;
 	const struct sysent *callp;
 	struct proc *p = curproc;
-	int error, new, indirect = -1;
+	int error = ENOSYS, new;
 	register_t args<a href="#8">[8]</a>;
 	register_t rval<a href="#2">[2]</a>;
+	register_t *argp;
 
 	if ((tf-&gt;tf_out<a href="#6">[6]</a> &amp; 1) == 0)
 		sigexit(p, SIGILL);
@@ -1137,44 +1138,31 @@ syscall(struct trapframe *tf, register_t
 	ap = &amp;tf-&gt;tf_out<a href="#0">[0]</a>;
 	nap = 6;
 
-	switch (code) {
-	case SYS_syscall:
-		indirect = code;
-		code = *ap++;
-		nap--;
-		break;
-	}
-
-	callp = sysent;
-	if (code &lt; 0 || code &gt;= SYS_MAXSYSCALL)
-		callp += SYS_syscall;
-	else {
-		register_t *argp;
-
-		callp += code;
-		i = callp-&gt;sy_narg; /* Why divide? */
-		if (i &gt; nap) {	/* usually false */
-			if (i &gt; 8)
-				panic("syscall nargs");
-			/* Read the whole block in */
-			if ((error = copyin((caddr_t)tf-&gt;tf_out<a href="#6">[6]</a>
-			    + BIAS + offsetof(struct frame, fr_argx),
-			    &amp;args[nap], (i - nap) * sizeof(register_t))))
-				goto bad;
-			i = nap;
-		}
-		/*
-		 * It should be faster to do &lt;= 6 longword copies than
-		 * to call bcopy
-		 */
-		for (argp = args; i--;)
-			*argp++ = *ap++;
+	if (code &lt;= 0 || code &gt;= SYS_MAXSYSCALL)
+		goto bad;
+	callp = sysent + code;
+	i = callp-&gt;sy_narg; /* Why divide? */
+	if (i &gt; nap) {	/* usually false */
+		if (i &gt; 8)
+			panic("syscall nargs");
+		/* Read the whole block in */
+		if ((error = copyin((caddr_t)tf-&gt;tf_out<a href="#6">[6]</a>
+		    + BIAS + offsetof(struct frame, fr_argx),
+		    &amp;args[nap], (i - nap) * sizeof(register_t))))
+			goto bad;
+		i = nap;
 	}
+	/*
+	 * It should be faster to do &lt;= 6 longword copies than
+	 * to call bcopy
+	 */
+	for (argp = args; i--;)
+		*argp++ = *ap++;
 
 	rval<a href="#0">[0]</a> = 0;
 	rval<a href="#1">[1]</a> = 0;
 
-	error = mi_syscall(p, code, indirect, callp, args, rval);
+	error = mi_syscall(p, code, callp, args, rval);
 
 	switch (error) {
 		vaddr_t dest;
Index: sys/kern/kern_ktrace.c
===================================================================
RCS file: /cvs/src/sys/kern/kern_ktrace.c,v
diff -u -p -u -r1.112 kern_ktrace.c
--- sys/kern/kern_ktrace.c	11 May 2023 09:51:33 -0000	1.112
+++ sys/kern/kern_ktrace.c	27 Oct 2023 03:26:49 -0000
@@ -160,7 +160,7 @@ ktrsyscall(struct proc *p, register_t co
 	u_int nargs = 0;
 	int i;
 
-	if ((code &amp; KTRC_CODE_MASK) == SYS_sysctl) {
+	if (code == SYS_sysctl) {
 		/*
 		 * The sysctl encoding stores the mib[]
 		 * array because it is interesting.
Index: sys/sys/ktrace.h
===================================================================
RCS file: /cvs/src/sys/sys/ktrace.h,v
diff -u -p -u -r1.46 ktrace.h
--- sys/sys/ktrace.h	23 Feb 2023 01:33:20 -0000	1.46
+++ sys/sys/ktrace.h	27 Oct 2023 03:26:49 -0000
@@ -76,8 +76,6 @@ struct ktr_header {
 #define KTR_SYSCALL	1
 struct ktr_syscall {
 	int	ktr_code;		/* syscall number */
-#define KTRC_CODE_MASK			0x0000ffff
-#define KTRC_CODE_SYSCALL		0x20000000
 	int	ktr_argsize;		/* size of arguments */
 	/*
 	 * followed by ktr_argsize/sizeof(register_t) "register_t"s
Index: sys/sys/syscall_mi.h
===================================================================
RCS file: /cvs/src/sys/sys/syscall_mi.h,v
diff -u -p -u -r1.28 syscall_mi.h
--- sys/sys/syscall_mi.h	11 Feb 2023 23:07:23 -0000	1.28
+++ sys/sys/syscall_mi.h	27 Oct 2023 03:26:49 -0000
@@ -51,8 +51,8 @@
  * The MD setup for a system call has been done; here's the MI part.
  */
 static inline int
-mi_syscall(struct proc *p, register_t code, int indirect,
-    const struct sysent *callp, register_t *argp, register_t retval<a href="#2">[2]</a>)
+mi_syscall(struct proc *p, register_t code, const struct sysent *callp,
+    register_t *argp, register_t retval<a href="#2">[2]</a>)
 {
 	uint64_t tval;
 	int lock = !(callp-&gt;sy_flags &amp; SY_NOLOCK);
@@ -73,15 +73,8 @@ mi_syscall(struct proc *p, register_t co
 #ifdef KTRACE
 	if (KTRPOINT(p, KTR_SYSCALL)) {
 		/* convert to mask, then include with code */
-		switch (indirect) {
-		case SYS_syscall:
-			indirect = KTRC_CODE_SYSCALL;
-			break;
-		default:
-			indirect = 0;
-		}
 		KERNEL_LOCK();
-		ktrsyscall(p, code | indirect, callp-&gt;sy_argsize, argp);
+		ktrsyscall(p, code, callp-&gt;sy_argsize, argp);
 		KERNEL_UNLOCK();
 	}
 #endif

<b>[<a href="https://marc.info/?l=openbsd-tech&amp;m=169840739832111&amp;w=2">prev in list</a>] [<a href="https://marc.info/?l=openbsd-tech&amp;m=169842095809570&amp;w=2">next in list</a>] [<span color="#c0c0c0">prev in thread</span>] [<a href="https://marc.info/?l=openbsd-tech&amp;m=169842095809570&amp;w=2">next in thread</a>] </b>
</pre>
  <br><center>
    <a href="https://marc.info/?q=configure">Configure</a> | 

    <a href="https://marc.info/?q=about">About</a> |
    <a href="https://marc.info/?q=news">News</a> |
    <a href="mailto:webguy@marc.info?subject=Add%20a%20list%20to%20MARC">Add&nbsp;a&nbsp;list</a> |
    Sponsored&nbsp;by&nbsp;<a href="http://www.korelogic.com/">KoreLogic</a>
</center>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[EPA moves towards banning leaded aviation gas (420 pts)]]></title>
            <link>https://www.federalregister.gov/documents/2023/10/20/2023-23247/finding-that-lead-emissions-from-aircraft-engines-that-operate-on-leaded-fuel-cause-or-contribute-to</link>
            <guid>38039133</guid>
            <pubDate>Fri, 27 Oct 2023 14:44:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalregister.gov/documents/2023/10/20/2023-23247/finding-that-lead-emissions-from-aircraft-engines-that-operate-on-leaded-fuel-cause-or-contribute-to">https://www.federalregister.gov/documents/2023/10/20/2023-23247/finding-that-lead-emissions-from-aircraft-engines-that-operate-on-leaded-fuel-cause-or-contribute-to</a>, See on <a href="https://news.ycombinator.com/item?id=38039133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <h3>Request Access</h3>
        

        <p>
  Due to aggressive automated scraping of FederalRegister.gov and eCFR.gov, programmatic access to these sites is limited to access to our extensive developer APIs.
</p>

<p>
  If you are human user receiving this message, we can add your IP address to a set of IPs that can access FederalRegister.gov &amp; eCFR.gov; complete the CAPTCHA (bot test) below and click "Request Access". This process will be necessary for each IP address you wish to access the site from, requests are valid for approximately one quarter (three months) after which the process may need to be repeated.
</p>

<form action="/request" method="post">
  

          

  
</form>

<p>
  <em>An official website of the United States government.</em>
</p>

<p>
  If you want to request a wider IP range, first request access for your current IP, and then use the "Site Feedback" button found in the lower left-hand side to make the request.
</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Automatic fraud detection is making my life hell (276 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38038713</link>
            <guid>38038713</guid>
            <pubDate>Fri, 27 Oct 2023 14:15:09 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38038713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38038713">
      <td><span></span></td>      <td><center><a id="up_38038713" href="https://news.ycombinator.com/vote?id=38038713&amp;how=up&amp;goto=item%3Fid%3D38038713"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38038713">Tell HN: Automatic fraud detection is making my life hell</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38038713">108 points</span> by <a href="https://news.ycombinator.com/user?id=aiProgMach">aiProgMach</a> <span title="2023-10-27T14:15:09"><a href="https://news.ycombinator.com/item?id=38038713">6 hours ago</a></span> <span id="unv_38038713"></span> | <a href="https://news.ycombinator.com/hide?id=38038713&amp;goto=item%3Fid%3D38038713">hide</a> | <a href="https://hn.algolia.com/?query=Tell%20HN%3A%20Automatic%20fraud%20detection%20is%20making%20my%20life%20hell&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38038713&amp;auth=5cd7d72fac8fa3d031b70c421368defe4328d1c4">favorite</a> | <a href="https://news.ycombinator.com/item?id=38038713">86&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>I've been in India for a while now, to support family member as she's here for medical reasons. I rely on online services to save on cash especially that it's hard to carry cash from my country (for "security" reasons, as most airports limit how much cash you can carry).</p><p>Yet, many online services are giving me hell with their "smart" anti fraud detection and things like that, at this point I can really understand the position of the people who are dooming about cashless society, because at some point here I felt trapped not being able to get services I needed so much (until I asked shop owner to pay for me and I paid him in cash + small profit...).</p><p>The thing is, the attitude of these companies is so frustrating;  like if my card was already accepted once and I successfully approved the payment via 3D secure with my bank, who are you (as a random online service) to assume you can act as my big brother? Even more, if I'm using a balance paid by gift card, who give Amazon or other services the right to put my account on hold while it still contains my hard earned money (I had to try literally multiple services just to buy expensive gift card as Amazon payment won't allow me to choose the correct currency of my Card). Mind you, I'm just a random guy and not world class criminal, or an Activist who's being actively targeted, this make me wonder what these services can do once we go completely cashless.</p><p>Simple tasks like downloading region-specific Indian apps become unnecessarily complex, as Google play have this "smart" rule that says I can only change my region once per year, what?? It's just an app just give me the apk, and you can just ask for my location! (I had to install the apks from some random websites at risk of getting some malware...).</p><p>I would said what this experience taught me as a developer, but it won't matter, as most products are designed to help the stake holders and upper managers and even Governments, and a dev's empathy won't matter much...</p><p>Apologies for this vent, but I really felt I need to post something about this frustrating situation I'm in.</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything I've learned building the fastest Arm desktop (129 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2023/everything-ive-learned-building-fastest-arm-desktop</link>
            <guid>38038682</guid>
            <pubDate>Fri, 27 Oct 2023 14:13:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2023/everything-ive-learned-building-fastest-arm-desktop">https://www.jeffgeerling.com/blog/2023/everything-ive-learned-building-fastest-arm-desktop</a>, See on <a href="https://news.ycombinator.com/item?id=38038682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://www.jeffgeerling.com/sites/default/files/images/ampere-altra-developer-platform-hero-shot_0.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-55f6ffb6-9f1f-48d9-8186-ab81519ca28a" data-insert-attach="{&quot;id&quot;:&quot;55f6ffb6-9f1f-48d9-8186-ab81519ca28a&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Ampere Altra Developer Platform Hero Shot"></p>

<p>This is the fastest Arm desktop in the world, yes, even faster than the <a href="https://www.apple.com/mac-pro/">M2 Ultra Mac Pro</a>. And today, I made it even faster.</p>

<p>I upgraded everything: Faster RAM, 128 core CPU, 40 series GPU, I did it all, and we'll see how much we can obliterate the M2 Mac Pro.</p>

<p>128 cores—that's five times more cores, I'm also going to upgrade this thing from 96 all the way to <em>384 gigabytes</em> of RAM. The Mac Pro? Sorry, it only goes up to 192.</p>

<p>And we're just in time for the <a href="https://www.maxon.net/en/article/maxon-introduces-cinebench-2024">new Cinebench 2024 benchmark</a>, which—yes—this machine dominates.</p>

<p>But it's not all perfection. The M2's individual cores are faster, and I didn't even mention Intel or AMD—they also do really well single-core. And 128 cores can be overkill if your application can't use all of them.</p>

<div>
<p><iframe src="https://www.youtube.com/embed/argfZlPZKdY" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p><em>The following is a transcript of the above video. Please watch the <a href="https://www.youtube.com/watch?v=argfZlPZKdY">original video</a> for more context.</em></p>

<p>I tested two systems for this video:</p>

<ul>
<li><a href="https://www.ipi.wiki/products/ampere-altra-developer-platform">Ampere Altra Developer Platform</a> (a full system build, in my case with the 96-core and 128-core CPU)</li>
<li><a href="https://www.ipi.wiki/products/com-hpc-ampere-altra">Ampere Altra Dev Kit</a>, in my case with the 64-core CPU)</li>
</ul>

<p>Ampere and ADLINK designed this system to be the ultimate Arm development workstation. And that, it is. But I like doing crazy things. Can this also be a great gaming rig? Can the CPU break a teraflop? Can we install a 4070 Ti in it?</p>

<h2>Current Status</h2>

<p>As of today, I have this thing running 128 CPU cores at 2.8 GHz. I upgraded the RAM to 384 GB of DDR4 3200 ECC RAM, specifically six Samsung 64 GB sticks. I installed an Nvidia 4070 Ti.</p>

<p>It's running both Ubuntu 22.04 Server and Windows 11 for Arm now. I even got Steam installed on Ubuntu, after so many commenters kindly pointed out <a href="https://box86.org/">Box86</a> and <a href="https://github.com/ptitSeb/box64">Box64</a> exist!</p>

<p>But before we get into full benchmarks and gaming, I want walk you through the RAM and CPU upgrades, because I learned a lot about this platform. Like, did you know at a certain point, more CPU cores doesn't necessarily give you more performance, even on pure multicore tasks?</p>

<p>Yeah. And the main reason for that? Memory is just not getting faster at the same rate as our CPUs.</p>

<h2>Upgrading the RAM (The importance of benchmarking)</h2>

<p>Have you ever seen one of those fancy server motherboards on Serve The Home? <a href="https://www.servethehome.com/supermicro-as-2015hs-tnr-review-a-server-with-amd-epyc-bergamo/2/">This is a new server</a> for AMD's Bergamo CPU.</p>

<p>Do you see how many memory slots are in this thing? There are <em>twenty four</em>! There're two memory slots for each of the <em>twelve</em> memory channels on the processor.</p>

<p>That's a lot, compared to a normal desktop, where you might get two or four slots for RAM. What gives? Well, modern multicore CPUs are getting faster and faster, but feeding them with data hasn't kept up. So big servers need more and more sticks of RAM feeding data to individual CPU cores just so they don't sit around waiting.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/ram-samsung-transcend-detail.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-0f7c92de-9952-4382-9922-0df52168d44b" data-insert-attach="{&quot;id&quot;:&quot;0f7c92de-9952-4382-9922-0df52168d44b&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="RAM - Samsung and Transcend detail DDR 3200 ECC CL22"></p>

<p>And RAM goes a lot deeper too. Look at these two sticks of RAM. See how the one on the right has twice the number of memory modules? That allows the individual stick of RAM to pump through data more quickly than the one on the left, even though <em>both</em> of them are rated at DDR 3200 and CL22.</p>

<p>If you look <em>really</em> closely on the labels, you can see one is 1Rx4, and the other one is 1Rx8. <a href="https://www.youtube.com/watch?v=w2bFzQTQ9aI">Actually Hardcore Overclocking</a> has a great video on this, but bottom line, this x4 stick is about 30% faster than the x8!</p>

<p>I tested three setups: 96 GB of Transcend RAM, 96 GB of Samsung RAM, and <em>384 GB</em> of Samsung RAM, and I learned a lot about memory latency and bandwidth.</p>

<p>But the most important thing I learned is this system design only exposes 6 out of the 8 available memory channels on this beefy CPU.</p>

<p>So there's actually an upper limit to how much performance I can get just upgrading the CPU.</p>

<p>This system's memory bandwidth <a href="https://github.com/AmpereComputing/HPL-on-Ampere-Altra/issues/11#issuecomment-1732099325">tops out around 174 Gigabytes per second</a>, but you might get more with more memory channels.</p>

<h2>Upgrading the CPU (96 to 128 cores!)</h2>

<p>A lot of Ampere server builds do give all eight, and maybe I'll get one someday. But for now, I still wanted to test all 128 cores.</p>

<p>For the upgrade, it's a little different than a normal desktop CPU. I popped off the water cooling block, which is normal, but underneath, I made sure to follow the 'OPEN' pattern for loosening the CPU bracket.</p>

<p>I pulled out the 96-core CPU, and that is a <em>lot</em> of pins:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/lga-socket-ampere-altra-max-cpu.jpeg" width="700" height="467" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-96583318-1f22-4894-a512-5524737ec8ab" data-insert-attach="{&quot;id&quot;:&quot;96583318-1f22-4894-a512-5524737ec8ab&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="LGA Socket for Ampere Altra Max CPU"></p>

<p>I mean, on any of these modern Epyc, or Xeon, or Altra systems, there's just an enormous amount of pins, in this case for up to <em>8</em> memory channels and <em>128</em> lanes of PCI express. That's just a ton of bandwidth.</p>

<p>So in goes the 128-core CPU, and in my case, it's the 2.8 Gigahertz version. They actually make a 3 GHz version, but since Ampere sent this thing to me for testing, and the overall efficiency's probably a tiny bit better at 2.8 Gigahertz anyway, I'm not complaining.</p>

<p>I plugged it back in, booted back up, and it posted at 2.8 Gigahertz, so the next step was to boot into Linux and make sure I could see all 128 cores, which it did.</p>

<p>I ran my linpack benchmark again. On the 96-core CPU it got about 1.2 Teraflops—but I could still only get around 1.2 Teraflops.</p>

<p>After a ton of research, and after upgrading the system to 384 gigabytes of RAM, I could eke out about 1.3 teraflops, but it seems like that's the upper limit on this particular motherboard.</p>

<p>Which, I mean... that's not bad at all. But if you put the same CPU in a server with all 8 channels of RAM, this thing should go even faster, probably past 1.5 teraflops.</p>

<p>But if you <em>really</em> care about teraflops, you need a graphics card.</p>

<p>Nowadays more and more workloads can go <em>way</em> faster using a GPU, especially AI and machine learning. Not to mention games and design apps.</p>

<p>And sorry, Apple, but only allowing your own integrated GPU just doesn't cut it.</p>

<h2>Installing the GPU (4070 Ti)</h2>

<p>I decided to go with an Nvidia 4070 Ti, and before you start yelling at me about not using AMD for a Linux-first build... AMD's drivers on Arm aren't quite as stable yet.</p>

<p>Nvidia making their own massive Arm processors probably has something to do with that, but in any case, I went with <a href="https://amzn.to/49chAc0">this understated ProArt GPU from ASUS</a>. It's not gaudy like most modern graphics cards, and it fits nicely in the case. I test-fitted my 4090 but that thing's a monster, and would also require this bigger power supply.</p>

<p>Maybe I'll upgrade to it someday, but for now, 4070 it is.</p>

<p>Now, before I could get anything out through the graphics card, I had to get drivers going.</p>

<p>Ampere has <a href="https://github.com/AmpereComputing/NVIDIA-GPU-Accelerated-Linux-Desktop-on-Ampere">a guide for the process</a>, but basically I installed a desktop environment since I was running Ubuntu Server, then I installed the Nvidia drivers.</p>

<p>I shut down the system, plugged my monitor into the card with HDMI instead of the integrated VGA port, and away it went!</p>

<p>One thing to note is you won't get any of the early boot stuff like the BIOS screen through a graphics card. Those things still go through the integrated ASPEED controller. But everything else in the OS goes through the GPU now.</p>

<h3>GPU support in Linux</h3>

<p>And Ubuntu had no problems!</p>

<p>I ran Glmark2 and got a score of 10,260, and installed OBS and was excited to see the NVENC hardware encoding worked without any extra setup.</p>

<p>I used OBS to record all the rest of my testing, and it worked without a hitch, allowing the GPU to do all the heavy compression for screen recordings.</p>

<p>Next I booted up SuperTuxKart and got an easy 100 fps with all the settings completely maxed out. I mean, this beat the pants off any other Arm system I've tested so far.</p>

<p>I also installed Blender and messed around with a demo scene. The UI was responsive, and rendering wasn't too painful, but I did notice Blender's CUDA support wasn't working. So the 128-core CPU could keep things moving, but I'm guessing a little more work is required for GPU acceleration.</p>

<p>GPUs are also huge for things like ChatGPT or Llama. And it's easy enough to install Llama locally so I grabbed a massive 13 billion parameter model and installed a web UI. The Ampere chewed through it as I asked a series of questions.</p>

<p>It worked okay, but could be a lot faster if I could get GPU support going. I had a little trouble but again, it's probably not too difficult to get it working, it's just that not many devs working on this software have access to these fast Arm workstations yet.</p>

<p>I mean, even without the GPU, large language models are certainly one way to utilize all 128 cores!</p>

<p>To round things out, I also played back a YouTube video at 4K60 and there was zero issue there. Firefox seems to be using the GPU just fine.</p>

<h3>GPU support in Windows</h3>

<p>I rebooted into Windows 11 and things were a lot more bleak there.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/microsoft-basic-display-adapter.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-9eb1b12f-bc5a-42bd-a9c8-c66d5549c20d" data-insert-attach="{&quot;id&quot;:&quot;9eb1b12f-bc5a-42bd-a9c8-c66d5549c20d&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Microsoft Basic Display Adapter"></p>

<p>The GPU can be seen by Windows, but Nvidia only publishes Arm drivers for Linux, not Windows. So in device manager you just see a Basic Display Adapter, and it can't really do anything.</p>

<p>OBS runs in Windows, but only with software encoding. And Blender won't start at all since it requires OpenGL and a graphics card, neither of which Windows can get going yet on Arm.</p>

<h2>Windows and Cinebench 2024</h2>

<p>But Windows <em>didn't</em> have any problems with the CPU or RAM. it picked up on all 128 cores, and all 384 gigs of RAM.</p>

<p>I was excited, because Cinebench just released their latest 2024 version, and one of the headline features is Windows on Arm support!</p>

<p>They mentioned Snapdragon CPUs, like the one that's in the Windows Dev Kit 2023 I tested last year.</p>

<p>I booted up that system and after waiting an hour or so for Windows Update to finish, I ran Cinebench and got 69 single and 435 multicore.</p>

<p>Just for fun, I also ran it on my M1 Max Mac Studio, and got 111 single, and 799 multi.</p>

<p>On the Ampere? 47 single and 2,409 multi!</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/cinebench-2024-scores-arm-cpus.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-c441ed28-3b56-458c-ba78-9ba90061c956" data-insert-attach="{&quot;id&quot;:&quot;c441ed28-3b56-458c-ba78-9ba90061c956&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Cinebench 2024 Arm CPU Scores"></p>

<p>That even beats the <a href="https://www.cpu-monkey.com/en/cpu_benchmark-cinebench_2024_multi_core">M2 Ultra</a>, which gets a maximum of 1,918 on the multicore test.</p>

<p>Now, the M2 Ultra is gimped a little bit: it only has 24 CPU cores.</p>

<p>But I noticed the MP ratio is only 51x on the Ampere. That ratio should be a lot higher, like at least 100 times. What gives?</p>

<p>Well, I opened up Task Manager, and whether I ran the 96-core or 128-core CPU, and even trying the <em>Enterprise</em> edition of Windows on Arm, there was no way to get Cinebench to use more than 64 CPU cores. <em>Windows</em> used all the cores, it was just Cinebench that seemed to have an issue.</p>

<p>If that gets fixed we should be able to go way past 2,400. Maybe around 4,000–but we'll see. I've been in contact with Maxon, and they now have access to some beefier hardware for testing.</p>

<p>So Cinebench is one thing, but something a lot of people mentioned is I could try Minecraft on Windows, since there may be an Arm native version in the Microsoft Store.</p>

<h3>Games: Minecraft on Windows</h3>

<p>I installed the Java and Bedrock edition from the Store, and... well... it ran. It wasn't quite playable, and it looks like it's trying to run the game off the tiny ASPEED graphics, which can barely do 10 frames a second.</p>

<h2>Steam on Ampere with Box86 and Box64</h2>

<p>But it's an entirely different experience on Linux. I installed Minecraft with Pi-Apps, and it ran beautifully. Zero issues getting 60 fps. I can't get ray tracing on this version, though. It's the one from the Google Play store, and I don't think that edition has RTX support.</p>

<p>Next I also tried installing Steam, and finally have that running! I followed Ampere's guide for installing Steam using Box86 and Box64, though I did have to tweak one install step to get the latest version.</p>

<p>The <a href="https://github.com/AmpereComputing/Steam-on-Ampere/issues/11#issuecomment-1732650185">main developer of Box86</a> actually has some Ampere hardware to test now, too, and he's already fixed some emulation bugs while I was making this video.</p>

<p>But anyway, with Steam installed, I started downloading all the games, to see what works. I made sure Proton was enabled, then booted up each game.</p>

<p>CS:GO installed and seemed to start launching, but it kept getting stuck in a boot loop where it would just die silently.</p>

<p>Halo Master Chief Collection would launch and eventually get to a black screen, but it died every time with this little Fatal Error message.</p>

<p>Portal 2 did the same thing as Counter Strike, where it would just silently die every time I launched it.</p>

<p>Despite the fact I got Crysis to run at like 1 frame per second on Windows, I couldn't get it to launch at all on Ubuntu.</p>

<p>I tried Quake but got an OpenGL error, and Need for Speed also died. Obduction gave me the same little fatal error Halo did, and Portal 1 also died.</p>

<p>Finally I tried Superhot, and... that actually worked! It was nice and smooth.</p>

<p>Seeing some progress, I downloaded another older game, Horizon Chase Turbo, and got it running decently well, but only like 10 or 20 fps.</p>

<p>My lucky streak was over though as I couldn't get Batman Arkham Knight to launch either, and Doom gave me this weird fatal error about some OpenGL function not being available.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/ksp-steam.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-cf1c63fa-cbaa-4002-bbae-4f9d468735e8" data-insert-attach="{&quot;id&quot;:&quot;cf1c63fa-cbaa-4002-bbae-4f9d468735e8&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Kerbal Space Program running on Ampere Altra Max with 4070 Ti"></p>

<p>My luck was back though, once I ran Kerbal Space Program, it seemed to run great and was plenty fast to be enjoyable. Blasting Jeb off in a rocket never gets old.</p>

<p>This stuff is in very active development right now, so things'll change. I highly recommend you follow Box64's development to find out if your favorite games could run on a Dev Workstation yet.</p>

<p>I mean, gaming isn't at all Ampere's main goal here, but it's cool to see how quickly the community's made things work, and I'm glad Ampere and ADLINK have been supportive of getting more stuff running.</p>

<h2>Devkit and what's next</h2>

<p>After all that testing on the Workstation, I also set up a bare Dev Kit on my test bench. Ampere sent me a board with a smaller 64-core CPU, and I installed the 96 GB of RAM that I originally bought for the Workstation along with a Kioxia SSD and a Corsair power supply.</p>

<p>And it ran actually a tiny bit more efficient than the full Workstation, putting it squarely at the top of my <a href="https://github.com/geerlingguy/top500-benchmark#results">top500 efficiency ranking</a>, outperforming even the Orange Pi 5!</p>

<p>There are a few quirks to it, though. Like the main fan header isn't actually wired up, so you have to use an adapter to get the CPU fan working. And (like I mentioned earlier) it only exposes 6 of the 8 memory channels, so the highest-end CPUs can't perform to their full potential. Finally, power consumption is about 3W powered off since it runs a built-in BMC for remote access, and booted up it idles around 50W.</p>

<p>But if you use it for anything that needs lots of CPU power and expansion, it's one of the most energy efficient computers on the market.</p>

<p>These things are infinitely more upgradeable than a Mac Pro, while costing less than half as much, and I'm excited to see where ADLINK and Ampere take this platform in the future. This is a good start, and I think they could actually make a dent in areas even outside the workstation space, but we'll see. Right now a lot of focus is on the even <em>more</em> massive <a href="https://amperecomputing.com/briefs/ampereone-family-product-brief">AmpereOne CPUs</a>, with up to <em>192</em> cores, DDR5, and PCIe Gen 5!</p>

<p>This thing can't do media production like my Mac, but for all my dev work, it could definitely be my main computer.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US immigration enforcement used AI-powered tool to scan posts derogatory to US (114 pts)]]></title>
            <link>https://www.techspot.com/news/100642-ice-used-ai-powered-tool-scan-social-media.html</link>
            <guid>38038512</guid>
            <pubDate>Fri, 27 Oct 2023 14:00:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techspot.com/news/100642-ice-used-ai-powered-tool-scan-social-media.html">https://www.techspot.com/news/100642-ice-used-ai-powered-tool-scan-social-media.html</a>, See on <a href="https://news.ycombinator.com/item?id=38038512">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>TechSpot is celebrating its 25th anniversary. TechSpot means tech analysis and advice <a href="https://www.techspot.com/ethics.html" target="_blank">you&nbsp;can&nbsp;trust</a>.</p><div>
<p id="why-it-matters"><strong>A hot potato:</strong> The rule about being careful what you put on social media appears to be especially relevant for anyone entering the US. Immigration and Customs Enforcement (ICE) has used an AI-powered tool to scan through social platforms to identify any visa applicants' posts that are "derogatory" to the US. </p>
<p>The system, called Giant Oak Search Technology (GOST), ranks a person's social media scores from one to 100 based on what it thinks is relevant to the user's specific mission. The database is searchable using identifiers such as a person's name, address, email address, and country of citizenship.</p>
<p>After clicking on a specific individual, analysts can review images collected from the subject's social media accounts and elsewhere, and give them a thumbs up or thumbs down rating. It's also possible for the analysts to look at the person's social media profiles, and their "social graph," themselves to see any potential connections with others.</p>
<p><picture><source type="image/webp" data-srcset="https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_500.webp 500w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_1100.webp 1100w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j.webp 2560w" data-sizes="(max-width: 960px) 100vw, 680px"><img alt="" height="1730" src="https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26.jpg" width="2560" data-src="https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26.jpg" data-srcset="https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_500.webp 500w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_1100.webp 1100w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j.webp 2560w" sizes="(max-width: 960px) 100vw, 680px" srcset="https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_500.webp 500w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j_1100.webp 1100w, https://www.techspot.com/images2/news/bigimage/2022/03/2022-03-04-image-26-j.webp 2560w"></picture></p>
<p>404 Media <a href="https://www.404media.co/inside-ices-database-derogatory-information-giant-oak-gost/">reports</a> that a Freedom of Information Act (FOIA) lawsuit brought by both the ACLU and the ACLU of Northern California showed GOST has been used by immigration services and multiple government agencies since 2014. ICE has paid Giant Oak Inc. more than $10 million since 2017, according to public procurement records.</p>
<p>GOST was part of a 2016 pilot called the HSI [Homeland Security Investigations] PATRIOT Social Media Pilot Program that targeted potential overstay violators from countries of concern.</p>
<p>Customs and Border Protection (CBP), the Drug Enforcement Administration (DEA), the State Department, the Air Force, and the Bureau of the Fiscal Service, which is part of the US Treasury, have all paid for Giant Oak services over the last nearly ten years.</p>
<p>The GOST <a href="https://www.giantoak.com/government">website</a> states that it leverages information on the open and deep web and applies search parameters focused on behavioral patterns rather than identity labels.</p>
<p>"The government should not be using algorithms to scrutinize our social media posts and decide which of us is 'risky.' And agencies certainly shouldn't be buying this kind of black box technology in secret without any accountability," said Patrick Toomey, Deputy Director of the ACLU's National Security Project. "DHS needs to explain to the public how its systems determine whether someone is a 'risk' or not, and what happens to the people whose online posts are flagged by its algorithms."</p>
<p>The records state that the contract between the DHS and Giant Oak ended in August 2022.</p>
<p>Back in 2019, the Trump administration brought in new rules first proposed in March 2018 in which visa applicants must hand over <a href="https://www.techspot.com/news/80332-us-visas-now-demand-social-media-details.html">details</a> of any social media channels they have used in the past 5 years. The State Department and the Department of Homeland Security can hold onto this information indefinitely, share it with other federal agencies, and disclose it - in some circumstances, to foreign governments.</p>
<p>2019 was the same year that a Harvard student was <a href="https://www.techspot.com/news/81644-harvard-student-denied-entry-us-over-friends-social.html">denied entry</a> to the US because of his friends' social media activity.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A third of chocolate products are high in heavy metals (267 pts)]]></title>
            <link>https://www.consumerreports.org/health/food-safety/a-third-of-chocolate-products-are-high-in-heavy-metals-a4844566398/</link>
            <guid>38038465</guid>
            <pubDate>Fri, 27 Oct 2023 13:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.consumerreports.org/health/food-safety/a-third-of-chocolate-products-are-high-in-heavy-metals-a4844566398/">https://www.consumerreports.org/health/food-safety/a-third-of-chocolate-products-are-high-in-heavy-metals-a4844566398/</a>, See on <a href="https://news.ycombinator.com/item?id=38038465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
                    

<div>
                      <figure>
            <picture>
                    <source srcset="https://article.images.consumerreports.org/image/upload/w_510,f_auto,q_auto,ar_16:9,c_lfill,dpr_2.0/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(max-width: 767px) and (-webkit-min-device-pixel-ratio: 2),
            (max-width: 767px) and (min-resolution: 192dpi)">
        <source srcset="https://article.images.consumerreports.org/image/upload/w_510,f_auto,q_auto,ar_16:9,c_lfill/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(max-width: 767px)">
                            <source srcset="https://article.images.consumerreports.org/image/upload/w_770,f_auto,q_auto,ar_16:9,c_lfill,dpr_2.0/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(max-width: 992px) and (-webkit-min-device-pixel-ratio: 2),
            (max-width: 992px) and (min-resolution: 192dpi)">
        <source srcset="https://article.images.consumerreports.org/image/upload/w_770,f_auto,q_auto,ar_16:9,c_lfill/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(max-width: 992px)">
                            <source srcset="https://article.images.consumerreports.org/image/upload/w_945,f_auto,q_auto,ar_16:9,c_lfill,dpr_2.0/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(min-width: 1200px) and (-webkit-min-device-pixel-ratio: 2),
            (min-width: 1200px) and (min-resolution: 192dpi)">
        <source srcset="https://article.images.consumerreports.org/image/upload/w_945,f_auto,q_auto,ar_16:9,c_lfill/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" media="(min-width: 1200px)">
            
    <img src="https://article.images.consumerreports.org/image/upload/w_945,f_auto,q_auto,ar_16:9,c_lfill/v1696263716/prod/content/dam/CRO-Images-2023/10October/Special-Projects/CR-SP-InlineHero-Heavy-Metals-in-Chocolate-Products-1023" alt="Lead and Cadmium element symbols on pieces of milk and dark chocolate surrounded by chocolate cake, brownies, chocolate chips, chocolate syrup, and Cocoa powder." fetchpriority="high" width="945" height="531">
</picture>
    
                <span>
            Photo Illustration: Chris Griggs/Consumer Reports, Getty Images
        </span>
    </figure>

                </div>

<div>
            <p><time datetime="2023-10-25T06:00">
                    October 25, 2023
            </time>
</p>
                        <div>
                    <p><span itemprop="author">Data Visualizations by Andy Bergmann</span>
                    </p>
                </div>
                        
        </div>

    



                    <div id="intro">
                <p>With the holiday season approaching, many of us will be indulging in a favorite treat: chocolate. Yet despite dark chocolate’s reputation as a healthier sweet, it can also be contaminated with lead and cadmium, two heavy metals linked to serious health problems, as many people learned from <a href="https://www.consumerreports.org/health/food-safety/lead-and-cadmium-in-dark-chocolate-a8480295550/">Consumer Reports’ testing last year</a>.</p>
<p>Now CR has the results of our new tests on heavy metal levels in other kinds of chocolates and foods made with it.</p>
            </div>
    <div>
                <p>In chocolate products, the lead and cadmium are concentrated in the cocoa (or cacao), the ingredient that gives chocolate its distinctive flavor. Dark chocolate tends to have higher levels of cacao. But other chocolate products contain cacao, too, in varying quantities—from cocoa powder, which is essentially pure cocoa, to <a href="https://www.consumerreports.org/health/food-safety/are-there-heavy-metals-in-milk-chocolate-a1095452037/">milk chocolate</a>, which can have very little.</p>
<p>CR’s experts wanted to see whether other cacao-containing foods posed a risk, so we tested 48 different products in seven categories—cocoa powder, chocolate chips, milk chocolate bars, and mixes for brownies, chocolate cake, and hot chocolate. We also added a few more dark chocolate bars to our test. Products came from big name brands such as Hershey’s, Ghirardelli, and Nestlé; national retailers like Costco, Target, Trader Joe’s, Walmart, and Whole Foods; and specialty makers such as Droste and Navitas.</p>
<p>As expected, dark chocolates tended to have higher levels of heavy metals and milk chocolate lower. “But every product we tested had detectable amounts of lead and cadmium,” says James E. Rogers, PhD, director and acting head of product safety testing at CR. “Sixteen of the 48 products had amounts above CR’s levels of concern for at least one of the heavy metals—in some cases more than twice our limit—but we did find safer options in each category of chocolate products.”</p>
            </div>
    
    <div id="heavy-metals-in-chocolate">
                    <p>Heavy metals can be found in many foods—such as arsenic in rice, mercury in some types of fish, cadmium in spinach, and lead in carrots and sweet potatoes. And you can also be exposed through drinking water or your environment (such as lead paint in your house). All these sources can add up, so it is important to be aware of different pathways that contribute to your overall heavy metal intake. Chocolate may just be one of a number of contributing factors to overall heavy metal levels, but it’s a popular treat eaten by children and adults and not an essential part of a someone’s diet. So it makes sense to try to limit the amount of heavy metals people get from chocolate.&nbsp;</p>
<p>Exposure to heavy metals is of greatest concern in children and during pregnancy, because they can damage the brain and nervous system, causing developmental delays, learning and behavior problems, and more. But adults can also experience negative effects. For example, frequent lead exposure has been linked to <a href="https://www.consumerreports.org/health/nutrition-healthy-eating/immune-boosting-foods-that-help-keep-you-well-a4816367434/">immune system suppression</a>, reproductive issues, kidney damage, and hypertension.</p>
<p>Lead and cadmium are the two heavy metals that CR’s tests have found to be the most problematic in chocolate. Research indicates that <a href="https://www.consumerreports.org/health/food-safety/how-lead-and-cadmium-get-into-dark-chocolate-a3299517114/">lead and cadmium get into cocoa in different ways</a>. For cadmium, it appears that the cocoa plant takes it up from the soil. Lead, however, can be deposited on the cocoa beans after harvest, potentially from dust and soil as beans dry outdoors. These metals are both found in the cocoa solids—which, along with cocoa butter, make up cacao. That’s why products rich in cocoa solids, such as dark chocolate and cocoa powder, tend to be higher in heavy metals.</p>
                </div>
    <div id="how-c-r-tested-chocolate-products">
                    <p>We measured the amount of lead, cadmium, mercury, and arsenic in three samples of each food and averaged the results. None of the products posed a risk of arsenic or mercury exposure.</p>
<p>To assess the risk from lead and cadmium, we looked at whether a serving of each product would expose someone to California’s standard maximum allowable dose levels (MADL) for lead (0.5 micrograms per day) and cadmium (4.1 mcg per day) in food. Note that as part of a settlement to a lawsuit currently in place brought by As You Sow, an organization that pushes for corporate accountability, the vast majority of chocolate products sold in the state are subject to less stringent standards, while companies work to reduce the levels of metals in their chocolate products. </p>
<p>CR’s scientists measured heavy metal content against California’s standard levels because there are no federal limits for the amount of lead and cadmium most foods can contain, and they believe that California’s standard levels are the most protective available. However, our tests are not assessments of whether a product exceeds California’s or any other legal standard—they are meant to indicate which products had comparatively higher levels of heavy metals.&nbsp;</p>
<p>Our results are shown by category in the charts in each section below. We list the percentages of the standard MADL levels for lead and cadmium supplied in one serving of the foods. While both heavy metals increase the risk of serious health problems, products within each category are listed in order of lead level, because that heavy metal poses particular concerns and no amount of it is considered safe.</p>
                </div>
    <div id="dark-chocolate">
                    <p>When we tested dark chocolate bars last year, we found lead or cadmium levels above CR’s thresholds in 23 of 28 bars, or 82 percent of them. Our results this time were similar. Of the seven bars we tested, five, or 71 percent, were above our levels for lead, cadmium, or both.</p>
<p>Two bars—Divine 70% Deliciously Smooth Dark Chocolate and Sam’s Choice (Walmart) Dark Chocolate 85% Cocoa—fell below CR’s levels for both lead and cadmium, based on a serving of about 1 ounce. (The following bars also came in below our thresholds when we tested them last year: Ghirardelli Intense Dark Chocolate 86% Cacao, Ghirardelli Intense Dark Chocolate Twilight Delight 72% Cacao, Mast Organic Dark Chocolate 80% Cocoa, Taza Chocolate Organic Deliciously Dark Chocolate 70% Cacao, and Valrhona Abinao Dark Chocolate 85% Cacao.)&nbsp;</p>
<p>Eating an ounce of four others would put you over our limit for lead. The Perugina Premium Dark Chocolate bars had the highest amounts. One of the four, Evolved Signature Dark 72% Cacao Chocolate Bar was high in both lead and cadmium. Another bar, Sam’s Choice Dark Chocolate 72% Cocoa, was high in cadmium only.&nbsp;</p>
<p>Nestlé, which owns Perugina, told CR, “We apply strict standards to ensure our products are high quality and comply with all applicable regulatory requirements, including limits for cadmium and lead<em>.</em>” And Rick Gusmano, co-founder of Evolved Chocolate, said the company’s chocolate products fall well below levels set in the As You Sow settlement and that the company “regularly tests raw materials and finished goods to ensure compliance and, ultimately, consumer safety.” Other makers of dark chocolate with high levels of lead or cadmium did not respond to a request for comment.&nbsp;</p>
                </div>
    
    <div id="milk-chocolate">
                <p>Milk chocolate tends to be lower in heavy metals than dark chocolate because it has less cocoa solids. And in fact none of the five milk chocolate bars in our tests were over CR’s limit for either heavy metal. Hershey’s Milk Chocolate bar had the most lead, reaching 67 percent of CR’s limit. Feastables Mr. Beast Bar Milk Chocolate, with 80 percent of CR’s limit, had the most cadmium per serving. Lindt Classic Recipe Milk Chocolate Bar was the lowest overall, with one serving (about 1 ounce) containing 11 percent of the daily maximum amount of lead and 13 percent of the daily cadmium limit.</p>
            </div>
    
    <div id="chocolate-chips">
                    <p>None of these 12 products had high levels of cadmium, and only two—Hu Dark Chocolate Gems and Good &amp; Gather (Target) Semi-Sweet Mini Chocolate Chips—were over CR’s limit for lead.&nbsp;</p>
<p>But there’s a caveat: The serving size for chocolate chips is just around ½ ounce (about 1 tablespoon)—the amount you might expect to get in a cookie or two, depending on the size of the cookie. If you’re the type that likes to eat more than a few cookies, or a handful of chips straight out of the bag, with many of these you could exceed the daily limits for both cadmium and lead by eating just two servings. Some good options for snacking that are relatively low in both heavy metals are 365 Whole Foods Market Semi-Sweet Chocolate Baking Chips, Kirkland Signature Semi-Sweet Chocolate Chips, and Nestlé Toll House Semi-Sweet Morsels.&nbsp;</p>
<p>A spokesperson for Hu told CR that our test results were in line with the company’s own testing, but added that those levels fall far below those set in the As You Sow lawsuit settlement. Target did not respond to a request for comment.</p>
                </div>
    
    <div id="cocoa-powder">
                    <p>Cocoa powder is almost all cocoa solids, so you might expect that most would be too high in lead and cadmium, even in small amounts. But none of those we tested were high in cadmium, and only two had high levels of lead.&nbsp;</p>
<p>Most of the cocoa powders in our tests were natural-style—the kind most commonly available in the U.S.—and of those, a serving (1 tablespoon) of Hershey’s Cocoa Naturally Unsweetened 100% Cacao exceeded our lead limit.&nbsp;</p>
<p>Droste Cacao Powder was the only Dutch processed cocoa in our tests. This type of cocoa is alkalized to give it a less bitter taste. It was also the highest in lead of any product in our tests, supplying 324 percent of CR’s limit.&nbsp;</p>
<p>The best cocoa powder overall was Navitas Organics Organic Cacao Powder, which reached 77 percent of CR’s lead limit and 17 percent of the cadmium limit. Navitas has a third party test all finished products for heavy metals to ensure low levels, according to the <a href="https://navitasorganics.zendesk.com/hc/en-us/articles/4408161123604-Are-there-heavy-metals-in-your-cacao-">company website</a>.</p>
<p>Neither Droste nor Hershey responded to a request for comment.</p>
                </div>
    
    <div id="hot-chocolate-mixes">
                    <p>These mixes contain cocoa powder plus sugar and other ingredients, so we expected that they would be relatively low in lead and cadmium. That’s not what we found. Four of the six mixes we tested exceeded our lead limit: Great Value (Walmart) Milk Chocolate Flavor Hot Cocoa Mix, had the highest levels, with mixes from Trader Joe’s and Nestlé (which also makes hot chocolate mix for Starbucks), above CR’s cutoff.&nbsp;</p>
<p>The Nestlé spokesperson said that the company stands by the safety of its products and that it works with its “suppliers on an ongoing basis to closely monitor and minimize the presence of these substances in our foods as much as possible.” Other makers of hot chocolate with high levels of lead did not respond to requests for comment.</p>
                </div>
    
    <div id="brownie-and-cake-mixes">
                    <p>These products fared well overall in our tests. None were high in cadmium, and just one brownie mix and two cake mixes exceeded CR’s lead limits—one by quite a bit. One serving of Bob’s Red Mill Gluten Free Chocolate Cake Mix had 216 percent. The heavy metal levels refer to the amounts of the mix that are in one serving of the finished cake or brownie. (We list the number of servings each mix makes in the charts below.)&nbsp;</p>
<p>However, the serving sizes are small. For instance, Duncan Hines Devil’s Food Cake mix makes a cake that the manufacturer says will serve 10. The company’s Double Fudge Brownie mix makes 20 servings. If your cake or brownie portions are more generous, keep in mind that you’ll be getting more lead and cadmium than we list here.&nbsp;</p>
<p>Bob’s Red Mill, Simple Mills, and Ghirardelli did not respond to requests for comment.</p>
                </div>
    
    
    <div id="making-chocolate-safer">
                    <p>Since any intake of heavy metals can be harmful over time, it’s important that products contain the lowest amount possible. There are ways for manufacturers to reduce the heavy metals in their products—such as sourcing chocolate from areas that have low levels of cadmium in the soil, and making improvements in cocoa harvesting, processing, and cleaning procedures.&nbsp;</p>
<p>CR reached out to an industry trade group as well as the Food and Drug Administration for comment. </p>
<p>“Chocolate and cocoa are safe to eat and can be enjoyed as treats, as they have been for centuries,” says Christopher Gindlesperger, senior vice president of public affairs and communications for the National Confectioners Association, a candy industry group. “Food safety and product quality remain our highest priorities, and we remain dedicated to being transparent and socially responsible.”</p>
<p>The Food and Drug Administration told CR that “While the presence of cadmium and lead in chocolate has been the subject of considerable media attention, experts from around the world have found that chocolate is a minor source of exposure to these contaminants internationally.” And the agency added&nbsp;that “ all food manufacturers and processors are responsible for ensuring the safety of their food."</p>
<p>Our results, however, show that some companies may be doing a better job of keeping metals out of their products than others. That’s true even for dark chocolate and cocoa powders. “In general, products with higher cocoa content tend to have higher levels of metals, but not always,” says Eric Boring, PhD, a CR chemist who oversaw our chocolate tests. “There’s enough variation in the lead levels within each category of foods that it’s clear factors other than cocoa content affect lead levels, and that means manufacturers have the ability to reduce the heavy metals in their products to the lowest levels possible.” </p>
<p>For example, if Navitas Organic Cacao can be lower in lead, Boring says, why can’t Hershey’s make a cocoa powder that is lower in the heavy metal, too?</p>
<p>Brian Ronholm, director of food policy at CR, adds that "Earlier this year, a Hershey executive stated that the company continues to look for ways to remove more of the metals through additional cleaning and alternate sourcing. We would like for them to honor that commitment." </p>
<p>“Since the metals occur naturally in soil, it may seem that it would be difficult to reduce contamination, but <a href="https://www.consumerreports.org/health/food-safety/chocolate-makers-urged-to-get-lead-cadmium-out-of-products-a6449371819/">there are some steps that chocolate makers can take</a> to make their products safer,” Ronholm says. These include sourcing from areas with lower levels and mixing beans from different areas to ensure that the final product has lower levels. Producers could also test lots of cocoa to identify problem areas and reject particularly contaminated lots, he says.</p>
                </div>
    <div id="making-healthier-choices">
                    <p>• As much as possible, it makes sense to try to avoid heavy metals in your diet—but that doesn’t mean you should never eat chocolate.</p>
<p>• Kids and pregnant people should consume dark chocolate sparingly, if at all, because heavy metals pose the highest risk to young children and developing babies. And if you do eat it, pick products that our tests showed to have lower levels of heavy metals. When consuming other cocoa-containing items—like hot chocolate or brownies—it may be best to limit these to not every day, and also choose products lower in heavy metals. And, of course, you should limit how much you eat other foods that tend to be high in heavy metals, such as rice and rice products, carrots, and sweet potatoes.</p>
<p>• Milk chocolate can be a fine alternative for those who want to limit heavy metal exposure, but don’t treat it as a health food—it’s packed with more sugar than dark chocolate, and should still be consumed in moderation.</p>
<p>• For other adults who want to eat dark chocolate, occasional consumption won’t necessarily expose you to extremely high levels of heavy metals. But as much as possible, try to be aware of potential metal exposure from multiple sources. For more tips, see our <a href="https://www.consumerreports.org/health/food-safety/lead-and-cadmium-in-dark-chocolate-a8480295550/">previous article on metals in chocolate</a>.&nbsp;</p>
<p>• When consuming hot chocolate, brownies, chocolate cake, and other cocoa-containing products, know that they can contribute to your overall heavy metal burden. As with other types of chocolate, these are best consumed in moderation.</p>
                </div>
    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ScratchDB – Open-Source Snowflake on ClickHouse (195 pts)]]></title>
            <link>https://github.com/scratchdata/ScratchDB</link>
            <guid>38038239</guid>
            <pubDate>Fri, 27 Oct 2023 13:34:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/scratchdata/ScratchDB">https://github.com/scratchdata/ScratchDB</a>, See on <a href="https://news.ycombinator.com/item?id=38038239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-scratchdb" dir="auto"><a href="#scratchdb">ScratchDB</a></h2>
<p dir="auto">ScratchDB is a wrapper around Clickhouse that lets you input arbitrary JSON and
perform analytical queries against it. It automatically creates tables
and columns when new data is added.</p>
<h2 tabindex="-1" id="user-content-quickstart" dir="auto"><a href="#quickstart">Quickstart</a></h2>
<h4 tabindex="-1" id="user-content-1-run-the-server" dir="auto"><a href="#1-run-the-server">1. Run the server</a></h4>
<p dir="auto">Clone the repo:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:scratchdata/ScratchDB.git
$ cd ScratchDB"><pre>$ git clone git@github.com:scratchdata/ScratchDB.git
$ <span>cd</span> ScratchDB</pre></div>
<p dir="auto">Start clickhouse and localstack:</p>

<p dir="auto">In a separate terminal, start the insert service:</p>

<p dir="auto">Finally, in an additional terminal window, start the ingest service:</p>

<h4 tabindex="-1" id="user-content-2-insert-json-data" dir="auto"><a href="#2-insert-json-data">2. Insert JSON data</a></h4>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl -X POST http://localhost:3000/data \
    -H 'Content-Type: application/json' \
    -H 'X-Api-Key: local' \
    -d '{&quot;table&quot;:&quot;my_table&quot;,&quot;data&quot;:{&quot;fruit&quot;: &quot;apple&quot;}}'"><pre>$ curl -X POST http://localhost:3000/data \
    -H <span><span>'</span>Content-Type: application/json<span>'</span></span> \
    -H <span><span>'</span>X-Api-Key: local<span>'</span></span> \
    -d <span><span>'</span>{"table":"my_table","data":{"fruit": "apple"}}<span>'</span></span></pre></div>
<h4 tabindex="-1" id="user-content-3-query" dir="auto"><a href="#3-query">3. Query</a></h4>
<p dir="auto">To view data in JSON format: <a href="http://localhost:3000/query?q=select%20*%20from%20my_table" rel="nofollow">http://localhost:3000/query?q=select * from my_table</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -H 'X-Api-Key: local' &quot;http://localhost:3000/query?q=select%20*%20from%20my_table&quot;"><pre>curl -H <span><span>'</span>X-Api-Key: local<span>'</span></span> <span><span>"</span>http://localhost:3000/query?q=select%20*%20from%20my_table<span>"</span></span></pre></div>
<p dir="auto">To view data in an HTML table: <a href="http://localhost:3000/query?format=html&amp;q=select%20*%20from%20my_table" rel="nofollow">http://localhost:3000/query?format=html&amp;q=select * from my_table</a></p>
<div data-snippet-clipboard-copy-content="curl -H 'X-Api-Key: local' &quot;http://localhost:3000/query?format=html&amp;q=select%20*%20from%20my_table&quot;"><pre><code>curl -H 'X-Api-Key: local' "http://localhost:3000/query?format=html&amp;q=select%20*%20from%20my_table"
</code></pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Soap Works: The Science Behind Handwashing (149 pts)]]></title>
            <link>https://www.pfizer.com/news/articles/how_soap_works_the_science_behind_handwashing</link>
            <guid>38038174</guid>
            <pubDate>Fri, 27 Oct 2023 13:28:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pfizer.com/news/articles/how_soap_works_the_science_behind_handwashing">https://www.pfizer.com/news/articles/how_soap_works_the_science_behind_handwashing</a>, See on <a href="https://news.ycombinator.com/item?id=38038174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>While there’s still much we don’t understand about COVID-19, there's one piece of advice that experts in the health care community agree on: washing your hands with soap and water is one of the most effective ways people can keep from getting sick, and from passing the virus to others<sup>1</sup>.</p><p>Soap, which has been in around for thousands of years,<sup>2</sup> is uniquely structured to help destroy the virus. “Soap works because it’s the right structure to do the job,” says Rebecca Gallego, senior principal scientist, medicinal sciences with Pfizer. “No mater how hard you try, if you were to scrub with just water, or if you were to scrub with sand, it wouldn't work.”<b>&nbsp;</b></p><h2><b>Here’s why it’s soap is so effective: </b></h2><p>Coronavirus molecules look a bit like spiky sea urchins. The outer layer is a plasma membrane made of two layers of phospholipids. The phospholipids consist of a greasy lipid part that is hydrophobic, meaning it hates water, and a phosphate head group that is hydrophilic, meaning it loves water. The spikes on a coronavirus are made of protein. They help transmit the illness by penetrating a host cell in a human being and transferring the genetic information of the virus, which then replicates itself. That’s when a person gets sick.</p><p>And that’s what soap is able to stop.</p><p>A soap molecule, which looks like a tadpole, has a hydrophilic (water-loving) head and a hydrophobic (water-hating) tail. The water-hating part of the soap wants to get away from the water. If the virus is on a person’s hands, that water-hating tail is drawn to that fatty layer. It pries its way in.</p><p>“When soap comes into contact with the&nbsp;plasma membrane of the virus, it’ll try to wedge itself in there,” says Gallego. “If you get enough of these soap molecules into the plasma membrane, it breaks it apart, destroying it.” The virus pops like a balloon, spilling its insides.</p><p>When a person scrubs his or her hands for 20 seconds, as the&nbsp;CDC guidelines recommend<sup>3</sup>, the motion builds up more bubbles, which finds their way into the cracks and crevices of the hands. This allows the soap to do its job more thoroughly by destroying more and more of the virus, preventing someone from getting sick, themselves, and from passing the virus on to others.</p><p>Gallego says that this approach is simple, but effective, when done correctly.</p><p>“Doing all these&nbsp;little things can add up to a big impact factor when it comes to preventing the disease,” she says.</p><p><img alt="" height="1" src="https://pixel.welcomesoftware.com/px.gif?key=YXJ0aWNsZT1hZTkwYjlhZjhiMTBhMWIxYThiNTU1ZjYzN2U0YTdhMw==" width="1"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Slow Death of Authenticity in an Attention Economy (438 pts)]]></title>
            <link>https://www.coryzue.com/writing/authenticity-and-engagement/</link>
            <guid>38037851</guid>
            <pubDate>Fri, 27 Oct 2023 13:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.coryzue.com/writing/authenticity-and-engagement/">https://www.coryzue.com/writing/authenticity-and-engagement/</a>, See on <a href="https://news.ycombinator.com/item?id=38037851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                <p><img src="https://www.coryzue.com/images/authenticity/midwit-twitter.jpg" alt="Midwit meme"></p>

<p>How I wish people used Twitter versus how they seem to be doing it lately.</p>

<p>I’m not quite sure when I started feeling uncomfortable with Twitter.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>It <em>wasn’t</em> when Elon Musk bought it, or during the mass firings, or the bluecheck fiasco, or the rebrand to X, or any of the other politically-obvious times that many people decided to give up on it.</p>

<p>No, I was a Twitter optimist for a long time.</p>

<p>But somehow, somewhere over the last few months, my positive outlook on the platform has slowly eroded away. As I—ironically—spend as much time as ever scrolling through my feed—I find myself more and more annoyed, jealous, outraged, yes, but mostly just… <em>bored</em>.</p>

<p>And what’s funny is that the content is more “engaging” than ever. My feed is full of posts that have obviously had more effort put into it than most of what I used to see. Megathreads about AI, thoughtful, longform narratives that could have been blog posts, carefully curated images, and super-positive business updates. It’s mostly <em>engaging stuff</em>.</p>

<p>And therein, I think, lies the problem. <strong>The content I now see on Twitter is content that has been designed to be seen on Twitter.</strong> Tweeting has become a job. Quite literally, for many people, ever since they’ve started paying creators a share of ad revenue.</p>

<p>And yes, on the surface this incentivizes people to create better content. The better your content is, the more it gets seen, and the more money you make. And yet, my felt experience of this change is the exact opposite—as people seek more engagement, their content gets <em>worse</em>. What’s going on here?</p>

<p>One possibility is that I am unusual. I go on Twitter for <em>authenticity</em>. I have carefully curated a list of human beings who I know by name, and whose ideas and actions interest me. But authenticity is often at odds with growth.</p>

<p>Why? Well to <em>grow</em> you need to be noticed. To be noticed, you need to stand out. And to stand out is—usually—inauthentic.
Yes, we all say and do noteworthy things, but not every day. To do or say noteworthy things every day involves some degree of forcedness, repetition, or <em>trying</em>. The opposite of authenticity.</p>

<p>If I wanted to get 10x more engagement than usual on a Tweet tomorrow, I could. I could post some celebratory brag about how much money I’m earning from my businesses (“omg $10k MRR!”). I could pick a fight on a topic people feel strongly about (“React sucks!”).
I could mention it’s my birthday and post a picture of myself (“Can’t believe I’m 41!”).<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>
I could ask a question that lets people promote themselves (“What’s your favorite personal website?”),
angrily quote-tweet a terrible take, and so on.</p>

<p>I know these things work. And I occasionally do them, knowing they will work.
I try to do this only a handful of times a year, because even though they <em>work</em>, and even though they <em>are useful for me and <a href="https://scriv.ai/">my</a> <a href="https://www.saaspegasus.com/">businesses</a></em>,
and even though they <em>make my lizard brain feel good</em>, a part of me still hates them. Even a few times a year.</p>

<blockquote><div lang="en" dir="ltr"><p>Take the red pill and get thousands of likes and new followers. You just have to sacrifice a tiny bit of your authenticity.</p><p>Take the blue pill and be your true, honest, and proud self. Except no one really notices or cares.</p><p>What do you do? <a href="https://t.co/OsIirl93Te">pic.twitter.com/OsIirl93Te</a></p></div>— Cory Zue (@czue) <a href="https://twitter.com/czue/status/1709291338406015447?ref_src=twsrc%5Etfw">October 3, 2023</a></blockquote>


<p>Clearly I’ve been wrestling with this issue for a little while now.</p>

<p>But oh boy, not the people in my feed. The people in my feed—most of whom I’m not following, by the way—<em>love</em> posting for engagement. Some of them love it so much that they offer courses teaching other people how to do it—which amplifies this godforsaken death spiral even further.</p>

<p>And so now we find ourselves in a situation where all these asshats with 20k followers and a Stripe account are now <em>running their Twitter account as a business</em>. And this has led to a slow and inevitable decline from authenticity to some version of marketing (look at my content!) and sales (follow me!).</p>

<blockquote><p lang="en" dir="ltr">The natural end state of marketplaces and social media is the eventual shift from user generated supply to professionalized supply/content. They can fight it for some time, but eventually there is no other way to keep scaling (or prevent power users from peeling off)</p>— Kevin Kwok (@kevinakwok) <a href="https://twitter.com/kevinakwok/status/1688978920001970177?ref_src=twsrc%5Etfw">August 8, 2023</a></blockquote>


<p>What we are witnessing now is the <em>professionalization</em> of Twitter.</p>

<p>And look, I don’t think it’s just the algorithm and the incentives. Elon’s political antics chased away a lot of good people.
Many of my favorite follows have moved to Mastodon, Threads, and Bluesky.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>
Also, more and more people are waking up and realizing that social media is actually quite bad for you, and leaving it behind.
Good for them. Bad for me.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup></p>

<p>Still—and quite ironically—if anything actually gets me to stop using this platform,
it’s going to be the changes that are supposed to make it grow.</p>

<hr>

<p><em>If you liked this, you can <a href="https://x.com/czue/status/1717889142997086412">share it on Twitter</a>, discuss it <a href="https://news.ycombinator.com/item?id=38037851">on Hacker News</a>,
or sign up below to get emailed when I post new stuff.</em></p>

<p><strong>Notes</strong></p>



            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Is the Django Admin "Ugly"? (131 pts)]]></title>
            <link>https://www.coderedcorp.com/blog/why-is-the-django-admin-ugly/</link>
            <guid>38037596</guid>
            <pubDate>Fri, 27 Oct 2023 12:32:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.coderedcorp.com/blog/why-is-the-django-admin-ugly/">https://www.coderedcorp.com/blog/why-is-the-django-admin-ugly/</a>, See on <a href="https://news.ycombinator.com/item?id=38037596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p><em>Updated October 27, 2023 to include additional quotes and commentary.</em></p>
<p>While talking with people at Djangocon US, one question kept coming up: “why is the Django admin so ‘ugly’?”. I’m paraphrasing here, so pardon the click-bait title, but the question came in many forms. Why does the Django admin have a “dated” UI? Why has the Django admin not changed much in all these years? Why is the Django admin missing &lt;insert feature&gt;?</p>
<p>Being an old-timer (my first Djangocon was 2012, a century ago in web dev time) I thought I had the answer: the Django admin is “ugly” to discourage you from giving it to clients or end-users.</p>
<p>But thankfully, there are better people than me who walk this earth. One such person is Janelle who asked: “can I get a source for that?”. Challenge accepted. Not wanting to let Janelle down, I searched far and wide, across the vast expanse of conference rooms and laptop screens, to seek the wisdom of Django maintainers. The teacher becomes the student.</p>
<blockquote>
<p>The Django admin is not ugly, rather, no effort was made to make it a beautiful end-user tool.</p>
</blockquote>
<p><a href="https://www.djangoproject.com/weblog/2020/dec/23/2020-malcolm-tredinnick-memorial-prize-awarded-ken/">Ken Whitesell</a>, longtime Django user and ever-present face in the Django community, has worked with Django since version 1.2. Ken very rightfully corrected my question: the Django admin is not ugly, rather, no effort was made to make it a beautiful end-user tool. Ken then pointed out that the answer to my question was front-and-center in the Django documentation itself:</p>
<blockquote>
<p>The admin’s recommended use is limited to an organization’s internal management tool. It’s not intended for building your entire front end around.</p>
<p>— From https://docs.djangoproject.com/en/4.2/ref/contrib/admin/</p>
</blockquote>
<p>Ken also pointed out that this exact question has come up time and time again in the Django forum. <a href="https://forum.djangoproject.com/search?q=The%20admin%27s%20recommended%20use%20is%20limited%20to%20an%20organization%27s%20internal%20management%20tool">See for yourself</a>.</p>
<p>So that answers the <em>how</em>; now I wanted the <em>why</em>. Why is this the intended use case for the Django admin?</p>
<blockquote>
<p>The Django admin was built for Phil.</p>
<p>— Jacob Kaplan-Moss</p>
</blockquote>
<p><a href="https://jacobian.org/">Jacob Kaplan-Moss</a>, co-creator of Django, gave me the most beautifully literal answer: “The Django admin was built for Phil”, referring to Phil Cauthon, then-editor of Lawrence.com weekly newspaper, one of the first Django sites ever built. Since Django was originally built for the newspaper, the admin was used by internal staff who were trusted to know how to use it. “If something was edited or messed up in the admin, you could walk over to someone’s desk and ask ‘why did you do that?’”, Jacob recounts of the original Django admin workflow.</p>
<p>Both Ken and Jacob came to a consensus, which sort of aligned with my answer as well. The Django admin is more about organizational administration and trust. You have administrative/organizational/political control over who uses the admin and what they do with it. There is an implicit level of trust in your staff. You don’t need to invest the time and effort into making it a customer-facing tool used by people who are not familiar with your product.</p>
<blockquote>
<p>Even in the 0.9x days we used to have a image that said “Admin: it’s not your app”.</p>
<p>— Curtis Maloney</p>
</blockquote>
<p><a href="https://www.djangoproject.com/weblog/2013/nov/04/announcing-inaugural-winner-malcolm-tredinnick-mem/">Curtis Maloney</a>, known as <a href="https://chaos.social/@FunkyBob/111298736068471171">FunkyBob online</a>, recalls the earliest days of Django: “Even in the 0.9x days we used to have a image that said ‘Admin: it’s not your app’”. Curtis and I both agree that the Django admin is a great database tool, but should be treated as such.  As Curtis put it, “encouraging people to build their own management interface, and treat admin as a DB admin tool, has saved a lot of people pain... the effort to customise it grows far faster than the payoffs.”</p>
<p>All that being said, the Django admin is still a tool used by humans, so we should continue making improvements to make it accessible. My colleague <a href="https://2023.djangocon.us/talks/djangos-accessibility-track-record/">Thibaud Colas gave a fantastic talk about this</a> (a recording of the talk will be available soon).</p>
<p>Lastly, if you find the need to give the Django admin to your customers or end-users, consider checking out the <a href="https://docs.wagtail.org/en/stable/reference/contrib/modeladmin/index.html">Wagtail ModelAdmin</a>, which is nearly a drop-in replacement (and runs alongside the existing Django admin) with the benefit of tremendous accessibility, fine-grained control, and a beautiful UX built for non-technical end-users.</p>
<p><strong>P.S.</strong> Thank you to Janelle who challenged me on this by asking for a source. I learned a thing or two in the process. It’s a great reminder to challenge your own understanding; and another reason why spending time with the wonderful folks in our community can really refresh your mind.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior (111 pts)]]></title>
            <link>https://mrtornado24.github.io/DreamCraft3D/</link>
            <guid>38037449</guid>
            <pubDate>Fri, 27 Oct 2023 12:11:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mrtornado24.github.io/DreamCraft3D/">https://mrtornado24.github.io/DreamCraft3D/</a>, See on <a href="https://news.ycombinator.com/item?id=38037449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-anchor="slide1">
            <h2>Abstract</h2>
            <p>
                We present DreamCraft3D, a hierarchical 3D content generation method that produces high-fidelity and coherent 3D objects. We tackle the problem by leveraging
                a 2D reference image to guide the stages of geometry sculpting and texture boosting. A central focus of this work is to address the consistency issue that existing
                works encounter. To sculpt geometries that render coherently, we perform score
                distillation sampling via a view-dependent diffusion model. This 3D prior, alongside several training strategies, prioritizes the geometry consistency but compromises the texture fidelity. 
                We further propose <b>Bootstrapped Score Distillation (BSD)</b> to
                specifically boost the texture. We train a personalized diffusion model, Dreambooth, on the augmented renderings of the scene, imbuing it with 3D knowledge
                of the scene being optimized. The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene. Notably, through an
                alternating optimization of the diffusion prior and 3D scene representation, we
                achieve mutually reinforcing improvements: the optimized 3D scene aids in training the scene-specific diffusion model, which offers increasingly view-consistent
                guidance for 3D optimization. The optimization is thus bootstrapped and leads
                to substantial texture boosting. With tailored 3D priors throughout the hierarchical generation, DreamCraft3D generates coherent 3D objects with photorealistic
                renderings, advancing the state-of-the-art in 3D content generation.
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div><div>
<h2>BibTeX</h2>
<div>
    <pre><code>@misc{sun2023dreamcraft3d,
        title={DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior}, 
        author={Jingxiang Sun and Bo Zhang and Ruizhi Shao and Lizhen Wang and Wen Liu and Zhenda Xie and Yebin Liu},
        year={2023},
        eprint={2310.16818},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
  }</code></pre>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study shows antibodies against PEG in 83% of the German population (155 pts)]]></title>
            <link>https://www.mpip-mainz.mpg.de/en/press/pr-2022-22</link>
            <guid>38037245</guid>
            <pubDate>Fri, 27 Oct 2023 11:42:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mpip-mainz.mpg.de/en/press/pr-2022-22">https://www.mpip-mainz.mpg.de/en/press/pr-2022-22</a>, See on <a href="https://news.ycombinator.com/item?id=38037245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  
  
  <p>Study shows antibodies against polyethylene glycol in 83 percent of the German population</p>
  

  

  <p>It has long been known that people can form defenses and thus antibodies against viruses. But antibodies can also develop against polyethylene glycol (PEG), a substance used in cosmetics, food and medicine. These influence the effectiveness of drugs. A team of researchers from the Max Planck Institute for Polymer Research has now investigated how widespread these antibodies already are in German society and how they might influence medical therapies using nanocarriers.</p>
  
  
<figure data-description="Anti-PEG antibodies circulate in the blood of many people and bind to PEGylated nanocarriers" data-picture="base64;<picture class="" data-iesrc="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--fd2c64c0a1a9d726b2a6aa4feccb5b57a30f0a58" data-alt="Anti-PEG antibodies circulate in the blood of many people and bind to PEGylated nanocarriers" data-class=""><source media="(max-width: 767px)" srcset="/881290/original-1697367387.webp?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--755904b1a79a7929fa0e2d7542075f13267a1b05 414w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--725c5d73fe12be804c540d12e7454ded6ad52907 375w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--c9aa6963f13e3ad5249c5e82edc62a9ccac2db1f 320w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--fddeae70e7d1ed1d9fead6a90d8c5952d5f73157 411w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--c27cff16d85995f5e14a6507483adbf91e499ab9 480w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--27bd52241ffa3c71dd891b03adbe734fe308bd4d 360w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--556e8cc2c2f1ffce0f8ff59b36c73c569dde13df 828w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--78f91df178c48c9a8c89ef81a17ea0686ab7a76e 750w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--ce3d9fee4b9dec8408e89a17584935f5df5afee4 640w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--52e1a046d74f1a5dfd599750a2f764ed042df294 822w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--b1164ae98eef88fda7e693f00e3b6010a71579f3 960w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--3cc2800ed006bfbffbf15a837d00ec44d9f28f98 720w" sizes="100vw" type="image/webp" /><source media="(max-width: 767px)" srcset="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--af0ad004477459e0ea8ae53ce63e5439bd9e68fe 414w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--d0378e94910bb029b137288daa61697b1bf41cc9 375w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--6be3a09c3c60c67b852933237098c4e06ec38014 320w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--e1cfd5aeb1f9c216af4f6d90c379d0f61edbc151 411w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--28430e7eb9b04905e7f32e824894258a7cd733c3 480w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--ffae65b452d08711fa72ea7a95e19789a07eeaec 360w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--32f63d7b931f3e3f904eb0bf335d5443f91666a9 828w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--a06367c925c699c502ceef8f7225901536bb96f7 750w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--359f6b33ede851f8544e436a9871a34d1c6cb504 640w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--5fa7305f1891f9466a3de6c9ef5d01dc627a5be0 822w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--03c0815571eed715cb22d9ef0dee1035480ac0fd 960w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--e8ef54d975ffb5ee8b9347b27647d6850adab762 720w" sizes="100vw" type="image/jpeg" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/881290/original-1697367387.webp?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjg4MTI5MH0%3D--349cd8aa5044af88b106cc824b3528b512699318 900w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo4ODEyOTB9--c5814f1464aca72008161a245799f56da4020bd4 1800w" sizes="900px" type="image/webp" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--557503f8a9313f5f222ae84fe91a41e1facf60c1 900w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--894ce05c7d78bf20347dbc4bda9905a421b4b978 1800w" sizes="900px" type="image/jpeg" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/881290/original-1697367387.webp?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--7c1f4798696bc8e7033a7de35dd267474f7f230f 1200w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo4ODEyOTB9--9821a7546e5a76dfb26a3fea9f130617347f938c 2400w" sizes="1200px" type="image/webp" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--8881ee14613f917948ae890dff7ceea1ef2f76bb 1200w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--e6f96412f0532e962edf25709f688f3647e8f60d 2400w" sizes="1200px" type="image/jpeg" /><source media="(min-width: 1200px)" srcset="/881290/original-1697367387.webp?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6ODgxMjkwfQ%3D%3D--115e29325f668828ab223629577ace3fd3231711 1400w, /881290/original-1697367387.webp?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo4ODEyOTB9--fe6002eb7771f9f3574fe82969ce28fb08339e95 2800w" sizes="1400px" type="image/webp" /><source media="(min-width: 1200px)" srcset="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--fd2c64c0a1a9d726b2a6aa4feccb5b57a30f0a58 1400w, /881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--27b15c040ab251f8298cd032980e674bebde424e 2800w" sizes="1400px" type="image/jpeg" /><img alt="Anti-PEG antibodies circulate in the blood of many people and bind to PEGylated nanocarriers" class="" title="Anti-PEG antibodies circulate in the blood of many people and bind to PEGylated nanocarriers" src="/881290/original-1697367387.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjg4MTI5MH0%3D--fd2c64c0a1a9d726b2a6aa4feccb5b57a30f0a58" /></picture>">
      
      

    
</figure>

<p>A virus invades the body and the immune system begins to work: Antibodies develop that fight the infection. At the same time, an immune memory builds up so that antibodies can be quickly made available in the event of a new infection. Surprisingly, antibodies can also form against polyethylene glycol (PEG), a molecule with a fairly simple structure.</p><p>In addition to cosmetic products - from creams, perfumes and lotions to lipstick - polyethylene glycol is also used in medicine. Here, it serves as a kind of camouflage coat against the body's own immune system, thus increasing the circulation time of an active ingredient in the blood.</p><p>"For us, PEG is interesting for coating nano-sized drug carriers with it," says Svenja Morsbach, group leader in Katharina Landfester's department at the MPI for Polymer Research. In this way, the researchers achieve a longer circulation time for the drug capsules, which are only nanometers in size and could be an important component in novel cancer therapies in the future, for example.</p><p>In their studies, the team led by Morsbach and Landfester examined more than 500 blood samples from patients taken in 2019. "The antibodies formed against PEG attach themselves to the coated nanocarriers, thus counteracting the effect that is actually desired: the nanocarrier becomes visible to the immune system and is removed before it can exert its effect," explains Katharina Landfester, director of the department.</p><p>The researchers led by Morsbach and Landfester assume that therapies will have to be adapted in the future to respond to this behavior of the immune system. In their statistical studies of blood samples, they found that PEG antibodies were already detectable in 83% of the samples examined.</p><p>The concentration of PEG antibodies in the blood correlates antiproportionally with the age of the person examined: the older the person, the fewer PEG antibodies were present. "We currently assume that this is due to the increasing use of PEG in various areas of life only recently and the variation of the immune system in age," says Morsbach.</p><p>In further studies, the researchers would now like to find out how future therapies could be adapted to compensate for the reduced camouflage of the nanocarriers. "Ideas would include whether PEG can be replaced or possibly dispensed with altogether," Morsbach said. But determining the antibody concentration in a patient's blood and individually adjusting the amount of active ingredient could also be an alternative.</p><p>They have published their current results in the renowned journal "Nanoscale Horizons".</p>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons Learned from Twenty Years of Site Reliability Engineering (309 pts)]]></title>
            <link>https://sre.google/resources/practices-and-processes/twenty-years-of-sre-lessons-learned/</link>
            <guid>38037141</guid>
            <pubDate>Fri, 27 Oct 2023 11:25:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sre.google/resources/practices-and-processes/twenty-years-of-sre-lessons-learned/">https://sre.google/resources/practices-and-processes/twenty-years-of-sre-lessons-learned/</a>, See on <a href="https://news.ycombinator.com/item?id=38037141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content">
        
        <h2>Or, Eleven things we have learned  as Site Reliability Engineers at Google</h2>
        <h3>Authors</h3>
        <p>Adrienne Walcer, Kavita Guliani, Mikel Ward, Sunny Hsiao, and Vrai Stacey</p>
        <h3>Contributors</h3>
        <p>Ali Biber, Guy Nadler, Luisa Fearnside, Thomas Holdschick, and Trevor Mattson-Hamilton</p>
        <h3>Foreword</h3>
<p>A lot can happen in twenty years, especially when you're busy growing.</p>
<p>Two decades ago, Google had a pair of small datacenters, each housing a few thousand servers, connected in a ring by a pair of 2.4G network links. We ran our private cloud (though we didn't call it that at the time) using Python scripts such as "Assigner" and "Autoreplacer" and "Babysitter" which operated on config files full of individual server names. We had a small database of the machines (MDB) which helped keep information about individual servers organized and durable. Our small team of engineers used scripts and configs to solve some common problems automatically, and to reduce the manual labor required to manage our little fleet of servers.</p>
<p>Time passed, Google's users came for the search and stayed for the free GB of Gmail, and our fleet and network grew with it. Today, in terms of computing power, we are over 1,000 times as large as we were 20 years ago; in network, over 10,000 times as large, and we spend far less effort per server than we used to while enjoying much better reliability from our service stack. Our tools have evolved from a collection of Python scripts, to integrated ecosystems of services, to a unified platform which offers reliability by default. And our understanding of the problems and failure modes of distributed systems also evolved, as we experienced new classes of outages. We created the <a href="https://sre.google/sre-book/accelerating-sre-on-call/" title="Wheel of Misfortune">Wheel of Misfortune</a>, we wrote <a href="https://sre.google/sre-book/service-best-practices/" title="Service Best Practices guides">Service Best Practices guides</a>, we published Google's Greatest Hits, and today are delighted to present:</p>
<p>Lessons learned from two decades of Site Reliability Engineering</p>
<p>Let's start back in 2016, when YouTube was offering your favorite videos such as "Carpool Karaoke with Adele" and the ever-catchy "Pen-Pineapple-Apple-Pen." YouTube experienced a fifteen-minute global outage, due to a bug in YouTube's distributed memory caching system, disrupting YouTube's ability to serve videos. Here are three lessons we learned from this incident.</p>
          <div>
            <h2>1</h2>
            <p>The riskiness of a mitigation should scale with the severity of the outage</p>
          </div>
          <p>There's a meme where one person posts a picture of a spider seen in their house, and the captain says, "TIME 2 MOVE 2 A NEW HOUSE!". The joke is that the incident (seeing a scary spider) would be responded to with a severe mitigation (abandon your current home and move to a new one). We, here in SRE, have had some interesting experiences in choosing a mitigation with more risks than the outage it's meant to resolve. During the aforementioned YouTube outage, a risky load-shedding process didn't fix the outage... it instead created a cascading failure.</p>
<p>We learned the hard way that during an incident, we should monitor and evaluate the severity of the situation and choose a mitigation path whose riskiness is appropriate for that severity. In a best case scenario, a risky mitigation resolves an outage. In a worst case scenario, the risky mitigation misfires and the outage is prolonged by something that was intended to fix it. Additionally, if everything is broken, you can make an informed decision to bypass standard procedures.</p>
          <div>
            <h2>2</h2>
            <p>Recovery mechanisms should be fully tested before an emergency</p>
          </div>
          <p>An emergency fire evacuation in a tall city building is a terrible opportunity to use a ladder for the first time. Similarly, an outage is a terrible opportunity to try a risky load-shedding process for the first time. To keep your cool during a high-risk and high-stress situation, it's important to practice recovery mechanisms and mitigations beforehand and verify that:</p>
<ul>
<li>they'll do what you need them to do</li>
<li>you know how to do them</li>
</ul>
<p>Testing recovery mechanisms has a fun side effect of reducing the risk of performing some of these actions. Since this messy outage, we've doubled down on testing.</p>
          
          <p>At one point, we wanted to push a caching configuration change. We were pretty sure that it would not lead to anything bad. But pretty sure is not 100% sure. Turns out, caching was a pretty critical feature for YouTube, and the config change had some unintended consequences that fully hobbled the service for 13 minutes. Had we <a href="https://sre.google/workbook/canarying-releases/" title="canaried those global changes">canaried those global changes</a> with a progressive rollout strategy, this outage could have been curbed before it had global impact. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/24017e52c907294589604a29a86f158828eda078.pdf" rel="noopener noreferrer" target="_blank" title="Read more">Read more about the canary strategy in this paper</a>, and <a href="https://www.usenix.org/conference/srecon18europe/presentation/davidovic" rel="noopener noreferrer" target="_blank" title="learn more">learn more in this video</a>.</p>
<p>Around the same timeframe, YouTube's slightly younger sibling, Google Calendar, also experienced an outage which serves as the backdrop for the next two lessons.</p>
          <div>
            <h2>4</h2>
            <p>Have a "Big Red Button"</p>
          </div>
          <p>A "Big Red Button" is a unique but highly practical safety feature: it should kick off a simple, easy-to-trigger action that reverts whatever triggered the undesirable state to (ideally) shut down whatever's happening. "Big Red Buttons" come in many shapes and sizes—and it's important to identify what those big red buttons might be before you submit a potentially risky action. We once narrowly missed a major outage because the engineer who submitted the would-be-triggering change unplugged their desktop computer before the change could propagate. So when planning your major rollouts, consider What is my big red button? Ensure every service dependency has a "big red button" to exercise in an emergency. See <a href="https://www.oreilly.com/content/generic-mitigations/" rel="noopener noreferrer" target="_blank" title="Generic Mitigations">"Generic Mitigations"</a> for more!</p>
          <div>
            <h2>5</h2>
            <p>Unit tests alone are not enough - integration testing is also needed</p>
          </div>
          <p>Ahh.... unit tests. They verify that an individual component can perform the way we need it to. Unit tests have intentionally limited scope, and are super helpful, but they also don't fully replicate the runtime environment and productionized demands that might exist. For this reason, we are big advocates of integration testing! We can use integration tests to verify that jobs and tasks can perform a cold start. Will things work the way we want them to? Will components work together the way we want them too? Will these components successfully create the system we want them to? This lesson was learned during a Calendar outage in which our testing didn't follow the same path as real use, resulting in plenty of testing... that didn't help us assess how a change would perform in reality.</p>
<p>Shifting to an incident that happened in February 2017, we find our next two lessons.</p>
<p>First, unavailable OAuth tokens caused millions of users to be logged out of devices and services, and 32,000 OnHub and Google WiFi devices to perform a factory reset. Manual account recovery claims jumped by 10x because of failed logins. It took Google about 12 hours to fully recover from the outage.</p>
          <div>
            <h2>6</h2>
            <p>COMMUNICATION CHANNELS! AND BACKUP CHANNELS!! AND BACKUPS FOR THOSE BACKUP CHANNELS!!!</p>
          </div>
          <p>Yes, it was a bad time. You want to know what made it worse? Teams were expecting to be able to use Google Hangouts and Google Meet to manage the incident. But when 350M users were logged out of their devices and services... relying on these Google services was, in retrospect, kind of a bad call. Ensure that you have non-dependent backup communication channels, and that you have tested them.</p>
<p>Then, the same 2017 incident led us to better understand <a href="https://sre.google/sre-book/addressing-cascading-failures/#:~:text=Graceful%20degradation%20takes%20the%20concept,decreasing%20the%20quality%20of%20responses." title="graceful degradation">graceful degradation:</a></p>
          <div>
            <h2>7</h2>
            <p>Intentionally degrade performance modes</p>
          </div>
          <p>It's easy to think of availability as either "fully up" or "fully down" ... but being able to offer a continuous minimum functionality with a degraded performance mode helps to offer a more consistent user experience. So we've built degraded performance modes carefully and intentionally—so during rough patches, it might not even be user-visible (it might be happening right now!). Services should degrade gracefully and continue to function under exceptional circumstances.</p>
<p>This next lesson is a recommendation to ensure that your last-line-of-defense system works as expected in extreme scenarios, such as natural disasters or cyber attacks, that result in loss of productivity or service availability.</p>
          <div>
            <h2>8</h2>
            <p>Test for Disaster resilience</p>
          </div>
          <p>Besides unit testing and integration testing, there are other types of very important testing: disaster resilience and recovery testing. While resilience testing verifies that your service or system could survive in the event of faults, latency, or disruptions, recovery testing verifies that your service can transition back to homeostasis after a full shutdown. Both should be critical pieces of your business continuity strategy—as described in <a href="https://queue.acm.org/detail.cfm?id=2371516" rel="noopener noreferrer" target="_blank" title="Weathering the Unexpected">"Weathering the Unexpected"</a>. A useful activity can also be sitting your team down and working through how some of these scenarios could theoretically play out—tabletop game style. This can also be a fun opportunity to explore those terrifying "What Ifs", for example, "What if part of your network connectivity gets shut down unexpectedly?".</p>
          <div>
            <h2>9</h2>
            <p>Automate your mitigations</p>
          </div>
          <p>In March of 2023, a near-simultaneous failure of multiple networking devices occurred in a few datacenters, resulting in a widespread packet loss. In this 6-day outage, an estimated 70% of services experienced varied levels of impact, depending on the location, service load, and configuration at the time of network failure.</p>
<p>In such instances, you can reduce your mean time to resolution (MTTR), by automating mitigating measures done by hand. If there's a clear signal that a particular failure is occurring, then why can't that mitigation be kicked off in an automated way? Sometimes it is better to use an automated mitigation first and save the root-causing for after user impact has been avoided.</p>
          <div>
            <h2>10</h2>
            <p>Reduce the time between rollouts, to decrease the likelihood of the rollout going wrong</p>
          </div>
          <p>In March of 2022, a widespread outage in the payments system prevented customers from completing transactions, resulting in the Pokémon GO community day being postponed. The cause was the removal of a single database field, which should have been safe as all uses of that field were removed from the code beforehand. Unfortunately, a slow rollout cadence of one part of the system meant that the field was still being used by the live system.</p>
<p>Having long delays between rollouts, especially in complex, multiple component systems, makes it extremely difficult to reason out the safety of a particular change. <a href="https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance" rel="noopener noreferrer" target="_blank" title="Frequent rollouts">Frequent rollouts</a>—with the proper testing in place— lead to fewer surprises from this class of failure.</p>
          <div>
            <h2>11</h2>
            <p>A single global hardware version is a single point of failure</p>
          </div>
          <p>Having only one particular model of device to perform a critical function can make for simpler operations and maintenance. However, it means that if that model turns out to have a problem, that critical function is no longer being performed.</p>
<p>This happened in March 2020 when a networking device that had an undiscovered zero-day bug, encountered a change in traffic patterns that triggered that bug. As the same model and version of the device was being used across the network, a substantial regional outage ensued. What prevented this from being a total outage was the presence of multiple network backbones that allowed high-priority traffic to be routed via a still working alternative.</p>
<p>Latent bugs in critical infrastructure can lurk undetected until a seemingly innocuous event triggers them. Maintaining a diverse infrastructure, while incurring costs of its own, can mean the difference between a troublesome outage and a total one.</p>
        <p>So there you have it! Eleven lessons learned, from two decades of Site Reliability Engineering at Google. Why eleven? Well, you see, Google Site Reliability, with our rich history, is still in our <span>prime</span>.</p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why you should probably be using SQLite (308 pts)]]></title>
            <link>https://www.epicweb.dev/why-you-should-probably-be-using-sqlite</link>
            <guid>38036921</guid>
            <pubDate>Fri, 27 Oct 2023 10:51:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.epicweb.dev/why-you-should-probably-be-using-sqlite">https://www.epicweb.dev/why-you-should-probably-be-using-sqlite</a>, See on <a href="https://news.ycombinator.com/item?id=38036921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Where you store your application data has enormous impacts on your entire application. There are implications on the entire stack based on what you decide to use here.</p>
<p>There are terrific solutions like MySQL and Postgres that have become the default for many people. These are fine solutions. But for most web app use cases, you could drastically simplify your life by using SQLite.</p>
<p>SQLite is a sql-based database with a particularly unique feature: the entire database is in a single file. Largely for this reason, many people have historically seen it as a simple database for simple use cases.</p>
<p>However, in recent years SQLite has received a great deal of development and attention making it a simple database for even more advanced use cases. Let’s talk about some of those advancements and why for most of us, SQLite is the best balance of trade-offs.</p>
<h2 id="zero-latency">Zero Latency</h2>
<p>The fact that SQLite is a single file on disk comes with a major benefit of 0 latency which&nbsp;<a href="https://www.sqlite.org/np1queryprob.html">drastically reduces the "n+1 problem."</a> This means that as a developer you don’t have to spend so much time worrying about reducing the number of queries you’re making to the database (which can lead to less efficient queries and certainly less efficient developers).</p>
<p>And latency itself is not to be underestimated. If you’re not thoughtful about the distance between your database and your application, you can easily put a baseline on your application’s performance. It’s not uncommon for the app-to-database latency to be measured in the tens of milliseconds (and sometimes even hundreds). This means no matter what you do, your page can’t load with fresh data in less than that amount of time.</p>
<p>I know performance isn’t the number 1 priority of all apps, but it’s pretty important for most. I’m  pretty sure even though the business executive who paid for your app and doesn’t have alternatives doesn’t like loading spinners flashing in their face for every interaction. 🌀😠</p>
<h2 id="one-less-service">One Less Service</h2>
<p>One huge benefit to SQLite is the fact that it runs as an embedded part of your application. So that’s one less service to babysit. Honestly, that was my primary motivation when I decided to migrate my own website from Postgres to SQLite. I just stick SQLite in the same volume I’m mounting for other data for my application already and I’m off the races.</p>
<p>This saves on complexity as well as cost.</p>
<p>And this is multiplied by the number of instances and replication considerations, but we’re getting ahead of ourselves… Let’s get into that…</p>
<h2 id="multi-instance-replication">Multi-instance replication</h2>
<p>As a file on disk, you cannot "distribute" SQLite directly. However, this is where there have been advancements in this space. For my own applications that need multiple instances, I use&nbsp;<a href="https://fly.io/docs/litefs">LiteFS</a>:</p>
<blockquote>
<p>LiteFS is a distributed file system that transparently replicates SQLite databases. You can run your application like it’s running against a local on-disk SQLite database but behind the scenes the database is replicated to all the nodes in your cluster. With LiteFS, you can run your database right next to your application on the edge. You can run LiteFS anywhere!</p>
</blockquote>
<p>On top of this, LiteFS has built-in support to handle the "Read Replica Consistency" challenge. So if you need your app to run in multiple instances, you need to use one of these tools.</p>
<p>Another solution here is <a href="https://turso.tech/">Turso</a> which uses SQLite under the hood and even has a concept called "embedded replicas" for zero latency reads. Very cool!</p>
<h2 id="database-size">Database size</h2>
<p>Another issue people sometimes bring up is database size. However,&nbsp;<a href="https://sqlite.org/hctree/doc/hctree/doc/hctree/index.html">SQLite is capable of handling databases that are an Exabyte in size</a>&nbsp;(that's one million Terabytes, or one billion Gigabytes 🤯). Most of us web developers don’t work with near that amount of data. You’ll have much different problems before database size is one of them with SQLite.</p>
<p>Even putting large amounts of data in a SQLite database record is pretty efficient! In fact, in some cases, <a href="https://www.sqlite.org/fasterthanfs.html">it can be faster</a> to retrieve data out of a SQLite database than from the file system 😆&nbsp;SQLite is an incredible feat of engineering!</p>
<h2 id="development-and-testing">Development and Testing</h2>
<p>I know some of you reading this right now are perfectly comfortable running <code>docker compose</code> as a regular part of your workflow before you start developing your application. But you have to admit that it’s annoying to run multiple apps at once with conflicting databases and ports. With SQLite, it’s a total non-issue. It’s just a file. So you can run multiple instances of the same app at once with no trouble whatsoever.</p>
<p>Also, while starting up a new Postgres database is fairly involved (there are of course tools that make it easier), SQLite has no such issue. Again, it’s just a file. Run your production migrations/seed and you’re good to go.</p>
<p>And this ease carries over to the testing side of things as well. When your database setup is complicated, you end up spending time evaluating ways to mock out your database at the ORM level so you can avoid having to run and connect to your database during testing and the isolation issues that can happen as a result of that.</p>
<p>Not a problem with SQLite. It’s just a file! Each test can have its own database with barely a thought. Just a little bit of code to create and connect the database and then your tests can run on the full database. You can definitely do this with other databases, but not as easily and efficiently as SQLite.</p>
<h2 id="weaknesses">Weaknesses</h2>
<p>SQLite is not without its shortcomings. And it would be unfair of me to just talk about where SQLite shines without addressing some of those.</p>
<ul>
<li>SQLite does not support subscriptions which can be a limitation on certain real-time use cases. However, there are plenty of reasons to recommend against using database subscriptions for real-time use cases anyway. Scaling real-time use cases is quite challenging, and personally have really enjoyed letting <a href="https://www.partykit.io/">Partykit</a> do that part for me in my apps.</li>
<li>SQLite being a file on disk does make connecting from external clients effectively impossible. But with <a href="http://fly.io/">Fly.io</a> at least, it’s easy to run prisma studio on the production server and proxy that for local access. If you need to connect to it from another app, then you’re out of luck and have to set up HTTP endpoints on the host app for any data you need (<a href="https://github.com/superfly/litefs/issues/326">for now</a>).</li>
<li>SQLite does not support plugins like&nbsp;<a href="https://github.com/timescale/timescaledb">TimescaleDB</a>&nbsp;for Postgres. While time-series data is possible with SQLite, I do not have experience with this use case and can't speak to the challenges there. My intuition says it's not advisable to use SQLite for that use case, but maybe someone else can offer me more insight.</li>
<li>SQLite does not support enums which means you're forced to use strings. I have mixed feelings about this, but I mostly don't like enums anyway. The main drawback to this is when it comes to the typings for the client which doesn't allow you to ensure all values of a column are only within a set of specific possible values for the string. However, with Prisma client extensions, handling this kind of enforcement at the client (and typing) level <a href="https://github.com/L-Steinmacher/epic-stack-with-prisma-client-extensions">is possible</a>.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>So, can <em>you</em> use SQLite? For the vast majority of you reading this, the answer is “yes.” Should you use SQLite? I’d say that still for the majority of you reading this, the answer is also “yes.” Though it’s complicated. As with everything in technology, there are multiple solutions that will work out. But I think you should give SQLite a serious look due to the performance, simplification, and cost benefits I’ve mentioned.</p>
<p>And that’s why I’m using SQLite for my own applications and why I teach you to use SQLite in the <a href="http://epicweb.dev/">EpicWeb.dev</a> series of workshops.</p>
<p>– Kent</p></div><section id="article"><div><p>Stay up to date</p><p>Subscribe to the newsletter to stay up to date with articles, courses and much more!</p></div><p>I respect your privacy. Unsubscribe at any time.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[0 To 100 kph in 1 second [video] (125 pts)]]></title>
            <link>https://www.youtube.com/watch?v=XQIu5tZ0vbQ</link>
            <guid>38036801</guid>
            <pubDate>Fri, 27 Oct 2023 10:30:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=XQIu5tZ0vbQ">https://www.youtube.com/watch?v=XQIu5tZ0vbQ</a>, See on <a href="https://news.ycombinator.com/item?id=38036801">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Lean4 helped Terence Tao discover a small bug in his recent paper (378 pts)]]></title>
            <link>https://mathstodon.xyz/@tao/111287749336059662</link>
            <guid>38035672</guid>
            <pubDate>Fri, 27 Oct 2023 07:25:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathstodon.xyz/@tao/111287749336059662">https://mathstodon.xyz/@tao/111287749336059662</a>, See on <a href="https://news.ycombinator.com/item?id=38035672">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Let me tell you about me Gear Fabrication Syndrome (157 pts)]]></title>
            <link>https://weenoisemaker.com/blog/2023/10/21/gear-fabrication-syndrome.html</link>
            <guid>38035516</guid>
            <pubDate>Fri, 27 Oct 2023 07:00:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weenoisemaker.com/blog/2023/10/21/gear-fabrication-syndrome.html">https://weenoisemaker.com/blog/2023/10/21/gear-fabrication-syndrome.html</a>, See on <a href="https://news.ycombinator.com/item?id=38035516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <main id="site-main" aria-label="Content" tabindex="1">
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If you are reading these lines, you may be familiar with the concept of Gear
Acquisition Syndrome (GAS). A person’s insatiable urge to buy equipment for
their art or hobby, distracting them from actually practicing said art or
hobby.</p>

<p>It’s driven in part by the belief that new gear will improve one’s art or
performance, e.g. I don’t sound like Jimi Hendrix because I don’t have the same
effects pedal he used. Or the instant gratification of acquiring and
discovering new shiny equipment, in contrast to the stressing and frustrating
creation process.</p>

<p>Because of my background and education, the “guilt” of spending money on
frivolous equipment will, most of the time, allow me to overcome my Gear
Acquisition Syndrome. But I developed another mechanism: Gear Fabrication
Syndrome (GFS).</p>

<h2 id="let-me-tell-you-the-most-recent-example">Let me tell you the most recent example:</h2>

<p>A few months ago, I was introduced to the wonderful world of <a href="https://en.wikipedia.org/wiki/Sim_racing">sim
racing</a>. As teenagers my brothers and
I used to play car racing video games, but I didn’t know how advanced the field
is today. So I started to look into it, watched videos on YouTube, dug up the
old force feedback wheel controller from our parent’s attic, bought a game,
etc.</p>

<p>Sim racing tutorials will often explain how braking is the most important skill
to drive fast. And to break with consistency and precision you need a so-called
“load cell pedal”. Unlike the cheap pedal I am using, a load cell pedal
measures the pressure you are putting on the pedal and not the distance your
foot moves. That’s way closer to how real car brakes operate (pression in a
hydraulic system).</p>

<p>For sure, the reason I am not going as fast as the other drivers online is
because of my cheap brake pedal! Enter the Gear Acquisition Syndrome!</p>

<p>Entry level load cell pedals are not extremely expensive, I can afford it. But
they are not cheap either, am I wasting money here? Trying to reconcile my urge
to get new gear and my fear of wasting money, I looked for an escape. Quick
online search for DIY sim racing pedals reveals a lot of <a href="https://www.youtube.com/watch?app=desktop&amp;v=C7pNnQlq8ro">different
designs</a>. For sure, I
can make one! Enter the Gear Fabrication Syndrome.</p>

<p>Cost saving is not always the motivation, one can try to make better gear than
what is available off the shelf, or just more adapted to personal taste. That’s
why I could also tell you about all the guitars,
<a href="https://fireverb.wordpress.com/2015/03/14/the-fireverb/">amplifiers</a> and
<a href="https://fireverb.wordpress.com/2015/03/14/leslievibratone-cabinet/">effects</a> I
made instead of practicing the instrument. Or my 6 years and going <a href="https://weenoisemaker.com/blog/2022/11/21/welcome.html">pocket
synthesizer project</a>.</p>

<p><img src="https://weenoisemaker.com/assets/fireverb_internals.jpg" alt="" width="60%"></p>

<h2 id="is-gfs-better-than-gas">Is GFS better than GAS?</h2>

<p>That’s hard to tell. The cost effectiveness is often hard to reach, in
particular if you factor in the cost of tools. Not to mention a failed DIY
project will lead you to end up buying the off the shelf gear, making things
way worse in the end.</p>

<p>Software developers are familiar with this credo:</p>

<div><pre><code>We do these things not because they are easy, but because we thought they were
going to be easy.
</code></pre></div>

<p>It’s also time consuming, and the time spent on making gear is of course not
available for practicing art/hobby.</p>

<p>On the other hand GFS can become a deeply rewarding part of your journey,
allowing you to shape and personalize your tools in a way that GAS never can.
You can learn a lot from it, and in the end, designing and making can become
your main art/hobby.</p>

<h2 id="gfs-ambassadors">GFS Ambassadors</h2>

<p>There are many individuals online that seem to exhibit signs of Gear
Fabrication Syndrome. I picked two.</p>

<p>Let’s start with Adam Savage. Watching the Tested YouTube channel, it’s clear
that Adam loves gear and tools. You can tell by this <a href="https://www.youtube.com/watch?v=7v8p0Bpbihw">8 minute video on hex
keys</a> for instance. He’s even
obsessed as some <a href="https://www.youtube.com/watch?v=SNc8y7d7Tic">video title will tell
you</a>. To me it’s pretty clear that
Adam shows signs for GAS. But what about GFS? Well Tested YouTube channel is
also <a href="https://www.youtube.com/playlist?list=PLJtitKU0CAej22ZWBqrimPkn0Bbo6ci-r">full of
videos</a>
where Adam makes custom equipment for his shop, or movie prop replicas, or any
other kind of gear. Things that he could either buy or have someone make for
him.</p>

<p><a href="https://www.youtube.com/watch?v=MdjGxn97lgI"><img src="https://weenoisemaker.com/assets/adam_savage_tested_portable_soldering_station_rebuild_yt_thumbnail.jpg" alt="" width="60%"></a></p>

<p>The second one is Sam Battle, known online as <a href="https://www.lookmumnocomputer.com/">Look Mum No
Computer</a>. Sam is a musician, performer,
videographer, inventor, and director of his own museum. I highly recommend
having a look at his <a href="https://www.youtube.com/c/LOOKMUMNOCOMPUTER/videos">YouTube
channel</a>.</p>

<p>Among many other things, Sam designed and built a big custom synthesizer called
Kosmo. Kosmo is tailored for live performance, rugged enough to sustain
transportation in a tour van, with big knobs and jacks so that Sam can use it
while singing and jumping around. Kosmo has become more than a tool, it’s a
musician on stage with Sam. You would never get that with off the shelf synths.</p>

<p><a href="https://www.youtube.com/watch?v=R1mliD9m1LM&amp;t=164s"><img src="https://weenoisemaker.com/assets/LMNC_kosmo.jpeg" alt="" width="60%"></a></p>

<h2 id="how-good-are-my-diy-pedals-in-the-end">How good are my DIY pedals in the end?</h2>

<p>Here’s what my DIY pedals look like so far:</p>

<p><img src="https://weenoisemaker.com/assets/DIY_sim_racing_pedals_oct2023.jpg" alt="" width="60%"></p>

<p>You are probably wondering if they allow me to drive faster in racing
simulators. Well, two months after the beginning of the project, they are still
not usable ^^ So this might be the topic for another post…</p>


  </div>

  

  
  
</article>

          
        </main>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to draw beautiful software architecture diagrams (2022) (272 pts)]]></title>
            <link>https://terrastruct.com/blog/post/draw-software-architecture-diagrams/</link>
            <guid>38035505</guid>
            <pubDate>Fri, 27 Oct 2023 06:57:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrastruct.com/blog/post/draw-software-architecture-diagrams/">https://terrastruct.com/blog/post/draw-software-architecture-diagrams/</a>, See on <a href="https://news.ycombinator.com/item?id=38035505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="n6rdy">Have you ever been in a meeting where a diagram is drawn, and when it ends, no one wants to erase the whiteboard? Instead, someone takes a picture of it on their phone, or they'll roll the whiteboard out to your team area and draw a big "DO NOT ERASE" sign. Over the next month, discussions gravitate around this diagram. People randomly walk up and stare at it. Questions are answered by pointing at it. Periodically throughout the day, chairs swivel around to face this centerpiece, their occupants folding their hands behind their heads.</p><p data-block-key="nh40">What defines a diagram like that? The content, of course, has to be correct: things have to exist at the right abstraction levels, it's up-to-date, there's no ambiguity, etc. But there are many ways to draw the same dozen entities and relationships. Some of those have staying power that clarify and spark collaboration for the entirety of a project, while others don't live past the end of the afternoon meeting.&nbsp;</p><p data-block-key="77ce8">Below are some properties of beautiful diagrams. I don't mean beautiful in the designer sense of drop shadows and rounded corners, but rather, functional beauty that maximizes its effectiveness to communicate ideas.</p><h2 data-block-key="78qli">Minimize neighbor distance</h2><p data-block-key="2kjdf">This is simple to get right for small diagrams, but much harder to do as they grow larger. If you just have two nodes connected to each other, obviously you draw them close to each other. But what if your diagram currently looks like this...</p><p><img alt="min_distance_1" height="697" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/min_distance_1.width-800.png" width="800"></p><p data-block-key="657t4">... and your next move is to draw that "engine" connects to more things. That's when this property starts eroding away.</p><p><img alt="min_distance_2" height="514" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/min_distance_2.width-800.png" width="800"></p><p data-block-key="8b58h">Instead, if you had planned ahead, or taken the time to redraw, you could've maintained the low distance between nodes.&nbsp;</p><p><img alt="min_distance_3" height="742" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/min_distance_3.width-800.png" width="800"></p><p data-block-key="a879d">If you were coding and realized a function you just wrote wasn't accounting for an edge case, you'd probably rewrite the relevant areas to account for it. Or in your written docs, if you realized you were missing an item in a list, you wouldn't write, "Oh and also this", you'd just go back and amend the original sentence! But when it comes to diagrams, it's an order of magnitude more time-consuming to erase and redraw than it is to backspace and retype. It's not worth the trouble in an interview context, but if you're drawing something for documentation-sake for multiple people -- maybe even multiple teams -- then the constant redraws will result in much more beautiful diagrams.</p><h2 data-block-key="3vh32">Find symmetry</h2><p data-block-key="2t8jm">Symmetry in diagrams is a big contributor to a pleasing perception of aesthetics. Our brains are subconsciously wired to favor visual symmetry (e.g. faces). Further, it helps us quickly make sense of diagrams.</p><p data-block-key="1t12v">In this example, all the nodes are maximally close to their neighbors.</p><p><img alt="symmetry_1" height="920" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/symmetry_1.width-800.png" width="800"></p><p data-block-key="beqv7">But it looks a little off, like a slightly askew painting. It's the lack of symmetry that stands out to us.&nbsp;</p><p><img alt="symmetrical" height="920" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/symmetry_2.width-800.png" width="800"></p><p data-block-key="c0t1m">This version looks more pleasing, even though "lb1" (bottom right) has increased in distance from its neighbors, and "cache" (middle left) identical distance to its neighbors as before.</p><p data-block-key="9he6r">Keeping things symmetrical can also enhance the meaning a diagram carries, like having all the inputs on one side, and all the outputs on the other.</p><p><img alt="symmetry_3" height="519" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/symmetry_3.width-800.png" width="800"></p><h2 data-block-key="enum5">Align centers</h2><p data-block-key="5l883">Alignment is the biggest contributor to diagrams looking neat, which you should care about because neat diagrams make concepts clearer, while messy diagrams make concepts more complex. A series of simple diagrams can make even the most complex systems understandable.</p><p data-block-key="4kvvo">It may not seem important how neat and aligned your handful of shapes are when you begin drawing a diagram, but nobody has ever thrown 50% of their clothes on the floor and folded the other 50%, or kept half their room neat or bed made. Starting off plopping shapes randomly on a blank canvas puts you on a road to random placements for the rest of the diagram. Alignment only has meaning <b>between</b> two or more shapes (i.e. something can't be aligned to itself). By maintaining the property for each new addition, you'll find your diagram looks neat ~effortlessly.</p><p data-block-key="3jen0">This property often comes from being symmetrical, but not always.</p><p><img alt="align_center_1" height="595" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/align_center_1.width-800.png" width="800"></p><hr><p><img alt="align_center_2" height="595" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/align_center_2.width-800.png" width="800"></p><h2 data-block-key="4t4mo">Use container groups</h2><p data-block-key="dcm8n">Distinguishing your diagram into multiple, labeled regions makes it much more understandable for viewers. Containers can</p><ul><li data-block-key="7u8qt">add context ("these services are in AWS and these are in Azure")</li><li data-block-key="3ofgg">show abstractions ("these are all implementations of ReaderWriter")</li><li data-block-key="euj5i">group related objects (cores 1, 2, 3, 4 in a "Cores" container)</li></ul><p><img alt="containers_1" height="802" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/containers_1.width-800.png" width="800"></p><p data-block-key="66u8r">Notice how adding containers makes the diagram much clearer</p><p><img alt="containers_2" height="802" src="https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/images/containers_2.width-800.png" width="800"></p><h2 data-block-key="dkm4v">To be continued</h2><p data-block-key="lua1">In part 2, we'll cover</p><ul><li data-block-key="7jdon">Drawing edge routes</li><li data-block-key="6qdp8">Label sizes and positions</li><li data-block-key="8948t">Colors</li><li data-block-key="1998e">Icons</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My 2023 all-flash ZFS NAS (Network Storage) build (111 pts)]]></title>
            <link>https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/</link>
            <guid>38034797</guid>
            <pubDate>Fri, 27 Oct 2023 04:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/">https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/</a>, See on <a href="https://news.ycombinator.com/item?id=38034797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  
  <details>
    <summary>Table of contents</summary>
    <nav>
  <ul>
    <li><a href="#design-goals">Design Goals</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#hardware">Hardware</a>
      <ul>
        <li><a href="#base-components">Base Components</a></li>
        <li><a href="#16-tb-ssd-data-disks">16 TB SSD Data Disks</a></li>
        <li><a href="#power-usage">Power Usage</a></li>
      </ul>
    </li>
    <li><a href="#operating-system">Operating System</a>
      <ul>
        <li><a href="#previously-coreos">Previously: CoreOS</a></li>
        <li><a href="#now-ubuntu-server">Now: Ubuntu Server</a></li>
        <li><a href="#maybe-later-gokrazy">Maybe later? gokrazy</a></li>
      </ul>
    </li>
    <li><a href="#setup">Setup</a>
      <ul>
        <li><a href="#uefi">UEFI</a></li>
        <li><a href="#operating-system-1">Operating System</a></li>
        <li><a href="#network">Network</a></li>
        <li><a href="#encrypted-zfs">Encrypted ZFS</a></li>
        <li><a href="#backup">Backup</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav>
  </details>
  <p>For over 10 years now, I run two self-built NAS (Network Storage) devices which serve media (currently via Jellyfin) and run daily backups of all my PCs and servers.</p>
<p>In this article, I describe my goals, which hardware I picked for my new build (and why) and how I set it up.</p>
<h2 id="design-goals">Design Goals</h2>
<p>I use my network storage devices primarily for archival (daily backups), and secondarily as a media server.</p>
<p>There are days when I don’t consume any media (TV series and movies) from my NAS, because I have my music collection mirrored to another server that’s running 24/7 anyway. In total, my NAS runs for a few hours in some evenings, and for about an hour (daily backups) in the mornings.</p>
<p>This usage pattern is distinctly different than, for example, running a NAS as a file server for collaborative video editing that needs to be available 24/7.</p>
<p>The goals of my NAS setup are:</p>
<ol>
<li>Save power: each NAS build only runs when needed.
<ul>
<li>They must support Wake-on-LAN or <a href="https://michael.stapelberg.ch/posts/2022-10-09-remote-power-button/">similar (ESP32 remote power button)</a>.</li>
<li>Scheduling of backups is done separately, on a Raspberry Pi with <a href="https://gokrazy.org/">gokrazy</a>.</li>
<li>Convenient <a href="https://github.com/stapelberg/regelwerk/commit/8b81d7a808b1d76a0e96bdb4ab43964623d133c4">power off (tied to our all-lights-out button)</a> and power on (with <a href="https://github.com/stapelberg/zkj-nas-tools/blob/master/webwake/webwake.go">webwake</a>).</li>
</ul>
</li>
<li>Use Off-the-shelf hardware and software.
<ul>
<li>When hardware breaks, I can get replacements from the local PC store the same day.</li>
<li>Even when only the data disk(s) survive, I should be able to access my data when booting a standard live Linux system.</li>
<li>Minimal application software risk: I want to minimize risk for manual screw-ups or software bugs, meaning I use the venerable rsync for my backup needs (not Borg, restic, or similar).</li>
<li>Minimal system software risk: I use reliable file systems with the minimal feature set — no LVM or btrfs snapshots, no ZFS replication, etc. To achieve redundancy, I don’t use a cluster file system with replication, instead I synchronize my two NAS builds using rsync, without the <code>--delete</code> flag.</li>
</ul>
</li>
<li>Minimal failure domains: when one NAS fails, the other one keeps working.
<ul>
<li>Having N+1 redundancy here takes the stress out of repairing your NAS.</li>
<li>I run each NAS in a separate room, so that accidents like fires or spilled drinks only affect one machine.</li>
</ul>
</li>
</ol>
<h4 id="file-system-zfs">File System: ZFS</h4>
<p>In this specific build, I am trying out <a href="https://en.wikipedia.org/wiki/ZFS">ZFS</a>. Because I have two NAS builds
running, it is easy to change one variable of the system (which file system to
use) in one build, without affecting the other build.</p>
<p>My main motivation for using ZFS instead of <a href="https://en.wikipedia.org/wiki/Ext4"><code>ext4</code></a> is that ZFS does data checksumming, whereas ext4 only checksums metadata and the journal, but not data at rest. With large enough datasets, the chance of bit flips increases significantly, and I would prefer to know about them so that I can restore the affected files from another copy.</p>
<h2 id="hardware">Hardware</h2>
<p>Each of the two storage builds has (almost) the same components. This makes it easy to diagnose one with the help of the other. When needed, I can swap out components of the second build to temporarily repair the first one, or vice versa.</p>















<p><a href="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/IMG_1974.jpg"><img srcset="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/IMG_1974_hubee9c905cc3b7237e7c96518cbb38b46_1156723_1200x0_resize_q75_box.jpg 2x,https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/IMG_1974_hubee9c905cc3b7237e7c96518cbb38b46_1156723_1800x0_resize_q75_box.jpg 3x" src="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/IMG_1974_hubee9c905cc3b7237e7c96518cbb38b46_1156723_600x0_resize_q75_box.jpg" alt="photo of the Network Storage PC from the side, showing the Noctua case fan and CPU cooler, data disks, PSU and cables" title="photo of the Network Storage PC from the side, showing the Noctua case fan and CPU cooler, data disks, PSU and cables" width="600" height="450" loading="lazy"></a></p><h3 id="base-components">Base Components</h3>
<table>
<thead>
<tr>
<th>Price</th>
<th>Type</th>
<th>Article</th>
<th>Remark</th>
</tr>
</thead>
<tbody>
<tr>
<td>114 CHF</td>
<td>mainboard</td>
<td><a href="https://www.digitec.ch/en/s1/product/asrock-b450-gaming-itxac-am4-amd-b450-mini-itx-motherboards-9385702">AsRock B450 Gaming ITX/ac</a></td>
<td>Mini ITX</td>
</tr>
<tr>
<td>80 CHF</td>
<td>cpu</td>
<td><a href="https://www.heise.de/preisvergleich/amd-athlon-3000g-yd3000c6m2ofh-yd3000c6fhmpk-a2174924.html?hloc=at&amp;hloc=de">AMD Athlon 3000G</a></td>
<td>35W TDP, GPU</td>
</tr>
<tr>
<td>65 CHF</td>
<td>cpu cooler</td>
<td><a href="https://www.digitec.ch/de/s1/product/noctua-nh-l12s-70-mm-cpu-kuehler-6817433">Noctua NH-L12S</a></td>
<td>silent!</td>
</tr>
<tr>
<td>58 CHF</td>
<td>power supply</td>
<td><a href="https://www.digitec.ch/en/s1/product/silverstone-power-supply-st30sf-300w-sfx-300-w-power-supply-pc-5988297">Silverstone ST30SF 300W SFX</a></td>
<td>SFX form factor</td>
</tr>
<tr>
<td>51 CHF</td>
<td>case</td>
<td><a href="https://www.digitec.ch/en/s1/product/silverstone-sst-sg05bb-lite-mini-itx-mini-dtx-pc-case-3525365">Silverstone SST-SG05BB-Lite</a></td>
<td>Mini ITX</td>
</tr>
<tr>
<td>48 CHF</td>
<td>system disk</td>
<td><a href="https://www.digitec.ch/en/s1/product/wd-red-sn700-250-gb-m2-2280-ssd-17688689">WD Red SN700 250GB</a></td>
<td>M.2 NVMe</td>
</tr>
<tr>
<td>32 CHF</td>
<td>case fan</td>
<td><a href="https://www.digitec.ch/en/s1/product/noctua-nf-s12a-uln-120mm-1x-pc-fans-2451401">Noctua NF-S12A ULN</a></td>
<td>silent 120mm</td>
</tr>
<tr>
<td>28 CHF</td>
<td>ram</td>
<td><a href="https://www.digitec.ch/en/s1/product/gskill-value-1-x-8gb-2400-mhz-ddr4-ram-dimm-ram-11056524">8 GB DDR4 Value RAM (F4-2400C15-8GNT)</a></td>
<td></td>
</tr>
</tbody>
</table>
<p>The total price of 476 CHF makes this not a cheap build.</p>
<p>But, I think each component is well worth its price. Here’s my thinking regarding the components:</p>
<ul>
<li>Why not a cheaper <strong>system disk</strong>? I wanted to use an M.2 NVMe disk so that I could mount it on the bottom of the mainboard instead of having to mount another SATA disk in the already-crowded case. Instead of chosing the cheapest M.2 disk I could find, I went with WD Red as a brand I recognize. While it’s not a lot of effort to re-install the system disk, it’s still annoying and something I want to avoid if possible. If spending 20 bucks saves me one disk swap + re-install, that’s well worth it for me!</li>
<li>Why not skip the <strong>system disk</strong> entirely and install on the data disks? That makes the system harder to (re-)install, and easier to make manual errors when recovering the system. I like to physically disconnect the data disks while re-installing a NAS, for example. (I’m a fan of simple precautions that prevent drastic mistakes!)</li>
<li>Why not a cheaper <strong>CPU cooler</strong>? In <a href="https://michael.stapelberg.ch/posts/2019-10-23-nas/">one of my earlier NAS builds</a>, I used a (cheaper) passive CPU fan, which was directly in the air stream of the Noctua 120mm case fan. This setup was spec’ed for the CPU I used, and yet said CPU died as the only CPU to die on me in many many years. I want a reliable CPU fan, but also an absolutely silent build, so I went with the Noctua CPU cooler.</li>
<li>Why not skip the <strong>case fan</strong>, or go with the Silverstone-supplied one? You might argue that the airflow of the CPU cooler is sufficient for this entire build. Maybe that’s true, but I don’t want to risk it. Also, there are 3 disks (two data disks and one system disk) that can benefit from additional airflow.</li>
<li>Regarding the <strong>CPU</strong>, I chose the cheapest AMD CPU for Socket AM4, with a 35W TDP and built-in graphics. The built-in graphics means I can connect an HDMI monitor for setup and troubleshooting, without having to use the mainboard’s valuable one and only PCIe slot.
<p>

Unfortunately, AMD CPUs with 35W TDP are not readily available right now. My tip is to look around for a bit, and maybe buy a used one. Chose either the predecessor Athlon 200GE, or the newer generation Ryzen APU series, whichever you can get your hands on.</p></li>
<li>Regarding the <strong>mainboard</strong>, I went with the AsRock Mini ITX series, which have served me well over the years. I started with an <a href="https://www.asrock.com/mb/AMD/AM1H-itx/">AsRock AM1H-ITX</a> in 2016, then bought two <a href="https://www.digitec.ch/en/s1/product/asrock-ab350-gaming-itxac-am4-amd-b350-mini-itx-motherboards-7022839">AsRock AB350 Gaming ITX/ac</a> in 2019, and recently an <a href="https://www.digitec.ch/en/s1/product/asrock-b450-gaming-itxac-am4-amd-b450-mini-itx-motherboards-9385702">AsRock B450 Gaming ITX/ac</a>.</li>
</ul>
<p>As a disclaimer: the two builds I use are <em>very similar</em> to the component list above, with the following differences:</p>
<ol>
<li>On storage2, I use an old AMD Ryzen 5 5600X CPU instead of the listed Athlon 3000G. The extra performance isn’t needed, and the lack of integrated graphics is annoying. But, I had the CPU lying around and didn’t want it to go to waste.</li>
<li>On storage3, I use an old AMD Athlon 200GE CPU on an <a href="https://www.digitec.ch/en/s1/product/asrock-ab350-gaming-itxac-am4-amd-b350-mini-itx-motherboards-7022839">AsRock AB350</a> mainboard.</li>
</ol>
<p>I didn’t describe the <em>exact</em> builds I use because a component list is more useful if the components on it are actually available :-).</p>
<h3 id="16-tb-ssd-data-disks">16 TB SSD Data Disks</h3>
<p>It used to be that Solid State Drives (SSDs) were just way too expensive compared to spinning hard disks when talking about terabyte sizes, so I used to put the largest single disk drive I could find into each NAS build: I started with 8 TB disks, then upgraded to 16 TB disks later.</p>
<p>Luckily, the price of flash storage has come down quite a bit: the <a href="https://www.digitec.ch/en/s1/product/samsung-870-qvo-8000-gb-25-ssd-13388185">Samsung SSD 870 QVO (8 TB)</a> costs “only” 42 CHF per TB. For a total of 658 CHF, I can get 16 TB of flash storage in 2 drives:</p>















<p><a href="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-22-samsung-870qvo-featured.jpg"><img srcset="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-22-samsung-870qvo-featured_hu799c805b17c89c62874113693200acea_520811_1200x0_resize_q75_box.jpg 2x,https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-22-samsung-870qvo-featured_hu799c805b17c89c62874113693200acea_520811_1800x0_resize_q75_box.jpg 3x" src="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-22-samsung-870qvo-featured_hu799c805b17c89c62874113693200acea_520811_600x0_resize_q75_box.jpg" alt="two samsung 870 QVO disks" title="two samsung 870 QVO disks" width="600" height="338" loading="lazy"></a></p><p>Of course, spinning hard disks are at 16 CHF per TB, so going all-flash is over 3x as expensive.</p>
<p>I decided to pay the premium to get a number of benefits:</p>
<ul>
<li>My NAS devices are quieter because there are no more spinning disks in them. This gives me more flexibility in where to physically locate each storage machine.</li>
<li>My daily backups run quicker, meaning each NAS needs to be powered on for less time. The effect was actually quite pronounced, because figuring out which files need backing up requires a lot of random disk access. My backups used to take about 1 hour, and now finish in less than 20 minutes.</li>
<li>The quick access times of SSDs solve the last remaining wrinkle in my backup scheme: deleting backups and measuring used disk space is finally fast!</li>
</ul>
<h3 id="power-usage">Power Usage</h3>
<p>The choice of CPU, Mainboard and Network Card all influence the total power usage of the system. Here are a couple of measurements to give you a rough idea of the power usage:</p>
<table>
<thead>
<tr>
<th>build</th>
<th>CPU</th>
<th>main board</th>
<th>network card</th>
<th>idle</th>
<th>load</th>
</tr>
</thead>
<tbody>
<tr>
<td>s2</td>
<td>5600X</td>
<td><a href="https://www.digitec.ch/en/s1/product/asrock-b450-gaming-itxac-am4-amd-b450-mini-itx-motherboards-9385702">B450</a></td>
<td>10G: Mellanox ConnectX-3</td>
<td>26W</td>
<td>60W</td>
</tr>
<tr>
<td>s3</td>
<td>200GE</td>
<td><a href="https://www.digitec.ch/en/s1/product/asrock-ab350-gaming-itxac-am4-amd-b350-mini-itx-motherboards-7022839">AB350</a></td>
<td>10G: <a href="https://www.fs.com/products/135978.html">FS Intel 82599</a></td>
<td>28W</td>
<td>50W</td>
</tr>
<tr>
<td>s3</td>
<td>200GE</td>
<td><a href="https://www.digitec.ch/en/s1/product/asrock-ab350-gaming-itxac-am4-amd-b350-mini-itx-motherboards-7022839">AB350</a></td>
<td>1G onboard</td>
<td>23W</td>
<td>40W</td>
</tr>
</tbody>
</table>
<p>These values were measured using a <a href="https://mystrom.ch/de/wifi-switch/">myStrom WiFi Switch</a>.</p>
<h2 id="operating-system">Operating System</h2>
<h3 id="previously-coreos">Previously: CoreOS</h3>
<p>Before this build, I ran my NAS using Docker containers on <a href="https://en.wikipedia.org/wiki/Container_Linux">CoreOS (later renamed to Container Linux)</a>, which was a light-weight Linux distribution focused on containers. There are two parts about CoreOS that I liked most.</p>
<p>The most important part was that CoreOS updated automatically, using an A/B updating scheme, just like I do in <a href="https://gokrazy.org/">gokrazy</a>. I want to run as many of my devices as possible with A/B updates.</p>
<p>The other bit I like is that the configuration is very clearly separated from the OS. I managed the configuration (a <a href="https://cloud-init.io/">cloud-init YAML file</a>) on my main PC, so when swapping out the NAS system disk with a blank disk, I could just plug my config file into the CoreOS installer, and be done.</p>
<p>When CoreOS was bought by Red Hat and merged into Project Atomic, there wasn’t a good migration path and cloud-init wasn’t supported anymore. As a short-term solution, I switched from CoreOS to Flatcar Linux, a spiritual successor.</p>
<h3 id="now-ubuntu-server">Now: Ubuntu Server</h3>
<p>For this build, I wanted to try out ZFS. I always got the impression that ZFS was a pain to run because its kernel modules are not included in the upstream Linux kernel source.</p>
<p>Then, in 2016, Ubuntu decided to include ZFS by default. There are a couple of other Linux distributions on which ZFS seems easy enough to run, like Gentoo, Arch Linux or NixOS.</p>
<p>I wanted to spend my “innovation tokens” on ZFS, and keep the rest boring and similar to what I already know and work with, so I chose Ubuntu Server over NixOS. It’s similar enough to Debian that I don’t need to re-learn.</p>
<p>Luckily, the migration path from Flatcar’s cloud-init config to Ubuntu Server is really easy: just copy over parts of the cloud-config until you’re through the entire thing. It’s like a checklist!</p>
<h3 id="maybe-later-gokrazy">Maybe later? gokrazy</h3>
<p>In the future, it might be interesting to build a NAS setup using <a href="https://gokrazy.org/">gokrazy</a>. In particular since we now can <a href="https://gokrazy.org/packages/docker-containers/">run Docker containers on gokrazy</a>, which makes running Samba or Jellyfin quite easy!</p>
<p>Using gokrazy instead of Ubuntu Server would get rid of a lot of moving parts. The current blocker is that ZFS is not available on gokrazy. Unfortunately that’s not easy to change, in particular also from a licensing perspective.</p>
<h2 id="setup">Setup</h2>
<h3 id="uefi">UEFI</h3>
<p>I changed the following UEFI settings:</p>
<ul>
<li>
<p>Advanced → ACPI Configuration → PCIE Devices Power On: Enabled</p>
<ul>
<li>This setting is needed (but not sufficient) for Wake On LAN (WOL). You also need to enable WOL in your operating system.</li>
</ul>
</li>
<li>
<p>Advanced → Onboard Devices Configuration → Restore on AC/Power Loss: Power On</p>
<ul>
<li>This setting ensures the machine turns back on after a power loss. Without it, WOL might not work after a power loss.</li>
</ul>
</li>
</ul>
<h3 id="operating-system-1">Operating System</h3>
<h4 id="network-preparation">Network preparation</h4>
<p>I like to configure static IP addresses for devices that are a permanent part of my network.</p>
<p>I have come to prefer configuring static addresses as static DHCP leases in my router, because then the address remains the same no matter which operating system I boot — whether it’s the installed one, or a live USB stick for debugging.</p>
<h4 id="ubuntu-server">Ubuntu Server</h4>
<ol>
<li>
<p>Download Ubuntu Server from <a href="https://ubuntu.com/download/server">https://ubuntu.com/download/server</a></p>
<ul>
<li>I initially let the setup program install Docker, but that’s a mistake. The setup program will get you Docker from snap (not apt), which <a href="https://stackoverflow.com/questions/52526219/docker-mkdir-read-only-file-system">can’t work with the whole file system</a>.</li>
</ul>
</li>
<li>
<p>Disable swap:</p>
<ul>
<li><code>swapoff -a</code></li>
<li><code>$EDITOR /etc/fstab</code> # delete the swap line</li>
</ul>
</li>
<li>
<p>Automatically load the corresponding sensors kernel module for the mainboard so that the Prometheus node exporter picks up temperature values and fan speed values:</p>
<ul>
<li><code>echo nct6775 | sudo tee /etc/modules</code></li>
</ul>
</li>
<li>
<p>Enable <a href="https://help.ubuntu.com/community/AutomaticSecurityUpdates">unattended upgrades</a>:</p>
<ul>
<li>
<p><code>dpkg-reconfigure -plow unattended-upgrades</code></p>
</li>
<li>
<p>Edit <code>/etc/apt/apt.conf.d/50unattended-upgrades</code> — I like to make the following changes:</p>
<pre tabindex="0"><code>Unattended-Upgrade::MinimalSteps "true";
Unattended-Upgrade::Mail "<a href="https://michael.stapelberg.ch/cdn-cgi/l/email-protection" data-cfemail="3c51555f545d59507c59445d514c505912525948">[email&nbsp;protected]</a>";
Unattended-Upgrade::MailReport "only-on-error";
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-Time "08:00";
Unattended-Upgrade::SyslogEnable "true";
</code></pre></li>
</ul>
</li>
</ol>
<h3 id="network">Network</h3>
<h4 id="tailscale-mesh-vpn">Tailscale Mesh VPN</h4>
<p>I have come to like Tailscale. It’s a mesh VPN (data flows directly between the machines) that allows me access to and from my PCs, servers and storage machines from anywhere.</p>
<p>Specifically, I followed the <a href="https://tailscale.com/download/linux/ubuntu-2204">install Tailscale on Ubuntu 22.04 guide</a>.</p>
<h4 id="prometheus-node-exporter">Prometheus Node Exporter</h4>
<p>For monitoring, I have an existing Prometheus setup. To add a new machine to my setup, I need to configure it as a new target on my Prometheus server. In addition, I need to set up Prometheus on the new machine.</p>
<p>First, I installed the Prometheus node exporter using <code>apt install prometheus-node-exporter</code>.</p>
<p>Then, I modified <code>/etc/default/prometheus-node-exporter</code> to only listen on the Tailscale IP address:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span><span>ARGS</span><span>=</span><span>"--web.listen-address=100.85.3.16:9100"</span>
</span></span></code></pre></div><p>Lastly, I added a systemd override to ensure the node exporter keeps trying to start until tailscale is up: the command <code>systemctl edit prometheus-node-exporter</code> opens an editor, and I configured the override like so:</p>
<pre tabindex="0"><code># /etc/systemd/system/prometheus-node-exporter.service.d/override.conf
[Unit]
# Allow infinite restarts, even within a short time.
StartLimitIntervalSec=0

[Service]
RestartSec=1
</code></pre><h4 id="static-ipv6-address">Static IPv6 address</h4>
<p>Similar to the static IPv4 address, I like to give my NAS a static IPv6 address as well. This way, I don’t need to reconfigure remote systems when I (sometimes temporarily) switch my NAS to a different network card with a different MAC address. Of course, this point becomes moot if I ever switch all my backups to Tailscale.</p>
<p>Ubuntu Server comes with Netplan by default, but I don’t know Netplan and don’t want to use it.</p>
<p>To switch to <code>systemd-networkd</code>, I ran:</p>
<pre tabindex="0"><code>apt remove --purge netplan.io
</code></pre><p>Then, I created a <code>systemd-networkd</code> config file with a static IPv6 token, resulting in a predictable IPv6 address:</p>
<pre tabindex="0"><code>$EDITOR /etc/systemd/network/enp.network
</code></pre><p>My config file looks like this:</p>
<pre tabindex="0"><code>[Match]
Name=enp*

[Network]
DHCP=yes
IPv6Token=0:0:0:0:10::253
IPv6AcceptRouterAdvertisements=yes
</code></pre><h4 id="ipv6-firewall-setup">IPv6 firewall setup</h4>
<p>An easy way to configure Linux’s <code>netfilter</code> firewall is to <code>apt install iptables-persistent</code>. That package takes care of saving firewall rules on shutdown and restoring them on the next system boot.</p>
<p>My rule setup is very simple: allow ICMP (IPv6 needs it), then set up <code>ACCEPT</code> rules for the traffic I expect, and <code>DROP</code> the rest.</p>
<p>Here’s my resulting <code>/etc/iptables/rules.v6</code> from such a setup:</p>
<details>
<summary>
<code>/etc/iptables/rules.v6</code>
</summary>
<pre tabindex="0"><code># Generated by ip6tables-save v1.4.14 on Fri Aug 26 19:57:51 2016
*filter
:INPUT DROP [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -p ipv6-icmp -m comment --comment "IPv6 needs ICMPv6 to work" -j ACCEPT
-A INPUT -m state --state RELATED,ESTABLISHED -m comment --comment "Allow packets for outgoing connections" -j ACCEPT
-A INPUT -s fe80::/10 -d fe80::/10 -m comment --comment "Allow link-local traffic" -j ACCEPT
-A INPUT -s 2001:db8::/64 -m comment --comment "local traffic" -j ACCEPT
-A INPUT -p tcp -m tcp --dport 22 -m comment --comment "SSH" -j ACCEPT
COMMIT
# Completed on Fri Aug 26 19:57:51 2016
</code></pre></details>
<h3 id="encrypted-zfs">Encrypted ZFS</h3>
<p>Before you can use ZFS, you need to install the ZFS tools using <code>apt install zfsutils-linux</code>.</p>
<p>Then, we create a zpool that spans both SSDs:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span>zpool create <span>\
</span></span></span><span><span><span></span>  -o <span>ashift</span><span>=</span><span>12</span> <span>\
</span></span></span><span><span><span></span>  srv <span>\
</span></span></span><span><span><span></span>  /dev/disk/by-id/ata-Samsung_SSD_870_QVO_8TB_S5SSNF0TC06121Z <span>\
</span></span></span><span><span><span></span>  /dev/disk/by-id/ata-Samsung_SSD_870_QVO_8TB_S5SSNF0TC06787P
</span></span></code></pre></div><p>The <code>-o ashift=12</code> ensures <a href="https://wiki.archlinux.org/title/ZFS#Advanced_Format_disks">proper alignment</a> on disks with a sector size of either 512B or 4KB.</p>
<p>On that zpool, we now create our datasets:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span><span>(</span><span>echo</span> -n on-device-secret <span>&amp;&amp;</span> <span>\
</span></span></span><span><span><span></span> wget -qO - https://autounlock.zekjur.net:8443/nascrypto<span>)</span> | zfs create <span>\
</span></span></span><span><span><span></span>  -o <span>encryption</span><span>=</span>on <span>\
</span></span></span><span><span><span></span>  -o <span>compression</span><span>=</span>off <span>\
</span></span></span><span><span><span></span>  -o <span>atime</span><span>=</span>off <span>\
</span></span></span><span><span><span></span>  -o <span>keyformat</span><span>=</span>passphrase <span>\
</span></span></span><span><span><span></span>  -o <span>keylocation</span><span>=</span>file:///dev/stdin <span>\
</span></span></span><span><span><span></span>  srv/data
</span></span></code></pre></div><p>The key I’m piping into <code>zfs create</code> is constructed from two halves: the on-device secret and the remote secret, which is a setup I’m using to implement an automated crypto unlock that is remotely revokable. See the next section for the corresponding <code>unlock.service</code>.</p>
<p>I repeated this same command (adjusting the dataset name) for each dataset: I currently have one for <code>data</code> and one for <code>backup</code>, just so that the used disk space of each major use case is separately visible:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span>df -h /srv /srv/backup /srv/data   
</span></span><span><span>Filesystem      Size  Used Avail Use% Mounted on
</span></span><span><span>srv             4,2T  128K  4,2T   1% /srv
</span></span><span><span>srv/backup      8,1T  3,9T  4,2T  49% /srv/backup
</span></span><span><span>srv/data         11T  6,4T  4,2T  61% /srv/data
</span></span></code></pre></div><h4 id="zfs-maintenance">ZFS maintenance</h4>
<p>To detect errors on your disks, ZFS has a feature called “scrubbing”. I don’t think I need to scrub more often than monthly, but <a href="https://wiki.archlinux.org/title/ZFS#Scrubbing">maybe your scrubbing requirements are different</a>.</p>
<p>I enabled monthly scrubbing on my zpool <code>srv</code>:</p>
<p>On this machine, a scrub takes a little over 4 hours and keeps the disks busy:</p>
<pre tabindex="0"><code>  scan: scrub in progress since Wed Oct 11 16:32:05 2023
	808G scanned at 909M/s, 735G issued at 827M/s, 10.2T total
	0B repaired, 7.01% done, 03:21:02 to go
</code></pre><p>We can confirm by looking at the Prometheus Node Exporter metrics:</p>















<p><a href="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-11-grafana-scrub.png"><img srcset="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-11-grafana-scrub_huab242c6c68f4e18b70199053338a4d4f_420340_1200x0_resize_box_3.png 2x,https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-11-grafana-scrub_huab242c6c68f4e18b70199053338a4d4f_420340_1800x0_resize_box_3.png 3x" src="https://michael.stapelberg.ch/posts/2023-10-25-my-all-flash-zfs-network-storage-build/2023-10-11-grafana-scrub_huab242c6c68f4e18b70199053338a4d4f_420340_600x0_resize_box_3.png" alt="screenshot of a Grafana dashboard showing Prometheus Node Exporter metrics" title="screenshot of a Grafana dashboard showing Prometheus Node Exporter metrics" width="600" height="226" loading="lazy"></a></p><p>The other maintenance-related setting I changed is to enable automated TRIM:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span>zpool <span>set</span> <span>autotrim</span><span>=</span>on srv
</span></span></code></pre></div><h4 id="auto-crypto-unlock">Auto Crypto Unlock</h4>
<p>To automatically unlock the encrypted datasets at boot, I’m using a custom <code>unlock.service</code> systemd service file.</p>
<p>My <code>unlock.service</code> constructs the crypto key from two halves: the on-device secret and the remote secret that’s downloaded over HTTPS.</p>
<p>This way, my NAS can boot up automatically, but in an emergency I can remotely stop this mechanism.</p>
<details>
<summary>
My unlock.service
</summary>
<div><pre tabindex="0"><code data-lang="systemd"><span><span><span>[Unit]</span>
</span></span><span><span><span>Description</span><span>=</span><span>unlock hard drive</span>
</span></span><span><span><span>Wants</span><span>=</span><span>network.target</span>
</span></span><span><span><span>After</span><span>=</span><span>systemd-networkd-wait-online.service</span>
</span></span><span><span><span>Before</span><span>=</span><span>samba.service</span>
</span></span><span><span>
</span></span><span><span><span>[Service]</span>
</span></span><span><span><span>Type</span><span>=</span><span>oneshot</span>
</span></span><span><span><span>RemainAfterExit</span><span>=</span><span>yes</span>
</span></span><span><span><span># Wait until the host is actually reachable.</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/bin/sh -c "c=0; while [ $c -lt 5 ]; do /bin/ping6 -n -c 1 autounlock.zekjur.net &amp;&amp; break; c=$((c+1)); sleep 1; done"</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/bin/sh -c "(echo -n secret &amp;&amp; wget --retry-connrefused -qO - https://autounlock.zekjur.net:8443/nascrypto) | zfs load-key srv/data"</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/bin/sh -c "(echo -n secret &amp;&amp; wget --retry-connrefused -qO - https://autounlock.zekjur.net:8443/nascrypto) | zfs load-key srv/backup"</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/bin/sh -c "zfs mount srv/data"</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/bin/sh -c "zfs mount srv/backup"</span>
</span></span><span><span>
</span></span><span><span><span>[Install]</span>
</span></span><span><span><span>WantedBy</span><span>=</span><span>multi-user.target</span>
</span></span></code></pre></div></details>
<h3 id="backup">Backup</h3>
<p>For the last 10 years, I have been doing my backups using <code>rsync</code>.</p>
<p>Each machine pushes an incremental backup of its entire root file system (and any mounted file systems that should be backed up, too) to the backup destination (storage2/3).</p>
<p>All the machines I’m backing up run Linux and the <code>ext4</code> file system. I verified that my backup destination file systems support all the features of the backup source file system that I care about, i.e. extended attributes and POSIX ACLs.</p>
<p>The scheduling of backups is done by “<a href="https://github.com/stapelberg/zkj-nas-tools/tree/master/dornroeschen">dornröschen</a>”, a Go program that wakes up the backup sources and destination machines and starts the backup by triggering a command via SSH.</p>
<h4 id="ssh-configuration">SSH configuration</h4>
<p>The backup scheduler establishes an SSH connection to the backup source.</p>
<p>On the backup source, I authorized the scheduler like so, meaning it will run <a href="https://github.com/stapelberg/zkj-nas-tools/blob/master/dornroeschen/backup-remote.pl"><code>/root/backup.pl</code></a> when connecting:</p>
<pre tabindex="0"><code>command="/root/backup.pl",no-port-forwarding,no-X11-forwarding ssh-ed25519 AAAAC3Nzainvalidkey backup-scheduler
</code></pre><p>backup.pl runs <code>rsync</code>, which establishes another SSH connection, this time from the backup source to the backup destination.</p>
<p>On the backup destination (storage2/3), I authorize the backup source’s SSH public key to run <a href="https://manpages.debian.org/rrsync.1"><code>rrsync(1)</code></a>
, a script that only permits running <code>rsync</code> in the specified directory:</p>
<pre tabindex="0"><code>command="/usr/bin/rrsync /srv/backup/server.zekjur.net",no-port-forwarding,no-X11-forwarding ssh-ed25519 AAAAC3Nzainvalidkey server.zekjur.net
</code></pre><h4 id="signaling-readiness-after-wake-up">Signaling Readiness after Wake-Up</h4>
<p>I found it easiest to signal readiness by starting an empty HTTP server gated on <code>After=unlock.service</code> in systemd:</p>
<details>
<summary><code>/etc/systemd/system/healthz.service</code></summary>
<div><pre tabindex="0"><code data-lang="systemd"><span><span><span>[Unit]</span>
</span></span><span><span><span>Description</span><span>=</span><span>nginx for /srv health check</span>
</span></span><span><span><span>Wants</span><span>=</span><span>network.target</span>
</span></span><span><span><span>After</span><span>=</span><span>unlock.service</span>
</span></span><span><span><span>Requires</span><span>=</span><span>unlock.service</span>
</span></span><span><span><span>StartLimitInterval</span><span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span>[Service]</span>
</span></span><span><span><span>Restart</span><span>=</span><span>always</span>
</span></span><span><span><span># https://itectec.com/unixlinux/restarting-systemd-service-on-dependency-failure/</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>/bin/sh -c 'systemctl is-active docker.service'</span>
</span></span><span><span><span># Stay on the same major version in the hope that nginx never decides to break</span>
</span></span><span><span><span># the config file syntax (or features) without doing a major version bump.</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>/usr/bin/docker pull nginx:1</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>-/usr/bin/docker kill nginx-healthz</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>-/usr/bin/docker rm -f nginx-healthz</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/usr/bin/docker run </span>\
</span></span><span><span><span>  --name nginx-healthz </span>\
</span></span><span><span><span>  --publish 10.0.0.253:8200:80 </span>\
</span></span><span><span><span>  --log-driver=journald </span>\
</span></span><span><span><span>nginx:1</span>
</span></span><span><span>
</span></span><span><span><span>[Install]</span>
</span></span><span><span><span>WantedBy</span><span>=</span><span>multi-user.target</span>
</span></span></code></pre></div></details>
<p>My <a href="https://github.com/stapelberg/zkj-nas-tools/blob/master/wake/wake.go"><code>wake</code></a> program then polls that port and returns once the server is up, i.e. the file system has been unlocked and mounted.</p>
<h4 id="auto-shutdown">Auto Shutdown</h4>
<p>Instead of explicitly triggering a shutdown from the scheduler program, I run “dramaqueen”, which shuts down the machine after 10 minutes, but will be inhibited while a backup is running. Optionally, shutting down can be inhibited while there are active samba sessions.</p>
<details>
<summary><code>/etc/systemd/system/dramaqueen.service</code></summary>
<div><pre tabindex="0"><code data-lang="systemd"><span><span><span>[Unit]</span>
</span></span><span><span><span>Description</span><span>=</span><span>dramaqueen</span>
</span></span><span><span><span>After</span><span>=</span><span>docker.service</span>
</span></span><span><span><span>Requires</span><span>=</span><span>docker.service</span>
</span></span><span><span>
</span></span><span><span><span>[Service]</span>
</span></span><span><span><span>Restart</span><span>=</span><span>always</span>
</span></span><span><span><span>StartLimitInterval</span><span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span># Always pull the latest version (bleeding edge).</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>-/usr/bin/docker pull stapelberg/dramaqueen</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>-/usr/bin/docker rm -f dramaqueen</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>/usr/bin/docker create --name dramaqueen stapelberg/dramaqueen</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>/usr/bin/docker cp dramaqueen:/usr/bin/dramaqueen /tmp/</span>
</span></span><span><span><span>ExecStartPre</span><span>=</span><span>/usr/bin/docker rm -f dramaqueen</span>
</span></span><span><span><span>ExecStart</span><span>=</span><span>/tmp/dramaqueen -net_command=</span>
</span></span><span><span>
</span></span><span><span><span>[Install]</span>
</span></span><span><span><span>WantedBy</span><span>=</span><span>multi-user.target</span>
</span></span></code></pre></div></details>
<h4 id="enabling-wake-on-lan">Enabling Wake-on-LAN</h4>
<p>Luckily, the network driver of the onboard network card supports WOL by
default. If that’s not the case for your network card, see <a href="https://wiki.archlinux.org/title/Wake-on-LAN">the Arch wiki
Wake-on-LAN article</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I have been running a PC-based few-large-disk Network Storage setup for years at this point, and I am very happy with all the properties of the system. I expect to run a very similar setup for years to come.</p>
<p>The low-tech approach to backups of using rsync has worked well — without changes — for years, and I don’t see rsync going away anytime soon.</p>
<p>The upgrade to all-flash is really nice in terms of random access time (for incremental backups) and to eliminate one of the largest sources of noise from my builds.</p>
<p>ZFS seems to work fine so far and is well-integrated into Ubuntu Server.</p>

<p>There are solutions for almost everyone’s NAS needs. This build obviously hits my personal sweet spot, but your needs and preferences might be different!</p>
<p>Here are a couple of related solutions:</p>
<ul>
<li>If you would like a more integrated solution, you could take a look at <a href="https://www.heise.de/ratgeber/Einplatinencomputer-Odroid-H3-als-NAS-und-Heimserver-einrichten-7496088.html">the Odroid H3 (Celeron)</a>.</li>
<li>If you’re okay with less compute power, but want more power efficiency, you could use an ARM64-based Single Board Computer.</li>
<li>If you want to buy a commercial solution, buy a device from qnap and fill it with SSD disks.
<ul>
<li>There are even commercial M.2 flash storage devices like the <a href="https://www.jeffgeerling.com/blog/2023/first-look-asustors-new-12-bay-all-m2-nvme-ssd-nas">ASUSTOR Flashstor</a> becoming available! If not for the “off the shelf hardware” goal of my build, this would probably be the most interesting commercial alternative to me.</li>
</ul>
</li>
<li>If you want more compute power, consider a Thin Client (perhaps used) instead of a Single Board Computer.
<ul>
<li><a href="https://www.servethehome.com/">ServeTheHome</a> has a nice series called Project TinyMiniMicro (<a href="https://www.servethehome.com/introducing-project-tinyminimicro-home-lab-revolution/">introduction</a>, <a href="https://www.servethehome.com/tag/tinyminimicro/">blog posts</a>)</li>
<li>If you’re a heise+ subscriber, <a href="https://www.heise.de/ratgeber/Schlank-guenstig-stromsparend-NAS-mit-Thin-Client-im-Eigenbau-7546763.html">they have a (German) article about building a NAS from a thin client</a>.</li>
</ul>
</li>
<li>Very similar to thin clients is the Intel NUC (“Next Unit of Computing”): <a href="https://www.golem.de/news/nuc-12-pro-test-mini-kraftpakete-fuers-buero-und-mediacenter-2303-172992.html">(German) article comparing different NUC 12 devices</a></li>
</ul>
<div id="bmc">
  <p>
    I run a blog since 2005, spreading knowledge and experience for almost 20 years! :)
  </p>
  <p>
    If you want to support my work, you
    can <a href="https://www.buymeacoffee.com/stapelberg">buy me a coffee</a>.
  </p>
  <p>
    Thank you for your support! ❤️
  </p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft: Require user consent before sending any telemetry (122 pts)]]></title>
            <link>https://github.com/microsoft/vscode/issues/176269</link>
            <guid>38034686</guid>
            <pubDate>Fri, 27 Oct 2023 04:25:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/vscode/issues/176269">https://github.com/microsoft/vscode/issues/176269</a>, See on <a href="https://news.ycombinator.com/item?id=38034686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">Here's how you (and all of us) have to handle it, according to the GDPR:</p>
<ol dir="auto">
<li>Contact the DPO (data protection officer) of Microsoft and point them to this discussion. The contact details are here: <a href="https://learn.microsoft.com/en-us/compliance/regulatory/gdpr-data-protection-officer" rel="nofollow">https://learn.microsoft.com/en-us/compliance/regulatory/gdpr-data-protection-officer</a>.</li>
</ol>
<div data-snippet-clipboard-copy-content="Data subjects may contact the data protection officer by filling
out the webform at https://aka.ms/privacyresponse.

The DPO can also be reached by post at:

Microsoft EU Data Protection Officer
One Microsoft Place
South County Business Park
Leopardstown
Dublin 18
D18 P521
Ireland
Telephone: +353 (1) 706-3117"><pre><code>Data subjects may contact the data protection officer by filling
out the webform at https://aka.ms/privacyresponse.

The DPO can also be reached by post at:

Microsoft EU Data Protection Officer
One Microsoft Place
South County Business Park
Leopardstown
Dublin 18
D18 P521
Ireland
Telephone: +353 (1) 706-3117
</code></pre></div>
<p dir="auto">In your message to the DPO, refer to <a href="https://gdpr-info.eu/art-7-gdpr/" rel="nofollow">art. 7(1) of the GDPR</a>, which has this to say:</p>
<blockquote>
<p dir="auto">Where processing is based on consent, the controller shall be able to demonstrate that the data subject has consented to processing of his or her personal data.</p>
</blockquote>
<p dir="auto">Point out that you did not give consent for the data to be collected, nor were you asked about it. Per GDPR, they're supposed to be <a href="https://gdpr-info.eu/art-5-gdpr/" rel="nofollow">transparent</a> about the way personal data are handled (see Art. 5). They ought to tell you: what personal data are collected, for what purpose, for how long the data are stored, with whom the data are shared (this could be buried somewhere deep in the UI). Give them ~2 weeks to respond. If you receive no feedback, then:</p>
<ol start="2" dir="auto">
<li>Contact your local DPA (data protection authority) and lodge a complaint (see <a href="https://gdpr-info.eu/art-77-gdpr/" rel="nofollow">art. 77 of the GDPR</a>)</li>
</ol>
<blockquote>
<p dir="auto">Without prejudice to any other administrative or judicial remedy, every data subject shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the data subject considers that the processing of personal data relating to him or her infringes this Regulation.</p>
</blockquote>
<p dir="auto">But step 0 would be to think about the situation and consider what data are collected. Are those personal data? Does Microsoft, perhaps, have a "legitimate interest" in collecting this information?</p>
<blockquote>
<p dir="auto">It is concluded, that you do not respect the users privacy, do not comply with the GDPR and ignore any users objections against your negligent way of personal data processing.</p>
</blockquote>
<p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/nandlab/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nandlab">@nandlab</a>  no, it is not concluded yet. It might be the case, but the right course of action is to get there  through the means the GDPR gives us. The regulation says you should contact the DPO, and eventually lodge a complaint with the DPA; it doesn't say that programmers on Github have to monitor issues and are responsible for handling privacy-related stuff. To play this game well, you have to play by the rules; let the DPO know about it - and if they're still silent, they might be more responsive if they get a call from a DPA ;-)</p>
      </div></div>]]></description>
        </item>
    </channel>
</rss>