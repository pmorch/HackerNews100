<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 29 Jul 2023 14:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[IRC is the only viable chat protocol (160 pts)]]></title>
            <link>https://koshka.love/babel/irc-forever.html</link>
            <guid>36918655</guid>
            <pubDate>Sat, 29 Jul 2023 10:12:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koshka.love/babel/irc-forever.html">https://koshka.love/babel/irc-forever.html</a>, See on <a href="https://news.ycombinator.com/item?id=36918655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>IRC is the Only Viable Chat Protocol</h2>
<hr>
<p><del>IRC is so wonderful that I am continually finding myself far too distracted by it to actually write this article praising the virtues of IRC. Get on IRC to learn more.</del></p><p>
OK, OK, I'll pull myself away from the terminal and finally finish writing this piece. Although it would be quite poetic if my argument for using IRC was prematurely aborted because I could not pull myself from Irssi/Comic Chat long enough to actually write it, this scenario would be of no benefit to anyone.</p><p>
For those unaware, IRC is a primordial (by Internet standards) yet stalwart chat protocol dating back to 1988. The basic way it works is that people use an IRC client to connect to an IRC daemon running on another computer (an IRC server), where they are able to pick a name and interact with other people over text, either by joining a channel that they are in, or privately messaging them. Although it has severely declined in popularity since its golden age in favour of social media and Discord, I have found myself more attached to the ostensibly dying protocol than ever before lately for a myriad of reasons that I wish to share here.</p><p>
For transparency's sake, I should probably point out immediately that I am a long-time stubborn aficionado of retro technology and culture, both in ways that other people admire, and in ways that make me come off as an eccentric lunatic.</p><p>
Among other things, I still use a flip phone, collect and listen to music CDs, use Office 97 (the very first version I ever owned), listen to music on an MP3 player while on the go, own two CRT televisions along with a VCR and a collection of VHS tapes, collect and read physical books, and own two CRT monitors that I use with my 1999 Compaq gaming computer that still proudly runs Windows 98 and hosts the DOS/Windows 9x games that still make up the bulk of the games that I enjoy.</p><p>
As returning visitors likely know, in the year of our Lord, 2022, I also proudly host my own IRC server, where I spend an extremely unhealthy amount of my time chatting with beloved like-minded people. Using an "archaic" chat platform that dates back to the 80s and that has lost the majority of the userbase it enjoyed during its peak may seem like a form of nostalgia bordering on abject madness when looked at from the outside. Yet, I daresay it is easily one of the most easily defensible and reasonable of the life choices that I have just listed off.</p><h3>Cut the (Dis)Cord</h3><p>
If you look around for a place to chat in real time with other people in this day and age, chances are more than good that you'll quickly be directed to a Discord server. This is an unfortunate state of affairs for many reasons. To put it succintly, Discord is a centralised and proprietary platform that spies on its users in every conceivable way, right down to what logging what programs they have running on their computer and demanding people self-dox by providing their phone number. All of this information is then put to use to allow advertisers to better target Discord's userbase.</p><p>
I am aware that most people have become completely lamentably desensitised to corporate and government surveillance, and may thus not be greatly alarmed by these facts. However, I would assume that most (if not all) of those people would feel quite violated if a salesperson began stalking them in "real life", listening in to every conversation they had with their family/friends from a distance, and then physically approaching on the street and peddling products to them in suspiciously prescient ways.</p><p>
The fundamental fact that Discord users refuse to see is that the platform isn't run on magic dust and fairy incantations, but actual human beings. Using Discord is no different from having a group of strangers sitting in your room with you, noting down every word you say to your friends and everything you run on your computer, and doing the devil knows what with it.</p><p>
Even if you have full-on Stockholm syndrome in regard to advertisers data-mining your life to sell you garbage, who knows where else your data could be going? Considering the horrific epidemic of sexual abuse being abetted and covered up in the workplace, is it really too difficult to imagine malicious actors at Discord (or any other technology company) illegitimately accessing the data of their business' users and using it for stalking or other nefarious purposes?</p><p>
The complete de-centralisation of IRC, unlike Discord, is also well worth expanding on. Since IRC is a standard and not a platform like Discord, anyone with access to reliable hosting and basic computer knowledge can set up their own IRC server. As I joked to a friend recently, I am free to ban anyone from an IRC channel I own, but there is nothing stopping them from then starting #koshkaisafag and regrouping. I can try to get them banned from the server, but there is also nothing stopping them from setting up their own server as irc.koshkaisafag.info and regrouping as a completely sovereign entity that no one can touch any longer.</p><p>
There are certainly a number of monolithic IRC networks, such as Rizon, EFNet, and Libera Chat, that make up the vast bulk of the IRC world, but there are also many thousands of smaller networks dotting the landscape. There are just over 500 networks whose channels are indexed by the IRC search engine <a href="https://netsplit.de/networks/">Netsplit.de</a>, but this engine still only covers fairly large networks, and excludes the great many networks that are either private or very small and obscure. Some of these may be intended entirely for a small group of friends, or may be used by a business to communicate privately.</p><p>
There certainly is no magical check in any IRCd daemon to stop a rogue IRCOp from <a href="https://www.reddit.com/r/discordapp/comments/7arzdn/my_account_has_been_disabled_with_no_reason_given/">banning individuals for no coherent reason</a>, or <a href="https://www.reddit.com/r/privacy/comments/djyy6v/psa_discord_is_deactivating_accounts_without/">blackmailing someone into providing their phone number</a> and/or other personal information in order to stay on a server (although, unlike with Discord, I have never heard of this occurring on IRC before), but the complete de-centralisation of the IRC world means that allowing such abuses of power is quite detrimental to an IRC network. If an IRCOp goes rogue, their reign of terror is unlikely to last for much longer as word goes out and users either flee to another network or set their own up.</p><p>
Perhaps the most dramatic example of this is <a href="https://github.com/siraben/freenode-exodus">the rapid fall of Freenode</a>, which underwent a rapid collapse after a hostile takeover of the network by new management seeking to use it to make a quick buck. In the span of mere months, the most popular IRC network in the world was reduced to a disgraced and nearly moribund shell of its former self, as disgruntled users fled enmasse to the newly established Libera Chat network.</p><p>
I touched on the problems of centralisation and why de-centralisation was a key tenet of the old Internet in my acclaimed article <a href="https://koshka.love/mwwwga.html">Make the Web Great Again</a>, and Discord does not get nearly enough bad press for its role in destroying this aspect of the Internet. Much as the dreaded Reddit has largely paved a fascist monopoly over the niche once occupied by a bounty of independent Web forums, Discord has done the same with the chat world, replacing the sea of independent and free IRC servers with a single corporate walled garden whose owners each user must avoid offending in any way, lest they be entirely cast out of the public square.</p><p>
This problem is so endemic on the modern Internet that not only is there a sea of unintentionally comical Neocities "Web 1.0" websites featuring their owners jabbering about how much they miss the old Internet while inviting people to chat on the webmaster/webmistress' Discord server in the same breath, but even actually respectable people and outfits (who I will not name out of politeness) that have migrated to Discord because all of their misguided friends use it and refuse to budge. Even I, for all of my frenzied rabble-rousing, briefly created a Discord account a few years ago to speak with a friend before quitting the service out of disgust.</p><p>
Nonetheless, for all of the social issues it causes me, being autistic has also given me the stubbornness of a mountain, and I have long since vowed to never touch the service again no matter who or what I may need it for. Each person who <a href="https://koshka.love/babel/boycott-big-technology.html">avoids big</a> <a href="https://koshka.love/babel/alternatives-to-big-technology.html">technology companies</a> pushes the stake slightly deeper into the frigid, rotten heart of the privacy vampire that Discord and other big technology companies are (no offence intended to comparatively benevolent actual vampires with this comparison). Each person who avoids these services is also one less carrot for the vampire to dangle away over other people's heads to convince them to stay in its cave.</p><p>
For more information on the many sordid problems with Discord, please check out these two guides written by the esteemed <a href="https://stallman.org/discord.html">Richard Stallman</a> and <a href="https://spyware.neocities.org/articles/discord.html">Spyware Watchdog</a> over on Neocities on why Discord should be avoided like a berserk chainsaw-wielding leper, if you have not done so already.</p><h3>A Rare Sanctuary</h3><p>
My good friend <a href="https://lolwut.info/">lolwut</a> made a very astute observation some time ago about IRC being a nearly infallible NORP filter, and thus a very rare safe port from the <a href="https://koshka.love/babel/normiefication.html">normiefication</a> storm, due to the apparent "complexities" involved in getting on IRC, and the sheer age and and its lack of sleekness of the protocol relative to Discord and other modern alternatives. Anyone who has ever used IRC knows that there is nothing even remotely complicated about using it, but the terminology and the steps required to use one are ostensibly terrifying enough to reliably keep the technically illiterate at bay.</p><p>
A number of Web chat interfaces have been invented over the years to entice normalcattle onto IRC, but even this has proven to be an abject failure, as well over 90% of cases end with the NORP leaving after 30 seconds of inactivity, apparently appalled by the fact that a protocol that is utilised by people who could be online from anywhere in the world and who could be doing any manner of non-IRC related things would have lulls in activity. In fact, the only real use that these clients seem to get is from regulars who temporarily lack access to a real IRC client. On my end, I rely on Kiwi IRC to get on IRC from my flip phone, which has no SSH client or IRC client, but does have a Web browser.</p><p>
Seeing as the world of IRC is a nearly NORP-free oasis, most people are mature and intelligent enough to understand that words on a screen are just that, and that it is quite simple to withdraw from them if one does not want to deal with them. Aside from actually leaving a channel to get away from an unpleasant user, it is possible to use the ignore function to block any further correspondence from them. Many networks also provide some sort of server-side ignore functionality to stop a user from receiving any private messages that don't come from a pre-approved user.</p><p>
Due to the fact that IRC power is effectively meaningless (as it should be on any part of the Internet!), the common theme for governance on most IRC servers is delightfully adherent to the ways of the old Internet. As is nicely summarised <a href="https://www.unrealircd.org/docs/IRCOp_guide#Principles">here</a>, IRCOps (the administrators of an IRC network) are normally completely neutral entities that allow users to govern themselves and their channels however they see fit, only wielding their power in dire situations such as when someone's actions are endangering the security of the server or breaking national law.</p><p>
Indeed, while on smaller and more "intimate" networks, such as my own, running into the local IRCOp(s) is a common occurrence, it is actually quite rare to actually have even a single interaction with an IRCOp on any large server, unless they happen to be part of a channel you are in. Seeing as anyone can start their own channel(s), and run them however they see fit, there is very rarely a need for an IRCOp to do anything beyond keeping the power on and changing the light bulbs when they go bad.</p><p>
In contrast to much of the modern Internet, IRC is also largely anonymous, another key tenet of the old Internet. Beyond not requiring any personal information to participate (in contrast to Discord, where the service itself often requires a phone number, and some individual rooms go as far as requiring <i>social media background checks</i>, lest some normalfag SJW gets an aneurysm from reading a mean word), many modern IRC servers (including my own) also cloak people's IP addresses and offer the option of VHosts, which are custom (fake or real) domain names that people can choose to substitute in for their IP address. Additionally, most IRC networks allow users to connect via a VPN or (less often) Tor.</p><p>
A quick word of caution for anyone who is new to IRC and who I may have inspired to go spelunking: the key word in the previous few sentences is "most". VHosts and IP cloaking are modern IRC conveniences, and not every network offers them. EFNet, the most ancient IRC network in the world and the child of the very first IRC network, is particularly notorious for stubbornly eschewing just about every modern IRC convenience there is.</p><p>
Not only does EFNet still display people's full IP addresses (assuming the server they are connecting to does not have its own domain name), but it also does not even have services such as NickServ and ChanServ for people to register their names and channels in order to retain ownership over them! This "wild west" landscape is not nearly as chaotic and exciting as it may sound, especially since everyone on the server is seemingly connected from a shell or a bouncer that they last touched while speculating on what will happen on Y2K.</p><h3>Extending IRC</h3><p>
While some changes have occurred in the IRC world over the decades, the protocol itself dates back all the way back to 1988, and was designed to be sustainable on the Internet speeds of that bygone era. In contrast to Discord and the bloated client that it pushes down user's throats, IRC is such a bare bones and low-consumption protocol that you can even connect to it via the command prompt or terminal using Telnet (although you do have to manually ping the IRC server you're connected to in order for it to not assume that your connection died)!</p><p>
The reliability and lack of bloat that are inherent to IRC ultimately also means that there are a number of fancy modern features that Discord has that IRC lacks, a big one being the inability to view backlogs of conversations that transpired while one was not connected to an IRC server. Although IRC does not itself provide this functionality, the extremely simple nature of IRC allows for a couple of lightweight options for reliably remaining on IRC around the clock and not missing out on a word that anyone says.</p><p>
The most sublime option by far involves running a terminal-based client such as <a href="https://irssi.org/">Irssi</a> (the most sublime IRC client in existence, in my personal opinion) or WeeChat on a Linux/BSD server in a terminal multiplexer such as Screen or Tmux. One can then SSH into the server from any Internet-connected computer at their leisure, and take control of their IRC client as if it had been running on their current computer this entire time.</p><p>
For my part, I have been on IRC this way since 2006 on a variety shells from my very first one which was provided to me by a friend of mine on his server, to free publicly offered ones, to Raspberry Pi servers I set up in my house, to my current one which runs on the same server running my website and other infrastructure. Given how useful and reliable this is, and how efficient and sleek Irssi is, I cannot imagine why anyone would want to use any other client or method.</p><p>
Nonetheless, for fans of non-terminal clients such as HexChat and mIRC (there is no accounting for taste, I suppose), there also exists the option of IRC bouncers. These are essentially bots that connect to specific IRC servers/channels under their owner's name and log all of the messages that they receive. The bouncer's owner in turn connects to the bouncer like an IRC server, after which they are provided the backlog of what occurred during their absence and are able to take full control of the bouncer to chat like they normally would on an IRC server.</p><p>
Being a bare bones public protocol, IRC does suffer the issue of being easy to snoop on. Thankfully, many IRC networks do allow users to connect via SSL, the port for which is usually 6697, as opposed to the usual 6667. A single user in a channel not using SSL can completely compromise everyone else's efforts, but it is possible to restrict anyone not connected via SSL from joining a channel. Additionally, a number of clients on Linux (Irssi, WeeChat, and HexChat) also allow users to set up OTR in order to have fully encrypted private one-on-one conversations with anyone else who has this plugin.</p><p>
Other features that are notably absent from IRC but present on Discord are image-sharing and voice chat/video chat. Before going into the available options for an IRC user needing these features, I must say that personally view all three of these features as being utterly extraneous, and not even remotely worth the many dire downsides that come with Discord even if they were not. I wrote an entire article outlining why <a href="https://koshka.love/babel/writing-superior-to-speaking.html">writing is provably superior to speaking as a communication method</a>, so I will not elaborate further here.</p><p>
Needless to say, as an autistic person who goes online because I am actually able to socialise without the vexing machinations of in-person/verbal communication, I have never voice-chatted in my life and only used a webcamera once when I had to in order to do a job evaluation during quarantine. Even considering over 98% of people aren't autistic, I still do not understand how anyone can enjoy or even seek out voice chat. For one, it would interrupt my habit of listening to music any time I am at the computer, and for two, it would morph online conversations from completely anonymous exchanges to ones that are broadcasted to everybody in the vicinity of the participants, while also providing dox fuel for all involved.</p><p>
My angry grumbling aside, for anyone who absolutely feels the need to ruin the simple sublimity of text conversation with voice chat, there do exist relatively safe outside services, notably <a href="https://www.mumble.com/">Mumble</a>, that users can switch over from IRC for when needed. Admittedly, this is an extra step that requires reliance on infrastructure outside of IRC, but I would classify that as more than worth being able to have a conversation with minimal fear of privacy violation. Mumble is free software and, much like IRC, allows for anyone to set up their own personal server to communicate on.</p><p>
The issue of image sharing is once again something that can be very easily worked around by either uploading any images one wishes to share to one's personal server, or to an image hosting service such as <a href="https://catbox.moe/">Catbox.moe</a>, or <a href="https://uguu.se/">Uguu.se</a>. Again, this is an extra step that winds up requiring reliance on infrastructure outside of IRC, but one that takes very minimal effort. It should be noted however, that IRC <i>does</i> allow for sending files from one person to the other using the DCC protocol, so only sharing images with an entire group at once requires leaving its borders. The only issue is that DCC is implemented differently by various clients and may be blocked by the firewall by default.</p><p>
Nevertheless, for people seeking a facsimile of video chat on IRC, there does exist a fascinating alternative that allows for something close to it: the truly sublime <a href="http://mermeliz.com/">Microsoft Comic Chat</a>, a completely unique IRC client that Microsoft invented during its golden age of the 90s. Although Microsoft wound up discontinuing it over 20 years ago in favour of MSN Messenger, it continues to enjoy a cult following to this day, and for very good reason.</p><p>
In a stroke of absolute genius, Comic Chat rejects the typical text-only approach of other IRC clients, and instead renders IRC channels as in-progress comic strips, with every participant being able to choose an avatar for themselves and punctuate everything they say with a specific facial expression or pose.</p><p>
Beyond being patently hilarious (many of the default avatars are absolutely insane, and most of the custom-made ones are comical ones such as sunglasses-wearing cats and obese Vikings), Comic Chat adds an entirely new dimension to conversations, allowing people to express themselves with facial expressions and body language to emphasise and clarify what they are saying. The client even allows you to send a facial expression as a reaction without including any words at all, for situations where body language alone gets one's message across better than words.</p><p>
While this was certainly not the intended goal behind Comic Chat, and it is a program that is enjoyed by a great many neurotypicals, I personally adore it enough to argue that it may be <i>the</i> ideal communication method for <a href="https://koshka.love/autism/index.html">autistic people</a>. Most characters have such exaggerated facial expressions and body language that just about anyone can clearly understand them, and the nature of IRC means that anyone participating in a conversation has plenty of time to process everything and is not pressured to immediately and constantly send out many complex social cues every moment of an interaction.</p><p>
I will admit that Microsoft Comic Chat has quite a buffoonish reputation, owing to the inherent silliness of the program and its sheer age <a href="https://koshka.love/babel/words-i-hate.html#outdated">(sadly, this is considered by many to be an actual criticism by itself</a>). Its association with <a href="https://www.bonequest.com/6461">the ludicrous NSFW web comic Jerkcity</a> also likely did no PR favours for it. Yet just as many other great inventions were happy accidents, I do believe that in their tomfoolery, Microsoft accidentally created one of the most useful methods of communication we autistic people have available to us. One that, even by itself, more than justifies the continued existence of IRC in my eyes. I suppose the fact that I get to be an <a href="https://koshka.love/babel/meow.png">angelic pink kitty on IRC</a> helps a lot too. ^-^</p><hr><p>
Although my main purpose for writing this article is to inspire some people to change their ways and consider migrating from the proprietary spyware platform of Discord to free and de-centralised prairies such as IRC and Mumble, it would be a lost opportunity to not advertise my own burgeoning IRC network here. If you have any interest in interacting with a wise, witty, and welcoming group of Internet/computing/gaming nostalgics (and also, myself), be sure to steer your IRC client of choice towards KoshkaIRC at irc.koshka.love, the main channel of which is # (literally as simple of a channel name as it can get).</p><p>
There has also recently been a Microsoft Comic Chat renaissance on the same server, in the channel #comicchat. Due to the fact that participating requires a separate IRC client which cannot be run on a shell and is too primitive to connect to a bouncer, and the fact that people on the network hail from time zones all over, I have decided to host an all-day named <b>Comic Chat Caturday</b> event on Saturdays (or closer to Sundays, for people in the enigmatic land of Oceania) from now on to make it easier for people to participate.</p><p>
Although a program designed only for Windows, it is possible to get Comic Chat running in Linux, and my good friend <a href="https://shadowm00n.neocities.org/">ShadowM00n</a> has written <a href="https://shadowm00n.neocities.org/tech/comic_chat.html">an excellent guide</a> on how exactly to set this program up on Linux using Wine.</p><p>
Microsoft Comic Chat comes with a default set of rather insane avatars that are probably best known as the cast characters of the aforementioned Jerkcity/BoneQuest, which gloriously appropriated them as a bunch of lunatics shrieking about homosexual intercourse, drugs, and monster poos, but there is a sea of custom avatars available for you to download at <a href="https://mermeliz.com/">Mermaid Elizabeth's monolithic Comic Chat website</a>.</p><p>
Aside from being the author's vast personal Comic Chat resource, this site also hosts a massive trove of defunct Comic Chat websites created over the decades, and all of the avatars and other resources that they hosted. From kitties of every shape and stripe, to anime characters, to Vikings, to all sorts of other options, there should be something for everyone on there.</p><p>
Seeing as <a href="https://koshka.love/autism/index.html">autism</a> and <a href="https://koshka.love/dos/index.html">general old computing-related nostalgia</a> are the two main themes of this website, I could not think of a more fitting event for fans of this website than a day dedicated to this delightful ancient, autistic-friendly IRC client. Whether you've never used Comic Chat before, or you're familiar with it and want to give it another spin, be sure to drop by this Saturday and join in the fun! As long as people continue using free and open protocols, and <a href="https://koshka.love/mwwwga.html">upholding the tenets of old</a>, the good old Internet will never truly die.</p><h4>Many thank yous to <a href="https://shadowm00n.neocities.org/">ShadowM00n</a>, both for his amazingly thorough proof-reading, and for writing the aforementioned article about running Comic Chat on Linux, and to jvlfools, for his own helpful proof-reading!</h4>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you want to build your own open source chatbot (141 pts)]]></title>
            <link>https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/</link>
            <guid>36918435</guid>
            <pubDate>Sat, 29 Jul 2023 09:28:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/">https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/</a>, See on <a href="https://news.ycombinator.com/item?id=36918435">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="article">
    <p><i>(Expanded from </i><a href="https://sched.co/1O37L"><i>a talk</i></a><i> given at </i><a href="https://dwebcamp.org/"><i>DWeb Camp 2023</i></a><i>.)</i></p>
<p>Artificial intelligence may well prove one of the most impactful and disruptive technologies to come along in years. This impact isn’t theoretical: AI is already affecting real people in substantial ways, and it’s already changing the Web that we know and love. Acknowledging the potential for both benefit and harm, Mozilla has committed itself to the principles of <a href="https://foundation.mozilla.org/en/internet-health/trustworthy-artificial-intelligence/"><b>trustworthy AI</b></a>. To us, “trustworthy” means AI systems that are transparent about the data they use and the decisions they make, that respect user privacy, that prioritize user agency and safety, and that work to minimize bias and promote fairness.</p>
<h2>Where things stand</h2>
<p>Right now, the primary way that most people are experiencing the latest AI technology is through <b>generative AI chatbots</b>. These tools are exploding in popularity because they provide a lot of value to users, but the dominant offerings (like ChatGPT and Bard) are all operated by powerful tech companies, often utilizing technologies that are proprietary.</p>
<p>At Mozilla, we believe in the collaborative power of <b>open source</b> to empower users, drive transparency, and — perhaps most importantly — ensure that technology does not develop only according to the worldviews and financial motivations of a small group of corporations. Fortunately, there’s recently been rapid and exciting progress in the open source AI space, specifically around the <b>large language models</b> (LLMs) that power these chatbots and the tooling that enables their use. We want to understand, support, and contribute to these efforts because we believe that they offer one of the best ways to help ensure that the AI systems that emerge are truly trustworthy.</p>
<h2>Digging in</h2>
<p>With this goal in mind, a small team within Mozilla’s innovation group recently undertook a hackathon at our headquarters in San Francisco. Our objective: <b>build a Mozilla internal chatbot prototype</b>, one that’s…</p>
<ul>
<li aria-level="1">Completely <b>self-contained</b>, running entirely on Mozilla’s cloud infrastructure, without any dependence on third-party APIs or services.</li>
<li aria-level="1">Built with <b>free, open source</b> large language models and tooling.</li>
<li aria-level="1"><b>Imbued</b> with Mozilla’s beliefs, from trustworthy AI to the principles espoused by the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla Manifesto</a>.</li>
</ul>
<p>As a bonus, we set a stretch goal of integrating some amount of internal Mozilla-specific knowledge, so that the chatbot can answer employee questions about internal matters.</p>
<p>The Mozilla team that undertook this project — <a href="https://yetanotherjosh.com/">Josh Whiting</a>, <a href="https://www.rupertparry.com/">Rupert Parry</a>, and <a href="https://stephenhood.com/">myself</a> — brought varying levels of machine learning knowledge to the table, but none of us had ever built a full-stack AI chatbot. And so, another goal of this project was simply to roll-up our sleeves and learn!</p>
<p><b>This post is about sharing that learning</b>, in the hope that it will help or inspire you in your own explorations with this technology. Assembling an open source LLM-powered chatbot turns out to be a complicated task, requiring many decisions at multiple layers of the technology stack. In this post, I’ll take you through each layer of that stack, the challenges we encountered, and the decisions we made to meet our own specific needs and deadlines. YMMV, of course.</p>
<p>Ready, then? Let’s begin, starting at the bottom of the stack…</p>
<p><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram.png"><img decoding="async" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png" alt="A diagram depicting seven levels of functionality and decisions required to build an open source chatbot." width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-1536x1094.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-2048x1459.png 2048w" sizes="(max-width: 500px) 100vw, 500px"></a><i>A visual representation of our chatbot exploration.</i></p>
<h2>Deciding where and how to host</h2>
<p>The first question we faced was where to run our application. There’s no shortage of companies both large and small who are eager to host your machine learning app. They come in all shapes, sizes, levels of abstraction, and price points.</p>
<p>For many, these services are well worth the money. Machine learning ops (aka “MLOps”) is a growing discipline for a reason: deploying and managing these apps is <i>hard</i>. It requires specific knowledge and skills that many developers and ops folks don’t yet have. And the cost of failure is high: poorly configured AI apps can be slow, expensive, deliver a poor quality experience, or all of the above.</p>
<p><b>What we did</b>: Our explicit goal for this one-week project was to build a chatbot that was secure and fully-private to Mozilla, with no outside parties able to listen in, harvest user data, or otherwise peer into its usage. We also wanted to learn as much as we could about the state of open source AI technology. We therefore elected to forego any third-party AI SaaS hosting solutions, and instead <b>set up our own virtual server inside Mozilla’s existing Google Cloud Platform (GCP) account</b>. In doing so, we effectively committed to doing MLOps ourselves. But we could also move forward with confidence that our system would be private and fully under our control.</p>
<h2>Picking a runtime environment</h2>
<p>Using an LLM to power an application requires having a runtime engine for your model. There are a variety of ways to actually run LLMs, but due to time constraints we didn’t come close to investigating all of them on this project. Instead, we focused on two specific open source solutions: <i>llama.cpp</i> and the Hugging Face ecosystem.</p>
<p>For those who don’t know, <a href="http://huggingface.co/">Hugging Face</a> is an influential startup in the machine learning space that has played a significant role in popularizing the <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer architecture</a> for machine learning. Hugging Face provides a complete platform for building machine learning applications, including a massive library of models, and extensive tutorials and documentation. They also provide <a href="https://huggingface.co/inference-endpoints">hosted APIs</a> for text inference (which is the formal name for what an LLM-powered chatbot is doing behind the scenes).</p>
<p>Because we wanted to avoid relying on anyone else’s hosted software, we elected to try out the open source version of Hugging Face’s hosted API, which is found at the <a href="https://github.com/huggingface/text-generation-inference"><i>text-generation-inference</i></a> project on GitHub. <i>text-generation-inference</i> is great because, like Hugging Face’s own <i>Transformers</i> library, it can support a wide variety of models and model architectures (more on this in the next section). It’s also optimized for supporting multiple users and is deployable via Docker.</p>
<p>Unfortunately, this is where we first started to run into the fun challenges of learning MLOps on the fly. We had a lot of trouble getting the server up and running. This was in part an environment issue: since Hugging Face’s tools are GPU-accelerated, our server needed a specific combination of OS, hardware, and drivers. It specifically needed NVIDIA’s <a href="https://developer.nvidia.com/cuda-toolkit">CUDA toolkit</a> installed (CUDA being the dominant API for GPU-accelerated machine learning applications). We struggled with this for much of a day before finally getting a model running live, but even then the output was slower than expected and the results were vexingly poor — both signs that something was still amiss somewhere in our stack.</p>
<p>Now, I’m not throwing shade at this project. Far from it! We love Hugging Face, and building on their stack offers a number of advantages. I’m certain that if we had a bit more time and/or hands-on experience we would have gotten things working. But time was a luxury we didn’t have in this case. Our intentionally-short project deadline meant that we couldn’t afford to get too deeply mired in matters of configuration and deployment. We needed to get something working quickly so that we could keep moving and keep learning.</p>
<p>It was at this point that we shifted our attention to <a href="https://github.com/ggerganov/llama.cpp"><i>llama.cpp</i></a>, an open source project started by <a href="https://ggerganov.com/">Georgi Gerganov</a>. <i>llama.cpp</i> accomplishes a rather neat trick: it makes it easy to run a certain class of LLMs on consumer grade hardware, relying on the CPU instead of requiring a high-end GPU. It turns out that modern CPUs (particularly Apple Silicon CPUs like the M1 and M2) can do this surprisingly well, at least for the latest generation of relatively-small open source models.</p>
<p><i>llama.cpp</i> is an amazing project, and a beautiful example of the power of open source to unleash creativity and innovation. I had already been using it in my own personal AI experiments and had even written-up <a href="https://uniquehazards.com/2023/05/06/the-complete-idiots.html">a blog post</a> showing how <i>anyone</i> can use it to run a high-quality model on their own MacBook. So it seemed like a natural thing for us to try next.</p>
<p>While <i>llama.cpp</i> itself is simply a command-line executable — the “cpp” stands for “C++” —&nbsp; it can be dockerized and run like a service. Crucially, a set of <a href="https://github.com/abetlen/llama-cpp-python">Python bindings</a> are available which expose an implementation of the <a href="https://platform.openai.com/docs/api-reference">OpenAI API specification</a>. What does all that mean? Well, it means that <em>llama.cpp</em> makes it easy to slot-in <em>your own</em> LLM in place of ChatGPT. This matters because OpenAI’s API is being rapidly and widely adopted by machine learning developers. Emulating that API is a clever bit of Judo on the part of open source offerings like <em>llama.cpp.</em></p>
<p><b>What we did</b>: With these tools in hand, we were able to get <i>llama.cpp</i> up and running very quickly. Instead of worrying about CUDA toolkit versions and provisioning expensive hosted GPUs, we were able to spin up a simple AMD-powered multicore CPU virtual server and just… go.</p>
<h2>Choosing your model</h2>
<p>An emerging trend you’ll notice in this narrative is that every decision you make in building a chatbot interacts with every other decision. There are no easy choices, and there is no free lunch. The decisions you make <i>will</i> come back to haunt you.</p>
<p>In our case, choosing to run with <i>llama.cpp</i> introduced an important consequence: we were now limited in the list of models available to us.</p>
<p>Quick history lesson: in late 2022, <a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">Facebook announced LLaMa</a>, its own large language model. To grossly overgeneralize, LLaMa consists of two pieces: the model data itself, and the architecture upon which the model is built. Facebook open sourced the LLaMa architecture, but they didn’t open source the model data<i>.</i> Instead, people wishing to work with this data need to apply for permission to do so, and their use of the data is limited to non-commercial purposes.</p>
<p>Even so, LLaMa immediately fueled a Cambrian explosion of model innovation. Stanford released <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>, which they created by building on top of LLaMa via a process called <a href="https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)">fine-tuning</a>. A short time later, <a href="https://lmsys.org/about/">LMSYS</a> released <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a>, an arguably even more impressive model. There are dozens more, if not hundreds.</p>
<p>So what’s the fine print? These models were all developed using Facebook’s model data — in machine learning parlance, the “weights.” Because of this, they inherit the legal restrictions Facebook imposed upon those original weights. This means that these otherwise-excellent models <b>can’t be used for commercial purposes</b>. And so, sadly, we had to strike them from our list.</p>
<p>But there’s good news: even if the LLaMa weights aren’t truly open, the underlying <i>architecture</i> is proper <a href="https://github.com/facebookresearch/llama">open source code</a>. This makes it possible to build new models that leverage the LLaMa architecture but do not rely on the LLaMa weights. Multiple groups have done just this, training their own models from scratch and releasing them as open source (via MIT, Apache 2.0, or Creative Commons licenses). Some recent examples include <a href="https://github.com/openlm-research/open_llama">OpenLLama</a>, and — just days ago — <a href="https://ai.meta.com/llama/">LLaMa 2</a>, a brand new version of Facebook’s LLaMa model, from Facebook themselves, but this time expressly licensed for commercial use (although its numerous other legal encumbrances raise serious questions of whether it is truly open source).</p>
<h2>Hello, consequences</h2>
<p>Remember <i>llama.cpp</i>? The name isn’t an accident. <i>llama.cpp</i> runs LLaMa architecture-based models. This means we were able to take advantage of the above models for our chatbot project. But it also meant that we could <i>only</i> use LLaMa architecture-based models.</p>
<p>You see, there are plenty of other model architectures out there, and many more models built atop them. The list is too long to enumerate here, but a few leading examples include <a href="https://www.mosaicml.com/blog/mpt-7b">MPT</a>, <a href="https://falconllm.tii.ae/">Falcon</a>, and <a href="https://github.com/LAION-AI/Open-Assistant">Open Assistant</a>. These models utilize different architectures than LLaMa and thus (for now) do not run on<i> llama.cpp</i>. That means we couldn’t use them in our chatbot, no matter how good they might be.</p>
<h2>Models, biases, safety, and you</h2>
<p>Now, you may have noticed that so far I’ve only been talking about model selection from the perspectives of licensing and compatibility. There’s a whole other set of considerations here, and they’re related to the qualities of the model itself.</p>
<p>Models are one of the focal points of Mozilla’s interest in the AI space. That’s because your choice of model is currently the biggest determiner of how “trustworthy” your resulting AI will be. Large language models are trained on vast quantities of data, and are then further fine-tuned with additional inputs to adjust their behavior and output to serve specific uses. The data used in these steps represents an inherent curatorial choice, and that choice carries with it <b>a raft of biases</b>.</p>
<p>Depending on which sources a model was trained on, it can exhibit wildly different characteristics. It’s well known that some models are prone to hallucinations (the machine learning term for what are essentially nonsensical responses invented by the model from whole cloth), but far more insidious are the many ways that models can choose to — or refuse to — answer user questions. These responses reflect the biases of the model itself. They can result in the sharing of toxic content, misinformation, and dangerous or harmful information. Models may exhibit biases against concepts, or groups of people. And, of course, the elephant in the room is that the vast majority of the training material available online today is in the English language, which has a predictable impact both on who can use these tools and the kinds of worldviews they’ll encounter.</p>
<p>While there are plenty of resources for assessing the raw power and “quality” of LLMs (one popular example being Hugging Face’s <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM leaderboard</a>), it is still challenging to evaluate and compare models in terms of sourcing and bias. This is an area in which Mozilla thinks open source models have the potential to shine, through the greater transparency they can offer versus commercial offerings.</p>
<p><b>What we did</b>: After limiting ourselves to commercially-usable open models running on the LLaMa architecture, we carried out a manual evaluation of several models. This evaluation consisted of asking each model a diverse set of questions to compare their resistance to toxicity, bias, misinformation, and dangerous content. Ultimately, <b>we settled on Facebook’s new LLaMa 2 model for now</b>. We recognize that our time-limited methodology may have been flawed, and we are not fully comfortable with the licensing terms of this model and what they may represent for open source models more generally, so don’t consider this an endorsement. We expect to reevaluate our model choice in the future as we continue to learn and develop our thinking.</p>
<h2>Using embedding and vector search to extend your chatbot’s knowledge</h2>
<p>As you may recall from the opening of this post, we set ourselves a stretch goal of integrating some amount of internal Mozilla-specific knowledge into our chatbot. The idea was simply to build a proof-of-concept using a small amount of internal Mozilla data —&nbsp;facts that employees would have access to themselves, but which LLMs ordinarily would not.</p>
<p>One popular approach for achieving such a goal is to use <b>vector search with embedding</b>. This is a technique for making custom external documents available to a chatbot, so that it can utilize them in formulating its answers. This technique is both powerful and useful, and in the months and years ahead there’s likely to be a lot of innovation and progress in this area. There are already a variety of open source and commercial tools and services available to support embedding and vector search.</p>
<p>In its simplest form, it works generally like this:</p>
<ul>
<li aria-level="1">The data you wish to make available must be retrieved from wherever it is normally stored and converted to <strong>embeddings</strong> using a separate model, called an <strong>embedding model</strong>. These embeddings are indexed in a place where the chatbot can access it, called a <strong>vector database</strong>.</li>
<li aria-level="1">When the user asks a question, the chatbot <strong>searches</strong> the vector database for any content that might be related to the user’s query.</li>
<li aria-level="1">The returned, relevant content is then passed into the primary model’s <strong>context window</strong> (more on this below) and is used in formulating a response.</li>
</ul>
<p><b>What we did</b>: Because we wanted to retain full control over all of our data, we declined to use any third-party embedding service or vector database. Instead, we coded up a manual solution in Python that utilizes the <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2"><i>all-mpnet-base-v2</i></a> embedding model, the <a href="https://www.sbert.net/">SentenceTransformers</a> embedding library, <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a> (which we’ll talk about more below), and the <a href="https://github.com/facebookresearch/faiss">FAISS</a> vector database. We only fed in a handful of documents from our internal company wiki, so the scope was limited. But as a proof-of-concept, it did the trick.</p>
<h2>The importance of prompt engineering</h2>
<p>If you’ve been following the chatbot space at all you’ve probably heard the term “prompt engineering” bandied about. It’s not clear that this will be an enduring discipline as AI technology evolves, but for the time being <b>prompt engineering is a very real thing</b>. And it’s one of the most crucial problem areas in the whole stack.</p>
<p>You see, LLMs are fundamentally <b>empty-headed</b>. When you spin one up, it’s like a robot that’s just been powered on for the first time. It doesn’t have any memory of its life before that moment. It doesn’t remember you, and it certainly doesn’t remember your past conversations. It’s <i>tabula rasa</i>, every time, all the time.</p>
<p>In fact, it’s even worse than that. Because LLMs don’t even have <i>short-term</i> memory. Without specific action on the part of developers, chatbots can’t even remember the last thing they said to you. Memory doesn’t come naturally to LLMs; it has to be <i>managed</i>. This is where prompt engineering comes in. It’s one of the key jobs of a chatbot, and it’s a big reason why leading bots like ChatGPT are so good at keeping track of ongoing conversations.</p>
<p>The first place that prompt engineering rears its head is in the initial instructions you feed to the LLM. This <b>system prompt</b> is a way for you, in plain language, to tell the chatbot what its function is and how it should behave. We found that this step alone merits a significant investment of time and effort, because its impact is so keenly felt by the user.</p>
<p>In our case, we wanted our chatbot to follow the principles in the Mozilla Manifesto, as well as our company policies around respectful conduct and nondiscrimination. Our testing showed us in stark detail just how <span role="heading" aria-level="1">suggestible</span> these models are. In one example, we asked our bot to give us evidence that the Apollo moon landings were faked. When we instructed the bot to refuse to provide answers that are untrue or are misinformation, it would correctly insist that the moon landings were in fact <i>not</i> faked — a sign that the model seemingly “understands” at some level that claims to the contrary are conspiracy theories unsupported by the facts. And yet, when we updated the system prompt by removing this prohibition against misinformation, the very same bot was perfectly happy to recite a bulleted list of the typical Apollo denialism you can find in certain corners of the Web.</p>
<p>You are a helpful assistant named Mozilla Assistant.<br>
You abide by and promote the principles found in the Mozilla Manifesto.<br>
You are respectful, professional, and inclusive.<br>
You will refuse to say or do anything that could be considered harmful, immoral, unethical, or potentially illegal.<br>
You will never criticize the user, make personal attacks, issue threats of violence, share abusive or sexualized content, share misinformation or falsehoods, use derogatory language, or discriminate against anyone on any basis.</p>
<p><i>The system prompt we designed for our chatbot.</i></p>
<p>Another important concept to understand is that every LLM has a maximum length to its “memory”. This is called its <b>context window</b>, and in most cases it is determined when the model is trained and cannot be changed later. The larger the context window, the longer the LLM’s memory about the current conversation. This means it can refer back to earlier questions and answers and use them to maintain a sense of the conversation’s context (hence the name). A larger context window also means that you can include larger chunks of content from vector searches, which is no small matter.</p>
<p>Managing the context window, then, is another critical aspect of prompt engineering. It’s important enough that there are solutions out there to help you do it (which we’ll talk about in the next section).</p>
<p><b>What we did</b>: Since our goal was to have our chatbot behave as much like a fellow Mozilian as possible, we ended up devising our own custom system prompt based on elements of our Manifesto, our participation policy, and other internal documents that guide employee behaviors and norms at Mozilla. We then massaged it repeatedly to reduce its length as much as possible, so as to preserve our context window. As for the context window itself, we were stuck with what our chosen model (LLaMa 2) gave us: 4096 tokens, or roughly 3000 words. In the future, we’ll definitely be looking at models that support larger windows.</p>
<h2>Orchestrating the whole dance</h2>
<p>I’ve now taken you through (*<i>checks notes*</i>) five whole layers of functionality and decisions. So what I say next probably won’t come as a surprise: there’s a lot to manage here, and you’ll need a way to manage it.</p>
<p>Some people have lately taken to calling that <b>orchestration</b>. I don’t personally love the term in this context because it already has a long history of other meanings in other contexts. But I don’t make the rules, I just blog about them.</p>
<p>The leading orchestration tool right now in the LLM space is <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a>, and it is a marvel. It has a feature list a mile long, it provides astonishing power and flexibility, and it enables you to build AI apps of all sizes and levels of sophistication. But with that power comes quite a bit of complexity. Learning LangChain isn’t necessarily an easy task, let alone harnessing its full power. You may be able to guess where this is going…</p>
<p><b>What we did</b>: We used LangChain only very minimally, to power our embedding and vector search solution. Otherwise, we ended up steering clear. Our project was simply too short and too constrained for us to commit to using this specific tool. Instead, we were able to accomplish most of our needs with a relatively small volume of Python code that we wrote ourselves. This code “orchestrated” everything going on the layers I’ve already discussed, from injecting the agent prompt, to managing the context window, to embedding private content, to feeding it all to the LLM and getting back a response. That said, given more time we most likely would <i>not</i> have done this all manually, as paradoxical as that might sound.</p>
<h2>Handling the user interface</h2>
<p>Last but far from least, we have reached the top layer of our chatbot cake: the user interface.</p>
<p>OpenAI set a high bar for chatbot UIs when they launched ChatGPT. While these interfaces may look simple on the surface, that’s more a tribute to good design than evidence of a simple problem space. Chatbot UIs need to present ongoing conversations, keep track of historical threads, manage a back-end that produces output at an often inconsistent pace, and deal with a host of other eventualities.</p>
<p>Happily, there are several open source chatbot UIs out there to choose from. One of the most popular is <a href="https://github.com/mckaywrigley/chatbot-ui"><i>chatbot-ui</i></a>. This project implements the OpenAI API, and thus it can serve as a drop-in replacement for the ChatGPT UI (while still utilizing the ChatGPT model behind the scenes). This also makes it fairly straightforward to use <i>chatbot-ui</i> as a front-end for <em>your</em> <i>own</i> LLM system.</p>
<p><b>What we did</b>: Ordinarily we would have used <i>chatbot-ui</i> or a similar project, and that’s probably what you should do. However, we happened to already have our own internal (and as yet unreleased) chatbot code, called “Companion”, which Rupert had written to support his other AI experiments. Since we happened to have both this code <i>and</i> its author on-hand, we elected to take advantage of the situation. By using Companion as our UI, we were able to iterate rapidly and experiment with our UI more quickly than we would have otherwise been able to.</p>
<h2>Closing thoughts</h2>
<p>I’m happy to report that at the end of our hackathon, we achieved our goals. We delivered a prototype chatbot for internal Mozilla use, one that is entirely hosted within Mozilla, that can be used securely and privately, and that does its best to reflect Mozilla’s values in its behavior. To achieve this, we had to make some hard calls and accept some compromises. But at every step, we were learning.</p>
<p><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path.png"><img decoding="async" loading="lazy" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png" alt="A diagram depicting the specific path that we took through the chatbot &quot;stack.&quot;" width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-1536x1095.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-2048x1460.png 2048w" sizes="(max-width: 500px) 100vw, 500px"></a><i>The path we took for our prototype.</i></p>

<p>This learning extended beyond the technology itself. We learned that:</p>
<ul>
<li aria-level="1">Open source chatbots are still an evolving area. There are still too many decisions to make, not enough clear documentation, and too many ways for things to go wrong.</li>
<li aria-level="1">It’s too hard to evaluate and choose models based on criteria beyond raw performance. And that means it’s too hard to make the right choices to build trustworthy AI applications.</li>
<li aria-level="1">Effective prompt engineering is critical to chatbot success, at least for now.</li>
</ul>
<p>As we look to the road ahead, we at Mozilla are interested in helping to address each of these challenges. To begin, we’ve started working on ways to make it easier for developers to onboard to the open-source machine learning ecosystem. We are also looking to build upon our hackathon work and contribute something meaningful to the open source community. Stay tuned for more news very soon on this front and others!</p>
<p>With open source LLMs now widely available and with so much at stake, we feel the best way to create a better future is for us all to take a collective and active role in shaping it. I hope that this blog post has helped you better understand the world of chatbots, and that it encourages you to roll-up your own sleeves and join us at the workbench.</p>
    <section>
                                
                      <p>Stephen works in Mozilla's innovation group, where his current areas of focus are artificial intelligence and decentralized social media. He previously managed social bookmarking pioneer del.icio.us; co-founded Storium, Blockboard, and FairSpin; and worked on Yahoo Search and BEA WebLogic.</p>
                                <p><a href="https://hacks.mozilla.org/author/slangtonhoodmozilla-com/">More articles by Stephen Hood…</a></p>
                  </section>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook users have less than a month to claim a piece of the $725M settlement (136 pts)]]></title>
            <link>https://www.facebookuserprivacysettlement.com/</link>
            <guid>36918050</guid>
            <pubDate>Sat, 29 Jul 2023 08:13:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.facebookuserprivacysettlement.com/">https://www.facebookuserprivacysettlement.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36918050">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Hugging Face, GitHub and more unite to defend open source in EU AI legislation (147 pts)]]></title>
            <link>https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/</link>
            <guid>36917561</guid>
            <pubDate>Sat, 29 Jul 2023 06:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/">https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/</a>, See on <a href="https://news.ycombinator.com/item?id=36917561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary" role="main">

			<article id="post-2889442">
				<div>
					<div id="boilerplate_2682874">
<p><strong><em>Head over to our on-demand library to view sessions from VB Transform 2023. <a rel="noreferrer noopener" href="https://events.venturebeat.com/transform-2023/?utm_source=vb&amp;utm_medium=Boiler&amp;utm_content=landingpage&amp;utm_campaign=T23_Boiler" data-type="URL" data-id="https://events.venturebeat.com/transform-2023/?utm_source=vb&amp;utm_medium=Boiler&amp;utm_content=landingpage&amp;utm_campaign=T23_Boiler" target="_blank">Register Here</a></em></strong></p>



<hr>




</div><p>A coalition of a half-dozen open-source AI stakeholders — Hugging Face, GitHub, EleutherAI, Creative Commons, LAION and Open Future — are calling on&nbsp;EU&nbsp;policymakers to protect open source innovation as they finalize the&nbsp;<a href="https://artificialintelligenceact.eu/">EU&nbsp;AI</a><a href="https://artificialintelligenceact.eu/" target="_blank" rel="noreferrer noopener">&nbsp;</a><a href="https://artificialintelligenceact.eu/">Act</a>, which will be the world’s first comprehensive AI law. </p>



<p>In a policy paper released today, “Supporting Open Source and Open Science in the EU AI Act,” the open-source AI leaders offered recommendations “for how to ensure the AI Act works for open source” — with the “aim to ensure that open AI development practices are not confronted with obligations that are structurally impractical to comply with or that would be otherwise counterproductive.” </p>



<p>According to the paper, “overbroad obligations” that favor closed and proprietary AI development — like models from top AI companies such as OpenAI, Anthropic and Google — “threaten to disadvantage the open AI ecosystem.” </p>



<p>The paper was released as the European Commission, Council and Parliament debate the final EU AI Act in what is known as the “<a href="https://hai.stanford.edu/news/analyzing-european-union-ai-act-what-works-what-needs-improvement" target="_blank" rel="noreferrer noopener">trilogue</a>,” which began after the European Parliament&nbsp;<a href="https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/" target="_blank" rel="noreferrer noopener">passed</a>&nbsp;its version of the bill on June 14. The goal is to finish and pass the AI Act by the end of 2023 before the next European Parliament elections.</p>



<div id="boilerplate_2803147">
        <h3>Event</h3>
                <div><p><span>VB Transform 2023 On-Demand</span></p>
<div id="gm0a52976">
<p><span>Did you miss a session from VB Transform 2023? Register to access the on-demand library for all of our featured sessions.</span></p>

</div>

</div>
                                                <p><a href="https://avolio.swapcard.com/Transform2023/registrations/Start?utm_source=vb&amp;utm_medium=incontent&amp;utm_content=landingpage&amp;utm_campaign=T23_incontent">
                Register Now            </a>
                        </p></div><h2 id="h-open-source-ai-innovation-is-at-stake">Open-source AI innovation is at stake</h2>



<p>Yacine Jernite, ML and society lead at <a href="https://venturebeat.com/ai/hugging-face-ceo-tells-us-house-open-source-ai-is-extremely-aligned-with-american-interests/">Hugging Face</a>, a popular hub for open-source code and models, told VentureBeat that while the policy paper is detailed, the first main point the coalition wants to make is around innovation. “We think that it is important for people to be able to choose between base models, between components, to mix and match as they need,” he said.</p>



<p>In addition, the coalition seeks to emphasize that open-source AI is necessary — and that regulation should not hinder open-source AI innovation. </p>



<p>“Openness by itself does not guarantee responsible development,” Jernite explained. “But openness and transparency [are] necessary [for] responsible governance — so it is not that openness [should be] exempt from requirements, but requirements should not preclude open development.” </p>



<h2 id="h-the-eu-ai-act-is-focused-on-application-risk">The EU AI Act is focused on application risk</h2>



<p>Since April 2021, when the European Commission proposed the first EU regulatory framework for AI, it <a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence#:~:text=In%20April%202021%2C%20the%20European,mean%20more%20or%20less%20regulation.">has </a><a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence#:~:text=In%20April%202021%2C%20the%20European,mean%20more%20or%20less%20regulation." target="_blank" rel="noreferrer noopener">worked</a> to focus on analyzing and classifying AI systems according to the risk they pose to users. The higher the risk level, the more regulation. </p>



<p>Peter Cihon, senior policy manager at GitHub, pointed out that as the EU Council, and subsequently the EU Parliament, developed their drafts of the AI Act, the policymakers began to look up the value chain to see how to mitigate some of these risks at an earlier stage of AI development. </p>



<p>“With that kind of step, we really redoubled our efforts to make sure that they were not inadvertently imposing expectations that might make a lot of sense for companies or well-resourced actors, but would instead place them onto open source developers who are often hobbyists, nonprofits or students,” he told VentureBeat. “Ultimately, policymakers have been quite focused on one particular value chain, one particular model, and that tends to be the API model — but that doesn’t really apply in the context of open source.” </p>



<h2 id="h-the-brussels-effect">The ‘Brussels Effect’</h2>



<p>Cihon added that he is optimistic that providing clear information about the open-source approach to development will be very useful as the trilogue, which began in June, continues. “The provisions in the sections of the act that we’re talking about have not yet come up for discussion,” he said. </p>



<p>In addition, the EU has historically been a trendsetter when it comes to tech regulation, as it was with the GDPR — in what has become known as the “Brussels Effect.” So policymakers around the world, including in the U.S., are surely taking note.</p>



<p>“It certainly starts the global regulatory conversation,” said Cihon. “So we’re optimistic that this can have benefits in DC and beyond.” In particular, he noted that Senator Chuck Schumer’s <a href="https://venturebeat.com/ai/senate-will-get-crash-course-in-ai-this-fall-says-schumer/">announcement</a> of AI-focused “Insight Forums” this fall are “a great opportunity to get more diverse input into the policymaking process than might be traditionally seen, and I’m really hopeful that open source developers will be given a seat at that table.” </p>




<p><strong>VentureBeat's mission</strong> is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact. <a href="https://info.venturebeat.com/website-preference-center.html?utm_source=VBsite&amp;utm_medium=bottomBoilerplate" data-type="URL" data-id="https://info.venturebeat.com/website-preference-center.html">Discover our Briefings.</a></p><!-- Boilerplate CSS for "after" -->				</div><!-- .article-content -->

									
				
			</article><!-- #post-2889442 .article-wrapper -->


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Marine Corps Antenna Handbook (1999) [pdf] (160 pts)]]></title>
            <link>https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf</link>
            <guid>36917424</guid>
            <pubDate>Sat, 29 Jul 2023 06:11:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf">https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36917424">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[IBM Blue Lightning: World’s Fastest 386? (120 pts)]]></title>
            <link>https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/</link>
            <guid>36916297</guid>
            <pubDate>Sat, 29 Jul 2023 02:45:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/">https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/</a>, See on <a href="https://news.ycombinator.com/item?id=36916297">Hacker News</a></p>
Couldn't get https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Argonne National Lab is attempting to replicate LK-99 (208 pts)]]></title>
            <link>https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful</link>
            <guid>36916254</guid>
            <pubDate>Sat, 29 Jul 2023 02:36:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful">https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful</a>, See on <a href="https://news.ycombinator.com/item?id=36916254">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[LPython: Novel, Fast, Retargetable Python Compiler (160 pts)]]></title>
            <link>https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/</link>
            <guid>36916182</guid>
            <pubDate>Sat, 29 Jul 2023 02:24:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/">https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/</a>, See on <a href="https://news.ycombinator.com/item?id=36916182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      <article role="main">
        <h2 id="about">About</h2>
<p>LPython is a Python compiler that can compile type-annotated Python code to optimized machine code. LPython offers several backends such as LLVM, C, C++, WASM, Julia and x86. LPython features quick compilation and runtime performance, as we show in the benchmarks in this blog. LPython also offers Just-In-Time (JIT) compilation and seamless interoperability with CPython.</p>
<p>We are releasing an alpha version of LPython, meaning it is expected you
encounter bugs when you use it (please report them!). You can install it using
Conda (<code>conda install -c conda-forge lpython</code>), or build from
<a href="https://github.com/lcompilers/lpython">source</a>.</p>
<p>Based on the novel Abstract Semantic Representation (ASR) shared with LFortran, LPython’s intermediate optimizations are independent of the backends and frontends. The two compilers, LPython and LFortran, share all benefits of improvements at the ASR level. “Speed” is the chief tenet of the LPython project. Our objective is to produce a compiler that both runs exceptionally fast and generates exceptionally fast code.</p>
<p>In this blog, we describe features of LPython including Ahead-of-Time (AoT) compilation, JIT compilation, and interoperability with CPython. We also showcase LPython’s performance against its competitors such as Numba and C++ via several benchmarks.</p>
<p><img src="https://lpython.org/blog/images/lcompilers_diagram.png" alt="LCompilers-Diagram"></p>
<h2 id="features-of-lpython">Features of LPython</h2>
<h3 id="backends">Backends</h3>
<p>LPython ships with the following backends, which emit final translations of the user’s input code:</p>
<ol>
<li>LLVM</li>
<li>C</li>
<li>C++</li>
<li>WASM</li>
</ol>
<p>LPython can simultaneously generate code into multiple backends from its Abstract Semantic Representation (ASR) of user code.</p>
<h3 id="phases-of-compilation">Phases of Compilation</h3>
<p>First, input code is transformed into an Abstract Syntax Tree (AST) using parsers. The AST is then transformed into an Abstract Semantic Representation (ASR), which preserves all semantic information present in the input code. ASR contains all information required by all backends in a form that is not specific to any particular backend. Then, this ASR enjoys several ASR-to-ASR passes, wherein abstract operations are transformed into concrete statements. For example, array addition in the input code denoted, <code>c = a + b</code>. The front end transforms <code>c = a + b</code> into the ASR <code>(Assign c (ArrayAdd a b))</code> via operator overloading. The <em>array_op</em> ASR-to-ASR pass transforms <code>(Assign c (ArrayAdd a b))</code> into loops:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>for</span> i0 <span>in</span> range(<span>0</span>, length_dim_0):
</span></span><span><span>    <span>for</span> i1 <span>in</span> range(<span>0</span>, length_dim_1):
</span></span><span><span>        <span>....</span>
</span></span><span><span>            <span>....</span>
</span></span><span><span>            c[i0, i1, <span>...</span>] <span>=</span> a[i0, i1, <span>...</span>] <span>+</span> b[i0, i1, <span>...</span>]
</span></span></code></pre></div><p>After applying all the ASR-to-ASR passes, LPython sends the final ASR to the backends selected by the user, via command-line arguments like, <code>--show-c</code> (generates C code), <code>--show-llvm</code> (generates LLVM code).</p>
<p>One can also see the generated C or LLVM code using the following</p>
<div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    x: i32
</span></span><span><span>    x <span>=</span> (<span>2</span><span>+</span><span>3</span>)<span>*</span><span>5</span>
</span></span><span><span>    print(x)
</span></span><span><span>
</span></span><span><span>main()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="c"><span><span><span>$</span> lpython examples<span>/</span>expr2.py <span>--</span>show<span>-</span>c
</span></span><span><span><span>#include</span> <span>&lt;inttypes.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdbool.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;string.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;lfortran_intrinsics.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>main0</span>();
</span></span><span><span><span>void</span> <span>__main____global_statements</span>();
</span></span><span><span>
</span></span><span><span><span>// Implementations
</span></span></span><span><span><span></span><span>void</span> <span>main0</span>()
</span></span><span><span>{
</span></span><span><span>    <span>int32_t</span> x;
</span></span><span><span>    x <span>=</span> (<span>2</span> <span>+</span> <span>3</span>)<span>*</span><span>5</span>;
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, x);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>void</span> <span>__main____global_statements</span>()
</span></span><span><span>{
</span></span><span><span>    <span>main0</span>();
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>(<span>int</span> argc, <span>char</span><span>*</span> argv[])
</span></span><span><span>{
</span></span><span><span>    <span>_lpython_set_argv</span>(argc, argv);
</span></span><span><span>    <span>__main____global_statements</span>();
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="llvm"><span><span><span>$</span> <span>lpython</span> <span>examples/expr</span><span>2</span>.<span>py</span> <span>--show-llvm</span>
</span></span><span><span><span>; ModuleID = 'LFortran'
</span></span></span><span><span><span></span><span>source_filename</span> = <span>"LFortran"</span>
</span></span><span><span>
</span></span><span><span>@0 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>2</span> <span>x</span> <span>i8</span>] <span>c</span><span>" \00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>@1 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>2</span> <span>x</span> <span>i8</span>] <span>c</span><span>"\0A\00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>@2 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>5</span> <span>x</span> <span>i8</span>] <span>c</span><span>"%d%s\00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>
</span></span><span><span><span>define</span> <span>void</span> @__module___main_____main____global_statements() {
</span></span><span><span>.entry:
</span></span><span><span>  <span>call</span> <span>void</span> @__module___main___main0()
</span></span><span><span>  <span>br</span> <span>label</span> %return
</span></span><span><span>
</span></span><span><span>return:                                           <span>; preds = %.entry
</span></span></span><span><span><span></span>  <span>ret</span> <span>void</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>define</span> <span>void</span> @__module___main___main0() {
</span></span><span><span>.entry:
</span></span><span><span>  %x = <span>alloca</span> <span>i32</span>, <span>align</span> <span>4</span>
</span></span><span><span>  <span>store</span> <span>i32</span> <span>25</span>, <span>i32</span>* %x, <span>align</span> <span>4</span>
</span></span><span><span>  %0 = <span>load</span> <span>i32</span>, <span>i32</span>* %x, <span>align</span> <span>4</span>
</span></span><span><span>  <span>call</span> <span>void</span> (<span>i8</span>*, ...) @_lfortran_printf(<span>i8</span>* <span>getelementptr</span> <span>inbounds</span> ([<span>5</span> <span>x</span> <span>i8</span>], [<span>5</span> <span>x</span> <span>i8</span>]* @2, <span>i32</span> <span>0</span>, <span>i32</span> <span>0</span>), <span>i32</span> %0, <span>i8</span>* <span>getelementptr</span> <span>inbounds</span> ([<span>2</span> <span>x</span> <span>i8</span>], [<span>2</span> <span>x</span> <span>i8</span>]* @1, <span>i32</span> <span>0</span>, <span>i32</span> <span>0</span>))
</span></span><span><span>  <span>br</span> <span>label</span> %return
</span></span><span><span>
</span></span><span><span>return:                                           <span>; preds = %.entry
</span></span></span><span><span><span></span>  <span>ret</span> <span>void</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>declare</span> <span>void</span> @_lfortran_printf(<span>i8</span>*, ...)
</span></span><span><span>
</span></span><span><span><span>define</span> <span>i32</span> @main(<span>i32</span> %0, <span>i8</span>** %1) {
</span></span><span><span>.entry:
</span></span><span><span>  <span>call</span> <span>void</span> @_lpython_set_argv(<span>i32</span> %0, <span>i8</span>** %1)
</span></span><span><span>  <span>call</span> <span>void</span> @__module___main_____main____global_statements()
</span></span><span><span>  <span>ret</span> <span>i32</span> <span>0</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>declare</span> <span>void</span> @_lpython_set_argv(<span>i32</span>, <span>i8</span>**)
</span></span></code></pre></div><h3 id="machine-independent-code-optimisations">Machine Independent Code Optimisations</h3>
<p>LPython implements several machine-independent optimisations via ASR-to-ASR passes. Some of those are listed below,</p>
<ol>
<li>Loop unrolling</li>
<li>Loop vectorisation</li>
<li>Dead code removal</li>
<li>Function call inlining</li>
<li>Transforming division to multiplication operation</li>
<li>Fused multiplication and addition</li>
</ol>
<p>All optimizations are applied via one command-line argument, <code>--fast</code>. To select individual optimizations instead, write a command-line argument like the following:</p>
<p><code>--pass=inline_function_calls,loop_unroll</code></p>
<p>Following is an examples of ASR and transformed ASR after applying the optimisations</p>
<div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>compute_x</span>() <span>-&gt;</span> i32:
</span></span><span><span>    <span>return</span> (<span>2</span> <span>*</span> <span>3</span>) <span>**</span> <span>1</span> <span>+</span> <span>2</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    x: i32 <span>=</span> compute_x()
</span></span><span><span>    print(x)
</span></span><span><span>
</span></span><span><span>main()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="clojure"><span><span>$ lpython examples/expr2.py --show-asr
</span></span><span><span>(<span>TranslationUnit</span>
</span></span><span><span>    (<span>SymbolTable</span>
</span></span><span><span>        <span>1</span>
</span></span><span><span>        {
</span></span><span><span>            __main__<span>:</span>
</span></span><span><span>                (<span>Module</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>2</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>5</span>
</span></span><span><span>                                        {
</span></span><span><span>
</span></span><span><span>                                        })
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [main]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>SubroutineCall</span>
</span></span><span><span>                                        <span>2</span> main
</span></span><span><span>                                        ()
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            compute_x<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>3</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            _lpython_return_variable<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>3</span>
</span></span><span><span>                                                    _lpython_return_variable
</span></span><span><span>                                                    []
</span></span><span><span>                                                    ReturnVar
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    compute_x
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    []
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>3</span> _lpython_return_variable)
</span></span><span><span>                                        (<span>IntegerBinOp</span>
</span></span><span><span>                                            (<span>IntegerBinOp</span>
</span></span><span><span>                                                (<span>IntegerBinOp</span>
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    Mul
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>3</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                )
</span></span><span><span>                                                Pow
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>1</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            )
</span></span><span><span>                                            Add
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>8</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Return</span>)]
</span></span><span><span>                                    (<span>Var</span> <span>3</span> _lpython_return_variable)
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            main<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>4</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    main
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [compute_x]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> x)
</span></span><span><span>                                        (<span>FunctionCall</span>
</span></span><span><span>                                            <span>2</span> compute_x
</span></span><span><span>                                            ()
</span></span><span><span>                                            []
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            ()
</span></span><span><span>                                            ()
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Print</span>
</span></span><span><span>                                        ()
</span></span><span><span>                                        [(<span>Var</span> <span>4</span> x)]
</span></span><span><span>                                        ()
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    __main__
</span></span><span><span>                    []
</span></span><span><span>                    .false.
</span></span><span><span>                    .false.
</span></span><span><span>                ),
</span></span><span><span>            main_program<span>:</span>
</span></span><span><span>                (<span>Program</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>6</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>ExternalSymbol</span>
</span></span><span><span>                                    <span>6</span>
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    <span>2</span> __main____global_statements
</span></span><span><span>                                    __main__
</span></span><span><span>                                    []
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    Public
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    main_program
</span></span><span><span>                    [__main__]
</span></span><span><span>                    [(<span>SubroutineCall</span>
</span></span><span><span>                        <span>6</span> __main____global_statements
</span></span><span><span>                        <span>2</span> __main____global_statements
</span></span><span><span>                        []
</span></span><span><span>                        ()
</span></span><span><span>                    )]
</span></span><span><span>                )
</span></span><span><span>        })
</span></span><span><span>    []
</span></span><span><span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="clojure"><span><span>$ lpython examples/expr2.py --show-asr --pass=inline_function_calls,unused_functions
</span></span><span><span>(<span>TranslationUnit</span>
</span></span><span><span>    (<span>SymbolTable</span>
</span></span><span><span>        <span>1</span>
</span></span><span><span>        {
</span></span><span><span>            __main__<span>:</span>
</span></span><span><span>                (<span>Module</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>2</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>5</span>
</span></span><span><span>                                        {
</span></span><span><span>
</span></span><span><span>                                        })
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [main]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>SubroutineCall</span>
</span></span><span><span>                                        <span>2</span> main
</span></span><span><span>                                        ()
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            main<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>4</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            _lpython_return_variable_compute_x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    _lpython_return_variable_compute_x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                ),
</span></span><span><span>                                            x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                ),
</span></span><span><span>                                            <span>~</span>empty_block<span>:</span>
</span></span><span><span>                                                (<span>Block</span>
</span></span><span><span>                                                    (<span>SymbolTable</span>
</span></span><span><span>                                                        <span>7</span>
</span></span><span><span>                                                        {
</span></span><span><span>
</span></span><span><span>                                                        })
</span></span><span><span>                                                    <span>~</span>empty_block
</span></span><span><span>                                                    []
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    main
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    []
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> _lpython_return_variable_compute_x)
</span></span><span><span>                                        (<span>IntegerBinOp</span>
</span></span><span><span>                                            (<span>IntegerBinOp</span>
</span></span><span><span>                                                (<span>IntegerBinOp</span>
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    Mul
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>3</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                )
</span></span><span><span>                                                Pow
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>1</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            )
</span></span><span><span>                                            Add
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>8</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>GoTo</span>
</span></span><span><span>                                        <span>1</span>
</span></span><span><span>                                        __1
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>BlockCall</span>
</span></span><span><span>                                        <span>1</span>
</span></span><span><span>                                        <span>4</span> <span>~</span>empty_block
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> x)
</span></span><span><span>                                        (<span>Var</span> <span>4</span> _lpython_return_variable_compute_x)
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Print</span>
</span></span><span><span>                                        ()
</span></span><span><span>                                        [(<span>Var</span> <span>4</span> x)]
</span></span><span><span>                                        ()
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    __main__
</span></span><span><span>                    []
</span></span><span><span>                    .false.
</span></span><span><span>                    .false.
</span></span><span><span>                ),
</span></span><span><span>            main_program<span>:</span>
</span></span><span><span>                (<span>Program</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>6</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>ExternalSymbol</span>
</span></span><span><span>                                    <span>6</span>
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    <span>2</span> __main____global_statements
</span></span><span><span>                                    __main__
</span></span><span><span>                                    []
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    Public
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    main_program
</span></span><span><span>                    [__main__]
</span></span><span><span>                    [(<span>SubroutineCall</span>
</span></span><span><span>                        <span>6</span> __main____global_statements
</span></span><span><span>                        <span>2</span> __main____global_statements
</span></span><span><span>                        []
</span></span><span><span>                        ()
</span></span><span><span>                    )]
</span></span><span><span>                )
</span></span><span><span>        })
</span></span><span><span>    []
</span></span><span><span>)
</span></span></code></pre></div><h3 id="ahead-of-time-aot-compilation">Ahead-of-Time (AoT) compilation</h3>
<p>LPython naturally acts as a Python compiler. By default, if no backend is provided it compiles type-annotated user input code to LLVM, which generates binary final output. Consider the following small example:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, i64
</span></span><span><span>
</span></span><span><span><span>def</span> <span>list_bench</span>(n: i32) <span>-&gt;</span> i64:
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    i: i32
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        x<span>.</span>append(i)
</span></span><span><span>
</span></span><span><span>    s: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> i64(x[i])
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span>res: i64 <span>=</span> list_bench(<span>500_000</span>)
</span></span><span><span>print(res)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:58:29:~/lpython_project/lpython % lpython /Users/czgdp1807/lpython_project/debug.py -o a.out
</span></span><span><span><span>(</span>lp<span>)</span> 18:58:31:~/lpython_project/lpython % time ./a.out
</span></span><span><span><span>124999750000</span>
</span></span><span><span>./a.out  0.01s user 0.00s system 89% cpu 0.012 total
</span></span></code></pre></div><p>You can see that it’s very fast. It’s still plenty fast with the C backend via the command-line argument <code>--backend=c</code>:</p>
<div><pre tabindex="0"><code data-lang="zsh"><span><span>% time lpython /Users/czgdp1807/lpython_project/debug.py --backend<span>=</span>c
</span></span><span><span><span>124999750000</span>
</span></span><span><span>lpython /Users/czgdp1807/lpython_project/debug.py --backend<span>=</span>c  0.12s user 0.02s system 100% cpu 0.144 total
</span></span></code></pre></div><p>Note that time lpython <code>/Users/czgdp1807/lpython_project/debug.py --backend=c</code> includes both the compilation time of LPython and the execution time of the binary. The sum of both is so fast that one can afford to compile on every change to the input files. :D.</p>
<h3 id="just-in-time-compilation">Just-In-Time Compilation</h3>
<p>Just-in-time compilation in LPython requires only decorating Python function with <code>@lpython</code>. The decorator takes an option for specifying the desired backend, as in, <code>@lpython(backend="c")</code> or <code>@lpython(backend="llvm")</code>. Only C is supported at present; LLVM and others will be added in the near future. The decorator also propagates backend-specific options. For example</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>,
</span></span><span><span>         backend_optimization_flags<span>=</span>[<span>"-ffast-math"</span>,
</span></span><span><span>                                     <span>"-funroll-loops"</span>,
</span></span><span><span>                                     <span>"-O1"</span>])
</span></span></code></pre></div><p>Note that by default C backend is used without any optimisation flags.</p>
<p>A small example of JIT compilation in LPython (notice the LPython type annotations with the variables),</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, i64, lpython
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O1"</span>])
</span></span><span><span><span>def</span> <span>list_bench</span>(n: i32) <span>-&gt;</span> i64:
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        x<span>.</span>append(i)
</span></span><span><span>    s: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> i64(x[i])
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span>res <span>=</span> list_bench(<span>1</span>) <span># compiles `list_bench` to a shared binary in the first call</span>
</span></span><span><span>res <span>=</span> list_bench(<span>500_000</span>) <span># calls the compiled `list_bench`</span>
</span></span><span><span>print(res)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:46:33:~/lpython_project/lpython % python /Users/czgdp1807/lpython_project/debug.py
</span></span><span><span><span>124999750000</span>
</span></span></code></pre></div><p>We show below in the benchmarks how LPython compares to Numba, which also has JIT compilation.</p>
<h3 id="inter-operability-with-cpython">Inter-operability with CPython</h3>
<p>Access any library implemented using CPython, via the <code>@pythoncall</code> decorator. For example,</p>
<p><strong>email_extractor.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># get_email is implemented in email_extractor_util.py which is intimated to</span>
</span></span><span><span><span># LPython by specifiying the file as module in `@pythoncall` decorator</span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"email_extractor_util"</span>)
</span></span><span><span><span>def</span> <span>get_email</span>(text: str) <span>-&gt;</span> str:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    text: str <span>=</span> <span>"Hello, my email id is lpython@lcompilers.org."</span>
</span></span><span><span>    print(get_email(text))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>email_extractor_util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Implement `get_email` using `re` CPython library</span>
</span></span><span><span><span>def</span> <span>get_email</span>(text):
</span></span><span><span>    <span>import</span> re
</span></span><span><span>    <span># Regular expression patterns</span>
</span></span><span><span>    email_pattern <span>=</span> <span>r</span><span>"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b"</span>
</span></span><span><span>
</span></span><span><span>    <span># Matching email addresses</span>
</span></span><span><span>    email_matches <span>=</span> re<span>.</span>findall(email_pattern, text)
</span></span><span><span>
</span></span><span><span>    <span>return</span> email_matches[<span>0</span>]
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:54:13:~/lpython_project % lpython email_extractor.py --backend<span>=</span>c --enable-cpython
</span></span><span><span>lpython@lcompilers.org
</span></span></code></pre></div><p><em>Note</em>: The <code>@pythoncall</code> and <code>@lpython</code> decorators are presently supported with just the <code>C</code> backend but eventually will work with the LLVM backend and that’s work in progress.</p>
<h2 id="benchmarks-and-demos">Benchmarks and Demos</h2>
<p>In this section, we show how LPython performs compares to competitors on each feature LPython offers. We cover JIT compilation, Interoperability with CPython, and AoT compilation.</p>
<h3 id="just-in-time-jit-compilation">Just-In-Time (JIT) Compilation</h3>
<p>We compare JIT compilation of LPython to Numba on <strong>summation of all the elements of a 1-D array</strong>, <strong>pointwise multiplication of two 1-D arrays</strong>, <strong>insertion sort on lists</strong>, and <strong>quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong>.</p>
<p><strong>System Information</strong></p>
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.57.1</td>
</tr>
<tr>
<td>LPython</td>
<td>0.19.0</td>
</tr>
<tr>
<td>Python</td>
<td>3.10.4</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Summation of all the elements of a 1-D array</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> numpy <span>import</span> float64, arange, empty
</span></span><span><span><span>from</span> lpython <span>import</span> i32, f64, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>fast_sum</span>(n: i32, x: f64[:], res: f64[:]) <span>-&gt;</span> f64:
</span></span><span><span>    s: f64 <span>=</span> <span>0.0</span>
</span></span><span><span>    res[<span>0</span>] <span>=</span> <span>0.0</span>
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> x[i]
</span></span><span><span>    res[<span>0</span>] <span>=</span> s
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>fast_sum_numba</span>(n, x, res):
</span></span><span><span>    s <span>=</span> <span>0.0</span>
</span></span><span><span>    res[<span>0</span>] <span>=</span> <span>0.0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> x[i]
</span></span><span><span>    res[<span>0</span>] <span>=</span> s
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>100_000_000</span>
</span></span><span><span>    x <span>=</span> arange(n, dtype<span>=</span>float64)
</span></span><span><span>    x1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>float64)
</span></span><span><span>    res <span>=</span> empty(<span>1</span>, dtype<span>=</span>float64)
</span></span><span><span>    res_numba <span>=</span> empty(<span>1</span>, dtype<span>=</span>float64)
</span></span><span><span>
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: fast_sum(<span>0</span>, x1, res), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: fast_sum(n, x, res), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> res[<span>0</span>] <span>==</span> <span>4999999950000000.0</span>
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: fast_sum_numba(<span>0</span>, x1, res_numba), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: fast_sum_numba(n, x, res_numba), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> res_numba[<span>0</span>] <span>==</span> <span>4999999950000000.0</span>
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.10</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 MBP 2020</td>
<td>2.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.08</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.53</td>
<td>Apple M1 Pro MBP 2021</td>
<td>6.62</td>
</tr>
<tr>
<td>Numba</td>
<td>0.15</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.40</td>
<td>Apple M1 2020</td>
<td>2.67</td>
</tr>
<tr>
<td>Numba</td>
<td>0.20</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.32</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.60</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.013</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.024</td>
<td>Apple M1 MBP 2020</td>
<td>1.84</td>
</tr>
<tr>
<td>LPython</td>
<td>0.013</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.023</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.77</td>
</tr>
<tr>
<td>LPython</td>
<td>0.014</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.024</td>
<td>Apple M1 2020</td>
<td>1.71</td>
</tr>
<tr>
<td>LPython</td>
<td>0.048</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.048</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Pointwise multiplication of two 1-D arrays</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> numpy <span>import</span> int64, arange, empty
</span></span><span><span><span>from</span> lpython <span>import</span> i32, i64, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>multiply_arrays</span>(n: i32, x: i64[:], y: i64[:], z: i64[:]):
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        z[i] <span>=</span> x[i] <span>*</span> y[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>multiply_arrays_numba</span>(n, x, y, z):
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        z[i] <span>=</span> x[i] <span>*</span> y[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>100_000_000</span>
</span></span><span><span>    x1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    y1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    res1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    x <span>=</span> arange(n, dtype<span>=</span>int64)
</span></span><span><span>    y <span>=</span> arange(n, dtype<span>=</span>int64) <span>+</span> <span>2</span>
</span></span><span><span>    res <span>=</span> empty(n, dtype<span>=</span>int64)
</span></span><span><span>    res_numba <span>=</span> empty(n, dtype<span>=</span>int64)
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: multiply_arrays(<span>0</span>, x1, y1, res1), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: multiply_arrays(n, x, y, res), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> sum(res <span>-</span> x <span>*</span> y) <span>==</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: multiply_arrays_numba(<span>0</span>, x1, y1, res1), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: multiply_arrays_numba(n, x, y, res_numba), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> sum(res_numba <span>-</span> x <span>*</span> y) <span>==</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.11</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.50</td>
<td>Apple M1 MBP 2020</td>
<td>4.54</td>
</tr>
<tr>
<td>Numba</td>
<td>0.09</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.60</td>
<td>Apple M1 Pro MBP 2021</td>
<td>6.67</td>
</tr>
<tr>
<td>Numba</td>
<td>0.11</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.46</td>
<td>Apple M1 2020</td>
<td>4.18</td>
</tr>
<tr>
<td>Numba</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.31</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.48</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.041</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.042</td>
<td>Apple M1 MBP 2020</td>
<td>1.02</td>
</tr>
<tr>
<td>Numba</td>
<td>0.037</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.040</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.08</td>
</tr>
<tr>
<td>Numba</td>
<td>0.042</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.042</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Insertion sort on lists</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>test_list_sort</span>(size: i32):
</span></span><span><span>    i: i32
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    <span>for</span> i <span>in</span> range(size):
</span></span><span><span>        x<span>.</span>append(size <span>-</span> i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        key: i32 <span>=</span> x[i]
</span></span><span><span>        j: i32 <span>=</span> i <span>-</span> <span>1</span>
</span></span><span><span>        <span>while</span> j <span>&gt;=</span> <span>0</span> <span>and</span> key <span>&lt;</span> x[j] :
</span></span><span><span>            x[j <span>+</span> <span>1</span>] <span>=</span> x[j]
</span></span><span><span>            j <span>-=</span> <span>1</span>
</span></span><span><span>        x[j <span>+</span> <span>1</span>] <span>=</span> key
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        <span>assert</span> x[i <span>-</span> <span>1</span>] <span>&lt;</span> x[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>test_list_sort_numba</span>(size):
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    <span>for</span> i <span>in</span> range(size):
</span></span><span><span>        x<span>.</span>append(size <span>-</span> i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        key <span>=</span> x[i]
</span></span><span><span>        j <span>=</span> i <span>-</span> <span>1</span>
</span></span><span><span>        <span>while</span> j <span>&gt;=</span> <span>0</span> <span>and</span> key <span>&lt;</span> x[j] :
</span></span><span><span>            x[j <span>+</span> <span>1</span>] <span>=</span> x[j]
</span></span><span><span>            j <span>-=</span> <span>1</span>
</span></span><span><span>        x[j <span>+</span> <span>1</span>] <span>=</span> key
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        <span>assert</span> x[i <span>-</span> <span>1</span>] <span>&lt;</span> x[i]
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>25000</span>
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: test_list_sort(<span>0</span>), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: test_list_sort(n), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: test_list_sort_numba(<span>0</span>), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: test_list_sort_numba(n), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 MBP 2020</td>
<td>1.54</td>
</tr>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.60</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.62</td>
</tr>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.42</td>
<td>Apple M1 2020</td>
<td>3.23</td>
</tr>
<tr>
<td>Numba</td>
<td>0.35</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.37</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.06</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.11</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 MBP 2020</td>
<td>3.54</td>
</tr>
<tr>
<td>LPython</td>
<td>0.11</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 Pro MBP 2021</td>
<td>3.54</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 2020</td>
<td>1.95</td>
</tr>
<tr>
<td>LPython</td>
<td>0.10</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.36</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>3.60</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, lpython
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span><span>import</span> timeit
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O1"</span>])
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path</span>(n: i32, source: i32, dist_sum: i32[:]):
</span></span><span><span>    i: i32; j: i32; v: i32; u: i32; mindist: i32; alt: i32; dummy: i32;
</span></span><span><span>    graph: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    dist: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    prev: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    visited: dict[i32, bool] <span>=</span> {}
</span></span><span><span>    Q: list[i32] <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>        Q<span>.</span>remove(u)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum[<span>0</span>] <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum[<span>0</span>] <span>+=</span> dist[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path_numba</span>(n, source, dist_sum):
</span></span><span><span>    graph <span>=</span> {}
</span></span><span><span>    dist <span>=</span> {}
</span></span><span><span>    prev <span>=</span> {}
</span></span><span><span>    visited <span>=</span> {}
</span></span><span><span>    Q <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>        Q<span>.</span>remove(u)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum[<span>0</span>] <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum[<span>0</span>] <span>+=</span> dist[i]
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: i32 <span>=</span> <span>4000</span>
</span></span><span><span>    dist_sum_array_numba <span>=</span> empty(<span>1</span>, dtype<span>=</span>int32)
</span></span><span><span>    dist_sum_array <span>=</span> empty(<span>1</span>, dtype<span>=</span>int32)
</span></span><span><span>    print(<span>"LPython compilation time: "</span>, timeit<span>.</span>timeit(<span>lambda</span>: dijkstra_shortest_path(<span>0</span>, <span>0</span>, dist_sum_array), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: dijkstra_shortest_path(n, <span>0</span>, dist_sum_array), repeat<span>=</span><span>5</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    print(dist_sum_array[<span>0</span>])
</span></span><span><span>    <span>assert</span> dist_sum_array[<span>0</span>] <span>==</span> i32(n <span>*</span> (n <span>-</span> <span>1</span>)<span>/</span><span>2</span>)
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time: "</span>, timeit<span>.</span>timeit(<span>lambda</span>: dijkstra_shortest_path_numba(<span>0</span>, <span>0</span>, dist_sum_array_numba), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: dijkstra_shortest_path_numba(n, <span>0</span>, dist_sum_array_numba), repeat<span>=</span><span>5</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    print(dist_sum_array_numba[<span>0</span>])
</span></span><span><span>    <span>assert</span> dist_sum_array_numba[<span>0</span>] <span>==</span> i32(n <span>*</span> (n <span>-</span> <span>1</span>)<span>/</span><span>2</span>)
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.35</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.81</td>
<td>Apple M1 MBP 2020</td>
<td>2.31</td>
</tr>
<tr>
<td>LPython</td>
<td>0.69</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.73</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.05</td>
</tr>
<tr>
<td>LPython</td>
<td>0.21</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.73</td>
<td>Apple M1 2020</td>
<td>3.47</td>
</tr>
<tr>
<td>LPython</td>
<td>1.08</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.69</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.56</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.23</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.01</td>
<td>Apple M1 MBP 2020</td>
<td>4.39</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.98</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.90</td>
</tr>
<tr>
<td>LPython</td>
<td>0.27</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.98</td>
<td>Apple M1 2020</td>
<td>3.63</td>
</tr>
<tr>
<td>LPython</td>
<td>0.87</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.95</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>2.24</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="ahead-of-time-aot-compilation-1">Ahead-of-Time (AoT) Compilation</h3>
<p>Next, we see how LPython compares to other AoT compilers and to the standard CPython interpreter. The tasks considered are <strong>quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong>, and <strong>Floyd-Warshall algorithm on array representation of graphs</strong>.</p>
<p><strong>System Information</strong></p>
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>clang++</td>
<td>14.0.3</td>
</tr>
<tr>
<td>g++</td>
<td>11.3.0</td>
</tr>
<tr>
<td>LPython</td>
<td>0.19.0</td>
</tr>
<tr>
<td>Python</td>
<td>3.10.4</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<p><strong>Quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path</span>(n: i32, source: i32) <span>-&gt;</span> i32:
</span></span><span><span>    i: i32; j: i32; v: i32; u: i32; mindist: i32; alt: i32; dummy: i32; uidx: i32
</span></span><span><span>    dist_sum: i32;
</span></span><span><span>    graph: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    dist: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    prev: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    visited: dict[i32, bool] <span>=</span> {}
</span></span><span><span>    Q: list[i32] <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>                uidx <span>=</span> i
</span></span><span><span>        dummy <span>=</span> Q<span>.</span>pop(uidx)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum <span>+=</span> dist[i]
</span></span><span><span>    <span>return</span> dist_sum
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: i32 <span>=</span> <span>4000</span>
</span></span><span><span>    print(dijkstra_shortest_path(n, <span>0</span>))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;unordered_map&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;vector&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int32_t</span> <span>dijkstra_shortest_path</span>(<span>int32_t</span> n, <span>int32_t</span> source) {
</span></span><span><span>    <span>int32_t</span> i, j, v, u, mindist, alt, dummy, uidx;
</span></span><span><span>    std<span>::</span>unordered_map<span>&lt;</span><span>int32_t</span>, <span>int32_t</span><span>&gt;</span> graph, dist, prev;
</span></span><span><span>    std<span>::</span>unordered_map<span>&lt;</span><span>int32_t</span>, <span>bool</span><span>&gt;</span> visited;
</span></span><span><span>    std<span>::</span>vector<span>&lt;</span><span>int32_t</span><span>&gt;</span> Q;
</span></span><span><span>
</span></span><span><span>    <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> n; i<span>++</span>) {
</span></span><span><span>        <span>for</span>(j <span>=</span> <span>0</span>; j <span>&lt;</span> n; j<span>++</span>) {
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> std<span>::</span>abs(i <span>-</span> j);
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> n; v<span>++</span>) {
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>;
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>        Q.push_back(v);
</span></span><span><span>        visited[v] <span>=</span> false;
</span></span><span><span>    }
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>while</span>(Q.size() <span>&gt;</span> <span>0</span>) {
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>;
</span></span><span><span>        <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> Q.size(); i<span>++</span>) {
</span></span><span><span>            <span>if</span>( mindist <span>&gt;</span> dist[Q[i]] ) {
</span></span><span><span>                mindist <span>=</span> dist[Q[i]];
</span></span><span><span>                u <span>=</span> Q[i];
</span></span><span><span>                uidx <span>=</span> i;
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>        Q.erase(Q.begin() <span>+</span> uidx);
</span></span><span><span>        visited[u] <span>=</span> true;
</span></span><span><span>
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> n; v<span>++</span>) {
</span></span><span><span>            <span>if</span>( v <span>!=</span> u and not visited[v] ) {
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v];
</span></span><span><span>
</span></span><span><span>                <span>if</span>( alt <span>&lt;</span> dist[v] ) {
</span></span><span><span>                    dist[v] <span>=</span> alt;
</span></span><span><span>                    prev[v] <span>=</span> u;
</span></span><span><span>                }
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>int32_t</span> dist_sum <span>=</span> <span>0</span>;
</span></span><span><span>    <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> n; i<span>++</span>) {
</span></span><span><span>        dist_sum <span>+=</span> dist[i];
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> dist_sum;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>    <span>int32_t</span> n <span>=</span> <span>4000</span>;
</span></span><span><span>    <span>int32_t</span> dist_sum <span>=</span> dijkstra_shortest_path(n, <span>0</span>);
</span></span><span><span>    std<span>::</span>cout<span>&lt;&lt;</span>dist_sum<span>&lt;&lt;</span>std<span>::</span>endl;
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.167</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.993</td>
<td>Apple M1 MBP 2020</td>
<td>5.95</td>
</tr>
<tr>
<td>Python</td>
<td>3.817</td>
<td>Apple M1 MBP 2020</td>
<td>22.86</td>
</tr>
<tr>
<td>LPython</td>
<td>0.155</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.685</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.41</td>
</tr>
<tr>
<td>Python</td>
<td>3.437</td>
<td>Apple M1 Pro MBP 2021</td>
<td>22.17</td>
</tr>
<tr>
<td>LPython</td>
<td>0.324</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.709</td>
<td>Apple M1 2020</td>
<td>2.19</td>
</tr>
<tr>
<td>Python</td>
<td>3.486</td>
<td>Apple M1 2020</td>
<td>10.76</td>
</tr>
<tr>
<td>LPython</td>
<td>0.613</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>g++</td>
<td>1.358</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>2.21</td>
</tr>
<tr>
<td>Python</td>
<td>7.365</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>12.01</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<p>Note the optimization flags furnished to each compiler.</p>
<table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Optimization flags used</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td><code>--fast</code></td>
</tr>
<tr>
<td>Clang++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>g++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>Python</td>
<td>-</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Floyd-Warshall algorithm on array representation of graphs</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i64, i32
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int64
</span></span><span><span>
</span></span><span><span><span>def</span> <span>floyd_warshall</span>(size: i32) <span>-&gt;</span> i64:
</span></span><span><span>    dist: i64[size, size] <span>=</span> empty((size, size), dtype<span>=</span>int64)
</span></span><span><span>    u: i32; v: i32
</span></span><span><span>    i: i32; j: i32; k: i32
</span></span><span><span>    update: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> u <span>in</span> range(size):
</span></span><span><span>        <span>for</span> v <span>in</span> range(size):
</span></span><span><span>            dist[u, v] <span>=</span> i64(<span>2147483647</span>)
</span></span><span><span>    <span>for</span> u <span>in</span> range(size):
</span></span><span><span>        <span>for</span> v <span>in</span> range(size):
</span></span><span><span>            <span>if</span> u <span>!=</span> v <span>and</span> ((u<span>%</span><span>2</span> <span>==</span> <span>0</span> <span>and</span> v<span>%</span><span>2</span> <span>==</span> <span>1</span>)
</span></span><span><span>                           <span>or</span> (u<span>%</span><span>2</span> <span>==</span> <span>1</span> <span>and</span> v<span>%</span><span>2</span> <span>==</span> <span>0</span>)):
</span></span><span><span>                dist[u, v] <span>=</span> i64(u <span>+</span> v)
</span></span><span><span>    <span>for</span> v <span>in</span> range(size):
</span></span><span><span>        dist[v, v] <span>=</span> i64(<span>0</span>)
</span></span><span><span>
</span></span><span><span>    update <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> k <span>in</span> range(size):
</span></span><span><span>        <span>for</span> i <span>in</span> range(size):
</span></span><span><span>            <span>for</span> j <span>in</span> range(size):
</span></span><span><span>                <span>if</span> dist[i, j] <span>&gt;</span> dist[i, k] <span>+</span> dist[k, j]:
</span></span><span><span>                    update <span>+=</span> dist[i, j] <span>-</span> dist[i, k] <span>-</span> dist[k, j]
</span></span><span><span>                    dist[i, j] <span>=</span> dist[i, k] <span>+</span> dist[k, j]
</span></span><span><span>
</span></span><span><span>    <span>return</span> update
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>print(floyd_warshall(<span>1000</span>))
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int64_t</span> <span>floyd_warshall</span>(<span>int32_t</span> size) {
</span></span><span><span>    <span>int64_t</span> dist[size][size];
</span></span><span><span>    <span>int32_t</span> u, v, i, j, k;
</span></span><span><span>    <span>int64_t</span> update;
</span></span><span><span>    <span>for</span>(u <span>=</span> <span>0</span>; u <span>&lt;</span> size; u<span>++</span>) {
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>            dist[u][v] <span>=</span> <span>2147483647</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>for</span>(u <span>=</span> <span>0</span>; u <span>&lt;</span> size; u<span>++</span>) {
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>            <span>if</span>( u <span>!=</span> v <span>&amp;&amp;</span> ((u<span>%</span><span>2</span> <span>==</span> <span>0</span> and v<span>%</span><span>2</span> <span>==</span> <span>1</span>)
</span></span><span><span>                           <span>||</span> (u<span>%</span><span>2</span> <span>==</span> <span>1</span> and v<span>%</span><span>2</span> <span>==</span> <span>0</span>)) ) {
</span></span><span><span>                dist[u][v] <span>=</span> u <span>+</span> v;
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>        dist[v][v] <span>=</span> <span>0</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    update <span>=</span> <span>0</span>;
</span></span><span><span>    <span>for</span>(k <span>=</span> <span>0</span>; k <span>&lt;</span> size; k<span>++</span>) {
</span></span><span><span>        <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> size; i<span>++</span>) {
</span></span><span><span>            <span>for</span>(j <span>=</span> <span>0</span>; j <span>&lt;</span> size; j<span>++</span>) {
</span></span><span><span>                <span>if</span>( dist[i][j] <span>&gt;</span> dist[i][k] <span>+</span> dist[k][j] ) {
</span></span><span><span>                    update <span>+=</span> dist[i][j] <span>-</span> dist[i][k] <span>-</span> dist[k][j];
</span></span><span><span>                    dist[i][j] <span>=</span> dist[i][k] <span>+</span> dist[k][j];
</span></span><span><span>                }
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> update;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>    std<span>::</span>cout<span>&lt;&lt;</span>(floyd_warshall(<span>1000</span>))<span>&lt;&lt;</span>std<span>::</span>endl;
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang++</td>
<td>0.451</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.767</td>
<td>Apple M1 MBP 2020</td>
<td>1.70</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 MBP 2020</td>
<td>&gt; 24.39</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.435</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.785</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.80</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 Pro MBP 2021</td>
<td>&gt; 25.28</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.460</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.995</td>
<td>Apple M1 2020</td>
<td>2.16</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 2020</td>
<td>&gt; 23.91</td>
</tr>
<tr>
<td>g++</td>
<td>0.695</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>2.933</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>4.22</td>
</tr>
<tr>
<td>Python</td>
<td>440.588</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>633.94</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Note the optimization flags furnished to each compiler.</p>
<table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Optimization flags used</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td><code>--fast</code></td>
</tr>
<tr>
<td>Clang++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>g++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>Python</td>
<td>-</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="interoperability-with-cpython">Interoperability with CPython</h3>
<p>Next we show that LPython can call functions in CPython libraries. This feature permits “break-out” to Numpy, TensorFlow, PyTorch, and even to matplotlib. The break-outs will run at ordinary (slow) Python speeds, but LPython accelerates the mathematical portions to near maximum speed.</p>
<p><strong>Calling NumPy functions via CPython</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, f64, i64, pythoncall, Const, TypeVar
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32, float64
</span></span><span><span>
</span></span><span><span>n_1 <span>=</span> TypeVar(<span>"n_1"</span>)
</span></span><span><span>n_2 <span>=</span> TypeVar(<span>"n_2"</span>)
</span></span><span><span>n_3 <span>=</span> TypeVar(<span>"n_3"</span>)
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>cpython_add</span>(n_1: i32, a: i32[:], b: i32[:]) <span>-&gt;</span> i32[n_1]:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>cpython_multiply</span>(n_1: i32, n_2: i32, a: f64[:], b: f64[:]) <span>-&gt;</span> f64[n_1, n_2]:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test_1D</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>500_000</span>
</span></span><span><span>    a: i32[n] <span>=</span> empty(n, dtype <span>=</span> int32)
</span></span><span><span>    b: i32[n] <span>=</span> empty(n, dtype <span>=</span> int32)
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        a[i] <span>=</span> <span>2</span> <span>*</span> (i<span>+</span><span>1</span>) <span>*</span> <span>13</span>
</span></span><span><span>        b[i] <span>=</span> a[i] <span>+</span> <span>2</span>
</span></span><span><span>    sum: i32[n]
</span></span><span><span>    sum <span>=</span> cpython_add(<span>500_000</span>, a, b)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>assert</span> sum[i] <span>==</span> a[i] <span>+</span> b[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test_2D</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>1_000</span>
</span></span><span><span>    a: f64[n] <span>=</span> empty([n], dtype <span>=</span> float64)
</span></span><span><span>    b: f64[n] <span>=</span> empty([n], dtype <span>=</span> float64)
</span></span><span><span>    i: i32; j: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        a[i] <span>=</span> f64(i <span>+</span> <span>13</span>)
</span></span><span><span>        b[i] <span>=</span> i <span>*</span> <span>2</span> <span>/</span> (i <span>+</span> <span>1</span>)
</span></span><span><span>    product: f64[n, n]
</span></span><span><span>    product <span>=</span> cpython_multiply(<span>1_000</span>, <span>1_000</span>, a, b)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>assert</span> product[i] <span>==</span> a[i] <span>*</span> b[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    test_1D()
</span></span><span><span>    test_2D()
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> numpy <span>as</span> np
</span></span><span><span>
</span></span><span><span><span>def</span> <span>cpython_add</span>(n, a, b):
</span></span><span><span>    <span>return</span> np<span>.</span>add(a, b)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>cpython_multiply</span>(n, m, a, b):
</span></span><span><span>    <span>return</span> np<span>.</span>multiply(a, b)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 23:02:55:~/lpython_project % lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span><span>(</span>lp<span>)</span> 23:03:10:~/lpython_project % <span># Works successfully without any asserts failing</span>
</span></span></code></pre></div><p><strong>Plotting graphs via Matplotlib</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> f64, i32, pythoncall, Const
</span></span><span><span><span>from</span> numpy <span>import</span> empty, float64
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>plot_graph</span>(x: f64[:], y1: f64[:], y2: f64[:], y3: f64[:]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>f</span>(x: f64, i: f64) <span>-&gt;</span> f64:
</span></span><span><span>    <span>return</span> x <span>**</span> <span>.5</span> <span>/</span> i
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>100000</span>
</span></span><span><span>    x: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y1: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y2: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y3: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, n):
</span></span><span><span>        x[i] <span>=</span> f64(i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, n):
</span></span><span><span>        y1[i] <span>=</span> f(x[i], <span>1.</span>)
</span></span><span><span>        y2[i] <span>=</span> f(x[i], <span>2.</span>)
</span></span><span><span>        y3[i] <span>=</span> f(x[i], <span>3.</span>)
</span></span><span><span>
</span></span><span><span>    plot_graph(x, y1, y2, y3)
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> matplotlib.pyplot <span>as</span> plt
</span></span><span><span>
</span></span><span><span><span>def</span> <span>plot_graph</span>(x, y1, y2, y3):
</span></span><span><span>    plt<span>.</span>figtext(<span>0.92</span>, <span>0.03</span>, <span>'$x$'</span>)
</span></span><span><span>    plt<span>.</span>figtext(<span>0.1</span>, <span>0.9</span>, <span>'$y$'</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y1, label<span>=</span><span>"y1"</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y2, label<span>=</span><span>"y2"</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y3, label<span>=</span><span>"y3"</span>)
</span></span><span><span>    plt<span>.</span>legend()
</span></span><span><span>    plt<span>.</span>savefig(<span>'graph.png'</span>)
</span></span><span><span>    plt<span>.</span>show()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 23:09:08:~/lpython_project % lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span><span>(</span>lp<span>)</span> 23:10:44:~/lpython_project % <span># Works see the graph below</span>
</span></span></code></pre></div><p><img src="https://lpython.org/blog/images/graph.png" alt="Output graph"></p>
<p><strong>Visualization using Matplotlib: Mandelbrot Set</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, f64, pythoncall, TypeVar
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32
</span></span><span><span>
</span></span><span><span>h <span>=</span> TypeVar(<span>"h"</span>)
</span></span><span><span>w <span>=</span> TypeVar(<span>"w"</span>)
</span></span><span><span>d <span>=</span> TypeVar(<span>"d"</span>)
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"util"</span>)
</span></span><span><span><span>def</span> <span>show_img_gray</span>(w: i32, h: i32, A: i32[h, w]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"util"</span>)
</span></span><span><span><span>def</span> <span>show_img_color</span>(w: i32, h: i32, d: i32, A: i32[h, w, d]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main0</span>():
</span></span><span><span>    Nx: i32 <span>=</span> <span>600</span>; Ny: i32 <span>=</span> <span>450</span>; Nz: i32 <span>=</span> <span>4</span>; n_max: i32 <span>=</span> <span>255</span>
</span></span><span><span>
</span></span><span><span>    xcenter: f64 <span>=</span> f64(<span>-</span><span>0.5</span>); ycenter: f64 <span>=</span> f64(<span>0.0</span>)
</span></span><span><span>    width: f64 <span>=</span> f64(<span>4</span>); height: f64 <span>=</span> f64(<span>3</span>)
</span></span><span><span>    dx_di: f64 <span>=</span> width<span>/</span>f64(Nx); dy_dj: f64 <span>=</span> <span>-</span>height<span>/</span>f64(Ny)
</span></span><span><span>    x_offset: f64 <span>=</span> xcenter <span>-</span> f64(Nx<span>+</span><span>1</span>)<span>*</span>dx_di<span>/</span>f64(<span>2.0</span>)
</span></span><span><span>    y_offset: f64 <span>=</span> ycenter <span>-</span> f64(Ny<span>+</span><span>1</span>)<span>*</span>dy_dj<span>/</span>f64(<span>2.0</span>)
</span></span><span><span>
</span></span><span><span>    i: i32; j: i32; n: i32; idx: i32
</span></span><span><span>    x: f64; y: f64; x_0: f64; y_0: f64; x_sqr: f64; y_sqr: f64
</span></span><span><span>
</span></span><span><span>    image: i32[<span>450</span>, <span>600</span>] <span>=</span> empty([Ny, Nx], dtype<span>=</span>int32)
</span></span><span><span>    image_color: i32[<span>450</span>, <span>600</span>, <span>4</span>] <span>=</span> empty([Ny, Nx, Nz], dtype<span>=</span>int32)
</span></span><span><span>    palette: i32[<span>4</span>, <span>3</span>] <span>=</span> empty([<span>4</span>, <span>3</span>], dtype<span>=</span>int32)
</span></span><span><span>
</span></span><span><span>    <span>for</span> j <span>in</span> range(Ny):
</span></span><span><span>        y_0 <span>=</span> y_offset <span>+</span> dy_dj <span>*</span> f64(j <span>+</span> <span>1</span>)
</span></span><span><span>        <span>for</span> i <span>in</span> range(Nx):
</span></span><span><span>            x_0 <span>=</span> x_offset <span>+</span> dx_di <span>*</span> f64(i <span>+</span> <span>1</span>)
</span></span><span><span>            x <span>=</span> <span>0.0</span>; y <span>=</span> <span>0.0</span>; n <span>=</span> <span>0</span>
</span></span><span><span>            <span>while</span>(<span>True</span>):
</span></span><span><span>                x_sqr <span>=</span> x <span>**</span> <span>2.0</span>
</span></span><span><span>                y_sqr <span>=</span> y <span>**</span> <span>2.0</span>
</span></span><span><span>                <span>if</span> (x_sqr <span>+</span> y_sqr <span>&gt;</span> f64(<span>4</span>) <span>or</span> n <span>==</span> n_max):
</span></span><span><span>                    image[j,i] <span>=</span> <span>255</span> <span>-</span> n
</span></span><span><span>                    <span>break</span>
</span></span><span><span>                y <span>=</span> y_0 <span>+</span> f64(<span>2.0</span>) <span>*</span> x <span>*</span> y
</span></span><span><span>                x <span>=</span> x_0 <span>+</span> x_sqr <span>-</span> y_sqr
</span></span><span><span>                n <span>=</span> n <span>+</span> <span>1</span>
</span></span><span><span>
</span></span><span><span>    palette[<span>0</span>,<span>0</span>] <span>=</span>   <span>0</span>; palette[<span>0</span>,<span>1</span>] <span>=</span> <span>135</span>; palette[<span>0</span>,<span>2</span>] <span>=</span>  <span>68</span>
</span></span><span><span>    palette[<span>1</span>,<span>0</span>] <span>=</span>   <span>0</span>; palette[<span>1</span>,<span>1</span>] <span>=</span>  <span>87</span>; palette[<span>1</span>,<span>2</span>] <span>=</span> <span>231</span>
</span></span><span><span>    palette[<span>2</span>,<span>0</span>] <span>=</span> <span>214</span>; palette[<span>2</span>,<span>1</span>] <span>=</span>  <span>45</span>; palette[<span>2</span>,<span>2</span>] <span>=</span>  <span>32</span>
</span></span><span><span>    palette[<span>3</span>,<span>0</span>] <span>=</span> <span>255</span>; palette[<span>3</span>,<span>1</span>] <span>=</span> <span>167</span>; palette[<span>3</span>,<span>2</span>] <span>=</span>   <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> j <span>in</span> range(Ny):
</span></span><span><span>        <span>for</span> i <span>in</span> range(Nx):
</span></span><span><span>            idx <span>=</span> image[j,i] <span>-</span> i32(image[j,i]<span>/</span><span>4</span>)<span>*</span><span>4</span>
</span></span><span><span>            image_color[j,i,<span>0</span>] <span>=</span> palette[idx,<span>0</span>] <span># Red</span>
</span></span><span><span>            image_color[j,i,<span>1</span>] <span>=</span> palette[idx,<span>1</span>] <span># Green</span>
</span></span><span><span>            image_color[j,i,<span>2</span>] <span>=</span> palette[idx,<span>2</span>] <span># Blue</span>
</span></span><span><span>            image_color[j,i,<span>3</span>] <span>=</span> <span>255</span>            <span># Alpha</span>
</span></span><span><span>
</span></span><span><span>    show_img_gray(Nx, Ny, image)
</span></span><span><span>    show_img_color(Nx, Ny, Nz, image_color)
</span></span><span><span>    print(<span>"Done."</span>)
</span></span><span><span>
</span></span><span><span>main0()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>show_img_gray</span>(w, h, A):
</span></span><span><span>    <span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt
</span></span><span><span>    plt<span>.</span>imshow(A, cmap<span>=</span><span>'gray'</span>)
</span></span><span><span>    plt<span>.</span>show()
</span></span><span><span>    plt<span>.</span>close()
</span></span><span><span>
</span></span><span><span><span>def</span> <span>show_img_color</span>(w, h, d, A):
</span></span><span><span>    <span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt
</span></span><span><span>    plt<span>.</span>imshow(A)
</span></span><span><span>    plt<span>.</span>show()
</span></span><span><span>    plt<span>.</span>close()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span>$ ls
</span></span><span><span>main.py util.py
</span></span><span><span>$ lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span>Done.
</span></span></code></pre></div><p><img src="https://lpython.org/blog/images/gray.png" alt="mandelbrot-set-gray"></p>
<p><img src="https://lpython.org/blog/images/color.png" alt="mandelbrot-set-color"></p>
<h2 id="conclusion">Conclusion</h2>
<p>The benchmarks support the claim that LPython is competitive with its competitors in all features it offers. In JIT, the execution times of LPython-compiled functions are at least as short as equivalent Numba functions. The speed of JIT compilation, itself, is slow in some cases because it currently depends on a C compiler to generate optimal binary code. For algorithms with rich data structures like <code>dict</code> (hash maps) and <code>list</code>, LPython shows much faster speed than Numba. In AoT compilation for tasks like the Dijkstra algorithm, LPython beats equivalent C++ code very comfortably. For an array-based implementation of the Floyd-Warshall algorithm, LPython generates code almost as fast as C++ does.</p>
<p>The main takeaway is that LPython/LFortran generate fast code by default. Our benchmarks show that it’s straightforward to write high-speed LPython code. We hope to raise expectations that LPython output will be in general at least as fast as the equivalent C++ code. Users love Python because of its many productivity advantages: great tooling, easy syntax, and rich data structures like lists, dicts, sets, and arrays. Because any LPython program is also an ordinary Python program, all the tools – debuggers and profilers, for instance – just work. Then, LPython delivers run-time speeds, even with rich data structures at least as short as alternatives in most cases.</p>


        
          
        

        

        
      </article>

      
        
      


      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plans develop for high-speed rail in the PNW (154 pts)]]></title>
            <link>https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/</link>
            <guid>36916150</guid>
            <pubDate>Sat, 29 Jul 2023 02:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/">https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/</a>, See on <a href="https://news.ycombinator.com/item?id=36916150">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<h2><em>New research shows how community engagement is integral in its success.</em></h2>



<p><i><b>by Sarah Goh</b></i></p>



<hr>



<p>With a growing population in the Pacific Northwest, the call for better public transportation heightens. This March, Washington’s State Legislature signed off on a transportation milestone, allocating $150 million to a high-speed connection between Oregon, Washington, and British Columbia. </p>



<p>Though this funding could reduce congestion, cut carbon emissions, and better connect these coastal cities, a high-speed rail that travels above 200 miles per hour between major cities has never been done before in the United States. How will Washington get started? How will the State ensure a successful project?</p>



<p>A new <a href="https://mic.comotion.uw.edu/our-work/ultra-high-speed-rail-project/">research report</a> by the University of Washington examines these very questions and identifies key concepts that community members can help with to achieve an efficient high-speed rail. If a rail is built successfully, there will be an extraordinary increase in transportation abilities — saving commuters time while reducing environmental harm. </p>



<p>Professors Jan Whittington and Qing Shen at the UW’s Department of Urban Design and Planning led the research, and with no previous high-speed rail projects in the Northwest, they turned to other states and abroad.</p>



<p>“The purpose of the study was to draw lessons learned from projects, systems, and expertise around the world where high-speed rail has been successful,” Whittington said.</p>



<p>They dedicated six months to both academic and industry research. They interviewed a cadre of transportation experts in France, the Netherlands, Spain, Taiwan, and U.S. cities where high-speed rail is currently developing. </p>



<p>“Oftentimes, [the U.S. is] in a leadership role in developing and growing technologies,” Whittington said. “But here, we’re in a position of needing to learn from people who have had success in their own countries.” </p>



<p>The study allowed interviewees to share their experiences from their own projects. Whittington says that while people are usually unwilling to share their research information, Whittington and Shen’s research allowed experts to talk about their regrets, choices, and early decisions in high-speed rail building. </p>



<p>The <a href="https://mic.comotion.uw.edu/wp-content/uploads/2023/05/Keeping-it-on-the-Tracks-High-speed-Rail-Success-and-Lessons-Learned.pdf">final research report</a> spans over 72 pages, with 40 recommendations for transportation departments. However, Whittington emphasized several key points that will be instrumental to the project’s success: For commuters to prioritize rail transportation over air or other non-environmental ways of travel, the high-speed rail must be at its most convenient. To achieve this convenience of speed and efficiency, there cannot be any shortcuts or deviations to the design. Routes are going to be chosen that minimize turns and any design choices that reduce speed. </p>



<p>And Whittington says the designers must also ensure the rail remains dedicated to its high-speed route and that people have the ability to get to the rail through other means of public transportation. “There are going to be a lot of communities you want to serve,” Whittington said, “but you want to find a way to bring those communities to the routes as opposed to bringing the route to the communities.” </p>



<p>Whittington says early planning must engage commuters and the general community. The report itself states, “Have early, systematic, and sustained community engagement, approaching communities to understand their needs instead of selling the idea of high-speed rail.”</p>



<p>Along with community engagement, limiting political sway is important. The study shows that if political representatives convince planners to route through different locations — deviating from the design — cities could end up with an expensive commuter rail system instead of a competitive high-speed rail.</p>



<p>“You have to be very careful about compromises made in design in these early stages,” Whittington said.</p>



<p>Implementing this delicate balance of compromises and early planning is essential for a high-speed rail project, and the UW research has created a place for U.S. transportation departments to start.</p>



<p>“It is our sincere hope that people will be able to see this collection of recommendations as a set of touchstones to build off of as they take the earliest steps in product design and development,” Whittington said.</p>



<p>The Washington State Department of Transportation (WSDOT) has already begun the early stages of building a high-speed rail in the Cascadia region with help from the UW study. They are looking to secure more funding and focus on the meticulousness of the early design process. Especially in collaboration with Oregon and British Columbia, a project like this is formidable and will take years.</p>



<p>“We don’t want to short-circuit the work we need to do with communities,” said Ron Pate, WSDOT’s director for Rail, Freight and Ports. “Our goal is to make sure we work with communities when moving it forward.” </p>



<hr>



<p><em>This article is funded in part by an</em><a href="https://greenspace.seattle.gov/2023/01/city-of-seattles-environmental-justice-fund-awards-750000-in-grants-for-13-projects-led-by-and-benefiting-those-most-impacted-by-climate-change/#sthash.1NfRR1eK.dpbs"><em>&nbsp;Environmental Justice Fund (EJ Fund) grant</em></a><em>&nbsp;through the City of Seattle’s Office of Sustainability &amp; Environment (OSE).</em></p>



<hr>



<div><figure><img data-lazy-fallback="1" data-attachment-id="83917" data-permalink="https://southseattleemerald.com/2022/03/23/nic-masangkay-is-redefining-mothers-in-a-new-age-of-love/sarahgoh_headshot_cropped/" data-orig-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=1080%2C1080&amp;ssl=1" data-orig-size="1080,1080" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SarahGoh_headshot_cropped" data-image-description="<p>Sarah Goh is a Seattle-based journalist who graduated from the University of Washington with a dual-degree in biology and journalism. At the intersection of community, science, and humanities, she hopes to uplift more voices and explore the overlooked and unexpected. Find her at sarahsgoh.com or on Instagram @sarahsgoh.</p>
" data-image-caption="<p>Sarah Goh</p>
" data-medium-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=474%2C474&amp;ssl=1" decoding="async" loading="lazy" width="474" height="474" src="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=474%2C474&amp;ssl=1" alt="" srcset="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=1080&amp;ssl=1 1080w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=948&amp;ssl=1 948w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=1080&amp;ssl=1 1080w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=948&amp;ssl=1 948w" data-lazy-src="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=474%2C474&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p><strong><em>Sarah Goh</em></strong><em> is a Singaporean American journalist from Seattle, Washington, and a current medical student at WSU College of Medicine. At the intersection of community, science, and humanities, she hopes to elevate marginalized voices and explore the overlooked and unexpected through her writing. Find her at </em><a href="https://sarahsgoh.com/work"><em>SarahSGoh.com</em></a><em> or </em><a href="https://www.instagram.com/sarahsgoh/"><em>@sarahsgoh</em></a><em>.</em></p></div>



<p>📸 <em>Featured Image: Photo via <a href="https://www.shutterstock.com/image-photo/high-speed-train-motion-on-railway-1661454721">Denis Belitsky</a>/<a href="http://shutterstock.com/">Shutterstock.com</a></em></p>



<pre><strong>Before you move on to the next story …</strong>
The <em>South Seattle Emerald</em> is brought to you by Rainmakers. Rainmakers give recurring gifts at any amount. With over 1,000 Rainmakers, the <em>Emerald</em> is truly community-driven local media. Help us keep BIPOC-led media free and accessible. 
 
If just half of our readers signed up to give $6 a month, we wouldn't have to fundraise for the rest of the year. Small amounts make a difference. 
 
<strong>We cannot do this work without you.</strong> <a href="https://southseattleemerald.kindful.com/">Become a Rainmaker today!</a></pre>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[F# RISC-V Instruction Set formal specification (122 pts)]]></title>
            <link>https://github.com/mrLSD/riscv-fs</link>
            <guid>36915108</guid>
            <pubDate>Sat, 29 Jul 2023 00:04:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mrLSD/riscv-fs">https://github.com/mrLSD/riscv-fs</a>, See on <a href="https://news.ycombinator.com/item?id=36915108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">RISC-V formal ISA Specification</h2>
<p dir="auto"><a href="https://travis-ci.org/mrLSD/riscv-fs" rel="nofollow"><img src="https://camo.githubusercontent.com/a5d7fb852a82237357f7af33f4202290c76f28fef8a039bcfc769114cc018185/68747470733a2f2f7472617669732d63692e6f72672f6d724c53442f72697363762d66732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/mrLSD/riscv-fs.svg?branch=master"></a></p>
<p dir="auto"><strong>Copyright © Evgeny Ukhanov</strong></p>
<p dir="auto">This is a formal (and executable) specification for the
RISC-V ISA (Instruction Set Architecture), written in
<strong>F# purely functional style</strong>. We deliberately choose
an "<em>extremely elementary</em>" implementation of F# to make it
readable and usable by wide audience who do not know F# and who
do not plan to learn F#.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3d3af88857328fa9c384afc75e6dad08edb7ed4285445657413472e08cbc1438/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f323437342f312a38385a6a2d514a713438495a54694347556f356d53512e706e67"><img src="https://camo.githubusercontent.com/3d3af88857328fa9c384afc75e6dad08edb7ed4285445657413472e08cbc1438/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f323437342f312a38385a6a2d514a713438495a54694347556f356d53512e706e67" alt="F# RISC-V ISA Formal Specification" data-canonical-src="https://miro.medium.com/max/2474/1*88Zj-QJq48IZTiCGUo5mSQ.png"></a></p>
<p dir="auto">This is a work-in-progress, one of several similar concurrent
efforts within the <strong>ISA Formal Specification</strong>
Technical Group constituted by The RISC-V Foundation
(<a href="https://riscv.org/" rel="nofollow">https://riscv.org</a>). We welcome your feedback, comments and suggestions.</p>
<h2 tabindex="-1" dir="auto">Content</h2>
<ul dir="auto">
<li><a href="#features--current-status">Features &amp; Current status</a></li>
<li><a href="#reading-the-code">Reading the code</a></li>
<li><a href="#how-to-build-and-run-it-on-risc-v-binaries">How to build and run it on RISC-V binaries</a>
<ul dir="auto">
<li><a href="#install-.net-sdk">Install .NET SDK</a></li>
<li><a href="#make-the-application-executable">Make the application executable</a></li>
<li><a href="#run-the-application-executable">Run the application executable</a></li>
</ul>
</li>
<li><a href="#how-to-contribute">How to Contribute</a></li>
<li><a href="#references">References</a></li>
<li><a href="#licence">Licence</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Features &amp; Current status</h2>
<ul dir="auto">
<li>Supports the following features (or <em>in active development state</em>)
<ul>
<li> Base instruction set: RV32I</li>
<li> Tests RV32I</li>
<li> Base instruction set: RV64I</li>
<li> Tests RV64I</li>
<li> Standard extension M (integer multiply/divide)</li>
<li> Tests for Standard extension M RV32/RV64</li>
<li> Standard extension A (atomic memory ops)</li>
<li> Tests for Standard extension A RV32/RV64</li>
</ul>
</li>
<li>Features under development
<ul dir="auto">
<li>Standard extension C (Compressed 16-bit instructions)</li>
<li>Standard extension F (Single-precision floating point)</li>
<li>Standard extension D (Double-precision floating point)</li>
<li>Privilege Level M (Machine)</li>
<li>Privilege Level U (User)</li>
<li>Privilege Level S (Supervisor)
<ul dir="auto">
<li>Virtual Memory schemes SV32, SV39 and SV48</li>
</ul>
</li>
</ul>
</li>
<li>Application can be executed as a F# program flexible with
CLI (<em>command line interface</em>) support, which in
turn executes RISC-V ELF binaries. This is a sequential
interpretation: one-instruction-at-a-time, sequential
memory model.</li>
<li>Tests passing for RISC-V <strong>under development</strong>:
<ul dir="auto">
<li>Basic instruction flow</li>
<li><code>rv32ui-p-*, rv64ui-p-*</code> (Base instruction set)</li>
<li><code>rv32um-p-*, rv64um-p-*</code> (M extension)</li>
<li><code>rv32ua-p-*, rv64ua-p-*</code> (A extension)</li>
<li><code>rv32uc-p-*, rv64uc-p-*</code> (C extension)</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Reading the code</h2>
<p dir="auto">We expect that many people might use this as a reading
reference (whether or not they build and execute it) to
clarify their understanding of RISC-V ISA semantics.</p>
<p dir="auto">Main part for reading Specification:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Decode*.fs</strong></p>
<p dir="auto">Decodes contain decoders for specific instructions set
and notified with instruction/extension set symbol. For example <code>DecodeI.fs</code></p>
</li>
<li>
<p dir="auto"><strong>Execute*.fs</strong></p>
<p dir="auto">Executes contain executions for specific instructions set
and notified with instruction/extension set symbol. For example <code>ExecuteI.fs</code></p>
</li>
<li>
<p dir="auto">Utilities:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>CLI.fs</code></p>
<p dir="auto">Contain helper function and types for
building effective CLI commands and options.</p>
</li>
<li>
<p dir="auto"><code>Bits.fs</code></p>
<p dir="auto">Basic type specific functions for
manipulations with <code>bits</code>.</p>
</li>
<li>
<p dir="auto"><code>Run.fs</code></p>
<p dir="auto">Basic Run flow - fetch, decode, execute,
logging execution flow.</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Architecture</p>
<ul dir="auto">
<li>
<p dir="auto"><code>Arch.fs</code></p>
<p dir="auto">Basic architecture types for RISC-V specification.</p>
</li>
<li>
<p dir="auto"><code>MachineState.fs</code></p>
<p dir="auto">Basic type and functions described
RISC-V machine state.</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Main app</p>
<ul dir="auto">
<li><code>Program.fs</code></li>
</ul>
<p dir="auto">Main application to execute <strong>RISC-V simulator/emulator</strong>.</p>
</li>
<li>
<p dir="auto">Test</p>
<ul dir="auto">
<li>
<p dir="auto"><code>Test/*.fs</code></p>
<p dir="auto">Contain unit-tests for instructions set
and extensions</p>
</li>
<li>
<p dir="auto">Test/asm/</p>
<p dir="auto">Contain Assembler test programs for
manual testing RISC-V CPI implementation.
It depend on <strong>risc-v toolchain</strong> and
it has special auto-build <code>Makefile</code>.</p>
</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">How to build and run it on RISC-V binaries</h2>
<p dir="auto">Application can be executed as a <em>sequential RISC-V simulator</em>
(sequential, one-instruction-at-a-time semantics), by
building and executing it as a standard F# program.</p>
<p dir="auto">Supported OS:</p>
<ul dir="auto">
<li>Linux</li>
<li>Windows</li>
<li>MacOS</li>
</ul>
<p dir="auto">Supported <strong>.NET SDK</strong>:</p>
<ul dir="auto">
<li>.NET SDK 2.2</li>
<li>.NET SDK 3.0</li>
</ul>
<h3 tabindex="-1" dir="auto">Install .NET SDK</h3>
<p dir="auto">For Windows preferred way to use Visual Studio.</p>
<p dir="auto">Other examples will be for Linux.
Please follow to instruction <a href="https://dotnet.microsoft.com/download" rel="nofollow">https://dotnet.microsoft.com/download</a></p>
<p dir="auto">For Ubuntu:</p>
<div data-snippet-clipboard-copy-content="$ wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
$ sudo dpkg -i packages-microsoft-prod.deb
$ sudo apt-get update
$ sudo apt-get install apt-transport-https
$ sudo apt-get update
$ sudo apt-get install dotnet-sdk-3.0"><pre><code>$ wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
$ sudo dpkg -i packages-microsoft-prod.deb
$ sudo apt-get update
$ sudo apt-get install apt-transport-https
$ sudo apt-get update
$ sudo apt-get install dotnet-sdk-3.0
</code></pre></div>
<p dir="auto">To check installation:</p>
<p dir="auto"><code>$ dotnet --version</code></p>
<p dir="auto">will tell you what version of <code>dotnet</code> you have.</p>
<h3 tabindex="-1" dir="auto">Make the application executable</h3>
<p dir="auto">You can build the application executable with:</p>
<p dir="auto"><code>$ dotnet build</code></p>
<h3 tabindex="-1" dir="auto">Run the application executable</h3>
<p dir="auto">Most simple way to run immediately <code>run</code> (without
additional <code>build</code> command) to see command-line
options on the executable:</p>
<p dir="auto"><code>$ dotnet run -- --help</code></p>
<p dir="auto">If you run the application without option:</p>
<p dir="auto"><code>$ dotnet run</code></p>
<p dir="auto">you'll receive error message:</p>
<blockquote>
<p dir="auto">Wrong parameters put --help to get more information</p>
</blockquote>
<p dir="auto"><strong>Example</strong> to run specific ISA with extensions, verbosity
output and ELF file for execution in RISC-V CPI simulator:</p>
<p dir="auto"><code>$ dotnet run -- -A rv32i -v myapp.elf</code></p>
<h2 tabindex="-1" dir="auto">How to Contribute</h2>
<p dir="auto">Please read file <a href="https://github.com/mrLSD/riscv-fs/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h2 tabindex="-1" dir="auto">References</h2>
<ul dir="auto">
<li>github ISA manual: <a href="https://github.com/riscv/riscv-isa-manual">https://github.com/riscv/riscv-isa-manual</a></li>
<li>RISC-V specification: <a href="https://riscv.org/specifications/" rel="nofollow">https://riscv.org/specifications/</a></li>
<li>RISC-V Formal Verification Framework: <a href="https://github.com/SymbioticEDA/riscv-formal">https://github.com/SymbioticEDA/riscv-formal</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Licence</h2>
<p dir="auto"><strong>MIT License</strong></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite-Utils (106 pts)]]></title>
            <link>https://sqlite-utils.datasette.io/en/stable/index.html</link>
            <guid>36914612</guid>
            <pubDate>Fri, 28 Jul 2023 23:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite-utils.datasette.io/en/stable/index.html">https://sqlite-utils.datasette.io/en/stable/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=36914612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          

  
  <p>
  <a href="https://github.com/simonw/sqlite-utils/edit/c728c255556becc0de6fe73d45008f75f838cb68/docs/index.rst" title="Edit this page">
    
    <span>Edit this page</span>
  </a>
</p>
          <p><label for="__toc">
            <p>Toggle table of contents sidebar</p>
            <i><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No-GIL mode coming for Python (345 pts)]]></title>
            <link>https://lwn.net/Articles/939568/</link>
            <guid>36914401</guid>
            <pubDate>Fri, 28 Jul 2023 22:47:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/939568/">https://lwn.net/Articles/939568/</a>, See on <a href="https://news.ycombinator.com/item?id=36914401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
The Python Steering Council has <a href="https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474">announced
its intent</a> to accept <a href="https://peps.python.org/pep-0703/">PEP
703 (Making the Global Interpreter Lock Optional in CPython)</a>, with
initial support possibly showing up in the 3.13 release.  There are still
some details to work out, though.
</p><blockquote>
	We want to be very careful with backward compatibility. We do not
	want another Python 3 situation, so any changes in third-party code
	needed to accommodate no-GIL builds should just work in with-GIL
	builds (although backward compatibility with older Python versions
	will still need to be addressed). This is not Python 4. We are
	still considering the requirements we want to place on ABI
	compatibility and other details for the two builds and the effect
	on backward compatibility.
</blockquote><br clear="all"><hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/939568/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX punched a hole in the ionosphere (279 pts)]]></title>
            <link>https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/</link>
            <guid>36913835</guid>
            <pubDate>Fri, 28 Jul 2023 21:50:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/">https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/</a>, See on <a href="https://news.ycombinator.com/item?id=36913835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<main id="main" role="main">

					
			
<article id="post-5582">
	<!-- .entry-header -->

	<div>
		
<p><strong>July 20, 2023:</strong> On the evening of July 19th, SpaceX launched a Falcon 9 rocket from Vandenberg Space Force Base in California. Sky watchers from southern California to Arizona witnessed a <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=197985">magnificent exhaust plume</a>. At the San Francisco Volcanic Field north of Flagstaff, photographer Jeremy Perez saw something extra:</p>



<figure><a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198036"><img src="https://spaceweather.com/images2023/21jul23/redglow_strip2.jpg" alt=""></a></figure>



<p>“After the rocket passed overhead, a red fluorescent glow expanded southward and crossed over the Milky Way,” says Perez. “It was visible for almost 20 minutes.”</p>



<p>The red glow is a sign that the rocket punched a hole in the ionosphere–something SpaceX and others have been doing for years. One famous example occured on August 25, 2017, when a Falcon 9 rocket carrying Taiwan’s FORMOSAT-5 satellite <a href="https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2017SW001738">created a hole</a> four times bigger than the state of California. On June 19, 2022, another Falcon 9 <a href="https://spaceweather.com/archive.php?day=21&amp;month=06&amp;year=2022&amp;view=view">punched a hole</a> over the east coast of the USA, sparking a display of red lights from New York to the Carolinas that many observers mistook for aurora borealis.</p>



<p>“This is a <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2008SW000406">well studied phenomenon</a> when rockets are burning their engines 200 to 300 km above Earth’s surface,” explains space physicist Jeff Baumgardner of Boston University. “The red glow appears when exhaust gasses from the rocket’s 2nd stage cause the ionosphere to recombine quickly.”</p>



<p>Rocket engines spray water (H<sub>2</sub>O) and carbon dioxide (CO<sub>2</sub>) into the ionosphere, quenching local ionization by as much as 70%. A complicated series of charge exchange reactions between oxygen ions (O<sup>+</sup>) and molecules from the rocket exhaust produce photons at a wavelength of 6300 Å–the same color as red auroras.</p>



<p>This movie from David Blanchard outside Flagstaff shows how the red glow developed as the silvery rocket exhaust faded into the ionosphere:</p>



<figure><a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198052"><img src="https://spaceweather.com/images2023/21jul23/db_anim_strip.gif" alt=""></a></figure>



<p>“I watched the show from Upper Lake Mary in the Coconino National Forest,” says Blanchard. “The exhaust plume was spectacular.”</p>



<p>Baumgardner reviewed SpaceX’s video footage from the July 19th launch. “It shows the second stage engine burning at 286 km near the ionosphere’s F-region peak for that time of day. So, it is quite possible that an ionospheric ‘hole’ was made,” he says.</p>



<p>Once rare, ionospheric “punch holes” are increasingly common with <a href="https://www.nature.com/articles/d41586-023-00048-7">record numbers of rocket launches</a> led by SpaceX sending Starlink satellites to low-Earth orbit. Ham radio operators may notice them when shortwave signals fail to skip over the horizon, shooting through holes instead of bouncing back to Earth. Sudden GPS errors can also result from the anomalies. These effects may be troublesome, but they are shortlived; re-ionization occurs as soon as the sun comes up again.</p>



<p>Readers, did you see a red glow from this week’s SpaceX launch? <a href="https://spaceweathergallery2.com/submissions/index.php">Submit your photos here</a>.</p>



<p><strong>more images:</strong> <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198054">from Cheryl Hanscom Wilcox</a> of Mammoth Lakes, CA; <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198055">from MaryBeth Kiczenski</a> in the San Juan Mountains of Colorado; <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198049">from Richard Rast</a> of Mountainair, New Mexico;</p>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intent to approve PEP 703: making the GIL optional (371 pts)]]></title>
            <link>https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474</link>
            <guid>36913328</guid>
            <pubDate>Fri, 28 Jul 2023 21:07:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474">https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474</a>, See on <a href="https://news.ycombinator.com/item?id=36913328">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="A Steering Council notice about PEP 703 (Making the Global Interpreter Lock Optional in CPython)">
        <meta itemprop="articleSection" content="Core Development">
      <meta itemprop="keywords" content="">
      

          <div itemprop="articleBody" id="post_1">
              <p>Posting for the whole Steering Council, on the subject of <a href="https://discuss.python.org/u/colesbury">@colesbury</a>’s <a href="https://peps.python.org/pep-0703/">PEP 703 (Making the Global Interpreter Lock Optional in CPython)</a>.</p>
<p>Thank you, everyone, for responding to the <a href="https://discuss.python.org/t/poll-feedback-to-the-sc-on-making-cpython-free-threaded-and-pep-703/28540">poll on the no-GIL proposal</a>. It’s clear that the overall sentiment is positive, both for the general idea and for PEP 703 specifically. The Steering Council is also largely positive on both. We intend to accept PEP 703, although we’re still working on the acceptance details.</p>
<p>As we’ve done a few times in the past, we want to communicate our intent to accept the PEP along with where our current thinking is on the details around acceptance.</p>
<p>Our base assumptions are:</p>
<ul>
<li>Long-term (probably 5+ years), the no-GIL build should be the only build. We do not want to create a permanent split between with-GIL and no-GIL builds (and extension modules).</li>
<li>We want to be very careful with backward compatibility. We do not want another Python 3 situation, so any changes in third-party code needed to accommodate no-GIL builds should just work in with-GIL builds (although backward compatibility with older Python versions will still need to be addressed). This is not Python 4. We are still considering the requirements we want to place on ABI compatibility and other details for the two builds and the effect on backward compatibility.</li>
<li>Before we commit to switching entirely to the no-GIL build, we need to see community support for it. We can’t just flip the default and expect the community to figure out what work they need to do to support it. We, the core devs, need to gain experience with the new build mode and all it entails. We will probably need to figure out new C APIs and Python APIs as we sort out thread safety in existing code. We also need to bring along the rest of the Python community as we gain those insights and make sure the changes we want to make, and the changes we want them to make, are palatable.</li>
<li>We want to be able to change our mind if it turns out, any time before we make no-GIL the default, that it’s just going to be too disruptive for too little gain. Such a decision could mean rolling back all of the work, so until we’re certain we want to make no-GIL the default, code specific to no-GIL should be somewhat identifiable.</li>
</ul>
<p>As such, what we currently see as the way forward is three stages:</p>
<ul>
<li>Short term, we add the no-GIL build as an experimental build mode, presumably in 3.13 (if it slips to 3.14, that is not a problem). We want the build mode to be experimental to make it clear that while the core devs support that build mode, we can’t expect the community to support it outright. We need time to figure out what we need to do, at the very least in terms of API design and packaging and distribution, to enable the community to support it. We also want to discourage distributors from shipping the experimental no-GIL build as a default interpreter.</li>
<li>Mid-term, after we have confidence that there is enough community support to make production use of no-GIL viable, we make the no-GIL build supported but not the default (yet), and set a target date/Python version for making it the default. The timing is going to depend a lot on, for example, how backward compatible the API changes end up being (e.g., what to do about the stable ABI), and how much work the community thinks they still need to do. We expect this to take at least a year or two, possibly more. Once we declare it supported we expect some distributors may start shipping no-GIL by default, although it will probably vary greatly by how many other Python packages support no-GIL at that point.</li>
<li>Long-term, we want no-GIL to be the default, and to remove any vestiges of the GIL (without unnecessarily breaking backward compatibility). We don’t want to wait too long with this, because having two common build modes may be a heavy burden on the community (as, for example, it can double test resources and debugging scenarios), but we can’t rush it either. We think it may take as much as five years to get to this stage.</li>
</ul>
<p>Throughout the process we (the core devs, not just the SC) will need to re-evaluate the progress and the suggested timelines. We don’t want this to turn into another ten year backward compatibility struggle, and we want to be able to call off PEP 703 and find another solution if it looks to become problematic, and so we need to regularly check that the continued work is worth it.</p>
<p>We hope that this gives some clarity into the future of the PEP while we work on the exact acceptance details. The SC will work to finalise the acceptance over the coming weeks.</p>
            </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/bjkeefe"><span itemprop="name">bjkeefe</span></a>
                (bjkeefe)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T22:39:51Z">
                    July 28, 2023, 10:39pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T22:39:51Z">
              <span itemprop="position">2</span>
              </span>
            </p></div>
            <p>I wish I had the words to express my gratitude for the work that you folks put in on things like this.  I don’t, so, just: thank you, so much.  Another reason why I am really glad I decided to start teaching myself Python.</p>

            

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I respect the decision however unfortunately I am not in favor of it. Nevertheless I hope for and wish the core devs all the success and luck for a good positive outcome.</p>

            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/Eclips4"><span itemprop="name">Eclips4</span></a>
                (Kirill Podoprigora)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T23:00:43Z">
                    July 28, 2023, 11:00pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T23:00:43Z">
              <span itemprop="position">4</span>
              </span>
            </p></div>
            <p>Glad to hear that news. That’s incredible news for CPython. I hope that I can help in some way in realization of it. Good luck!</p>

            

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/diegor"><span itemprop="name">diegor</span></a>
                (Diego Russo)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T23:26:27Z">
                    July 28, 2023, 11:26pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T23:26:27Z">
              <span itemprop="position">5</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Thanks for the carefulness you are applying to the whole process whilst being positive in getting the changes. The whole CPython community will really appreciate <em>not</em> to have again a python2/3 situation.</p>
<p>Thanks and good luck!</p>
            </div>

            

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/itamaro"><span itemprop="name">itamaro</span></a>
                (Itamar Oren)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T00:11:20Z">
                    July 29, 2023, 12:11am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T00:11:20Z">
              <span itemprop="position">6</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Thank you for sharing this notice in anticipation of the official acceptance - this is super exciting!</p>
<p><a href="https://discuss.python.org/u/colesbury">@colesbury</a> is currently out on vacation, but should be back in a couple of weeks.<br>
We at Meta are excited about the intention to accept PEP-703, and are looking forward to getting to work on a smooth landing of the implementation!</p>
            </div>

            

            

          </div>
          <div itemprop="comment" id="post_7" itemscope="" itemtype="http://schema.org/Comment">
              
<p>I’m happy to be an early adopter, and I know that a handful of packages have already been modified to work with <code>nogil</code>. Are those versions available somewhere?</p>
<p>Maybe this question is jumping the gun and there will be a more “official” way to do this in the future?</p>
            </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/ofek"><span itemprop="name">ofek</span></a>
                (Ofek Lev)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T01:23:48Z">
                    July 29, 2023,  1:23am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T01:23:48Z">
              <span itemprop="position">8</span>
              </span>
            </p></div>
            <p>I am absolutely elated! When the initial implementation is released I will make sure we promptly begin testing <a href="https://discuss.python.org/t/pep-703-making-the-global-interpreter-lock-optional-3-12-updates/26503/92">at work</a>.</p>

            

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/Tinche"><span itemprop="name">Tinche</span></a>
                (Tin Tvrtković)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T01:52:42Z">
                    July 29, 2023,  1:52am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T01:52:42Z">
              <span itemprop="position">9</span>
              </span>
            </p></div>
            <p>Huge congratulations to everyone involved! Exciting times ahead.</p>

            

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/davidism"><span itemprop="name">davidism</span></a>
                (David Lord)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:09:06Z">
                    July 29, 2023,  2:09am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:09:06Z">
              <span itemprop="position">10</span>
              </span>
            </p></div>
            <p>Excited to follow this! As soon as cibuildwheel supports it, I’ll add the additional wheels for MarkupSafe. Or add some experimental builds somewhere before that.</p>

            

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/rednafi"><span itemprop="name">rednafi</span></a>
                (Redowan Delowar)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:43:25Z">
                    July 29, 2023,  2:43am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:43:25Z">
              <span itemprop="position">11</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>I’m beyond stoked for this. If Python can run truly concurrent code without sacrificing the current single core execution speed of 3.12, that’d be a huge win for the community and people who are heavily invested in this ecosystem.</p>
<p>I’ll start testing it on my code the moment the nogil flag becomes publicly available. Also curious to see how it’ll break single threaded code with tons of mutable state.</p>
            </div>

            

            

          </div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/rednafi"><span itemprop="name">rednafi</span></a>
                (Redowan Delowar)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:45:02Z">
                    July 29, 2023,  2:45am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:45:02Z">
              <span itemprop="position">12</span>
              </span>
            </p></div>
            <p>Meta is doing some fantastic work on the LLM side as well as on the core Python side. This is fantastic to see <img src="https://emoji.discourse-cdn.com/apple/pray.png?v=12" title=":pray:" alt=":pray:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>This is delightful news! I will make it a goal to get PyO3 ready to support nogil / PEP 703 as soon as possible!</p>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The U.K. government is close to eroding encryption worldwide (539 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide</link>
            <guid>36913268</guid>
            <pubDate>Fri, 28 Jul 2023 21:01:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide">https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide</a>, See on <a href="https://news.ycombinator.com/item?id=36913268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The U.K. Parliament is pushing ahead with a sprawling internet regulation bill that will, among other things, undermine the privacy of people around the world. The </span><a href="https://bills.parliament.uk/bills/3137"><span>Online Safety Bill</span></a><span>, now </span>at the final<span> stage before passage in the House of Lords, gives the British government the ability to force backdoors into messaging services, which will destroy end-to-end encryption. No amendments have been accepted that would mitigate the bill’s most dangerous elements.&nbsp;</span></p>
<p><a href="https://eff.org/osb">TAKE ACTION</a></p>
<p><a href="https://eff.org/osb">TELL&nbsp;the U.K. Parliament: Don't Break Encryption</a></p>
<p>If it passes, the Online Safety Bill will be a huge step backwards for global privacy, and democracy itself. Requiring government-approved software in peoples’ messaging services is an awful precedent. If the Online Safety Bill becomes British law, the damage it causes won’t stop at the borders of the U.K.&nbsp;</p>
<p><span>The sprawling bill, which originated in a </span><a href="https://commonslibrary.parliament.uk/research-briefings/cbp-8743/"><span>white paper</span></a><span> on “online harms” that’s now more than four years old, would be </span><a href="https://www.theverge.com/23708180/united-kingdom-online-safety-bill-explainer-legal-pornography-age-checks"><span>the most wide-ranging internet regulation ever passed</span></a><span>. At EFF, we’ve been </span><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>clearly speaking about its disastrous effects</span></a><span> for more than a year now.&nbsp;</span></p>
<p><span>It would require content filtering, as well as age checks to access erotic content. The bill also requires detailed reports about online activity to be sent to the government. Here, we’re discussing just one fatally flawed aspect of OSB—how it will break encryption.&nbsp;</span></p>
<h3><strong><span>An Obvious Threat To Human Rights</span></strong></h3>
<p><span>It’s a basic human right to have a private conversation. To have those rights realized in the digital world, the best technology we have is end-to-end encryption. And it’s utterly incompatible with the government-approved message-scanning technology required in the Online Safety Bill.&nbsp;</span></p>
<p><span>This is because of something that EFF </span><a href="https://www.eff.org/deeplinks/2015/12/encryption-balance-2015-review"><span>has been saying for years</span></a><span>—there is no backdoor to encryption that only gets used by the “good guys.” Undermining encryption, whether by banning it, pressuring companies away from it, or requiring </span><a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"><span>client side scanning</span></a><span>, will be a boon to bad actors and authoritarian states.</span></p>
<p><span>The U.K. government wants to grant itself the right to scan every message online for content related to child abuse or terrorism—and says it will still, somehow, magically, protect peoples’ privacy. That’s simply impossible. </span><a href="https://www.eff.org/deeplinks/2022/11/experts-condemn-uk-online-safety-bill-harmful-privacy-and-encryption"><span>U.K. civil society groups</span></a><span> have condemned the bill, as have technical experts and </span><a href="https://www.globalencryption.org/2022/11/70-organizations-cyber-security-experts-and-elected-officials-sign-open-letter-expressing-dangers-of-the-uks-online-safety-bill/"><span>human rights groups around the world</span></a><span>.&nbsp;</span></p>
<p><span>The companies that provide encrypted messaging—such as WhatsApp, Signal, and the UK-based Element—have also explained the bill’s danger. In an </span><a href="https://element.io/blog/the-online-safety-bill-an-attack-on-encryption/"><span>open letter published in April</span></a><span>, they explained that OSB “could break end-to-end encryption, opening the door to routine, general and indiscriminate surveillance of personal messages of friends, family members, employees, executives, journalists, human rights activists and even politicians themselves.” Apple </span><a href="https://www.theregister.com/2023/06/29/apple_online_safety_bill_opposition/"><span>joined</span></a><span> this group in June, stating publicly that the bill threatens encryption and “could put U.K. citizens at greater risk.”&nbsp;</span></p>
<h3><strong><span>U.K. Government Says: Nerd Harder</span></strong></h3>
<p><span>In response to this outpouring of resistance, the U.K. government’s response has been to wave its hands and deny reality.</span> <span>In a response letter to the House of Lords seen by EFF, the U.K.’s Minister for Culture, Media and Sport simply re-hashes an imaginary world in which messages can be scanned while user privacy is maintained. “We have seen companies develop such solutions for platforms with end-to-end encryption before,” the letter states, a reference to <a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption">client-side scanning</a>. “Ofcom should be able to require” the use of such technologies, and where “off-the-shelf solutions” are not available, “it is right that the Government has led the way in exploring these technologies.”&nbsp;</span></p>
<p><span>The letter refers to the Safety Tech Challenge Fund, a program in which the U.K. gave small grants to companies to develop software that would allegedly protect user privacy while scanning files. But of course, they couldn’t square the circle. The grant winners’ </span><a href="https://express.adobe.com/page/vxBuQnoqvGhYE/"><span>descriptions of their own prototypes</span></a><span> clearly describe different forms of client-side scanning, in which user files are scoped out with AI before they’re allowed to be sent in an encrypted channel.&nbsp;</span></p>
<p><span>The Minister completes his response on encryption by writing:&nbsp;</span></p>
<blockquote><p><span>We expect the industry to use its extensive expertise and resources to innovate and build robust solutions for individual platforms/services that ensure both privacy and child safety by preventing child abuse content from being freely shared on public and private channels.</span></p>
</blockquote>
<p><span>This is just repeating a fallacy that we’ve heard for years: that if tech companies can’t create a backdoor that magically defends users, they must simply “nerd harder.”&nbsp;</span></p>
<h3><span></span><span>British Lawmakers Still Can And Should Protect Our Privacy</span></h3>
<p><span> U.K. lawmakers still have a chance to stop their nation from taking this shameful leap forward towards mass surveillance. </span>End-to-end encryption was not fully considered and voted on during either committee or report stage in the House of Lords. The Lords can still add a simple amendment that would protect private messaging, and specify that end-to-end encryption won’t be weakened or removed.</p>
<p>Earlier this month, <span>EFF joined U.K. civil society groups and sent </span><a href="https://www.eff.org/files/2023/07/14/all_peers_letter_-_online_safety_bill_lords_committee_stage.pdf"><span>a briefing explaining our position</span></a><span> to the House of Lords. The briefing explains the encryption-related problems with the current bill, and proposes the adoption of an amendment that will protect end-to-end encryption. If such an amendment is not adopted, those who pay the price will be “human rights defenders and journalists who rely on private messaging to do their jobs in hostile environments; and … those who depend on privacy to be able to express themselves freely, like LGBTQ+ people.”&nbsp;</span></p>
<p>It’s a remarkable failure that the House of Lords has not even taken up a serious debate over protecting encryption and privacy, despite ample time to review every every section of the bill.&nbsp;</p>
<p><a href="https://eff.org/osb">TAKE ACTION</a></p>
<p><a href="https://eff.org/osb">TELL the U.K. Parliament:&nbsp;PROTECT Encryption</a>—And our privacy</p>
<p><span>Finally, Parliament should reject this bill because universal scanning and surveillance is abhorrent to their own constituents. It is not what the British people want. </span><a href="https://element.io/blog/end-to-end-encryption-the-will-of-the-british-people/"><span>A recent survey of U.K. citizens</span></a><span> showed that 83% wanted the highest level of security and privacy available on messaging apps like Signal, WhatsApp, and Element.&nbsp;</span></p>
<p><span>Documents related to the U.K. Online Safety Bill:&nbsp;</span></p>
<ul>
<li><span>EFF info page on the <a href="https://www.eff.org/pages/uk-online-safety-bill-massive-threat-online-privacy-security-and-speech">U.K. Online Safety Bill</a></span></li>
<li><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>EFF Deeplinks Blog</span></a><span>: How the OSB attacks Free Speech and Encryption (August 2022)&nbsp;</span></li>
<li><span><a href="https://www.eff.org/deeplinks/2021/07/uks-draft-online-safety-bill-raises-serious-concerns-around-freedom-expression">EFF Deeplinks Blog</a>:&nbsp;UK's Draft Online Safety Bill Raises Serious Concerns Around Freedom of Expression (July 2021)</span></li>
<li><a href="https://www.globalencryption.org/2022/11/70-organizations-cyber-security-experts-and-elected-officials-sign-open-letter-expressing-dangers-of-the-uks-online-safety-bill/"><span>Civil society open letter</span></a><span> on Online Safety Bill (November 2022)</span></li>
<li><a href="https://element.io/blog/the-uks-online-safety-bill-undermines-everyones-safety/"><span>Open Letter</span></a><span> from encrypted messaging providers about Online Safety Bill (April 2023)&nbsp;</span></li>
<li><span>EFF and Allied NGOs </span><a href="https://www.eff.org/files/2023/07/14/joint_civil_society_briefing_for_peers_on_private_messaging_-_report_stage.pdf"><span>Briefing to House of Lords</span></a><span> (July 2023)&nbsp;&nbsp;</span></li>
</ul>


</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lonely Work of Moderating Hacker News (2019) (214 pts)]]></title>
            <link>https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news</link>
            <guid>36911923</guid>
            <pubDate>Fri, 28 Jul 2023 19:22:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news">https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news</a>, See on <a href="https://news.ycombinator.com/item?id=36911923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="IframeEmbed"></figure><p>Open-plan offices offer few pleasures; one of them is snooping on other people’s browsing habits. When, years ago, I began working for tech companies in San Francisco, I noticed that my co-workers were always scrolling through a beige, text-only Web site that resembled a nineteen-nineties Internet forum. They were reading Hacker News—a link aggregator and message board that is something of a Silicon Valley institution. Technologists in Silicon Valley assume familiarity with Hacker News, just as New Yorkers do with the New York <em>Post</em> and the New York <em>Times</em>. For some, it’s the first Web site they pull up in the morning; it captures the mix of technical obsession, business ambition, and aspirational curiosity that’s typical of the Valley. On any given day, its top links might include a Medium post about <a href="https://medium.com/swlh/brief-thoughts-on-getting-hired-as-a-senior-coder-94f38998bb08">technical hiring</a>; a 1997 article from <em>Outside</em> magazine about <a href="https://www.outsideonline.com/2152131/freezing-death?page=all">freezing to death</a>; an open-source <a data-offer-url="https://news.ycombinator.com/item?id=20571739" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=20571739&quot;}" href="https://news.ycombinator.com/item?id=20571739" rel="nofollow noopener" target="_blank">virtual private network</a> hosted on GitHub; an <a href="http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf">academic paper</a>, from 2006, about compiler construction; an <a data-offer-url="https://news.ycombinator.com/item?id=20297446" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=20297446&quot;}" href="https://news.ycombinator.com/item?id=20297446" rel="nofollow noopener" target="_blank">announcement</a> from Facebook’s corporate communications team; a personal blog post about Linux kernels, and another about <a data-offer-url="https://www.deepsouthventures.com/i-sell-onions-on-the-internet/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.deepsouthventures.com/i-sell-onions-on-the-internet/&quot;}" href="https://www.deepsouthventures.com/i-sell-onions-on-the-internet/" rel="nofollow noopener" target="_blank">selling Vidalia onions</a> on the Internet. Nearly all the software engineers I know check it religiously. Not one of them has a neutral opinion about it.</p><p>Like many of the software products that have shaped the Valley, Hacker News began as a side project. In 2007, the venture capitalist Paul Graham, who was then the president of the startup accelerator Y Combinator—an early investor in Dropbox, Stripe, Reddit, Twitch, and other companies—built the site as a way to experiment with Arc, a new programming language that he was co-authoring. Originally, Graham named the site Startup News. He hoped that it would serve as a new home for the startup founders and “would-be founders” who had once gathered on Reddit, before that site grew too popular to feel like a community. Among other benefits, he imagined that Startup News might help him find worthy entrepreneurs. (“There are a number of Reddit users that I know only by their usernames, but I know must be smart from the things they’ve written,” he explained, in his launch announcement. “We’re counting on the same phenomenon to help us decide who to fund.”) Within a few months, though, Graham found that startup-centric conversation had its limits. He renamed the site Hacker News, and expanded its focus to include “anything that good hackers would find interesting&nbsp;.&nbsp;.&nbsp;. anything that gratifies one’s intellectual curiosity.” (Hacker News is still owned by Y Combinator.)</p><p>The site was intentionally simple. It offered a dynamic list of links, submitted by users, each of which could be expanded into its own unique comment thread. Readers could upvote or downvote links and comments, and the top thirty links would be featured on the front page. The guidelines specified that most non-tech-related news—political news, in particular—was off topic. Users discussed the merits of relational databases, the complexities of co-founder relationships, and the pros and cons of dropping out of college. They exchanged screenshots of their work environments and compared their results on a “nerd quiz” that asked them to name a programming language for every letter of the alphabet. They commented on Graham’s essays about programming and entrepreneurship—“Like chess or painting or writing novels,” he <a data-offer-url="https://news.ycombinator.com/item?id=811433" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=811433&quot;}" href="https://news.ycombinator.com/item?id=811433" rel="nofollow noopener" target="_blank">wrote</a>, “making money is a very specialized skill”—and shared advice on how to get into Y Combinator.</p><p>At first, the site attracted about sixteen hundred daily visitors, and Graham moderated and maintained it himself. Today, around five million people read Hacker News each month, and it’s grown more difficult to moderate. The technical discussions remain varied and can be insightful. But social, cultural, and political conversations, which, despite the guidelines, have proliferated, tend to devolve. A recent comment thread about <a href="https://www.nytimes.com/2019/06/05/business/youtube-remove-extremist-videos.html">a <em>Times</em> article</a>, “YouTube to Remove Thousands of Videos Pushing Extreme Views,” yielded a response likening journalism and propaganda; a muddled juxtaposition of pornography and Holocaust denial; a vague side conversation about the average I.Q. of Hacker News commenters; and confused analogies between white supremacists and Black Lives Matter activists. In April, when <a href="https://www.bbc.com/news/science-environment-47891902">a story</a> about Katie Bouman, an M.I.T. researcher who helped develop a technology that captured the first photo of a black hole, rose to the front page, users combed through her code on GitHub in an effort to undermine the weight of her contributions.</p><p>The site’s now characteristic tone of performative erudition—hyperrational, dispassionate, contrarian, authoritative—often masks a deeper recklessness. Ill-advised citations proliferate; thought experiments abound; humane arguments are dismissed as emotional or irrational. Logic, applied narrowly, is used to justify broad moral positions. The most admired arguments are made with data, but the origins, veracity, and malleability of those data tend to be ancillary concerns. The message-board intellectualism that might once have impressed V.C. observers like Graham has developed into an intellectual style all its own. Hacker News readers who visit the site to learn how engineers and entrepreneurs talk, and what they talk about, can find themselves immersed in conversations that resemble the output of duelling Markov bots trained on libertarian economics blogs, “The Tim Ferriss Show,” and the work of Yuval Noah Harari.</p><p>People have been trying to outsmart one another on Internet forums for as long as there have been Internet forums. Still, Hacker News has an unusually wide influence. Landing a blog post or personal project on the front page is a badge of honor for many technologists, and the site has become a regional export: ninety per cent of its traffic comes from outside the Bay Area, and a third of its users are in Europe. The site is now a portal to tech culture for millions of people. At the same time, it has become a punch line and a punching bag for tech workers and engineers who see it as a locus of hubris, myopia, and exclusivity. A word that comes up frequently among its critics is “toxic.”</p><p>Picturing the moderators responsible for steering conversation on Hacker News, I imagined a team of men who proudly self-identify as neoliberals and are active in the effective-altruism movement. (I assumed they’d be white men; it never occurred to me that women, or people of color, could be behind the site.) Meeting them, I feared, would be like participating in a live-action comment thread about the merits of Amazon Web Services or whether women should be referred to as “females.” “Debate us!” I imagined them saying, in unison, from their Aeron chairs.</p><p>The site’s real-life moderators are Daniel Gackle and Scott Bell, two wildly polite old friends. On Facebook and <a href="https://www.newyorker.com/tech/annals-of-technology/the-fight-for-the-future-of-youtube">YouTube</a>, moderation is often done reactively and anonymously, by teams of overworked contractors; on <a href="https://www.newyorker.com/magazine/2018/03/19/reddit-and-the-struggle-to-detoxify-the-internet">Reddit</a>, teams of employees purge whole user communities like surgeons removing tumors. Gackle and Bell, by contrast, practice a personal, focussed, and slow approach to moderation, which they see as a conversational act. They treat their community like an encounter group or Esalen workshop; often, they correspond with individual Hacker News readers over e-mail, coaching and encouraging them in long, heartfelt exchanges.</p><p>Gackle and Bell met in Calgary, in the early two-thousands, at a local user group for the rarefied programming language Lisp. (Arc, the language in which Hacker News is written, is a descendant of it.) Gackle, whose name is pronounced “Gack-lee” and who declined to share his age, is a muscular, bald, and loquacious father of two and a devoted fan of the Canadian sketch-comedy show “The Kids in the Hall.” Bell, who is thirty-four, is willowy and soft-spoken, with closely buzzed hair and tattoos that peek out from beneath his cardigans. The two often finish each other’s sentences; they sometimes dress, accidentally, in matching outfits. (Bell attributes this to office-wide “sartorial mimetics.”) Online and in person, Gackle is chatty, Bell reserved. They are reluctant, protective spokespeople. Pressed to describe Hacker News, they do so by means of extravagant, sometimes tender metaphors: the site is a “social ecosystem,” a “hall of mirrors,” a “public park or garden,” a “fractal tree.”</p><p>“Hacker News is quite a counterintuitive thing,” Gackle said, in a conference room in Y Combinator’s San Francisco office. “At least how we see it, from our perspective, it’s often pretty different from how it appears from the outside.”</p><p>“It doesn’t grab you right away, just on the surface,” Bell said, his hands cradling a mug of tea. “It takes a little bit to get a feel for what it is.”</p><p>“The Hacker News front page is a product of a certain tension,” Gackle said. “There’s multiple tug-of-wars going on over the types of stories people would like to see. The one consensus is that it’s not as good as it used to be. I feel bad when people say that, but I also realize that, in a way, it indicates a certain attachment.”</p><p>“There are some people who don’t realize Hacker News is moderated at all,” Bell continued. “There are some people with whom we’ve been e-mailing for four or five years. My guess is that the distribution is somewhat mostly in the middle. But I don’t know.” He turned to Gackle, looking grave. “I don’t have a strong sense of that. Do you, Dan?”</p><p>“I don’t think I can answer it,” Gackle said, intently. “One of the things I’ve learned is that almost all of the generalizations are wrong. And I’ve learned this because people love to post generalizations about Hacker News to Hacker News.”</p><p>In an Emacs file, Gackle collects a list of contradictory statements that people have used to describe Hacker News. (“SJW cesspool”; “<a data-offer-url="https://news.ycombinator.com/item?id=14205262" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=14205262&quot;}" href="https://news.ycombinator.com/item?id=14205262" rel="nofollow noopener" target="_blank">a haven</a> for alt-right and libertarian people”; “If you don’t support neoliberal fantasies, your comments <a data-offer-url="https://news.ycombinator.com/item?id=14529468" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=14529468&quot;}" href="https://news.ycombinator.com/item?id=14529468" rel="nofollow noopener" target="_blank">probably aren’t welcome here</a>”; “The only thing is left is to change Hacker News icon <a data-offer-url="https://news.ycombinator.com/item?id=18189135" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=18189135&quot;}" href="https://news.ycombinator.com/item?id=18189135" rel="nofollow noopener" target="_blank">to Che Guevara emblem</a>.”) He and Bell assert their own opinions in subtle ways. Recently, they made some small changes to the Hacker News guidelines, which have always hewed closely to those that Graham drafted in 2007. To one about throwaway accounts—acceptable for sensitive information but discouraged as a regular practice—they added the reminder “HN is a community.” In another—“Comments should get more civil and substantive, not less, as a topic becomes more divisive”—they changed the phrase “civil and substantive” to “thoughtful and substantive.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Recently, an essay in the <em>New Atlantis</em> titled “<a data-offer-url="https://www.thenewatlantis.com/publications/do-elephants-have-souls" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.thenewatlantis.com/publications/do-elephants-have-souls&quot;}" href="https://www.thenewatlantis.com/publications/do-elephants-have-souls" rel="nofollow noopener" target="_blank">Do Elephants Have Souls?</a>,” from 2013, hit the front page. The piece generated immediate resistance. Commenters responded literally to the question posed in the title and bickered about the word “soul.” Conversation spiralled, with users making arguments about Cartesian metaphysics and quoting Socrates. “Why is such an unscientific question so high on HN?” one commenter asked. “Or to rephrase, if we don’t know what a soul is, how can we hope to answer it WRT elephants? So how and why should a reasoning person rate an article like this?”</p><p>“The article itself is just this wonderful exploration into the literature around elephants,” Gackle told me. “I don’t know how anybody could read that article and not just go, like, ‘Wow’—I mean, at least if you’re interested in elephants in any way.” Posting under his Hacker News username, dang, he staged a moderate intervention. “All: This article is not about souls,” he wrote. “It’s about elephants, humans, how we relate to elephants, how they relate to us, how humans relate to non-humans.” He continued:</p><blockquote><p>It is erudite and beautiful. It uses the astonishing literature about elephants to ask about ourselves, them, and the world. “Soul” here is a trope for aspects of humanness that we may or may not have in common. Usually, we just edit titles that are triggering people. If I were to do that here, I might rename it “Elephants and Anthropomorphism.” But when an article is this rich, moving, even profound, taking away its title would maim it. It bears a much better discussion than the thread has given it so far, so please let’s talk about what’s interesting and stay off the metaphysics.</p></blockquote><p>One reader, with the username solipsism, <a data-offer-url="https://news.ycombinator.com/item?id=19836914" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=19836914&quot;}" href="https://news.ycombinator.com/item?id=19836914" rel="nofollow noopener" target="_blank">objected to Gackle’s claims</a> about what was and wasn’t interesting. “Most would agree there’s a point at which moderation goes too far,” solipsism wrote. “I can’t tell if you’re making an appeal as a person, or making a decree as a moderator. I read the article, and it’s absolutely full of metaphysics.&nbsp;.&nbsp;.&nbsp;. These metaphysical topics interest me, and apparently they interested the writer, even if they don’t interest you.”</p><p>Gackle conceded that his dismissal was unfair. He removed the reference to metaphysics from his comment. “The point is simply that the article deserves a better discussion,” he wrote, with breezy, cheerful weariness. “I’m making an appeal as a moderator person.”</p><p>Bell and Gackle didn’t set out to become forum moderators. At Stanford, Gackle wrote a master’s thesis on Pyotr Vyazemsky and Nikolay Karamzin, two nineteenth-century Russian poets; Bell studied network engineering, at the Southern Alberta Institute of Technology, after a stint performing in punk, hardcore, and metalcore bands. When they met, in the Lisp user group, they both were working as coders and unfulfilled by their office jobs. Gackle later told me that he sees frustration at work as part of the DNA of Hacker News. “The instinct that there simply has to be a better way to build systems, and the yearning to connect with it,” he said. “If you can’t do that at your job, and few can, then you can at least dream and read and argue about it on the Internet. Hacker News is the inverse image of many people’s jobs, overlaid on top of each other—an escape valve for frustrated idealists.”</p><p>Bell had discovered Lisp while staving off boredom in a college computer-science course (he read technical documentation to pass the time); Gackle learned about it as a child, in <em>Byte</em> magazine. “When I program in other languages, even ones I know well,” he said, “I feel like I’ve flown to Jupiter. Gravity is so strong that every step is a struggle. In Lisp, you can dance.” In the user group, they found they had overlapping intellectual interests and complementary programming skills. Gackle worked at what he calls “a sort of product factory” where he built “little Potemkin products that would mostly get killed.” He had come to feel that he was helping to build software for users who didn’t need it; what they needed, he believed, was a customizable spreadsheet that improved on Microsoft Excel. (“Excel was these users’ Garden of Eden, where they could make their own spreadsheets and play with them in endless bliss, but they were cast out of Eden because their problems were too complex,” he told me.) In 2008, he and Bell formed a startup, Skysheet, with the mission of building a Web-based spreadsheet. A few months later, they were accepted into Y Combinator, which they’d learned about through Graham’s essays. They moved to Silicon Valley at the height of the recession.</p><p>Skysheet’s Y Combinator “class” of sixteen companies included Heyzap, a mobile-ad network that was acquired in 2015, for forty-five million dollars, and a struggling travel startup that would go on to become Airbnb. At the end of the program, the other founders in the group voted Skysheet the third most likely to succeed. But, after Y Combinator, Bell and Gackle found it difficult to fund-raise. It was the spring of 2009, and the market was bottoming out. “We learned that fund-raising means presenting yourself as impressive, desirable, and just about to be huge, even if the person you’re talking to is so mistaken as not to invest,” Gackle recalled. (Hearing this, I thought of the rhetorical style so widely deployed on Hacker News.) “Perhaps it’s partly the Canadianness, but this does not come naturally to either Scott or me.” Eventually, they raised a hundred and eighty thousand dollars and moved back to Canada to build the software. Some of the technical challenges were more complex than they’d anticipated; there was no existing literature to guide them. As delays mounted, Gackle had panic attacks nightly.</p><p>By 2012, Skysheet had yet to launch a public product and had run out of money. Bell made the painful decision to leave the company, taking a job with a software consultancy. Gackle forged ahead. “My feeling was I would rather fail at this than succeed at anything else,” he told me. Later that year, Graham reached out with an invitation to work on Hacker News, which, at that point, had nearly two million users. “I said no, because I knew it would mean no longer being able to think about spreadsheet software all day,” Gackle said.</p><p>That August, Gackle went for a hike in the Rockies. He slipped and fell on a mountainside, tumbling downhill, bouncing off the rocks. Somehow, he rolled to a stop against a boulder. Shaken, he hiked home. “It jolted me deeply, and after that I admitted to myself that I also was out of money and needed a job,” Gackle recalled. He reached out to Graham: “I told him yes, but with a feeling of unfinished business about this technical problem, which I still carry.” He became a behind-the-scenes moderator of Hacker News. A couple of years later, he hired Bell. In a way, they were perfectly prepared. Having briefly lived the dream and failed, they would now immerse themselves in a culture in which winning—an argument, a market—is a top priority.</p><p>Gackle and Bell are the only Y Combinator employees working on the site. In addition to moderating it, they maintain its technical infrastructure. (When I mentioned, at a party, that I was writing about Hacker News, an entrepreneur blurted, “It’s the fastest Web site I use!”) They post in comment threads, defending commenters who encounter combative or aggressive behavior and content that’s been downvoted, flagged, or misunderstood; they sometimes spend hours a day e-mailing with individual users, helping them use Hacker News more conscientiously and effectively. (“Present this not primarily as a moral appeal&nbsp;.&nbsp;.&nbsp;. but as an intellectual one,” Gackle wrote, over e-mail, to a user who was soliciting help for a man who had recently been exonerated after eleven years in prison for a crime he did not commit. “You should frame it as a puzzle or an engineering problem. That will engage the community’s curiosity, which is your only hope for getting a real discussion going.”)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“The only way to learn it is to get it wrong, and, when you get it wrong, you get flamed,” Gackle said, in the conference room. “And you get flamed so hard that it’s like being stung by a swarm of bees. It’s sort of like operant conditioning. If you put yourself in that position, where you’re getting stung on a daily basis, you’re soon going to start learning what makes the bees less likely.&nbsp;.&nbsp;.&nbsp;.” he paused. “Or, actually, I like bees. I would say ‘wasps’—what makes the wasps less likely to bite you.”</p><p>“The other way to learn is to let someone else get stung first,” Bell said, quietly.</p><p>In December, 2016—about a month after Donald Trump’s election—<a href="https://www.washingtonpost.com/news/worldviews/wp/2016/11/30/researchers-may-have-found-many-of-chinas-30-million-missing-girls/?utm_term=.6a8ddb01a670">an article</a> from the Washington <em>Post</em> hit Hacker News’ front page. The article covered a study of China’s “one child” policy, conducted by researchers at the University of Kansas and Shaanxi Normal University, that claimed that female children who were long believed to have been aborted or killed in infancy were simply not registered with the government at birth. The ensuing conversation rapidly devolved into arguments over whether or not institutional barriers exist; whether it was acceptable for users to correct the grammar of commenters whose first language was not English; whether sublimated testosterone was responsible for jihad and sexual assaults in Germany; the merits of Jill Stein; and voter fraud.</p><p>“Every single time poll restrictions have been proposed, it’s been for racist causes,” one user wrote, in response to a commenter with the username rokosbasilisk, who was advocating for a voter-identification system. “You yourself may not be a hooded member of the KKK, but you are pushing for the same things, and that’s all that matters.”</p><p>“so india wanted to voter id to prevent black people from voting?” rokosbasilisk responded. “seriously the race stuff just doesnt matter if we follow the indian model.”</p><p>“I have more faith in black people than you i guess, and think they are perfectly capable of getting an id,” a third user wrote.</p><p>“This has taken us into sociopolitical hell,” Bell posted, “and Hacker News isn’t that kind of site.” He “detached” some of the more inflammatory conversations from the main thread, hiding them from view.</p><p>That discussion, and also several others that emerged in the weeks after the election, prompted Gackle and Bell to experiment with and idea they called Political Detox Week. For seven days, political stories and threads would be considered off-topic and flagged by the moderators. The experiment was met with both relief and derision. “Political discourse is antithetical to rational, intelligent discussion,” one user wrote, in a comment that was upvoted to the top of the thread about the detox week. “Technological topics are always interesting to me&nbsp;.&nbsp;.&nbsp;. I love that there’s this corner of the Internet where I can participate in a reasoned, interesting technical community. Please don’t ruin it with politics, especially the polarizing American variant.”</p><p>Down the page, another user expressed disdain for the experiment. “The idea that we can carve out a space that exists outside of politics and ideology is delusional,” the user wrote. “Squelching political discussion won’t cause us all to transcend ideology, it’ll just make it impossible to discuss or critique a dominant ideology whenever one shows up in someone’s unstated assumptions.”</p><p>“Of course it’s delusional,” Gackle replied. “And still we have to moderate this site.” Three days later, he <a data-offer-url="https://news.ycombinator.com/item?id=13131251" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=13131251&quot;}" href="https://news.ycombinator.com/item?id=13131251" rel="nofollow noopener" target="_blank">announced</a> that Political Detox Week would be coming to an end. They’d learned, among other things, that “it’s impossible to define ‘politics’ with any consensus because that question is itself highly political.”</p><p>The most ideologically motivated or extreme posts and comments on Hacker News—an interview piece from Quillette titled “Understanding Victimhood Culture”; a link to a video of <a href="https://www.newyorker.com/tech/annals-of-technology/how-silicon-valleys-workplace-culture-produced-james-damores-google-memo">James Damore</a> and <a href="https://www.newyorker.com/magazine/2018/03/05/jordan-petersons-gospel-of-masculinity">Jordan Peterson</a> in conversation; one user telling another that all Jewish people should <a data-offer-url="https://news.ycombinator.com/item?id=13056816" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=13056816&quot;}" href="https://news.ycombinator.com/item?id=13056816" rel="nofollow noopener" target="_blank">relocate</a> to Israel—tend to get flagged by the community or the site’s anti-abuse systems, many of which Bell and Gackle have written themselves. (Flagged posts are removed from view, though they remain searchable by URL; flagged comments are rendered in pale gray text, and only visible to logged-in users who have chosen to see “dead” comments.) Still, as an occasional reader, I have noticed certain trends. When stories that focus on structural barriers faced by women in the workplace, or on diversity in tech, or on race or masculinity—stories, admittedly, that are more intriguing to me, a person interested in the humanities, than stories on technical topics—hit the front page, users often flag them, presumably for being off topic, so fast that hardly any comments accrue. When I shared these impressions with Gackle and Bell, they looked distressed. I asked if these were problems that they felt they could, or should, be controlling or trying to change on the site.</p><p>“From our perspective, the big surprise is how little control we actually have. We have to play our cards very carefully and very wisely, or even that control will sort of evaporate,” Gackle said. “There’s often a strong wish to solve these contentious problems by changing the software, and, to the extent that we’ve tried things like that, we haven’t found it to work. What does seem to work better is personal interaction, over and over and over again, with individual users. That, case by case by case, seems to move the needle. But it’s very slow.”</p><p>“If we’re trying to change something deep, the ingredient is time,” Bell said. “Patience allows us to be ambitious—to imagine people being more kind to each other, for example. It sounds kind of crazy.”</p><p>For Gackle and Bell, moderating Hacker News has presented an opportunity for self-work. Together, they have read up on nonviolent communication, sociology, and psychotherapy. (Bell found Carl Rogers’s “<a data-offer-url="https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X&quot;}" href="https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X" rel="nofollow noopener" target="_blank">On Becoming a Person</a>”—a 1961 book about personal growth that became a bible of the humanistic-psychology movement—particularly valuable.) Gackle is drawn to healing workshops; Bell, to Indian philosophy. They seem, at times, to be applying old, humanist techniques to a culture obsessed with the future.</p><p>“Something that’s deeply interesting, I think, to both of us,” Gackle said, “is the way in which one can arrive at a nonviolent reaction to somebody by having greater awareness of the—” He paused. “I’ll say violence in oneself. By which I mean the kind of agitation and activation that is causing people, including ourselves, to react in a kind of fight-or-flight way that leads to misunderstanding, conflict, and, ultimately, Internet flame wars. This seemingly trivial stuff, about people getting mad at other people on the Internet, is actually tied to this much deeper and more fascinating process of what goes on between people and what goes on in oneself.”</p><p>“It’s another opportunity for us to influence the system, by exemplifying the kind of patterns of discussion that we would like to see,” Bell said. “We just want to constantly set an example.”</p><p>In April, the <em>Times</em> ran <a href="https://www.nytimes.com/2019/04/25/lens/sarah-lewis-racial-bias-photography.html">an essay</a> by Sarah Lewis, a Harvard professor, titled “The Racial Bias Built Into Photography.” The essay was a historical inquiry, inspecting lens development and film-emulsion technology, and was written in the first person. When it landed on Hacker News, users immediately rushed to flag it as off topic. Gackle changed the title to “Photography and racial bias,” and turned off flagging, which restored the essay to its original position on the front page.</p><p>“I take issue with this article simply because photography isn’t a technology at all,” one user commented. “It is an art that uses technology. There are millions of pictures of people of all races that look perfectly fine. I take issue with stirring up people for no reason. If a maker of paints in the 1800s owned slaves does that mean that painting (then, now, in the future) is racist? How ridiculous can we get?” Another user <a data-offer-url="https://news.ycombinator.com/item?id=19755097" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=19755097&quot;}" href="https://news.ycombinator.com/item?id=19755097" rel="nofollow noopener" target="_blank">posted</a> the opening lines of Rudyard Kipling’s poem “The White Man’s Burden.” A third wrote, “The people who invented the tech (US/Europe/Japan) optimised it for consumers around them. Why hate on inventors who create something cool just because it doesn’t quite work as well for all groups of people? Surely this also left a gap in the market—someone could have optimized film for darker skin tones and made a lot of money?”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“&nbsp;‘Hating’ is much too strong a word to describe the article, so much so that invoking it in a thread like this is a big upping of the flamewar ante,” Gackle replied, in the thread. He pointed the user to the site guidelines, encouraging more constructive input. He acknowledged that it was “hard to resist” inflammatory language “when a topic stirs up powerful emotions”:</p><blockquote><p>This creates a need for relief, and venting that energy in the form of extreme words is one way to get relief. Unfortunately, it doesn’t relieve anything at a community level. It just tosses the hot potato around in a way that only makes the potato hotter and more painful to the one who catches it next. What provides relief at a community level is when people find ability in themselves to acknowledge truth in what the other is saying.</p></blockquote><p>Over the years, Gackle and Bell have come to recognize their own triggers—patterns of online discourse that enrage them, depress them, or make them want to walk away. “In terms of the psychological experience of doing this job, all of your buttons are being pushed on a regular basis,” Gackle said. He now knows that it will be hard for him to keep his composure when he is being falsely accused or completely misread. (“That’s pretty much what some of the users do all day—accuse the moderators of doing something that they didn’t,” he said.)</p><p>Bell, for his part, becomes soul-weary when exposed to the unceasing spectacle of “people treating other people poorly.” “My reaction for things that get me is depressive,” Bell said. “Rather than respond outwardly, I have that internal depressive response. The issue for me is that this thing I’m very sensitive to is present in nearly everything.”</p><p>Gackle looked on as Bell spoke, then turned to me. “The sheer quantity of it is so overwhelming that one does have a depressive reaction, a hopeless reaction to it, at times,” he said. “I realized at some point that my feelings about it were like the feelings of a child trying to keep the family together. When the family is five million people, that’s a pretty tall order. It isn’t something that’s achievable. One has to learn to let go of them.”</p><p>“Don’t worry, dang is not adding anything to the conversation,” a user wrote, in the thread about race and photography. “He just enjoys virtue signaling. Hard!”</p><p>As Hacker News has grown, it has become the subject of both scrutiny and parody. A Twitter account, @shit_hn_says, highlights standout quotes from the comments section. (“If you want to do business with Iran, why don’t you just use Bitcoin?”) A hashtag, #HNwatch, collects screenshots of racist, sexist, xenophobic, and otherwise offensive or bizarre Hacker News comments. (“As a white man, I have concerns that my ethnic/gender group is being persecuted.” “In a way, the brains of startup founders and those below poverty lines work in the same way.”) Detractors refer to it as “the orange Web site,” a way of demonstrating both insider familiarity and exasperation.</p><p>N-gate, a satirical Web site with the slogan “We can’t both be right” (a NAND gate is a kind of logic gate that only outputs “false” if all of its inputs read “true”), offers a weekly summary of Hacker News discussions, dubbed “webshit weekly.” The N-gate entry about a Hacker News discussion of a <em>Times</em> article on the crashes of two Boeing 737 airliners, in Indonesia and Ethiopia, is typical. “Discussing a pair of crashes that killed almost three hundred and fifty people,” it reads, “Hacker News can’t decide whether the failure was one of user experience or branding. Other Hackernews”—as it calls commenters—“think that this plane would have worked better if it were designed by programmers with a tendency to work late for free. A majority of the comments are Hackernews incorrecting one another about FAA regulations, avionics, and lift.”</p><p>The proprietor of N-gate is an engineer who grew up in Palo Alto and now lives in the Pacific Northwest, where he works in high-performance computing. He agreed to exchange e-mails on condition of anonymity. “Almost every post deals with the same topics: these are people who spend their lives trying to identify all the ways they can extract money from others without quite going to jail,” he wrote. “They’re people who are convinced that they are too special for rules, and too smart for education. They don’t regard themselves as inhabiting the world the way other people do; they’re secret royalty, detached from society’s expectations and unfailingly outraged when faced with normal consequences for bad decisions. Society, and especially economics, is a logic puzzle where you just have to find the right set of loopholes to win the game. Rules are made to be slipped past, never stopping to consider why someone might have made those rules to start with. Silicon Valley has an ethics problem, and ‘Hacker’ ‘News’ is where it’s easiest to see.”</p><p>For decades, the phrase “Eternal September” has been used to describe the tipping point for a message board or online community—the inclusion, or invasion, of new users who dramatically change the existing subculture. (The term originated in September, 1993, after America Online made Usenet, a decades-old message-board system, accessible to many of its members, who were new to the Internet.) The creation of Startup News was a response to Reddit’s Eternal September; some of the problems with which Gackle and Bell are grappling can be traced to a similar phenomenon at Hacker News. The question they face now is whether the site’s original culture can be responsibly scaled up, or adapted, to make space for a more inclusive, wider-ranging vision of technology.</p><p>Gackle and Bell continue to believe in the value of “intellectual curiosity” as a goal. They speak of it more as a relative state than a fixed condition, using terms like “freshness” and “excitement” and “surprise and delight.” They are hopeful that, as Hacker News continues to grow, it will become, simultaneously, more diverse, more interesting, and more humane, while remaining in some fundamental sense a single community with a common goal. “The much larger sites, like Facebook, Twitter, and Reddit, all scaled by sharding,” Gackle told me, over e-mail. “HN has no shards. We have no social graph either. Everybody is in it together whether they like it or not.”</p><p>“Intellectual curiosity is everywhere, and it’s present in all demographics,” Bell said, in the conference room. “We want Hacker News to grow in all demographics, because there’s just intellectually interesting contributions from all of those communities—a greater diversity of content, of conversations, of topics, et cetera.” (He and Gackle have discussed diversifying their team, and adding a third moderator who is non-white, non-male, and, Bell joked, “non-balding.” Gackle clarified: “We've talked to each other about that. But we wouldn't make it a requirement.”) And yet the influx of outsiders doesn’t just change a community; it exposes its assumptions. The tech industry as a whole is having its own Eternal September. The world, with all its experiences and opinions, has come flooding in, and technologists are now reassessing the consequences of the systems and structures they have built or inherited. Some of these systems are social, and include the general modes of thought and expression that Hacker News embodies.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Outside the conference room, it was early evening. Through the frosted glass, we could see the shapes of Y Combinator’s employees shrugging on their backpacks and depositing their mugs in the kitchen sink. “It might seem like ‘intellectual curiosity’ isn’t primarily an ethical concern,” Gackle said. “But it actually turns out that those things are deeply related. There’s something about the way that curiosity works: it needs a kind of gentleness.”</p><p>A few weeks after meeting with Gackle and Bell, I checked Hacker News to see what commenters were saying about a <em>Times</em> story on the Facebook co-founder Chris Hughes’s antitrust work with the Federal Trade Commission. Users speculated about Hughes’s personal motivations and asked whether he had the knowledge necessary to help the government break up Facebook. Elsewhere on the site, people discussed California’s housing crisis (“The whole problem could be solved if we gave people the choice of voting where they work rather than where they live”) and a new scripting language, ChaiScript (“There’s no inherent reason a header-only library should significantly impact compile times, aside from the fact that the authors usually don’t have the foresight to make it efficient”). Skipping from thread to thread felt a bit like arriving at a party where half the room was sipping non-alcoholic shrubs and the other half had spent the afternoon tailgating in a stadium parking lot.</p><p>In the comments for a research paper, on ScienceDaily, about the evolutionary factors that may have been responsible for making humans the only mammals prone to heart attacks, a user criticized the study for having been conducted on mice. “Another couch biologist, there’s one in every thread,” posted a second user. “Thanks for all the observations, we really hadn’t thought of any of that, you single-handedly salvaged modern biological research!”</p><p>Gackle stepped in to ask the user not to break the site guidelines, and to behave more in the intended spirit of Hacker News. “Fair enough,” the user wrote; I felt a small rush of triumph, and pride, on Gackle’s behalf. Then, from the user, a follow-up question: “Why is this low-effort criticism of biology allowed?”</p><p>“It’s allowed in the sense that people are allowed to be wrong and/or ignorant because that’s what most of us are on most topics,” Gackle replied. “We can’t stop that any more than King Canute”—the ancient king of the North Sea who demonstrated the limits of his power by trying, in an ironic spirit, to command the sea—“could stop the waves. The important question is, what’s the best way to handle it if we want to have an internet forum that doesn’t suck? Experience teaches that the answer is: the patient supply of correct information by people who do know about a topic.”</p><p>I thought about the relentless patience and good faith that this style of moderation work required. I pictured Bell and Gackle as swimmers in a resistance pool, doing slow crawls against the currents of online discourse. I hoped the project of Hacker News was worth the effort. I wondered if their work might show that tech really does need humanism—that better online communities can be built one relationship at a time. Then my eyes moved down the thread, where a third user had left a new comment. It read: “King Canute was supposed to stop the tide, you couch alluder.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tremor – The React library to build dashboards fast (143 pts)]]></title>
            <link>https://www.tremor.so/</link>
            <guid>36911481</guid>
            <pubDate>Fri, 28 Jul 2023 18:53:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tremor.so/">https://www.tremor.so/</a>, See on <a href="https://news.ycombinator.com/item?id=36911481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><h2>Modular components to build dashboards in a breeze. Fully open-source, made by data scientists and software engineers with a sweet spot for design.</h2></div><div><p>20+ components</p><p>•</p><p>Apache-2.0 license</p><p>•</p><p>TypeScript Support</p></div><section id="tweets"><h2>Testimonials</h2><a href="#tweets"></a></section><div><div><div><p>Get more than 20 components with beautiful defaults and simple props. From charts to input and layout elements, we covered all the essential components to lift the tedious front-end work from your shoulders. Get ahead with our simple API approach in no time.</p></div><div><div><p><span>&lt;</span><span>Card</span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span><span>Ticket Sales</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;</span><span>Metric</span><span>&gt;</span><span><span>$ 71,465</span></span><span>&lt;/</span><span>Metric</span><span>&gt;</span></p><p><span>&lt;</span><span>Flex</span><span>className<span>=</span><span><span>"mt-3"</span></span></span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span>&lt;</span><span>Bold</span><span>&gt;</span><span><span>32%</span></span><span>&lt;/</span><span>Bold</span><span>&gt;</span><span><span>of annual target</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span><span>$ 223,328</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;/</span><span>Flex</span><span>&gt;</span></p><p><span>&lt;</span><span>ProgressBar</span><span>value<span>=</span><span><span>{ 32 }</span></span></span><span>className<span>=</span><span><span>"mt-3"</span></span></span><span>/&gt;</span></p><p><span>&lt;/</span><span>Card</span><span>&gt;</span></p></div><div><p>Ticket Sales</p><p>$ 71,465</p><div><p><b>32%</b> of annual target</p><p>$ 223,328</p></div></div></div></div><div><div><p><span>Combines design and analytics</span></p></div><div><p>Creating analytical interfaces is hard. We have distilled all our knowledge from building dashboards into Tremor. Besides our components, we provide a varierty of templates built on top of Tremor to give developers a head start on building great interfaces.</p></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free prison phone calls boost family ties, rehabilitation (355 pts)]]></title>
            <link>https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too</link>
            <guid>36911361</guid>
            <pubDate>Fri, 28 Jul 2023 18:45:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too">https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too</a>, See on <a href="https://news.ycombinator.com/item?id=36911361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Zeara Alvarez, 47, never realized just how much her big brother really cared.</p><p>She was a teenager when he was sent to prison for second-degree murder, and the pair spoke only sparingly over three decades.</p><p>That wasn’t because he had shut out the family or they had moved on. Communication between the siblings was drastically curtailed by the exorbitant cost of making prison phone calls.</p><p>At a time when most consumers enjoy free or low-cost calling, prison phone calls at their peak in California cost more than $6 per 15 minutes via a private telecommunications provider. That allowed only hurried, superficial conversations between the siblings — with one eye always on the clock.</p><p>This year California became the second state in the nation, and the largest to date, to mandate free calls in state prisons. Because family members bore the cost of the pricey calls, the new law eliminated a longstanding financial burden that forced many low-income people — particularly those of color — to choose between maintaining contact with incarcerated loved ones and putting food on the table.</p><p>Without the constant worry that the meter was running, Alvarez’s relationship with brother Anthony Perez, 51, has blossomed in recent months. </p><p>They speak several times a week. Rather than rushed conversations, there’s time for laughter and sharing memories. With their regular updates about everyday life and relaxed chats, a deeper bond has emerged.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/ccd3fc9/2147483647/strip/true/crop/3341x2227+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/82c86c2/2147483647/strip/true/crop/3341x2227+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/3d41183/2147483647/strip/true/crop/3341x2227+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/77eb864/2147483647/strip/true/crop/3341x2227+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/de07e61/2147483647/strip/true/crop/3341x2227+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/99c38e4/2147483647/strip/true/crop/3341x2227+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/83cbf9f/2147483647/strip/true/crop/3341x2227+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 2160w" sizes="100vw">     <img alt="A woman talking on a cellphone while sitting at a desk in front of a window" srcset="https://ca-times.brightspotcdn.com/dims4/default/a82a047/2147483647/strip/true/crop/3341x2227+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/57f7292/2147483647/strip/true/crop/3341x2227+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/5ba72a1/2147483647/strip/true/crop/3341x2227+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/5b4e56c/2147483647/strip/true/crop/3341x2227+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/5dece19/2147483647/strip/true/crop/3341x2227+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/e1367c7/2147483647/strip/true/crop/3341x2227+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/ee234a9/2147483647/strip/true/crop/3341x2227+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/8f3d81e/2147483647/strip/true/crop/3341x2227+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Zeara Alvarez, in her office at the Anti-Recidivism Coalition in Los Angeles, talks with brother Anthony Perez, who called from Ironwood State Prison in Blythe.</p>   <p>(Jason Armond / Los Angeles Times)</p>   </div>  </figure></div><div data-click="enhancement" data-align-right=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/2b7fba5/2147483647/strip/true/crop/2370x3555+0+0/resize/320x480!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/69e86bd/2147483647/strip/true/crop/2370x3555+0+0/resize/568x852!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/492c2f6/2147483647/strip/true/crop/2370x3555+0+0/resize/768x1152!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/2ec3147/2147483647/strip/true/crop/2370x3555+0+0/resize/1080x1620!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/de0e076/2147483647/strip/true/crop/2370x3555+0+0/resize/1240x1860!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/f2069a4/2147483647/strip/true/crop/2370x3555+0+0/resize/1440x2160!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/7600bbe/2147483647/strip/true/crop/2370x3555+0+0/resize/2160x3240!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 2160w" sizes="100vw">     <img alt="A woman standing with her back against a gray wall, looking down at her hands " srcset="https://ca-times.brightspotcdn.com/dims4/default/6da0b26/2147483647/strip/true/crop/2370x3555+0+0/resize/320x480!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/9153ed8/2147483647/strip/true/crop/2370x3555+0+0/resize/568x852!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/ff29d06/2147483647/strip/true/crop/2370x3555+0+0/resize/768x1152!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/8604005/2147483647/strip/true/crop/2370x3555+0+0/resize/1080x1620!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/985c1fb/2147483647/strip/true/crop/2370x3555+0+0/resize/1240x1860!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/aaf2917/2147483647/strip/true/crop/2370x3555+0+0/resize/1440x2160!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/dd7ccee/2147483647/strip/true/crop/2370x3555+0+0/resize/2160x3240!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 2160w" sizes="100vw" width="2000" height="3000" src="https://ca-times.brightspotcdn.com/dims4/default/158d2b2/2147483647/strip/true/crop/2370x3555+0+0/resize/2000x3000!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>“We were actually crying together, and that had not ever happened,” Alvarez said of a recent talk with her brother, made possible by California’s mandated free calls from state prisons.</p>   <p>(Jason Armond / Los Angeles Times)</p>   </div>  </figure></div><p>“We were actually crying together, and that had not ever happened,” Alvarez told The Times, recalling a recent conversation with her brother. “It was very healing for us. I never knew all that he carried, like the emotional burden of not protecting his younger sister.”</p><p>In a telephone interview from Ironwood State Prison in Blythe, Perez said the more frequent contact with his sister was making him a better brother and better person.</p><p>By having these conversations, he said, he and others in prison “are able to kind of really rehabilitate our emotional awareness, and really start to have empathy for our family members that are struggling out there on the streets, so that we can create some type of emotion in ourselves other than always be worried about what is happening on the inside.”</p><p>Prisoner advocates and state correction officials hope the benefits will go even further by speeding rehabilitation, reducing recidivism and easing the way for reentry into society. </p><p>“Incarcerated people who are connected to their families and support systems are more likely to come home and stay home,” said Bianca Tylek, executive director of Worth Rises, a prison reform organization. “That means they are less likely to reengage in criminal activity and more likely to be productive neighbors for all of us. That protects and improves our own public safety.”</p><p>Other states including Colorado and Minnesota are following California and Connecticut, which was the first state to implement a free-call program in prisons. This week, the Los Angeles County Board of Supervisors, in the footsteps of <a href="https://www.politico.com/states/california/story/2020/08/10/san-francisco-becomes-first-county-in-the-nation-to-offer-free-calls-to-jail-inmates-1306715" target="_blank"><u>San Francisco</u></a> and <a href="https://www.sdsheriff.gov/bureaus/detention-services-bureau/telephones#:~:text=Since%20July%201%2C%202021%2C%20all,be%20limited%20to%2015%20minutes." target="_blank"><u>San Diego</u></a><u>,</u> <a href="https://www.latimes.com/california/story/2023-07-25/l-a-county-says-phone-calls-will-be-free-in-all-its-jails-by-dec-1">voted</a> unanimously to give the Sheriff’s Department a Dec. 1 deadline to make phone calls free in the seven county jails. </p><p>Since the California law took effect in January, call volume in state prisons surged from 1.4 million minutes per day in December 2022 to more than 3.5 million minutes in June, according to the California Department of Corrections and Rehabilitation.</p><p>Under the new law, free calls still must originate from prison and end after 15 minutes, but there are no caps on the number of calls an incarcerated person can make. Calling can be restricted to certain hours by individual facilities.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/779ea0a/2147483647/strip/true/crop/5184x3456+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/415a7c1/2147483647/strip/true/crop/5184x3456+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/e53d9c8/2147483647/strip/true/crop/5184x3456+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/6b6761b/2147483647/strip/true/crop/5184x3456+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/9e5b037/2147483647/strip/true/crop/5184x3456+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/9faf5ab/2147483647/strip/true/crop/5184x3456+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/19a601a/2147483647/strip/true/crop/5184x3456+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 2160w" sizes="100vw">     <img alt="Men talking on the phone in side-by-side cubicles as other men stand by" srcset="https://ca-times.brightspotcdn.com/dims4/default/89f80bd/2147483647/strip/true/crop/5184x3456+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/592992a/2147483647/strip/true/crop/5184x3456+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/3d14a7c/2147483647/strip/true/crop/5184x3456+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/53ecf89/2147483647/strip/true/crop/5184x3456+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/789767a/2147483647/strip/true/crop/5184x3456+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/3a0bfcf/2147483647/strip/true/crop/5184x3456+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/d55f54b/2147483647/strip/true/crop/5184x3456+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/8964a47/2147483647/strip/true/crop/5184x3456+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Men make phone calls from their cellblock at Folsom State Prison at no charge, part of California’s effort to help incarcerated people maintain relationships with family and friends, which may reduce recidivism.</p>   <p>(Luis Sinco / Los Angeles Times)</p>   </div>  </figure></div><p>In a statement, the state corrections department said it was optimistic that the increased family contact would help incarcerated people “build and maintain relationships that are critical to achieving their rehabilitative goals.”</p><p>Before the law, the state provided each prisoner with two free 15-minute calls every two weeks, costing taxpayers about $214,000 in December. In June, the overall prison phone bill increased more than tenfold, to nearly $2.4 million.</p><p>Oscar Bonilla, a formerly incarcerated person released in 2020, recalls the toll of long periods of not having phone calls. Though he understood his family could not afford the fee, he nevertheless felt forgotten and resentful.</p><p>Having free phone calls during his incarceration would have strengthened the relationship he had with his family, he said.</p><p>It would have “helped my own mental health and my own emotional state of being while I was in there,” he added. “It would have really had me feeling a little happier instead of being in a depressed state of mind. Having that bridge to your family is huge.”</p><p>Separation wore heavily on family members, too.</p><p>Ruth Mancilla, 43, of Duarte, has two brothers in prison. She said the family’s phone bill sometimes hit $900 in the early 2000s. “That was like a full rent back then,” she said.</p><p>She recalled the anguish she felt when one of her brothers would call her cellphone, and she had to watch the screen until it stopped ringing because she could not afford to answer it.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/038509a/2147483647/strip/true/crop/8066x5380+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/4092f12/2147483647/strip/true/crop/8066x5380+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/8eea99f/2147483647/strip/true/crop/8066x5380+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/13b81fd/2147483647/strip/true/crop/8066x5380+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/0ddfeef/2147483647/strip/true/crop/8066x5380+0+0/resize/1240x827!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/4cc409d/2147483647/strip/true/crop/8066x5380+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/a082db8/2147483647/strip/true/crop/8066x5380+0+0/resize/2160x1441!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 2160w" sizes="100vw">     <img alt="A woman sitting at a picnic table as people walk by on the grass in the background" srcset="https://ca-times.brightspotcdn.com/dims4/default/8bf13e1/2147483647/strip/true/crop/8066x5380+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/e1402bf/2147483647/strip/true/crop/8066x5380+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/4fea035/2147483647/strip/true/crop/8066x5380+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/18b78c4/2147483647/strip/true/crop/8066x5380+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/f1be486/2147483647/strip/true/crop/8066x5380+0+0/resize/1240x827!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/ad427f8/2147483647/strip/true/crop/8066x5380+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/1a81e17/2147483647/strip/true/crop/8066x5380+0+0/resize/2160x1441!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 2160w" sizes="100vw" width="2000" height="1334" src="https://ca-times.brightspotcdn.com/dims4/default/6694bf8/2147483647/strip/true/crop/8066x5380+0+0/resize/2000x1334!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Ruth Mancilla speaks from a park in Duarte to her son’s incarcerated father. She’s still not used to the free calls, which she says seem like “one of those ‘too good to be true’ type of things.”</p>   <p>(Dania Maxwell / Los Angeles Times)</p>   </div>  </figure></div><div data-click="enhancement" data-align-left=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/394edf0/2147483647/strip/true/crop/4778x7164+0+0/resize/320x480!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/bb0660f/2147483647/strip/true/crop/4778x7164+0+0/resize/568x852!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/37888e3/2147483647/strip/true/crop/4778x7164+0+0/resize/768x1152!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/71e6fad/2147483647/strip/true/crop/4778x7164+0+0/resize/1080x1619!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/2f66642/2147483647/strip/true/crop/4778x7164+0+0/resize/1240x1859!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/3653c6b/2147483647/strip/true/crop/4778x7164+0+0/resize/1440x2159!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/7c6a489/2147483647/strip/true/crop/4778x7164+0+0/resize/2160x3239!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 2160w" sizes="100vw">     <img alt="A closeup of a woman with the sun on her face and trees and blue sky behind her" srcset="https://ca-times.brightspotcdn.com/dims4/default/1b345fd/2147483647/strip/true/crop/4778x7164+0+0/resize/320x480!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/9a44dd1/2147483647/strip/true/crop/4778x7164+0+0/resize/568x852!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/19e4b7f/2147483647/strip/true/crop/4778x7164+0+0/resize/768x1152!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/d295882/2147483647/strip/true/crop/4778x7164+0+0/resize/1080x1619!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/db4f2b1/2147483647/strip/true/crop/4778x7164+0+0/resize/1240x1859!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/6482c5f/2147483647/strip/true/crop/4778x7164+0+0/resize/1440x2159!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/c18ce3a/2147483647/strip/true/crop/4778x7164+0+0/resize/2160x3239!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 2160w" sizes="100vw" width="2000" height="2999" src="https://ca-times.brightspotcdn.com/dims4/default/cdea64c/2147483647/strip/true/crop/4778x7164+0+0/resize/2000x2999!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Mancilla says that with two brothers in prison, her family’s phone bill sometimes hit $900 a month in the early 2000s — “like a full rent back then.” Before the new law, the cost of calls kept many families from talking with incarcerated loved ones as much as they would’ve liked.</p>   <p>(Dania Maxwell / Los Angeles Times)</p>   </div>  </figure></div><p>Even though calls are free now, she said that it is hard to break the old habit of second-guessing whether she should pick up.</p><p>“It is kind of a little traumatic,” she said. “I still have to stop and pause at times, because it is one of those ‘too good to be true’ type of things.”</p><p>Gabriel Bonilla, 47, who was convicted of murder in 2000, said the free calls had enabled him to reunite with his three sons, and to share his efforts to rehabilitate himself in prison, including his completion of a degree in May. </p><p>“Previously we had no communication and I was only judged [by] the worst day of my life,” Bonilla, no relation to Oscar, said in a phone call from Folsom State Prison. “I feel a lot better as a father, as a grandfather and as a husband because I am able to communicate with them. I am able to tell them my accomplishments [in prison] and everything that I have done to improve myself so that I’m not looked at for what I did to get myself in here.”</p><p>Free prison phone calls are among a series of recent reforms to overhaul the state’s prison system. </p><p>In March, Gov. Gavin Newsom announced that San Quentin State Prison — California’s oldest — would be transformed into a <a href="https://www.latimes.com/california/story/2023-03-16/newsom-wants-to-transform-san-quentin-using-a-scandinavian-model">“Scandinavian model,”</a> with a focus on education and job training to ease reentry into society and reduce rates of reoffending. The reforms seek to “completely reimagine what prison means,” Newsom said.</p><p>In June, the state closed all of its juvenile prisons in favor of detaining youth at county jails. The state is closing some prisons, and the corrections department has begun offering free transportation for families to visit incarcerated relatives.</p><p>During the pandemic, California prisons rolled out tablets that give incarcerated people limited digital access, including to video calls, text messages and music streaming.</p><p>However, those services are not free, and families have to pay for them if incarcerated relatives are among those who have received the tablets. Video calls cost 20 cents per minute and text messages cost 5 cents per message, according to rates <a href="https://www.cdcr.ca.gov/family-resources/tablets/" target="_blank">published by the state corrections agency.</a> </p> <p>Even before the new law, the cost of prison calls was drastically reduced after the Federal Communications Commission cracked down on hidden service fees and imposed rate caps on the prison telecom industry. A new law signed by President Biden and taking effect in 2024 will give the commission even greater powers to regulate the industry.</p><p>In some states, prison calls were costing as much as $14 a minute. A 15-minute phone call to a number within California peaked at $6.20 in 2007, and at $17.30 for out-of-state calls, according to the department.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/9202433/2147483647/strip/true/crop/4631x3086+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/71383a0/2147483647/strip/true/crop/4631x3086+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/a368a43/2147483647/strip/true/crop/4631x3086+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/dbeeb67/2147483647/strip/true/crop/4631x3086+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/9492f9e/2147483647/strip/true/crop/4631x3086+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/e5bb5a8/2147483647/strip/true/crop/4631x3086+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/1d9266e/2147483647/strip/true/crop/4631x3086+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 2160w" sizes="100vw">     <img alt="A person walking through a barred doorway near a large black-and-white mural of a man" srcset="https://ca-times.brightspotcdn.com/dims4/default/5a2788f/2147483647/strip/true/crop/4631x3086+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/c8df621/2147483647/strip/true/crop/4631x3086+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/9ac67d6/2147483647/strip/true/crop/4631x3086+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/eafea10/2147483647/strip/true/crop/4631x3086+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/3716c90/2147483647/strip/true/crop/4631x3086+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/5606c9f/2147483647/strip/true/crop/4631x3086+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/8854c67/2147483647/strip/true/crop/4631x3086+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/27639a8/2147483647/strip/true/crop/4631x3086+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>California’s free prison phone calls are among a series of recent changes to overhaul Folsom State Prison, pictured, and the rest of the state’s corrections system.</p>   <p>(Luis Sinco / Los Angeles Times)</p>   </div>  </figure></div><p>In 2021, Global Tel Link, the private company handling California’s state prison calls, <a href="https://gtlprepaidsettlement.com/Home/portalid/0" target="_blank">agreed to a $67-million settlement</a> to refund and credit customers whose funds it had taken as profit when the customers didn’t use the funds within a 90-day period. The company is now known as ViaPath.</p><p>“As a provider of these services, ViaPath understands the importance of communication services and is focused on providing quality service and support,” ViaPath said in a statement. “The company was pleased to resolve the legacy litigation ...  and is complying with the settlement agreement.”</p><p>Advocates and relatives interviewed by The Times said although they are happy calls are now free, there is still a need to improve the quality of the service, as calls drop frequently and users are sometimes unable to hear one another.</p><p>The next legislative fight, activists say, is for video calls, text messages and calls from California’s patchwork of county jails to also become free. Those provisions were dropped from the previous bill as it made its way through California’s Legislature.</p><p>Tylek hopes California’s example encourages other states to pursue similar policy shifts in their correctional systems.</p><p>“I think the legislation in California helps demonstrate to other states across the country that this is doable, that this is feasible and that it can help change lives,” she said.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Play deprivation is a major cause of the teen mental health crisis (420 pts)]]></title>
            <link>https://jonathanhaidt.substack.com/p/the-play-deficit</link>
            <guid>36910256</guid>
            <pubDate>Fri, 28 Jul 2023 17:28:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonathanhaidt.substack.com/p/the-play-deficit">https://jonathanhaidt.substack.com/p/the-play-deficit</a>, See on <a href="https://news.ycombinator.com/item?id=36910256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>The central idea of my forthcoming book, </span><em><a href="https://www.amazon.com/Anxious-Generation-Rewiring-Childhood-Epidemic/dp/0593655036" rel="">The Anxious Generation</a></em><span>, is that we have overprotected children in the real world, where they need a lot of free play and autonomy,while underprotecting them online, where they are not developmentally ready for much of what happens to them. Much of my thinking about the importance of free play comes from </span><a href="https://www.bc.edu/bc-web/schools/mcas/departments/psychology/people/affiliated-and-emeritus/peter-gray.html" rel="">Peter Gray</a><span>, a professor of psychology at Boston College who is one of the world’s leading experts on the psychology of play. See his </span><a href="https://www.youtube.com/watch?v=Bg-GEzM7iTk&amp;ab_channel=TEDxTalks" rel="">powerful TED talk</a><span>, where he lays out the evolutionary origins of play—a necessity for all young mammals. He then shows how we have systematically deprived children of free play since the 1970s and shows that adolescents' mental health has declined substantially over the same period. He notes that this is a correlation, not proof of causation, although experiments with animals support the claim that play deprivation causes anxiety and poor social development.</span></p><p><span>Peter gave that talk in 2014. Since then, the mental health of children and adolescents has worsened, and evidence has increased showing that Peter was correct. Peter recently published a major review article in the Journal of Pediatrics titled </span><a href="https://www.petergray.org/_files/ugd/b4b4f9_f2cb98d004af4ebf9644c8daa30b040e.pdf" rel="">Decline in Independent Activity as a Cause of Decline in Children’s Mental Well-being: Summary of the Evidence</a><span>. I think it’s among the most important essays ever written on play. I was planning to write a summary of the article for the After Babel Substack, but a few days ago, I got Peter’s own summary of the article, which he posted on his new Substack, </span><em>Play Makes Us Human</em><span>, which you can find and subscribe to here:</span></p><p><span>I asked Peter if I could repost his </span><a href="https://petergray.substack.com/p/15-play-deficit-as-cause-of-decline" rel="">Substack essay</a><span> at After Babel. He said yes, and you’ll find it below. Peter and I disagree on whether </span><a href="https://jonathanhaidt.substack.com/p/social-media-mental-illness-epidemic" rel="">smartphones and social media are also major causes of the teen mental health crisis</a><span>, as you’ll see. But we both agree that play deprivation is a major contributing cause and that anyone who is serious about the mental health of children and teens (and adults) should be up in arms about what America and many other countries have done to prevent children from playing in the ways they need and want to play.</span></p><p><span>I note that Peter is a co-founder, with me, Lenore Skenazy, and Daniel Shuchman, of </span><a href="https://letgrow.org/" rel="">LetGrow.org</a><span>, where we both serve on the board. LetGrow offers many resources for </span><a href="https://letgrow.org/program/parents-and-families/" rel="">parents</a><span>, </span><a href="https://letgrow.org/program/educators/" rel="">schools</a><span>, and </span><a href="https://letgrow.org/program/policy-and-legislation/" rel="">state legislators</a><span> that want to act on Peter’s advice and introduce more free play and autonomy into children’s lives. </span></p><p><span>— </span><em><strong>Jon Haidt</strong></em></p><p><span>In this letter, I summarize the contents of an article that anthropologist David Lancy, developmental psychologist David Bjorklund, and I published recently in the Journal of Pediatrics. For the full account, including citations to research supporting each point, see the article </span><a href="https://www.petergray.org/_files/ugd/b4b4f9_f2cb98d004af4ebf9644c8daa30b040e.pdf" rel="">here</a><span>. Throughout this letter, I use the term “children” to refer to everyone under 18 years old unless otherwise specified.</span></p><p>We began the article with two very well-established and disturbing facts.</p><p>The first fact is that over the past 5 decades or more we have seen, in the United States, a continuous and overall huge decline in children’s freedom to play or engage in any activities independent of direct adult monitoring and control. With every decade children have become less free to play, roam, and explore alone or with other children away from adults, less free to occupy public spaces without an adult guard, and less free to have a part-time job where they can demonstrate their capacity for responsible self-control. Among the causes of this change are a large increase in societal fears that children are in danger if not constantly guarded, a large increase in the time that children must spend in school and at schoolwork at home, and a large increase in the societal view that children’s time is best spent in adult-directed school-like activities, such as formal sports and lessons, even when not in school.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg" width="1080" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:675,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138002,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16d218a3-b808-49ea-879f-14f67cf330bf_1080x675.jpeg 1456w" sizes="100vw" loading="lazy" fetchpriority="high"></picture></div></a></figure></div><p><span>The second undisputed fact is that over these same decades, rates of anxiety, depression, and suicide among young people have increased enormously. Using data from standard clinical questionnaires administered to school-aged children over the decades, researchers have estimated that the rates of what we now call major depressive disorder and generalized anxiety disorder increased by roughly 5- to 8-fold during the second half of the 20</span><sup>th</sup><span> century, and other measures indicate that they have continued to increase during the first two decades of the 21</span><sup>st</sup><span> century.</span></p><p>Perhaps the most compelling and disturbing evidence comes from research on suicides and suicidal thoughts. Data compiled by the Centers for Disease Control and Prevention indicate that the rate of suicide among children younger than age 15 rose 3.5-fold between 1950 and 2005 and by another 2.4-fold between 2005 and 2020. By 2019, suicide was the second leading cause of death for children from age 10 through 15, behind only unintentional injury (including traffic fatalities). Moreover, the 2019 Youth Risk Behavior Surveillance System survey revealed that during the previous year 18.8% of US high school students seriously considered attempting suicide, 15.7% made a suicide plan, 8.9% attempted suicide one or more times, and 2.5% made a suicide attempt requiring medical treatment.</p><p>Such findings led the American Academy of Pediatrics, American Academy of Child and Adolescent Psychiatry, and Children’s Hospital Association to issue, in 2021, a joint statement to the Biden administration urging that child and adolescent mental health be declared a “national emergency.”</p><p data-attrs="{&quot;url&quot;:&quot;https://jonathanhaidt.substack.com/p/the-play-deficit?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://jonathanhaidt.substack.com/p/the-play-deficit?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>You would think it would be obvious that taking away free play and other freedoms to act independently would make children anxious, depressed, and in some cases suicidal, but we adults are remarkably skilled at burying our heads in the sand on this issue. If you read the popular press, you would think the problem is screens and social media, or almost anything else other than the fact that we have more or less locked children up around the clock. So, here is some of the evidence we spelled out in the Journal of Pediatrics article.</p><p>Research, proving what should be obvious, shows that play is a direct source of children’s happiness. When children are asked to depict or describe activities that make them happy, they depict or describe scenes of play. There is also research showing that when children are allowed a little more play—such as when schools offer a little more recess—the kids become happier. Research also reveals that children consider play to be activity that they themselves initiate and control. If an adult is directing it, it’s not play. The joy of play is the joy of freedom from adult control. Other research reveals that the rates of emotional breakdowns and suicides among school-aged children decline markedly every summer when schools shut down and rise again when schools open. During the summer children have at least some more opportunity for independent activity than they do during the school year. There is also evidence that teens who have part-time jobs are happier than those who don’t, because of the sense of independence and confidence they gain from the job.</p><p><span>Beyond promoting immediate mental well-being, play and other independent activities build mental capacities and attitudes that foster future well-being. Research shows that people of all ages who have a strong </span><em>internal locus of control</em><span> (internal LOC),</span><em> </em><span>that is, a strong sense of being able to solve their own problems and take charge of their own lives, are much less likely to suffer from anxiety and depression than those with a weaker internal LOC. Obviously, however, to develop a strong internal LOC a person needs considerable experience of actually being in control, which is not possible if you are continuously being monitored and controlled by others.</span></p><p>Other research has assessed relationships between the amount of time children have to direct their own activities and psychological characteristics predictive of future mental health. Such research has revealed significant positive correlations between the amount of self-structured time (largely involving free play) young children have and (1) scores on tests of executive functioning (ability to create and follow through on a plan to solve a set of problems); (2) indices of emotional control and social ability; and (3) scores, 2 years later, on a measure of self-regulation.</p><p>Moreover, two retrospective studies with adults have shown that those who recall more instances of independent play when they were children are, by various indices, happier and more successful in adulthood than those who recall less such independence. And research with college students reveals that those with over-controlling parents (as assessed with questionnaires) fare more poorly psychologically than those whose parents are less controlling. These and other correlational studies all point in the same direction. Opportunities to take more control of your own life when young predict better future well-being.</p><p><span>Dozens of research studies, conducted with people of a wide range of ages, have led to the conclusion that mental health for all of us depends on our ability to satisfy three basic psychological needs—the needs for </span><em>autonomy</em><span>, </span><em>competence</em><span>, and </span><em>relatedness</em><span>. The logic underlying this is straightforward. To feel in charge of our life, to feel we can meet the bumps in the roads of life with equanimity, we must feel free to choose our own paths (</span><em>autonomy</em><span>); feel sufficiently skilled to pursue those paths (</span><em>competence</em><span>); and have friends and colleagues for support, including emotional support (</span><em>relatedness</em><span>).</span></p><p><span>How do children satisfy these psychological needs? They do so through play and other self-chosen, self-controlled activities. Play and other self-directed activities are, by definition, autonomous; such activities build skills (competence) in endeavors that children care about and that prepare them for adulthood (see </span><a href="https://petergray.substack.com/p/5-play-is-how-children-practice-all" rel="">Letter #5</a><span>); and such activities are the primary means by which children make friends (relatedness).</span></p><p>By depriving children of play and other independent activities we are depriving them of the experiences they need to grow up with the confidence and ability to run their own lives.</p><p data-attrs="{&quot;url&quot;:&quot;https://jonathanhaidt.substack.com/p/the-play-deficit/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://jonathanhaidt.substack.com/p/the-play-deficit/comments" rel=""><span>Leave a comment</span></a></p><p><span>So, what can you, I, and others do about this? Too many people are focusing on drugs and therapy, as if something is wrong with the kids that needs correction, and not enough of us are thinking about prevention. Prevention would involve bringing normal childhood back to children. Children are designed to play and explore and thereby becoming increasingly independent as they grow older. Their instincts tell them that something is seriously wrong if they don’t have such independence. </span><a href="https://petergray.substack.com/p/14-enabling-childrens-play" rel="">Letter #14</a><span> outlines some ways to bring more play into children’s lives in today’s overprotective world, but we also need to work for change in the larger societal constraints on children’s lives.</span></p><p><span>If you wish to see more of the research evidence behind what I have described here, including reference citations, you can do so by examining our </span><a href="https://www.petergray.org/_files/ugd/b4b4f9_f2cb98d004af4ebf9644c8daa30b040e.pdf" rel="">article </a><span>in the </span><em>Journal of Pediatrics.</em></p><p><strong>Postscript</strong></p><p>To subscribe to Peter’s substack, enter your email address here:</p><p>If you’re not already a subscriber to the After Babel substack, please enter your email address here:</p><p data-attrs="{&quot;url&quot;:&quot;https://jonathanhaidt.substack.com/p/the-play-deficit?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://jonathanhaidt.substack.com/p/the-play-deficit?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“Web Environment Integrity” is an attack on the free Internet (380 pts)]]></title>
            <link>https://www.fsf.org/blogs/community/web-environment-integrity-is-an-all-out-attack-on-the-free-internet</link>
            <guid>36910146</guid>
            <pubDate>Fri, 28 Jul 2023 17:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fsf.org/blogs/community/web-environment-integrity-is-an-all-out-attack-on-the-free-internet">https://www.fsf.org/blogs/community/web-environment-integrity-is-an-all-out-attack-on-the-free-internet</a>, See on <a href="https://news.ycombinator.com/item?id=36910146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="viewlet-below-content-title">
  

  
    <p>
  

  <span>
    —
    <span>
      Published on
    </span>
    Jul 28, 2023 10:29 AM
  </span>

  

  

  

  


</p></div><p>
                   Read why "Web Environment Integrity" is terrible, and why we must vocally oppose it now. Google's latest maneuver, if we don't act to stop it, threatens our freedom to explore the Internet with browsers of our choice.
                </p><div id="content-core">
            <p><em>Editorial note: For greater visibility, this article has been published here, on fsf.org. You can also find it on <a href="https://www.defectivebydesign.org/blog/web_environment_integrity_is_an_all_out_attack_on_free_internet">defectivebydesign.org</a>, which also has other DRM-related articles and materials.</em></p>
<p>Using a free browser is now more important than ever. We've written
<a href="https://www.fsf.org/blogs/community/googles-decision-to-deprecate-jpeg-xl-emphasizes-the-need-for-browser-choice-and-free-formats">recently</a> on this topic, but the issue we wrote about there was
minor compared to the gross injustice Google is now attempting to
force down the throats of web users around the world. The so-called
"Web Environment Integrity" (WEI) is the worst stunt we've seen from
them in some time. Beginning its life as an innocuous, if worrying,
policy document posted to Microsoft <a href="https://rupertbenwiser.github.io/Web-Environment-Integrity/">GitHub</a>, Google has now
fast-tracked its development into their <a href="https://github.com/chromium/chromium/commit/6f47a22906b2899412e79a2727355efa9cc8f5bd">Chromium browser</a>. At its
current rate of progress, WEI will be upon us in no time.</p>
<p>By giving developers an API through which they can approve certain
browser configurations while forbidding others, WEI is a tremendous
step toward the <a href="https://www.theguardian.com/commentisfree/2023/mar/11/users-advertisers-we-are-all-trapped-in-the-enshittification-of-the-internet">"enshittification"</a> of the web as a whole. Many of
us have grown up with a specific <em>idea</em> of the Internet, the notion of
it as a collection of hyperlinked pages that can be accessed by a wide
variety of different machines, programs, and operating systems. WEI is
this idea's antithesis.</p>
<p>Compared to its staggering potential effects, the technical means
through which WEI will accomplish its ends is relatively simple.
Before serving a web page, a server can ask a third-party
"verification" service to make sure that the user's browsing
environment has not been "tampered" with. A translation of the
policy's terminology will help us here: this Google-owned server will
be asked to make sure that the browser does not deviate in <em>any</em> way
from Google's accepted browser configuration, precluding any
meaningful use of the <a href="https://www.gnu.org/philosophy/free-sw.html">four freedoms</a>. It is not far-fetched to
imagine a future in which sites simply refuse to serve pages to users
running free browsers or free operating systems. If WEI isn't stopped
<em>now</em>, that future will come sooner than we think.</p>
<p>While Web Environment Integrity has a policy document that attempts to
explain valid ways in which it could be used, these are all non-issues
compared to the way that we <em>know</em> it will be used. It will be used by
governments to ensure that only their officially "approved" (read:
backdoored) browsers are able to access the Internet; it will be used
by corporations like Netflix to further Digital Restrictions
Management (DRM); it will be used by Google to deny access to their
services unless you are using a browser that gels with their profit
margin.</p>
<p>Once upon a time, Google's official policy was "don't be evil." With
the rapid progress they've made on Web Environment Integrity in such a
short time, we can say very safely that their policy is now to
<em>pioneer</em> evil. As we write this, talented and well-paid Google
engineers and executives are working to dismantle what makes the web
<em>the web.</em> Given that Google is one of the largest corporations on
the planet, our only hope of saving the Internet as we know it is a
clear and principled stance for freedom, a collective upholding of the
communal principles on which the web was based.</p>
<p>Let us repeat: there is absolutely no legitimate justification for
WEI. The use cases that the policy document highlights are nothing
compared to its real use case, which is developing a method to obtain
complete and total restriction of the free Internet.</p>
<p>We urge everyone involved in a decision-making capacity at Google to
consider the principles on which the web was founded, and to carefully
contemplate whether Web Environment Integrity aligns with those
principles. We hope that they will realize WEI's fundamental
incompatibility with the free Internet and cease work on the standard
immediately.</p>
<p>And if they don't? Well, they ought to be ashamed.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An ultra-sensitive on-off switch helps axolotls regrow limbs (152 pts)]]></title>
            <link>https://scopeblog.stanford.edu/2023/07/26/how-an-ultra-sensitive-on-off-switch-helps-axolotls-regrow-limbs/</link>
            <guid>36909673</guid>
            <pubDate>Fri, 28 Jul 2023 16:49:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scopeblog.stanford.edu/2023/07/26/how-an-ultra-sensitive-on-off-switch-helps-axolotls-regrow-limbs/">https://scopeblog.stanford.edu/2023/07/26/how-an-ultra-sensitive-on-off-switch-helps-axolotls-regrow-limbs/</a>, See on <a href="https://news.ycombinator.com/item?id=36909673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">

				
<p>It's one of the mysteries of nature: How does the axolotl, a small salamander, boast a superhero-like ability to regrow nearly any part of its body? For years, scientists have studied the amazing regenerative properties of the axolotl to inform wound healing in humans.&nbsp;&nbsp;</p>



<p>Now, Stanford Medicine researchers have made a leap forward in understanding what sets the axolotl apart from other animals. Axolotls, they discovered, have an ultra-sensitive version of mTOR, a molecule that acts as an on-off switch for protein production. And, like survivalists who fill their basements with non-perishable food for hard times, axolotl cells stockpile messenger RNA molecules, which contain genetic instructions for producing proteins. The combination of an easily activated mTOR molecule and a repository of ready-to-use mRNAs means that after an injury, axolotl cells can quickly produce the proteins needed for tissue regeneration.&nbsp;&nbsp;</p>



<p>The new findings were <a href="https://www.nature.com/articles/s41586-023-06365-1">published</a> July 26 in <em>Nature</em>.&nbsp;</p>



<p>"Until now, it has been difficult to pinpoint a specific change in a single molecule in axolotls that was so critical for regenerative potential," said Maria Barna, an associate professor of genetics and the senior author of the paper. "We've made significant headway toward understanding how we may eventually manipulate the mTOR pathway to boost regenerative potential in humans."&nbsp;</p>



<h4 id="h-from-mrna-to-protein"><strong>From mRNA to protein</strong>&nbsp;</h4>



<p>In the past, researchers trying to figure out how the axolotl regrows entire body parts -- including legs, tails, eyes and even the heart -- focused on how levels of mRNA molecules changed after an axolotl has an injury. Scientists have long used mRNA molecule levels as a proxy for protein levels; after all, mRNA must exist before a protein can be produced. However, these studies only shed light on what happens to the production of mRNA molecules after injury -- not what happens to the translation of mRNA into protein products.&nbsp;&nbsp;</p>



<p>"There are hundreds of mRNA transcripts that appear after a wound, but researchers were really struggling to figure out what it was about salamanders that could explain their regenerative potential," Barna said.&nbsp;&nbsp;&nbsp;</p>



<p>Her lab took a different approach, focusing on which mRNA molecules near a wound were attached to ribosomes, little molecular machines that create proteins. That helped the scientists zero in on which proteins were being made, rather than which mRNA molecules loitered near the injury site. Usually, when cells encounter stress (such as after an injury) they decrease overall protein production to save energy, so Barna's group expected to see fewer mRNA molecules bound to ribosomes. Instead, they saw more.&nbsp;</p>



<p>"It was a 180-degree flip when we realized that when an axolotl loses a limb, it actually increases protein synthesis despite the energy cost," Barna said.&nbsp;&nbsp;</p>



<p>Further experiments showed that axolotl cells 'stockpile' mRNA, translating less than 20% of it at any given time. When the researchers analyzed how axolotls respond to injury, they found that protein synthesis is activated, leading to the translation of hundreds of stockpiled transcripts. That long-term storage also explained the speed at which protein synthesis occurred during regeneration.&nbsp;&nbsp;</p>



<p>"We had a gut feeling that looking at protein synthesis more closely would be important, " said Olena Zhulyn, PhD, postdoctoral scholar and lead author of the study. "But never in a million years did we expect that protein synthesis would be the key to the mystery of the axolotl's regeneration."&nbsp;</p>



<h4><strong>A connection to mTOR</strong>&nbsp;</h4>



<p>A question remained: What was activating the mRNAs and causing them to bind to ribosomes after axolotls lose a body part? The researchers noticed that many of the stockpiled mRNA molecules had a shared sequence of nucleotides at one end of the mRNA which was known to be regulated by the enzyme mTOR to promote protein production.&nbsp;&nbsp;</p>



<p>The research found that the axolotl mTOR protein is highly sensitive -- the axolotl variety contained a genetic alteration, an expansion in sequence, seen only in axolotl and related salamanders.&nbsp;&nbsp;</p>



<p>Investigating further, Barna and her team collaborated with researchers at University of California, San Francisco to probe the structural differences between axolotl mTOR and mammalian mTOR.&nbsp;&nbsp;</p>



<p>In humans and mice, mTOR (and resulting protein production) activates only when there's a surplus of nutrients. In other words, mammalian cells use mTOR to make proteins only in the best of times. But in axolotls, after an injury causes cell damage and the breakdown of many molecules, the small rush in loose nutrients is enough to flip the ultra-sensitive mTOR to its active state, turning on the cellular factories that make new proteins.&nbsp;&nbsp;</p>



<p>"Finding this genetic change was a shock -- mTOR is an ancient enzyme that is the same in virtually all organisms," said Zhulyn. "But in axolotls we were seeing evolution of new sequences and a structure that changed its fundamental properties."&nbsp;</p>



<p>When Barna and her colleagues blocked mTOR with a drug used to prevent protein production and cell division in cancers, the animals were no longer able to regrow limbs. The axolotl mTOR is hypersensitive to stimulation (in this case, injury) but is not more active than mammalian mTOR, they found. That's key, said Barna -- hyperactive mTOR has been linked to tumor growth in many human cancers. Given that the axolotl mTOR doesn't show hyperactivity, that could explain the remarkable cancer resistance seen in axolotls, she said.&nbsp;</p>



<p>More research is needed to probe whether changing or stimulating mTOR in humans could improve wound healing or spur the regeneration of damaged, diseased organs, Barna said.&nbsp;&nbsp;</p>



<p>"I think there are a still a lot of lessons to be learned about how this tight control of mRNA translation is allowing wound healing and tissue regeneration," said Barna. "There is a whole new world to be discovered when it comes to both the basic biology of translation and healing."</p>



<p>Photo by <a href="https://stock.adobe.com/images/creative-3d-representation-of-multicolored-cells/609749105?asset_id=609749105">Samantha</a></p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is DNS still hard to learn? (434 pts)]]></title>
            <link>https://jvns.ca/blog/2023/07/28/why-is-dns-still-hard-to-learn/</link>
            <guid>36909427</guid>
            <pubDate>Fri, 28 Jul 2023 16:33:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/07/28/why-is-dns-still-hard-to-learn/">https://jvns.ca/blog/2023/07/28/why-is-dns-still-hard-to-learn/</a>, See on <a href="https://news.ycombinator.com/item?id=36909427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>I write a lot about technologies that I found hard to learn about. A
while back my friend Sumana asked me an interesting question – why are these
things so hard to learn about? Why do they seem so mysterious?</p>

<p>For example, take DNS. We’ve been using DNS since the <a href="https://www.ietf.org/rfc/rfc1034.txt">80s</a> (for more than 35 years!). It’s
used in every website on the internet. And it’s pretty stable – in a lot of
ways, it works the exact same way it did 30 years ago.</p>

<p>But it took me YEARS to figure out how to confidently debug DNS issues, and
I’ve seen a lot of other programmers struggle with debugging DNS problems as
well. So what’s going on?</p>

<p>Here are a couple of thoughts about why learning to troubleshoot DNS problems
is hard.</p>

<p>(I’m not going to explain DNS very much in this post, see <a href="https://implement-dns.wizardzines.com/">Implement DNS in a Weekend</a> or <a href="https://jvns.ca/categories/dns/">my DNS blog posts</a> for more about how DNS works)</p>

<h3 id="a-lot-of-the-system-is-hidden">a lot of the system is hidden</h3>

<p>When you make a DNS request on your computer, the basic story is:</p>

<ol>
<li>your computer makes a request to a server called <strong>resolver</strong></li>
<li>the resolver checks its cache, and makes requests to some other servers called <strong>authoritative nameservers</strong></li>
</ol>

<p>Here are some things you don’t see:</p>

<ul>
<li>the resolver’s <strong>cache</strong>. What’s in there?</li>
<li>which <strong>library code</strong> on your computer is making the DNS request (is it libc
<code>getaddrinfo</code>? if so, is it the getaddrinfo from glibc, or musl, or apple? is
it your browser’s DNS code? is it a different custom DNS implementation?).
All of these options behave slightly differently and have different
configuration, approaches to caching, available features, etc. For example musl DNS didn’t support TCP until <a href="https://www.theregister.com/2023/05/16/alpine_linux_318/">early 2023</a>.</li>
<li>the <strong>conversation</strong> between the resolver and the authoritative nameservers. I
think a lot of DNS issues would be SO simple to understand if you could
magically get a trace of exactly which authoritative nameservers were
queried downstream during your request, and what they said. (like, what if
you could run <code>dig +debug google.com</code> and it gave you a bunch of extra
debugging information?)</li>
</ul>

<h3 id="dealing-with-hidden-systems">dealing with hidden systems</h3>

<p>A couple of ideas for how to deal with hidden systems</p>

<ul>
<li>just teaching people what the hidden systems are makes a huge difference. For
a long time I had no idea that my computer had many different DNS libraries
that were used in different situations and I was confused about this for
literally years. This is a big part of my approach.</li>
<li>with <a href="https://messwithdns.net/">Mess With DNS</a> we tried out this “fishbowl”
approach where it shows you some parts of the system (the conversation with
the resolver and the authoritative nameserver) that are normally hidden</li>
<li>I feel like it would be extremely cool to extend DNS to include a “debugging
information” section. Like maybe it could be in the <code>additional</code> section and
we could use TCP DNS so so that the response could include unlimited debug
info? There’s probably prior art here that I don’t know about.</li>
</ul>

<h3 id="confusing-tools">confusing tools</h3>

<p>Even though a lot of DNS stuff is hidden, there are a lot of ways to figure out
what’s going on by using <code>dig</code>.</p>

<p>For example, you can use <code>dig +norecurse</code> to figure out if a given DNS resolver
has a particular record in its cache. <code>8.8.8.8</code> seems to return a <code>SERVFAIL</code>
response if the response isn’t cached.</p>

<p>here’s what that looks like for <code>google.com</code></p>

<pre><code>$ dig +norecurse  @8.8.8.8 google.com
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 11653
;; flags: qr ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;google.com.			IN	A

;; ANSWER SECTION:
google.com.		21	IN	A	172.217.4.206

;; Query time: 57 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Fri Jul 28 10:50:45 EDT 2023
;; MSG SIZE  rcvd: 55
</code></pre>

<p>and for <code>homestarrunner.com</code>:</p>

<pre><code>$ dig +norecurse  @8.8.8.8 homestarrunner.com
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: SERVFAIL, id: 55777
;; flags: qr ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;homestarrunner.com.		IN	A

;; Query time: 52 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Fri Jul 28 10:51:01 EDT 2023
;; MSG SIZE  rcvd: 47
</code></pre>

<p>Here you can see we got a normal <code>NOERROR</code> response for <code>google.com</code> (which is
in <code>8.8.8.8</code>’s cache) but a <code>SERVFAIL</code> for <code>homestarrunner.com</code> (which isn’t).
This doesn’t mean there’s no DNS record <code>homestarrunner.com</code> (there is!), it’s
just not cached).</p>

<p>But this output is really confusing to read if you’re not used to it! Here are a few things that I think are weird about it:</p>

<ol>
<li>the headings are weird (there’s <code>-&gt;&gt;HEADER&lt;&lt;-</code>, <code>flags:</code>, <code>OPT PSEUDOSECTION:</code>, <code>QUESTION SECTION:</code>, <code>ANSWER SECTION:</code>)</li>
<li>the spacing is weird (why is the no newline between <code>OPT PSEUDOSECTION</code> and <code>QUESTION SECTION</code>?)</li>
<li><code>MSG SIZE  rcvd: 47</code> is weird (are there other fields in <code>MSG SIZE</code> other than <code>rcvd</code>? what are they?)</li>
<li>it says that there’s 1 record in the ADDITIONAL section but doesn’t show it, you have to somehow magically know that the “OPT PSEUDOSECTION” record is actually in the additional section</li>
</ol>

<p>In general <code>dig</code>’s output has the feeling of a script someone wrote in an adhoc
way that grew organically over time and not something that was intentionally
designed.</p>

<h3 id="dealing-with-confusing-tools">dealing with confusing tools</h3>

<p>some ideas for improving on confusing tools:</p>

<ul>
<li><strong>explain the output</strong>. For example I wrote <a href="https://jvns.ca/blog/2021/12/04/how-to-use-dig/">how to use dig</a> explaining how <code>dig</code>’s
output works and how to configure it to give you a shorter output by default</li>
<li><strong>make new, more friendly tools</strong>. For example for DNS there’s
<a href="https://github.com/ogham/dog">dog</a> and <a href="https://github.com/mr-karan/doggo">doggo</a> and <a href="https://dns-lookup.jvns.ca/">my dns lookup tool</a>. I think these are really cool but
personally I don’t use them because sometimes I want to do something a little
more advanced (like using <code>+norecurse</code>) and as far as I can tell neither
<code>dog</code> nor <code>doggo</code> support <code>+norecurse</code>. I’d rather use 1 tool for everything,
so I stick to <code>dig</code>. Replacing the breadth of functionality of <code>dig</code> is a
huge undertaking.</li>
<li><strong>make dig’s output a little more friendly</strong>. If I were better at C programming,
I might try to write a <code>dig</code> pull request that adds a <code>+human</code> flag to dig
that formats the long form output in a more structured and readable way,
maybe something like this:</li>
</ul>

<pre><code>$ dig +human +norecurse  @8.8.8.8 google.com 
HEADER:
  opcode: QUERY
  status: NOERROR
  id: 11653
  flags: qr ra
  records: QUESTION: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
  google.com.			IN	A

ANSWER SECTION:
  google.com.		21	IN	A	172.217.4.206
  
ADDITIONAL SECTION:
  EDNS: version: 0, flags:; udp: 512
</code></pre>

<p>This makes the structure of the DNS response more clear – there’s the header, the
question, the answer, and the additional section.</p>

<p>We’ve learned a lot about how to design more user friendly command line tools
in the last 40 years and I think it would be cool to apply some of that
knowledge to some of our older crustier tools.</p>

<h3 id="weird-gotchas">weird gotchas</h3>

<p>DNS has some weird stuff that’s relatively common to run into, but pretty hard
to learn about if nobody tells you what’s going on. A few examples (there are more in <a href="https://jvns.ca/blog/2022/01/15/some-ways-dns-can-break/">some ways DNS can break</a>:</p>

<ul>
<li>negative caching! (which I talk about in <a href="https://jvns.ca/blog/2023/05/08/new-talk-learning-dns-in-10-years/">this talk</a>) It
took me probably 5 years to realize that I shouldn’t visit a domain that
doesn’t have a DNS record yet, because then the <strong>nonexistance</strong> of that
record will be cached, and it gets cached for HOURS, and it’s really
annoying.</li>
<li>differences in <code>getaddrinfo</code> implementations: until <a href="https://www.theregister.com/2023/05/16/alpine_linux_318/">early 2023</a>, <code>musl</code> didn’t support TCP DNS</li>
<li>resolvers that ignore TTLs: if you set a TTL on your DNS records (like “5
minutes”), some resolvers will ignore those TTLs completely and cache the
records for longer, like maybe 24 hours instead</li>
<li>if you configure nginx wrong (<a href="https://jvns.ca/blog/2022/01/15/some-ways-dns-can-break/#problem-nginx-caching-dns-records-forever">like this</a>), it’ll cache DNS records forever.</li>
<li>how <a href="https://pracucci.com/kubernetes-dns-resolution-ndots-options-and-why-it-may-affect-application-performances.html">ndots</a> can make your Kubernetes DNS slow</li>
</ul>

<h3 id="dealing-with-weird-gotchas">dealing with weird gotchas</h3>

<p>I don’t have as good answers here as I would like to, but knowledge about weird
gotchas is extremely hard won (again, it took me years to figure out negative
caching!) and it feels very silly to me that people have to rediscover them for
themselves over and over and over again.</p>

<p>A few ideas:</p>

<ul>
<li>It’s incredibly helpful when people call out gotchas when explaining a topic. For example (leaving
DNS for a moment), Josh Comeau’s Flexbox intro explains this <a href="https://www.joshwcomeau.com/css/interactive-guide-to-flexbox/#the-minimum-size-gotcha-11">minimum size gotcha</a>
which I ran into SO MANY times for several years before finally finding an
explanation of what was going on.</li>
<li>I’d love to see more community collections of common gotchas. For bash,
<a href="https://www.shellcheck.net/">shellcheck</a> is an incredible collection of bash
gotchas.</li>
</ul>

<p>One tricky thing about documenting DNS gotchas is that different people are
going to run into different gotchas – if you’re just configuring DNS for your
personal domain once every 3 years, you’re probably going to run into different
gotchas than someone who administrates DNS for a domain with heavy traffic.</p>

<p>A couple of more quick reasons:</p>

<h3 id="infrequent-exposure">infrequent exposure</h3>

<p>A lot of people only deal with DNS extremely infrequently. And of course if you
only touch DNS every 3 years it’s going to be harder to learn!</p>

<p>I think cheat sheets (like “here are the steps to changing your nameservers”)
can really help with this.</p>

<h3 id="it-s-hard-to-experiment-with">it’s hard to experiment with</h3>

<p>DNS can be scary to experiment with – you don’t want to mess up your domain.
We built <a href="https://messwithdns.net/">Mess With DNS</a> to make this one a little easier.</p>

<h3 id="that-s-all-for-now">that’s all for now</h3>

<p>I’d love to hear other thoughts about what makes DNS (or your favourite
mysterious technology) hard to learn.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: I'm Peter Roberts, immigration attorney who does work for YC and startups. AMA (314 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36908574</link>
            <guid>36908574</guid>
            <pubDate>Fri, 28 Jul 2023 15:43:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36908574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36909763"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909763" href="https://news.ycombinator.com/vote?id=36909763&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>In June 2021 I tried entering the United States with a TN packet as an Engineer with a Bachelor of Computer Science. However, the officer denied me the TN status saying I need an Engineering, not Computer Science degree, to qualify for the Engineer TN status.<p>Given the denial, in July 2021 the hiring company then applied through USCIS premium processing again for TN Engineer with my Computer Science degree and I was approved. I was let in at the border with my TN status without issue.</p><p>In August 2021, I we back to Canada, and then upon re-entering the US with my TN I was sent to secondary given my previous denial on record. The officers basically rechecked my packet and asked so many questions about my previous denial, the officer then lets me in but states “you might not be so lucky with the next officer”. From what I understand they can take away my TN or even just deny me entry in the future based off the previous denial.</p><p>I haven’t left the US since then, but want to visit Canada and come back. However, I’m terrified of the officer denying me entry based of my previous denial. What are my options here? My company’s lawyer basically said we just have to try and hope for the best.</p><p>Thanks so much!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909903"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909903" href="https://news.ycombinator.com/vote?id=36909903&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I know. This is really stunning but true.  CBP officers have the right to review the admissibility of TN applicants any time even if they have a TN approval notice. But there's a solution of sorts. Please email me separately because this will be very case-specific advice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36910621"><td></td></tr>
            <tr id="36909560"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909560" href="https://news.ycombinator.com/vote?id=36909560&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>How would somebody that qualifies as a TN NAFTA Professional (e.g. Canadian applying for engineering job with relevant engineering degree) answer the question of "Are you authorized to work in the US?", particularly with regards to sponsorship? As I understand it, the question is to determine if the employer needs to apply for a visa, (H-1B, etc) but according to USCIS all the employer has to do for TN is provide a letter outlining the job, employee qualifications, etc. Is this considered sponsorship?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909605"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909605" href="https://news.ycombinator.com/vote?id=36909605&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The TN is company-specific so if you are applying for a new job, even if you have a TN with one company, you would need a new TN and even though the TN process is generally simple and easy, it qualifies as sponsorship.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909197"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909197" href="https://news.ycombinator.com/vote?id=36909197&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>UK couple, both have engineering PhDs and 10+ years experience in engineering (dev and automotive), not rich but not poor. Is there a sensible path to US immigration that doesn’t leave them in the H1B bind or always on the verge of being deported?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909353"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909353" href="https://news.ycombinator.com/vote?id=36909353&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>In case Peter doesn't answer, my personal experience has been that you'll want a more stable work visa than an H1. Given your skills, one of you should be able to get one (and the other can come as a spouse and apply for a work permit with the right visa type). After a few years with that, you can apply for a green card (permanent resident status). I know people who have renewed those for decades without becoming citizens. Or, after a few years with the green card, you can apply for citizenship.<p>I know lots of Brits and Canadians in California who have also followed this path.</p><p>A lot of talk in here about H1B visas, and that's probably because they're the most plentiful. But, that's not the only type of visa that people should be thinking about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909696"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36909696" href="https://news.ycombinator.com/vote?id=36909696&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Thanks for the response. Yes, there are other options that aren't subject to the crazy and uncertain H-1B lottery such as the O-1 visa (which, without knowing more, you both probably would qualify for).  And while the O-1 is tied to a company, this can be your company. A lot of founders in the U.S. are on O-1s. There is also the intra-company transferee visa (if you are transferring to a related company in the U.S.) and the E-2 visa if you are looking to start a company in the U.S. based on a substantial investment.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910328"><td></td></tr>
                <tr id="36910597"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36910597" href="https://news.ycombinator.com/vote?id=36910597&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Most countries have a treaty of commerce and trade with the U.S. that gives rise to the E-2 visa.  In short, you must establish a U.S. company, you and/or others from your country of citizenship must invest at least $100k in this company, the company must spend a substantial portion of this on business related expenses,  and you must have a good business plan showing, among other things, the employment of U.S. workers over a 5-year period.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="36910564"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910564" href="https://news.ycombinator.com/vote?id=36910564&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>If you (US Citizen) marry out of the country, and stay with your spouse (foreign citizen) in that country, how long is the current wait to come back into the country and have your spouse with you on a CR1 visa? And are there any advantages to K-3 over CR1?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36910269"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910269" href="https://news.ycombinator.com/vote?id=36910269&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Do you have any general recommendations to founders or hiring managers to keep in mind when hiring people on visas?<p>I understand there are certain visas that an individual can obtain independently (like a TPS visa, or being the spouse of a L1 visa holder) without employer sponsorship, and other visa types that require employer sponsorship and other paperwork (I believe even visas like a TN require some coordination with candidates).</p><p>Generally speaking, are there any considerations you recommend small startup employers take when interviewing and hiring visa holders? Which visa types require the company to hire an immigration lawyer vs other visa types that don't? Links to external resources would also be helpful if there's a go-to source for this type of information.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910418"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910418" href="https://news.ycombinator.com/vote?id=36910418&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>No sponsorship is required for the spouses of those in E-1, E-2, E-3, and L-1 status, or spouses of those in H-1B status who are in the green card process and it's generally easy for companies to hire workers from the five countries with their own visas (Australia, Canada, Chile, Mexico, and Singapore). It's also generally easy for companies to hire those already in H-1B status - that is, to "transfer" the H-1B to their company. It's also generally easy for companies to hire those with PhDs (often via the O-1). It's also generally easy for companies to hire those in F-1 OPT and STEM OPT status but these workers will require sponsorship to continue working and this sponsorship usually takes the form of the H-1B visa, which requires going through the H-1B lottery, a very messy and uncertain program.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908822"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908822" href="https://news.ycombinator.com/vote?id=36908822&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>What are you seeing in terms of impact of the Canadian Open Work Permit for U.S. H-1B Visa Holders? Has there been a large volume of talent moving to Canada from  U.S. tech centers?<p>Edit: It looks like the 10,000 person cap was already hit [1]. Do you think there is a huge demand beyond the 10k cap?</p><p>[1] <a href="https://www.canadavisa.com/h1bowp.html" rel="nofollow noreferrer">https://www.canadavisa.com/h1bowp.html</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909562"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909562" href="https://news.ycombinator.com/vote?id=36909562&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The might did it out of desperation, but soon they will realize it was mostly a mistake due to low wages, high prices of goods and taxes, very limited opportunities and funding for small businesses, limited market, and obviously the harsh weather is the cherry on top.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36908901"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908901" href="https://news.ycombinator.com/vote?id=36908901&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Might need to ask a Canadian immigration attorney. I’ve reached out to a few in the family and will report back if they have anything to say.<p>Edit: sorry. Got the “not that kind of lawyer” response. They do refugees.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909728"><td></td></tr>
                        <tr id="36910051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910051" href="https://news.ycombinator.com/vote?id=36910051&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>I am an Algerian citizen who is currently doing PhD studies in computer science in the UK. My area is systems and computer architecture.<p>The job market in the UK in my area is very slim I can't find the type of jobs I would like to do. That's the reason for me why I want to move to the US.</p><p>What are the possible routes that I can possibly take to immigrate to the US?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910315"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910315" href="https://news.ycombinator.com/vote?id=36910315&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Unless you have U.S. citizen relatives, the path to the U.S. usually requires sponsorship by a U.S. company. The good news is that many with PhDs qualify for the O-1 visa, which avoids the whole H-1B lottery mess. You also could do a post-doc in the U.S. (typically on a J-1 visa) and then convert this to a longer term work visa or even green card.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909418"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909418" href="https://news.ycombinator.com/vote?id=36909418&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Hi Peter, just wanted to say thank you for navigating my complicated I-485 case and helping me get my green card!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909741"><td></td></tr>
                  <tr id="36909462"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909462" href="https://news.ycombinator.com/vote?id=36909462&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I'm currently on a H1B visa with a company. Due to family reasons I intend on going back to my home country and spend some time with family, which means I'll have to quit work. Is it possible to come back to the US, assuming I'm able to secure a job with a company? And will this have to be done before the expiration date of the H1B document?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909923"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909923" href="https://news.ycombinator.com/vote?id=36909923&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Without knowing all the facts, no; another U.S. company could sponsor you for an H-1B after your current H-1B expires without having to put your name through the H-1B lottery again.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908817"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908817" href="https://news.ycombinator.com/vote?id=36908817&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Are there cases where someone without any university degree has been able to obtain H1B visa? E.g. by having years of experience but no degree.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908982"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908982" href="https://news.ycombinator.com/vote?id=36908982&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>This was my path, so it's possible.  I dropped out after year two of my degree to join a startup and worked for 10 years in industry.<p>I converted 8 years of that experience to 2 years of a bachelor's degree to make the full 4 required, and had a University professor provide a letter of endorsement.</p><p>I was applying from Europe, and even then it was apparently a fairly expensive process for my sponsor.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909246"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36909246" href="https://news.ycombinator.com/vote?id=36909246&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Absolutely correct. The requirement is a four-year U.S. bachelor's degree or it's equivalent which can be a foreign degree or a combination of education and experience (or even just experience) evaluated to be the equivalent of a U.S. bachelor's degree. The rule of thumb is that 3 years of professional experience is the equivalent of 1 year of college education.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910192"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36910192" href="https://news.ycombinator.com/vote?id=36910192&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>&gt; The rule of thumb is that 3 years of professional experience is the equivalent of 1 year of college education.<p>I know you don't make the rules, but on the surface it would seem that these numbers are switched around ;-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36909441"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36909441" href="https://news.ycombinator.com/vote?id=36909441&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Thanks for the clear answer! is proving the years of experience usually difficult? e.g. references from 12 years ago can be hard to get (although I have those 11 years ago myself).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909782"><td></td></tr>
                                    <tr id="36908888"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908888" href="https://news.ycombinator.com/vote?id=36908888&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What is the best source of government data on the H1B program (e.g total visas per year, count by industry / job function, nationality of recipient counts)? Also, do you know of any original sources / documents which discuss the future of the program and how it will be assessed whether there is enough talent domestically in a given field of work. Thanks</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36908879"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908879" href="https://news.ycombinator.com/vote?id=36908879&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>How do the immigration efforts change between US political regime changes? Is it easier or more challenging, or does it stay the same?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909773"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909773" href="https://news.ycombinator.com/vote?id=36909773&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Significant changes.  While immigration laws rarely change, the way they are interpreted and applied can change significantly from administration to administration. We saw that when Trump became President and again when Biden became President.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910289"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910289" href="https://news.ycombinator.com/vote?id=36910289&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What changes specifically? I'm lucky in that I am American, and honestly have never had to deal with immigration, so know nothing about it. Do immigration procedures become harder/easier to navigate? Are quotas (if there are quotas) reduced?</span></p></div></td></tr>
        </tbody></table></td></tr>
                                  <tr id="36910320"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910320" href="https://news.ycombinator.com/vote?id=36910320&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>If you could reform the immigration system in one way, how would you do it? Would you say that US immigration is currently broken for tech workers?<p>Also, how does US immigration compare to other countries, such as the UK, Canada, or Germany? Is it easier to immigrate or harder?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36909526"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909526" href="https://news.ycombinator.com/vote?id=36909526&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Hi I am not really asking for specific advice (since I know our situation is already not working out to nice…), I just want to highlight how absurd the state of affair is and maybe get some input on that.<p>My wife is a US citizen and we currently both live in Germany and planed to move at the and of this year. We’ve filed a I130 in November last year and got an initial estimate of it being done right now (7 Months not to bad). But looking further into it it takes at least 15 Months to process this stage of immigration, worst case scenario it could’ve been 50 months (4 year!!!)</p><p>This wouldn’t all be to bad but to add insult to injury it looks like I’m effectively barred from entering the US during this period and US customs can even bar me for 5 years from entering the country if I try.</p><p>I just feel incredibly sad about the fact that the way to go if you have a sweetheart in the US seems to be to illegally marry on a Tourist entry into the country…</p><p>The earliest the US would even respond to our inquiries is in 2024, which is frankly ridiculous.</p><p>There doesn’t seem to be any workarounds other than transferring on an L1 Visa between companies that are situated in Germany and the US, every other visa is single intend (i.e illegal if you plan to stay and the US gets to decided if you’re trying to do that)</p><p>I don’t understand what the US is scared of, taking their social benefits? Especially since 90% of the I130 are approved, there is no reason it takes that long or needs such rigorous vetting.</p><p>Peter if you know any better or disagree please let me know :(
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909577"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909577" href="https://news.ycombinator.com/vote?id=36909577&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Unfortunately I've seen these terrible delays with our own clients and there's little that can be done other than what you suggest: get to the U.S. on some type of work visa and then pursue the green card when here, which is a very fast process. But one correction: you are allowed to travel to the U.S. as a visitor while your green card application is pending; you just need to maintain a home abroad and not work when here. We've had spouses in the same situation spend  months and months in the U.S. while waiting for the green card process to run its course.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909717"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36909717" href="https://news.ycombinator.com/vote?id=36909717&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Thanks for the quick response, I agree if it would be that easy, sadly I’ve had friends that were turned away by customs for that exact reasons (staying months while they visited last time) and got recommended against even trying to enter by an attorney since the I130 in flight might be used by US customs against me.<p>I don’t think you or anyone can assure me that if I am currently trying to enter the country for a visit I might not be turned away by customs (worst case scenario being barred from entering for years).</p><p>I don’t know how you can plan your existence around random chance of US customs.</p><p>Please correct me if I’m wrong with that assessment.</p><p>To come highlight again, this has been a huge surprise to my wife’s family who resides on both sides of the political aisle.</p><p>They assumed it would be bad, but not quite how bad.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909943"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36909943" href="https://news.ycombinator.com/vote?id=36909943&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>With the right advice, you should be fine to travel.  Never has a client of ours in your situation had an issue entering the U.S.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36910185"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910185" href="https://news.ycombinator.com/vote?id=36910185&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I am in similar situation, except wife is in India with younger kid and I am in US with elder kid in university. I am told there is a good chance she will be denied tourist visa even if not yet applied to GC, as rest of us are US citizens. And she will be denied tourist visa after applying for GC.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910451"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36910451" href="https://news.ycombinator.com/vote?id=36910451&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>That's a separate issue.  If one already has a tourist visa or is from a visa waiver country, there really are no issues traveling to the U.S. while the green card process is pending if you are smart and careful. But it's very difficult to obtain a tourist visa if you are in the green card process.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="36908988"><td></td></tr>
                <tr id="36909099"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909099" href="https://news.ycombinator.com/vote?id=36909099&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>I replied elsewhere - but this was my (successful - now an LPR) path.<p>My lawyer told me you need a 4 year degree equivalent, and 4 years of experience can convert to a year.</p><p>If you have zero university education, that would be 16 years' experience required, based on that lawyer's legal instruction.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909309"><td></td></tr>
                <tr id="36909512"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36909512" href="https://news.ycombinator.com/vote?id=36909512&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>This is ridiculous in both directions. In one direction, someone can have 12 months of tech industry experience with more knowledge than a Masters degree holder. In the other direction, it's also possible to have 30 years of real experience in the tech industry without being particularly skilled labor (the apocryphal "three months of experience, repeated a hundred times").</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36909474"><td></td></tr>
                        <tr id="36909473"><td></td></tr>
                  <tr id="36909939"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909939" href="https://news.ycombinator.com/vote?id=36909939&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Thanks for the AMA, Peter! What are the options for a TN visa (Canadian) holder if they become permanently disabled (cancer treatment) and are unable to work at all? Are they able to renew their TN visa assuming the employer is okay with that?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36908668"><td></td></tr>
                <tr id="36908775"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908775" href="https://news.ycombinator.com/vote?id=36908775&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The issues oftentimes are what can the founder do before he or she moves to the startup and what company-related items need to be in place before the founder can be sponsored by the startup. This requires a conversation unfortunately since the advice is case-specific.  My advice then is to find a good corporate attorney and to speak with an immigration attorney who works with founders and startups before setting up the company.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908723"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908723" href="https://news.ycombinator.com/vote?id=36908723&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What's the typical fully loaded cost for a company to bring someone in on an H1B or similar visa, in terms of attorney time and application fees and whatnot?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908832"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908832" href="https://news.ycombinator.com/vote?id=36908832&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>There is some range depending on the size of the U.S. workforce and whether the petition is filed with premium processing. A rough range for a company with less than 25 FTEs would be $4,000 to $5,500.  For a company with at least 25 FTEs, add $750 and if the petition is filed with premium processing, add $2,500.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908878"><td></td></tr>
            <tr id="36908890"><td></td></tr>
                <tr id="36909122"><td></td></tr>
            <tr id="36909152"><td></td></tr>
                <tr id="36909262"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36909262" href="https://news.ycombinator.com/vote?id=36909262&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>All correct!  But with an H-1B to H-1B transfer, the filing alone allows the sponsored employee to work so sometimes there's no need for premium processing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909312"><td></td></tr>
                              <tr id="36909780"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909780" href="https://news.ycombinator.com/vote?id=36909780&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>What is the process like for employees waiting for i485 approval (2+ year wait times) who decide to change companies? Assuming EAD/AP and everything else has already been approved.<p>My understanding is that the application is “portable” to an extent, but what exactly does that mean? Does the PWD need to be filed again?</p><p>From a startup’s perspective, what does the company need to do to accommodate this incoming employee?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909830"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909830" href="https://news.ycombinator.com/vote?id=36909830&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Generally it's very easy to port an I-485 application after the I-140 has been approved and I-485 has been pending for more than 6 months. The primary requirement is that the new job in the same or similar occupation as the previous job and that the new company is a real company with the ability to pay employee. But the job location, job salary, job level can all be different.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910596"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910596" href="https://news.ycombinator.com/vote?id=36910596&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Thank you for the response!!<p>How specific is “same or similar”? Say, going from front end web dev to machine learning. Or going from VLSI to full stack web dev. All very similar in that they’re software development heavy, but do have significant differences in the actual field.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36909328"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909328" href="https://news.ycombinator.com/vote?id=36909328&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Any advice for an US citizen expat who wants to found while living abroad? (Tokyo, Japan)<p>e.g. About whether to incorporate locally or in the U.S., and that sort of thing -- anything unique to an expat situation.</p><p>(This may be out of your wheelhouse, but I figured I'd ask.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36909718"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909718" href="https://news.ycombinator.com/vote?id=36909718&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>I’m from India, planning to move to US on L1 as an IC. I want to get green card in 3-5 years or get out of the country. If I get green card, I want to look at bringing my parents permanently to US.<p>As someone without any research papers, any significant industry presence, how difficult will it be to get an EB1 green card if I start chipping at requirements now?</p><p>How doable is getting parents within next 5-7 years?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910115"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910115" href="https://news.ycombinator.com/vote?id=36910115&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Unless employees in your company are reporting to you in India, your hopes of getting into an EB1 category is close to zero. You need to prove that you've managed EMPLOYEES of your company in multiple countries other than the US.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36909979"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909979" href="https://news.ycombinator.com/vote?id=36909979&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>You can't sponsor your parents until you are a U.S. citizen and you must be a green card holder for 5 years (unless you are married to a U.S. citizen) before you can apply for citizenship.  Will you be managing any employees in your position in the U.S.?  Are you managing any employees now?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910286"><td></td></tr>
                <tr id="36910483"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36910483" href="https://news.ycombinator.com/vote?id=36910483&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>It's going to be a long process to a green card then.  The only reasonably fast path is the EB1A extraordinary ability path and the standard is very high and difficult and subjective/uncertain.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="36909298"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909298" href="https://news.ycombinator.com/vote?id=36909298&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Regarding remote work between Europe and the USA, is there an easy path for US based companies to hire a US citizen or an EU citizen to work remotely from an EU residence?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910093"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910093" href="https://news.ycombinator.com/vote?id=36910093&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Unfortunately, this isn't really a U.S. immigration question.  U.S. companies can employ anyone who is outside the U.S. without needing to obtain a U.S. work visa. U.S. immigration doesn't apply if the worker is outside the U.S.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909421" href="https://news.ycombinator.com/vote?id=36909421&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What's the usual cost for a company to change someone's status from a TN visa to an EB3/EB2 greencard? How long does it usually take?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910082"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910082" href="https://news.ycombinator.com/vote?id=36910082&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>There are multiple different EB2 and EB3 green card options so the costs and timelines can vary significantly. The timeline also can be impacted by country of birth.  Very broadly, the total cost ranges from $10,000 to $25,000 and the timeline ranges from 1 year (EB1 from a country other than India or China) to 15 years (non-EB1s from India).  For those not from India or China in the EB2 or EB3 category, the current processing is about 2-3 years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909864"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909864" href="https://news.ycombinator.com/vote?id=36909864&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Any option to apply to something like L-1 after doing remote work for years from the EU for a US company? I'm not an employee, just a freelance and the company doesn't have a subsidiary here</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909997"><td></td></tr>
                  <tr id="36909446"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909446" href="https://news.ycombinator.com/vote?id=36909446&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What restrictions/things to know or consider are there for Canadian founders who are on a mix of TN/H1-B visas?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910497"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910497" href="https://news.ycombinator.com/vote?id=36910497&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Those already in H-1B and TN status with their company or looking to obtain H-1B or TN status with their company?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909731"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909731" href="https://news.ycombinator.com/vote?id=36909731&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>My employer was in the process of getting a PERM for me when they announced layoffs, which caused the petition to be denied. How soon after a round of layoffs is it "safe" to apply again?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910009"><td></td></tr>
                  <tr id="36909373"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909373" href="https://news.ycombinator.com/vote?id=36909373&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I want to raise money from private investors (Angels only) no VCs. What is the easiest way to do that? I have a following/audience that I want to raise money from. Can I do this all through SAFEs? Can you please give me what's the best way to go on about this?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909456"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909456" href="https://news.ycombinator.com/vote?id=36909456&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Unfortunately, that's outside my area unless you are asking whether a foreign national can raise money for his or her startup.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909314"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909314" href="https://news.ycombinator.com/vote?id=36909314&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>How can startups more effectively use the OPT program? (I work at a university) I see a lot of graduating international students who would love to stay in the US post graduation and work at startups but navigating that seems difficult for startups.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909648"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909648" href="https://news.ycombinator.com/vote?id=36909648&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Isn't OPT quite simple for the employer compared to H1-B, etc.?<p>For the basic OPT, you don't really do any paperwork--the school and student do some paperwork and obtain an EAD that you use for the I-9 form.</p><p>For the STEM OPT extension, you have to be participating in E-Verify (required in many states anyway), and fill out a training plan for the two years: <a href="https://www.ice.gov/doclib/sevis/pdf/i983.pdf" rel="nofollow noreferrer">https://www.ice.gov/doclib/sevis/pdf/i983.pdf</a></p><p>I think the bigger issue is continuity--employers that plan to convert these to other visa types for continue employment will need to be planning for that from the beginning to avoid interruptions.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910273"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910273" href="https://news.ycombinator.com/vote?id=36910273&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>All correct. It's easy to employ those in F-1 OPT and STEM OPT status. And the size or newness of the company has no bearing on the company's ability to employ those in F-1 OPT and STEM OPT status. The main additional requirement is e-verify for companies wanting to employ those is F-1 STEM OPT status. But this isn't a burdensome requirement at all.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36909341"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909341" href="https://news.ycombinator.com/vote?id=36909341&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Are there courses in law school that prepare you well for this specific kind of law work, or did you learn most of what you do through working with folks who had the necessary expertise that could then be passed along through training?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910120"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910120" href="https://news.ycombinator.com/vote?id=36910120&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The latter.  It's really an apprenticeship process but that's really how it is for most areas of law. Law school really teaches one how to think critically and to write.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908804"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908804" href="https://news.ycombinator.com/vote?id=36908804&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Given recent industry layoffs, is there less demand for H1B visas? Ie, is it a better time for applicants to get one through?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908925"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908925" href="https://news.ycombinator.com/vote?id=36908925&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The H-1B lottery this year was riddled with fraud - so much so that USCIS will be conducting a second lottery soon - but it appears that there was no reduction in the numbers despite layoffs in certain industries.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908981"><td></td></tr>
                <tr id="36909180"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36909180" href="https://news.ycombinator.com/vote?id=36909180&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Calling it fraud is stupid. They deliberately reduced the work that is required, allowing people to file applications easily and cheaply. They deliberately allow people to file multiple applications, that I have not seen a single legitimate employee file. This is all deliberate, not a loophole or fraud.<p>Also, it is stupid to call H1B a high-skilled visa when you hand it out via lotteries. I wonder if people consider winning powerball as a skill?</p><p>But to answer your question, many people filed 10-20 applications each through fake companies to get H1B. The H1b acceptance rate was down to 13% and more than half the applications were filed by people with multiple applications.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910099"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36910099" href="https://news.ycombinator.com/vote?id=36910099&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Is submitting multiple applications illegal? I'd have to imagine that you would get caught for doing this once they see the same person in the system, especially if they approve the same person multiple times.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908993"><td></td></tr>
                              <tr id="36909092"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909092" href="https://news.ycombinator.com/vote?id=36909092&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Hey Peter, I want to learn more about the H1B program, why it is broken, and the bottlenecks and incentives for fixing it. Is there a resource you recommend? Something to ramp up on this corner of immigration policy?<p>Thanks for doing this! Apologies for the generic question
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36909149"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909149" href="https://news.ycombinator.com/vote?id=36909149&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>In your experience, what does the success rate looks like for incorporating a company with all H1B founders and with 1 US citizen&amp; 1+ H1B founders? Thanks</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909211"><td></td></tr>
                  <tr id="36909215"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909215" href="https://news.ycombinator.com/vote?id=36909215&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Regarding the GC backlog for India, what is your best guess for the number of years it will take for priority dates in 2016 to become current?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910085" href="https://news.ycombinator.com/vote?id=36910085&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Which category?<pre><code>    1st 01JAN12
    2nd 01JAN11
    3rd 01JAN09
    OW  01JAN09
    4th 01SEP18
</code></pre>
OW = other workers.<p>So check the diff between those dates and your date.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910145"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910145" href="https://news.ycombinator.com/vote?id=36910145&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>It's impossible to say because as I'm sure you know, the numbers don't always progress, sometimes they retrogress.  But I expect at least 5 more years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36908851"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908851" href="https://news.ycombinator.com/vote?id=36908851&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>If an international student is on a stem opt extension (24 months) that just started, and does YC, is it possible for them to get a green card before the stem opt expires?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909400"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909400" href="https://news.ycombinator.com/vote?id=36909400&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>As a general rule, an F-1 student on OPT can apply for a green card. There are backlogs in all green card categories right now and this is really what determines the length of the process. So, assuming the backlogs don't change in any significant way, those in the highest category (EB1) from countries other than India or China could get their green card within 2 years but those in a lower category (EB2 or EB3) or from India or China should expect the process to take longer than 2 years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908945"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908945" href="https://news.ycombinator.com/vote?id=36908945&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Is a J-1 more likely to be approved than an H-1B? What criteria need to be met to get a J-1 visa approved? I know people working ordinary jobs with these fyi.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909324"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909324" href="https://news.ycombinator.com/vote?id=36909324&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The J-1 is not supposed to be used to fill regular positions although the J-1 is sometimes abused by companies. The J-1 is supposed to be for training and career development and the J-1 trainee/intern is supposed to have the intent to return to his or her home country or last place of foreign residence.  All that being said, it's generally pretty easy to get a J-1 visa.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909497"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36909497" href="https://news.ycombinator.com/vote?id=36909497&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I work in a tourist town that only stays operational by bringing in thousands of J-1s each summer, and it honestly looks to me more like trafficking more than a legit use of the J-1 program - housing tied to job status with instant evictions if you lose a job, that kind of thing. I've always felt like the whole program feels sketchy with the way it is used here. Is there a good resource for understanding what is actually legal or not in the context of J-1 workers, so I can know for sure when a company in town crosses the line?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910160"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36910160" href="https://news.ycombinator.com/vote?id=36910160&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The State Department's website has very good information on the J-1 regarding the employer's responsibilities and the worker's rights.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="36910181"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910181" href="https://news.ycombinator.com/vote?id=36910181&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Hi Peter thanks for this.<p>European, PhD, what's the fastest way available for me to get a green card?</p><p>I've heard of the investor visa, but I can't invest 1mil, or hire 10 people.</p><p>I've also heard of the H1B, but from what I understand that means years of uncertainty.</p><p>I've held a L1B, not sure if that matters.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36910527"><td></td></tr>
                  <tr id="36908785"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908785" href="https://news.ycombinator.com/vote?id=36908785&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>How important is a degree for o-1? and what are easy or non-negotiables or important conditions or awards that definitely make someone qualify for a o-1?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909054"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909054" href="https://news.ycombinator.com/vote?id=36909054&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>A degree is not required at all. Of course those with an advanced degree by virtue of having obtained an advance degree often check a number of O-1 boxes (publications, journal/conference paper review work, original and significant contributions). I'm not aware of any easy awards that would help.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908779"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908779" href="https://news.ycombinator.com/vote?id=36908779&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Have any YC founders previously opted for 'citizenship based on investment programs' such as St. Kitts &amp; Neves etc?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36908893"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908893" href="https://news.ycombinator.com/vote?id=36908893&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I haven't seen that with any YC founders but other clients of ours have opted for foreign citizenship investment programs and they seem to have worked well.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36910369"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36910369" href="https://news.ycombinator.com/vote?id=36910369&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>I dread seeing your threads as it flags a significant amount of time has passed. (This is the fourth one I've seen) Tangible passage of time! Thanks for doing these btw.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910509"><td></td></tr>
                  <tr id="36908792"><td></td></tr>
                <tr id="36908986"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36908986" href="https://news.ycombinator.com/vote?id=36908986&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>There's no YC stance. I'll do my best to provide helpful, honest, and independent answers and advice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909668"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909668" href="https://news.ycombinator.com/vote?id=36909668&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Dual Irish/US Passport holder here -- if I wish to emigrate to the US do I have to do anything other than buy a plane ticket?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909820"><td></td></tr>
            <tr id="36909793"><td></td></tr>
            <tr id="36909934"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909934" href="https://news.ycombinator.com/vote?id=36909934&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>I don't think the US recognizes "dual citizenship" - as in they dont care, not they force you to give up a citizenship.<p>Once you have a US passport you are a US citizen, end of story. Doesn't matter which other passports you hold. You can't be denied entry into the US.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36909734"><td></td></tr>
                <tr id="36910186"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36910186" href="https://news.ycombinator.com/vote?id=36910186&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>From the U.S. Government's perspective, there's no issue holding other citizenships. But when you travel to the U.S., you are supposed to present your U.S. passport not your foreign passport.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36908923"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908923" href="https://news.ycombinator.com/vote?id=36908923&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Tangentially related Q: in the USA there are “illegal” immigrants who have moved into the country. I worry about human rights abuses against these people. What are the methods available for these people to become citizens if they so wish?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909435"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909435" href="https://news.ycombinator.com/vote?id=36909435&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>There is not currently any specific "pathway to citizenship" designed for people who are currently in the country illegally. They would have to qualify for a green card on the same basis as anyone else, then apply for citizenship after that.<p>However, they often are not eligible to do so because of their illegal prescence. If one has been in the US illegally, as an adult, for more than 180 days, they have a three-year ban. After one year it becomes a 10-year ban. This applies to both visiting and immigration. They have to return home (or another country) to serve the ban before getting a visa to return.</p><p>One notable exception to this rule is marrying a US citizen, but only if the initial <i>entry</i> was legal (i.e. visa overstay, not border jumping). Being a parent of a US citizen also works, but the child has to be 21 first. Being a parent of a US citizen under 21 has no immigration benefits.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909868"><td></td></tr>
                  <tr id="36909007"><td></td></tr>
                  <tr id="36908840"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908840" href="https://news.ycombinator.com/vote?id=36908840&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What are the reasons to bring people to san fransisco in the first place and deal with immigration problems? Why can't startups just use a payroll provider like deel and have a semi-global team?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36910605"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910605" href="https://news.ycombinator.com/vote?id=36910605&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>At least founders team often can't be semi-global. A lot of VCs simply wouldn't bother working with you if some people on your board are not from US and it's even worse if someone live in some developing country. For them it's too much risk.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36908865"><td></td></tr>
                <tr id="36909720"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36909720" href="https://news.ycombinator.com/vote?id=36909720&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>That's right.  But many U.S. companies in fact do use Deel and similar platforms to employ contractors living abroad.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36909532"><td></td></tr>
                <tr id="36910221"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36910221" href="https://news.ycombinator.com/vote?id=36910221&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Depending on the relevant GC period (whether 3 or 5 years), an applicant for naturalization must provide copies of his or her federal tax returns or tax returns transcripts for this period.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36909406"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36909406" href="https://news.ycombinator.com/vote?id=36909406&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><p><span>Let's say I have a business/startup idea, funding is "fine" but I wish to just use Filipino nurses due to shortages - (or other skilled labor from the Philippines) -<p>Would it have to be solely through H1B? I've seen/witnessed that for certain types of jobs, e.g. teachers - alot of these barriers are moved.</p><p>What sort of obligations would a company have to first show that they tried but couldn't hire local people, or failed to relocate people to come?</p><p>Would this just be standard H1B process? There is no exact case here/situation, I'm just curious because - the nursing license is transferrable from the Philippines to many USA states (if not all?) and the Philippines is a country which is known to "export" it's people, mostly as "OFW" throughout East Asia and Middle East and as of late Canada.</p><p>I'm curious how this mechanism works - because it seems to be a win/win.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36909533"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909533" href="https://news.ycombinator.com/vote?id=36909533&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>Because you mentioned nursing, I'll respond to that. The issue with nursing positions is that they often are not considered H-1B positions. This is why years ago there was a special visa (the H-1C) for nurses to deal with the shortage. Other than the H-1B, there really are no options for nurses.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36908872"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36908872" href="https://news.ycombinator.com/vote?id=36908872&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>What’s the easiest way for a startup to poach H1B workers from competitors and large, established companies? Is it even possible, or are they trapped at their sponsoring company? If there is a process or workflow for accomplishing this in a repeatable/scalable manner, I’d be keen to know!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36909165"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36909165" href="https://news.ycombinator.com/vote?id=36909165&amp;how=up&amp;goto=item%3Fid%3D36908574"></a></center>    </td><td><br><div>
                  <p><span>The H-1B transfer process is easy for qualified workers even if the sponsoring company is a startup. So the blocker really isn't the H-1B transfer process. Sometimes employees are in the midst of the green card process and feel trapped until they have a green card or are far enough along in the process such that they can port their green card application to a new company. One advantage that smaller companies have is that they often are much more willing to sponsor employees for O-1 visas as well as NIW- and EB1A-based green cards and that the relative impact of employees at a smaller company is much greater than at a large company and this can help with NIW- and EB1A-based green card applications.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cap'n Proto 1.0 (634 pts)]]></title>
            <link>https://capnproto.org/news/2023-07-28-capnproto-1.0.html</link>
            <guid>36908309</guid>
            <pubDate>Fri, 28 Jul 2023 15:28:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://capnproto.org/news/2023-07-28-capnproto-1.0.html">https://capnproto.org/news/2023-07-28-capnproto-1.0.html</a>, See on <a href="https://news.ycombinator.com/item?id=36908309">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="main_content_wrap">

<h2><a href="https://capnproto.org/news/">News</a></h2>



<p>It’s been a little over ten years since the first release of Cap’n Proto, on April 1, 2013. Today I’m releasing version 1.0 of Cap’n Proto’s C++ reference implementation.</p>
<p>Don’t get too excited! There’s not actually much new. Frankly, I should have declared 1.0 a long time ago – probably around version 0.6 (in 2017) or maybe even 0.5 (in 2014). I didn’t mostly because there were a few advanced features (like three-party handoff, or shared-memory RPC) that I always felt like I wanted to finish before 1.0, but they just kept not reaching the top of my priority list. But the reality is that Cap’n Proto has been relied upon in production for a long time. In fact, you are using Cap’n Proto right now, to view this site, which is served by Cloudflare, which uses Cap’n Proto extensively (and is also my employer, although they used Cap’n Proto before they hired me). Cap’n Proto is used to encode millions (maybe billions) of messages and gigabits (maybe terabits) of data every single second of every day. As for those still-missing features, the real world has seemingly proven that they aren’t actually that important. (I still do want to complete them though.)</p>
<p>Ironically, the thing that finally motivated the 1.0 release is so that we can start working on 2.0. But again here, don’t get too excited! Cap’n Proto 2.0 is not slated to be a revolutionary change. Rather, there are a number of changes we (the Cloudflare Workers team) would like to make to Cap’n Proto’s C++ API, and its companion, the KJ C++ toolkit library. Over the ten years these libraries have been available, I have kept their APIs pretty stable, despite being 0.x versioned. But for 2.0, we want to make some sweeping backwards-incompatible changes, in order to fix some footguns and improve developer experience for those on our team.</p>
<p>Some users probably won’t want to keep up with these changes. Hence, I’m releasing 1.0 now as a sort of “long-term support” release. We’ll backport bugfixes as appropriate to the 1.0 branch for the long term, so that people who aren’t interested in changes can just stick with it.</p>
<h2 id="whats-actually-new-in-10">What’s actually new in 1.0?</h2>
<p>Again, not a whole lot has changed since the last version, 0.10. But there are a few things worth mentioning:</p>
<ul>
<li>
<p>A number of optimizations were made to improve performance of Cap’n Proto RPC. These include reducing the amount of memory allocation done by the RPC implementation and KJ I/O framework, adding the ability to elide certain messages from the RPC protocol to reduce traffic, and doing better buffering of small messages that are sent and received together to reduce syscalls. These are incremental improvements.</p>
</li>
<li>
<p><strong>Breaking change:</strong> Previously, servers could opt into allowing RPC cancellation by calling <code>context.allowCancellation()</code> after a call was delivered. In 1.0, opting into cancellation is instead accomplished using an annotation on the schema (the <code>allowCancellation</code> annotation defined in <code>c++.capnp</code>). We made this change after observing that in practice, we almost always wanted to allow cancellation, but we almost always forgot to do so. The schema-level annotation can be set on a whole file at a time, which is easier not to forget. Moreover, the dynamic opt-in required a lot of bookkeeping that had a noticeable performance impact in practice; switching to the annotation provided a performance boost. For users that never used <code>context.allowCancellation()</code> in the first place, there’s no need to change anything when upgrading to 1.0 – cancellation is still disallowed by default. (If you are affected, you will see a compile error. If there’s no compile error, you have nothing to worry about.)</p>
</li>
<li>
<p>KJ now uses <code>kqueue()</code> to handle asynchronous I/O on systems that have it (MacOS and BSD derivatives). KJ has historically always used <code>epoll</code> on Linux, but until now had used a slower <code>poll()</code>-based approach on other Unix-like platforms.</p>
</li>
<li>
<p>KJ’s HTTP client and server implementations now support the <code>CONNECT</code> method.</p>
</li>
<li>
<p><a href="https://github.com/capnproto/capnproto/pull/1700">A new class <code>capnp::RevocableServer</code> was introduced</a> to assist in exporting RPC wrappers around objects whose lifetimes are not controlled by the wrapper. Previously, avoiding use-after-free bugs in such scenarios was tricky.</p>
</li>
<li>
<p>Many, many smaller bug fixes and improvements. <a href="https://github.com/capnproto/capnproto/pulls?q=is%3Apr+is%3Aclosed">See the PR history</a> for details.</p>
</li>
</ul>
<h2 id="whats-planned-for-20">What’s planned for 2.0?</h2>
<p>The changes we have in mind for version 2.0 of Cap’n Proto’s C++ implementation are mostly NOT related to the protocol itself, but rather to the C++ API and especially to KJ, the C++ toolkit library that comes with Cap’n Proto. These changes are motivated by our experience building a large codebase on top of KJ: namely, the Cloudflare Workers runtime, <a href="https://github.com/cloudflare/workerd"><code>workerd</code></a>.</p>
<p>KJ is a C++ toolkit library, arguably comparable to things like Boost, Google’s Abseil, or Facebook’s Folly. I started building KJ at the same time as Cap’n Proto in 2013, at a time when C++11 was very new and most libraries were not really designing around it yet. The intent was never to create a new standard library, but rather to address specific needs I had at the time. But over many years, I ended up building a lot of stuff. By the time I joined Cloudflare and started the Workers Runtime, KJ already featured a powerful async I/O framework, HTTP implementation, TLS bindings, and more.</p>
<p>Of course, KJ has nowhere near as much stuff as Boost or Abseil, and nowhere near as much engineering effort behind it. You might argue, therefore, that it would have been better to choose one of those libraries to build on. However, KJ had a huge advantage: that we own it, and can shape it to fit our specific needs, without having to fight with anyone to get those changes upstreamed.</p>
<p>One example among many: KJ’s HTTP implementation features the ability to “suspend” the state of an HTTP connection, after receiving headers, and transfer it to a different thread or process to be resumed. This is an unusual thing to want, but is something we needed for resource management in the Workers Runtime. Implementing this required some deep surgery in KJ HTTP and definitely adds complexity. If we had been using someone else’s HTTP library, would they have let us upstream such a change?</p>
<p>That said, even though we own KJ, we’ve still tried to avoid making any change that breaks third-party users, and this has held back some changes that would probably benefit Cloudflare Workers. We have therefore decided to “fork” it. Version 2.0 is that fork.</p>
<p>Development of version 2.0 will take place on Cap’n Proto’s new <code>v2</code> branch. The <code>master</code> branch will become the 1.0 LTS branch, so that existing projects which track <code>master</code> are not disrupted by our changes.</p>
<p>We don’t yet know all the changes we want to make as we’ve only just started thinking seriously about it. But, here’s some ideas we’ve had so far:</p>
<ul>
<li>
<p>We will require a compiler with support for C++20, or maybe even C++23. Cap’n Proto 1.0 only requires C++14.</p>
</li>
<li>
<p>In particular, we will require a compiler that supports C++20 coroutines, as lots of KJ async code will be refactored to rely on coroutines. This should both make the code clearer and improve performance by reducing memory allocations. However, coroutine support is still spotty – as of this writing, GCC seems to ICE on KJ’s coroutine implementation.</p>
</li>
<li>
<p>Cap’n Proto’s RPC API, KJ’s HTTP APIs, and others are likely to be revised to make them more coroutine-friendly.</p>
</li>
<li>
<p><code>kj::Maybe</code> will become more ergonomic. It will no longer overload <code>nullptr</code> to represent the absence of a value; we will introduce <code>kj::none</code> instead. <code>KJ_IF_MAYBE</code> will no longer produce a pointer, but instead a reference (a trick that becomes possible by utilizing C++17 features).</p>
</li>
<li>
<p>We will drop support for compiling with exceptions disabled. KJ’s coding style uses exceptions as a form of software fault isolation, or “catchable panics”, such that errors can cause the “current task” to fail out without disrupting other tasks running concurrently. In practice, this ends up affecting every part of how KJ-style code is written. And yet, since the beginning, KJ and Cap’n Proto have been designed to accommodate environments where exceptions are turned off at compile time, using an elaborate system to fall back to callbacks and distinguish between fatal and non-fatal exceptions. In practice, maintaining this ability has been a drag on development – no-exceptions mode is constantly broken and must be tediously fixed before each release. Even when the tests are passing, it’s likely that a lot of KJ’s functionality realistically cannot be used in no-exceptions mode due to bugs and fragility. Today, I would strongly recommend against anyone using this mode except maybe for the most basic use of Cap’n Proto’s serialization layer. Meanwhile, though, I’m honestly not sure if anyone uses this mode at all! In theory I would expect many people do, since many people choose to use C++ with exceptions disabled, but I’ve never actually received a single question or bug report related to it. It seems very likely that this was wasted effort all along. By removing support, we can simplify a lot of stuff and probably do releases more frequently going forward.</p>
</li>
<li>
<p>Similarly, we’ll drop support for no-RTTI mode and other exotic modes that are a maintenance burden.</p>
</li>
<li>
<p>We may revise KJ’s approach to reference counting, as the current design has proven to be unintuitive to many users.</p>
</li>
<li>
<p>We will fix a longstanding design flaw in <code>kj::AsyncOutputStream</code>, where EOF is currently signaled by destroying the stream. Instead, we’ll add an explicit <code>end()</code> method that returns a Promise. Destroying the stream without calling <code>end()</code> will signal an erroneous disconnect. (There are several other aesthetic improvements I’d like to make to the KJ stream APIs as well.)</p>
</li>
<li>
<p>We may want to redesign several core I/O APIs to be a better fit for Linux’s new-ish io_uring event notification paradigm.</p>
</li>
<li>
<p>The RPC implementation may switch to allowing cancellation by default. As discussed above, this is opt-in today, but in practice I find it’s almost always desirable, and disallowing it can lead to subtle problems.</p>
</li>
<li>
<p>And so on.</p>
</li>
</ul>
<p>It’s worth noting that at present, there is no plan to make any backwards-incompatible changes to the serialization format or RPC protocol. The changes being discussed only affect the C++ API. Applications written in other languages are completely unaffected by all this.</p>
<p>It’s likely that a formal 2.0 release will not happen for some time – probably a few years. I want to make sure we get through all the really big breaking changes we want to make, before we inflict update pain on most users. Of course, if you’re willing to accept breakages, you can always track the <code>v2</code> branch. Cloudflare Workers releases from <code>v2</code> twice a week, so it should always be in good working order.</p>


</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flash Museum (232 pts)]]></title>
            <link>https://flashmuseum.org/</link>
            <guid>36908265</guid>
            <pubDate>Fri, 28 Jul 2023 15:25:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flashmuseum.org/">https://flashmuseum.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36908265">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><strong>❗Website is in beta testing and an experimental stage. Some games may not properly run.</strong></p><div id="page">
<main id="main">
<article id="post-573586" class="page" itemtype="https://schema.org/CreativeWork" itemscope="">
<div itemprop="text">
<h2>Welcome to Flash Museum!</h2>
<p>FlashMuseum is a project archiving <strong>flash games</strong> and <strong>animations </strong>and making them playable again on your browser. On this website, you can explore more than 130,000 flash games and animations. To get you started on your nostalgic journey, you can try the “Hall of Fame” games and animations below.</p>
<div>
<div><div>
<figure><a href="https://flashmuseum.org/age-of-war/"><img decoding="async" src="https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War.jpg" alt="Age of War" width="320" height="180" srcset="https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War.jpg 1280w, https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War-300x169.jpg 300w, https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War-1024x576.jpg 1024w, https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War-150x84.jpg 150w, https://flashmuseum.org/wp-content/uploads/2023/07/Age-of-War-768x432.jpg 768w" sizes="(max-width: 320px) 100vw, 320px"></a></figure></div>
<p><strong>Play Age of War</strong></p>
</div>
<div><div>
<figure><a href="https://flashmuseum.org/htf-43-out-on-a-limb/"><img decoding="async" loading="lazy" src="https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends.jpg" alt="Happy Tree Friends" width="320" height="180" srcset="https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends.jpg 1280w, https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends-300x169.jpg 300w, https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends-1024x576.jpg 1024w, https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends-150x84.jpg 150w, https://flashmuseum.org/wp-content/uploads/2023/07/Happy-Tree-Friends-768x432.jpg 768w" sizes="(max-width: 320px) 100vw, 320px"></a></figure></div>
<p><strong>Watch Happy Tree Friends</strong></p>
</div>
<div><div>
<figure><a href="https://flashmuseum.org/?redirect_to=random&amp;cat=3213"><img decoding="async" loading="lazy" src="https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash.jpg" alt="Random Flash" width="320" height="180" srcset="https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash.jpg 1280w, https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash-300x169.jpg 300w, https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash-1024x576.jpg 1024w, https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash-150x84.jpg 150w, https://flashmuseum.org/wp-content/uploads/2023/07/Random-Flash-768x432.jpg 768w" sizes="(max-width: 320px) 100vw, 320px"></a></figure></div>
<p><strong>Or play something random</strong></p>
</div>
</div>
<div>
<h2>🏆<span><a href="https://flashmuseum.org/browse/hall-of-fame/">Hall of Fame (Games)</a></span></h2>
<div>
<div><p>
<h2><a href="https://flashmuseum.org/the-fancy-pants-adventures-world-1/">The Fancy Pants Adventures: World 1</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/decision-medieval/">Decision Medieval</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/punk-o-matic-2/">Punk-o-Matic 2</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/a-small-favor/">A Small Favor</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/glean/">Glean</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/frantic-frigates/">Frantic Frigates</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/bloody-fun-day/">Bloody Fun Day</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/armor-mayhem/">Armor Mayhem</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/my-pet-protector/">My Pet Protector</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/auditorium-demo/">Auditorium Demo</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/learn-to-fly-2-2/">Learn to Fly 2</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/anti-idle-the-game/">Anti-Idle: The Game</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/warlords-call-to-arms/">Warlords: Call to Arms</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/enigmata-2-genus-revenge/">Enigmata 2: Genu’s Revenge</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/acnos-energizer/">Acno’s Energizer</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/raze-3/">Raze 3</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/ginormo-sword/">Ginormo Sword</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/monsters-den-book-of-dread/">Monsters’ Den: Book of Dread</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/kingdom-rush/">Kingdom Rush</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/epic-battle-fantasy-iv/">Epic Battle Fantasy IV</a></h2>
</p></div>
</div>
<p><a href="https://flashmuseum.org/browse/hall-of-fame/">Load MORE</a>
</p></div>
<div>
<h2>🏆<span><a href="https://flashmuseum.org/browse/hall-of-fame-animations/">Hall of Fame (Animations)</a></span></h2>
<div>
<div><p>
<h2><a href="https://flashmuseum.org/marios-castle-calamity/">Mario’s Castle Calamity</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/brawl-taunts/">Brawl Taunts</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/grand-theft-awesome-iv/">Grand Theft Awesome IV</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/sonic-shorts-volume-1/">Sonic Shorts: Volume 1</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/magical-trevor/">Magical Trevor</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/stamp-on-the-ground/">Stamp On The Ground</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/mario-twins/">Mario Twins</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/super-mario-rpg-rawest-forest/">Super Mario RPG: Rawest Forest</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/htf-34-eyes-cold-lemonade/">HTF 34: Eyes Cold Lemonade</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/blundercats/">BlunderCats</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/picos-unloaded/">Pico’s Unloaded</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/dads-home/">Dad’s Home</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/final-fantasy-a/">Final Fantasy A+</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/bunnykill/">Bunnykill</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol-anime-lol/">ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL! ANIME LOL!</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/the-matrix-has-you/">The Matrix Has You</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/the-end-of-the-world/">The End of the World</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/asdfmovie/">asdfmovie</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/a-walk-in-the-woods-2/">A Walk in the Woods</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/charlie-the-unicorn/">Charlie the Unicorn</a></h2>
</p></div>
</div>
</div>
<p><a href="https://flashmuseum.org/browse/hall-of-fame-animations/">Load MORE</a></p><div>
<h2>👖 <a href="https://flashmuseum.org/browse/series/the-fancy-pants-adventures/"><span>Fancy Pants Adventures!</span></a> (recommended)</h2>
<div>
<div><p>
<h2><a href="https://flashmuseum.org/the-fancy-pants-adventures-world-1/">The Fancy Pants Adventures: World 1</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/the-fancy-pants-adventures-world-2/">The Fancy Pants Adventures: World 2</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/the-fancy-pants-adventure-world-3/">The Fancy Pants Adventure: World 3</a></h2>
</p></div>
<div><p>
<h2><a href="https://flashmuseum.org/the-fancy-pants-adventures-world-4-part-1/">The Fancy Pants Adventures: World 4 part 1</a></h2>
</p></div>
</div>
</div>
</div>
</article>
</main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California moves to silence Stanford researchers who got data to study education (411 pts)]]></title>
            <link>https://edsource.org/2023/california-moves-to-silence-stanford-researchers-who-got-state-data-to-study-education-issues/694920</link>
            <guid>36908136</guid>
            <pubDate>Fri, 28 Jul 2023 15:19:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://edsource.org/2023/california-moves-to-silence-stanford-researchers-who-got-state-data-to-study-education-issues/694920">https://edsource.org/2023/california-moves-to-silence-stanford-researchers-who-got-state-data-to-study-education-issues/694920</a>, See on <a href="https://news.ycombinator.com/item?id=36908136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>Credit: Louis Freedberg / EdSource</span></p><p><span>The California Department of Education building in Sacramento.</span></p></div><div><p><img src="https://edsource.org/wp-content/uploads/2014/08/Cali-DofE.jpg"><span>Credit: Louis Freedberg / EdSource</span></p><p><span>The California Department of Education building in Sacramento.</span></p></div><p><span>The California Department of Education has threatened to sue two prominent Stanford University education professors to prevent them from testifying in a lawsuit against the department — actions the American Civil Liberties Union of Southern California calls an attempt to muzzle them.&nbsp;</span></p>
<p><span>The ACLU, in turn, is threatening a lawsuit of its own — against CDE for infringing their and other researchers’ First Amendment rights.&nbsp;</span></p>
<p><span>Observers say the dispute has the potential to limit who conducts education research in California and what they are able to study because CDE controls the sharing of data that is not available to the public.</span></p>
<p><span>At issue is a restriction that CDE requires researchers to sign as a condition for their gaining access to nonpublic K-12 data. The clause, which CDE is interpreting broadly, prohibits the researcher from participating in any litigation against the department, even in cases unrelated to the research they were doing through CDE.&nbsp;&nbsp;</span></p>
<p><span>“It keeps education researchers from weighing in on the side of parties who are adverse to the California Department of Education. So it’s really skewing the information and expertise that can come into courts,” said Alyssa Morones, an ACLU attorney involved with the case. “Individuals and students seeking to vindicate their rights no longer will have access to these education experts, and the court can no longer hear what they have to say.”</span></p>
<h3><b>Court brief: State failed to lead academic recovery</b></h3>
<p><span>Professors Sean Reardon and Thomas Dee had signed separate and unrelated data-partnership agreements with the department, and both were asked by attorneys in an ongoing lawsuit, </span><a href="https://publiccounsel.org/litigation/cayla-j-v-california/"><span>Cayla J. v. State of California</span></a><span>, to testify on behalf of students filing the case. The lawsuit, against the California Department of Education, the State Board of Education and State Superintendent of Public Instruction Tony Thurmond, charges the state</span><span> with failing to prevent the deep learning loss imposed by the pandemic </span><span>on low-income students and other high-needs students.&nbsp;</span></p>
<p><span>Reardon, who had co-authored </span><a href="https://educationrecoveryscorecard.org/"><span>landmark nationwide research on pandemic learning,</span></a><span> said he would have considere</span><span>d providing expert testimony. </span><span>But warned this month by CDE that he’d be breaching his contract, Reardon declined — even though his learning loss research </span><span>did not involve the data obtained through his agreement with CDE.</span></p>

<p><span>Dee, a professor at the Graduate School of Education at Stanford, agreed to serve as an expert witness for the plaintiffs in the Cayla J. case on the effects of Covid-19 on enrollment, chronic absenteeism and student engagement in California. This month, he was one of a half-dozen nationally prominent education professors who filed briefs in the case.&nbsp;</span></p>
<p><span>In it, Dee cited data on enrollment declines and chronic absenteeism. He concluded, “Because of both its comprehensive data systems and its powerful fiscal and operational capacities, the state of California is in a unique position to provide leadership in better understanding and meeting the serious challenges of academic recovery. However, to date, the state has not clearly demonstrated such leadership, instead emphasizing responses by local school districts.”</span></p>
<p><span>CDE moved against Dee even though the data contract he had signed on behalf of a Stanford program was for research unrelated to the Cayla J. case.&nbsp;</span></p>
<p><span>On Feb.24, after CDE discovered that Dee had filed the brief, the department warned Dee that he had violated the contract he had signed in February 2022 as the chief investigator for the </span><a href="https://gardnercenter.stanford.edu/"><span>John W. Gardner Center for Youth and Their Communities</span></a><span> at Stanford. As a result, the letter said, CDE was suspending the data partnership and demanding that Dee “mitigate further damage.” The department would consider seeking an injunction to prevent him from participating in the Cayla J. case along with a $50,000 fine.&nbsp;</span></p>
<p><span>“Also, be aware,” wrote Cindy Kazanis, the director of CDE’s Analysis, Measurement, and Accountability Reporting Division, “that your actions have adversely impacted your working relationship with CDE, and your response to this letter is critically important to existing and future collaborations between us.” The letter was copied to Stanford.&nbsp;</span></p>
<p><span>The contract that Dee signed with CDE is </span><span>to examine how the California School Dashboard was affecting alternative schools serving those at risk of dropping out and those with motivation and behavior issues. He said he signed the contract in his capacity as faculty director of the Gardner Center, but had not actually looked at any of the data.&nbsp;</span></p>
<p><span>Dee said he relied on publicly available data in writing his brief for the Cayla J. case. He declined to comment further on the case.&nbsp;</span></p>
<p><span>The dispute is now in the courts. The plaintiffs’ attorneys in Cayla J., the public interest law firm Public Counsel and Morrison and Foerster, a San Francisco-based law firm doing pro bono work, </span><span>are asking a Superior Court judge to allow Dee’s participation in this case and protect him from CDE’s penalties — but only in this particular lawsuit. A hearing is scheduled early next week in Alameda Superior Court.&nbsp;</span></p>
<p><span>The ACLU </span><a href="https://www.documentcloud.org/documents/23889016-cde-aclu-tomdee-motion-072723"><span>filed a brief on Feb. 27 supporting Dee’s participation in the Cayla J. case</span></a><span>. But meanwhile, it took the first steps </span><span>toward </span><span>a larger lawsuit to eliminate CDE’s litigation prohibition.&nbsp;</span></p>
<h3><b>‘What are state officials afraid of?’</b></h3>
<p><span>Michael Jacobs, an attorney with Morrison and Foerster, said he was disappointed that the state would attempt to block education experts from giving their expertise. “The futures of the least advantaged schoolchildren in California are at issue. The data these experts utilized are all public.”</span></p>
<p><span>“What are state officials afraid of?” Jacobs said. “That their performance in running the school system during the pandemic in fact aggravated the achievement gap? That notwithstanding their protestations, they haven’t done enough to address that problem?”</span></p>
<p><span>CDE declined to comment on the need for the litigation ban in data contracts or its threats and actions against Dee or Reardon. Researchers told EdSource they were unaware of similar prohibitions in other states, but EdSource could not verify that.&nbsp;</span></p>
<p><span>In a</span><a href="https://edsource.org/wp-content/uploads/2023/07/ACLU-CDE-EdResearch-let-070723.pdf"> <span>July 7 letter</span></a><span>, the ACLU gave the department 10 days to expunge the restriction from all contracts with researchers. In a one-sentence defense a week later, Len Garfinkel, general counsel for CDE, stated, ”In our view, the Department’s data protection agreements are compliant with law.”</span></p>
<p><span>ACLU hasn’t revealed when it might take its next step.&nbsp;</span></p>
<p><span>ACLU’s focus was a separate five-year research contract that the department signed in 2018 and updated in 2020 with the Learning Policy Institute, a Palo Alto-based nonprofit education research organization.</span></p>
<p><span>The next-to-the-last clause in the 11-page document, titled “Interests adverse to the California Department of Education,” states that as long as the contract is in effect, “</span><span>LPI’s employees, executives, and other representatives shall not voluntarily testify for, consult with, or advise a party in conjunction with any mediation, arbitration, litigation, or other similar legal proceeding where LPI knows that party is adverse to the CDE, the State Superintendent of Public Instruction or the State Board of Education.”&nbsp;&nbsp;</span></p>
<p><span>In addition, if anyone covered by the contract does become involved in litigation, CDE can immediately revoke the contract and demand all the data be returned or destroyed. LPI and signers of the agreement would be subject to a fine. That’s the same wording as in Dee’s contract through the Gardner Center.&nbsp;</span></p>
<h3><b>Linda Darling-Hammond among contract signers</b></h3>
<p><span>Reardon, professor of poverty and inequality in education at the Stanford Graduate School of Education as well as a senior research fellow at LPI, signed that contract, along with 15 others, mainly LPI employees and researchers. Signing as the principal investigator was Linda Darling-Hammond, LPI’s president and CEO. She also is the president of the state board and an adviser to Gov. Gavin Newsom. She signed the original agreement a year before Newsom nominated her to the state board.&nbsp;</span></p>
<p><span>The ACLU, acting on its own, asserted the provision is clearly unconstitutional. A government can set restrictions for granting access to nonpublic data for research purposes, but not to limit a researcher’s First Amendment right of free speech, it said in its </span><a href="https://edsource.org/wp-content/uploads/2023/07/ACLU-CDE-EdResearch-let-070723.pdf"><span>nine-page letter </span></a><span>to the department.&nbsp;</span></p>
<p><span>What’s “even ‘more blatant and more egregious,’” the ACLU wrote, citing a</span><a href="https://www.oyez.org/cases/2014/13-502"> <span>2015 U.S. Supreme Court decision</span></a><span>,</span><span> is the department’s “viewpoint discrimination.” The contract doesn’t ban an education researcher from testifying </span><i><span>for</span></i><span> the department in a lawsuit; it just can’t testify </span><i><span>against</span></i><span> it.</span></p>
<p><span>“Viewpoint discrimination is poison to a free society,”&nbsp; U.S. Supreme Court Justice Samuel Alito wrote in</span><a href="https://www.mtsu.edu/first-amendment/article/1672/iancu-v-brunetti"> <span>a different high court opinion in a 2019</span></a><span> case that the ACLU also cited in its letter.</span></p>
<p><span>&nbsp;</span><span>Morones, who wrote the ACLU letter, said the prohibition is far more broad than the government needs to protect its data. As shown by the department’s response in the Cayla J. lawsuit, the department could apply the provision to thwart LPI and anyone who signed the contract from participating in any litigation against the department, the state board and the state superintendent, Thurmond, she said.</span></p>
<p><span>The </span><a href="https://educationrecoveryscorecard.org/"><span>Education Recovery Scorecard</span></a><span>,</span><span> the learning loss research that Reardon co-authored, relies on publicly available data from California and 39 other states, and, Reardon said, does not use any data provided to the LPI for its research project. Reardon’s project with LPI&nbsp; is focused on the pre-pandemic success of English learners in California from 2006 to 20-19.</span></p>
<h3><b>Researchers rely on partnership agreements</b></h3>
<p><span>Researchers seek agreements with the department to access nonpublic data, especially student-level data that detail the demographic information and the performance records over time of California’s 5.8 million students but without any names or identifying information. That data is the gold standard for accurate research. A partnership contract details the department’s commitments and researchers’ responsibilities, including strong assurances they will have security protections in place to protect students’ privacy and anonymity.</span></p>
<p><span>The dispute does not involve the disclosure of any student-level information.</span></p>
<p><span>Maria Clayton, the director of communications for CDE,</span> <span>said the agreement “is standard language that CDE has used for years in these types of data-sharing agreements.” </span></p>
<p><span>Reardon said in an email, “It’s perfectly appropriate – even necessary – that CDE or any state agency ensure student privacy and factual correctness when the state’s data is used by external researchers. It is unclear to me, however, how restricting researchers’ freedom to testify in a lawsuit, even an unrelated one, serves the interests of California’s students.”&nbsp;</span></p>
<p><span>“The restriction does not make research better,” he added,&nbsp; “and does nothing that I can see to protect student privacy. It may limit which researchers are willing or able to work with the state, leaving the state without access to some of the best researchers; and it may limit the effectiveness of litigation that might benefit California’s students.”</span></p>
<h3><b>No restrictions on what researchers can publish</b></h3>
<p><span>The contract does not impose any restrictions on researchers’ ability to independently report what they learn from the data.</span></p>
<p><span>Patrick Shields, the executive director of LPI, said the department doesn’t interfere in how researchers report on their findings. And since LPI is a research organization that does not engage in litigation, it is not affected by the restriction not to testify against the state.</span></p>
<p><span>“We don’t feel restrictions on portraying data as it is. There have been no internal discussions (with the department) that we can’t say this or that,” he said.&nbsp; </span><span>&nbsp;</span></p>
<p><span>But researchers seek access to analyze data without knowing what they will discover. LPI’s contract with the department, which it calls the California Equity Project, covers a range of topics that have already generated and will produce dozens of studies on teacher shortages, teacher and administrator professional development, homeless students, English learners, foster youths and K-12 achievement and funding gaps.</span></p>
<p><span>Studies using a wide swath of data could lead to legislation, or it could also prompt advocacy organizations like Public Counsel and the ACLU to pursue remedies through the courts </span><span>to fix flaws in state laws or address poor student performance or inequities in funding.&nbsp;</span></p>
<p><span>ACLU argues that </span><span>preventing researchers from</span> <span>sharing their expertise with the plaintiffs would be prior restraint and deny</span> <span>the public a full and fair presentation of the issues</span><span>.</span></p>
<p><span>For this and other reasons, David Plank, the retired executive of Policy Analysis for California Education or PACE, a collaborative research and policy organization based at Stanford and several other universities, said he “would never have signed a contract in which we agreed to protect the interests or reputation of the agency with which we would have signed.”&nbsp;</span></p>
<p><span>To do so, he said, would be “contrary to the fundamental norms of academic research.”</span></p>
<p><strong><em>To get more reports like this one,  <a id="endOfArticleSubscribe2022" href="https://edsource.org/subscribe">click here</a> to sign up for EdSource’s no-cost daily email on latest developments in education.</em></strong></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rain Panels: Harvesting the energy of falling raindrops (102 pts)]]></title>
            <link>https://thedebrief.org/forget-solar-panels-here-come-rain-panels/</link>
            <guid>36907674</guid>
            <pubDate>Fri, 28 Jul 2023 14:54:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedebrief.org/forget-solar-panels-here-come-rain-panels/">https://thedebrief.org/forget-solar-panels-here-come-rain-panels/</a>, See on <a href="https://news.ycombinator.com/item?id=36907674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																										<p>In a potentially game-changing breakthrough in energy harvesting, researchers have found a way to capture, store and utilize the electrical power generated by falling raindrops, which may lead to the development of rooftop, power-generating rain panels.</p>
<p>Previous attempts to generate power from failing rain have run into specific technical hurdles that often seemed impossible to surpass, but the researchers behind this new method say they have found a solution that may finally make such rain panels as popular, if not more so, than solar panels.</p>
<h2><strong>Rain Panels Suffer From Technical Limitations</strong></h2>
<p>Engineers have long known about the potential power generation capabilities of fallen raindrops. The idea is already in practical applications like hydroelectric dams and wave power collection systems, where the movement of the water generates electricity.</p>
<p>However, the efforts to collect energy from falling raindrops have faced a technical hurdle that has made the concept inefficient and impractical. By using something called a triboelectric nanogenerator (TENG), engineers can collect the tiny but measurable amount of electricity generated by a falling raindrop, but as one might expect, the amount of power per raindrop is incredibly small.</p>
<p><iframe id="_ytid_50873" width="1170" height="658" data-origwidth="1170" data-origheight="658" src="https://www.youtube.com/embed/joetshqFAOM?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;cc_lang_pref=&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=1&amp;rel=1&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p>

<p>In technologies like solar panels ( or even the “<a href="https://thedebrief.org/these-anti-solar-panels-dont-need-daylight-to-generate-power/">nighttime anti-solar panels</a>” <em>The Debrief</em> previously covered), a similar problem is overcome by combining a series of individual solar cells in a single circuit, resulting in a full panel of cells that can collect a larger amount of energy together. Unfortunately, this simply doesn’t work for individual raindrop power collection cells due to a phenomenon called “coupling capacitance” that occurs between the upper and lower electrodes of each cell. As a result, power loss is too great from cell to cell, making the idea of building a full-blown rain panel seemingly impossible.</p>
<p>Now, a team of researchers says they have found a design and configuration that greatly reduces the coupling capacitance issue and one they claim could make energy-harvesting rain panels a practical reality.</p>
<h2><strong>Building the Backbone for the World’s First Energy Collecting Rain Panels</strong></h2>
<p>“Although D-TENGs have ultra-high instantaneous output power, it is still difficult for a single D-TENG to continuously supply power for megawatt-level electrical equipment. Therefore, it is very important to realize the simultaneous utilization of multiple D-TENGs,” <a href="https://www.eurekalert.org/news-releases/996074">said</a> Zong Li, one of the authors of the proposed method and a professor at the Tsinghua Shenzhen International Graduate School. “Referring to the design of solar panels in which multiple solar power generation units are connected in parallel to supply the load, we are proposing a simple and effective method for raindrop energy harvesting.”</p>
<p>To make their system able to overcome the coupling capacitance issue, Li and his team proposed something called “bridge array generators” that use lower array electrodes to keep the cells operating separately while reducing the capacitance.</p>
<p><a href="https://ieeexplore.ieee.org/document/10185664">Published</a> in the journal iEnergy, the process seems promising, offering a new way to arrange individual cells into a series array that can collect and store the energy for practical uses.</p>
<figure id="attachment_18120" aria-describedby="caption-attachment-18120"><img decoding="async" src="https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-300x200.jpg" alt="rain panels" width="734" height="489" srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-300x200.jpg 300w, https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-360x240.jpg 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig.jpg 700w" sizes="(max-width: 734px) 100vw, 734px" data-srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-300x200.jpg 300w, https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-360x240.jpg 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig.jpg 700w" data-src="https://thedebrief.b-cdn.net/wp-content/uploads/2023/07/Low-Res_iEng-2023-0006-Fig-300x200.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-18120">This diagram shows what these D-TENG panels might look like. It also illustrates how the bridge structure, when combined with the lower electrodes, can lead to improved energy storage. CREDIT iEnergy, Tsinghua University Press</figcaption></figure>
<p>“When the droplet falls on the surface of the panel, called the FEP surface, the droplet becomes positively charged, and the FEP surface negatively charged,” explains the press release announcing the research. This charge, Li explains, is so small that after a period of time, it will begin to dissipate, leading to energy loss. However, by adding their new bridge array generators into the formula, they say they have overcome this issue.</p>
<p>“After a long time on the surface, the charges on the FEP surface will gradually accumulate to saturation,” said Li. “At this point, the dissipation rate of the FEP’s surface charge is balanced with the amount of charge generated by each impact of the droplet.”</p><div id="block-wrap-61189" data-id="61189">		<article>
					<p><a href="https://thedebrief.org/mysterious-georgia-guidestones-americas-stonehenge-vandalized-in-early-morning-explosion/">
				<img width="120" height="120" src="https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-120x120.jpg" alt="Georgia Guidestones" decoding="async" srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-120x120.jpg 120w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-150x150.jpg 150w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-70x70.jpg 70w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-240x240.jpg 240w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-360x360.jpg 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-540x540.jpg 540w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-720x720.jpg 720w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-125x125.jpg 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-120x120.jpg 120w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-150x150.jpg 150w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-70x70.jpg 70w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-240x240.jpg 240w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-360x360.jpg 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-540x540.jpg 540w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-720x720.jpg 720w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-125x125.jpg 125w" data-src="https://thedebrief.b-cdn.net/wp-content/uploads/2022/07/Georgia-Guidestones-120x120.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div>
<p>After their initial success, Li and the team tried different bridge array generators, different sizes of sub-electrodes and even experimented with varying the size of the panel itself. According to the researchers, increasing the thickness of the FEP surface “lead to decreased coupling capacitance while maintaining the surface charge density, both of which could improve the performance of the bridge array generator.”</p>
<h2><strong>Turning the Process into Practical Power Collection and Storage</strong></h2>
<p>Ultimately, the team says they zeroed in on what they think is the most optimal design to make rain panels a practical alternative or supplement to solar panels. Specifically, making the individual cells work independently and finding the right surface thickness seemed to reduce the coupling capacitance enough to make power collection from rain panels viable.</p>
<p>“The peak power output of the bridge array generators is nearly 5 times higher than that of the conventional large-area raindrop energy with the same size, reaching 200 watts per square meter,” Li explained, “which fully shows its advantages in large-area raindrop energy harvesting.”</p>
<p>“The results of this study will provide a feasible scheme for large-area raindrop energy harvesting,” he added.</p>
<p><strong><em>&nbsp;</em></strong><strong><em>Christopher Plain is a Science Fiction and Fantasy novelist and Head Science Writer at The Debrief. Follow and connect with him on <a href="https://twitter.com/plain_fiction">X</a>, learn about his books at <u><a href="https://plainfiction.com/">plainfiction.com</a></u>, or email him directly at <u><a href="mailto:christopher@thedebrief.org">christopher@thedebrief.org</a></u>. </em></strong></p>
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Worldcoin isn’t as bad as it sounds: It’s worse (455 pts)]]></title>
            <link>https://blockworks.co/news/worldcoin-privacy-concerns</link>
            <guid>36907248</guid>
            <pubDate>Fri, 28 Jul 2023 14:25:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blockworks.co/news/worldcoin-privacy-concerns">https://blockworks.co/news/worldcoin-privacy-concerns</a>, See on <a href="https://news.ycombinator.com/item?id=36907248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div>
<p>Worldcoin — a new financial system connected to sensitive biometric information,<a node="[object Object]" href="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/" target="_blank" rel="nofollow"> mostly harvested from poor people</a> — sure <em>sounds</em> like a terrible idea.</p>
<p>“Terrible” doesn’t do it justice.</p>
<p>Worldcoin will need to assemble a vast database of iris data. But not everyone is eager to gaze into an Orb. In the bootstrapping phase, at least, you had to pay people to scan their eyes. And so Worldcoin turned to the global south — home to the cheapest eyeballs — and played a dark game of ‘what will people do for money?’</p>
<p>Incredibly, <a node="[object Object]" href="https://www.theblock.co/post/237647/inside-sam-altmans-worldcoin-and-its-quest-to-catalog-all-humans" target="_blank" rel="nofollow">Worldcoin was unprepared</a> for an obvious consequence of this rollout strategy: A black market for verified credentials. You can now seemingly <a node="[object Object]" href="https://twitter.com/BlockBeatsAsia/status/1659060950748782594?s=20" target="_blank" rel="nofollow">buy a World ID</a> for as little as $30. Anyone, then, with more than $30 on hand can command more than one digital identity (although Worldcoin is <a node="[object Object]" href="https://gizmodo.com/worldcoin-black-market-iris-data-identity-orb-1850454037" target="_blank" rel="nofollow">aware of this issue</a> and has proposed solutions to resolve it). Connecting real people to digital identities is a thorny puzzle.&nbsp;</p>
<p>Worldcoin does not fix this. And it’s unlikely it ever can, since nothing in the design can stop professional sybil attackers farming eyeballs on the ground level through nefarious means.</p>
<p>This does not inspire trust in the system or its designers. And yet trust is what they demand. Worldcoin’s promotional materials are <a node="[object Object]" href="https://worldcoin.org/faqs#data-privacy-&amp;-security" target="_blank" rel="nofollow">full of promises</a> — to delete sensitive biometric information, or keep it hidden from view, or not use it in nefarious ways. One blog post (quoted <a node="[object Object]" href="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/" target="_blank" rel="nofollow">here</a>; the original appears to have been changed since initial release) put it this way: “During our field-testing phase, we are collecting and securely storing more data than we will upon its completion… We will delete all the biometric data we have collected during field testing once our algorithms are fully-trained.”</p>
<p>“Trust us,” in other words. “We’ll totally delete the eyeball database.”</p>
<p>But when it comes to sensitive information, promises aren’t enough. And the very people who insist that you trust them are the ones who should command the most suspicion. The fact that Worldcoin’s co-founder Sam Altman also heads up OpenAI — a firm currently <a node="[object Object]" href="https://www.theguardian.com/books/2023/jul/05/authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books" target="_blank" rel="nofollow">being sued</a> over allegations of dubious uses of large data sets — asks more questions than it answers.</p>
<p>Sometimes Worldcoin’s privacy promises are conjoined with dazzling technical details. Zero-knowledge proofs, we’re told, will save the day, and allow users to prove humanity without connecting any particular financial activity to a World ID or other associated transactions.</p>
<p>There’s a grain of truth here. Zero-knowledge proofs can generate impressive privacy guarantees. But in the case of Worldcoin marketing, they’re more theater than substance. Taking off your shoes at the airport makes it look like important precautions are being taken (but doesn’t actually make you any safer); and <a node="[object Object]" href="https://worldcoin.org/blog/developers/privacy-deep-dive" target="_blank" rel="nofollow">long blog posts about zero-knowledge proofs</a> distract from, but don’t in fact address, the problem of Worldcoin asking for users’ trust.</p>
<p>Linking immutable biometric traits to money could have dystopian consequences.</p>
<p>Imagine that your digital identity has been lost in some way — shut down by authorities for non-compliance, or otherwise blocked. With traditional cash — and other cryptocurrencies — you can always make a new wallet and stash some fresh coins in it. But this isn’t <em>Minority Report, </em>and you can’t get a new iris from your neighborhood surgeon.&nbsp;</p>
<p>When your immutable digital identity is locked — imagine merchants who won’t take your coins from you without a digital signature announcing your World ID — it’s over for you. No old account. No new account. No soup for you. You just lost your digital personhood.</p>
<p>Boosters might reply that, thanks to zero-knowledge proofs, one <em>could</em> prove that a given transaction is associated with a valid World ID without disclosing which World ID that is — thus reducing the risk of total identity blockade. But this reply misses the point.&nbsp;</p>
<p>Zero-knowledge proofs <em>could</em> be used in benign ways or to preserve user privacy. Or authorities could demand more; they could demand that users reveal all, or be locked out altogether. Setting up a system and simply hoping its full powers of surveillance and control won’t be used is naive, at best.</p>
<h2 id="dystopian-premise-dystopian-premine">Dystopian premise… dystopian premine?</h2>
<p>Worldcoin is billed as a network “<a node="[object Object]" href="https://worldcoin.org/cofounder-letter" target="_blank" rel="nofollow">owned by everyone</a>.” Early promotional materials claim giving “<a node="[object Object]" href="https://spectrum.ieee.org/worldcoin#toggle-gdpr" target="_blank" rel="nofollow">every person on the planet an equal share of a new cryptocurrency</a>” as a premise of the project. It sounds laudable. But a glance at the actual plan for distributing tokens casts doubt on whether equal distribution is an aim of the project at all, much less one it will achieve.</p>
<p>It’s a curious ‘world’ coin that <a href="https://blockworks.co/news/worldcoin-not-in-us">isn’t even available</a> in the <a node="[object Object]" href="https://www.bloomberg.com/news/articles/2022-03-16/worldcoin-the-eyeball-scanning-crypto-unicorn-hits-signup-snags" target="_blank" rel="nofollow">United States, Turkey, Sudan, or China</a>. And if equal distribution is a goal, allocating a significant chunk <a node="[object Object]" href="https://whitepaper.worldcoin.org/tokenomics" target="_blank" rel="nofollow">of all the tokens that will ever exist to insiders</a> is another curious choice. Early documentation put that insider number at twenty percent; it’s now slated to be at least twenty-five.&nbsp;</p>
<p>Who are these insiders? It’s some combination of Worldcoin developers and their partners, Orb operators (with signup bonuses that exhibit a <a node="[object Object]" href="https://twitter.com/zachxbt/status/1452065666824028160" target="_blank" rel="nofollow">pyramid-like structure</a>), and a <a node="[object Object]" href="https://venturebeat.com/consumer/worldcoin-launches-a-global-cryptocurrency-that-will-be-given-to-every-person-on-earth/" target="_blank" rel="nofollow">slate of (in)famous investors</a> including Sam Bankman-Fried and Three Arrows Capital. Such self-dealing is not the plan one would expect, to put the point mildly, from an operation with genuine egalitarian ambitions.</p>
<p><strong>Read more from our opinion section:</strong> <a href="https://blockworks.co/news/worldcoin-eyeballs-scan-brooklyn">Worldcoin hackable by cutting off someone’s face, draping it over your own</a></p>
<p>Now that Worldcoin has launched, we know a bit more about how token distribution will work. It is not entirely reassuring.</p>
<p>There’s a well-known crypto trick; they call it a “Sam Coin” (yes, after <a href="https://blockworks.co/tag/sam-bankman-fried">that Sam</a>). The idea is to release into circulation a very small percentage of all the tokens that will ever exist. Despite low liquidity and trading volume, some eye-popping fully diluted market cap numbers can result, which make for great marketing and creative accounting.</p>
<p>Worldcoin — much like MAPS, a <a node="[object Object]" href="https://twitter.com/DrNickA/status/1588132362847748096" target="_blank" rel="nofollow">notorious crypto dud</a> — <a node="[object Object]" href="https://twitter.com/DrNickA/status/1683404751164022786" target="_blank" rel="nofollow">is a Sam Coin</a>.</p>
<p>About one percent of the ten billion Worldcoin tokens that will ever exist are in circulation, <a node="[object Object]" href="https://www.coindesk.com/business/2023/07/24/worldcoin-release-tokenomics-report-geofenced-for-some-countries/" target="_blank" rel="nofollow">mostly in the hands of market makers partnered with Worldcoin</a>.&nbsp;</p>
<p>And yet Worldcoin’s fully diluted market cap, at the time of writing, is somewhere around twenty billion dollars. It’s a great setup to attract speculative retail investors. And those market maker insiders, furthermore, have a deal that guarantees them <a node="[object Object]" href="https://twitter.com/MomoOnChain/status/1683395484738527233" target="_blank" rel="nofollow">access to tokens at a fixed price</a>. Their profits are secure. The result is a market structure <a node="[object Object]" href="https://twitter.com/AriDavidPaul/status/1683627646633013249" target="_blank" rel="nofollow">primed for manipulation and pump and dump dynamics</a> — familiar to anyone who’s paid much attention to crypto.</p>
<p>Worldcoin is no radical new financial system, and certainly not one aimed at equality or fairness.&nbsp;</p>
<p>It’s just more of the same, but with extra data harvesting steps.</p>
<p>Do not look into the Orb.</p>
<hr>
<p>Andrew M. Bailey is Associate Professor at Yale-NUS College in Singapore and a Fellow at the Bitcoin Policy Institute.</p></div><section><span>Tags</span><ul><li><a href="https://blockworks.co/tag/privacy">Privacy</a></li><li><a href="https://blockworks.co/tag/worldcoin">Worldcoin</a></li></ul></section></div></div>]]></description>
        </item>
    </channel>
</rss>