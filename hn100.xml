<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 02 Mar 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[DeepSeek releases distributed DuckDB (237 pts)]]></title>
            <link>https://www.definite.app/blog/smallpond</link>
            <guid>43232410</guid>
            <pubDate>Sun, 02 Mar 2025 17:00:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.definite.app/blog/smallpond">https://www.definite.app/blog/smallpond</a>, See on <a href="https://news.ycombinator.com/item?id=43232410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>March 2, 2025</span><span>10 minute read</span></p><p>Mike Ritchie</p></div><div><p>I didn't have "DeepSeek releases distributed DuckDB" on my 2025 bingo card.</p>
<p>You may have stumbled across <a href="https://github.com/deepseek-ai/smallpond">smallpond</a> from Twitter/X/LinkedIn hype. From that hype, you might have concluded Databricks and Snowflake are dead 😂. Not so fast. The reality is, although this is interesting and powerful open source tech, it's unlikely to be widely used in analytics anytime soon. Here's a concise breakdown to help you cut through the noise.</p>
<p>We'll cover what <code>smallpond</code> and its companion, <code>3FS</code>, are, how you can (maybe) use them, and if they're suitable for your use case.</p>
<h3>What is <code>smallpond</code>?</h3>
<p><code>smallpond</code> is a lightweight, distributed data processing framework recently introduced by DeepSeek AI. It extends DuckDB—typically a high-performance, single-node analytics database—to handle larger datasets across multiple nodes. <code>smallpond</code> enables DuckDB to manage distributed workloads by using a distributed storage and compute system.</p>
<p>Key features:</p>
<ul>
<li><strong>Distributed Analytics</strong>: Allows DuckDB to handle larger-than-memory datasets by partitioning data and running analytics tasks in parallel.</li>
<li><strong>Open Source Deployment</strong>: If you can manage to get it running, 3FS would give you powerful and performant storage at a fraction of the cost of alternatives.</li>
<li><strong>Manual Partitioning</strong>: Data is manually partitioned by users, and <code>smallpond</code> distributes these partitions across nodes for parallel processing.</li>
</ul>
<h3>What is 3FS?</h3>
<p>3FS, or Fire-Flyer File System, is a high-performance parallel file system also developed by DeepSeek. It's optimized specifically for AI and HPC workloads, offering extremely high throughput and low latency by using SSDs and RDMA networking technology. Think of 3FS as the high-speed, distributed storage backend that <code>smallpond</code> leverages for fast, scalable analytics.</p>
<p>Key features:</p>
<ul>
<li><strong>High Performance</strong>: Achieves multi-terabyte-per-minute throughput, ideal for massive datasets.</li>
<li><strong>Optimized for AI workloads</strong>: Delivers consistent, high-speed data access, minimizing bottlenecks common in other storage systems.</li>
<li><strong>Open-source but Complex</strong>: Powerful yet requires specialized hardware and significant expertise to deploy effectively.</li>
</ul>
<h3>How Can I Use It?</h3>
<p>Using <code>smallpond</code> and 3FS depends largely on your data size and infrastructure:</p>
<ul>
<li><strong>Under 10TB</strong>: <code>smallpond</code> is likely unnecessary unless you have very specific distributed computing needs. A single-node DuckDB instance or simpler storage solutions will be simpler and possibly more performant.</li>
<li><strong>10TB to 1PB</strong>: <code>smallpond</code> begins to shine. You'd set up a cluster with several nodes, leveraging 3FS or another fast storage backend to achieve rapid parallel processing.</li>
<li><strong>Over 1PB (Petabyte-Scale)</strong>: <code>smallpond</code> and 3FS were explicitly designed to handle massive datasets. At this scale, you'd need to deploy a larger cluster with substantial infrastructure investments.</li>
</ul>
<p>Deployment typically involves:</p>
<ol>
<li>Setting up a compute cluster (AWS EC2, Google Compute Engine, or on-prem).</li>
<li>Deploying 3FS on nodes with high-performance SSDs and RDMA networking.</li>
<li>Installing <code>smallpond</code> via Python to run distributed DuckDB tasks across your cluster.</li>
</ol>
<p>Steps #1 and #3 are really easy. Step #2 is <strong>very</strong> hard. 3FS is new, so there's no guide on how you would set it up on AWS (if that's even possible). You could certainly deploy it on bare metal, but you'd be descending into a lower level of DevOps hell.</p>
<blockquote>
<p>Note: if you're in the 95% of companies in the under 10TB bucket, you should really try <a href="https://www.definite.app/">Definite</a>.</p>
</blockquote>
<p>I experimented with running <code>smallpond</code> with S3 swapped in for 3FS <a href="https://github.com/definite-app/smallpond">here</a>, but it's unclear what, if any, performance gains you'd get over scaling up a single node for moderate-sized data.</p>
<h3>Is <code>smallpond</code> for me?</h3>
<p><strong>tl;dr: probably not.</strong></p>
<p>Whether you'd want to use <code>smallpond</code> depends on several factors:</p>
<ul>
<li><strong>Your Data Scale</strong>: If your dataset is under 10TB, <code>smallpond</code> adds unnecessary complexity and overhead. For larger datasets (&gt;10TB), it provides substantial performance advantages.</li>
<li><strong>Infrastructure Capability</strong>: <code>smallpond</code> and 3FS require significant infrastructure and DevOps expertise. Without a dedicated team experienced in cluster management, this could be challenging.</li>
<li><strong>Analytical Complexity</strong>: <code>smallpond</code> excels at partition-level parallelism but is less optimized for complex distributed joins. For workloads requiring intricate joins across partitions, performance might be limited.</li>
</ul>
<h3>How Smallpond Works (Under the Hood)</h3>
<p><strong>Lazy DAG Execution</strong><br>
Smallpond uses lazy evaluation for operations like <code>map()</code>, <code>filter()</code>, and <code>partial_sql()</code>. It doesn't run these immediately. Instead, it builds a logical execution plan as a directed acyclic graph (DAG), where each operation becomes a node (e.g., <code>SqlEngineNode</code>, <code>HashPartitionNode</code>, <code>DataSourceNode</code>).</p>
<p>Nothing actually happens until you trigger execution explicitly with actions like:</p>
<ul>
<li><code>write_parquet()</code> — Writes data to disk</li>
<li><code>to_pandas()</code> — Converts results to a pandas DataFrame</li>
<li><code>compute()</code> — Forces computation explicitly</li>
<li><code>count()</code> — Counts rows</li>
<li><code>take()</code> — Retrieves a subset of rows</li>
</ul>
<p>This lazy evaluation is efficient because it avoids unnecessary computations and optimizes the workflow.</p>
<p><strong>From Logical to Execution Plan</strong><br>
When you finally trigger an action, the logical plan becomes an execution plan made of specific tasks (e.g., <code>SqlEngineTask</code>, <code>HashPartitionTask</code>). These tasks are the actual work units distributed and executed by Ray.</p>
<p><strong>Ray Core and Distribution</strong><br>
Smallpond’s distribution leverages Ray Core at the Python level, using partitions for scalability. Partitioning can be done manually, and Smallpond supports:</p>
<ul>
<li><strong>Hash partitioning</strong> (based on column values)</li>
<li><strong>Even partitioning</strong> (by files or row counts)</li>
<li><strong>Random shuffle partitioning</strong></li>
</ul>
<p>Each partition runs independently within its own Ray task, using DuckDB instances to process SQL queries. This tight integration with Ray emphasizes horizontal scaling (adding more nodes) rather than vertical scaling (larger, more powerful nodes). To use it at scale, you’ll need a Ray cluster. You can run one on your own infrastructure on a cloud provider (e.g. AWS), but if you just want to test this out, it'll be easier to get started with Anyscale (founded by Ray creators).</p>
<h3>Conclusion</h3>
<p><code>smallpond</code> and 3FS offer powerful capabilities for scaling DuckDB analytics across large datasets. However, their complexity and infrastructure demands mean they're best suited for scenarios where simpler solutions no longer suffice. If you're managing massive datasets and already have robust DevOps support, <code>smallpond</code> and 3FS could significantly enhance your analytics capabilities. For simpler scenarios, sticking with a single-node DuckDB instance or using managed solutions remains your best option.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lifestyle of out of touch execs who are pushing return to office (450 pts)]]></title>
            <link>https://twitter.com/EthanEvansVP/status/1895845734177452369</link>
            <guid>43232255</guid>
            <pubDate>Sun, 02 Mar 2025 16:47:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/EthanEvansVP/status/1895845734177452369">https://twitter.com/EthanEvansVP/status/1895845734177452369</a>, See on <a href="https://news.ycombinator.com/item?id=43232255">Hacker News</a></p>
Couldn't get https://twitter.com/EthanEvansVP/status/1895845734177452369: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Mark Cuban offers to fund 18f (326 pts)]]></title>
            <link>https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/</link>
            <guid>43231062</guid>
            <pubDate>Sun, 02 Mar 2025 14:58:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/">https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/</a>, See on <a href="https://news.ycombinator.com/item?id=43231062">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Billionaire investor Mark Cuban waded into the latest government tech shake-up on Saturday, posting an unexpected offer of support for newly laid-off federal workers on the social network Bluesky.</p>

<p><br>His <a rel="nofollow" href="https://bsky.app/profile/mcuban.bsky.social/post/3lje6uqhmdc2w">message</a>, which quickly gained traction, urged the displaced engineers and designers to turn the upheaval to their advantage.</p>







<p><br>“If you worked for 18F and got fired, Group together to start a consulting company,” wrote Cuban. “It’s just a matter of time before DOGE needs you to fix the mess they inevitably created. They will have to hire your company as a contractor to fix it. But on your terms. I’m happy to invest and/or help.”</p>

<p><br>Cuban’s offer came after the government’s General Services Administration (GSA) abruptly gutted its 18F technology unit, which helps other government agencies build, buy, and share tech products. <a rel="nofollow" href="https://www.politico.com/news/2025/03/01/general-services-administration-cuts-tech-unit-00206860">Per Politico</a>, the layoffs affected roughly 70 individuals who learned the news around 1 a.m. Eastern time on Saturday. Among other things, the unit had reportedly built Login.gov, a secure and private way for the public to access services at government agencies, including Social Security and the Department of Veterans Affairs.</p>

<p><br>The early-morning layoffs tie to a Trump administration directive to shrink the federal workforce and slash spending at the behest of Elon Musk’s Department of Government Efficiency (DOGE). The cuts weren’t a first for 18F; according to Politico, two dozen more 18F employees were laid off in February when GSA cut probationary staffers.</p>

<p><br>Those impacted in the wee hours of Saturday morning <a rel="nofollow" href="https://www.politico.com/news/2025/02/28/federal-workers-told-once-again-to-justify-their-work-to-doge-00206853">also received</a> emails late Friday from DOGE with the subject line, “What did you do last week? Part II.”</p>

<p><br>According to Politico, the emails — prompting employees to list their weekly accomplishments by Monday — were widely distributed across multiple agencies, including the State Department, the IRS, and the NIH.</p>


<p><br>In the wake of these new layoffs, Cuban’s proposal presents an intriguing possibility: could the very workers pushed out of government help reshape the future of civic tech on their own terms? As DOGE moves to dismantle agencies, even Musk has acknowledged fallout tied to the speed with which his team is moving. On Wednesday, Musk shared that, “For example, with USAID, one of the things we <a rel="nofollow" href="https://www.nytimes.com/2025/02/27/health/musk-ebola-funding.html">accidentally canceled</a> — very briefly — was Ebola prevention.” (Public health experts have since said the government’s support has <a rel="nofollow" href="https://www.npr.org/sections/goats-and-soda/2025/02/27/g-s1-50929/elon-musk-ebola-usaid">not been fully restored</a>.)</p>

<p><br>The question now is whether some percentage of the government’s growing number of displaced former employees will seize the moment, banding together to build the startups that could one day sell their expertise back to the government. If so, it would represent a striking twist in the administration’s efforts to shrink the public workforce.</p>

<p><br>If Cuban has his way, at least one such unit may find itself inside a private company the government has no choice but to rely on. Another Bluesky user even had a branding idea for the startup, <a rel="nofollow" href="https://bsky.app/profile/qew2.bsky.social/post/3ljebrzhnwk2q">telling Cuban</a>, “Name the new company 18FU.”</p>
</div><div>
	
	
	
	

	
<div>
	<p>Loizos has been reporting on Silicon Valley since the late ’90s, when she joined the original Red Herring magazine. Previously the Silicon Valley Editor of TechCrunch, she was named Editor in Chief and General Manager of TechCrunch in September 2023. She’s also the founder of StrictlyVC, a daily e-newsletter and lecture series acquired by Yahoo in August 2023 and now operated as a sub brand of TechCrunch.</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/connie-loizos/" data-event="button" href="https://techcrunch.com/author/connie-loizos/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a modern Goodreads alternative (193 pts)]]></title>
            <link>https://kaguya.io/</link>
            <guid>43230994</guid>
            <pubDate>Sun, 02 Mar 2025 14:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kaguya.io/">https://kaguya.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43230994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sentry-component="MaxWidthWrapper" data-sentry-source-file="MaxWidthWrapper.tsx"><div data-sentry-component="ReviewCarousel" data-sentry-source-file="ReviewCarousel.tsx"><p data-sentry-component="ReviewCarouselHeader" data-sentry-source-file="ReviewCarousel.tsx"><h3>Recently Reviewed on Kaguya</h3></p><div><div><a href="https://kaguya.io/books/the-hundred-thousand-kingdoms/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-brightest-shadow/reviews/buu"></a></div><div><a href="https://kaguya.io/books/changing-faces-1/reviews/buu"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>Changing Faces</p><p>-<!-- --> <!-- -->Sarah Lin</p></div></a></div><div><a href="https://kaguya.io/books/metropolitan/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-praxis/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-rift-1/reviews/synedocheny"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>The Rift</p><p>-<!-- --> <!-- -->Walter Jon Williams</p></div></a></div><div><a href="https://kaguya.io/books/pandemic-6/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-knight/reviews/synedocheny"></a></div></div><div><div><a href="https://kaguya.io/books/the-hundred-thousand-kingdoms/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-brightest-shadow/reviews/buu"></a></div><div><a href="https://kaguya.io/books/changing-faces-1/reviews/buu"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>Changing Faces</p><p>-<!-- --> <!-- -->Sarah Lin</p></div></a></div><div><a href="https://kaguya.io/books/metropolitan/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-praxis/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-rift-1/reviews/synedocheny"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>The Rift</p><p>-<!-- --> <!-- -->Walter Jon Williams</p></div></a></div><div><a href="https://kaguya.io/books/pandemic-6/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-knight/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/misquoting-muhammad-the-challenge-and-choices/reviews/nico"></a></div></div></div><section data-sentry-component="Features" data-sentry-source-file="Features.tsx"><h4>Kaguya lets you...</h4><div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><h3>Write Reviews</h3><p>Share your thoughts and insights by writing detailed reviews.</p></div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><h3>Rate Books</h3><p>Express your opinions by rating each book on a ten-star scale. </p></div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><p><img alt="feature icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" src="https://kaguya.io/icons/features/streamline_shelf-solid.svg"></p><div><h3>Organize Shelves</h3><p>Arrange your books with custom shelves to easily manage your library.</p></div></div></div></section><section><!--$?--><template id="B:0"></template><!--/$--><div data-sentry-component="Top10Books" data-sentry-source-file="Top10Books.tsx"><p><h3>Popular Books This Week</h3></p><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-martian"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>01</span></p><div><p><span>01</span></p><p><h4>The Martian</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/harry-potter-and-the-sorcerers-stone"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>02</span></p><div><p><span>02</span></p><p><h4>Harry Potter and the Sorcerer'...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/ready-player-one"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>03</span></p><div><p><span>03</span></p><p><h4>Ready Player One</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/1984"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>04</span></p><div><p><span>04</span></p><p><h4>1984</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>05</span></p><div><p><span>05</span></p><p><h4>Sapiens: A Brief History of Hu...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-three-body-problem"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>06</span></p><div><p><span>06</span></p><p><h4>The Three-Body Problem</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-hunger-games"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>07</span></p><div><p><span>07</span></p><p><h4>The Hunger Games</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/harry-potter-and-the-goblet-of-fire"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>08</span></p><div><p><span>08</span></p><p><h4>Harry Potter and the Goblet of...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/neuromancer"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>09</span></p><div><p><span>09</span></p><p><h4>Neuromancer</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/why-we-sleep-unlocking-the-power-of-sleep-and"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>10</span></p><div><p><span>10</span></p><p><h4>Why We Sleep: Unlocking the Po...</h4></p></div></div></a></div></div></section><div data-sentry-component="BookCarousel" data-sentry-source-file="BookCarousel.tsx"><div data-sentry-component="BookCarouselHeader" data-sentry-source-file="BookCarouselHeader.tsx"><p><a href="https://kaguya.io/list/popular">Top 100 Rated Books</a></p><a href="https://kaguya.io/list/popular"><span>See More</span><span>See All</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 320 512" height="12" width="12" xmlns="http://www.w3.org/2000/svg"><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"></path></svg></a></div><div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-martian"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-hobbit-or-there-and-back-again"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-fellowship-of-the-ring"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-clash-of-kings"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-game-of-thrones"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/red-rising"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/enders-game"></a></div></div><div data-sentry-element="Carousel" data-sentry-source-file="MobileCarousel.tsx" role="region" aria-roledescription="carousel" data-sentry-component="MobileCarousel"><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-martian"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-hobbit-or-there-and-back-again"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-fellowship-of-the-ring"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-clash-of-kings"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-game-of-thrones"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/red-rising"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/enders-game"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-storm-of-swords"></a></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4.5: "Not a frontier model"? (125 pts)]]></title>
            <link>https://www.interconnects.ai/p/gpt-45-not-a-frontier-model</link>
            <guid>43230965</guid>
            <pubDate>Sun, 02 Mar 2025 14:47:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model">https://www.interconnects.ai/p/gpt-45-not-a-frontier-model</a>, See on <a href="https://news.ycombinator.com/item?id=43230965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>As GPT-4.5 was being released, the first material the public got access to was OpenAI’s system card for the model that details some capability evaluations and mostly safety estimates. Before the </span><a href="https://www.youtube.com/watch?v=cfRYp0nItZ8" rel="">live stream</a><span> and official blog post, we knew things were going to be weird because of this line:</span></p><blockquote><p>GPT-4.5 is not a frontier model.</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png" width="1271" height="699" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:699,&quot;width&quot;:1271,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85687,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The </span><a href="https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf" rel="">updated system card</a><span> in the </span><a href="https://openai.com/index/introducing-gpt-4-5/" rel="">launch blog post</a><span> does not have this. Here’s the original system card if you need a reference:</span></p><p>Regardless, someone at OpenAI felt the need to put that in. The peculiarity here summarizes a lot of the release. Some questions are still really not answered, like “Why did OpenAI release this?” That game theory is not in my purview. </p><p><span>The main contradiction to the claims that it isn’t a frontier model is that </span><strong>this is the biggest model the general public has ever gotten to test</strong><span>. Scaling to this size of model did NOT make a clear jump in capabilities we are measuring. To summarize the arc of history, the jump from GPT-3.5 to GPT-4 made the experience with the models go from okay to good. The jump from GPT-4o (where we are now) to GPT-4.5 made the models go from great to really great.</span></p><p>Feeling out the differences in the latest models is so hard that many who are deeply invested and excited by AI’s progress are just as likely to lie to themselves about the model being better as they are to perceive real, substantive improvements. In this vein, I almost feel like I need to issue a mea culpa. I expected this round of scaling’s impacts to still be obvious before the brutal economic trade-offs of scaling kicked in. </p><p data-attrs="{&quot;url&quot;:&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>While we got this model, Anthropic has also unintentionally confirmed that their next models will be trained on an approximation of “10X the compute,” via a correction on </span></p><p><span>’s </span><a href="https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37" rel="">post on Claude 3.7</a><span>.</span></p><blockquote><p>Note: After publishing this piece, I was contacted by Anthropic who told me that Sonnet 3.7 would not be considered a 10^26 FLOP model and cost a few tens of millions of dollars to train, though future models will be much bigger.</p></blockquote><p><span>GPT-4.5 is a point on the graph that scaling is still coming, but trying to make sense of it in a day-by-day transition is hard. In many ways, zooming out, GPT-4.5 will be referred to in the same breath as </span><a href="https://www.interconnects.ai/p/reverse-engineering-openai-o1" rel="">o1</a><span>, </span><a href="https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai" rel="">o3</a><span>, and </span><a href="https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1" rel="">R1</a><span>, where it was clear that scaling pretraining alone was not going to give us the same level of breakthroughs. Now we really know </span><a href="https://www.latent.space/p/what-ilya-saw" rel="">what Ilya saw</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg" width="1200" height="900" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:900,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Shane Gu on X: \&quot;\&quot;Pre-training as we know it will end\&quot;. See my slide on  \&quot;online learning\&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Shane Gu on X: &quot;&quot;Pre-training as we know it will end&quot;. See my slide on  &quot;online learning&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start." title="Shane Gu on X: &quot;&quot;Pre-training as we know it will end&quot;. See my slide on  &quot;online learning&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>All of this marks GPT-4.5 as an important moment in time for AI to round out other stories we’ve been seeing. GPT-4.5 likely finished training a long time ago — highlighted by how it has a date cutoff in 2023 still — and OpenAI has been using it internally to help train other models, but didn’t see much of a need to release it publicly.</p><p><em>In the following,</em><span> </span><em><span>I am going to make some estimates on the parameter counts of GPT-4.5 and GPT-4o. These are not based on any leaked information and should be taken with big error bars, but they are very useful for context</span><strong>.</strong></em></p><p><span>GPT-4.5 is a very big model. I’d bet it is well bigger than </span><a href="https://www.interconnects.ai/p/grok-3-and-an-accelerating-ai-roadmap" rel="">Grok 3</a><span>. We have seen this story before. For example, GPT-4 </span><a href="https://semianalysis.com/2023/07/10/gpt-4-architecture-infrastructure/" rel="">was roughly known to be a very big mixture of experts model with over 1T parameters total</a><span> and ~200B active parameters. Since then, rumors have placed the active parameters of models like GPT-4o or Gemini Pro at as low as 60B parameters. This type of reduction, along with infrastructure improvements, accounts for massive improvements in speed and price.</span></p><p>Estimates place GPT-4.5 as about an order of magnitude more compute than GPT-4. These are not based on any released numbers, but given a combination of a bigger dataset and parameters (5X parameters + 2X dataset size = 10X compute), the model could be in in the ballpark of 5-7T parameters total, which if it had a similar sparsity factor to GPT-4 would be ~600B active parameters. </p><p>With all of these new parameters, actually seeing performance improvements is hard. This is where things got very odd. The two “capabilities” OpenAI highlighted in the release are:</p><ol><li><p>Reduced hallucinations.</p></li><li><p>Improved emotional intelligence.</p></li></ol><p>Both of these have value but are hard to vibe test. </p><p><span>For example, </span><a href="https://openai.com/index/introducing-simpleqa/" rel="">SimpleQA</a><span> is a benchmark we at Ai2 are excited to add to our post-training evaluation suite to improve world knowledge of our models. OpenAI made and released this evaluation publicly. GPT-4.5 makes huge improvements here.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png" width="1301" height="541" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:541,&quot;width&quot;:1301,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:47370,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In another one of OpenAI’s evaluations, PersonQA, which is questions regarding individuals, the model is also state of the art. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png" width="880" height="165" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:165,&quot;width&quot;:880,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:24190,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And finally, also GPQA, the Google-proof knowledge evaluation that reasoning models actually excel at.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png" width="1111" height="528" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/df28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:528,&quot;width&quot;:1111,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:54872,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>At the time of release, many prominent AI figures online were touting how GPT-4.5 is much nicer to use and better at writing. These takes should be taken in the context of your own testing. It’s not that simple. GPT-4.5 is also being measured as </span><a href="https://x.com/paulgauthier/status/1895221869844013108" rel="">middle of the pack</a><span> in most code and technical evaluations relative to Claude 3.7, R1, and the likes.</span></p><p><span>For an example on the writing and style side, Karpathy ran some </span><a href="https://x.com/karpathy/status/1895337579589079434" rel="">polls comparing GPT-4.5’s writing to GPT-4o-latest</a><span>, and </span><strong>most people preferred the smaller, older model</strong><span>. Given what we know about post-training and the prevalence of distilling from the most powerful model you have access to, it is likely that GPT-4o-latest is distilled from this new model, previously called Orion</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-158107244" href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model#footnote-1-158107244" target="_self" rel="">1</a></span><span>, and its drastically smaller size gives it a night and day difference on iteration speed, allowing for better post-training.</span></p><p>More on the character in that GPT-4o-latest model was covered in our previous post on character training.</p><div data-component-name="DigestPostEmbed"><a href="https://www.interconnects.ai/p/character-training" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6abd9e2-beb0-4959-a8ba-452577b30c10_1357x758.webp"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6abd9e2-beb0-4959-a8ba-452577b30c10_1357x758.webp" sizes="100vw" alt="Character training: Understanding and crafting a language model's personality" width="140" height="140"></picture></div></a></div><p>All of this is a big price to pay to help OpenAI reclaim their top spot on ChatBotArena — I expect GPT 4.5 to do this, but the results are not out yet.</p><p>I’ve been using GPT-4.5 in preparation for this. It took a second to get used to the slower speed, but it’s fine. I will keep using it for reliability, but it’s not worth paying more for. o1 Pro and the other paid offerings from OpenAI offer far more value than GPT-4.5.</p><p><span>When the original GPT-4 first launched, it was extremely expensive. In fact, </span><strong>GPT-4 was comparable in price to GPT-4.5 at launch</strong><span>. Here’s a </span><a href="https://help.openai.com/en/articles/7127956-how-much-does-gpt-4-cost" rel="">help post on the OpenAI forums</a><span>, </span><s>conveniently found by OpenAI DeepResearch with GPT-4.5</s><span> EDIT: DeepResearch always uses o3, the UX is a lie, that captures the context. GPT-4 launched in March 2023.</span></p><blockquote><p><span>We are excited to announce GPT-4 has </span><a href="https://openai.com/pricing" rel="">a new pricing model</a><span>, in which we have reduced the price of the prompt tokens.</span></p><p><span>For our models with </span><strong>128k</strong><span> context lengths (e.g. </span><code>gpt-4-turbo</code><span>), the price is:</span></p><ul><li><p>$10.00 / 1 million prompt tokens (or $0.01 / 1K prompt tokens)</p></li><li><p>$30.00 / 1 million sampled tokens (or $0.03 / 1K sampled tokens)</p></li></ul><p><span>For our models with </span><strong>8k</strong><span> context lengths (e.g. </span><code>gpt-4</code><span> and </span><code>gpt-4-0314</code><span>), the price is:</span></p><ul><li><p>$30.00 / 1 million prompt token (or $0.03 / 1K prompt tokens)</p></li><li><p>$60.00 / 1 million sampled tokens (or $0.06 / 1K sampled tokens)</p></li></ul><p><span>For our models with </span><strong>32k</strong><span> context lengths (e.g. </span><code>gpt-4-32k</code><span> and </span><code>gpt-4-32k-0314</code><span>), the price is:</span></p><ul><li><p>$60.00 / 1 million prompt tokens (or $0.06 / 1K prompt tokens)</p></li><li><p>$120.00 / 1 million sampled tokens (or $0.12 / 1K sampled tokens)</p></li></ul></blockquote><p><strong>GPT-4.5’s pricing</strong><span> launched at: </span></p><blockquote><p><span>Input:</span><br><span>$75.00 / 1M tokens</span></p><p><span>Cached input:</span><br><span>$37.50 / 1M tokens</span></p><p><span>Output:</span><br><span>$150.00 / 1M tokens</span></p></blockquote><p>OpenAI included language in the release that they may not keep this model in the API, likely forecasting low demand, as they wanted to hear from users if it enabled entirely new use-cases. </p><p>Many analysts think that Nvidia’s next generation of GPU, Blackwell, which comes with GPUs with far more memory per FLOP (enabling storing bigger models), are not priced into this. We can expect to see the same arc of pricing with 4.5 as we did with 4 to 4 Turbo to 4o. </p><ul><li><p>GPT-4 Turbo launched in November 2023 at $10 / 1M input and $30 / 1M output.</p></li><li><p>GPT-4o launched in May 2024 at $2.5 / 1M input and $10 / 1M output.</p></li></ul><p>These are huge reductions, about 10X.</p><p>These are products that OpenAI makes a healthy margin on, and there are no signs that that isn’t the case. The AI community collectively has grown so accustomed to incredible progress in making the technology more efficient that even a blip in the process, where bigger models are available, feels potentially bubble-popping.</p><p><a href="https://www.interconnects.ai/t/scaling" rel="">Scaling</a><span> language models is not dead. Still, reflecting on why this release felt so weird is crucial to staying sane in the arc of AI’s progress. We’ve entered the era where trade-offs among different types of scaling are real.</span></p><p>If forced to summarize all of this curtly, it would be: GPT-4.5 is, oddly, ahead of its time. </p><p><span>This means that the progression of AI needs to take a different tack, but we already knew this with the rapid progress of reasoning models. The true impact of GPT-4.5 is when it is integrated with </span><em>multiple</em><span> lines of rapid progress. </span></p><p>One of the flagship results in the DeepSeek R1 paper and related RL follow-up work in the AI community is that scaling RL training works better on bigger models. There is a lot of work to do to know all the domains that’ll be absorbed into this umbrella. Future models like o4 could be distilled from a reasoning model trained on GPT-4.5. In fact, this may already be the case. OpenAI’s current models likely would not be so good without GPT-4.5 existing.</p><p>In as soon as a year, most of the models we are working with will be GPT-4.5 scale and they will be fast. The “well-rounded” improvements they offer are going to help make many more applications more robust, but OpenAI and others in the AI labs have pushed scaling a bit further than the current serving infrastructure can support.</p><p>Frontier labs are not taking enough risk if they’re not going to try to push the limits of every direction of scaling they have. Though releasing the model isn’t needed, we have to guess why OpenAI actually wanted to do this. It’s likely that GPT-4.5 is being used in other internal systems for now and other external products soon, so releasing it is a natural step on the way to the next thing, rather than a detour.</p><p>GPT-4.5 is a frontier model, but its release is not an exciting one. AI progress isn’t free, and it takes a lot of hard work. Most people should only care when GPT-4.5 is integrated into more than just chat.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla flamed by Firefox fans after reneging on promises to not sell their data (283 pts)]]></title>
            <link>https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/</link>
            <guid>43229668</guid>
            <pubDate>Sun, 02 Mar 2025 12:13:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/">https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/</a>, See on <a href="https://news.ycombinator.com/item?id=43229668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Mozilla this week asked Firefox users to abide by new Terms of Use, and updated its Privacy Notice as well as an FAQ – only to quickly issue a clarification that it isn’t actually claiming ownership of user data.</p>
<p>Mind you, the language of the <a target="_blank" rel="nofollow" href="https://www.mozilla.org/about/legal/terms/firefox/">Terms of Use</a> document <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250226211527/https://www.mozilla.org/en-US/about/legal/terms/firefox/">initially suggested</a> as much:</p>

<p>But Mozilla subsequently removed those terms, and insisted it was just necessary boilerplate.</p>
<p>“On Wednesday we shared that we’re introducing a new Terms of Use (TOU) and Privacy Notice for Firefox,” said Ajit Varma, veep of Firefox Product, on Friday in <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/products/firefox/update-on-terms-of-use/#:~:text=TL%3BDR%20Mozilla%20doesn't,would%20usually%20understand%20that%20word.">an update</a> to the open source browser maker's initial <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/products/firefox/firefox-terms-of-use/">announcement</a> of the new terms.</p>
<blockquote>

<p>Our intent was just to be as clear as possible about how we make Firefox work</p>
</blockquote>
<p>“Since then, we’ve been listening to some of our community’s concerns with parts of the TOU, specifically about licensing. Our intent was just to be as clear as possible about how we make Firefox work, but in doing so we also created some confusion and concern.”</p>
<p>Varma said its contractual language has been updated in an effort to assuage concerns. For one thing, it now states "this does not give Mozilla any ownership" of the data you put into Firefox to use it.</p>
<p>While much of the confusion can be written off as an unforced error in communication – legalese is often misunderstood – the developer's privacy commitment has changed, in its wording at least. The answer to "what is Firefox?" on Mozilla's FAQ page about its browser <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250130092351/https://www.mozilla.org/en-US/firefox/faq/">used to read</a>:</p>

<p>Now it <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/firefox/faq/">just says</a>:</p>

<p>In other words, Mozilla is no longer willing to commit to not selling your personal data to advertisers.</p>
<p>A related change was also <a href="https://connect.mozilla.org/t5/discussions/information-about-the-new-terms-of-use-and-updated-privacy/m-p/87949/highlight/true#M33725" rel="nofollow">highlighted</a> by mozilla.org commenter jkaelin, who linked direct to the <a target="_blank" rel="nofollow" href="https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/faq.html">source code</a> for that FAQ page. To answer the question, "is Firefox free?" Moz used to say:</p>

<p>Now it simply reads:</p>

<p>Again, a pledge to not sell people's data has disappeared. Varma insisted this is the result of the fluid definition of “sell” in the context of data sharing and privacy.</p>
<p>“Mozilla doesn’t sell data about you (in the way that most people think about ‘selling data’), and we don’t buy data about you,” he said. “We changed our language because some jurisdictions define ‘sell’ more broadly than most people would usually understand that word.”</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/13/mozillas_firefox_browser/">Mozilla's Firefox browser turns 20. Does it still matter?</a></li>

<li><a href="https://www.theregister.com/2024/09/25/mozilla_noyb_privacy_complaint/">Campaigners claim 'Privacy Preserving Attribution' in Firefox does the opposite</a></li>

<li><a href="https://www.theregister.com/2024/06/21/firefox_127_private_window/">Privacy features lose their way in latest Firefox update</a></li>

<li><a href="https://www.theregister.com/2024/12/12/firefox_do_not_track/">Firefox ditches Do Not Track because nobody was listening anyway</a></li>

<li><a href="https://www.theregister.com/2024/09/02/zen_firefox_fork_alpha/">Zen Browser is a no-Google zone that offers tiling nirvana</a></li>
</ul>
<p>Though the TOU – and its connected <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/privacy/firefox/">privacy policy</a> and <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/about/legal/acceptable-use/">acceptable use rules</a> – are written in clear, plain English, are short and readable, and in our opinion contain no huge surprises, Mozilla's earlier choice of wording sparked a backlash on <a href="https://connect.mozilla.org/t5/discussions/information-about-the-new-terms-of-use-and-updated-privacy/m-p/87735#M33600" rel="nofollow">its own</a> forums, as well as <a href="https://www.reddit.com/r/firefox/comments/1iyuvjf/introducing_a_terms_of_use_and_updated_privacy/" rel="nofollow">on Reddit</a> and other places.</p>
<p>Following that outcry, Varma's announcement on Wednesday about the new fine print was updated to include this disclaimer:</p>

<p>One might argue the new terms are the result of a December management shakeup. That month it was <a href="https://blog.mozilla.org/en/mozilla/new-executives/" rel="nofollow">announced</a> three executives were joining Mozilla, including Varma, the author of the above announcements, as a Firefox veep after previously looking after WhatsApp for Meta, and before that, Gmail, and its related tools for Google. The other two were Anthony Enzor-DeMeo, senior veep of Firefox, who previously held top roles at Wayfair, Better, and Roofstock; and Girish Rao, SVP of infrastructure, who was previously at Warner Bros Discovery, EA, Cisco, and Equinix.</p>
<p>Then in early February, Mozilla <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/mozilla/leadership/peter-rojas-svp-new-products/">gained</a> Peter Rojas as a senior veep of new products; he has an interesting history spanning from co-founding Engadget to holding senior roles at Meta and AOL to investing in AI model warehouse Hugging Face and others.</p>

    

<p>These high-level appointments were announced by Laura Chambers, who <a href="https://www.theregister.com/2024/02/09/mozilla_ceo_mitchell_baker_departs/">hopped aboard</a> as CEO a year ago; the hiring came the month after <a href="https://www.theregister.com/2024/11/06/mozilla_foundation_layoffs/">deep staffing cuts</a> at the Mozilla Foundation – the non-profit that overseas the Mozilla Corporation that develops Firefox and other things.</p>
<h3>Competition</h3>
<p>Sadly, it looks like the <a href="https://www.jwz.org/blog/2024/10/mozillas-ceo-doubles-down-on-them-being-an-advertising-company-now/" rel="nofollow">assessment</a> of Moz by former Netscape coder Jamie Zawinski was not far off the mark. He also links to his own earlier criticisms, none of which we can really fault.</p>
<p>This seems like a good time to remind readers that there are other browsers out there based on the Firefox codebase, including <a href="https://www.theregister.com/2021/11/04/waterfox_firefox_fork/">our own go-to Waterfox</a>, as well as the <a href="https://www.theregister.com/2024/09/02/zen_firefox_fork_alpha/">tiling Zen browser</a> which has now reached beta.</p>

        

<p>Others that happen not to press our buttons quite so much, but may appeal more to you, include the security-centric <a href="https://librewolf.net/" rel="nofollow">LibreWolf</a> and the customization-heavy <a href="https://floorp.app/en" rel="nofollow">Floorp</a>. Other projects showing less recent activity are <a href="https://pulsebrowser.app/" rel="nofollow">Pulse</a> and <a href="https://thorium.rocks/mercury" rel="nofollow">Mercury</a>. Still in active development, but based on older versions of the Firefox codebase, are <a href="https://www.palemoon.org/" rel="nofollow">PaleMoon</a> and <a href="https://www.basilisk-browser.org/" rel="nofollow">Basilisk</a>.</p>
<p>Most venerable of all is the continuing fork of the original all-in-one Netscape suite, <a href="https://www.seamonkey-project.org/" rel="nofollow">Seamonkey</a>. We're sad to note that its release engineer William Andrew Gianopoulos <a href="https://www.chesmorefuneralhome.com/obituaries/william-andrew-gianopoulos/20284/" rel="nofollow">died</a> in January.</p>

        

<p>Whether or not one agrees with the outrage over the TOU changes, the fact remains that <a target="_blank" href="https://www.theregister.com/2024/06/18/mozilla_buys_anonym_betting_privacy/">Mozilla is now</a> in the <a target="_blank" rel="nofollow" href="https://www.anonymco.com/">advertising business</a>. Use that information as you wish. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[German tourist held indefinitely in San Diego area immigrant detention facility (114 pts)]]></title>
            <link>https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility</link>
            <guid>43229475</guid>
            <pubDate>Sun, 02 Mar 2025 11:48:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility">https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility</a>, See on <a href="https://news.ycombinator.com/item?id=43229475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>It was meant to be a perfect reunion.</p><p>Amelia Lofving, a designer, had just moved to Los Angeles. Her friend Jessica Brösche, a tattoo artist from Germany, was spending the winter in Mexico.</p><p>The two planned to meet up in Tijuana, cross the border, and head to LA.</p><p>“We were going to have a month of just making art,” said the 37-year-old Lofving. “That was our plan.”</p><p>Brösche, 26, never made it to LA. She’s been in federal immigration custody since Jan. 25 — the day they tried to cross into the United States through the San Ysidro Port of Entry.</p><p>Brösche had her German passport, confirmation of her visa waiver to enter the country, along with a copy of her return ticket back to Berlin, Lofving said. A U.S. Customs and Border Protection (CBP) agent pulled Brösche aside for a secondary inspection.</p><p>“I look at her and go, ‘I’m going to wait right outside for you,’” Lofving recalled.</p><p>She didn’t know it then, but it would be 25 days before Lofving would see her friend again. Brösche would spend that time in federal detention, where she remains, waiting for a deportation flight back to Berlin.</p><h3>‘I can’t find Jessica’</h3><p>CBP agents at the border accused Brösche of planning to violate the terms of the <a href="https://esta.cbp.dhs.gov/esta" target="_blank" data-cms-ai="0">visa waiver program</a> by intending to work as a tattoo artist during her trip to LA, Lofving said.</p><p>KPBS independently confirmed that Brösche is in federal custody. CBP declined to comment on the specifics of the case, citing privacy concerns.</p><p>Lofving said a CBP agent told her Brösche would be deported back to Germany in a few days. “She’s like, ‘Jessica is going to call you in a couple of days from Germany,’” she said.</p><p>Lofving waited two days. No calls from Germany. She waited a week. Still no contact with Brösche.</p><p>Mutual friends also hadn’t heard from her. People started to freak out, Lofving said. No one knew where Brösche was.</p><p>“I’m a dumb artist, I don’t know what to do in these situations,” Lofving said. “I posted something online, ‘hey guys, help me out. I can’t find Jessica.’”</p><p>The posts generated hundreds of views. And some people answered the call.</p><p>Using the federal <a href="https://locator.ice.gov/odls/#/search" target="_blank" data-cms-ai="0"><u>Detainee Locator website</u></a>, online sleuths tracked Brösche to the Otay Mesa Detention Center, which is a U.S. Immigration and Customs Enforcement (ICE) facility run by the private contractor Core Civic.</p><p>Meanwhile, local resident Ashley Paschen found Brösche’s story while, “doom scrolling TikTok.”</p><p>“At the end of the video, she just asked is there anybody in the area that can put eyes on her and help?” said Paschen, who lives near the detention center.</p><p>Paschen said she’s not an activist and doesn’t consider herself the type of person who would normally get involved in a situation like this. But something about Brösche’s story grabbed her.</p><p>“I think it was just the mom in me,” she said. “Her mom hasn’t heard from her and doesn’t know where she is. At that point, no one had had any contact with her at all.”</p><p>Despite being a complete stranger, Paschen decided to visit Brösche at the detention center. She brought Brösche messages from family and friends. Paschen also told her that friends had already contacted the German embassy and were trying to get her out of there.</p><p>“She was blown away,” Paschen said.</p><h3>‘It was like a horror movie’</h3><p>A few weeks later, with Paschen’s help, Lofving was able to visit Brösche.</p><p>It was a tearful reunion, filled with hugs and Lofving repeatedly saying, “I’m sorry, I’m so sorry.”</p><p>Lofving said Brösche told her about her time in custody — and a particularly difficult nine-day period in what amounted to solitary confinement in a CBP holding cell.</p><p>“She says it was like a horror movie,” Lofving said. “There were people screaming from the rooms all around. They are feeding her through a little mailbox hole. She didn’t have a blanket, she didn’t have a pillow. It’s basically a yoga mat on the ground and a toilet on the corner.”</p><p>Spending that many days in one of CBP’s short-term detention facilities appears to be a violation of the agency's own internal detention standards, which, “generally limit detention in these facilities to 72 hours,” according to a <a href="https://www.oig.dhs.gov/sites/default/files/assets/2022-12/OIG-23-03-Dec22.pdf" target="_blank" data-cms-ai="0"><u>2023 report from the Office of Inspector General.</u></a></p><p>Inspectors conducted unannounced inspections of four short-term facilities in San Diego and El Centro. They found that of the 447 migrants detained in all four stations, 42% of them exceeded the 72-hour standard, with some being there for more than 20 days.</p><p>Brösche told friends that the prolonged confinement has impacted her mental health.</p><p>“After nine days, she says she started freaking out and punching the walls,” Lofving said. “There was blood everywhere.”</p><p>Brösche was transferred to the ICE Otay Mesa facility after that episode. She has been there since.</p><p>Lofving and Paschen say they still don’t know when Brösche will be released. Their questions to ICE have gone unanswered. The agency did not respond to an inquiry from KPBS.</p><h3>Costs to taxpayers</h3><p>Lofving said the episode is particularly absurd because Brösche’s original return flight to Berlin was on Feb. 15 — nearly two weeks ago.</p><p>“Why are American taxpayers spending thousands of dollars detaining tourists who are perfectly willing to leave,” she said.</p><p>The average cost of detaining a noncitizen adult is <a href="https://www.aila.org/library/featured-issue-immigration-detention-and-alternatives-to-detention#:~:text=Current%20Population%3A%20Per%20ICE%2C%20on,detaining%20an%20adult%20noncitizen%3A%20%24164.65." target="_blank" data-cms-ai="0"><u>$164 per day, according to an ICE memo</u></a>. Based on that average, a month of detention costs taxpayers $4,900.</p><p>An immigrant rights activist said Brösche’s story is an example of the country’s broken immigration system.</p><p>“It speaks to how inefficient this whole situation is,” said Pedro Rios, with the San Diego-based American Friends Service Committee. “There’s a lack of appreciation for how to make things run smoothly, and people are suffering in the process.”</p><p>KPBS was unable to reach the German consulates in LA and Washington D.C.</p><p>German officials told a <a href="https://www.bz-berlin.de/berlin/deutsche-in-us-abschiebehaft" target="_blank" data-cms-ai="0">Berlin-based news outlet</a>, “Our colleagues at the Consulate General in Los Angeles are in constant contact with U.S. authorities and family members regarding the case and are trying to find a solution.”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trust in Firefox and Mozilla Is Gone – Let's Talk Alternatives (219 pts)]]></title>
            <link>https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/</link>
            <guid>43229378</guid>
            <pubDate>Sun, 02 Mar 2025 11:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/">https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/</a>, See on <a href="https://news.ycombinator.com/item?id=43229378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <header>

            
            
            <p><time datetime="2025-03-01">
                2025-03-01
              </time>
            </p>
            
            
          
            
          </header>
          
    <section>
    <p>It’s been a long time coming, but the trust in Firefox and its mother organization, Mozilla, seems to be mostly gone, after a recent commit on the source code removed the <em>“we don’t sell your data”</em> promise, along with a change of <a href="https://www.mozilla.org/en-US/privacy/firefox/#notice">Privacy notice</a> and <a href="https://blog.mozilla.org/en/products/firefox/firefox-news/firefox-terms-of-use/">Terms of Use</a>.</p>
<h2 id="a-commit-too-far">A Commit Too Far</h2>
<p>You can see the changes in <a href="https://github.com/mozilla/bedrock/commit/d459addab846d8144b61939b7f4310eb80c5470e">this commit</a>.</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/firefox-privacy-bye.jpg" alt=""></p>
<p>It’s been something like 10 years that <em>Mozilla</em> is no stranger to doing <em>shady things</em> and playing a double game with its users, one one hand pretending in its PR to be a “champion of privacy”, and at the same time deploying tracking services without asking its end users (the famous <em>studies</em>). I have seen multiple times privacy settings being reset to collect data when updating the browser. Adding you <em>sponsored links</em> by default, and all that kind of things.</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/privacy.jpg" alt=""></p>
<p>At the same time, <em>Firefox</em> has lost a huge amount of market share over the years (most of it going to <em>Google Chrome</em>), and its presence on the desktop is now just a blip of what it used to be:</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/firefox-market-share-desktop.jpg" alt=""></p>
<p>Well, it was a good time to ask people what was their level of trust in <em>Mozilla</em> when it came to respecting their users. Most of our surveys get between 100 and 200 answers. This one skyrocketed to more than 700 hundred (thanks to numerous boosters on the <em>Fediverse</em>). And the result is unsurprising:</p>
<div>
<p>Do you trust Firefox (Mozilla) to respect and keep their users' interest at heart in the long run?</p>

<p>731 Answers - Poll closed on 2025-03-01</p>
<p>Always have, always will</p>

<p>I have my doubts right now</p>

<p>Nah, they lost my trust for good</p>

<p>I don't use or care about Firefox</p>


</div>
<p>For background, a lot of our followers are <em>Firefox</em> users, so this is likely to be somewhat representative of our of the core audience of <em>Firefox</em>. And it looks like trust has been completely shattered, with more than a third of respondents having no faith in <em>Mozilla</em> anymore, and the majority (54%) having serious doubts. When people are on the fence, it could go either way (losing trust, or regaining trust), but even if only half of these respondents end up not trusting <em>Mozilla</em>, this is a devastating blow.</p>
<p>Following the backlash, Mozilla has tried <a href="https://blog.mozilla.org/en/products/firefox/update-on-terms-of-use/">to backpedal with a clarification</a>. Unfortunately, the clarification confirms the initial fears. They are removing the mention of <em>not selling data</em> because of a wider meaning associated to the word <em>selling</em> in certain jurisdictions, such as in California:</p>
<blockquote>
<p>We never sell your data” is because, in some places, the LEGAL definition of “sale of data” is broad and evolving. As an example, the California Consumer Privacy Act (CCPA) defines “sale” as the “selling, renting, releasing, disclosing, disseminating, making available, transferring, or otherwise communicating orally, in writing, or by electronic or other means, a consumer’s personal information by [a] business to another business or a third party” in exchange for “monetary” or “other valuable consideration.”</p>
</blockquote>
<p>Well, if that’s what Mozilla is doing, then yes, it is clearly what most people would understand as <em>selling your data</em>, as in making some kind of profit or revenue from what they collect.</p>
<h2 id="alternatives-to-firefox">Alternatives to Firefox</h2>
<p>Now the talk is all about alternatives, and those of you who are looking for your next browser, here are some things you can consider. As you will see, you do not lack options.</p>
<h3 id="librewolf">Librewolf</h3>
<p>A hardened fork of Firefox, <em>LibreWolf</em> takes Firefox’s base (ESR) and dials up the privacy settings while removing telemetry and other potential leaks. It is pre-configured with strict anti-tracking, no telemetry, and uBlock Origin (an ad blocker) included out of the box.</p>
<p>Site: <a href="https://librewolf.net/">https://librewolf.net/</a></p>
<h3 id="waterfox">Waterfox</h3>
<p><em>Waterfox</em> is an open-source browser forked from <em>Firefox</em> (ESR), originally created by <em>Alex Kontos</em> in 2011 to optimize for 64-bit systems when <em>Firefox</em> lagged in that area. Over time, it evolved to emphasize privacy, speed, and user control. Unlike <em>Librewolf</em>, it does not ship with uBlock Origin under the hood, leaving you the freedom of installing your own extensions to maximize your privacy.</p>
<p>Site: <a href="https://www.waterfox.net/">https://www.waterfox.net/</a></p>
<h3 id="zen-browser">Zen Browser</h3>
<p>Forked from Firefox, <em>Zen Browser</em> builds on the latest stable <em>Firefox</em> releases (not strictly ESR like some forks). It uses the <em>Gecko</em> engine with minimal changes to the core, focusing instead on enhancing the user interface and experience, with a radical approach to clean up <em>Firefox</em>‘s UI. Development started in April 2024, with its first public alpha in July 2024. It entered beta in December 2024, emphasizing a modern, visually appealing design. It’s probably not your first choice if you are looking specifically for a focus on privacy, but let’s keep it in this list anyway.</p>
<p>Site: <a href="https://zen-browser.app/">https://zen-browser.app/</a></p>
<h3 id="gnome-web">Gnome Web</h3>
<p><em>GNOME Web</em> is the default browser for the <em>GNOME</em> desktop environment, built from the ground up by the <em>GNOME</em> project. It’s a lightweight, open-source browser that uses WebKitGTK (a WebKit port for Linux) as its rendering engine, unlike <em>Firefox</em>’s <em>Gecko</em> or <em>Chromium</em>’s <em>Blink</em>. Its focus is simplicity, integration with GNOME, and a clean browsing experience, with some privacy considerations baked in (no telemetry and some tracking protection). However, since it is not based on any of the major browsers, you don’t get to access something like uBlock Origin, so this may be something to factor in.</p>
<p>Site: <a href="https://apps.gnome.org/Epiphany/">https://apps.gnome.org/Epiphany/</a></p>
<h3 id="ungoogled-chromium">Ungoogled Chromium</h3>
<p>This is a stripped-down version of <em>Chromium</em> that removes all Google-related services, telemetry, and dependencies while keeping the browser functional. No Google tracking, no built-in data collection, and enhanced control over what the browser can access. It’s barebones and relies on you to configure it.</p>
<p>Site: <a href="https://github.com/ungoogled-software/ungoogled-chromium">https://github.com/ungoogled-software/ungoogled-chromium</a></p>
<h3 id="gnu-icecat">GNU Icecat</h3>
<p>Another <em>Firefox</em> fork (based on ESR), maintained by the <em>GNU Project</em>, <em>IceCat</em> focuses on free software purity and privacy. It also blocks trackers by default, disables proprietary plugins, and includes privacy extensions like HTTPS Everywhere and LibreJS (which checks for non-free JavaScript). It does not get as frequent updates as other browsers, but its development is still well alive with the latest version being released in January 2025. However it’s not super easy to install, as they do not provide binaries for every distro out there, so you have to compile it. Even on <a href="https://aur.archlinux.org/packages/icecat">Arch’s AUR</a> it seems that there will be problems to build it because of incompatibilities with clang and python.</p>
<p>Site: <a href="https://www.gnu.org/software/gnuzilla/">https://www.gnu.org/software/gnuzilla/</a></p>
<h3 id="pale-moon">Pale Moon</h3>
<p><em>Pale Moon</em> is an open-source web browser originally forked from an older version of Firefox (around 2011, based on Firefox 38 ESR). Developed by <em>Moonchild Productions</em>, it’s designed to maintain a lightweight, customizable experience while sticking to the classic Firefox interface and Gecko engine (though heavily modified). It diverges from <em>Firefox</em>’s modern direction, focusing on efficiency and user control rather than chasing the latest web trends.</p>
<p>Site: <a href="https://www.palemoon.org/">https://www.palemoon.org/</a></p>
<h3 id="brave">Brave</h3>
<p><em>Brave</em> is built on <em>Chromium</em> (the open-source base of <em>Google Chrome</em>) but strips out <em>Google</em>’s tracking elements. It’s designed with privacy and speed in mind, featuring a built-in ad blocker, tracker blocker, and script blocking. It follows the Mozilla Public License for all of its components. However it does integrate a system based on crypto tokens to reward the visits that you make to certain site creators, which is something you may want to avoid.</p>
<p>Site: <a href="https://brave.com/">https://brave.com/</a></p>
<h3 id="ladybird">Ladybird</h3>
<p><em>Ladybird</em> is a web browser project aiming to be a truly independent, user-focused alternative. It started as part of SerenityOS, a hobby operating system created by <em>Andreas Kling</em> in 2018, but forked into a standalone project in 2022. Unlike most modern browsers, <em>Ladybird</em> doesn’t rely on existing engines like <em>Blink</em> (Chromium), <em>WebKit</em> (Safari), or <em>Gecko</em> (Firefox). Instead, it’s building its own engine from scratch, called <em>LibWeb</em>, paired with a custom JavaScript engine, <em>LibJS</em>. The focus is on adhering to web standards, delivering good performance, stability, and security, all while prioritizing user privacy over monetization. It’s in pre-alpha, targeting a usable alpha release in 2026, and is backed by the <em>Ladybird Browser Initiative</em>, a nonprofit funded by donations (e.g., from <em>GitHub</em> co-founder <em>Chris Wanstrath</em> and <em>Shopify</em>). So it’s still early days, but it should become an interesting option to consider later in 2025 or next year.</p>
<p>Site: <a href="https://ladybird.org/">https://ladybird.org/</a></p>
<h2 id="the-future-is-bright">The Future is Bright</h2>
<p>While there is some alarmism about the decadence of <em>Mozilla</em> and <em>Firefox</em>, ultimately good things will come out of it. Investments into other alternatives will increase (like Ladybird) and the void will be replaced by other incumbents, especially since Privacy protections and Ad-blockers are values that attract a certain following. This will lead into a more fragmented market place, which should ultimately lead to stronger standards.</p>

    
    </section>
    
    </article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What, if anything, should I do about using Mozilla's Firefox (141 pts)]]></title>
            <link>https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/</link>
            <guid>43229267</guid>
            <pubDate>Sun, 02 Mar 2025 11:06:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/">https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/</a>, See on <a href="https://news.ycombinator.com/item?id=43229267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I currently use Firefox as one of my main browsers.</p>
<p>I have used it for a <em>long</em> time - 20 years now, including for a while the IceWeasel variant - and I like it as a browser.</p>
<p>(I use Firefox as a browser; I don’t use any of Mozilla’s services such as sync or VPN or whatever.)</p>
<p>Given Mozilla’s recent shenanigans (pro ad industry, AI, never feeling quite sure what settings have changed upon upgrade, terms of service, operating model, perhaps more), I want to revisit this choice.</p>
<p>But finding a sustainable, viable alternative Free/open source browser, in a state which I can use <em>today</em>, supporting the plugins that I use daily, which is not based on Chromium, is not easy.</p>
<p>Genuinely, I don’t know…</p>
<h2 id="librewolf">LibreWolf</h2>
<p>LibreWolf is, in a sense, an obvious choice, and I installed it and copied my Firefox profile across to give it a try.</p>
<p>I’ve only done limited testing so far - a couple of days of using it - and it seems to do what I want.</p>
<p>The biggest reason stopping me from jumping to that is that it is a tweaked version of Firefox. That’s not to denigrate the work that the LibreWolf team does to improve it, but, as far as I can tell, it is completely, utterly dependent on Firefox.</p>
<p>I don’t know how quickly LibreWolf gets security updates. (<em>Edit 2025-03-02: quite quickly, various people have told me.</em>) I don’t know how much work it will be for LibreWolf to keep up to date with whatever changes Mozilla makes.</p>
<p>If I stick with Firefox, perhaps I am better of sticking with Firefox itself? I genuinely don’t know.</p>
<h2 id="firefox-from-debians-own-repos">Firefox from Debian’s own repos</h2>
<p>At the moment, I am using Mozilla’s repositories for Firefox. I get the most up to date version of Firefox, automatically, and rapidly.</p>
<p>It is convenient.</p>
<p>It also means that, regularly, I have to check my settings to see if Mozilla has changed anything. So definite trade-offs there.</p>
<p>I could switch to use the version of Firefox in the Debian repositories, and accepting that it will be an older, but perhaps safer, version.</p>
<p>That’s an option.</p>
<h2 id="standalone-applications">Standalone applications</h2>
<p>My preference to date has been to use my browser, rather than installing some additional, purpose-specific, software (with some exceptions; I prefer an email client over webmail, for instance).</p>
<p>I do a lot of video conferencing, and I use Jitsi, Teams, Zoom etc. within my browser.</p>
<p>I spend a fair amount of time in the fediverse, and on my computer I use my browser rather than a standalone client. I’ve yet to find a standalone client with an interface to match Mastodon’s “Advanced” web UI. On my phone, I use Tusky, so that’s fine.</p>
<p>For at least some sites and services, I could look for standalone clients / applications instead, and reduce my dependency on a browser.</p>
<p>Sadly, for at least some cases, this probably means “bloated Electron client” and I suspect that I’d trust them less than I trust Mozilla right now.</p>
<h2 id="tor-browser">Tor Browser</h2>
<p>I use Tor Browser regularly, on both my laptop and my phone.</p>
<p>Tor Browser is built on Firefox, so I will need to keep an eye on that.</p>
<p>I will continue to use Tor Browser for the foreseeable future, but it is not suitable for all the sites and services I want to use.</p>
<h2 id="links">links</h2>
<p>When <a href="https://neilzone.co.uk/2024/11/using-only-a-linux-terminal-for-my-personal-computing-in-2024/">experimenting with terminal-only computing</a>, the web was one of the more challenging aspects.</p>
<p>I like <code>links</code>, as a TUI browser, and I’ll continue to use it a lot.</p>
<p>But it is not suitable for all sites that I need to use.</p>
<p><code>brow.sh</code> doesn’t solve the problem here, since it is Firefox on the backend.</p>
<h2 id="other-more-esoteric-options">Other, more esoteric, options?</h2>
<p><a href="https://www.gnu.org/software/gnuzilla/">IceCat</a>?</p>
<p><a href="https://www.palemoon.org/">Palemoon</a> forked Firefox a long time ago, and still gets regular updates, so perhaps this is an option.</p>
<p><a href="https://www.netsurf-browser.org/">NetSurf</a>?</p>
<p><a href="https://astian.org/midori-browser/">Midori</a>? Looks interesting, but I’m immediately put off by the screenshot which prominently shows links for Facebook, Google etc. And there have been no commits to <a href="https://github.com/midori-browser/core">its Github repo</a> for years.</p>
<h2 id="stick-with-mozilla-and-firefox-for-a-bit-longer">Stick with Mozilla and Firefox for a bit longer?</h2>
<p>The most <em>convenient</em> option for me is to stick with Mozilla’s Firefox, and see how it goes.</p>
<p>Right now, I’ve been <em>disappointed</em> with the direction, but not more than that.</p>
<p>I don’t feel ethically compromised using Firefox. (Should I? Perhaps I’m missing something. But I don’t think so.)</p>
<p>I could keep an eye on the direction of travel, and make another assessment in the future.</p>



  <div>
	<hr>   
	<h2>You may also like:</h2>
	
    
</div>


</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The A.I. Monarchy (175 pts)]]></title>
            <link>https://substack.com/home/post/p-156886169</link>
            <guid>43229245</guid>
            <pubDate>Sun, 02 Mar 2025 11:02:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://substack.com/home/post/p-156886169">https://substack.com/home/post/p-156886169</a>, See on <a href="https://news.ycombinator.com/item?id=43229245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tab="[object Object]"><p><h3 translated="">The app for independent voices</h3></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NIH.gov DNS servers down, making PubMed, BLAST, etc. unreachable (450 pts)]]></title>
            <link>https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative</link>
            <guid>43229201</guid>
            <pubDate>Sun, 02 Mar 2025 10:50:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative">https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative</a>, See on <a href="https://news.ycombinator.com/item?id=43229201">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Crossing the uncanny valley of conversational voice (354 pts)]]></title>
            <link>https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice</link>
            <guid>43227881</guid>
            <pubDate>Sun, 02 Mar 2025 06:13:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice">https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice</a>, See on <a href="https://news.ycombinator.com/item?id=43227881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2><span>Crossing the<!-- --> </span><span>uncanny valley of</span><span>conversational voice</span></h2><div><p>February 27, 2025</p><p><span>Brendan Iribe</span>,<!-- --> <span>Ankit Kumar</span>, and the Sesame team</p></div></div><div><p><span>How do we know when someone truly understands us? It is rarely just our words—it is in the subtleties of voice: the rising excitement, the thoughtful pause, the warm reassurance.<p>Voice is our most intimate medium as humans, carrying layers of meaning through countless variations in tone, pitch, rhythm, and emotion.</p><p>Today’s digital voice assistants lack essential qualities to make them truly useful. Without unlocking the full power of voice, they cannot hope to effectively collaborate with us. A personal assistant who speaks only in a neutral tone has difficulty finding a permanent place in our daily lives after the initial novelty wears off.</p><p>Over time this emotional flatness becomes more than just disappointing—it becomes exhausting.</p></span></p><div><h3>Achieving voice presence</h3><p><span>At Sesame, our goal is to achieve “voice presence”—the magical quality that makes spoken interactions feel real, understood, and valued. We are creating conversational partners that do not just process requests; they engage in genuine dialogue that builds confidence and trust over time. In doing so, we hope to realize the untapped potential of voice as the ultimate interface for instruction and understanding.</span></p></div><div><h3>Key components</h3><div><ul><li>Emotional intelligence: reading and responding to emotional contexts.</li><li>Conversational dynamics: natural timing, pauses, interruptions and emphasis.</li><li>Contextual awareness: adjusting tone and style to match the situation.</li><li>Consistent personality: maintaining a coherent, reliable and appropriate presence.</li></ul></div></div></div><div><div><h3>We’re not there yet </h3><p><span>Building a digital companion with voice presence is not easy, but we are making steady progress on multiple fronts, including personality, memory, expressivity and appropriateness. This demo is a showcase of some of our work in conversational speech generation. The companions shown here have been optimized for friendliness and expressivity to illustrate the potential of our approach.</span></p></div><div><h3>Conversational voice demo</h3><p>1. Microphone permission is required. 2. Calls are recorded for quality review but not used for ML training and are deleted within 30 days. 3. By using this demo, you are agreeing to our<!-- --> <a data-sentry-element="NextLink" data-sentry-source-file="Link.tsx" data-sentry-component="Link" href="https://www.sesame.com/terms">Terms of Use<!-- --> </a> <!-- -->and<!-- --> <a data-sentry-element="NextLink" data-sentry-source-file="Link.tsx" data-sentry-component="Link" href="https://www.sesame.com/privacy">Privacy Policy</a>. 4. We recommend using Chrome (Audio quality may be degraded in iOS/Safari 17.5).</p></div></div><div><p>Technical post</p><h2><span>Conversational</span><span> speech generation</span></h2><div><p>Authors</p><p><span>Johan Schalkwyk</span>,<!-- --> <span>Ankit Kumar</span>,<!-- --> <span>Dan Lyth</span>,<!-- --> <span>Sefik Emre Eskimez</span>, <span>Zack Hodari</span>,<!-- --> <span>Cinjon Resnick</span>,<!-- --> <span>Ramon Sanabria</span>,<!-- --> <span>Raven Jiang</span></p></div><div><p>To create AI companions that feel genuinely interactive, speech generation must go beyond producing high-quality audio—it must understand and adapt to context in real time. Traditional text-to-speech (TTS) models generate spoken output directly from text but lack the contextual awareness needed for natural conversations. Even though recent models produce highly human-like speech, they struggle with the one-to-many problem: there are countless valid ways to speak a sentence, but only some fit a given setting. Without additional context—including tone, rhythm, and history of the conversation—models lack the information to choose the best option. Capturing these nuances requires reasoning across multiple aspects of language and prosody.</p><p>To address this, we introduce the Conversational Speech Model (CSM), which frames the problem as an end-to-end multimodal learning task using transformers. It leverages the history of the conversation to produce more natural and coherent speech. There are two key takeaways from our work. The first is that CSM operates as a</p><!-- --> <p><span>single-stage model</span>, thereby improving efficiency and expressivity. The second is our</p><!-- --> <p><span>evaluation suite</span>, which is necessary for evaluating progress on contextual capabilities and addresses the fact that common public evaluations are saturated.</p></div></div><div><h3>Background</h3><p>One approach to modeling audio with transformers is to convert continuous waveforms into discrete audio token sequences using tokenizers. Most contemporary approaches (<a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2306.12925">[1]</a>,<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2107.03312">[2]</a>) rely on two types of audio tokens:</p><ol><li><span>Semantic tokens</span>: Compact speaker-invariant representations of semantic and phonetic features. Their compressed nature enables them to capture key speech characteristics at the cost of high-fidelity representation.</li><li><span>Acoustic tokens</span>: Encodings of fine-grained acoustic details that enable high-fidelity audio reconstruction. These tokens are often generated using Residual Vector Quantization (RVQ)<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2107.03312">[2]</a>. In contrast to semantic tokens, acoustic tokens retain natural speech characteristics like speaker-specific identity and timbre.</li></ol><p>A common strategy first models semantic tokens and then generates audio using RVQ or diffusion-based methods. Decoupling these steps allows for a more structured approach to speech synthesis—the semantic tokens provide a compact, speaker-invariant representation that captures high-level linguistic and prosodic information, while the second-stage reconstructs the fine-grained acoustic details needed for high-fidelity speech. However, this approach has a critical limitation; semantic tokens are a bottleneck that must fully capture prosody, but ensuring this during training is challenging.</p><p>RVQ-based methods introduce their own set of challenges. Models must account for the sequential dependency between codebooks in a frame. One method, the delay pattern (figure below)<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2309.08804">[3]</a>, shifts higher codebooks progressively to condition predictions on lower codebooks within the same frame. A key limitation of this approach is that the time-to-first-audio scales poorly because an RVQ tokenizer with N codebooks requires N backbone steps before decoding the first audio chunk. While suitable for offline applications like audiobooks, this delay is problematic in a real-time scenario.</p><p>Example of delayed pattern generation in an RVQ tokenizer with 4 codebooks</p></div><div><h3>Conversational Speech Model</h3><p>CSM is a multimodal, text and speech model that operates directly on RVQ tokens. Inspired by the RQ-Transformer<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2203.01941">[4]</a>, we use two autoregressive transformers. Different from the approach in<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2410.00037">[5]</a>, we split the transformers at the zeroth codebook. The first<span> multimodal backbone</span> processes interleaved text and audio to model the zeroth codebook. The second <span>audio decoder</span> uses a distinct linear head for each codebook and models the remaining N&nbsp;–&nbsp;1 codebooks to reconstruct speech from the backbone’s representations. The decoder is significantly smaller than the backbone, enabling low-latency generation while keeping the model end-to-end.</p><p>CSM model inference process. Text (T) and audio (A) tokens are interleaved and fed sequentially into the Backbone, which predicts the zeroth level of the codebook. The Decoder then samples levels 1 through N&nbsp;–&nbsp;1 conditioned on the predicted zeroth level. The reconstructed audio token (A) is then autoregressively fed back into the Backbone for the next step, continuing until the audio EOT symbol is emitted. This process begins again on the next inference request, with the interim audio (such as a user utterance) being represented by interleaved audio and text transcription tokens.</p><p>Both transformers are variants of the Llama architecture. Text tokens are generated via a Llama tokenizer<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2407.21783">[6]</a>, while audio is processed using Mimi, a split-RVQ tokenizer, producing one semantic codebook and N&nbsp;–&nbsp;1 acoustic codebooks per frame at 12.5&nbsp;Hz.<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2410.00037">[5]</a> <!-- -->Training samples are structured as alternating interleaved patterns of text and audio, with speaker identity encoded directly in the text representation.</p></div><div><h3>Compute amortization</h3><p>This design introduces significant infrastructure challenges during training. The audio decoder processes an effective batch size of B&nbsp;×&nbsp;S and N codebooks autoregressively, where B is the original batch size, S is the sequence length, and N is the number of RVQ codebook levels. This high memory burden even with a small model slows down training, limits model scaling, and hinders rapid experimentation, all of which are crucial for performance.</p><p>To address these challenges, we use a compute amortization scheme that alleviates the memory bottleneck while preserving the fidelity of the full RVQ codebooks. The audio decoder is trained on only a random 1/16 subset of the audio frames, while the zeroth codebook is trained on every frame. We observe no perceivable difference in audio decoder losses during training when using this approach.</p><p>Amortized training process. The backbone transformer models the zeroth level across all frames (highlighted in blue), while the decoder predicts the remaining N&nbsp;–&nbsp;31 levels, but only for a random 1/16th of the frames (highlighted in green). The top section highlights the specific frames modeled by the decoder for which it receives loss.</p></div><div><h3>Experiments</h3><p><span>Dataset</span>: We use a large dataset of publicly available audio, which we transcribe, diarize, and segment. After filtering, the dataset consists of approximately one million hours of predominantly English audio.</p><p><span>Model Sizes</span>: We trained three model sizes, delineated by the backbone and decoder sizes:</p><ul><li><span>Tiny</span>: 1B backbone, 100M decoder</li><li><span>Small</span>: 3B backbone, 250M decoder</li><li><span>Medium</span>: 8B backbone, 300M decoder</li></ul><p>Each model was trained with a 2048 sequence length (~2 minutes of audio) over five epochs.</p></div><div><h3>Samples</h3><p>Paralinguistics</p><p>Sentences from<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2402.08093">Base TTS</a></p><p>Foreign words</p><p>Sentences from<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2402.08093">Base TTS</a></p><p>Contextual expressivity</p><p>Samples from Expresso, continuation after chime</p><p>Pronunciation correction</p><p>Pronunciation correction sentence is a recording, all other audio is generated.</p><p>Conversations with multiple speakers</p><p>Single generation using audio prompts from two speakers</p></div><div><h3>Evaluation</h3><p>Our evaluation suite measures model performance across four key aspects: faithfulness to text, context utilization, prosody, and latency. We report both objective and subjective metrics—objective benchmarks include word error rate and novel tests like homograph disambiguation, while subjective evaluation relies on a Comparative Mean Opinion Score (CMOS) human study using the <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2308.05725">Expresso</a> <!-- -->dataset.</p></div><div><h3>Objective metrics</h3><p>Traditional benchmarks, such as word error rate (WER) and speaker similarity (SIM), have become saturated—modern models, including CSM, now achieve near-human performance on these metrics.</p><p>Objective metric results for Word Error Rate (top) and Speaker Similarity (bottom) tests, showing the metrics are saturated (matching human performance).</p><p>To better assess pronunciation and contextual understanding, we introduce a new set of phonetic transcription-based benchmarks.</p><ul><li><span>Text understanding through Homograph Disambiguation:</span> <!-- -->Evaluates whether the model correctly pronounced different words with the same orthography (e.g., “lead” /lɛd/ as in “metal” vs. “lead” /liːd/ as in “to guide”).</li><li><span>Audio understanding through Pronunciation Continuation Consistency:</span> <!-- -->Evaluates whether the model maintains pronunciation consistency of a specific word with multiple pronunciation variants in multi-turn speech. One example is “route” (/raʊt/ or /ruːt/), which can vary based on region of the speaker and context.</li></ul><p>Objective metric results for Homograph Disambiguation (left) and Pronunciation Consistency (right) tests, showing the accuracy percentage for each model’s correct pronunciation. Play.ht, Elevenlabs, and OpenAI generations were made with default settings and voices from their respective API documentation.</p><p>The graph above compares objective metric results across three model sizes. For Homograph accuracy we generated 200 speech samples covering 5 distinct homographs—lead, bass, tear, wound, row—with 2 variants for each and evaluated pronunciation consistency using<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://huggingface.co/facebook/wav2vec2-lv-60-espeak-cv-ft">wav2vec2-lv-60-espeak-cv-ft</a>. For Pronunciation Consistency we generated 200 speech samples covering 10 distinct words that have common pronunciation variants—aunt, data, envelope, mobile, route, vase, either, adult, often, caramel.</p><p>In general, we observe that performance improves with larger models, supporting our hypothesis that scaling enhances the synthesis of more realistic speech.</p></div><div><h3>Subjective metrics</h3><p>We conducted two Comparative Mean Opinion Score (CMOS) studies using the<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2308.05725">Expresso</a> <!-- -->dataset to assess the naturalness and prosodic appropriateness of generated speech for CSM-Medium. Human evaluators were presented with pairs of audio samples—one generated by the model and the other a ground-truth human recording. Listeners rated the generated sample on a 7-point preference scale relative to the reference. Expresso’s diverse expressive TTS samples, including emotional and prosodic variations, make it a strong benchmark for evaluating appropriateness to context.</p><p>In the first CMOS study we presented the generated and human audio samples with no context and asked listeners to<!-- --> <span>“choose which rendition feels more like human speech.”</span> In the second CMOS study we also provide the previous 90 seconds of audio and text context, and ask the listeners to<!-- --> <span>“choose which rendition feels like a more appropriate continuation of the conversation.”</span> Eighty people were paid to participate in the evaluation and rated on average 15 examples each.</p><p>Subjective evaluation results on the Expresso dataset. No context: listeners chose<!-- --> <span>“which rendition feels more like human speech”</span> <!-- -->without knowledge of the context. Context: listeners chose<!-- --> <span>“which rendition feels like a more appropriate continuation of the conversation”</span> <!-- -->with audio and text context. 50:50 win–loss ratio suggests that listeners have no clear preference.</p><p>The graph above shows the win-rate of ground-truth human recordings vs CSM-generated speech samples for both studies. Without conversational context (top), human evaluators show no clear preference between generated and real speech, suggesting that naturalness is saturated. However, when context is included (bottom), evaluators consistently favor the original recordings. These findings suggest a noticeable gap remains between generated and human prosody in conversational speech generation.</p></div><div><h3>Open-sourcing our work</h3><p>We believe that advancing conversational AI should be a collaborative effort. To that end, we’re committed to open-sourcing key components of our research, enabling the community to experiment, build upon, and improve our approach. Our models will be available under an Apache 2.0 license.</p></div><div><h3>Limitations and future work</h3><p>CSM is currently trained on primarily English data; some multilingual ability emerges due to dataset contamination, but it does not perform well yet. It also does not take advantage of the information present in the weights of pre-trained language models.</p><p>In the coming months, we intend to scale up model size, increase dataset volume, and expand language support to over 20 languages. We also plan to explore ways to utilize pre-trained language models, working towards large multimodal models that have deep knowledge of both speech and text.</p><p>Ultimately, while CSM generates high quality conversational prosody, it can only model the text and speech content in a conversation—not the structure of the conversation itself. Human conversations are a complex process involving turn taking, pauses, pacing, and more. We believe the future of AI conversations lies in fully duplex models that can implicitly learn these dynamics from data. These models will require fundamental changes across the stack, from data curation to post-training methodologies, and we’re excited to push in these directions.</p></div><div><h3>Join us</h3><p>If you’re excited about building the most natural, delightful, and inspirational voice interfaces out there, reach out—we’re hiring. Check our<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://jobs.ashbyhq.com/sesame">open roles</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowing CSS is mastery to Front end Development (151 pts)]]></title>
            <link>https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development</link>
            <guid>43227303</guid>
            <pubDate>Sun, 02 Mar 2025 04:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development">https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development</a>, See on <a href="https://news.ycombinator.com/item?id=43227303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>There are countless articles why developers should not focus on Frameworks too much and instead learn to understand the underlying languages. But I think rarely we can find good reasons except that Frameworks come and go. To me, the main reason is different: You won’t be a master at frontend development if you don’t understand underlying mechanisms of a language.</p>
<p>A usual stack today is React together with countless layers in between the language and the framework itself. CSS as styling method is not used natively but via JavaScript tools that translate it into native CSS. For JavaScript we nowadays write an opinionated Framework language mix using TypeScript which by itself is translated to native JavaScript in the end again. And while we all know the comfort of these tools and languages, there are many things that make it easier if you understand a browser’s ecosystem:</p>
<ul>
<li>Debug JavaScript errors easier and also in foreign environments without a debugging browser extension installed</li>
<li>Debug CSS</li>
<li>Write custom CSS (and every project I’ve seen so far needs it somewhere)</li>
<li>Understand why errors occur that you may not find locally and only in client’s browsers</li>
</ul>
<p>In the past years I had various situations where TypeScript developers (they called themselves) approached me and asked whether I could help them out with CSS. <strong>I expected to solve a complex problem</strong> but for me — knowing CSS very well —&nbsp;it was always a simple, straightforward solution or code snippet:</p>
<ul>
<li><em>A multi-colored footer bar should not be an image, it’s a simple CSS background multi-step gradient</em> with one line of code. No need to scale an image, create an SVG, just CSS.  </li>
<li><em>Custom icons for an input field?</em> Welp, it’s not that easy for privacy reasons to add a pseudo-class here in certain cases. But there are many simple solutions and no need to include another bloated npm dependency that nobody understands what it does.  </li>
<li><em>Webfonts</em>: Dev: We can’t add another webfont style, we already serve 4MB of webfonts.<br>
→ Me: Alright, why don’t we serve it as Variable Font?<br>
→ Dev: Oh, what’s this?<br>
→ Check it out, we now load 218kb async, only one file and have all our styles we have and will ever need inside. </li>
</ul>
<p>Nowadays people can write great React and TypeScript code. Most of the time a component library like MUI, Tailwind and others are used for styling. However, nearly no one is able to judge whether the CSS in the codebase is good or far from optimal. It is magically applied by our toolchain into the HTML and we struggle to understand why the website is getting slower and slower.</p>
<p>Most of the performance basics I learned ten years ago are still the most relevant ones today. Yet, most developers don’t know about them because we use create-react-web-app or similar things. Put Cloudflare on top to boost performance and reduce costs. Yes, that works for your website and little project. </p>
<p><strong>What companies expect</strong> when they ask for a web dashboard serving real time data for their customers is different: It should be a robust, well working application that is easy to maintain. That means we need to combine the developer experience (React, TypeScript, all the little helpers) with the knowledge of how browsers and networks work. And only then we can boost performance, write accessible code, load dynamic data in a proper and safe way and provide fallbacks in case something goes wrong.</p>
<p><strong>In cases of emergency like an Incident with the service, I’ve seen the difference often enough</strong> between people who exactly know where to look at, start debugging and go further, and those who try to find out in panic what’s going on here, hoping that a restart or re-deployment with reinstalled dependencies will help bring the service back to life.</p>
<p><strong>And that means in the end again: If you know CSS, you also know the style framework. If you understand JavaScript, TypeScript is not a big problem for you. And that makes you a Senior or Principal.</strong></p>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The NIH is being slashed and burned, not "reformed" (194 pts)]]></title>
            <link>https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned</link>
            <guid>43227180</guid>
            <pubDate>Sun, 02 Mar 2025 04:09:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned">https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned</a>, See on <a href="https://news.ycombinator.com/item?id=43227180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><strong><span>Sensible Medicine continues to encourage criticism of our viewpoints. Vinay Prasad wrote recently that cutting </span><a href="https://www.sensible-med.com/p/cutting-nih-indirects-is-sensible" rel="">NIH funding was Sensible Medicine</a><span>. Dr. Leslie Bienen offers this rebuttal. It is an excellent read. JMM</span></strong></em></p><p>By Leslie Bienen </p><p><span>Since the NIH </span><a href="https://grants.nih.gov/grants/guide/notice-files/NOT-OD-25-068.html" rel="">order</a><span> on February 7</span><sup>th</sup><span> capping indirect funds to grantees at 15%, the “outrage machine” that is X is filled with mostly fact-free criticisms of the NIH and academic research. I explain here why I think the criticisms are flawed, and why a blanket 15% cap is a terrible idea.</span></p><p><strong>Any cap should be blocked because only Congress can legally change NIH funding formulas.</strong></p><p><span>On February 21</span><sup>st</sup><span> a federal judge </span><a href="https://www.nytimes.com/2025/02/21/us/politics/judge-nih-medical-research-cuts-universities.html?smid=em-share" rel="">extended a temporary stay </a><span>of the February 7</span><sup>th</sup><span> policy, as she should have. Many have debated the “right” number for capping indirect rates and whether it is 15, 25% or some other number. But few mention that the current cap is illegal. In 2017 Trump similarly tried and failed to impose a 10% cap on NIH indirect rates, and Congress responded with several appropriations bills specifying that only Congress can change formulas for determining indirect costs. S</span><a href="https://www.acenet.edu/Documents/AAU-ACE-APLU-Complaint-NIH-Funding.pdf" rel="">everal lawsuits</a><span> detail why NIH can’t change indirects itself, including that “Congress exercised its constitutional power of the purse and forbade the executive from expending appropriated funds” and that “the Guidance does not even acknowledge the statutes that expressly prohibit NIH from taking this step.” If Congress wants to change the cap, let them do it legally.</span></p><p><strong>Claims that 1) NIH funds mostly weak research, 2) cutting budgets will reduce the amount of weak research funded, or 3) NIH spends lots of money on DEI trainings are unsupported by evidence.</strong></p><ol><li><p>Finding a weak NIH-funded study and tweeting it does not prove that NIH funds mostly bad research. I can cite thousands of examples of excellent research funded by NIH—which would also be cherry picking. We do not have robust analyses of quality of NIH-funded studies or reliable metrics to assess strength of a funded study. In short, no one knows how much of NIH-funded research is weak.</p></li><li><p><span>There is no evidence that changing the </span><em>amount</em><span> of money dispensed will magically change how good the funded research is. We could end up with little research funded, all of it weak. To improve quality of funded research requires changing criteria or creating mechanisms that prioritize innovation, or replicability, or creating more randomized trial mechanisms.</span></p></li><li><p><span>The NIH data book shows exactly what the agency spends its </span><a href="https://report.nih.gov/nihdatabook/" rel="">47B budget</a><span> on: ~ 60,000 research grants plus intramural research and R and D awards and research centers. In 2023 approximately 3.3B went to “other” or “trainings”, or ~7% of the total. About 22% went to running the NIH (study sessions, salaries, etcetera).</span></p></li></ol><p><strong>The idea that universities are not “accountable” to the NIH for how they spend money is incorrect.</strong></p><p>Universities cannot spend indirect funds on anything they choose; the list of expenses is approved by the government and is renegotiated every few years. I have written thousands of pages of budget reports to NIH and in my experience, money, including salary money, is extremely closely accounted for. In addition, universities already prohibit luxury expenditures such as flying first class, as does the NIH, which requires medical waivers to fly Economy Plus.</p><p><strong>If Congress places an overall cap, it should be higher than 15%.</strong></p><p><span>In 1994, the Federal government capped administrative rates at 26%. That cap is still in effect. What fluctuates per university is the rate that goes to facilities. If universities spend more of their </span><em>own budget</em><span> on facilities devoted to research, then their facilities rate rises, in order to incentivize university spending on research building and equipment. This is why large wealthy research universities (somewhat counterintuitively) tend to have higher indirect rates than state universities that build fewer labs, e.g., or buy less new equipment.</span></p><p><span>To understand why 15% will result in major reductions in research, take Harvard’s rate of 69% as an example. Their facilities rate is 43% and the administrative rate is 26%, equaling 69%. The new 15% cap </span><em>would include both those numbers</em><span>. Thus, Harvard would now have 21% of the money for research they had with a 69% cap. Jeffrey Flier, former Dean of Harvard Medical School,</span><a href="https://www.sensible-med.com/p/a-conversation-with-professor-jeffrey" rel=""> estimated</a><span> this as a loss of ~$70 million at Harvard’s current level of NIH support. For many universities, even wealthy ones, this size budget hole is unfillable without significantly reducing research.</span></p><p><strong>Lower-endowment state universities will suffer disproportionately.</strong></p><p>Big state universities such as UCSF, Univ. of California, Berkeley, University of Illinois, and UCLA will be the hardest hit by lowering indirect rates so steeply. Smart policy reforms at NIH should protect state university research programs because they allow lower-income students access and exposure to careers and top scientists. Many of these universities are located in the South and Midwest and are vital to local economies and bring clinical trials and high-tech research labs which provide cutting edge health-care in places that would otherwise not have it.</p><p><strong>These cuts will undermine the US’s position as the dominant world leader in biomedical innovation.</strong></p><p><span>The USA is a global leader in biomedical research, partly because the NIH is the largest biomedical research funder in the world and a substantial percentage of biomedical innovations emerge from academic research. A </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8552459/#:~:text=Overall%2C%20academic%20inventors%20or%20founders,50%25%20of%20prostate%20cancer%20medicines." rel="">2020 analysis </a><span>found that academic researchers contributed to 37% of cancer medicines discovered from 2010-2019 and 29% of antiviral drugs such as for HIV and hepatic cancers. The National Science Board </span><a href="https://www.nsf.gov/nsb/news/news_summ.jsp?cntn_id=303449" rel="">reported</a><span> that half of basic research in the USA is done in universities. A </span><a href="https://www.bio.org/press-release/licensing-academic-patents-contributed-19-trillion-us-economy-supported-65-million" rel="">2022 report</a><span> from the Biotechnology Innovation Organization noted </span><em>academic patents alone</em><span> contributed $1.9 trillion and 6.5 million jobs to the US economy. The NIH </span><a href="https://www.nih.gov/about-nih/what-we-do/impact-nih-research/serving-society/direct-economic-contributions#:~:text=With%20an%20annual%20budget%20of,%2492.89%20billion%20in%20economic%20activity." rel="">estimates</a><span> its 47B budget generates 97B to the US economy. Claims that this number could be higher are not supported by evidence and do not negate that 97B is a lot of money.</span></p><p><span>There is evidence, however, that the US is slipping as a leader in biomedical research. China now leads the world in new patents for pharmaceuticals. American scientists have been awarded </span><a href="https://www.statista.com/statistics/262896/nobel-prize-laureates-in-medicine-by-nationality/" rel="">106 of the total 229</a><span> Nobel Prizes in Medicine or Physiology since the prize’s founding in 1901 but the UK now leads the world (31 total) after correcting for population. We should be shoring up our position not cheering as it plummets.</span></p><p><strong>Arguments that these chaotic and destructive changes will lead to a future better NIH are unconvincing given how changes were accomplished.</strong></p><p><span>It would be possible to improve the NIH, and research quality, without gutting academic research or laying off </span><a href="https://nymag.com/intelligencer/article/how-many-federal-employees-fired-jobs-cut-trump-doge.html" rel="">1800 people</a><span> solely because they were recently hired or promoted. Instead, the last few weeks’ chaos will make future meaningful reform </span><em>more</em><span> difficult as Dr. Jay Bhattacharya, whom I have </span><a href="https://www.norfolkgroup.org/" rel="">worked with</a><span> and greatly respect, will now inherit a demoralized and haphazardly reduced workforce. The recent layoffs are also penny wise and pound foolish as mostly younger and healthier people, the cheapest to employ and insure, are now gone.</span></p><p>It is hard not to conclude that these changes were a slash and burn operation or, more aptly, an operation to remove a nose to spite a face. Sadly, the face that is being spited is the American public’s and, to the extent that American innovation drives global biomedical research, the world’s.</p><p><em><strong><span>Leslie Bienen is a veterinarian, writer, and editor who researches and writes about disease, health policy, and topics that catch her fancy. She has published in The Atlantic, The NYT, Slate, USA Today, UnHerd, City Journal, Persuasion, WSJ, and elsewhere. Here is a </span><a href="https://lesliebienen.substack.com/" rel="">link to her Substack</a><span>. </span></strong></em></p><p><strong>She reports working with academic scientists across many disciplines on grants to federal agencies and philanthropic organizations.</strong></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla site down due to "overdue hosting payments" (159 pts)]]></title>
            <link>https://linuxmom.net/@vkc/114089626244932902</link>
            <guid>43226089</guid>
            <pubDate>Sun, 02 Mar 2025 01:20:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxmom.net/@vkc/114089626244932902">https://linuxmom.net/@vkc/114089626244932902</a>, See on <a href="https://news.ycombinator.com/item?id=43226089">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I'm done with coding (152 pts)]]></title>
            <link>https://www.neelc.org/2025/03/01/im-done-with-coding/</link>
            <guid>43225901</guid>
            <pubDate>Sun, 02 Mar 2025 00:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neelc.org/2025/03/01/im-done-with-coding/">https://www.neelc.org/2025/03/01/im-done-with-coding/</a>, See on <a href="https://news.ycombinator.com/item?id=43225901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In my high school days, I was a huge server and networking person. My homelab was basically my identity, and not even a good one: consumer-level networking gear running Tomato and a then-7-year-old homebuilt desktop PC running FreeBSD.</p>



<p>Then I joined <a href="https://engineering.nyu.edu/">NYU’s Tandon School of Engineering</a> for Computer Science. It was a full 180 into software engineering. I didn’t just code for assignments, I started with <a href="https://github.com/neelchauhan/TorNova">toy</a> <a href="https://github.com/neelchauhan/OnionLauncher">projects</a> and went to <a href="https://gitlab.torproject.org/tpo/core/tor/-/commits/main?author=Neel%20Chauhan">major Tor contributions</a> writing very complex patches, had two internships and ultimately a job at Microsoft.</p>



<p>Primarily due to “Big Data” experience at NYU CUSP, Microsoft placed me on the <em><a href="https://www.microsoft.com/en-us/microsoft-viva/insights">Viva Insights</a></em> team. I’ve always hated the product, feeling it was unnecessary surveillance. I wanted out.</p>



<p>In fact, the disdain of Viva Insights was big enough to make me lose passion for coding and get into obsessive browsing and shopping because facing the music of working on a surveillance product would bother me even more. Open source work outside of package maintenance went to zero.</p>



<p>I’ve tried to discuss this with my mom, and she kept telling me how “lucky” I am for working at Microsoft saying “it’s big tech” and “you’re neurodivergent” and “you won’t survive at a smaller company.” She even bought into the marketing material telling me how it’s “not surveillance.”</p>



<p>I’ve decided that in the shitty job market, it’s not worth being a software engineer even if I make much less. Part of it is being “specialized” in over-glorified surveillance so even if I change employers, what’s the guarantee I won’t be working on another surveillance product. Assuming I can even get another job.</p>



<p>In fact, I’ll just live off dividend income and try to get my new IT startup <a href="https://www.fourplex.net/">Fourplex</a> off the ground. Sure, I won’t be able to buy shiny homelab equipment as often as I did in the past, but I at least have the guarantee I’m not working on an unethical product.</p>



<p>While six figures is certainly <em>nice</em>, it’s only nice if it’s ethically done. I’d much rather flip burgers or bag groceries than work on surveillance for six figures. After all, Edward Snowden had a “stable” federal government job (not so stable now thanks to “DOGE”) and he gave it up to stand up for the right to privacy.</p>



<p>And I care more for my values than the name or salary. It’s not like I use Windows at home, I haven’t since 2012. I kept self-hosting email <em>despite</em> having worked at Microsoft 365 and <a href="https://bgp.he.net/dns/neelc.org">still do even now</a>. And I sacrificed job performance for my values of strong privacy.</p>



<p>Little did I know that my father (who was previously a big Big Data and AI advocate) would come out to hate Viva Insights. He says it’s “bullshit” and nobody uses it. Even when I worked at Microsoft I <em>never</em> used it. Not even once. It’s bloatware. Microsoft is 100% better off porting Office apps to Linux (despite me using a Mac now) or beefing up cybersecurity.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The early days of Linux (2023) (429 pts)]]></title>
            <link>https://lwn.net/Articles/928581/</link>
            <guid>43225686</guid>
            <pubDate>Sun, 02 Mar 2025 00:18:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/928581/">https://lwn.net/Articles/928581/</a>, See on <a href="https://news.ycombinator.com/item?id=43225686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="https://lwn.net/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</p></blockquote>

<p>
My name is Lars Wirzenius, and I was there when Linux started.  Linux
is now a global success, but its beginnings were rather more humble.
These are my memories of the earliest days of Linux, its creation, and the
start of its path to where it is today.
</p>

<p>
I
started my <a href="https://www.helsinki.fi/en/faculty-science/faculty/computer-science">computer science studies at the University
of Helsinki</a> in the fall of&nbsp;1988, and met Linus Torvalds, who was the
other new Swedish speaking student in computer science that year. Toward
the end of that first year, we had gotten access to a Unix server, and I
accidentally found <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a>, the discussion 
system, by mistyping <tt>rm</tt> as <tt>rn</tt>, the Usenet reader. I told
Linus about it and we spent way too much time exploring this.
</p>

<p>After the first year, we both went away to do the mandatory military
service, though in different places. We returned to our university
studies in the fall of&nbsp;1990, and both took the course on C and Unix
programming, which included a fair bit of theory of the Unix kernel
architecture as well. This led to us reading about other operating
system kernels, such as <a href="https://en.wikipedia.org/wiki/QNX">QNX</a> and
<a href="https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs">Plan&nbsp;9</a>. Linus
and I discussed with some enthusiasm how an operating system
should be built correctly. We had all the overconfidence of
20-year-old second-year university students. Everyone is better off
that this wasn't recorded for posterity.
</p>

<p>In January&nbsp;1991, Linus bought his first <a href="https://en.wikipedia.org/wiki/IBM_PC_compatible">PC</a> from a local
shop 
that assembled computers from parts. The PC had a&nbsp;386 CPU, which was
relatively 
fancy at that time, because
Linus wanted to explore multitasking. Also, since he came from a
<a href="https://en.wikipedia.org/wiki/Sinclair_QL">Sinclair QL</a>
with a&nbsp;32-bit Motorola&nbsp;68008 CPU, he wanted a&nbsp;32-bit CPU, and did
not want to step down to a&nbsp;16-bit one, so a&nbsp;286 was not an option.
Linus's first PC had a whopping&nbsp;4 megabytes of RAM and a hard drive.
</p>

<p>He got a copy of the game Prince of Persia, which occupied most
of his spare time for the next couple of months. He later also bought
a copy of <a href="https://en.wikipedia.org/wiki/Minix">MINIX</a>, because after
using Unix at the university, he wanted something like that at home as
well.
</p>

<h4>As and Bs</h4>

<p>After finishing the game, Linus started learning Intel assembly
language. One day he showed me a program that did multitasking. One
task or thread would write a stream of the letter "A" on the screen, the
other "B"; the context switches were visually obvious when the stream
of As became Bs. This was the first version of what would later become
known as the Linux kernel.
</p>

<p>Linus would later expand the program, and write most of it in C.
During this time, late spring of&nbsp;1991, I wrote an implementation of the C
<a href="https://linux.die.net/man/3/sprintf"><tt>sprintf()</tt></a> function
for him, as he hadn't yet learned how to write functions with variable
argument lists. I wanted to spare him the pain of having a different
function for every type of value to write out. The core of this code is
still in the kernel, <a href="https://elixir.bootlin.com/linux/v6.3-rc6/source/lib/vsprintf.c#L2911">as
<tt>snprintf()</tt></a>. 
</p>

<p>As time went on, Linus made his fledgling kernel better and kept
implementing new things. After a while, he had drivers for the keyboard and
the serial port, emulation of <a href="https://en.wikipedia.org/wiki/VT100">VT100</a> terminal escape sequences
for the screen, and could use it to dial via a modem to the university to
read Usenet from home. Science fiction!
One day, Linus accidentally attempted to use his hard drive to dial the
university, resulting in his master boot sector starting with
<a href="https://en.wikipedia.org/wiki/Hayes_AT_command_set">"ATDT"</a> and the
university modem-pool phone number. After recovering from this, he
implemented file permissions in his kernel.
</p>

<p>In August&nbsp;1991, Linus mentioned his new kernel in <a href="https://en.wikipedia.org/wiki/History_of_Linux#The_creation_of_Linux">public
for the first time</a>, in the <tt>comp.os.minix</tt> newsgroup. This
included the phrase "<q>I'm doing a (free) operating system (just a hobby,
won't be big and professional like gnu)</q>". Such humility.
The system was initially called Freax. A few weeks later, 
Linus asked Ari Lemmke, one of
the administrators of <tt>ftp.funet.fi</tt>, to do an upload of the first
tar archive. Ari chose the name Linux.  The initial
version still contains the original name embedded in <a href="https://elixir.bootlin.com/linux/0.01/source/kernel/Makefile">one of the
source files</a>.
</p>

<p>During this time, people were interested in trying out this new
thing, so Linus needed to provide an installation method and
instructions. Since he only had one PC, he came to visit to
install it on mine. Since his computer had been used to develop Linux,
which had simply
grown on top of his Minix installation, it had never actually been
installed before. Thus, mine was the first PC
where Linux was ever installed. While this was happening, I was taking
a nap, and I recommend this method of installing Linux: napping, while
Linus does the hard work.
</p>

<p>The first releases of Linux used a license that forbade commercial
use. Some of the early contributors suggested a change to a free-software
license. In the fall of&nbsp;1991, Richard Stallman visited 
Finland and I took Linus to a talk given by Stallman. This, the
pressure from contributors, and my nagging eventually convinced Linus
to choose the GNU GPL license instead, in early&nbsp;1992.
</p>

<p>Over the Christmas break, Linus implemented virtual memory in Linux.
This made Linux a much more practical operating system on cheap
machines with little memory.
</p>

<h4>1992</h4>

<p>The year&nbsp;1992 started with the famous <a href="https://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate">debate with Andrew
Tanenbaum</a>, who is a university professor and the author of MINIX. He had
some opinions about Linux and its architecture. Linus had opinions on
MINIX. The debate has been described as a flame war, but was actually
rather civil in hindsight.
</p>

<p>More importantly for the future success of Linux was that the X11
system was ported to it, making&nbsp;1992 the year of the Linux desktop.
</p>

<p>I had chosen to contribute on the community side, rather than to the
kernel directly, and helped answer questions, write documentation, and
such. I also ran a short-lived newsletter about Linux, which is mainly
interesting for publishing the <a href="https://liw.fi/linux-news/issue03/">first ever interview with
Linus</a>. The newsletter was effectively replaced by the
<tt>comp.os.linux.announce</tt> newsgroup.
</p>

<p>The first Linux distribution was also started in&nbsp;1992: 
<a href="https://en.wikipedia.org/wiki/Softlanding_Linux_System">Softlanding
Linux System</a> or SLS. The next year, SLS morphed into Slackware, which
inspired Ian Murdock to start Debian in&nbsp;1993, in order to explore a
more community-based development structure. A few other distributions would
follow in the 
years to come.
</p>

<p>In&nbsp;1993, both Linus and I got hired as teaching assistants at the
university. We got to share an office. That room had a PC, which Linus
took over, and used for Linux development. I was happy with a DEC
terminal for Usenet access.
</p>

<p>One day, Linus was bored and the PC at work felt slow. He spent the
day rewriting the Linux kernel command-line parser in assembly
language, for speed. (That was, of course, quite pointless, and the
parser would later be rewritten again in C, for portability. Its speed
does not matter.) A couple of years later, he spent days playing
Quake, ostensibly to stress-test kernel memory management, although
that was with a newer PC. Much fun was had in that room, and there were no
pranks 
whatsoever. None at all.
</p>

<p>At some point, Linux gained support for Ethernet and TCP/IP. That meant
one could read Usenet without having to use a modem. Alas, early Linux
networking code was occasionally a little rough, having been written
from scratch. At one point, Linux would send some broken packets that
took down all of the Sun machines on the network. As it was difficult to get
the Sun kernel fixed, Linux was banned from the university network
until its bug was fixed. Not having Usenet access from one's desk is a
great motivator.
</p>

<h4>1.0</h4>

<p>In the spring of&nbsp;1994 we felt that Linux was done. Finished. Nothing
more to add. One could use Linux to compile itself, to read Usenet, and
run many copies of the <tt>xeyes</tt> program at once.  We
decided to release version&nbsp;1.0 and arranged a <a href="https://www.youtube.com/watch?v=qaDpjlFpbfo">release event</a>. The
Finnish computer press was invited, and a TV station even sent a crew. Most
of the event consisted of ceremonially compiling Linux&nbsp;1.0 in the
background, while Linus and others spoke about what Linux was and what it
was good for. Linus explained that commercial Unix for a PC was so
expensive that it was easier to write your own.
</p>

<p>In&nbsp;1995 Linus and I did a software engineering course at the university,
which mostly consisted of a large practical project. This was built on top
of Linux, of course. I insisted that a version-control system be used. I
had witnessed students in earlier courses do the shouting kind of version
control: the students shared a source tree over NFS and shouted "I'm
editing this file" when they were changing something.  This did not seem
like an effective method to me, so I insisted on <a href="https://en.wikipedia.org/wiki/Concurrent_Versions_System">CVS</a>,
which I'd just learned about. This experience is why Linus dislikes CVS and
for years refused to use any version control beyond uploading tar balls to
FTP sites.
</p>

<p>That year was also when Linux was first ported to a new architecture
by Linus. He'd been given a DEC Alpha machine. I would later get the
machine to use as a terminal for reading Usenet. Other people ported
Linux to other architectures, but that did not result in me getting any
more machines to read Usenet on.
</p>

<p>In&nbsp;1997 Linus graduated and moved to the US to take a job at
<a href="https://en.wikipedia.org/wiki/Transmeta">Transmeta</a>. I took a
job at a different university in the Helsinki area.
</p>

<p>In the following years, many things happened. It turned out that there
were still a few missing features from Linux, so people worked on
those. The term "open source" was coined and IBM invested a ton of money in
Linux development. Netscape published a version of its web browser as
open source. Skipping a few details and many years, open source basically
took over the world. LWN was started and covered much of this history on a
week-by-week basis.
</p>

<p>In&nbsp;1991, Linus wrote that Linux "<q>won't be big and professional
like gnu</q>". 
In&nbsp;2023. Linux is running on every continent, on every ocean, on billions
of devices, in orbit, and on Mars. Not bad for what started as two threads,
writing streams of As and Bs on the screen.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Wirzenius_Lars">Wirzenius, Lars</a></td></tr>
            </tbody></table><br clear="all">
<hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Flash games shaped the video game industry (2020) (217 pts)]]></title>
            <link>https://www.flashgamehistory.com/</link>
            <guid>43225560</guid>
            <pubDate>Sun, 02 Mar 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flashgamehistory.com/">https://www.flashgamehistory.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43225560">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        There were many more Flash games. Millions more.
    </p><p>
        Played billions of times on thousands of different gaming websites.
    </p><p>
        It was creative chaos.
        <br>
        <span id="explosiveEmoji">🤯</span>
    </p><div id="story1">


            <p>
            

            Flash games were the gateway for many developers in the games industry, and served as an experimental
            playground
            for distilling games down to their most pure and engaging elements. The end-of-life of Flash in December
            2020 marks the end of one of the most creative periods in the history of gaming.

            </p><p>
            
            It all started in 1996, when the Flash player was first released. Originally it was intended for Web
            graphics
            and animations, but when it got its own programming language in 2000, developers started to use
            it to make games.
            </p><p>
            
            That was the same year we saw the rise of the first automated Flash games website, Newgrounds.
            Anyone could upload their games and they were published immediately.
            </p></div><div id="svgContainer">
        


        <div>

            <br>
            <!--
            <div style="font-size:calc(25px + 0.5vw);color:#999999">
                Flash games on Newgrounds
            </div>
            -->
            <p>
                The following graph shows the 2000 most popular Flash games on Newgrounds in chronological order.


                Each bubble represents a game and the area of the bubble corresponds to the number of times that game
                was
                played on Newgrounds.
            </p>
            </div>
        <svg>
        </svg>

        <p><span>Everything by everyone</span>
            <br>
            Websites like Newgrounds made it possible for anyone to publish their games without a studio
            or a publisher. Developers uploaded experimental games, artistic games, brutally violent games, funny games
            and
            activist games. It was the wild west of gaming and the creativity that came out of that environment was
            amazing.
            People made games just because they wanted to make games, not to turn a profit.
        </p>


        <div>
            <p><span>The Flash workflow</span>
            <br>
            Flash had a designer centric workflow that brought together art, animation, and coding.
            People that wouldn't have written code otherwise could gradually make their animations into games. An
            example is
            the game <span>Xiao Xiao</span>, which started as a simple stick figure animation
            that evolved into a fighting game.
            </p><p>
            
            Developers also didn't have to worry about the technical details of cross-platform support. A game written
            in Flash 20 years ago is still playable today, while games written for iOS or Android require regular
            updates to keep them working on new phones.
        </p></div>


        <p><span>Accessibility</span>
            <br>
            Anyone could play Flash games by just clicking a link. Playing and sharing games today is still not as easy
            as it was 20 years ago.
        </p>


        <p><span>Decentralization</span>
            <br>
            The <span>Fancy Pants Adventures</span> game was played a few million times on
            Newgrounds, but across all websites, it
            was played more than 300 million times. Most Flash games were featured on thousands of different websites.
            If a game
            didn't connect with the audience
            of one site, it could still reach many others. The Internet was a more decentralized place back then.
            Nowadays, games like the <span>McDonald's Videogame</span>, where you corrupt
            politicians and destroy the rainforest to make
            fast food, would most likely be banned from the App Store, cutting it off from a large percentage of
            players.
        </p>


        <p><span>Rapid iteration</span>
            <br>
            The culture around Flash games promoted original ideas and made it acceptable to fail.
            Most games were made in less than a few months, some even in just a few days.
            If your game didn't do well, you could just make another one. Game design evolved at a rapid pace.
        </p>

        <p><span>The beginning of the end for Flash</span><br>
            In 2010, two years after the release of the iPhone, Steve Jobs wrote an open letter explaining why Flash
            wouldn't be allowed on Apple's platform. Flash had security issues, drained
            the
            battery, and was built for desktop computers, not mobile devices with touch interfaces.
            <br>
            <a href="https://web.archive.org/web/20200104081626/https://www.apple.com/hotnews/thoughts-on-flash/" target="_blank">Read the letter</a>


        </p>


        <div>
            <p><span>Flash exodus</span><br>

            By 2012, the number of players on Flash game websites was declining and fewer and fewer games were being
            made in Flash.
            Many developers jumped ship to make mobile or console games, and former Flash game animators started Youtube
            channels.
            </p><p>
            
            It was not just the rise of the iPhone that was responsible for the decline of Flash. Ultimately, the
            Internet became a different place that had to support a wide variety of different devices.
        </p></div>


        
    </div><div id="quotes">
        

        <br>


        <div><p>

            “Being a creator of and steward for Flash as a platform was a privilege. I felt that we were building a
            pencil
            and it was the community of creators that was responsible for the creation of Flash as a creative form. Our
            job
            as stewards was to anticipate needs, listen and make sure it worked. The core idea of having an accessible
            system for creating interactive media content that works across a range of devices is still a powerful one.
            Just
            like pencil and paper is a powerful tool. I hope it will happen again. Many years ago, I had the idea of
            Flash
            Forever. How can we treat what is created in Flash as valuable information like a book? Sadly, the need to
            drive
            business growth by adding features and capabilities, trumped the need for permanence. It’s great that Flash
            still lives in the skills and experiences of the community of people who learned and grew with it.”
            </p><p>
                Jonathan Gay
                <br>
                Creator of Flash
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Flash_logo.png" width="140" height="140">
            </p>
        </div>


        <div><p>
            “Over the years, my companies have made a number of software tools, but Flash was by far the most
            impactful. For me, the most gratifying thing has been having Flash animators thank me for giving them a
            career. Not just a tool, but a career. But the person that really is the one to be thanked is Jonathan Gay,
            the visionary behind Flash from day one and all the way until Adobe acquired it. Jonathan is an amazing man,
            and I was lucky to start working with him from the time he was a 17-year old in high school.”


            </p><p>
                Charlie Jackson
                <br>
                Co-Founder of FutureWave Software
                <br>
                <a href="https://www.s-beach.com/blog" target="_blank">Blog</a>
                <a href="https://twitter.com/wiredcoach" target="_blank">Twitter</a>

            </p>
            <p><img src="https://www.flashgamehistory.com/img/FutureWave_logo.png" width="250" height="104">
            </p>
        </div>
        <div><p>

            “Having grown up tinkering with animation software while programming text-based games, Flash was the first
            program that merged art and code in a way that I always hoped could be possible. Even better, anything you
            made could be played instantly on any computer via the web.
            </p><p>
            
            It was a magical time of experimentation and a lot of goofing off with friends found over the Internet. The
            moment was especially ideal for newcomers and outsiders, who now had a low barrier to entry and no industry
            gatekeeping. The joy of that era embodies what Newgrounds seeks to achieve to this very day; a place where
            people with no experience can learn, create and share wonderful things together.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Newgrounds_logo.png" width="140" height="140">
            </p>
        </div>
        <div><p>
            “Flash made the online game industry evolve, flourish and then explode. We played a small part, but it was a
            huge part of my life. I saw our games being played close to 3 billion times, with some including Bowman
            being played hundreds of millions of times. It is with great sadness I am witness to the death of Flash.
            Flash games made me, my business and altered my life. They allowed me to connect with the world and feel
            slightly less alone.”


            </p><p>
                Frank Valzano
                <br>
                Creator of Bowman and FreeWorldGroup.com
                <br>
                <a href="http://www.freeworldgroup.com/games4/gameindex/bowman2.htm" target="_blank">Play
                    game</a>
                <a href="http://www.freeworldgroup.com/" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Bowman.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I owe my success as a game developer to Flash. My Rebuild series and my husband's Fantastic Contraption
            both
            started as Flash games played by millions of people freely in their browsers. That ease of sharing was so
            revolutionary - we went from buying games at the mall to just clicking a link! Flash gave all these small
            experimental games an instant audience, and gave rise to indie games as we know them today including my
            own.”

            </p>
            <p><img src="https://www.flashgamehistory.com/img/Rebuild.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “For me, Flash was an integral part of my game dev journey - a wonderful, eccentric piece of tech that I
            will always hold dear. I'd been making games using various tools and languages since I was a kid but when
            Flash arrived on the scene it was a 'lightbulb moment', because I was a little bit of an artist, a little
            bit of a coder and this bridged that gap perfectly.
            <br>

            There just weren't any tools that I know of that allowed animators to make creations and coders to bring
            them to life. The fact that it compiled into this one tiny SWF file that could be distributed everywhere,
            (fonts, sounds, graphics and all!) just meant games could go viral in an instant and reach millions of
            players - which is exactly what happened when I launched the first Swords and Sandals game way back in 2007.
            <br>

            It's funny, I still find myself defending Flash against the lumbering and dreary HTML5 pipeline that
            proclaimed itself successor - even now, HTML5 gaming struggles to hold a candle to what Flash could do a
            decade ago with a lack of decent vector animation and inconsistent performance across browers.
            </p><p>
            

            Ten years after Steve Jobs declared it dead tech I still have a bunch of games on Steam made with AIR ( a
            sort of desktop 'successor' to Flash ) that have sold well enough to allow me to build an indie games
            business and given me the freedom to continue the Swords and Sandals story - I owe Flash a huge debt, thanks
            for saving the universe (for me at least!)”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/SwordsAndSandals.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “The old Flash scene was an incredible place to learn gamedev: it was a lively and fun community, and the
            content was free to access, but devs could still get paid for "pretty much any project" through the
            (honestly, kind of insane) sponsorship market - which also ended up handling distribution and marketing for
            you. These combined into a perfect storm of weird and unrestrained experimentation in all directions. I
            didn't realize until it was already over, but it was a tech bubble for strange art!”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/CompanyOfMyself.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I was coming out of art school right when Flash was becoming popular and for me it was a way to create
            something and put it out in the world with no mediation — a Flash website was accessible to anyone with a
            web-browser. I would get emails from people at libraries enjoying my work! And I didn’t really think of the
            things I was making as games — it seemed that a browser window could have absolutely anything inside of it,
            and it didn’t need to be explained as long as it was compelling. To me, that element of surprise (or
            sometimes, confusion) is really magical. It probably had as much to do with the time as the technology, but
            it’s a feeling I’ve tried to keep alive in my work ever since.”
            </p>

            <p><img src="https://www.flashgamehistory.com/img/Windosill.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “My background is in visual arts and design so Flash was the perfect gateway drug to game making. It allowed
            me
            to start from simple animations, and gradually add more complex gameplays release after release.
            I still miss its timeline-based logic, its IDE, and its sharp vector rendering.
            Flash's streamlined workflow and huge ecosystem meant that I could make a game responding to an urgent issue
            in
            a matter of days and immediately make it accessible to an audience of millions.
            Tools and communities change all the time but certain kinds of Flash games are almost impossible to make
            with
            other tools, and the exuberant, fast and dirty world of online games has been only partially replaced by
            platforms like http://itch.io.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/TheMcDonaldsVideogame.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash as a platform gave "outsiders" an accessible tool to make games, but this wasn't the most important
            aspect: it was reach. It was mindblowing to put my game on Kongregate and have *thousands* of people play it
            overnight. This combo "runs in browser + access to player community" put a beginner, unknown, south american
            developer in the spotlight and allowed me to have a career in game development. It was just sad that Flash
            was in the hands of Adobe, who didn't know what to do with it and let it wither. HTML5 is still no
            replacement because it lacks the toolchain, it was a calamity when it died.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/IWishIWereTheMoon.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash games at their best had such a raw, personal connection to their creators. When playing them you
            could feel artist’s hand, and the passion they poured into their work. Flash games and animations felt
            accessible, they had a way of making you think, ‘Hey, I could do that!' The effect was immediate and
            intoxicating. The first shape on your canvas, no matter how crude, had the potential to be given life.
            </p><p>
            
            For someone who made videos, stop motion animations, built contraptions, and generally felt the urge to just
            making something, Flash just felt like exactly what I needed. I’ve heard ‘I didn’t know Flash could do that’
            a few times in regards to The Fancy Pants Adventures, but in reality, the series was shaped heavily by
            Flash’s unique vector based, animation-centric workflow. I was able to build something that I felt was
            distinctly mine, while working around and also embracing my own strengths and weaknesses.
            </p><p>
            
            The insane reach, the community, the crazy creatives, nothing else comes close, and most people just have no
            clue how absolutely massive Flash was.
            </p><p>
            
            It’s still almost impossible for me to wrap my head around the fact that I was able to create something that
            had an impact in the world, and Flash made that possible.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/FancyPants.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash had a huge influence on me as a game developer and designer. Relatively accessible code and very easy
            online sharing made game making a social activity, even when I didn't know a lot of other designers in
            person.
            Folks I met through making Flash games starting almost 15 years ago are still people I count as my very best
            friends. I have no idea what my life or career would look like without Flash. I also feel very honored and
            privileged to have had a hand in thousands of Flash games over the years by sharing my Flash game engine
            Flixel
            with other developers. Flash ruled and I miss it a lot.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Canabalt.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash gave me the opportunity to be creative and ambitious with what I was making while I was still
            learning
            to use it. It taught me how I could make games with the most basic of coding ability, and then taught me
            something new with every little project I made. Once I started making games professionally, it gave me the
            tools to make something new and fresh on an almost monthly basis without ever feeling particularly
            restricted by the platform.
            </p><p>
            
            Unfortunately as technology advanced, Adobe either dragged or dug in their heels and refused to adapt.
            Casual gamers and our target audience moved to mobile platforms which we simply were not provided any
            meaningful tools to properly cater to until it was years too late and there were other engines and
            technologies better suited to it.
            </p><p>
            
            It became harder to make just a simple game and have it run well, and I found myself recommending to others
            to stay away or choose a different path.
            </p><p>
            
            What didn't change though, was the experience of making so many games in an industry that was just beginning
            to find its feet, and I find it influencing so many decisions I make now that I work as a designer at SEGA.
            </p><p>
            
            Making Flash games for Armor Games was one of the best experiences of my life, even if the fast pace
            sometimes did feel crushing, there was nothing more thrilling than releasing a game out to Armor, Newgrounds
            and Kongregate and seeing the mostly positive reviews roll in. I met some amazing people, and got the chance
            to do amazing things. I miss Flash, and the ease of prototyping something so quickly and easily and just
            having it work everywhere. I also miss all the players of the games I had, it was incredible seeing people
            react to something I'd created and I still every so often hear from people who played one of my games and
            it's the best feeling in the world.
            </p><p>
            
            I've heard from people that Apple helped kill of Flash by not supporting it on iPhone, but Adobe had years
            and years to adapt and constantly let the community down, and I wonder what the world of casual games would
            be like now if Flash was still a viable platform for developers to use. I have a suspicion that the
            democratisation of platform and development that was seen in the early flash days on web portals would mean
            a less stale corporate run culture around small free to play games these days.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/SHIFT.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “Flash was an incredible force in the democratization of game development and the initial spark of what was
            to become a thriving ecosystem of indie game developers. It provided access to a market of unprecedented
            scale where you could reach anybody with a web browser by giving them nothing but a hyperlink and a way for
            games to spread virally with less friction than ever before. For XGen this meant the ability to reach tens
            of millions of players with our games, to build lasting direct relationships with our fans and to share in
            their experiences.
            </p><p>
            
            The creativity and experimentation enabled by Flash as a platform and the distribution that it enabled
            brought the industry countless new ideas, fresh perspectives on what games can be, and even whole new
            genres. Massive worldwide sensations like Minecraft and so many others can trace their ancestral lineage
            back to concepts and experiments that originated in the world of Flash games. It's clear that we owe a lot
            of the game industry's brightest stars to these funny little games that brought us all so much joy and
            delight.”
            </p><p>
                Jordan Dubuc
                <br>
                Director of Operations at XGen Studios
                <br>
                XGen Studios created Motherload
                <br>
                <a href="http://www.xgenstudios.com/play/motherload" target="_blank">Play game</a>
                <a href="https://twitter.com/XGenStudios" target="_blank">Twitter</a>
                <a href="http://www.xgenstudios.com/" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Motherload.png" width="250" height="167">
            </p>

        </div>

        <div><p>
            “Flash was a remarkable technology: an accessible programming tool that created games that you could play
            from almost any computer connected to the internet. Where Steam and Apple are often credited with
            democratising development, an incredible number of developers entering the industry around that time had
            already learned that anyone could make games that could become 'a hit' via Flash and the many Flash games
            portals around.
            </p><p>
            

            Each technology shapes the work created in it, through the things that are easy to achieve in it, the
            opportunities of what is possible in it, and the challenges from what is not possible in it. Flash was an
            incredibly fast 2D animation tool, and the limitations of the internet in the Flash era limited the filesize
            you could expect players to wait for. This gave Flash a primary aesthetic of fast, 2D action games - and
            seeking to stand out within that space, a huge amount of experimentation and iteration followed. As the
            community found tricks and shortcuts, new possibilities would open up, and new experiments would follow. The
            community turned into a self-growing organism, ever seeking the ever-expanding possibilities of the space -
            some excelled in animation, others in design, others in creation speed, others in humor, and again others in
            technology. Whatever your focus, there were others chasing that same dream, appreciating your efforts - and
            that felt exciting.
            </p><p>
            

            It wouldn't be an exaggeration that Vlambeer, and with it games as Super Crate Box, Ridiculous Fishing,
            LUFTRAUSERS, and Nuclear Throne, would not have existed without Flash. We made our first dollar via Flash,
            and earned the money we needed to keep the studio afloat for the first few years via Flash. I know for a
            fact that we're not the only one. Many people I would consider indie legends today would not have been able
            to create their defining works, or sustain their passion projects without messing around in Flash.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/RadicalFishing.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I was doing a PhD in BioChemistry back in 2008. I was conducting experiements where I needed to press a
            button every 5 minutes for over 6 hours. I started playing flash games to pass the time. They were so
            simple, accessible and fun that after a while I was drawn to making one.<br>
            I followed some tutorials and code examples (thanks Keith Peters!) and made a couple of games. They were
            played hundreds of thousands of times and I was instantly hooked. I never finished the PhD. I could no
            longer motivate myself to spend years writing something that will be read by 1 or 2 people if I’m lucky when
            instead I could spend a week making something silly and fun that 100k+ people would play. I’ve been making
            web games for over a decade now and they’ve been played around a billion times. I will never forget the
            start of my journey. Thinking up a bonkers new game idea, throwing it together then putting it on Kongregate
            and Newgrounds to see what people think. It was the golden age of indie game development in my opinion. The
            most creative and fun ideas got the most attention no matter who made them. No need for a marketing budget
            and definitely no in-app purchases etc. I’ve closed my flash site now (TheGameHomepage.com) to focus on my
            new(er) HTML5 game site FreeGames.org. I’ve had a few hiatuses and a job in between but I’m still making web
            games 12 years later!”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/RedRemover.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “A lot of new indie studios were popping up all across Indonesia in 2010. The main driving factor was Flash
            games. Flash games and its sponsorship business model had opened doors for Indonesians to create games and
            earn
            a decent living from web-based games. For Indonesians, making Flash games were the closest thing to being a
            “real” game developer. There were no big AAA studios nor schools with game development courses in Indonesia
            back
            then, even now access to game development knowledge is still very limited. And to make things even harder,
            games
            are still considered “bad” and not a legit career path in the eyes of parents, teachers, and government
            officials in Indonesia.
            </p><p>
            
            Many Indonesians who dreamt of working in the games industry or wanted to create their own games turned to
            Flash
            games and started forming studios or teams, I was one of them. The best thing was, you don’t need a lot of
            capital to start making Flash games and you can earn a pretty decent living in Indonesia. To put things into
            perspective, a simple Flash game that a single developer worked on for less than a month could get US$500 -
            US$1000 in sponsorships and ads, while the standard salary for a university fresh graduate in Jakarta was
            about
            Rp 3,000,000/month (US$200/month in today’s currency), even less if you live outside of Jakarta. The higher
            quality Flash game could even earn US$20K and more.
            </p><p>
            
            In this era, Indonesian game developers released many notable games and hits, such as the Epic War series
            from
            Artlogic games, Infectonator and Necronator series from Toge Productions, Valthirian Arc series from Agate,
            and
            many more. These games were being played by millions of people worldwide and their success helped the growth
            of
            Indonesian games industry.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Infectonator.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I started making Flash games when I was 18. It was just a hobby, because I loved video games, was a
            computer science student and always wanted to make my own game. Flash was the easiest tool to do it, and it
            also had a huge community which could actually play the game and provide some feedback.
            </p><p>
            
            And the feedback from players became the most valuable thing for me. It inspired me to move further, make
            bigger, better and more detailed games. For example, Feudalism III had an AI system equal to Final Fantasy
            XII or Dragon Age: Origins, with unique settings for every one of 184 types of units.
            The feedback also really helped to improve my English ;)
            </p><p>
            
            I’ve been making Flash games fulltime for 10 years (2004 – 2014), and it was the best part of my life. In
            2014, when the flash started slowly dying, I’ve accidentally found an opening in big company making AAA
            games. I’ve decided to give it a try – mostly because I was curious if my skills would interest them.
            Surprisingly, they did! Since then I was even promoted to a lead UI programmer. So, I’m still a game
            developer, but currently as a part of big team.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Feudalism.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I basically grew up on Newgrounds and developed an interest in making my own games very early on. I begged
            my parents to buy Flash (I believe the first version I got was Macromedia Flash MX 2004) and they were very
            skeptical of the cost, a few hundred dollars IIRC, but they got it for me for my 13th birthday.
            </p><p>
            

            I made a few low quality games which are lost to the ether, and then I started releasing some slightly
            better games under the name IcyLime. I made Multitask in 2009 when I was 15. Actually it only took about 10
            days to make, and I figured it would get maybe a few hundred, or maybe even a thousand views.
            </p><p>
            

            Multitask ended up getting over 10 million views across different sites like Kongregate, Newgrounds,
            ArmorGames, and others. I was overwhelmed and had NO idea how to properly monetize it at the time so I gave
            away licenses for less than market value, but since then it has still made around $15,000. I then made a few
            other games including Multitask 2 before life took over, and I never had time to return.
            I credit Flash for guiding me to my career path as a software developer, although I no longer have as much
            of an interest in making games specifically.”
            </p><p>
                Creed Gallagher
                <br>
                Creator of Multitask
                <br>
                <a href="https://www.newgrounds.com/portal/view/506546" target="_blank">Play game</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Multitask.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Long before Mario Maker was a thing, N by Metanet Software offered a level editor, and I submitted a couple
            hundred of my own designs to nmaps.net, where the community would play them and give feedback. My college
            offered a quality game design program, but I unironically learned more from this one little community of
            players and designers.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Run.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I was basically a kid during the Flash-era, and I feel like I grew up alongside it. I would always frequent
            Newgrounds as I was enthralled by all the amazing content people were uploading and the community around it
            all. I would mess-around on the computers at school slowly teaching myself both animation and scripting with
            dreams of also uploading my own content one-day.
            </p><p>
            
            The first 'game' I ever made was entirely based off someone else's scripts they had uploaded for public use.
            I kept tweaking the code and drawing art, learning as much as I could but honestly just having fun; the
            concept of being a real game developer just didn't exist in my mind. Eventually I released my first serious
            game and people loved it, and that blew me away. So I kept doing it. A decade later and I've since changed
            careers to pursuing game development professionally, still learning and still honestly just having fun.
            Flash made that possible.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/ColourMyWorld.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “Nitrome would not have existed without flash. It may on the surface only seem like a tool to make games but
            at the time we started there were few realistic options for small indies. The low barrier to entry was two
            fold in that the application was easy to learn to a standard that you could make a game and as a platform
            there has never been an easier way to get your game out there. We even made decent money from it for a
            while.
            </p><p>
            
            In total Nitrome made over 130 games in flash. Making that many games was a great learning tool for us. Some
            of the games were better than others but that was part of the process and making lots of game quickly meant
            we got better quickly too.
            </p><p>
            
            The demise of flash led Nitrome to stop making flash games and led to our future games finding homes on
            mobile console and PC. Though the tools we use is now Unity and the stores are different the main spirit of
            the games we make is still firmly rooted in what we learnt making flash games.
            </p><p>
            
            Nitrome recently began converting our entire catalogue of Flash games to be playable in HTML5. The player
            may soon be gone but the games themselves will live on we hope for a long time to come.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Nitrome_logo.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Bob and I started making Flash games in early 2001. It was as much fun to make the games as it was to play
            them. However, we all knew the dark side of Flash games was how the games would be pirated to multiple
            sites. It wasn't until 2005 that we developed the concepts for MochiBot and MochiAds. Thus, Mochi Media was
            born.
            </p><p>
            
            Working so closely with the Flash games community was such an inspiration to us all. We saw how
            life-changing these games could be for people around the world. I've built lifelong friendships through the
            community and I miss the camaraderie we had in the forums.”
            </p><p>
                Jameson Hsu
                <br>
                Co-Founder of Mochi Media
                <br>
                <a href="https://twitter.com/jamesonh" target="_blank">Twitter</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/MochiMedia_logo.png" width="232" height="186">
            </p>
        </div>


        <div><p>
            “Nowadays the internet is synonymous with posting your own stuff, but in 2004 there was no Twitter,
            Facebook, Youtube or SoundCloud. NewGrounds (and DeviantArt) was years ahead of the curve letting you not
            just upload home-made games, cartoons and music, but also letting users watch, vote on, review, give
            feedback, follow creators, download and share the stuff they liked, then learn how to make their own games
            and meet musicians or artists to collaborate with. This was in 2002, when most people thought "the internet"
            was a thing you installed from an AOL disc.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/NoTimeToExplain.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I think its amazing to see the sort of things that came out of a misfit tool like Flash, if you think
            beyond the game / cartoon creation aspect of it, there was a brief period where websites were being built in
            Flash. Pretty elaborate ones in its hay day. So to me (I'm a designer, by profession) it directly
            intertwined with my career for a brief moment. I hope that something down the road, whatever that road ends
            up being, has a scrappy tool like Flash that can allow quick iteration and collaboration. It makes me
            sad to think that the next generation of edgy teens wont have the outlet that we old heads had back then.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/CastleCrashingTheBeard.png" width="250" height="167">
            </p>

        </div>

        <div><p>
            “I'd like to think I would have found a path into games no matter what, but flash was the first thing that
            made
            it possible for me. Its ease of use combined with sites like Newgrounds meant that a kid at home could make
            silly games and reach thousands of players with them. Luckily I was able to gain traction with some of my
            early
            games and start to earn revenue from them. Unfortunately Flash as a tool wasn't really built to keep up with
            market shifts like mobile development and the acceptance of indie devs onto console platforms. Since then
            I've
            made the move to Unity and I still continue to make games as my full-time job today. Kids now can just start
            with an engine like Unity or Unreal of course, but my time with flash gave me a huge leg up when jumping
            into
            these modern tools.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/ANEscapeSeries.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I first got into Flash because I watched some badly animated Counter Strike parody cartoons on Newgrounds.
            It was so entertaining but also so scrappy that it inspired me to download the program and play around with
            it myself. From then on, it was just a cycle of playing and being inspired by things coming out of the
            portal, working on my own stuff, begging for help on the forums, and submitting my own scrappy work.
            </p><p>
            
            The influence on my career was massive. I essentially learned how to program and make digital art from
            Flash, and these are the skills that have shaped my career since. I've stopped working on games for the past
            few years now. I jumped into visual machine learning research for a while, and now I am a software engineer
            at AWS. I still hold game development dearly to my heart. It is very fun and fulfilling work.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Sonny.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I think that the Flash game scene circa 2006-2010 was a LOT more friendly to newcomers. The current mobile
            market is too noisy and everything goes through one gatekeeper. If mobile stores worked more like the Flash
            portals of that era, I think there would be a much more interesting and vibrant indie ecosystem on mobile.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Filler.png" width="250" height="169">
            </p>
        </div>


        <div><p>
            “We can keep records of the games, the animations, and the sheer level of work that was put into making
            media with its tech. That's what I've been working on for over two years. But the microcosm of intense
            creativity, easy to access software, notable but not crippling limitations, almost universal compatibility
            across the entire technological space of its time, widespread adoption by encouraging free consumption and
            sharing in an age where 'going viral' actually meant something, all combining to influence the entire
            entertainment industry with one strike after another? That's something that we'll never be able to recreate,
            only remember fondly. All driven by a bunch of guys sitting in their bedrooms who watched a bit too much
            Xiao Xiao. Flash wasn't just a massive platform for games, it's a bite-sized model of our industry - the
            talent, the drive, the creativity - and I couldn't be happier it happened. There will never be anything like
            it again, and that's the most depressing thing about it going away.”
            </p><p>
                Ben Latimore
                <br>
                Creator of Flashpoint: The webgame preservation project
                <br>
                <a href="https://twitter.com/BlueMaxima" target="_blank">Twitter</a>
                <a href="https://bluemaxima.org/flashpoint" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Flashpoint_logo.png" width="130" height="130">
            </p>
        </div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Letter to the American People (978 pts)]]></title>
            <link>https://18f.org/</link>
            <guid>43224350</guid>
            <pubDate>Sat, 01 Mar 2025 22:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://18f.org/">https://18f.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43224350">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
        <p>March 1, 2025</p>
<h2 id="a-letter-to-the-american-people" tabindex="-1"><strong>A letter to the American People:</strong></h2>
<p>For over 11 years, 18F has been proudly serving you to make government technology work better. We are non-partisan civil servants. 18F has worked on hundreds of projects, all designed to make government technology not just efficient but effective, and to save money for American taxpayers.</p>
<p>However, all employees at 18F – a group that the Trump Administration GSA Technology Transformation Services Director called "the gold standard" of civic tech – were terminated today at midnight ET.</p>
<h2 id="18f-was-doing-exactly-the-type-of-work-that-doge-claims-to-want-yet-we-were-eliminated" tabindex="-1">18F was doing exactly the type of work that DOGE claims to want – yet we were eliminated.</h2>
<p>When former Tesla engineer Thomas Shedd took the position of TTS director and met with TTS including 18F on February 3, 2025, he acknowledged that the group is <strong>the “gold standard” of civic technologists</strong> and that “you guys have been doing this far longer than I’ve been even aware that your group exists.” He repeatedly emphasized the importance of the work, and the value of the talent that the teams bring to government.</p>
<h2 id="despite-that-skill-and-knowledge-at-midnight-et-on-march-1-the-entirety-of-18f-received-notice-that-our-positions-had-been-eliminated" tabindex="-1">Despite that skill and knowledge, at midnight ET on March 1, the entirety of 18F received notice that our positions had been eliminated.</h2>
<p>The letter said that 18F "has been identified as part of this phase of GSA’s Reduction in Force (RIF) as non-critical”.</p>
<p>"This decision was made with explicit direction from the top levels of leadership within both the Administration and GSA," Shedd said in an email shortly after we were given notice.</p>
<p>This was a surprise to all 18F staff and our agency partners. Just yesterday we were working on important projects, including improving access to weather data with NOAA, making it easier and faster to get a passport with the Department of State, supporting free tax filing with the IRS, and other critical projects with organizations at the federal and state levels.</p>
<p>All of that work has now abruptly come to a halt. Since the entire staff was also placed on administrative leave, we have been locked out of our computers, and have no chance to assist in an orderly transition in our work. We don’t even have access to our personal employment data. We’re supposed to return our equipment, but can’t use our email to find out how or where.</p>
<h2 id="dismantling-18f-follows-the-gutting-of-the-original-us-digital-service-these-cuts-are-just-the-most-recent-in-a-series-of-a-sledgehammer-approach-to-the-critical-us-teams-supporting-it-infrastructure" tabindex="-1">Dismantling 18F follows the gutting of the original US Digital Service. These cuts are just the most recent in a series of a sledgehammer approach to the critical US teams supporting IT infrastructure.</h2>
<p>Before today’s RIF, DOGE members and GSA political appointees demanded and took access to IT systems that hold sensitive information. They ignored security precautions. Some who pushed back on this questionable behavior resigned rather than grant access. Others were met with reprisals like being booted from work communication channels.</p>

<p>We’re still absorbing what has happened. We’re wrestling with what it will mean for ourselves and our families, as well as the impact on our partners and the American people.</p>
<p>But we came to the government to fix things. And we’re not done with this work yet.</p>
<p>More to come.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefly Blue Ghost Mission 1 Lunar Landing (179 pts)]]></title>
            <link>https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/</link>
            <guid>43224107</guid>
            <pubDate>Sat, 01 Mar 2025 21:53:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/">https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/</a>, See on <a href="https://news.ycombinator.com/item?id=43224107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

	<main id="primary">
		    <div id="fullscreen-player" aria-labelledby="modal-2-heading" aria-describedby="modal-2-description">
        <video id="main-video" controls="" preload="auto" width="auto" height="auto" poster="https://plus.nasa.gov/wp-content/uploads/2025/02/clps-blue-ghost-1-landing-key-art-r4-horizontal-program-tile-16-9-without-title.jpg?w=1024" title="Firefly Blue Ghost Mission 1 Lunar Landing">
            <source src="https://ntv1.akamaized.net/hls/live/2110242/landing030225/master.m3u8" type="application/x-mpegURL">
            <p> To view this video please enable JavaScript, and consider upgrading to a web browser that
                <a href="https://videojs.com/html5-video-support/" target="_blank">supports HTML5 video</a>
            </p>
        </video>
        <div>
                
                
                <p>With a suite of NASA science and technology on board, Firefly Aerospace is targeting no earlier than 3:34 a.m. EST Sunday, March 2, to land their Blue Ghost lunar lander […]</p>
            </div>
    </div>
<section>
	<article id="post-6417" data-start-time="1740900000" data-end-time="1740906660">
		<header>
			<figure>
				<img width="1024" height="576" src="https://plus.nasa.gov/wp-content/uploads/2025/02/clps-blue-ghost-1-landing-key-art-r4-horizontal-program-tile-16-9-without-title.jpg?w=1024" alt="Firefly Blue Ghost Mission 1 Lunar Landing">				<div id="countdown-container">
    <div id="countdownclock">
        <div>
            <p><span>00</span></p><p>Days</p>
        </div>
        <div>
            <p><span>00</span></p><p>Hours</p>
        </div>
        <div>
            <p><span>00</span></p><p>Min</p>
        </div>
        <div>
            <p><span>00</span></p><p>Sec</p>
        </div>
    </div>
    
    <div id="pastblock">  
        <p>This event has already occurred</p>
    </div>
</div>			</figure>
			<a href="#fullscreen-player" aria-controls="fullscreen-player" title="Open video player" data-open-modal=""><span>Open Video Player</span></a>
		</header>

		<div>
				<div>
					<p><span>Today</span> <span>2:20 am</span></p>
					<h2>Firefly Blue Ghost Mission 1 Lunar Landing</h2>
					<div>
						<ul>
															<li>
									<a href="#fullscreen-player" aria-controls="fullscreen-player" title="Open video player" data-open-modal="">Watch Livestream</a>
								</li>
														<li>
															
							</li>
							<li>
																
							</li>
						</ul>
					</div>
					<p>With a suite of NASA science and technology on board, Firefly Aerospace is targeting no earlier than 3:34 a.m. EST Sunday, March 2, to land their Blue Ghost lunar lander on the Moon. Blue Ghost is slated to touch down near Mare Crisium, in the northeast quadrant on the near side of the Moon, as part of NASA’s CLPS (Commercial Lunar Payload Services) initiative and Artemis campaign to establish a long-term lunar presence. Live coverage of the landing, jointly hosted by NASA and Firefly, will air on NASA+ starting at 2:20 a.m. EST, approximately 75 minutes before touch down on the Moon’s surface.</p><!-- .entry-content -->
				</div>
				<div>

					<table data-event-timestamp="1740900000">
						<thead>
							<tr>
								<th scope="row">Details</th>
							</tr>
						</thead><tbody>
							<tr>
								<th scope="row">Date</th>
								<td><span>Today</span></td>
							</tr>
							<tr>
								<th scope="row">Time</th>
								<td><span>2:20 am</span></td>
							</tr>
							<tr>
								<th scope="row">Timezone</th>
								<td><span><div><form><label for="city-location">Select Your Location or Timezone</label></form></div></span></td>
							</tr>
																				</tbody>
					</table>
				</div>

			</div>
	</article><!-- #post-6417 -->
</section>

	</main><!-- #main -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why can't we screenshot frames from DRM-protected video on Apple devices? (156 pts)]]></title>
            <link>https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video</link>
            <guid>43223985</guid>
            <pubDate>Sat, 01 Mar 2025 21:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video">https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video</a>, See on <a href="https://news.ycombinator.com/item?id=43223985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">



<p>Nora Deligter, writing for Screen Slate in June 2023, “<a href="https://www.screenslate.com/articles/elegy-screenshot">Elegy for the Screenshot</a>”:</p>

<blockquote>
  <p>About five years ago, Catherine Pearson started taking screenshots
of every bouquet featured on <em>The Nanny</em> (1993–1999), the
six-season CBS sitcom that was then streaming on Netflix. She was
just becoming a florist, and she found the arrangements — ornate,
colorful, and distinctly tropical — inspirational. She now keeps
them in a folder on her desktop, alongside screenshots of flower
arrangements featured on <em>Poirot</em> (1989–2013), the British
detective drama. A few months ago, however, Pearson suddenly found
that when her fingers danced instinctively toward Command-Shift-3,
she was greeted by a black box where her flowers used to be, a
censored version of what she had meant to capture.</p>

<p>It was around this time when streaming platforms like Netflix, HBO
Max, Amazon Prime, and the Criterion Channel imposed a quiet
embargo on the screenshot. At first, there were workarounds: users
could continue to screenshot by using the browser Brave or by
downloading extensions or third-party tools like Fireshot. But
gradually, the digital-rights-management tech adapted and became
more sophisticated. Today, it is nearly impossible to take a
screenshot from the most popular streaming services, at least not
on a Macintosh computer. [...]</p>

<p>For PC users, this story takes a different, and happier, turn.
With the use of Snipping Tool — a utility exclusive to Microsoft
Windows, users are free to screen grab content from all streaming
platforms. This seems like a pointed oversight, a choice on the
part of streamers to exclude Mac users (though they make up a tiny
fraction of the market) because of their assumed cultural class.
This assumption isn’t unreasonable. Out of everyone interviewed
for this article, only one of them was a PC user.</p>
</blockquote>

<p>Deligter’s essay has been sitting in my long (and ever-growing) list of things to link to ever since she published it back in 2023. I referenced it in <a href="https://daringfireball.net/linked/2025/03/01/green-imessage-disappearing-messages">my post earlier today</a> re: <a href="https://blog.cryptographyengineering.com/2025/03/01/dear-apple-add-disappearing-messages-to-imessage-right-now/">Matthew Green’s entreaty to Apple</a> to add “disappearing messages” to iMessage, and re-reading it made me annoyed enough to finally write about it.</p>

<p>I’m not entirely sure what the technical answer to this is, but on MacOS, it seemingly involves the GPU and video decoding hardware. These DRM blackouts happen at such a low level that no high-level software — any sort of utility you might install — can route around them. I think Windows still offers easy screenshotting of frames from DRM video not because the streaming services somehow don’t care about what Windows users do (which, when you think about it, would be a weird thing <em>not</em> to care about, given Windows’s market share), but because Windows uses a less sophisticated imaging pipeline. Or perhaps rather than less <em>sophisticated</em>, it’s more accurate to say less <em>integrated</em>. These DRM blackouts on Apple devices (you can’t capture screenshots from DRM video on iPhones or iPads either) are enabled through the deep integration between the OS and the hardware, thus enabling the blackouts to be imposed at the hardware level. And I don’t think the streaming services opt into this screenshot prohibition other than by “protecting” their video with DRM in the first place. If a video is DRM-protected, you can’t screenshot it; if it’s not, you can.</p>

<p>On the Mac, it used to be the case that DRM video was blacked-out from screen capture in Safari, but not in Chrome (or the dozens of various Chromium-derived browsers). But at some point a few years back, you stopped being able to capture screenshots from DRM videos in Chrome, too — <em>by default</em>. But in Chrome’s Settings page, under System, if you disable “Use graphics acceleration when available” and relaunch Chrome, boom, you can screenshot everything in a Chrome window, including DRM video. You can go to the magic URL <code>chrome://gpu/</code> before and after toggling this setting to see a full report on the differences — as you’d expect, it turns off all hardware acceleration for video encoding/decoding, compositing, and more. You wouldn’t want to browse like this all the time (certainly not on battery power), but it’s a great trick to know for capturing stills from videos.</p>

<p>What I don’t understand is why Apple bothered supporting this in the first place for hardware-accelerated video (which is all video on iOS platforms — there is no workaround like using Chrome with hardware acceleration disabled on iPhone or iPad). No one is going to create bootleg copies of DRM-protected video one screenshotted still frame at a time — and even if they tried, they’d be capturing only the images, not the sound. And it’s not like this “feature” in MacOS and iOS has put an end to bootlegging DRM-protected video content. This “feature” accomplishes nothing of value for anyone, including the streaming services, but imposes a massive (and for most people, confusing and frustrating) hindrance on honest people simply trying to easily capture high-quality (as opposed to, say, using their damn phone to take a photograph of their reflective laptop display) screenshots of the shows and movies they’re watching.</p>



 <!-- PreviousNext -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Berlin Swapfest – Electronics flea market (288 pts)]]></title>
            <link>https://www.swapfest.berlin/</link>
            <guid>43223718</guid>
            <pubDate>Sat, 01 Mar 2025 21:11:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swapfest.berlin/">https://www.swapfest.berlin/</a>, See on <a href="https://news.ycombinator.com/item?id=43223718">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-rurh3fhj=""> <p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p><p><span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj=""> <span data-astro-cid-rurh3fhj="">BERLIN SWAPFEST</span> <span data-astro-cid-rurh3fhj="">April 19th @ c-base</span> </span> </span> </p> <p><img src="https://www.swapfest.berlin/_astro/tear-outline.CiVzhoHJ.png" alt="tear" data-astro-cid-rurh3fhj=""> </p></div><div> <p>
In association with Berlin's long-time hacker space <a href="https://c-base.org/">c-base</a> we're hosting the first of a quarterly Swapfest at their space in Kreuzberg.
      This is a place to buy, sell, and swap electronics, computer equipment, and
      tools.
</p> <p>
In tune with the spirit of right-to-repair as well as re-use; the goal of
      the Berlin Swapfest is for people to bring electronics, equipment, and
      tools they no longer use, but want to bring to a good home. If you've been
      trying to find the perfect equipment to build your home-lab or looking for
      new electronic components or tools, this should be the place for you.
</p> <h2> <span>F</span><span>A</span><span>Q</span> </h2>  <div> <p>
Being a seller will always be free. Depending on the size of the item
        you're bringing you may be asked for a deposit to handle disposal of
        your items should you not bring it back home with you.
</p> <p>
However, we highly encourage you to only bring items you're comfortable
        bringing back home with you.
</p> </div>  <di> <p>
Yes, c-base will provide space and tables for sellers. Space will be
        allocated based on registration information. If you forgot to register
        as a seller, it may be possible to sell items at a table
        space-permitting.
</p> </di>  <p>
We have no requirements with how to exchange goods; if you choose to use
        PayPal, Cryptocurrency, or cash, it is entirely up to you. Any disputes
        must be taken up with the seller. Only in the case of a breach of c-base
        rules will a team member step in.
</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euclid finds complete Einstein Ring in NGC galaxy (145 pts)]]></title>
            <link>https://www.euclid-ec.org/einstein-ring-in-ngc-6505/</link>
            <guid>43223596</guid>
            <pubDate>Sat, 01 Mar 2025 20:56:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.euclid-ec.org/einstein-ring-in-ngc-6505/">https://www.euclid-ec.org/einstein-ring-in-ngc-6505/</a>, See on <a href="https://news.ycombinator.com/item?id=43223596">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-5156" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div data-ast-blocks-layout="true" itemprop="text">

		
		
<p>Gravitational lenses are rare in the sky – galaxies bending the light-paths of light from other galaxies behind them to form distorted or even multiple images. Even rarer is a perfect alignment of the two galaxies with us, the obervers, with the light being bent into a so-called Einstein Ring. And the rarest case was now observed by Euclid: this happening in an extremely nearby NGC galaxy.</p>



<p>Gravitational lensing is the effect of mass bending space and light following along this bent space. If the masses are high enough, as for a galaxy, then this can lead to an image of an object behind a galaxy to be distorted or even split up into several images: a strong gravitational lens. If vary rare cases – for a perfect alignment of source, galaxy, and observer on a line – the image gets bent into a ring. These so-called Einstein Rings have been found before, but in all configurations only approximately 1000 gravitational galaxy–galaxy lenses are currently known across the sky.</p>



<figure><a href="https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic.png"><img fetchpriority="high" decoding="async" width="1024" height="576" src="https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1024x576.png" data-src="https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1024x576.png" alt="" data-srcset="https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1024x576.png 1024w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-300x169.png 300w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-768x432.png 768w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1536x864.png 1536w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-2048x1152.png 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1024x576.png 1024w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-300x169.png 300w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-768x432.png 768w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-1536x864.png 1536w, https://www.euclid-ec.org/wp-content/uploads/EinsteinRING_infographic-2048x1152.png 2048w"></a><figcaption><em>Principle behind formation of an Einstein Ring image. Credit: ESA</em></figcaption></figure>



<p>The phenomenon of strong gravitational lensing has been first discussed already in the late 1700s, in the case of Newtonian gravity. But only Albert Einstein was able to calculate the correct angle of light-bending, using his General Theory of Relativity in 1915. In the years after, expeditions to properly measure the lensing effect for the mass of the sun during a solar eclipse then actually confirmed General Relativity based on the lensing effect. This was for the sun.</p>



<p>Coming back much more massive galaxies, the realisation that they could act as lenses – and image sources in the background – took until 1937 when Fritz Zwicky used the new knowledge about galaxies being really distant collections of stars like our own Milky Way. And in the 1960s it was realized that quasars, very bright, point-like active centers of galaxies, would make the perfect sources for lensing. And so it took until 1979, when the first “twin” quasar was found and identified as two images of the same background source – the first observed gravitational lens.</p>



<p>To dive deeper, the chance of a galaxy – or galaxy cluster – acting as a gravitational lens is highest for some intermediate distance from us observers, and for the source galaxy to be quite a bit further away. Most gravitational lens galaxies are therefore several billions of light-years away. So it’s extremely rare for lensing galaxies to be very close to us. A galaxy has to be very massive to have enough impact to create multiple lensed images, so what we would call “in our neighbourhood”, within a distance of 700 million light years, only 2400 galaxies exist that would be massive enough. Then, given the background distribution of available sources, of these nearby galaxies only 1 in 2000 has a statistical chance of actually creating a bright lensed system, with an increasing chance for fainter and fainter sources being lensed.</p>



<div><figure><a href="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed.jpg"><img decoding="async" width="1024" height="1024" src="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1024x1024.jpg" data-src="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1024x1024.jpg" alt="" data-srcset="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1024x1024.jpg 1024w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-300x300.jpg 300w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-150x150.jpg 150w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-768x768.jpg 768w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1536x1536.jpg 1536w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-2048x2048.jpg 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1024x1024.jpg 1024w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-300x300.jpg 300w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-150x150.jpg 150w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-768x768.jpg 768w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-1536x1536.jpg 1536w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing_embargoed-2048x2048.jpg 2048w"></a></figure><div>
<p><em>Euclid colour image of the full NGC 6505, composited using data from Euclid’s VIS high-resolution imager (structure), and the NISP near-infrared instrument (colours). The Einstein Ring is visible in around the very center of the galaxy. Credit: ESA/Euclid/Euclid Consortium/NASA, image processing by J.-C. Cuillandre, T. Li&nbsp; </em></p>



<p>(Click to enlarge)</p>
</div></div>



<p>So when ESA and Euclid Consortium scientists looked through the first science data, it did not come as a surprise that they spotted a first first gravitational lens – overall Euclid is expected to 100-fold the number of known lenses and find 100,000 during its 6-year mission. However it is beyond astonishing that the first lens is very nearby, actually located in an NGC galaxy – from the New General Catalogue of nearby galaxies – and that it shows a perfect Einstein Ring of the source galaxy. The lens galaxy is NGC 6505, located at redshift z=0.042, corresponding to a distance of only 590 million light-years. Only five similarly nearby other gravitational lenses are known so far, but none in such a prominent galaxy. NGC 6505 has been known since the year 1884, but no-one up to now was able to take an image as clear as Euclid has done. Follow-up spectroscopy with the Keck telescope on Hawaii and its KCWI integral-field spectrograph showed the source galaxy to lie at redshift z=0.406, or about 4.5 billion light-years distance from us.</p>



<p>While the image of NGC 6505 itself is already stunning, with many other galaxies around it and thousand’s more in the background, the surprise came with the first look into its very center: Is that a ring? And why did it look so peculiar? Galaxies can in fact have rings of stars near their centers that can form from motions of gas and stars – but normally only for rotating spiral galaxies, when at a certain distance from the center no net forces exist to move material further in or out. But this is not expected for a spheroidal galaxy as NGC 6505. With the peculiar structure of the right it was quickly clear that this must be the case of strong gravitational lensing, and the ring was actually not part of NGC 6505 but the distorted image of a background galaxy. A more close inspection and modelling extracted an almost too-good-to-be true Einstein Ring.</p>



<div><figure><img decoding="async" width="400" height="400" src="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed.jpg" data-src="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed.jpg" alt="" data-srcset="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed.jpg 400w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed-300x300.jpg 300w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed-150x150.jpg 150w" data-sizes="(max-width: 400px) 100vw, 400px" srcset="https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed.jpg 400w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed-300x300.jpg 300w, https://www.euclid-ec.org/wp-content/uploads/Euclid-EWS-NGC6505-EinsteinRing-Zoom_embargoed-150x150.jpg 150w"></figure><p><em>The lensed image of the background galaxy, in the very center of NGC 6505, as seen by Euclid’s VIS instrument. The background of NGC 6505’s light has been suppressed for clarity. The ring is made up of the stretched image of the background source galaxy. The bright center is the center of NGC 6505 itself. Credit: ESA/Euclid/Euclid Consortium/NASA, image processing by J.-C. Cuillandre, T. Li</em></p></div>



<p>But this is understandable: never before has an Einstein Ring be found in an NGC galaxy, and never has such an exquisite telescope looked at this galaxy so long. Euclid visited NGC 6505 and the region around it in its initial “Performance Verification” phase in late 2023. Euclid observed this region multiple times, with a total integration time of more than 11 hours with VIS and almost 2 hours with NISP, about 50x longer than most fields in Euclid ongoing Wide Survey. So this image and the whole field have an exceptional signal, low noise, and this allowed an unprecendented modelling of the lens system.</p>



<p>The science analysis was able to extract information about the amount of dark matter in the center of NGC 6505 (11.1% of the total central mass), as well as make very precise statements about the composition of low- and high-mass stars in the central region. Simulation show that the chance for finding a lens at this distance with the brighness that is seen in NGC 6505 was computed 1 in 2000 – and between 4 and 20 further nearby lenses are predicted to still be found in Euclid’s Wide Survey over the next years. However, the fact that this lens in NGC 6505 indeed exists and was observed by Euclid and recognised so quickly, was sheer coincidence – and attention to the data.</p>



<p>More lenses at larger distances <a href="https://www.euclid-ec.org/space-warps-euclid/" target="_blank" rel="noreferrer noopener">are currently being searched for</a> and first results for Euclid’s Q1 Data Release will be presented on the 19th of March 2025.</p>



<p>Further reading:</p>



<ul>
<li><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_discovers_a_stunning_Einstein_ring" target="_blank" rel="noreferrer noopener">Press release by ESA</a> on the NGC 6505 lens and full-resolution images</li>



<li>Original paper: <em>“Euclid: A complete Einstein ring in NGC 6500”</em>, O’Riordan et al. (2025), published by Astronomy &amp; Astrophysics, <a href="https://www.aanda.org/10.1051/0004-6361/202453014">https://www.aanda.org/10.1051/0004-6361/202453014</a></li>
</ul>

		
		
			</div>

	
</article></div>]]></description>
        </item>
    </channel>
</rss>