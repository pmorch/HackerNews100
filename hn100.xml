<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 10 Sep 2023 23:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[$400M in assets to bankrupt in 45-minutes because of a failed deployment (2014) (218 pts)]]></title>
            <link>https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/</link>
            <guid>37459495</guid>
            <pubDate>Sun, 10 Sep 2023 20:07:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/">https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/</a>, See on <a href="https://news.ycombinator.com/item?id=37459495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>I was speaking at a conference last year on the topics of DevOps, Configuration as Code, and Continuous Delivery and used the following story to demonstrate the importance making deployments fully automated and repeatable as part of a DevOps/Continuous Delivery initiative. Since that conference I have been asked by several people to share the story through my blog. This story is true – this really happened. This is my telling of the story based on what I have read (I was not involved in this).</p>
<p>This is the story of how a company with nearly $400 million in assets went bankrupt in 45-minutes because of a failed deployment.</p>
<h2>Background</h2>
<p>Knight Capital Group is an American global financial services firm engaging in <a href="http://en.wikipedia.org/wiki/Market_making">market making</a>, electronic execution, and institutional sales and trading. In 2012 Knight was the largest trader in US equities with market share of around 17% on each the NYSE and NASDAQ. Knight’s Electronic Trading Group (ETG) managed an average daily trading volume of more than 3.3 billion trades daily, trading over 21 billion dollars…daily. That’s no joke!</p>
<p>On July 31, 2012 Knight had approximately $365 million in cash and equivalents.</p>
<p>The NYSE was planning to launch a new <a href="http://www.nyse.com/press/1341483497580.html" target="_blank">Retail Liquidity Program</a> (a program meant to provide improved pricing to retail investors through retail brokers, like Knight) on August 1, 2012. In preparation for this event Knight updated their automated, high-speed, algorithmic router that send orders into the market for execution known as SMARS. One of the core functions of SMARS is to receive orders from other components of Knights trading platform (“parent” orders) and then send one or more “child” orders out for execution. In other words, SMARS would receive large orders from the trading platform and break them up into multiple smaller orders in order to find a buyer/seller match for the volume of shares. The larger the parent order, the more child orders would be generated.</p>
<p>The update to SMARS was intended to replace old, unused code referred to as “Power Peg” – functionality that Knight hadn’t used in 8-years (why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the point). The code that that was updated repurposed an old flag that was used to activate the Power Peg functionality. The code was thoroughly tested and proven to work correctly and reliably. What could possibly go wrong?</p>
<h2>What Could Possibly Go Wrong? Indeed!</h2>
<p>Between July 27, 2012 and July 31, 2012 Knight manually deployed the new software to a limited number of servers per day – eight (8) servers in all. This is what the <a href="http://www.sec.gov/litigation/admin/2013/34-70694.pdf" target="_blank">SEC filing</a> says about the manual deployment process (BTW – if there is an SEC filing about your deployment something may have gone terribly wrong).</p>
<blockquote><p>“During the deployment of the new code, however, one of Knight’s technicians did not copy the new code to one of the eight SMARS computer servers. Knight did not have a second technician review this deployment and no one at Knight realized that the Power Peg code had not been removed from the eighth server, nor the new RLP code added. Knight had no written procedures that required such a review.<br>
SEC Filing | Release No. 70694 | October 16, 2013</p></blockquote>
<p>At 9:30 AM Eastern Time on August 1, 2012 the markets opened and Knight began processing orders from broker-dealers on behalf of their customers for the new Retail Liquidity Program. The seven (7) servers that had the correct SMARS deployment began processing these orders correctly. Orders sent to the eighth server triggered the supposable repurposed flag and brought back from the dead the old Power Peg code.</p>
<h2>Attack of the Killer Code Zombies</h2>
<p>Its important to understand what the “dead” Power Peg code was meant to do. This functionality was meant to count the shares bought/sold against a parent order as child orders were executed. Power Peg would instruct the the system to stop routing child orders once the parent order was fulfilled. Basically, Power Peg would keep track of the child orders and stop them once the parent order was completed. In 2005 Knight moved this cumulative tracking functionality to an earlier stage in the code execution (thus removing the count tracking from the Power Peg functionality).</p>
<p>When the Power Peg flag on the eighth server was activated the Power Peg functionality began routing child orders for execution, but wasn’t tracking the amount of shares against the parent order – somewhat like an endless loop.</p>
<h2>45 Minutes of Hell</h2>
<p>Imagine what would happen if you had a system capable of sending automated, high-speed orders into the market without any tracking to see if enough orders had been executed. Yes, it was that bad.</p>
<p>When the market opened at 9:30 AM people quickly knew something was wrong. By 9:31 AM it was evident to many people on Wall Street that something serious was happening. The market was being flooded with orders out of the ordinary for regular trading volumes on certain stocks. By 9:32 AM many people on Wall Street were wondering why it hadn’t stopped. This was an eternity in high-speed trading terms. Why hadn’t someone hit the kill-switch on whatever system was doing this? As it turns out there was no kill switch. During the first 45-minutes of trading Knight’s executions constituted more than 50% of the trading volume, driving certain stocks up over 10% of their value. As a result other stocks decreased in value in response to the erroneous trades.</p>
<p>To make things worse, Knight’s system began sending automated email messages earlier in the day – as early as 8:01 AM (when SMARS had processed orders eligible for pre-market trading). The email messages references SMARS and identified an error as “Power Peg disabled.” Between 8:01 AM and 9:30 AM there were 97 of these emails sent to Knight personnel. Of course these emails were not designed as system alerts and therefore no one looked at them right away. Oops.</p>
<p>During the 45-minutes of Hell that Knight experienced they attempted several counter measures to try and stop the erroneous trades. There was no kill-switch (and no documented procedures for how to react) so they were left trying to diagnose the issue in a live trading environment where 8 million shares were being traded every minute . Since they were unable to determine what was causing the erroneous orders they reacted by uninstalling the new code from the servers it was deployed to correctly. In other words, they removed the working code and left the broken code. This only amplified the issues causing additional parent orders to activate the Power Peg code on all servers, not just the one that wasn’t deployed to correctly. Eventually they were able to stop the system – after 45 minutes of trading.</p>
<p>In the first 45-minutes the market was open the Power Peg code received and processed 212 parent orders. As a result SMARS sent millions of child orders into the market resulting in 4 million transactions against 154 stocks for more than 397 million shares. For you stock market junkies this meant the Knight assumed approximately $3.5 billion net long positions in 80 stocks and $3.15 billion net short positions in 74 stocks. In laymen’s terms, Knight Capital Group realized a $460 million loss in 45-minutes. Remember, Knight only has $365 million in cash and equivalents. In 45-minutes Knight went from being the largest trader in US equities and a major market maker in the NYSE and NASDAQ to bankrupt. They had 48-hours to raise the capital necessary to cover their losses (which they managed to do with a $400 million investment from around a half-dozen investors). Knight Capital Group was eventually acquired by Getco LLC (December 2012) and the merged company is now called KCG Holdings.</p>
<h2>A Lesson to Learn</h2>
<p>The events of August 1, 2012 should be a lesson to all development and operations teams. It is not enough to build great software and test it; you also have to ensure it is delivered to market correctly so that your customers get the value you are delivering (and so you don’t bankrupt your company). The engineer(s) who deployed SMARS are not solely to blame here – the process Knight had set up was not appropriate for the risk they were exposed to. Additionally their process (or lack thereof) was inherently prone to error. Any time your deployment process relies on humans reading and following instructions you are exposing yourself to risk. Humans make mistakes. The mistakes could be in the instructions, in the interpretation of the instructions, or in the execution of the instructions.</p>
<p>Deployments need to be automated and repeatable and as free from potential human error as possible. Had Knight implemented an automated deployment system – complete with configuration, deployment and test automation – the error that cause the Knightmare would have been avoided.</p>
<p>A couple of the principles for Continuous Delivery apply here (even if you are not implementing a full Continuous Delivery process):</p>
<ul>
<li>Releasing software should be a repeatable, reliable process.</li>
<li>Automate as much as is reasonable.</li>
</ul>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Senior Engineer's Check-List (2019) (186 pts)]]></title>
            <link>https://littleblah.com/post/2019-09-01-senior-engineer-checklist/</link>
            <guid>37458283</guid>
            <pubDate>Sun, 10 Sep 2023 17:57:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://littleblah.com/post/2019-09-01-senior-engineer-checklist/">https://littleblah.com/post/2019-09-01-senior-engineer-checklist/</a>, See on <a href="https://news.ycombinator.com/item?id=37458283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div id="control-accordion">
<h3>Controls (click to expand)</h3>

</div>
<p>
This is a simple checklist, and while it is useful to any software engineer, it is especially useful to senior engineers.
</p><table id="datatable">
<thead>
<tr>
<th rowspan="1">#</th>
<th rowspan="1">Task</th>
<th colspan="1">Effort</th>
<th colspan="1">Category</th>
<th colspan="2">Impact</th>
</tr>
<tr>
<th></th>
<th>
Task
</th>
<th>
</th>
<th>
</th>
<th>
Career
</th>
<th>
Company
</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Understand the business aspect of your work, and what makes money. Eventually, only that matters.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>2</td>
<td>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.</td>
<td>medium</td>
<td>hiring</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>3</td>
<td>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>4</td>
<td>Question everything and ask "why" repetitively until you get to the root of problems and situations.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>5</td>
<td>Demand accountability and ownership from others.</td>
<td>high</td>
<td>leadership</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>6</td>
<td>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>7</td>
<td>Work towards disambiguating ambiguous problem statements.</td>
<td>high</td>
<td>leadership</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>8</td>
<td>Cultivate relationships with other teams and develop trust.</td>
<td>high</td>
<td>network</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>9</td>
<td>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.</td>
<td>medium</td>
<td>network</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>10</td>
<td>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.</td>
<td>medium</td>
<td>network</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>11</td>
<td>Follow the principles of extreme ownership.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>12</td>
<td>Have strong mentors to help you navigate and grow in the company.</td>
<td>high</td>
<td>mentor</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>13</td>
<td>Take projects with high risk and high rewards.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>14</td>
<td>Strive for deep technical expertise in technologies used in your team.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>15</td>
<td>Ask for stretch projects from your manager, or help her identify one for you.</td>
<td>medium</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>16</td>
<td>Discuss the goals of your manager, and how you align your work with it.</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>17</td>
<td>Invest time in networking effectively with seniors, peers, and juniors.</td>
<td>medium</td>
<td>network</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>18</td>
<td>Be a mentor to a couple of junior engineers.</td>
<td>medium</td>
<td>mentor</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>19</td>
<td>Increase your breadth of knowledge in the domain of your team/company.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>20</td>
<td>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.</td>
<td>medium</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>21</td>
<td>Discuss problems with your manager, but have some solutions beforehand.</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>22</td>
<td>Increase your breadth of knowledge in technology.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>23</td>
<td>Explore emerging technologies by building small prototypes.</td>
<td>high</td>
<td>growth</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>24</td>
<td>Read a few technical books every year.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>25</td>
<td>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
<tr>
<td>26</td>
<td>Schedule a regular one-on-one with your manager</td>
<td>low</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>27</td>
<td>Schedule a regular one-on-one with your skip level manager</td>
<td>low</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>28</td>
<td>[Reminder] One-on-one usually is not a status meeting</td>
<td>medium</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>29</td>
<td>Involve the manager in your personal life (just a little though)</td>
<td>low</td>
<td>managers</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>30</td>
<td>Actively seek feedback from your manager</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>31</td>
<td>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>32</td>
<td>Keep your manager up-to-date in things you are blocked on</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>33</td>
<td>Keep your manager up-to-date on people you have difficulty working with</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>34</td>
<td>Give constructive feedback to your manager</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>35</td>
<td>If you are overworked, let your manager know</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>36</td>
<td>If you are under-utilized, ask your manager for areas to explore</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>37</td>
<td>If you have an ineffective or neglectful manager, talk to your manager about your expectations</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>38</td>
<td>If you have a micromanager, talk to your manager about your expectations</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>39</td>
<td>If you have an abusive manager, talk to your skip manager or HR with data points</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>40</td>
<td>If you have an ineffective skip manager and ineffective manager, switch the team or company</td>
<td>high</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>41</td>
<td>If you do not have a cordial relationship with your manager, switch the team or company</td>
<td>high</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>42</td>
<td>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>43</td>
<td>Measure what you want to improve. Make efforts measurable</td>
<td>medium</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>44</td>
<td>Maintain high visibility of projects which have a high risk</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>45</td>
<td>To deal with difficult folks, discuss with your managers and mentors</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>46</td>
<td>To deal with difficult folks, fall back to first principles</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>47</td>
<td>Be reachable to other engineers</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>48</td>
<td>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required</td>
<td>high</td>
<td>leadership</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>49</td>
<td>Simplify code, systems, and architectures relentlessly</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>50</td>
<td>Demand high-quality work from others, but be pragmatic</td>
<td>medium</td>
<td>technology</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>51</td>
<td>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>52</td>
<td>Document extensively, and demand it from others. Document "why" more than "how"</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>53</td>
<td>Avoid politics, but have right folks vouch for your work</td>
<td>high</td>
<td>politics</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>54</td>
<td>When dealing with politics, fall back to first principles</td>
<td>high</td>
<td>politics</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>55</td>
<td>If politics thrives due to team or company culture, switch</td>
<td>high</td>
<td>politics</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>56</td>
<td>Try not to get involved in office gossip</td>
<td>low</td>
<td>politics</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>57</td>
<td>Avoid stretching yourself too thin to be effective</td>
<td>medium</td>
<td>leadership</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>58</td>
<td>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production</td>
<td>low</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>59</td>
<td>Before you suggest major refactors, ensure you understand the system deeply</td>
<td>medium</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
<tr>
<td>60</td>
<td>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time</td>
<td>medium</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
</tbody>
</table>
<div id="simpleList">
<ol>
<li>Understand the business aspect of your work, and what makes money. Eventually, only that matters.</li>
<li>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.</li>
<li>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.</li>
<li>Question everything and ask "why" repetitively until you get to the root of problems and situations.</li>
<li>Demand accountability and ownership from others.</li>
<li>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.</li>
<li>Work towards disambiguating ambiguous problem statements.</li>
<li>Cultivate relationships with other teams and develop trust.</li>
<li>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.</li>
<li>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.</li>
<li>Follow the principles of extreme ownership.</li>
<li>Have strong mentors to help you navigate and grow in the company.</li>
<li>Take projects with high risk and high rewards.</li>
<li>Strive for deep technical expertise in technologies used in your team.</li>
<li>Ask for stretch projects from your manager, or help her identify one for you.</li>
<li>Discuss the goals of your manager, and how you align your work with it.</li>
<li>Invest time in networking effectively with seniors, peers, and juniors.</li>
<li>Be a mentor to a couple of junior engineers.</li>
<li>Increase your breadth of knowledge in the domain of your team/company.</li>
<li>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.</li>
<li>Discuss problems with your manager, but have some solutions beforehand.</li>
<li>Increase your breadth of knowledge in technology.</li>
<li>Explore emerging technologies by building small prototypes.</li>
<li>Read a few technical books every year.</li>
<li>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.</li>
<li>Schedule a regular one-on-one with your manager</li>
<li>Schedule a regular one-on-one with your skip level manager</li>
<li>[Reminder] One-on-one usually is not a status meeting</li>
<li>Involve the manager in your personal life (just a little though)</li>
<li>Actively seek feedback from your manager</li>
<li>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail</li>
<li>Keep your manager up-to-date in things you are blocked on</li>
<li>Keep your manager up-to-date on people you have difficulty working with</li>
<li>Give constructive feedback to your manager</li>
<li>If you are overworked, let your manager know</li>
<li>If you are under-utilized, ask your manager for areas to explore</li>
<li>If you have an ineffective or neglectful manager, talk to your manager about your expectations</li>
<li>If you have a micromanager, talk to your manager about your expectations</li>
<li>If you have an abusive manager, talk to your skip manager or HR with data points</li>
<li>If you have an ineffective skip manager and ineffective manager, switch the team or company</li>
<li>If you do not have a cordial relationship with your manager, switch the team or company</li>
<li>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness</li>
<li>Measure what you want to improve. Make efforts measurable</li>
<li>Maintain high visibility of projects which have a high risk</li>
<li>To deal with difficult folks, discuss with your managers and mentors</li>
<li>To deal with difficult folks, fall back to first principles</li>
<li>Be reachable to other engineers</li>
<li>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required</li>
<li>Simplify code, systems, and architectures relentlessly</li>
<li>Demand high-quality work from others, but be pragmatic</li>
<li>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising</li>
<li>Document extensively, and demand it from others. Document "why" more than "how"</li>
<li>Avoid politics, but have right folks vouch for your work</li>
<li>When dealing with politics, fall back to first principles</li>
<li>If politics thrives due to team or company culture, switch</li>
<li>Try not to get involved in office gossip</li>
<li>Avoid stretching yourself too thin to be effective</li>
<li>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production</li>
<li>Before you suggest major refactors, ensure you understand the system deeply</li>
<li>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time</li>
</ol>
</div>
<div id="simpleDetailedList">
<ol>
<li>Understand the business aspect of your work, and what makes money. Eventually, only that matters.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: hiring</li>
</span>
</ul>
</li>
<li>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Question everything and ask "why" repetitively until you get to the root of problems and situations.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Demand accountability and ownership from others.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Work towards disambiguating ambiguous problem statements.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Cultivate relationships with other teams and develop trust.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Follow the principles of extreme ownership.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Have strong mentors to help you navigate and grow in the company.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: mentor</li>
</span>
</ul>
</li>
<li>Take projects with high risk and high rewards.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Strive for deep technical expertise in technologies used in your team.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Ask for stretch projects from your manager, or help her identify one for you.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Discuss the goals of your manager, and how you align your work with it.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Invest time in networking effectively with seniors, peers, and juniors.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be a mentor to a couple of junior engineers.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: mentor</li>
</span>
</ul>
</li>
<li>Increase your breadth of knowledge in the domain of your team/company.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Discuss problems with your manager, but have some solutions beforehand.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Increase your breadth of knowledge in technology.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Explore emerging technologies by building small prototypes.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Read a few technical books every year.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Schedule a regular one-on-one with your manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Schedule a regular one-on-one with your skip level manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>[Reminder] One-on-one usually is not a status meeting
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Involve the manager in your personal life (just a little though)
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Actively seek feedback from your manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date in things you are blocked on
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date on people you have difficulty working with
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Give constructive feedback to your manager
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you are overworked, let your manager know
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you are under-utilized, ask your manager for areas to explore
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an ineffective or neglectful manager, talk to your manager about your expectations
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have a micromanager, talk to your manager about your expectations
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an abusive manager, talk to your skip manager or HR with data points
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an ineffective skip manager and ineffective manager, switch the team or company
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you do not have a cordial relationship with your manager, switch the team or company
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Measure what you want to improve. Make efforts measurable
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Maintain high visibility of projects which have a high risk
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>To deal with difficult folks, discuss with your managers and mentors
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>To deal with difficult folks, fall back to first principles
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be reachable to other engineers
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Simplify code, systems, and architectures relentlessly
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Demand high-quality work from others, but be pragmatic
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Document extensively, and demand it from others. Document "why" more than "how"
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Avoid politics, but have right folks vouch for your work
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>When dealing with politics, fall back to first principles
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>If politics thrives due to team or company culture, switch
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>Try not to get involved in office gossip
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>Avoid stretching yourself too thin to be effective
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Before you suggest major refactors, ensure you understand the system deeply
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
</ol>
</div>
<hr>
<h2>Resources</h2>
<div id="accordion">
<h3>click to expand</h3>
<div>
<p><span>Note</span>: <a href="https://github.com/littleblah/senior-engineer-checklist" target="_blank">This is the source</a> of the data in the checklist. Pull requests are welcome.</p>
<p>This page refreshes daily. So this page might be lagging by couple of hours.</p>
<h2>My Definitions</h2>
<p>These are my definitions, and may not exactly align with yours. If you want, you can download this list as a CSV (download button is present in table view), and create your own version.</p>
<p>
<span>Senior Engineer</span>: Someone who has these basic attributes
</p><ul>
<li>Couple of years of Relevant Practical Experience <i>(Exact number of years is not easy to identify since we are looking at having variety of experiences over time rather than similar experience repeated over years)</i> </li>
<li>Influence within and across teams</li>
<li>Breadth of knowledge of technologies</li>
<li>Depth in one or more domains and/or technologies</li>
</ul>

<p><span>Effort</span>: Effort of a task as compared to others in the list. This may not exactly align with level of effort of the task for you.</p>
<p><span>Category</span>: Category of the task.</p>
<p><span>Career Impact</span>: Level of impact on your career growth.</p>
<p><span>Company Impact</span>: Level of impact on your company and your team.</p>
<p><span>Difficulty</span>: I did not see a point of listing difficulty. What may be difficult for one may not be for other.</p>
<h2>References</h2>
<ul>
<h3>Books (Non-affiliate links)</h3>
<ul>
<li>
<a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897" target="_blank">The manager's Path</a>
</li>
<li>
<a href="https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959" target="_blank">The Mythical Man-Month</a>
</li>
</ul>
<h3>Articles and Discussions</h3>
<ul>
</ul>
</ul>
</div>
</div>
<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Goodbye to Thien-Thi Nguyen (170 pts)]]></title>
            <link>https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html</link>
            <guid>37457796</guid>
            <pubDate>Sun, 10 Sep 2023 17:08:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html">https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html</a>, See on <a href="https://news.ycombinator.com/item?id=37457796">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center>




</center>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<hr>
[<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00712.html">Date Prev</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00714.html">Date Next</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00705.html">Thread Prev</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00715.html">Thread Next</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/index.html#00713">Date Index</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/threads.html#00713">Thread Index</a>]

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->

<hr>
<table>
<tbody>
<tr>
<td>
<b>From</b>: </td>
<td>
Amin Bandali</td>
</tr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->

<tr>
<td>
<b>Subject</b>: </td>
<td>
Goodbye to Thien-Thi Nguyen</td>
</tr>

<tr>
<td>
<b>Date</b>: </td>
<td>
Sat, 09 Sep 2023 23:55:05 -0400</td>
</tr>

<tr>
<td>
<b>User-agent</b>: </td>
<td>
Gnus/5.13 (Gnus v5.13) Emacs/30.0.50 (gnu/linux)</td>
</tr>

</tbody>
</table>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre>We have learned with deep sadness that Thien-Thi Nguyen (ttn) died in
October 2022.  Thien-Thi was a hacker, artist, writer, and long-time
maintainer and contributor to many GNU programs as well as other free
software packages.  He was the GNU maintainer of the rcs, guile-sdl,
alive, and superopt packages, and he was working on GNU Go as well.

Thien-Thi especially loved GNU Emacs, GNU Taler, and GNU Go: he was
the author and maintainer of the xpm, gnugo, ascii-art-to-unicode,
and hideshow GNU Emacs packages and made substantial contributions to
many others such as vc, as well as to GNU Taler and its documentation.

We greatly miss Thien-Thi in the free software community - his death
is a great loss to the Free World.


</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>

<hr>
<table>
<tbody><tr><td>[Prev in Thread]</td>
<td><b>Current Thread</b></td>
<td>[Next in Thread]</td></tr></tbody></table>
<ul>
<li><span color="#666666"><strong>Goodbye to Thien-Thi Nguyen</strong>,
<em>Amin Bandali</em></span>&nbsp;<b>&lt;=</b>
</li></ul>

<hr>
<!--X-Follow-Ups-End-->
<!--X-References-->
<!--X-References-End-->
<!--X-BotPNI-->
<ul>
<li>Prev by Date:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00712.html">Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Next by Date:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00714.html">Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Previous by thread:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00705.html">Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Next by thread:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00715.html">Re: Clojure mode</a></strong>
</li>
<li>Index(es):
<ul>
<li><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/index.html#00713"><strong>Date</strong></a></li>
<li><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/threads.html#00713"><strong>Thread</strong></a></li>
</ul>
</li>
</ul>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Bézier curves for vector graphics (125 pts)]]></title>
            <link>https://ad8e.pages.dev/curve</link>
            <guid>37457051</guid>
            <pubDate>Sun, 10 Sep 2023 15:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ad8e.pages.dev/curve">https://ad8e.pages.dev/curve</a>, See on <a href="https://news.ycombinator.com/item?id=37457051">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><h2>Remodeling Béziers</h2>
<p>This article is about how math creates an easier-to-use version of Béziers. We'll show examples of issues with Béziers, then discuss the issues academically, then derive a curve that fixes the problems (and can draw circles!).</p>
<p>This is a Bézier. You can drag the handles. The green lines represent curvature.</p>

<p>Béziers are a little unintuitive to use, because it's not always clear where to put the control points, or how long the handles should be. This leads to a lot of trial and error. To see for yourself, use the handles below to align the black and pink curves.</p>

<p><label>Show answer</label></p>
<p>Click "Show answer" when done. You probably got the curve right, but you had to go back and forth between the two handles, iterating the curve. You couldn't set each handle to the correct position on the first try. (I can't do it either.)</p>
<p>Here's another one:</p>

<p><label>Show answer</label></p>
<p>You probably got the curve close, but your handles are way off.</p>
<p>Adjust the middle node:</p>

<p><label>Show answer</label></p>
<p>I don't know of a reasonable way to guess the right location.</p>
<p>These illustrate the following problems with Béziers:</p>
<ol>
<li>It's hard to guess the correct handle length on the first try; you have to see the result and adjust iteratively.</li>
<li>The correct value of a handle depends on too many other things. If you move a node or handle, then you have to adjust its handles, then re-adjust the neighboring handles, then re-adjust the first handles, then re-adjust the neighboring handles, etc. You can't set each handle to the correct value on its own. In mathematics, this means they are "non-orthogonal".</li>
<li>Widely different inputs can lead to similar outputs, and then you have to adjust neighboring handles a lot. In mathematics, this means the output-to-input map is "poorly conditioned". This becomes an issue when it is not axis-aligned, like the second example.</li>
<li>There's no obvious way to figure out where to put nodes.</li>
</ol>
<p>And there are three more problems:</p>
<ol start="5">
<li>Béziers can't represent circles. If you try to approximate one by hand, it'll look lopsided.</li>
<li>Deleting existing nodes from a curve creates a mess.</li>
<li>It's hard to keep curvature continuous across a node; you'd have to stare at curvature combs and fiddle a lot.</li>
</ol>
<p>Mathematics resolves these issues.</p>
<h2>Local and global</h2>
<p>The words "local" and "global" appear in disparate domains in mathematics, like parallel evolution. These concepts are broadly useful.</p>
<p>Small and simple objects are "local". Large and complex objects are "global". For example, your house is a global object, and each room is a local object. If you want to know whether the whole house is painted white (a global property), you can check whether each individual room is painted white (a local property). This splits the global task into smaller local tasks.</p>
<p>The key insight is: Local properties are easy, and global properties are hard. Whenever global objects can be decomposed into local objects, it's more convenient to work with the local objects. This is the backbone of the <a href="https://math.stackexchange.com/questions/34053/list-of-local-to-global-principles">local to global principle</a>.</p>
<p>A curve is determined by a finite number of points on the screen - those points are the artist's interface. These points should control the curve <em>locally</em>, determining the curve in a small region.</p>
<p>In geometry, the standard local description of a curve is its derivatives, like a Taylor series. (We can safely ignore analyticity, thanks to Stone-Weierstrass.) The zeroth derivative is position - where the curve is. The first derivative is direction - which way the curve points. The second derivative is curvature - how curvy the curve is. These three parameters are easy for humans to understand, and artists don't use higher derivatives. So the points should control position, direction, and curvature. These three parameters produce a circular arc.</p>
<p>Local control is easy to draw with, because you just need to match behavior at points:</p>
<ul>
<li>You understand what an input point does - it chooses a circular arc for the nearby curve.</li>
<li>It's easy to position input points - put them where you want to change the curve.</li>
</ul>
<p>This explains the underlying issue with Béziers. Bézier controls are local for position and direction, but not local for curvature. Local position and local direction coincide with the easy tasks - placing the node on the curve and setting the handle direction. Non-local curvature coincides with the hard task - setting handle length. So it's failure of locality causing the issues.</p>
<h2>Given local behavior, how do we create a global curve?</h2>
<p>The user only inputs a finite number of points. It's best if the correct curve extends naturally between these points, requiring as few correction points as possible.</p>
<p>Because of locality, a curve between two points is determined solely by these two points, and ignores any points farther away.</p>
<p>Each point specifies either 0, 1, or 2 derivatives. Remember that the 0th derivative is position, the 1st derivative is direction, and the 2nd derivative is curvature. If you specify a higher derivative (like curvature), you specify all its lower derivatives as well (like position and direction). So given two points and a number of derivatives for each point (0 1 2), we have to come up with a curve.</p>
<p>If each point specifies only its position (the derivative numbers are 0 0), the curve is a line.</p>
<p>If one point specifies direction and the other specifies position (derivatives are 1 0), then the curve is a circle.</p>
<p>That's the easy cases. For the rest, we need math. We specify some possible axioms, then choose which ones to satisfy.</p>
<ol>
<li>Primacy of lines and circles. The desired curves are disproportionately lines and circles. If the points express a line or circle, then the curve is a line or circle.</li>
<li>Affirmation invariance. Adding extra derivatives that agree with the existing curve should keep the curve the same.</li>
<li>Affine transformation. Affine transformation of the points causes affine transformation of the curve. This is important for drawing 3D objects (which most things are). For example, ellipses are circles on a 3D plane, projected down to your 2D surface. They are an affine transformation of a circle.</li>
<li>Subdivision (strong). If we truncate a curve specified by points with N and M derivatives, then the two endpoints of the snipped curve have N and M derivatives.</li>
<li>Subdivision (weak). If we truncate a curve specified by points with N and M derivatives, then the two endpoints of the snipped curve have at most max(N, M) derivatives.</li>
<li>Finite length. Curves don't travel to infinity. (For example, a parabola does.)</li>
<li>Non-singularity. When the input varies smoothly, the output also varies smoothly.</li>
</ol>
<p>Unfortunately, not all these axioms can be satisfied simultaneously. So we have to make some tradeoffs, just like <a href="https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem">Arrow's impossibility theorem</a>. An example is that axioms 1 + 3 together create the conic sections - whose paths travel to infinity, and hence cannot satisfy axioms 6 or 7.</p>
<p>If both points specify direction (1 1), then a parabola satisfies axioms 3, 4, and 5. It's equivalent to a quadratic Bézier. The best UI control is the intersection of the handles, which satisfies axiom 7.</p>
<p>An alternative is to choose <code>sin(angle/2)</code> as the weight for a rational quadratic Bézier. This satisfies axioms 1, 2, and 6 (and 7 with the right UI). The curve is always an ellipse. If the directions are perpendicular, then the points are the maximum and minimum curvature points of an ellipse.</p>
<p>If one point specifies direction and curvature, and the other point specifies only position (2 0), then the previous choices are still available: ellipses and parabolas. There's an additional alternative, where the direction and curvature are mirrored to the other point across the line between them. This satisfies axioms 1, 2, 3, and symmetry.</p>
<p>If one point specifies direction and curvature, and the other point specifies direction (2 1), then we get a uniquely determined conic section, and axioms 1, 2, 3, 4, and 5 are satisfied. These are ellipses, parabolas, and hyperbolas. Curves which travel to infinity should have their handles flipped.</p>
<p>If both points specify direction and curvature (2 2), then the curve is overspecified for a conic, so we have choices to make.</p>
<p>Here's one possible solution. Blue circles control curvature.</p>

Now blue circular handles control radius:

<p>The handles determine the radius of a circular arc near the point. The in-between is interpolated.</p>
<p>There are better curves; I didn't look too hard. This one respects axioms 1, 2, 3, and 6. 4 and 5 are probably achievable with a week of work. This one happens to be computationally efficient. It flips when the handles cross parallel, but this flip can be adjusted with more work (letting you represent a whole circle with one point).</p>
<p>This curve is a rational cubic Bézier. You can read it in <code>final3()</code> in the source code, or follow these steps:</p>
<ol>
<li>Affine transform the two input points so that the intersection of their directions creates an isosceles right triangle, with the two points forming the hypotenuse. (Like the first of the two diagrams above.)</li>
<li>Let the curvatures of the points be <code>c</code> and <code>k</code>. Draw a rational cubic Bézier. Let <code>r = √(8c)/3/(c + k)</code>, <code>s = √(8k)/3/(c + k)</code>. The second control point has weight <code>w = 3krr/2 + s</code> and is proportion <code>r/w</code> between the first and second control points. The third control point is calculated symmetrically by exchanging the input points.</li>
<li>Affine transform the curve back to the original position.</li>
</ol>
<p>The old list of problems with Béziers is fixed:</p>
<ol>
<li>The handle length can be set on the first or second try; just match a small arc around the point.</li>
<li>The correct handle length only depends on a small region around the point, not anything else. After it's set, moving nodes and other handles won't interfere; it'll still be correct.</li>
<li>High condition numbers for the inverse map are axis-aligned.</li>
<li>Placing nodes is simple. (Put them at the largest deviations, and on inflection points.)</li>
<li>Circles are easy to draw.</li>
<li>Deleting existing nodes from a curve leaves the curve in good shape.</li>
<li>The curvature is well behaved (the green lines). At a smooth node, the curvature is equal on both sides - no jump discontinuities.</li>
</ol>
<p>Here's a trick that turns curve-finding from a boring math problem into an interesting geometry problem. The subdivision axiom is secretly reversible:</p>
<ul>
<li>Extension axiom: Any curve has a unique curve that extends it, which produces the original curve when subdivided. This extension continues forever, so the curve must either loop back to itself or approach a singularity. This infinitely-continuing curve is called a "parent curve".</li>
</ul>
<p>Finding a set of parent curves is a very intuitive process. Each parent curve extends infinitely, ending in loops or singularities, and every curve is just a short snippet of a parent curve. For example, the parent curves for conics are the parabolas and hyperbolas (which extend forever) and the ellipses (which loop). You can try to construct your own parent curves, using these constraints as a guide:</p>
<ol start="0">
<li>Any pair of points, containing the information {position, direction, curvature}, must belong to exactly one parent curve.
<ul>
<li>Since conics create every valid symmetric tuple, your parent curves can have no axis of symmetry unless they are conics.</li>
</ul>
</li>
<li>Parent curves should be useful curves to draw with. So singularities should generally be points at infinity. Spirals aren't useful, so they are disallowed.</li>
<li>The curves should behave well with inflection points; this is necessary to cover the lack of inflection points with conic sections. So the curve should be non-degenerate when one point has curvature 0.</li>
</ol>
<p>Which curves do you think are elegant or useful? Is there an optimal set of parent curves?</p>
<p>Here are some possible approaches:</p>
<ol>
<li>Try existing classes of curves with nice properties, like cardioids, conic generalizations, or other geometric shapes. See if any of them form parametrized families. <a href="https://en.wikipedia.org/wiki/List_of_curves">Here's a list.</a></li>
<li>Create parametrized families of curves directly. The interesting case is with singularities at infinity, where curvatures approach 0. Some promising classes are <a href="https://sci-hub.ru/https://doi.org/10.1016/j.cagd.2009.06.003">complex rational Béziers</a>, rational Béziers, and curves on the complex plane. For example, conic sections have a nice polar form.</li>
<li>Eyeball the loop case, where one curvature is zero and the other is not.</li>
</ol>
<h2>Future work</h2>
<p>These control systems can be extended to curves and surfaces in 3D. And to curves on 3D surfaces.</p>
<p>With a suitable UI, animations should be convenient. Conics express the sine wave, which is the physically natural "ease-in-out", a spring force. They also express the parabola, the physically natural "ease-in", a constant force (like gravity).</p>
<p>2 2's curve can be improved. There's also alternative UIs for the node handles that allow inflection points away from input points.</p>
<p>If you develop drawing software, you can implement these curves. They are easier to learn than Béziers, and are easier to be accurate with. No more staring at curvature combs needed.</p>
<p>Discussion: <a href="https://news.ycombinator.com/item?id=37457051">Hacker News</a>, <a href="https://app.element.io/#/room/#localcurves:matrix.org">Temporary chatroom</a></p>
<p>Author: Kevin Yin</p>
<p>Visualizations are thanks to <a href="https://omrelli.ug/g9/gallery/">G9</a> and took minimal effort.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peredvizhnikov Engine is a fully lock-free game engine written in C++20 (263 pts)]]></title>
            <link>https://github.com/eduard-permyakov/peredvizhnikov-engine</link>
            <guid>37456471</guid>
            <pubDate>Sun, 10 Sep 2023 15:03:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine">https://github.com/eduard-permyakov/peredvizhnikov-engine</a>, See on <a href="https://news.ycombinator.com/item?id=37456471">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/docs/images/peredvizhnikov-engine-logo.png"><img src="https://github.com/eduard-permyakov/peredvizhnikov-engine/raw/master/docs/images/peredvizhnikov-engine-logo.png" alt="logo"></a></h2>
<p dir="auto">Peredvizhnikov Engine is a fully lock-free game engine written in C++20. It implements the <em>actor model</em> of concurrent computation on top of the language's coroutine primitives.</p>
<p dir="auto">Using the <em>actor model</em> abstraction, it is possible to develop complex, parallel logic while being wholly isolated from the details of inter-thread synchronization. A completely lock-free implementation of the model brings with it many advantages, namely guaranteed progress even in the presence of arbitrary thread termination, deadlock-freedom, predictable latency in reacting to critical events, and fault-tolerance.</p>
<p dir="auto">In fact, the degree of fault-tolerance in Peredvizhnikov Engine is so great, that the engine is guaranteed to continue running even when any of the worker threads is asynchronously killed. You may <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/test/test_fault_tolerance.cpp">verify this yourself</a>.</p>
<p dir="auto">The implementation is founded upon a mix of classical and novel ideas in lock-free programming. It includes <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_struct.cpp">a novel implementation of Software Transactional Memory</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/lockfree_sequenced_queue.cpp">a new kind of lock-free queue</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_work.cpp">an original lock-free serialization primitive</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_shared_ptr.cpp">a lock-free std::atomic_shared_ptr</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/scheduler.cpp">a lock-free scheduler</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/alloc.cpp">a lock-free memory allocator</a> and plenty more!</p>
<p dir="auto">For a detailed breakdown of all the lock-free algorithms that went into realizing the engine, rationale for the design, benchmarks, and more, please take a look at the accompanying document: <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/docs/lockfree.pdf">Peredvizhnikov Engine: Design and Implementation of a Completely Lock-Free Scheduler</a>.</p>
<h2 tabindex="-1" dir="auto">Building Peredvizhnikov Engine</h2>
<p dir="auto">At the moment, the only supported platform is Linux. Clang++ 16 is required to build the sources.</p>
<ol dir="auto">
<li><code>git clone https://github.com/eduard-permyakov/peredvizhnikov-engine.git</code></li>
<li><code>cd peredvizhnikov-engine</code></li>
<li><code>make -j16 DEBUG=0</code></li>
</ol>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">The source code of Peredvizhnikov Engine is freely available under the GPLv3 license. However, I may grant permission to use parts or all of the code under a different license on a case-by-case basis. Please inquire by e-mail.</p>
<h2 tabindex="-1" dir="auto">Contact</h2>
<p dir="auto">You may contact me with any questions, comments, or concerns pertaining to the source code or the underlying algorithms.</p>
<p dir="auto">In addition, I am currently actively seeking employment. Please don't hesitate to reach out regarding any suitable opportunities.</p>
<p dir="auto">My e-mail is: <a href="mailto:edward.permyakov@gmail.com">edward.permyakov@gmail.com</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How does Linux NAT a ping? (209 pts)]]></title>
            <link>https://devnonsense.com/posts/how-does-linux-nat-a-ping/</link>
            <guid>37455621</guid>
            <pubDate>Sun, 10 Sep 2023 13:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devnonsense.com/posts/how-does-linux-nat-a-ping/">https://devnonsense.com/posts/how-does-linux-nat-a-ping/</a>, See on <a href="https://news.ycombinator.com/item?id=37455621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>A few months ago, I found myself wondering how a command like <code>ping 1.1.1.1</code> works from within a private network.</p><p>In most private networks, multiple hosts connect to the Internet through a router. For IPv4, the router performs network address translation (NAT) by rewriting the original host’s source address to the router’s public IP address. The router can lookup the correct host for a reply packet based on the packet’s <em>port</em> field, at least for protocols like TCP and UDP.</p><p>But a command like <code>ping</code> doesn’t use TCP or UDP; it uses ICMP, and those packets do <em>not</em> have a port field. So how does NAT work for ICMP packets?</p><p>This led me down a deep rabbit hole: running experiments in network namespaces, capturing packets, reading RFCs, and tracing through the Linux source code. This post summarizes what I did and learned along the way.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p><em>Before these experiments, I hadn’t spent much time in the Linux networking code – this is something new I’m learning. If I’ve made any mistakes please <a href="https://devnonsense.com/contact">let me know</a> so I can correct them.</em></p><details open=""><summary><b>Table of contents</b></summary><nav id="TableOfContents"><ul><li><a href="#experiment-setup">Experiment setup</a><ul><li><a href="#step-1-connect-two-clients-to-a-bridge">Step 1: Connect two clients to a bridge</a></li><li><a href="#step-2-connect-natbox-and-server">Step 2: Connect natbox and server</a></li><li><a href="#step-3-configure-routing-and-nat">Step 3: Configure routing and NAT</a></li></ul></li><li><a href="#packet-capture">Packet capture</a></li><li><a href="#rfc-792">RFC 792</a></li><li><a href="#ping-source-code">Ping source code</a></li><li><a href="#id-conflict">ID conflict</a></li><li><a href="#netfilter-conntrack-and-nat">Netfilter, conntrack, and NAT</a></li><li><a href="#bpftrace">bpftrace</a></li><li><a href="#conclusion">Conclusion</a></li></ul></nav></details><h2 id="experiment-setup">Experiment setup</h2><p>One of the best ways to understand Linux networking is through experimentation. These days, it’s easy to run experiments using <a href="https://www.man7.org/linux/man-pages/man7/network_namespaces.7.html">network namespaces</a> to simulate multiple devices on a single Linux machine.</p><p>This is the setup I wanted to test:</p><p><img src="https://devnonsense.com/img/icmp-nat-setup.svg" alt="Diagram showing the setup of the experiment"></p><p>There are two clients (client1 and client2) connected to a router (natbox) performing NAT from private network 192.168.99.0/24 to public network 10.0.100.0/24. The clients, natbox, and server are each separate network namespaces. Once everything is ready, a <code>ping</code> from either client to the server at <code>10.0.100.2</code> should get a reply!</p><p>For these experiments, I used a Fedora 38 Server VM running version 6.2.9 of the Linux kernel. Most of the below commands (<code>ip</code>, <code>iptables</code>, <code>tcpdump</code>, etc.) were run as the root user.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><h3 id="step-1-connect-two-clients-to-a-bridge">Step 1: Connect two clients to a bridge</h3><p>The first step is to create two clients connected to a bridge, like this:
<img src="https://devnonsense.com/img/icmp-nat-clients-and-bridge.svg" alt="Diagram showing two clients connected to a bridge"></p><p>To set it up:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># Create a network namespace for each client.</span>
</span></span><span><span>ip netns add <span>"client1"</span>
</span></span><span><span>ip netns add <span>"client2"</span>
</span></span><span><span>
</span></span><span><span><span># Create a virtual bridge.</span>
</span></span><span><span>ip link add name <span>"br0"</span> <span>type</span> bridge
</span></span><span><span>ip link <span>set</span> dev <span>"br0"</span> up
</span></span><span><span>
</span></span><span><span><span># Disable iptables processing for bridges so rules don't block traffic over br0.</span>
</span></span><span><span>sysctl -w net.bridge.bridge-nf-call-iptables<span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span># Connect client1 to the bridge with a veth pair and assign IP address 192.168.99.1</span>
</span></span><span><span>ip link add dev <span>"vethclient1"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"client1"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient1"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient1"</span> up
</span></span><span><span>ip -n <span>"client1"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.1/24"</span>
</span></span><span><span>ip -n <span>"client1"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span><span><span>
</span></span><span><span><span># Same for client2, with IP address 192.168.99.2</span>
</span></span><span><span>ip link add dev <span>"vethclient2"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"client2"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient2"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient2"</span> up
</span></span><span><span>ip -n <span>"client2"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.2/24"</span>
</span></span><span><span>ip -n <span>"client2"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span></code></pre></div><p>If this worked, then:</p><ul><li><code>ip netns</code> should show <code>client1</code> and <code>client2</code>.</li><li><code>ip -n client1 addr</code> and <code>ip -n client2 addr</code> should show <code>192.168.99.1</code> and <code>192.168.99.2</code> respectively, and the <code>eth0</code> interface should show “state UP”.</li></ul><p>Now the two clients can ping each other over the bridge:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping client1 -&gt; client2</span>
</span></span><span><span>ip netns <span>exec</span> client1 ping 192.168.99.2
</span></span><span><span>
</span></span><span><span><span># ping client2 -&gt; client1</span>
</span></span><span><span>ip netns <span>exec</span> client2 ping 192.168.99.1
</span></span></code></pre></div><h3 id="step-2-connect-natbox-and-server">Step 2: Connect natbox and server</h3><p>Next, create network namespaces for the natbox and server:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns add <span>"natbox"</span>
</span></span><span><span>ip netns add <span>"server"</span>
</span></span></code></pre></div><p>Then connect the natbox to the bridge:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip link add dev <span>"vethnatbox"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"natbox"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethnatbox"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethnatbox"</span> up
</span></span><span><span>ip -n <span>"natbox"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.3/24"</span>
</span></span><span><span>ip -n <span>"natbox"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span></code></pre></div><p>The natbox needs a second interface in the 10.0.100.0/24 network, so add that and call it “eth1”. Since there’s only one server, there’s no need for a bridge – just connect the natbox and server directly with a veth pair:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip -n <span>"natbox"</span> link add <span>"eth1"</span> <span>type</span> veth peer name <span>"eth1"</span> netns <span>"server"</span>
</span></span><span><span>ip -n <span>"natbox"</span> addr add dev <span>"eth1"</span> <span>"10.0.100.1/24"</span>
</span></span><span><span>ip -n <span>"natbox"</span> link <span>set</span> dev <span>"eth1"</span> up
</span></span><span><span>ip -n <span>"server"</span> addr add dev <span>"eth1"</span> <span>"10.0.100.2/24"</span>
</span></span><span><span>ip -n <span>"server"</span> link <span>set</span> dev <span>"eth1"</span> up
</span></span></code></pre></div><p>Now the natbox can reach both clients and the server. Test it with ping:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping natbox -&gt; client1</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 192.168.99.1
</span></span><span><span>
</span></span><span><span><span># ping natbox -&gt; client2</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 192.168.99.2
</span></span><span><span>
</span></span><span><span><span># ping natbox -&gt; server</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span></code></pre></div><p>At this point, every network namespace, interface, and veth pair has been created:
<img src="https://devnonsense.com/img/icmp-nat-setup.svg" alt="Diagram showing the setup of the experiment"></p><p>However, the client cannot yet ping the server because the natbox isn’t forwarding traffic between its interfaces or performing NAT.</p><h3 id="step-3-configure-routing-and-nat">Step 3: Configure routing and NAT</h3><p>Add a default route in each client to send traffic to the natbox:</p><pre tabindex="0"><code>ip -n client1 route add 0.0.0.0/0 via 192.168.99.3
ip -n client2 route add 0.0.0.0/0 via 192.168.99.3
</code></pre><p>For security reasons, Linux does not forward packets between interfaces unless specifically enabled. So configure the natbox to forward traffic by setting <code>net.ipv4.ip_forward</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> natbox sysctl <span>"net.ipv4.ip_forward=1"</span>
</span></span></code></pre></div><p>At this point, packets from a client will reach the server. However, these packets will retain the original source IP in the 192.168.99.0/24 network, so replies from the server back to this IP will go… nowhere. Fix it by configuring the natbox to NAT the traffic from a client IP (in network 192.168.99.0/24) to the natbox’s public IP (10.0.100.1/24). The easiest way to do this is to add a MASQUERADE rule to the iptables “nat” chain:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> natbox iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE
</span></span></code></pre></div><p>At last, clients can reach the server through the natbox! Test it with ping:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping client1 -&gt; server via natbox</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span><span><span>
</span></span><span><span><span># ping client2 -&gt; server via natbox</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span></code></pre></div><h2 id="packet-capture">Packet capture</h2><p>Now capture ICMP packets from both client and server network namespaces.</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> client1 tcpdump -n icmp
</span></span><span><span>ip netns <span>exec</span> server tcpdump -n icmp
</span></span></code></pre></div><p>This is the tcpdump for client1:</p><pre tabindex="0"><code>08:01:33.549598 IP 192.168.99.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64
08:01:33.549661 IP 10.0.100.2 &gt; 192.168.99.1: ICMP echo reply, id 31428, seq 1, length 64
08:01:34.610605 IP 192.168.99.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64
08:01:34.610654 IP 10.0.100.2 &gt; 192.168.99.1: ICMP echo reply, id 31428, seq 2, length 64
</code></pre><p>… and the corresponding tcpdump for the server:</p><pre tabindex="0"><code>08:01:33.549643 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64
08:01:33.549654 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 31428, seq 1, length 64
08:01:34.446611 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 33391, seq 1, length 64
08:01:34.446619 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 33391, seq 1, length 64
08:01:34.610635 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64
08:01:34.610646 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 31428, seq 2, length 64
08:01:35.506411 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 33391, seq 2, length 64
08:01:35.506423 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 33391, seq 2, length 64
</code></pre><p>These captures show that:</p><ul><li>Traffic is being NAT’d. By the time an ICMP echo request reaches the server (10.0.100.2), its source IP has been rewritten to the IP of the natbox (10.0.100.1).</li><li>Each client has a different “id” field (in the capture above, client1 has ID 31428 and client2 has ID 33391).</li></ul><p>The “id” field seemed like it might allow the natbox to distinguish reply packets destined for each client. But what does the “id” field mean, and how is it chosen?</p><h2 id="rfc-792">RFC 792</h2><p>ICMP is a very, very old protocol. It is defined in <a href="https://datatracker.ietf.org/doc/html/rfc792">RFC 792</a>, which was published in 1981. The RFC specifies the exact structure of an ICMP echo and echo reply message:</p><pre tabindex="0"><code>    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |     Type      |     Code      |          Checksum             |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |           Identifier          |        Sequence Number        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |     Data ...
   +-+-+-+-+-
</code></pre><p>The “type” field distinguishes an echo request (8) from an echo reply (1). Code is always 0 (I guess it isn’t used for anything?). What about “sequence number” and “identifier”?</p><blockquote><p>If code = 0, an identifier to aid in matching echos and replies,
may be zero…</p><p>If code = 0, a sequence number to aid in matching echos and
replies, may be zero…</p><p>The identifier and sequence number may be used by the echo sender
to aid in matching the replies with the echo requests. For
example, the identifier might be used like a port in TCP or UDP to
identify a session, and the sequence number might be incremented
on each echo request sent. The echoer returns these same values
in the echo reply.</p></blockquote><p>The RFC doesn’t say anything about how the IDs are actually chosen. That’s not part of the protocol specification, so the next step is to look at an implementation – in this case, the source code for the <code>ping</code> command.</p><h2 id="ping-source-code">Ping source code</h2><p>The <code>ping</code> command is part of the “iputils” package, with source code available at <a href="https://github.com/iputils/iputils">github.com/iputils/iputils</a>. There is a <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L1511-L1519">comment</a> just before <code>ping4_send_probe</code>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>/*
</span></span></span><span><span><span> * pinger --
</span></span></span><span><span><span> * 	Compose and transmit an ICMP ECHO REQUEST packet.  The IP packet
</span></span></span><span><span><span> * will be added on by the kernel.  The ID field is a random number,
</span></span></span><span><span><span> * and the sequence number is an ascending integer.  The first several bytes
</span></span></span><span><span><span> * of the data portion are used to hold a UNIX "timeval" struct in VAX
</span></span></span><span><span><span> * byte-order, to compute the round-trip time.
</span></span></span><span><span><span> */</span>
</span></span></code></pre></div><p>So <code>ping</code> chooses the identifier randomly. It’s a bit difficult to see where this actually happens in the code, but from what I understand:</p><ol><li>There is a <code>struct ping_rts</code> that has a field <code>ident</code>.</li><li>The <code>ident</code> field <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L327C9-L327C9">defaults to <code>-1</code></a>, but can be <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L375-L378">overridden by the CLI flag “-e”</a> to any value between zero and <code>IDENTIFIER_MAX</code> (0xFFFF).</li><li>When <code>rts-&gt;ident == -1</code>, <code>ping</code> binds to a socket with type <code>SOCK_DGRAM</code> and protocol <code>IPPROTO_ICMP</code>. <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L893-L895">In this configuration, it does not modify <code>source.sin_port</code></a>, so the source port is zero.</li></ol><p>I didn’t find much documentation for how Linux implements <code>SOCK_DGRAM</code> sockets with <code>IPPROTO_ICMP</code>, except for this description from the <a href="https://lore.kernel.org/lkml/20110413113204.GB6948@albatros/T/">mailing list “net: ipv4: add IPPROTO_ICMP socket kind”</a>:</p><blockquote><p>ICMP headers given to send() are checked and sanitized. The type must be
ICMP_ECHO and the code must be zero (future extensions might relax this,
see below). <strong>The id is set to the number (local port) of the socket</strong>, the
checksum is always recomputed.</p></blockquote><p>I suspect that when <code>ping</code> doesn’t specify a source port (<code>source.sin_port == 0</code>), then the Linux kernel chooses a free port at random. This port then gets used as the ID for ICMP packets.</p><h2 id="id-conflict">ID conflict</h2><p>What happens if two <code>ping</code> processes on different hosts both choose the exact same ID? Test it using <code>ping -e</code> to explicitly set the ICMP ID to the same value for both clients:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping from client1 -&gt; server with ICMP ID 999</span>
</span></span><span><span>ip netns <span>exec</span> client1 ping 10.0.100.2 -e <span>999</span>
</span></span><span><span>
</span></span><span><span><span># ping from client2 -&gt; server with ICMP ID 999</span>
</span></span><span><span>ip netns <span>exec</span> client2 ping 10.0.100.2 -e <span>999</span>
</span></span></code></pre></div><p>This time, the packet capture from the server shows something different:</p><pre tabindex="0"><code>10:22:18.807289 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 1, length 64
10:22:18.807300 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 1, length 64
10:22:19.838650 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 2, length 64
10:22:19.838661 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 2, length 64
10:22:20.011677 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 30218, seq 1, length 64
10:22:20.011687 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 30218, seq 1, length 64
10:22:20.862591 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 3, length 64
10:22:20.862603 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 3, length 64
10:22:21.054598 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 30218, seq 2, length 64
10:22:21.054614 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 30218, seq 2, length 64
</code></pre><p>One of the clients is using ID 999, but the other one is using ID 30218. Where did that second ID come from? Time to go to the Linux source code.</p><h2 id="netfilter-conntrack-and-nat">Netfilter, conntrack, and NAT</h2><p>The kernel subsystem responsible for implementing iptables rules is called “netfilter.” The iptables MASQUERADE rule is responsible for NAT’ing packets, so the NAT implementation for ICMP must be in netfilter. Grep’ing through the <code>net/netfilter</code> directory in the Linux repository, I found a few places where the ICMP “id” field is used:</p><ul><li>In “nf_nat_core.c” the function <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L580"><code>nf_nat_setup_info</code></a> calls <code>get_unique_tuple</code>, which calls <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L380"><code>nf_nat_l4proto_unique_tuple</code></a>. There is a switch statement with a case for <code>IPPROTO_ICMP</code>, and a reference to <code>&amp;tuple-&gt;src.u.icmp.id</code>.</li><li>In “nf_nat_proto.c” the function <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_proto.c#L419"><code>nf_nat_manip_pkt</code></a> calls <code>nf_nat_ipv4_manip_pkt</code>, which calls <code>l4proto_manip_pkt</code>. When the protocol is <code>IPPROTO_ICMP</code> this calls <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_proto.c#L223"><code>icmp_manip_pkt</code>, which has a line <code>hdr-&gt;un.echo.id = tuple-&gt;src.u.icmp.id</code></a>.</li></ul><p>In order to NAT packets, netfilter needs to store something called a <em>connection</em>. For TCP, not surprisingly, this represents the TCP connection, uniquely identified by the 5-tuple (src IP, src port, dst IP, dst port, L4 protocol). However, in netfilter the term “connection” has a broader meaning: it can correlate outgoing and incoming packets <em>even for connectionless protocols</em> like UDP and ICMP.</p><p>Examining the <a href="https://elixir.bootlin.com/linux/v6.2.9/source/include/net/netfilter/nf_conntrack.h#L75"><code>nf_conn</code></a> data structure:</p><ul><li><code>nf_conn</code> has a field <code>struct nf_conntrack_tuple_hash tuplehash[IP_CT_DIR_MAX]</code>. There are two tuple hashes, one for outgoing packets and one for incoming packets (<code>IP_CT_DIR_ORIGINAL</code> and <code>IP_CT_DIR_REPLY</code> respectively).</li><li>Each <code>nf_conntrack_tuple_hash</code> has a field <code>nf_conntrack_tuple tuple</code> with the tuple uniquely identifying the connection.</li><li>Each tuple is split into a part that can be manipulated, called <code>src</code>, and a part that is immutable called <code>dst</code>.<ul><li><code>src</code> has type <code>struct nf_conntrack_man</code>, which has an IP address (<code>union nf_inet_addr u3</code>) and protocol-specific fields (<code>union nf_conntrack_man_proto u</code>). For ICMP, the protocol-specific field is <code>__be16 id</code>.</li><li><code>dst</code> has the unmodified IP address as well as the ICMP <code>type</code> and <code>code</code> fields.</li></ul></li></ul><p>Connection tracking and NAT are closely related. To NAT a packet, netfilter needs to “remember” how it modified the outgoing packet so it can reverse those modifications on the reply packet. It does so by representing the modifications in a connection.</p><p>For ICMP, I believe netfilter works like this:</p><ol><li>When natbox receives an ICMP echo, <code>nf_nat_setup_info</code> creates a new connection. This is where it chooses whether it needs to rewrite the source IP address and/or the ICMP id field on the outgoing packet.</li><li>For each incoming and outgoing ICMP packet, the function <code>nf_nat_manip_pkt</code> sets the source IP and ICMP id field to whatever is set in the connection. The argument <code>ip_conntrack_dir dir</code> determines whether the packet is treated as an outgoing echo (rewrite the source IP) or incoming reply (rewrite the destination IP).</li></ol><p><a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L580"><code>nf_nat_setup_info</code></a> is responsible for choosing the ICMP ID for the NAT’d packets. The NAT rewrites happen in <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L504"><code>get_unique_tuple</code></a>.</p><p>Here are the key steps:</p><ol><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L541">line 541</a>, <code>find_best_ips_proto(zone, tuple, range, ct, maniptype)</code> rewrites the source IP address.</li><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L548">lines 548-560</a>, <code>nf_nat_used_tuple(tuple, ct)</code> checks whether the tuple is already being used; if not, the current tuple is returned. This explains why when two clients use <em>different</em> ICMP IDs, those IDs are preserved in the NAT’d packets.</li><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L563">line 563</a>, <code>nf_nat_l4proto_unique_tuple</code> is called to perform protocol-specific NAT (in this case manipulating the ICMP ID field).</li><li>In <code>nf_nat_l4proto_unique_tuple</code> <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L393">lines 393-403</a> set <code>keyptr = &amp;tuple-&gt;src.u.icmp.id</code> to choose the ICMP ID field as the “key” to NAT, then jumps to <code>find_free_id</code> at the end of the function.</li><li><code>find_free_id</code> on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L471">line 471</a> calls <code>get_random_u16()</code> to generate a random ID, adjusts the value into the range<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of valid ICMP IDs (on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L485">line 485</a>), then checks if it’s used (another call to <code>nf_nat_used_tuple</code> on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L486">line 486</a>).</li><li>If a tuple with the random ID not yet used, then it gets returned. Otherwise, netfilter searches for an unused ID from progressively smaller ranges starting at random offsets (<a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L483">lines 483-494</a>).</li><li>If an unused tuple cannot be found within a maximum number of attempts, then <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L491"><code>nf_nat_l4_proto_unique_tuple</code> returns</a>, leaving the duplicate ID in the connection. Later, <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L502">__nf_conntrack_confirm will detect the duplicate and drop the packet</a>.</li></ol><h2 id="bpftrace">bpftrace</h2><p>To verify my understanding of the netfilter code, I used a tool called <a href="https://github.com/iovisor/bpftrace/"><code>bpftrace</code></a>.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> After much tinkering, I ended up with this program to trace the kernel functions <code>nf_nat_setup_info</code> and <code>nf_nat_manip_pkt</code>:</p><pre tabindex="0"><code>// from linux/socket.h
#define AF_INET		2	/* Internet IP Protocol 	*/

// from net/netfilter/nf_nat.h
enum nf_nat_manip_type {
	NF_NAT_MANIP_SRC,
	NF_NAT_MANIP_DST
};

// from include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
// Use #define instead of enum so we can use these in bpftrace array indices.
#define IP_CT_DIR_ORIGINAL 0
#define IP_CT_DIR_REPLY 1

kprobe:nf_nat_setup_info {
	// nf_nat_setup_info gets called twice, once in the prerouting chain
	// to modify the destination (actually a no-op), and once in the output
	// chain to modify the source (which is what we care about).
	$mtype = arg2;
	if ($mtype != NF_NAT_MANIP_SRC) {
		return;
	}

	$conn = (struct nf_conn *)arg0;
	if ($conn-&gt;tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.protonum == IPPROTO_ICMP) {
		@setupConn[tid] = $conn;
	}
}

kretprobe:nf_nat_setup_info {
	if (@setupConn[tid] == none) {
		return;
	}
	$conn = (struct nf_conn *)@setupConn[tid];
	$origTuple = $conn-&gt;tuplehash[IP_CT_DIR_ORIGINAL].tuple;
	$replyTuple = $conn-&gt;tuplehash[IP_CT_DIR_REPLY].tuple;
	printf("nf_nat_setup_info: origTuple.addr=%s, origTuple.id=%d, replyTuple.addr=%s, replyTuple.id=%d\n",
		ntop(AF_INET, $origTuple.src.u3.ip),
		bswap($origTuple.src.u.icmp.id),
		ntop(AF_INET, $replyTuple.src.u3.ip),
		bswap($replyTuple.src.u.icmp.id));
	delete(@setupConn[tid]);
}

kprobe:nf_nat_manip_pkt {
	$mtype = arg2;
	$skb = (struct sk_buff *)arg0;
	$iphdr = (struct iphdr *)$skb-&gt;data;
	$icmphdr = (struct icmphdr *)($skb-&gt;data + $iphdr-&gt;ihl * 4);
	printf("nf_nat_manip_pkt before: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\n",
		$mtype,
		ntop(AF_INET, $iphdr-&gt;saddr),
		ntop(AF_INET, $iphdr-&gt;daddr),
		bswap($icmphdr-&gt;type),
		bswap($icmphdr-&gt;un.echo.id));
	@manipType[tid] = $mtype;
	@manipSkb[tid] = $skb
}

kretprobe:nf_nat_manip_pkt {
	$mtype = @manipType[tid];
	$skb = @manipSkb[tid];
	$iphdr = (struct iphdr *)$skb-&gt;data;
	$icmphdr = (struct icmphdr *)($skb-&gt;data + $iphdr-&gt;ihl * 4);
	printf("nf_nat_manip_pkt after: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\n",
		$mtype,
		ntop(AF_INET, $iphdr-&gt;saddr),
		ntop(AF_INET, $iphdr-&gt;daddr),
		bswap($icmphdr-&gt;type),
		bswap($icmphdr-&gt;un.echo.id));
	delete(@manipType[tid]);
	delete(@manipSkb[tid]);
}
</code></pre><p>The important parts are:</p><ul><li><p><code>kprobe</code> traces when a kernel function is called, and <code>kretprobe</code> traces when the function returns.</p></li><li><p><code>kretprobe</code> cannot access function arguments directly, so store the arguments in a BPF map on entry and retrieve them on exit. For example, <code>kprobe:nf_nat_setup_info</code> writes the netfilter connection argument to <code>@setupConn[tid]</code> (a BPF map keyed by thread ID). Then <code>kretprobe:nf_nat_setup_info</code> reads the connection from the map and deletes the entry.</p></li><li><p><code>struct sk_buff</code> is how the Linux kernel <a href="https://docs.kernel.org/networking/skbuff.html">represents a packet</a>.</p></li><li><p><code>bswap</code> reverses byte order, which is used to convert from big endian (network byte order) to little endian.</p></li><li><p><code>ntop</code> returns the string representation of an IP address.</p></li><li><p>The BPF program can reference kernel data structures like <code>sk_buff</code> and <code>nf_conn</code> without including any headers. This is the magic of BPF Type Format (BTF) available in recent versions of the Linux kernel.</p></li><li><p>I tested this program on Linux kernel version 6.2.9. It may or may not work on other kernel versions.</p></li></ul><p>To execute the program, I saved the above code to a file called <code>trace.bt</code> then ran <code>bpftrace trace.bt</code> as root. This is what the output looks like with two clients pinging the server using the same ICMP ID (999):</p><pre tabindex="0"><code>$ bpftrace trace.bt
Attaching 4 probes...
nf_nat_setup_info: origTuple.addr=192.168.99.1, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=999
nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=999
nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.1, icmp.type=0, icmp.id=999
nf_nat_setup_info: origTuple.addr=192.168.99.2, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=32809
nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.2, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=32809
nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=32809
nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.2, icmp.type=0, icmp.id=999
</code></pre><p>The output shows that <code>nf_nat_setup_info</code> gets called twice, once for each client.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> For the first client (IP 192.168.99.1), both the original and reply tuple have the ICMP ID sent by the client (999). For the second client (IP 192.168.99.2), however, the reply tuple has been <em>rewritten</em> to ID 32809. For both clients, the source IP address has been rewritten to the IP of the natbox (10.0.100.2).</p><p>Once <code>nf_nat_setup_info</code> has created the connection, <code>nf_nat_manip_pkt</code> modifies the echo and echo reply ICMP packets. For the echo packet, <code>mtype=0</code> (<code>NF_NAT_MANIP_SRC</code>) because the source IP is rewritten. Likewise, the reply packet has <code>mtype=1</code> (<code>NF_NAT_MANIP_DST</code>) to rewrite the destination IP of the incoming reply back to the original client IP.</p><h2 id="conclusion">Conclusion</h2><p>So that is how Linux NATs a ping! In the end, maybe the answer isn’t very surprising – and, in fact, I discovered much later that most of this behavior is documented in the <a href="https://netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO-4.html#ss4.4">Netfilter Hacking HOWTO</a>. But it was a fun journey, and it’s nice to know exactly where this magic happens in the code.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google no longer offers new domain registrations (140 pts)]]></title>
            <link>https://domains.google/</link>
            <guid>37455574</guid>
            <pubDate>Sun, 10 Sep 2023 13:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://domains.google/">https://domains.google/</a>, See on <a href="https://news.ycombinator.com/item?id=37455574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><span aria-level="2" role="heading">
          An update on domains
    </span>
      </p>
      <p><span>
          Google no longer offers new domain registrations, but try&nbsp;Squarespace
    </span></p>
      <div>
            <p><a href="https://domains.squarespace.com/?channel=bd&amp;subchannel=google-domain&amp;campaign=&amp;subcampaign=&amp;source=google_domain_referral&amp;utm_source=google_domain_referral&amp;utm_medium=bd&amp;utm_content=google-domain&amp;utm_term=&amp;utm_campaign=" rel="noreferrer noopener" target="_blank" data-ga4-event="dahlia_select" data-ga4-eventparams="{&quot;contentType&quot;: &quot;cta&quot;, &quot;moduleName&quot;: &quot;purchase domain squarespace&quot;, &quot;itemId&quot;: &quot;purchase domain squarespace - hero&quot;}">
      <span>
          Get a new domain from&nbsp;Squarespace
    </span>
  </a>

      </p></div>
      <p><span>
          On September 7, 2023 Squarespace acquired all domain registrations and related customer accounts from Google Domains. Customers and domains will be transitioned over the next few months. <a href="https://support.google.com/domains/answer/13689670">Learn&nbsp;more.</a>
    </span></p>
      <div>
            <p><a href="https://domains.google.com/registrar" rel="noreferrer noopener" target="_blank" data-ga4-event="dahlia_select" data-ga4-eventparams="{&quot;contentType&quot;: &quot;link&quot;, &quot;moduleName&quot;: &quot;manage domains&quot;, &quot;itemId&quot;: &quot;manage domains - hero&quot;}">
      Already a Google Domains customer? Manage&nbsp;your&nbsp;current&nbsp;domains
  </a>

      </p></div>
      <p><span>
          This is an affiliate link. If you make a purchase from Squarespace, we may earn a&nbsp;commission.
    </span>
      </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Earth had hottest 3-months on record; unprecedented sea temps & extreme weather (340 pts)]]></title>
            <link>https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface</link>
            <guid>37455534</guid>
            <pubDate>Sun, 10 Sep 2023 13:14:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface">https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface</a>, See on <a href="https://news.ycombinator.com/item?id=37455534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><strong>Bonn and Geneva, 6 September 2023 (ECMWF and WMO)</strong> -&nbsp;Earth just had its hottest three months on record, according to the European Union-funded&nbsp;<a href="https://wmo.us9.list-manage.com/track/click?u=618614864060486033e4590d6&amp;id=fa16212f5d&amp;e=3e6d95b4e5">Copernicus Climate Change Service (C3S)</a> implemented by ECMWF. Global sea surface temperatures are at unprecedented highs for the third consecutive month and Antarctic sea ice extent remains at a record low for the time of year.</p>

<p>It was the hottest August on record – by a large margin – and the second hottest ever month after July 2023, according to the Copernicus Climate Change Service ERA 5 dataset. August as a whole is estimated to have been around 1.5°C warmer than the preindustrial average for 1850-1900, <a href="https://climate.copernicus.eu/summer-2023-hottest-record">according to the C3S monthly climate bulletin.</a></p>

<p>The year so far (January to August) is the second warmest on record behind 2016, when there was a powerful warming El Niño event.</p>

<p>August as a whole saw the highest global monthly average sea surface temperatures on record across all months, at 20.98°C. Temperatures exceeded the previous record (March 2016) every single day in August.</p>

<p>Antarctic sea ice extent remained at a record low level for the time of year, with a monthly value 12% below average, by far the largest negative anomaly for August since satellite observations began in the late 1970s. Arctic sea ice extent was 10% below average, but well above the record minimum of August 2012.</p>

<p>WMO consolidates data from C3S and five other international datasets for its climate monitoring activities and its State of the Climate reports<em>.&nbsp;</em></p>

<p>A report in May from WMO and the UK's Met Office predicted&nbsp;that there is a 98% likelihood that at least one of the next five years will be the warmest on record and a 66% chance of&nbsp;temporarily&nbsp;exceeding 1.5°C above the 1850-1900 average for at least one of the five years.&nbsp;This does not mean that we will permanently exceed the 1.5°C level specified in the Paris Agreement which refers to long-term warming over many years.</p>



<p>&nbsp;&nbsp;<img alt="red chart on black background" title="Copernicus ECMWF: warmest months on record" data-delta="1" typeof="foaf:Image" src="https://ane4bf-datap1.s3-eu-west-1.amazonaws.com/wmocms/s3fs-public/ckeditor/files/6b8d528f-36ee-43c2-920e-44fec02063f9.png?ni8DG4pTlOSP8XsKWzThg.Qp8pa0Rrfi" width="1893" height="1225"></p>



<p><strong>Commentary</strong></p>

<p>“Our planet has just endured a season of simmering -- the hottest summer on record. Climate breakdown has begun.&nbsp;Scientists have long warned what our fossil fuel addiction will unleash. Surging temperatures demand a surge in action. Leaders must turn up the heat now for climate solutions. We can still avoid the worst of climate chaos – and we don’t have a moment to lose,&nbsp;“<strong> <em>said UN Secretary-General António Guterres.</em></strong><em>&nbsp;</em></p>

<p>“The northern hemisphere just had a summer of extremes – with repeated heatwaves fuelling devastating wildfires, harming health, disrupting daily lives and wreaking a lasting toll on the environment. In the southern hemisphere Antarctic sea ice extent was literally off the charts, and the global sea surface temperature was once again at a new record. It is worth noting that this is happening BEFORE we see the full warming impact of the El Niño event, which typically plays out in the second year after it develops” s<em>ays <strong>World Meteorological Organization Secretary-General Prof. Petteri Taalas.</strong></em></p>

<p>“Eight months into 2023, so far we are experiencing the second warmest year to date, only fractionally cooler than 2016, and August was estimated to be around 1.5°C warmer than pre-industrial levels. What we are observing, not only new extremes but the persistence of these record-breaking conditions, and the impacts these have on both people and planet, are a clear consequence of the warming of the climate system,” <em>comments <strong>Carlo Buontempo, Director of the Copernicus Climate Change Service, ECMWF.</strong></em></p>



<p>&nbsp;<img alt="red, white and blue chart on black background " title="Copernicus ECMWF sea surface temperature anamolies" data-delta="3" typeof="foaf:Image" src="https://ane4bf-datap1.s3-eu-west-1.amazonaws.com/wmocms/s3fs-public/ckeditor/files/timeseries_era5_daily_sst_60S-60N_1940-2023_0.png?VQ1ajBah_dEP8011aB6lGYOICJWwlNp1" width="2550" height="1650"></p>



<p>Notes for Editors</p>

<p><em>The World Meteorological Organization is the UN system's authoritative voice on weather climate and water.</em></p>

<p><em>C3S, implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) on behalf of the European Commission, routinely monitors climate and has also been closely following recent development of global air and sea surface temperatures. The monthly report and associated assets is <a href="https://climate.copernicus.eu/summer-2023-hottest-record">here</a>.</em></p>

<p>More information on the sea surface temperatures in August 2023 can be found&nbsp;<a data-auth="NotApplicable" data-linkindex="7" href="https://climate.copernicus.eu/record-high-global-sea-surface-temperatures-continue-august?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here.</a></p>

<p>More information about climate variables in August and climate updates of previous months as well as high-resolution graphics and the video can be downloaded&nbsp;<a data-auth="NotApplicable" data-linkindex="8" href="https://climate.copernicus.eu/climate-bulletins?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here</a>.</p>

<p>Answers to frequently asked questions regarding temperature monitoring can be found&nbsp;<a data-auth="NotApplicable" data-linkindex="9" href="https://climate.copernicus.eu/temperature-qas?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here</a>.</p>








  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The molecule DIM reduces biofilms causing dental plaque: study (103 pts)]]></title>
            <link>https://scitechdaily.com/90-reduction-scientists-discover-natural-molecule-that-eradicates-plaques-and-cavities/</link>
            <guid>37455106</guid>
            <pubDate>Sun, 10 Sep 2023 12:11:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scitechdaily.com/90-reduction-scientists-discover-natural-molecule-that-eradicates-plaques-and-cavities/">https://scitechdaily.com/90-reduction-scientists-discover-natural-molecule-that-eradicates-plaques-and-cavities/</a>, See on <a href="https://news.ycombinator.com/item?id=37455106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="attachment_228158"><p><img aria-describedby="caption-attachment-228158" decoding="async" fetchpriority="high" src="https://scitechdaily.com/images/Dental-Cavities-Chewing-Teeth.jpg?ezimgfmt=rs%3Adevice%2Frscb2-1" alt="Dental Cavities Chewing Teeth" width="777" height="522" srcset="" sizes="" ezimgfmt="rs rscb2 src ng ngcb2 srcset" loading="eager" importance="high"></p><p id="caption-attachment-228158">Scientists have discovered that the molecule DIM reduces biofilms causing dental plaque by 90%. Its addition to toothpaste and mouthwash could revolutionize dental hygiene.</p></div><h3>3,3′-Diindolylmethane (DIM) decreased the <em>Streptococcus mutans</em> biofilm, a leading contributor to plaque and cavities, by 90%.</h3><p>A significant portion of the global population experiences persistent issues with dental plaque and cavities or will face them at some time. While toothpaste, mouthwash, and routine dental visits help in prevention, there’s always room for improvement.</p><p>Researchers from <a href="https://scitechdaily.com/tag/ben-gurion-university-of-the-negev/amp/">Ben-Gurion University of the Negev</a>, in collaboration with teams from Sichuan University and the <a href="https://scitechdaily.com/tag/national-university-of-singapore/">National University of Singapore</a>, have identified that 3,3′-Diindolylmethane (DIM) – a naturally occurring molecule also referred to as bisindole – can reduce biofilms responsible for plaque and cavities by a remarkable 90%.</p><p>The molecule is also found to have anti-carcinogenic properties.</p><p>Their findings were recently published in the journal <em>Antibiotics.</em></p><p>Your mouth is a great reservoir for bacteria such as&nbsp;<em>S.</em>&nbsp;<em>mutans</em>, which is believed to be one of the primary actors in dental cavities.&nbsp;<em>S. mutans</em> grows in the moist and sugary atmosphere of your mouth after food in a biofilm that coats your teeth. Biofilm generates plaque, attacks enamel, and causes cavities. The scientists found that the bisindole (DIM) disrupted that biofilm by 90% and therefore the bacterium was not given a chance to grow.</p><p>“The molecule, which was found to have low toxicity, could be added to toothpastes and mouthwashes to greatly improve dental hygiene,” says lead author Prof. Ariel Kushmaro of the Avram and Stella Goldstein-Goren Department of Biotechnology Engineering. He is also a member of the Ilse Katz Institute for Nanoscale Science and Technology and the Goldman Sonnenfeldt School of Sustainability and Climate Change.</p><p>Reference: “3,3′-Diindolylmethane (DIM): A Potential Therapeutic Agent against Cariogenic <em>Streptococcus mutans</em> Biofilm” by Yifat Baruch, Karina Golberg, Qun Sun, Karina Yew-Hoong Gin, Robert S. Marks and Ariel Kushmaro, 6 June 2023, <em>Antibiotics</em>.<br><a href="https://doi.org/10.3390/antibiotics12061017">DOI: 10.3390/antibiotics12061017</a></p><p>The study was conducted with his student Yifat Baruch, and Dr. Karina Golberg, as well as Prof. Robert S. Marks of the same department and Qun Sun<sup>&nbsp;</sup>of Sichuan University, and Karina Yew-Hoong Gin<sup>&nbsp;</sup>of the National University of Singapore.<span data-ez-ph-id="608"></span></p><p>The research was supported by the International Research and Development Program of Sichuan (2019YFH0113) and SMART innovation grant ING-000398 (Singapore).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“Make” as a Static Site Generator (2022) (219 pts)]]></title>
            <link>https://www.karl.berlin/static-site.html</link>
            <guid>37454853</guid>
            <pubDate>Sun, 10 Sep 2023 11:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.karl.berlin/static-site.html">https://www.karl.berlin/static-site.html</a>, See on <a href="https://news.ycombinator.com/item?id=37454853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Static site generators are in fashion for good reasons. The resulting pages are easy to host, fast and extremely low on maintenance while being sufficient for many use cases.
As I learned when <a href="https://www.karl.berlin/blog.html">setting up my blog</a>, writing a simple script myself is faster and more satisfying than learning one of the other site builders and customizing it to my needs.
This time, I only need a plain site without automatically updated timestamps or an RSS-feed, so I can go even simpler than by blog script.</p>
<h2>Basic setup</h2>
<p>To get the site into a working state, I require the following functionality:</p>

<ul>
<li>All input files reside in the <code>source</code> directory, in the same layout as I want them in the output.</li>
<li>During processing, add a header to all HTML files.</li>
<li>Copy all other files to the <code>build</code> directory as they are.</li>
</ul>
<p>Each of these points results in one rule in the Makefile:</p>
<pre><code># The `build` target depends on all output files in the `build` directory. It
# does not do anything by itself, but causes one of the following rules to be
# applied for each file.
build: $(patsubst source/%,build/%,$(shell find source -type f))

# For each .html file do `cat header.html $input &gt; $output`.
build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	cat header.html $&lt; &gt; $@

# Copy all other files without changes.
build/%: source/%
	cp $&lt; $@
</code></pre>
<p>With a corresponding <code>header.html</code> and these rules in place, calling <code>make build</code> will create a <code>build</code> directory that can be browsed locally or uploaded to any web server.</p>
<h2>Variations</h2>
<p>This is really all you need, but the real strength of this approach is that it is so simple, that you can trivially extend it to fit different needs. Let me show you a few examples!</p>
<h3>Mark Current Page</h3>
<p>It is helpful to highlight the current page in the navigation so that the visitor sees where he is within the site at a glance. To do this, we search for the link within the navigation and replace the link with a highlighted version. The specifics vary depending on your markup. I'm using the following code to add the <code>current</code> class to the link tag:</p>
<pre><code>build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	sed -E 's|(href="$(subst source,,$&lt;))|class="current" \1|' header.html | cat - $&lt; &gt; $@
</code></pre>
<h3>Generate Page From Markdown</h3>
<p>If you dislike writing HTML or if you have existing content in markdown format, you can pipe your markdown content through a markdown-to-HTML converter of you choice (I like <a href="https://github.com/karlb/smu">smu</a>).</p>
<pre><code>build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	smu $&lt; | cat header.html - &gt; $@
</code></pre>
<p>Since we still assume that <code>build/foo.html</code> is built from <code>source/foo.html</code>, you should keep the <code>.html</code> suffix for the markdown files or modify the rules to look for <code>.md</code> files as input.</p>
<h2>Little Helpers</h2>
<p>You can not only modify the site generation itself. Convenience features can also be added as additional make targets.</p>
<h3>Serve Site Locally</h3>
<p>Not all sites can be accurately previewed by opening the local files in your browser.
The most common reason for this is using absolute links instead of relative ones.
In those cases, you will want to run a small test web server locally to preview your site.
Python is already installed on many systems and comes with a web server this is suitable for the task.</p>
<pre><code>serve:
	python -m http.server -d build
</code></pre>
<h3>Rebuild on Change</h3>
<p>If you work a lot on your site, manually rebuilding after each change is a hassle.
Just use <a href="https://eradman.com/entrproject/"><code>entr</code></a> (or <a href="https://linux.die.net/man/1/inotifywait"><code>inotifywait</code></a> if you want to avoid the dependency) to rebuild automatically when a file in the source directory changes.</p>
<pre><code>watch:
	find source header.html Makefile | entr make build
</code></pre>
<h3>Upload to GitHub Pages</h3>
<p>I store my repositories on GitHub, so using GitHub Pages to host the resulting HTML is a natural choice.
Getting the commands just right so that you don't have to care about git details when publishing is a bit tricky, but easy enough in the end.
The approach is based on <a href="https://sangsoonam.github.io/2019/02/08/using-git-worktree-to-deploy-github-pages.html">Sangsoo Nam's post</a>.</p>
<pre><code>deploy:
	git worktree add public_html gh-pages
	cp -rf build/* public_html
	cd public_html &amp;&amp; \
	  git add --all &amp;&amp; \
	  git commit -m "Deploy to github pages" &amp;&amp; \
	  git push origin gh-pages
	git worktree remove public_html
</code></pre>
<h2>Summary</h2>
<p>Having your own static site generator in only six simple lines in a Makefile is great!
There are no exotic dependencies, nothing to maintain and you can quickly adapt it to your needs.
A page I built using this approach is available at <a href="https://github.com/karlb/astridbartel.de">https://github.com/karlb/astridbartel.de</a> and can serve as a real world example.</p>
<small>Written on 2022-06-14.</small>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I wired up my bike's GPS to order me pizza during a gravel race (250 pts)]]></title>
            <link>https://steele.blue/geofence-pizza-ordering/</link>
            <guid>37454766</guid>
            <pubDate>Sun, 10 Sep 2023 11:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steele.blue/geofence-pizza-ordering/">https://steele.blue/geofence-pizza-ordering/</a>, See on <a href="https://news.ycombinator.com/item?id=37454766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As harvest season begins here in the Midwest, I once again celebrate by grinding Nebraska gravel at the <a href="https://www.gravel-worlds.com/the-long-voyage">Gravel Worlds Long Voyage</a> bike race.
As in previous years (<a href="https://steele.blue/gravel-worlds">2021</a>) (<a href="https://steele.blue/serverless-bike-gps">2022</a>), I spent more time writing code for a marginally-useful project than I did training. But hey, I finished!</p>
<p><span>
      <a href="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b4e28/matt-gw.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/3e828/matt-gw.webp 192w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/e6f2f/matt-gw.webp 384w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/8b983/matt-gw.webp 768w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b2d4b/matt-gw.webp 1152w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/0abaa/matt-gw.webp 1536w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/11d0e/matt-gw.webp 4005w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/7809d/matt-gw.jpg 192w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/4ecad/matt-gw.jpg 384w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/212bf/matt-gw.jpg 768w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/5ef17/matt-gw.jpg 1152w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/ac99c/matt-gw.jpg 1536w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b4e28/matt-gw.jpg 4005w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/212bf/matt-gw.jpg" alt="Matt riding on Gravel Worlds" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<h2>Fueled by Pizza</h2>
<p>My goal this year involved optimizing my food choices during the race: pizza from <a href="https://www.caseys.com/">Casey's General Store</a>.
These convenience stores are S-Tier options when out in the middle of nowhere.
In addition to snacks and drinks, most Casey's have a kitchen, and have pretty decent grab 'n go slices of pizza.</p>
<p><span>
      <a href="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/3e828/self-serve-pizza.webp 192w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/e6f2f/self-serve-pizza.webp 384w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/c1dc5/self-serve-pizza.webp 650w" sizes="(max-width: 650px) 100vw, 650px" type="image/webp">
          <source srcset="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/7809d/self-serve-pizza.jpg 192w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/4ecad/self-serve-pizza.jpg 384w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg 650w" sizes="(max-width: 650px) 100vw, 650px" type="image/jpeg">
          <img src="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg" alt="A sample of the pizza on offer at a Casey's" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>My problem: last year, there were so many faster riders ahead of me, that <strong>all the pizza was taken by the time I made it to the stops.</strong> This is an outrage!</p>
<p>This year, I knew I had to do better. But with time winding down on improving my fitness, I had to resort to the latent superpower of software hackery.
My thought: <strong>why not have a fresh pizza ordered ahead of time, scheduled precisely for when I arrived?</strong></p>
<p>More precisely, I could write a script that ordered a pizza for me, GPS-triggered by my bike leaving a geofence about an hour from the stop. Building this <a href="https://steele.blue/serverless-bike-gps">on top of the serverless GPS tracker I made last year</a> should fit into the architecture pretty well.</p>
<h2>Casey's Pizza API When</h2>
<p><span>
      <a href="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/3e828/pizza-diagram.webp 192w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e6f2f/pizza-diagram.webp 384w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/c0989/pizza-diagram.webp 691w" sizes="(max-width: 691px) 100vw, 691px" type="image/webp">
          <source srcset="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/8514f/pizza-diagram.png 192w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/804b2/pizza-diagram.png 384w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png 691w" sizes="(max-width: 691px) 100vw, 691px" type="image/png">
          <img src="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png" alt="Architecture diagram" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>The overall design: I setup a geofence within the AWS Location service, which was monitoring my GPS tracker.
When my tracker exited the geofence, it would trigger a Lambda function that calculates an ETA for my next stop, and orders the pizza.</p>
<p>The problem: Casey's doesn't have a public API for online ordering.
So I had to resort to alternate approaches. More specifically, I fell back to <strong>screen scraping the website</strong>, everyone's favorite hack.
I've had to screen-scrape for other projects (such as <a href="https://steele.blue/secret-strava">updating privacy on Strava activities</a>), but since Casey's website was a complex React app that rendered everything on the client, I had to use a more powerful scraper; this time powered by <a href="https://playwright.dev/">Playwright</a>.</p>
<p>Getting Playwright to run in a Lambda was An Experience. Full writeup <a href="https://steele.blue/playwright-on-lambda">here</a>.</p>
<p>To keep track of the status, I also setup a push notification to be delivered to my phone (and watch) on a success or failure. Configuring Web Push to work on iOS devices is probably worthy of its own post.</p>
<h2>Pizza False Positive</h2>
<p>I had the triggering geofence configured around mile 180 of the race, with the pizza setup to be delivered at mile 200.</p>
<p><span>
      <a href="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b17f8/pizza-watch.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/3e828/pizza-watch.webp 192w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/e6f2f/pizza-watch.webp 384w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/8b983/pizza-watch.webp 768w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b2d4b/pizza-watch.webp 1152w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/0abaa/pizza-watch.webp 1536w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/fad48/pizza-watch.webp 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/7809d/pizza-watch.jpg 192w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/4ecad/pizza-watch.jpg 384w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/212bf/pizza-watch.jpg 768w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/5ef17/pizza-watch.jpg 1152w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/ac99c/pizza-watch.jpg 1536w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b17f8/pizza-watch.jpg 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/212bf/pizza-watch.jpg" alt="A push notification indicating pizza was delivered" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>As I left the geofence, I got a push notification on my watch saying that the pizza had been successfully ordered.</p>
<p>But when I made it to the stop, <strong>there was nothing at the counter, and they had no record of an order</strong>. And sure enough, I checked my account, and no order had been placed.
<strong>False positive.</strong></p>
<p>There were a few pre-made slices available, so I picked those up. They left a bitter taste in my mouth, not just because they weren't especially fresh. Through the rest of the 300-mile race, all I could think about was what might have went wrong with my function.</p>
<p><span>
      <a href="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b17f8/pizza-slices.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/3e828/pizza-slices.webp 192w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/e6f2f/pizza-slices.webp 384w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/8b983/pizza-slices.webp 768w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b2d4b/pizza-slices.webp 1152w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/0abaa/pizza-slices.webp 1536w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/fad48/pizza-slices.webp 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/7809d/pizza-slices.jpg 192w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/4ecad/pizza-slices.jpg 384w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/212bf/pizza-slices.jpg 768w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/5ef17/pizza-slices.jpg 1152w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/ac99c/pizza-slices.jpg 1536w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b17f8/pizza-slices.jpg 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/212bf/pizza-slices.jpg" alt="A pair of dirty legs, eating slices of pre-made pizza" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>After finishing the race, I made it to a computer and quickly checked the logs to see what had gone wrong. But to my chagrin, there was nothing in the logs indicating what caused the failure; it was just a silent success. I had nothing to go on to try and debug.</p>
<p>A few days later, I enhanced the Lambda to capture a video of the browser in action and upload it to an S3 bucket for analysis. Running a test of the updated behavior, <strong>it finally worked</strong>. I picked up a fresh Hawaiian pizza, and we enjoyed the pie from the comfort of our home.</p>
<p>I'm still not entirely sure why it worked. My going theory is that the Lambda had terminated processing as soon as the final <code>form.submit()</code> went through in the embedded Playwright browser. It's quite possible that the online ordering website saw that the browser never received a Success response, and didn't fully process the order.
My guess is that the additional time spent processing and uploading the video gave the browser sufficient time to clean up properly, with serendipity in timing.</p>
<h2>Pizza Lessons</h2>
<p>While I was bummed the pizza ordering functionality didn't run, I think it's in a good spot to try again in upcoming races.
I also learned a lot while building this out:</p>
<ul>
<li>Consistently screen-scraping a React client-side app with a browser running in the cloud: possible, but boy howdy is it finicky. If I were to redo project, I may opt for reverse engineering one of their native apps, focusing on triggering their APIs directly</li>
<li>Having a good workflow to simulate geospatial behavior is necessary. At first, I setup a geofence around my house for testing, but having to leave for a walk at 11pm gets pretty old, pretty fast</li>
<li>That said, don't skimp on real-world testing. Prior to the race, I was mostly testing the function by running it on my local workstation, not in a Lambda. The successes of the local functions gave me false confidence that everything was working as expected</li>
<li>If you're worried about running out of Casey's pizza during a gravel race, another option is to just let the groups ahead of you get more than 30 minutes ahead, so they have plenty of time to make more slices</li>
</ul>
<p>The code is available on GitHub: <a href="https://github.com/mattdsteele/spot-tracker-tracker/tree/main/pizza-function">https://github.com/mattdsteele/spot-tracker-tracker/tree/main/pizza-function</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New JFK assassination revelation could upend the lone gunman theory (191 pts)]]></title>
            <link>https://www.vanityfair.com/news/2023/09/new-jfk-assassination-revelation-upend-lone-gunman</link>
            <guid>37454707</guid>
            <pubDate>Sun, 10 Sep 2023 10:59:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vanityfair.com/news/2023/09/new-jfk-assassination-revelation-upend-lone-gunman">https://www.vanityfair.com/news/2023/09/new-jfk-assassination-revelation-upend-lone-gunman</a>, See on <a href="https://news.ycombinator.com/item?id=37454707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>He has kept his secret for 60 years.</p><p><strong>Paul Landis</strong> was one of two Secret Service agents tasked with guarding first lady Jacqueline Kennedy on November 22, 1963—the day President John F. Kennedy was assassinated. In a new book, <a data-offer-url="https://www.amazon.com/Final-Witness-Kennedy-Service-Silence/dp/1641609443" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://cna.st/affiliate-link/HR4R9gBZvZ4obp8cqsotyF1isewS25CYVHxrjcTEHpWnPkNciKMvpjqEB44jKjyUogEZRRHky5sahMh2UGBPGMk6hp3mn7RSvpuziBEcEnfcMrFNDo6BSYZ4fdcVVcKP8ZmY4Fc4dSxksAtopMDmPSLUpy839nQ8pj6TsF5sYoAVgfekXtMMe22n2AD&quot;}" href="https://cna.st/affiliate-link/HR4R9gBZvZ4obp8cqsotyF1isewS25CYVHxrjcTEHpWnPkNciKMvpjqEB44jKjyUogEZRRHky5sahMh2UGBPGMk6hp3mn7RSvpuziBEcEnfcMrFNDo6BSYZ4fdcVVcKP8ZmY4Fc4dSxksAtopMDmPSLUpy839nQ8pj6TsF5sYoAVgfekXtMMe22n2AD" rel="sponsored" target="_blank"><em>The Final Witness</em></a><em>,</em> to be published in October, Landis claims to have seen something that afternoon that he had never publicly admitted before. His secret, coming to light only now, will certainly reorient how historians and laymen perceive that grave and harrowing event. His account also raises questions about whether there might have been a second gunman in Dallas that day.</p><p>After much prodding and reflection, Landis, now 88, made the decision to begin laying out his recollections for publication. Because I have written three books on presidential history, and because Landis’s publisher, Chicago Review Press, happens to be my publisher, an editor there asked me to read a copy of the galley and offer my comments, which I did quite eagerly. In fact, I was so taken with Landis’s backstory and, upon spending time with him, so drawn to the facets of his tale that are not answered in the book (whose details were <a href="https://www.nytimes.com/2023/09/09/us/politics/jfk-assassination-witness-paul-landis.html">first reported</a> in <em>The New York Times</em>), that I probed further, maintaining a healthy dose of skepticism.</p><p>And yet, as I got to know him during more than a dozen meetings this past year, I was won over by his integrity and by the way his account of what he witnessed in Dallas—and in the grave months of American mourning that followed—remained consistent and unwavering. Over time, Landis and I became close. As a result, I am writing this assessment of his narrative (and of his motives for coming out with his story) not only as a historian and armchair investigator but as Landis’s confidant.</p><p>Twenty-three-year-old Paul Landis applied to become a Secret Service agent in 1958. He came from Worthington, Ohio, a suburb of Columbus, and had graduated from Ohio Wesleyan University 15 months earlier. A neighborhood boy, Bob Foster, who was friends with Landis’s sister, had joined the Secret Service two years before. After speaking with Foster, Landis thought being in the Secret Service sounded like the “coolest job in the universe.”</p><p>Landis was intrigued. But because he has always been slight of build, his immediate concern was whether he could meet the minimum height requirement (five feet, eight inches). During the physical exam, he stretched himself like a rubber band and, as he recalls, barely made it.</p><p>He started work in October 1959, at the time the youngest special agent, at 24. Just over a year later, John Kennedy was elected president; soon the young recruit was assigned the job of guarding the Kennedy children and, eventually, along with Special Agent <strong>Clint Hill,</strong> Mrs. Kennedy herself. Not all agents were given code names, but as a result of Landis’s new assignment, and because of his youth and boyish looks, he was eventually christened “Debut.”</p><p>Landis found himself deep in the inner workings of <a href="https://www.vanityfair.com/news/2004/05/jackie-kennedy-200405" target="_blank">Camelot</a>, coinciding with the apex of Jackie’s popularity. As an international superstar, she was the Princess Di of her era, and Landis was on hand as the media followed her every move. Landis traveled with the first lady and her daughter, <strong>Caroline,</strong> to Italy in 1962. (John Jr., her young son, remained back home.) Landis was the agent who helped speed and accompany Jackie to the Otis Air Force Base emergency facilities when she went into premature labor with son Patrick, who died two days after his birth in August 1963. That October, at the suggestion of Jackie’s sister, <a href="http://www.vanityfair.com/style/2016/04/jackie-kennedy-lee-radziwill-sisterhood" target="_blank">Lee Radziwill</a>, a trip to Greece followed for an excursion aboard the luxury yacht of the shipping magnate Aristotle Onassis.</p></div><div data-testid="RowWrapper"><figure><p><span>First lady Jackie Kennedy and Landis (second from left) in Italy; August 30, 1962</span><span>From AP.</span></p></figure><figure><p><span>Jackie Kennedy, her sister, Lee Radziwill, and Landis (far right) at a museum in Greece; October 8, 1963</span><span>Raoul Fornezza/AP.</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Then came November 22, 1963. A month after returning from Greece, Landis stood on the right rear running board of the Secret Service follow-up car, code-named “Halfback,” in the president’s motorcade as the vehicle headed from Dallas’s Love Field airport to a luncheon at the city’s Trade Mart. Landis was approximately 15 feet away when Kennedy was mortally wounded, a close witness to unspeakable horror.</p><p>That horror was compounded when the president’s limo reached Parkland Memorial Hospital, where Landis and Clint Hill tried to coax Jackie to release the president, whom, by that point, she had cradled in her lap. Climbing into the back seat area, which had been spattered with blood and brains and bullet fragments, both agents, according to their subsequent accounts, gently encouraged the first lady to let go.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>As she did—standing up to follow Hill and another agent, Roy Kellerman, who lifted her husband’s body onto a gurney and raced into the hospital—Landis saw and did something that he has kept secret for six decades, he says now. He claims he spotted a bullet resting on the top of the back of the seat. He says he picked it up, put it in his pocket, and brought it into the hospital. Then, upon entering Trauma Room No. 1 (at that stage, he was the only nonmedical person in the room besides Mrs. Kennedy, and both stayed for only a short period), he insists, he placed the bullet on a white cotton blanket on the president’s stretcher.</p><p>This secret, as it turns out, may upend <a href="https://www.archives.gov/research/jfk/select-committee-report/part-1a.html" target="_blank">key conclusions</a> of the Warren Commission, the body created by President Lyndon Johnson to investigate the assassination.</p><p>The sad fact is that Landis—though required to provide his version of events to the Secret Service (and, in a second report, to what would become the Warren Commission)—never sat for an interview before the FBI and never testified before the commission itself. He left the Secret Service months after the assassination and before the panel had finished its work and issued its report.</p><p>Landis, to this day, attests that in the first few years following the assassination, he was simply unable to overcome his PTSD from witnessing the murder firsthand. He says that the mental image of the president’s head, exploding, had become a recurring flashback. He maintains that he desperately tried to push down the memories. He also says he felt unable to read anything in detail about the assassination until some 50 years later, starting in 2014, when he began to come to grips with all that he had witnessed, suppressed, and finally processed.</p><figure><p><span>Landis holding up John F. Kennedy Jr. on the South Lawn of the White House; 1962</span><span>By Cecil Stoughton/White House Photographs/John F. Kennedy Presidential Library and Museum, Boston.</span></p></figure><p>Landis, two years shy of his 90th birthday, remains vigorous. He exercises daily and plays golf once a week. He works a steady job as a security guard and a kind of welcome ambassador at the Cleveland History Center.</p><p>But still, the <a href="https://www.vanityfair.com/news/2008/11/conspiracy200811" target="_blank">JFK conspiracy hounds</a> are legion, and with his new book’s publication, Landis can expect intense scrutiny. I made myself available to him as a way of helping to prepare him for what was to come.</p><p>In writing this analysis of his account, I have tried to determine if his story was possible, seen against the mountains of evidence, not to mention newly released documents collected over the years by the Warren Commission, congressional probes, <a href="https://www.vanityfair.com/news/2013/11/jfk-assassination-anniversary-books" target="_blank">countless individual authors</a>, and a kind of industry that has evolved, in which dozens upon dozens of “researchers” trade information and, inevitably, misinformation.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Over the decades, there have been endless theories surrounding the assassination, but not one of them considered that a Secret Service agent might have brought a fully intact bullet, found on top of the rear seat of the limousine, into Parkland Memorial Hospital and placed it on the president’s stretcher. Not one.</p><p>So there is virtue in looking anew at the evidence that was collected in 1963 and attempting to draw some tentative conclusions.</p><p>My own conclusion is that Landis’s story, for several reasons, is not just possible; it in fact makes more sense than the core finding of the Warren Commission, known as the “single bullet” theory.</p><p>That theory posits that a single bullet caused all of the wounds in Kennedy’s neck as well as all of the serious injuries to Texas governor John Connally—who was sitting in front of the president at the time—including the shattering of four inches of Connolly’s fifth rib and the fracturing of a major bone in his right wrist.</p><p>Yet the bullet that Landis now claims to have discovered that morning emerged largely intact and only moderately damaged, its base having been squeezed in.</p><p>By possibly placing the “magic bullet” theory in doubt, Landis’s disclosure raises as many questions as it answers. I will try to address some of them here.</p><p>First, it makes sense to retrace the main tenets of the Warren Commission’s official version of the assassination. According to the panel’s final report, issued in September 1964, three gunshots rang out as the president’s limousine passed by the Texas School Book Depository building in Dallas. Witnesses’ auditory memory differed, their testimony ranging from two to six shots. Most, however, recalled hearing a trio of blasts.</p><p>Three spent shells, in fact, were found under a window on the sixth floor of the book depository. Nearby, partially hidden by some cartons, a rifle with a scope was discovered, a cheap Mannlicher-Carcano. Lee Harvey Oswald, the man history identifies as the lone assassin, worked in that building. The commission determined that the three shots all came from the sixth floor of the book depository.</p><p>The commission concluded that two of the three shots had hit the occupants of the limousine: One bullet had transited Kennedy’s neck and then, most probably, hit Governor Connally, and one had fatally wounded Kennedy, striking his head. (Connally survived the attack, later becoming President Richard Nixon’s Treasury secretary.)</p><p>In the view of the task force, one of the shots had likely missed the limo and, though the conjecture was inconclusive, possibly struck a nearby cement curb, sending a fragment that hit a spectator some distance away, near an overpass, slightly grazing his face.</p><p>But what of the ammunition itself? Two large bullet fragments were found in the front seat of the limo, and slivers of lead fragments were recovered from an area below the jump seat where the governor’s wife, Nellie Connally, had been sitting.</p><figure><p><span>President Kennedy and the first lady with Texas governor John Connally; November 22, 1963</span><span>Bettmann/Getty Images.</span></p></figure><p>At Parkland Memorial Hospital, on the day of the assassination, an additional intact bullet was discovered on a stretcher. Through testing, commission investigators determined that the copper-jacketed, 6.5-millimeter bullet matched the rifling of the Mannlicher-Carcano that had been abandoned on the sixth floor of the depository. Testing on the bullet fragments resulted in a similar finding.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>One key point to raise here concerns a fundamental underpinning of the Warren Commission report: the supposition that the retrieved intact bullet had been discovered on Governor Connally’s stretcher, not on Kennedy’s. It was from this assumption, in part, that the commission reached its pivotal conclusion: The available evidence indicated that “the bullet found on the Governor’s stretcher”—the single bullet—“could have caused all his wounds.” Over time, critics have referred to it as the “pristine” or “magic” bullet.</p><p>Moreover, if that single bullet did <em>not</em> cause the damage, then ballistics tests performed at the time suggest it would have been almost impossible for Oswald to have fired all three shots within the tight, multi-second time frame derived from the other main piece of evidence of the assassination: the Zapruder film, a <a data-offer-url="https://www.life.com/history/jfks-assassination-how-life-brought-the-zapruder-film-to-light/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.life.com/history/jfks-assassination-how-life-brought-the-zapruder-film-to-light/&quot;}" href="https://www.life.com/history/jfks-assassination-how-life-brought-the-zapruder-film-to-light/" rel="nofollow noopener" target="_blank">26.6-second home movie</a> recorded in color by bystander Abraham Zapruder, a local clothing manufacturer who happened to have brought along his Bell &amp; Howell 8mm camera that day and, by happenstance, captured the entire sequence of the assassination.</p><p>In his book, Paul Landis now says that when Jackie Kennedy stood up to enter Parkland, he looked over and saw that a bullet was improbably sitting on top of the rear seat of the limo, right around the spot where the limo’s detachable roof, which had been removed that day, would have otherwise been affixed to the trunk. Also, amid the blood and gore, Landis remembers, were two bullet fragments on the back seat, next to where Jackie had been sitting.</p><p>Landis contends that he reached over, picked up the lone bullet nestled in the crevice, and decided to place it in his pocket, mindful that if it were left there, precariously, it might be overlooked, pilfered by an unauthorized passerby, or misplaced once the president’s body was removed. Accompanying the first lady into Parkland, he says, he brought the bullet with him and, without conferring with Mrs. Kennedy, his fellow agents, or hospital staffers, placed it on JFK’s stretcher, thinking it needed to be with the body for the autopsy. As such, he contradicts a key linchpin underlying the findings of the Warren Commission. The bullet—as Landis tells it—was not from Connally’s stretcher.</p><p>From Landis’s description, three lines of inquiry emerge.</p><p>First, how did a largely intact bullet wind up on the ledge of the back seat, where JFK had been riding when he was shot?</p><p>Second, if Landis’s account is accurate, could Lee Harvey Oswald—who shot the president from a vantage point <em>behind</em> the motorcade—have acted alone, as the Warren Commission theorized?</p><p>And finally, why did Landis decide to keep this information to himself for six decades?</p></div><div data-testid="RowWrapper"><figure><p><span>A view of the Kennedys’ motorcade</span><span>Corbis/Getty Images.</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>There is no way to know for sure how the undamaged bullet ended up on top of the rear seat. But there seem to be only two real possibilities, both of which can be inferred from the Zapruder film. One way is that an undercharged bullet, having already been lodged in the president’s back from an initial gunshot, was jolted out of his body after a subsequent shot to the head caused his upper body to be thrown violently back against the seat, bouncing off of it with great force. A second possibility is that at some point in those hectic moments, the bullet fell out of the president’s back and onto the first lady’s clothing (her white-gloved hand did brush hard against his back, around where the bullet could have been embedded at the moment of the final shot). As one can see in the Zapruder film, Jackie, at this stage, climbed onto the trunk of the speeding car, possibly to look for or retrieve a portion of her husband’s skull—or out of sheer panic to take cover from further gunshots. In fact, the section of the back seat over which she stretched corresponds to the spot where Landis says he found the bullet.</p><p>The autopsy evidence, as developed the night of the assassination, supports either one of these results.</p><p>A short recap is in order. Initially, President Kennedy was declared dead at Parkland—his body lying face-up on the table after the surgical team had performed a tracheotomy, hoping to provide needed oxygen through a ventilator to keep him breathing (which by that time was described as gasping or <a href="https://www.google.com/search?sca_esv=558593241&amp;rlz=1C1GCEA_enUS913US913&amp;sxsrf=AB5stBjGKpe8xhb1GKxgYo20DdGjFHlKCQ:1692557166565&amp;q=parkland+anesthesiologist,+jfk&amp;tbm=vid&amp;source=lnms&amp;sa=X&amp;ved=2ahUKEwjq67Ll8uuAAxUvIzQIHfFbDBAQ0pQJegQIChAB&amp;biw=1280&amp;bih=603&amp;dpr=1.5#fpstate=ive&amp;vld=cid:ab3501ab,vid:DX58vrL5ZiA" target="_blank">agonal respiration</a>). These emergency room doctors used what they believed was an entry bullet wound in the front of the president’s neck to create the tracheotomy. They were apparently unaware of a bullet hole in the president’s back.</p><p>But later that night, an autopsy began at Bethesda Naval Hospital, near Washington, DC. During the procedure, doctors examined the president’s remains, only to discover a small bullet hole in the right shoulder, about five inches down from the top of the collar. This injury had gone unnoticed at Parkland since the president was declared dead before his body could be surveyed in its entirety. The Bethesda pathologists were puzzled when they probed the wound because it clearly was an entrance puncture, but it did not seem to have an exit wound, even though X-rays showed no bullet in the body.</p><p>In fact, the shoulder wound was shallow. Two doctors found that they could not pass more than half a pinky finger into the opening. Metal probes likewise uncovered no path of the bullet through the body.</p><p>Standing in proximity to the doctors were two FBI agents, Frank O’Neill and Jim Sibert, who had been dispatched by the bureau’s director, J. Edgar Hoover, to witness the autopsy and recover bullets or bullet fragments for the FBI lab. In their written statement, the agents discussed the frustration of the Bethesda doctors when they could not locate a bullet or exit wound for the projectile that had entered the president’s shoulder.</p><p>That night, according to the agents’ account, one of them placed a call to the FBI lab and found out that a “stretcher bullet” had been discovered at Parkland. Doctors used this information to theorize that “this accounted for no bullet being located which had entered the back region and that since external cardiac massage had been performed at Parkland Hospital, it was entirely possible that through such movement the bullet had worked its way back out of the point of entry and had fallen on the stretcher.”</p><p>The next morning, the Bethesda pathologists, as stated in their Warren Commission testimony, were told by Parkland doctors that the wound in the front of Kennedy’s neck was more than just the result of the tracheotomy they had performed. In fact, the Parkland team stated, there had been a bullet hole in the anterior (front) of the neck, and the ER staff had used that wound to create the tracheotomy. No one at the autopsy, according to FBI agents Sibert and O’Neill, had suspected there was a hole in the <em>front</em> of the president’s neck. With this new information, the Bethesda doctors revised their findings and assumed that the front wound was an exit for the bullet that had entered the president’s body from the back.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span>Warren Commission members Hale Boggs, John Cooper, and Richard Russell leave the Texas School Book Depository after inspecting President Kennedy’s assassination scene</span><span>Bettmann/Getty Images.</span></p></figure><p>There were problems with this inference. The neck and shoulder had not been sectioned by those performing the autopsy to establish a bullet path. And by the time of the revelation of the front-neck injury, the president’s body had been brought to the White House to lay in repose in the East Room. (The next day, it lay in state in the Capitol rotunda.) Further, the wound in the back, according to Silbert and O’Neill, did not align with the location of the front-neck wound; such a pathway would have required a bullet traveling from the book depository, behind the motorcade, to have changed course inside the president’s body so as to exit higher up, through the neck, without hitting any bone to alter its course.</p><p>Agents O’Neill and Sibert didn’t buy it. “I do not see how the bullet that entered below the shoulder in the back could have come out the front of the throat,” O’Neill told the House Select Committee on Assassinations in 1978.</p><p>Landis’s discovery of the bullet on top of the rear seat, if true, comports with the initial finding: that the bullet had lodged superficially in the president’s back before being dislodged by the final blast to his head. It also explains the “pristine” nature of the bullet.</p><p>The genesis of the “single bullet” theory was twofold.</p><p>First, the Zapruder footage showed Kennedy reacting to the bullet that hit him in the back—and then, apparently, exited through the front of his neck (his arms spasmodically began to rise, elbows out, fists shielding his throat)—<em>about a second or so</em> before Connally seemed to react to his own wounding. To the Warren Commission staff, that double reaction on the part of the two men was puzzling. Given the type of weapon Oswald was using, there would have been no way for him to have gotten off two firings in such a short span of time.</p><p>Secondly, when the panel attempted to recreate the shooting in a manner consistent with the Zapruder film, FBI marksmen found that it took about 2.3 seconds to shoot, reload the bolt-action rifle, aim, and shoot again. Given Governor Connally’s reaction time, there did not appear to have been enough time for Oswald to have taken a second shot so quickly, let alone with any accuracy.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>Howard Willens,</strong> an assistant counsel to the Warren Commission, and the author of the 2013 book <em>History Will Prove Us Right,</em> wrote about this dilemma: “If the interval between the first and second shots covered a span of less than 2.25 seconds, the time estimated to be necessary for the assassin to fire two shots, it might suggest that a second rifle was involved.”</p><p>The commission’s solution, however, championed by staff attorney Arlen Specter (who would become a US senator from Pennsylvania), was that the same bullet that hit Kennedy must have gone on to hit Connally on his right side. Connally’s second-later response was explained by the commission as a “delayed reaction” to an earlier wounding.</p><p>But, as noted, that theory depended on the single bullet having been found on Connally’s stretcher at Parkland Memorial Hospital, not on Kennedy’s stretcher.</p><p>The panel’s members speculated that the bullet, after causing Kennedy’s and Connally’s wounds, ended up superficially stuck in Connally’s left leg and must have dropped onto his stretcher once inside the hospital.</p><p>That said, the original evidence from 1963 is far from clear on this point.</p></div><div data-testid="RowWrapper"><figure><p><span>President Kennedy stands on the Texas airstrip with Jackie Kennedy and Governor John Connally</span><span>Bettmann/Getty Images.</span></p></figure><figure><p><span>Governor Connally recovering in his hospital room with his wife, Nellie</span><span>Bettmann/Getty Images.</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The provenance of the bullet is also important in supporting or refuting Paul Landis’s purported memory. How was that bullet found? And how did it make its way to the FBI lab in Washington, DC, on the night of the assassination?</p><p>Landis’s recollection, as stated above, is that he found the undeformed bullet on top of the back seat of the limousine. “It was resting in a seam where the tufted leather padding ended against the car’s metal body,” he writes. When Jackie Kennedy stood up to follow her husband into the hospital, he saw it. He picked up the bullet, worried that souvenir seekers or others might take it or move it.</p><p>Upon arriving inside the emergency room, as stated above, he was jammed in with the first lady and a gathering horde of doctors and nurses. Standing near the feet of the president’s body, Landis left the bullet on his stretcher, as he believed it was crucial evidence and needed for the autopsy, which, under Texas law, should have taken place in Dallas.</p><p>But then a new chain of events overtook the gruesome sequence surrounding the assassination. A decision was made to transfer the president’s body, along with the first lady, Vice President Johnson, and others, back to Air Force One at Love Field. And with new tasks taking precedence for Landis—and the overwhelming national shock of the first assassination of an American president in 62 years (since the death of William McKinley in 1901)—the special agent simply never gave the bullet a second thought, he says. He had left it where someone would find it.</p><p>Landis didn’t make reference to the bullet in either of the two reports he submitted, hastily written in the turbulent days following the assassination. One short file, written two days after the funeral, didn’t even mention Parkland Memorial Hospital. A second, typed three days later—a day after <em>Life</em> magazine journalist Theodore White interviewed Jackie at the Kennedy compound in Hyannis Port, in what became known, famously, as the “Camelot” interview—was drafted during a time of deep shock and trauma.</p><p>That Thanksgiving, November 28—three days after the state funeral at which world leaders marched behind Mrs. Kennedy in the streets of Washington, DC—Landis and Hill traveled to Hyannis Port in a security capacity, protecting Jackie and her children. The agents had no time off to regroup or get their bearings. Sleep had eluded them. Landis had been up for practically four days straight. In the months after Lyndon Johnson was sworn in and assumed the presidential reins, Landis’s role switched from being part of the overall White House protection group to working full time for the former first lady. (Congress passed an act to authorize this service.) With this change of responsibilities, he found it hard to think of much beyond the weeks ahead. And if his thoughts did migrate back to November 22, he dwelled on the horrific scenes of the assassination, and rarely on what he says he considered a minor detail: the fact that he had picked up a bullet and placed it next to the president’s body.</p><p>The evidence from 1963 makes it fully plausible that the stretcher on which the bullet was found could have been President Kennedy’s. How so? A Parkland Memorial Hospital engineer, Darrell Tomlinson, was asked on November 22, before the president’s remains had been taken from the hospital to travel back north, to set the controls of the elevator in the emergency area—the one that had taken the wounded Governor Connally up to the second floor for surgery—so that the elevator would only be operable manually. The security team had determined that only people with official clearance would be allowed access; Tomlinson was instructed to control who got on the elevator and where they would go.</p><p>When he pushed the button to open the elevator, he later recalled, there was a stretcher in the elevator—one that the Warren Commission presumed was Governor Connally’s stretcher, returned from the surgery floor. Tomlinson testified that the stretcher had some sheets on it and a white covering on the pad, but no bullet. He moved the stretcher out of the elevator and placed it against a wall.</p><p>However, Tomlinson testified that there was <em>another</em> stretcher already in the hall, which had been placed in front of a men’s restroom in the corner. <em>That</em> stretcher had bloody sheets and some used medical paraphernalia on it.</p><p>Tomlinson said that sometime later, “an intern or doctor,” in order to use the bathroom, pushed the stretcher out of the way but failed to return it to its spot against the wall after leaving. Tomlinson roughly pushed it back against the wall, and when he did so, he claimed, a bullet rolled out from under the mat. This was clearly not Connally’s stretcher.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span>Jackie Kennedy looking into the ambulance, November 22, 1963. Landis stands just behind her (third from right).</span><span>Bettmann/Getty Images.</span></p></figure><p>Arlen Specter, who had traveled to Dallas to take Tomlinson’s deposition in March 1964, was thunderstruck when Tomlinson relayed this scenario. To judge from a transcript of that conversation, Specter spent much of the remainder of his time with Tomlinson essentially trying to talk him out of his recollection, causing a distressed Tomlinson to say he just was not sure about his memory.</p><p>But the Q&amp;A itself clearly suggests that Tomlinson, unprompted and unbadgered, had a cogent recollection that a bullet, wherever else it ultimately ended up, had come from the stretcher that had already been left in the hall in front of the men’s room.</p><p>In its final report, the Warren Commission mentioned nothing about this detail from Tomlinson’s account. Instead, the panel largely dismissed Tomlinson’s testimony, writing that even though he was “not certain whether the bullet came from the Connally stretcher or the adjacent one,” the commission “has concluded that the bullet came from the Governor’s stretcher.”</p><p>And what of the contemporaneous evidence from the witnesses who provided care to the governor in the emergency room and on the surgery floor?</p><p>When Connally was brought in from the limo, he was in great distress. He was taken to Trauma Room No. 2, where his clothes were immediately cut off. No one saw a bullet sticking out of his leg when his pants were removed. Neither was a bullet seen on the stretcher nor found in his clothing. Once stabilized, he was wheeled to the emergency room elevator and taken to surgery on the second floor.</p><p>Connally was then transported from the emergency room stretcher and placed on an operating table. No one testified to having seen a bullet on that stretcher. All of the medical paraphernalia on Connally’s stretcher was removed by a nurse before the stretcher was put back in the elevator. And the attendant who placed that stretcher onto the elevator did not recall having seen a bullet.</p><p>Darrell Tomlinson, however, went further. He said that as soon as he found the bullet, he alerted O.P. Wright, the chief of security at the hospital. Wright, in turn, gave the bullet to Secret Service agent Dick Johnsen, who was in the process of leaving the hospital with the president’s casket and Mrs. Kennedy. Johnsen wrapped the bullet in a handkerchief and placed it in his pocket. He then rode on Air Force One back to Washington.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Johnsen was assigned to sit with the casket and near Mrs. Kennedy in the back of Air Force One on the return journey to the nation’s capital. The body, the widow, and the bullet all returned to Washington on the same plane, in close proximity.</p><p>When Johnsen got back to the White House, he typed a short note to describe the bullet and how he ended up with it. “The attached expended bullet was received by me about 5 min., prior to Mrs. Kennedy’s departure from the hospital,” he wrote. “It was found on one of the stretchers located in the emergency ward of the hospital. Also on this same stretcher were rubber gloves, a stethoscope and other doctor’s paraphernalia.”</p><p>Johnsen dated his note: “7:30 p.m., Nov. 22, 1963.”</p><p>Johnsen then handed over the bullet to the director of the Secret Service, James Rowley. Rowley, finally, gave the bullet to the FBI that very night; it was signed in as the first piece of evidence in the assassination investigation, labeled with the designation “Q1.”</p><p>That evening, the initial supposition was that the bullet had come from JFK’s stretcher because the autopsy doctors at Bethesda, attempting to understand the whereabouts of the bullet that had entered Kennedy’s back, thought it might have been lodged in his back and then fallen out when rigorous chest massages were performed at Parkland.</p><p>It was only after the autopsy (and after the president’s body had been moved to the White House) that Parkland doctors told the pathologists that they had used a bullet wound in the front of Kennedy’s neck to make a tracheotomy.</p><p>Upon hearing this, the autopsy doctors tentatively revised their thesis and surmised that the bullet that entered Kennedy’s back must have exited through the front of his neck.</p><p>And so the problem started: The Warren Commission could not explain what happened to the bullet if it exited through the <em>front</em> of Kennedy’s neck. Howard Willens described the Warren Commission staff’s internal debate: “There was one basic question that now seems very simple,” he wrote. “Where did the bullet go after it exited the president’s neck?”</p><p>Paul Landis, in effect, answers that question: It ended up in a crevice on top of the back seat. It seems unlikely that the bullet traversed the president’s body and exited through the front of his neck.</p><p>Maybe the bullet entered the president’s back only superficially; these WW II–vintage bullets, after all, were notoriously undercharged with gunpowder. If this were the case, it might have indeed fallen out when he was violently struck with the final shot; when Mrs. Kennedy, at one point, pushed him down onto the seat; or when she clambered onto the trunk, the bullet falling off of her and onto the top of the back seat.</p><p>To be fair to the record, the Warren Commission’s findings suggested that Kennedy’s stretcher was not the stretcher in the elevator lobby because the nurses who had treated the president testified that once they’d been informed that a casket had arrived at Parkland, they had removed bloody sheets from his stretcher before moving it across the hall to Trauma Room No. 2.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But given the blood-soaked scene described by all of the medical personnel in Trauma Room No. 1, it is not unreasonable to assume that an orderly in Trauma Room No. 2 preemptively moved the president’s stretcher into the hall, stained sheets, medical paraphernalia, and all, to be further cleaned up by other attendants.</p></div><div data-testid="RowWrapper"><figure><p><span>Attorney General Robert Kennedy, Senator Edward Kennedy, the first lady, and Landis (far right) walking during the funeral procession on November 25, 1963</span><span>Bettmann/Getty Images.</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>What does all this mean when considering whether Lee Harvey Oswald, as proposed by the Warren Commission, was the lone assassin? It certainly raises the stakes that another shooter might have been involved.</p><p>First, if the “pristine” bullet did not travel through both Kennedy and Connally, somehow ending up on Connally’s stretcher, then it stands to reason that Connally might have actually been hit by a separate bullet, coming from above and to the rear. The FBI recreation suggests that Oswald would not have had enough time to get off two separate shots so quickly as to hit Connally after wounding the president in the back. A second shooter must be considered.</p><p>And what about the bullet wound in the front of Kennedy’s neck? In one of the earliest critiques of the Warren Commission report, <strong>Josiah Thompson,</strong> author of <em>Six Seconds in Dallas,</em> proposed, not unreasonably, that the front-neck wound might have come from a bullet or bone fragment that was driven down and exited through the president’s throat from the final blast to his skull.</p><p>But there are other, darker explanations arising from the secrecy surrounding the X-rays and photographs taken at the autopsy and then not made public for decades. Jerrol F. Custer, the principal X-ray technician at the autopsy, testified in 1997 that there were several small metallic fragments in the cervical spine (the spinal region directly below the skull), which were visible in an X-ray, and that this was one of three X-ray exposures he took that night that went missing from the collection in the National Archives. This might have contained evidence of a shot from the front of the motorcade—a frangible bullet that disintegrated into tiny pieces after entry into the body. A heavy lift, for sure, but medical staffers who saw the front-of-the-neck wound before the tracheotomy believed it was an entrance wound because of its neatness.</p><p>Though some observers, down through the years, have mentioned the possibility of a second shooter, perhaps positioned on the so-called “grassy knoll” area along the route of the motorcade, neither this article nor Landis’s book has the insight or forensic expertise to hazard any new conclusions in this area. Others will have to analyze the evidence in full to see where it now leads. But, without question, this revelation will spark major debates. And that should not be surprising. The Warren Commission report, though lauded right after it was issued, has had its share of credibility detractors as time has passed. In 2013, a week before the 50th anniversary of the assassination, <a href="https://news.gallup.com/poll/165893/majority-believe-jfk-killed-conspiracy.aspx" target="_blank">public opinion polls</a> found that more than 60% of Americans believed the president’s murder had not been the work of one man, as the commission contended, but part of some kind of conspiracy.</p><p>There are many reasons for this skepticism, including a growing public distrust toward governmental pronouncements. And yet a chronic source of questioning has been the commission’s claim that a single bullet wounded both Kennedy and Connally, emerging mostly undamaged after having done so much damage.</p><p>Perhaps Landis’s revelations will offer a critical mass of additional conjecture to prompt a reassessment of the “magic bullet” theory.</p><p>The more confounding question, in my view, is a simple, human one: Why did Paul Landis decide to keep this information to himself for 60 years? The answer is complicated. But it is in many ways understandable if one considers his predicament at the time and in the years that followed.</p><p>Upon leaving the bullet on Kennedy’s stretcher, Landis explains today, he felt that he had done the right thing, expecting an autopsy and mindful of the need for the bullet to remain with the body. Like all of the Secret Service members on hand that day—and, indeed, the entire nation—he was also racked with grief and loss (to say nothing of PTSD, which was an unrecognized condition at the time). For Landis, however, a man who had been a constant presence in his life had been slain right in front of him—a man whose wife’s safety had been, in part, his own responsibility.</p><p>But soon the intensity of the moment enveloped him. Landis’s focus turned to responding to Mrs. Kennedy at Parkland; attending to the needs of the family upon the return of the remains to the capital; accompanying Jackie and the president’s brother Robert F. Kennedy during the nine-hour wait at Bethesda as the autopsy proceeded; remaining on protective duty during one of the riskiest state funerals in history; and then staying on in <a href="https://www.vanityfair.com/style/society/2014/10/jacqueline-kennedy-jfk-assassination-depression" target="_blank">Jackie’s peripatetic orbit</a> for the next several months—unable to find the time to properly attempt to cope with the raw trauma he had experienced.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In May, nearly six months after the assassination, Landis realized that the ordeal had taken its toll; concerned about his own mental health, he decided he couldn’t take it anymore. By August, at age 29, he had left the Secret Service. At the time, the Warren Commission had not issued its report, nor had Landis been interviewed for it; the public had not yet heard of the “single bullet” theory.</p><p>From that point onward, Landis now says, he withdrew from his more public-facing life, adamantly refusing to read more about the assassination. He avoided most requests for interviews by the media. He assumed, without looking at the final report, that the Warren Commission must have gotten it right.</p><p>Then, around 2010, things began to thaw. A project by Secret Service agent <strong>Gerald Blaine</strong> brought Landis out of his shell. Blaine was writing a book, <em>The Kennedy Detail,</em> with <strong>Lisa McCubbin,</strong> and Landis agreed to participate, mainly, he says, because his friend Clint Hill had also signed on. The agents met in Dallas to film an accompanying documentary, and Landis discovered he was not alone in feeling guilty and isolated following the assassination. But even then, Landis was not yet prepared to tell his own story.</p></div><div data-testid="RowWrapper"><figure><p><span>Jackie Kennedy mourns at the funeral with children Caroline and John, brothers-in-law Ted and Robert, and Landis</span><span>From Getty Images.</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>That all changed in 2014 when Landis finally read a 1967 book on the assassination—a gift from a friend. When he began to page through <em>Six Seconds in Dallas,</em> by Josiah Thompson, he first saw that CE 399—the “pristine” bullet—was believed to have come from Governor Connally’s stretcher. Landis claims today that he immediately reached out to Clint Hill to tell him that he brought the bullet into Parkland and left it on the president’s stretcher, not the governor’s. He needed to correct this record.</p><p>One issue at the time was that the Secret Service was struggling with <a href="https://www.nbcnews.com/news/us-news/long-list-breaches-scandals-secret-service-under-obama-n215751" target="_blank">very public scandals</a>, ranging from breaches of the White House grounds by intruders to accusations of liaisons with prostitutes in South America. And so, in deference to the troubles roiling the agency, Landis decided to remain mum.</p><p>In late 2015, however, Landis had a change of heart, he insists. He spoke with former Secret Service director Lewis Merletti, who had lived nearby, in Beachwood, Ohio, as the former head of security for the Cleveland Browns. Landis told Merletti of his secret; soon thereafter, Landis began the odyssey of carefully writing his book.</p><p>In the intervening seven years, he struggled with his conscience. His guilt, in my estimation, stemmed in part from a creeping concern that others might accuse him of having done something wrong by moving the bullet. Moreover, he must have worried, to some degree, about not having spoken out about finding the bullet in the first place—and not having sought to clarify the record more speedily once it became apparent to him that many historians and the public at large had cast doubt on the findings of the Warren Commission. Another factor amplifying his angst, I would imagine, was that the longer he remained silent, the harder it became to speak out.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Adding to his concerns, I’m sure, was the fact that Landis had been criticized—unfairly, in my view—for having stayed out most of the night before the assassination. Over the years, journalists and others have written sporadically about how “nine members” of the Kennedy Secret Service contingent went out drinking into the wee hours of November 22. A detailed report, with statements by the agents, was gathered following the assassination, and those comments are included as part of the record in the Warren Commission report <a data-offer-url="https://www.maryferrell.org/showDoc.html?docId=1135#relPageId=680" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.maryferrell.org/showDoc.html?docId=1135#relPageId=680&quot;}" href="https://www.maryferrell.org/showDoc.html?docId=1135#relPageId=680" rel="nofollow noopener" target="_blank">volumes</a>.</p><p>That investigation showed that around midnight on November 21, the Secret Service agents arrived in Fort Worth at the Hotel Texas with the president and first lady. Kennedy had <a data-offer-url="https://www.jfklibrary.org/asset-viewer/archives/JFKWHF/WHN17/JFKWHF-WHN17/JFKWHF-WHN17" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.jfklibrary.org/asset-viewer/archives/JFKWHF/WHN17/JFKWHF-WHN17/JFKWHF-WHN17&quot;}" href="https://www.jfklibrary.org/asset-viewer/archives/JFKWHF/WHN17/JFKWHF-WHN17/JFKWHF-WHN17" rel="nofollow noopener" target="_blank">barnstormed</a> the state that day with events and motorcades in San Antonio and Houston. Though exhausted and famished, the agents were nonetheless used to putting in long hours in service to a youthful, hard-charging—and sometimes hard-partying—president. Double shifts were not uncommon.</p><p>Some members of the group, seeking food, were encouraged by Merriman Smith, a respected wire service reporter with United Press International, to visit a complimentary room set up by the Fort Worth Press Club in a nearby hotel. By that late hour, however, the food was gone. Several agents had a beer or two. Some had mixed drinks. Landis, for his part, professed to having had a scotch and soda.</p><p>Still hungry, the agents were told of a late-night coffeehouse, The Cellar, that might have something to eat. The Cellar was known for its “beatnik” performers—poetry-reading and guitar-playing—and a female waitstaff that wore skimpy outfits. Landis was among the agents who went to The Cellar, where, as he mentioned in one of his 1963 statements to authorities, he had two “Salty Dicks”—a local concoction that might or might not have had alcohol. Landis attested that he drank grapefruit juice, which he says today had no alcohol. At 4 a.m. CT, he says, he left to retire to his hotel.</p><p>By 8 a.m., Landis had breakfast and was asked by Roy Kellerman, the man in charge of the entire unit, to assist in protection for the president, who had decided to give an impromptu speech in front of the Hotel Texas. He later helped escort Mrs. Kennedy to a breakfast sponsored by the Fort Worth Chamber of Commerce at the hotel. He contends that he and his fellow agents that day were amped up by the heightened alertness involved with a presidential motorcade. They were likely stoked, as well, by the adrenaline of the crowds and the excitement and pomp. To a man, everyone involved who was interviewed for the Warren Commission said that all of the agents, including those who had gone out the night before, showed up on time for work, exhibiting no effects of excess drinking. Photos from that morning and day, in fact, show Landis bright-eyed and working diligently in his protective capacity.</p><p>Columnist Drew Pearson, however, got wind of the late-night excursion and in the week following the assassination published an exposé about the agents’ behavior. It caused an uproar. The incident, in fact, has continued to attract attention: In 2014, author <strong>Susan Cheever,</strong> finishing up a book called <em>Drinking in America,</em> reconstructed her own <a href="https://www.vanityfair.com/news/politics/2014/10/secret-service-jfk-assassination" target="_blank">narrative of the evening</a> for <em>Vanity Fair,</em> quoting both Paul Landis and Clint Hill.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><div><p>I believe there is little reason to think that late-night alcohol consumption contributed to the agents’ response times or decision-making that day. Hill, who had been out with the others, reacted quickly in trying to get to the limo. In a six-second incident, he did not make it in time. The agent on the running board in front of Landis, Jack Ready, started to jump off himself but was called back by the agent in charge of that car, Emory Roberts, who feared that Ready might be run over and realized that Hill was already on his way toward the vehicle. Roberts had not been out the night before, drinking or otherwise. The same is true of the only agent who really had a chance to avert disaster, driver Bill Greer, who might have taken evasive action with the president’s limo once the shooting started. The agent next to Greer in the front passenger seat of the presidential limo, Roy Kellerman, likewise didn’t react in time. Kellerman had not been out drinking; he had gone straight to bed once they checked into the Hotel Texas.</p><p>Landis recognized that, despite any accusations to the contrary, there was nothing he could have done to prevent the tragedy. He also knew that he risked being criticized for having stayed out most of the night and having violated Secret Service policy by drinking any alcohol that might possibly impair him “if called upon to perform an official duty.” This no doubt contributed to his overall reluctance to come forward.</p><p>More to the point, I sense that he had an underlying guilt about what he <em>might</em> have done. He had found a bullet—the first piece of evidence logged into the record of the assassination of a US president—and then he went on his way, alone, in private.</p><p>He understands today how history might have changed had he told the pathologists at Bethesda that night where the “stretcher bullet” had come from—but he was not the one in the autopsy room (Kellerman and Greer were), and he had his hands full with the stream of family and mourners who arrived on the hospital’s 17th floor to console Jackie.</p><p>Landis is an upright, respected, private man. His moral authority and personal credibility have always been two hallmarks of his persona. My gut tells me that in his own way, he didn’t want to be the guy who had done a good deed under intense pressure, and then, forevermore, was raked over the coals for it. Which is how society often treats people these days. That anxiety might well have led to a sense of regret—even though his initial actions had been completely laudable.</p><p>In addition, he was in his late 20s at the time, a man whose values were grounded in those of the 1950s and ’60s. Silence and discretion, to him, had always been virtues. And he didn’t feel that it was appropriate to change his stripes and “go public”—drawing attention to his own behavior—when conspiracy theorists ran rampant, when other agents had been in the press over the years, and when President Kennedy had been killed, in effect, on his watch.</p><p>All of this, I contend, contributed to his years of silence.</p><p>But nothing, as I see it—and as Landis himself sees it—should detract from the fact that he has now come forward with his version of what happened on that dreadful day. And history will be the better for it.</p><hr><p><em>James David Robenalt is an attorney and</em> Washington Post <em>contributor. He is the author of four nonfiction books:</em> The Harding Affair; Linking Rings; Ballots and Bullets; <em>and</em> January 1973: Watergate, Roe v. Wade, Vietnam, and the Month That Changed America Forever.</p></div><div data-testid="LinkStack"><ul><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"><p><a href="https://www.vanityfair.com/style/2023/08/kyle-deschanel-the-rothschild-who-wasnt" target="_blank">Meet Kyle Deschanel</a>, the Pretend Playboy Who Seems to Have Fooled Half of Manhattan</p></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nginx Unit – Universal web app server (515 pts)]]></title>
            <link>https://github.com/nginx/unit</link>
            <guid>37453854</guid>
            <pubDate>Sun, 10 Sep 2023 08:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nginx/unit">https://github.com/nginx/unit</a>, See on <a href="https://news.ycombinator.com/item?id=37453854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">NGINX Unit</h2>
<h2 tabindex="-1" dir="auto">Universal Web App Server</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nginx/unit/blob/master/docs/unitlogo.svg"><img src="https://github.com/nginx/unit/raw/master/docs/unitlogo.svg" alt="NGINX Unit Logo"></a></p>
<p dir="auto">NGINX Unit is a lightweight and versatile open-source server that has
two primary capabilities:</p>
<ul dir="auto">
<li>serves static media assets,</li>
<li>runs application code in seven languages.</li>
</ul>
<p dir="auto">Unit compresses several layers of the modern application stack into a potent,
coherent solution with a focus on performance, low latency, and scalability. It
is intended as a universal building block for any web architecture regardless
of its complexity, from enterprise-scale deployments to your pet's homepage.</p>
<p dir="auto">Its native <a href="#openapi-specification">RESTful JSON API</a> enables dynamic
updates with zero interruptions and flexible configuration, while its
out-of-the-box productivity reliably scales to production-grade workloads. We
achieve that with a complex, asynchronous, multithreading architecture
comprising multiple processes to ensure security and robustness while getting
the most out of today's computing platforms.</p>
<h2 tabindex="-1" dir="auto">Quick Installation</h2>
<h3 tabindex="-1" dir="auto">macOS</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ brew install nginx/unit/unit"><pre>$ <span>brew install nginx/unit/unit</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#homebrew" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Docker</h3>

<p dir="auto">For a description of image tags, see the
<a href="https://unit.nginx.org/installation/#docker-images" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Amazon Linux, Fedora, RedHat</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit &amp;&amp; chmod +x setup-unit
# ./setup-unit repo-config &amp;&amp; yum install unit
# ./setup-unit welcome"><pre>$ <span>wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit <span>&amp;&amp;</span> chmod +x setup-unit</span>
# <span>./setup-unit repo-config <span>&amp;&amp;</span> yum install unit</span>
# <span>./setup-unit welcome</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#official-packages" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Debian, Ubuntu</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit &amp;&amp; chmod +x setup-unit
# ./setup-unit repo-config &amp;&amp; apt install unit
# ./setup-unit welcome"><pre>$ <span>wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit <span>&amp;&amp;</span> chmod +x setup-unit</span>
# <span>./setup-unit repo-config <span>&amp;&amp;</span> apt install unit</span>
# <span>./setup-unit welcome</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#official-packages" rel="nofollow">docs</a>.</p>
<h2 tabindex="-1" dir="auto">Running a Hello World App</h2>
<p dir="auto">Unit runs apps in a
<a href="https://unit.nginx.org/howto/samples/" rel="nofollow">variety of languages</a>.
Let's consider a basic example,
choosing PHP for no particular reason.</p>
<p dir="auto">Suppose you saved a PHP script as <code>/www/helloworld/index.php</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<?php echo &quot;Hello, PHP on Unit!&quot;; ?>"><pre><span>&lt;?php</span> <span>echo</span> "<span>Hello, PHP on Unit!</span>"; <span>?&gt;</span></pre></div>
<p dir="auto">To run it on Unit with the <code>unit-php</code> module installed, first set up an
application object. Let's store our first config snippet in a file called
<code>config.json</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;helloworld&quot;: {
        &quot;type&quot;: &quot;php&quot;,
        &quot;root&quot;: &quot;/www/helloworld/&quot;
    }
}"><pre>{
    <span>"helloworld"</span>: {
        <span>"type"</span>: <span><span>"</span>php<span>"</span></span>,
        <span>"root"</span>: <span><span>"</span>/www/helloworld/<span>"</span></span>
    }
}</pre></div>
<p dir="auto">Saving it as a file isn't necessary, but can come in handy with larger objects.</p>
<p dir="auto">Now, <code>PUT</code> it into the <code>/config/applications</code> section of Unit's control API,
usually available by default via a Unix domain socket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl -X PUT --data-binary @config.json --unix-socket  \
       /path/to/control.unit.sock http://localhost/config/applications"><pre># <span>curl -X PUT --data-binary @config.json --unix-socket  \</span>
<span>       /path/to/control.unit.sock http://localhost/config/applications</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="
{
	&quot;success&quot;: &quot;Reconfiguration done.&quot;
}"><pre>{
	<span>"success"</span>: <span><span>"</span>Reconfiguration done.<span>"</span></span>
}</pre></div>
<p dir="auto">Next, reference the app from a listener object in the <code>/config/listeners</code>
section of the API.  This time, we pass the config snippet straight from the
command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl -X PUT -d '{&quot;127.0.0.1:8000&quot;: {&quot;pass&quot;: &quot;applications/helloworld&quot;}}'  \
       --unix-socket /path/to/control.unit.sock http://localhost/config/listeners"><pre># <span>curl -X PUT -d <span><span>'</span>{"127.0.0.1:8000": {"pass": "applications/helloworld"}}<span>'</span></span>  \</span>
<span>       --unix-socket /path/to/control.unit.sock http://localhost/config/listeners</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;success&quot;: &quot;Reconfiguration done.&quot;
}"><pre>{
    <span>"success"</span>: <span><span>"</span>Reconfiguration done.<span>"</span></span>
}</pre></div>
<p dir="auto">Now Unit accepts requests at the specified IP and port, passing them to the
application process. Your app works!</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl 127.0.0.1:8080

      Hello, PHP on Unit!"><pre>$ <span>curl 127.0.0.1:8080</span>

<span>      Hello, PHP on Unit!</span></pre></div>
<p dir="auto">Finally, query the entire <code>/config</code> section of the control API:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl --unix-socket /path/to/control.unit.sock http://localhost/config/"><pre># <span>curl --unix-socket /path/to/control.unit.sock http://localhost/config/</span></pre></div>
<p dir="auto">Unit's output should contain both snippets, neatly organized:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;listeners&quot;: {
        &quot;127.0.0.1:8080&quot;: {
            &quot;pass&quot;: &quot;applications/helloworld&quot;
        }
    },

    &quot;applications&quot;: {
        &quot;helloworld&quot;: {
            &quot;type&quot;: &quot;php&quot;,
            &quot;root&quot;: &quot;/www/helloworld/&quot;
        }
    }
}"><pre>{
    <span>"listeners"</span>: {
        <span>"127.0.0.1:8080"</span>: {
            <span>"pass"</span>: <span><span>"</span>applications/helloworld<span>"</span></span>
        }
    },

    <span>"applications"</span>: {
        <span>"helloworld"</span>: {
            <span>"type"</span>: <span><span>"</span>php<span>"</span></span>,
            <span>"root"</span>: <span><span>"</span>/www/helloworld/<span>"</span></span>
        }
    }
}</pre></div>
<p dir="auto">For full details of configuration management, see the
<a href="https://unit.nginx.org/configuration/#configuration-management" rel="nofollow">docs</a>.</p>
<h2 tabindex="-1" dir="auto">OpenAPI Specification</h2>
<p dir="auto">Our <a href="https://github.com/nginx/unit/blob/master/docs/unit-openapi.yaml">OpenAPI specification</a> aims to simplify
configuring and integrating NGINX Unit deployments and provide an authoritative
source of knowledge about the control API.</p>
<p dir="auto">Although the specification is still in the early beta stage, it is a promising
step forward for the NGINX Unit community. While working on it, we kindly ask
you to experiment and provide feedback to help improve its functionality and
usability.</p>
<h2 tabindex="-1" dir="auto">Community</h2>
<ul dir="auto">
<li>
<p dir="auto">The go-to place to start asking questions and share your thoughts is
our <a href="https://community.nginx.org/joinslack" rel="nofollow">Slack channel</a>.</p>
</li>
<li>
<p dir="auto">Our <a href="https://github.com/nginx/unit/issues">GitHub issues page</a> offers
space for a more technical discussion at your own pace.</p>
</li>
<li>
<p dir="auto">The <a href="https://github.com/orgs/nginx/projects/1">project map</a> on
GitHub sheds some light on our current work and plans for the future.</p>
</li>
<li>
<p dir="auto">Our <a href="https://unit.nginx.org/" rel="nofollow">official website</a> may provide answers
not easily found otherwise.</p>
</li>
<li>
<p dir="auto">Get involved with the project by contributing! See the
<a href="https://github.com/nginx/unit/blob/master/CONTRIBUTING.md">contributing guide</a> for details.</p>
</li>
<li>
<p dir="auto">To reach the team directly, subscribe to the
<a href="https://mailman.nginx.org/mailman/listinfo/unit" rel="nofollow">mailing list</a>.</p>
</li>
<li>
<p dir="auto">For security issues, <a href="https://github.com/nginx/unit/blob/master/security-alert@nginx.org">email us</a>, mentioning
NGINX Unit in the subject and following the <a href="https://www.first.org/cvss/v3.1/specification-document" rel="nofollow">CVSS
v3.1</a> spec.</p>
</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Decline of Usability (2020) (214 pts)]]></title>
            <link>https://datagubbe.se/decusab/</link>
            <guid>37453616</guid>
            <pubDate>Sun, 10 Sep 2023 07:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datagubbe.se/decusab/">https://datagubbe.se/decusab/</a>, See on <a href="https://news.ycombinator.com/item?id=37453616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h2>The Decline of Usability</h2>

<p><b>In which we delve into the world of user interface design.</b></p>

<p><i>Spring 2020</i></p>

<h2>Our premise</h2>

<p>
There was a time (roughly between 1994 and 2012) when a reasonably computer-literate user could sit down in front of almost any operating system and quickly get to grips with the GUI, no matter what their home base was. Windows, MacOS, CDE, OpenStep, OS/2 and even outliers like Amiga, Atari and BeOS all had more in common than what set them apart. All windows had a title bar for dragging, easy identification and displaying current input focus. Clearly labeled drop-down menus following a set standard (File, Edit, View, Help etc.) made it easy for a newcomer to an application to browse program features and learn keyboard shortcuts. Buttons, input fields and other widget elements were clearly identifiable through various visual cues, such as 3D bevels.
</p>

<p>
A few rogue applications didn't play by the rules, but the vast majority of software did, at least in the fundamental places that really mattered.
</p>

<p>
Today, it seems we're on another track completely. Despite being endlessly fawned over by an army of professionals, Usability, or as it used to be called, "User Friendliness", is steadily declining. During the last ten years or so, adhering to basic standard concepts seems to have fallen out of fashion. On comparatively new platforms, I.E. smartphones, it's inevitable: the input mechanisms and interactions with the display are so different from desktop computers that new paradigms are warranted.
</p>

<p>
Worryingly, these paradigms have begun spreading to the desktop, where keyboards for fast typing and pixel-precision mice  effectively render them pointless. Coupled with the flat design trend, UI elements are increasingly growing both bigger and yet somehow harder to locate and tell apart from non-interactive decorations and content.
</p>

<p>
Overall, designers of desktop applications seem to have abandoned the fact that a desktop computer is capable of displaying several applications and windows at the same time and that many users are accustomed to this. Instead, we're increasingly treated to small-screen, single-app paradigms copied from smartphones. That's a turn for the worse in its own right, but perhaps more troubling and annoying is the recurring sidestepping from the tried and true UI design that is so ingrained in many users it's practically muscle memory by now.
</p>

<h2>Examples to prove a point</h2>
<br>
<h3>Window Management</h3>

<p>
Consider these title bars of a few popular Windows 10 applications:
</p>

<p><img src="https://datagubbe.se/decusab/windowtitles.png" alt="Screenshot of six heterogenous window titles stacked closely together"></p>

<p>
The image above is composed from screenshots taken on the same computer during the span of a few minutes. No settings have been changed between shots. Immediately, a plethora of UI problems become apparent.
</p>

<p>
Can you even tell how many windows there are? The answer is six - although the top three and bottom two could, when ending up stacked like this, look as if they're two single applications.
</p>

<p>
All of these title bars denote active windows. The top one, Outlook, looks exactly the same when inactive, as does Slack. Except for the command prompt (cmd.exe), the change between active and inactive on the remaining windows is so subtle that when aligned next to each other, it's virtually impossible to determine which one has the input focus.
</p>

<p>
Almost all of the title bars contain some kind of UI widget. Some have little tool icons, some have tabs, some have drop-down menus, some have combinations thereof. There is no set behavior and, more importantly, the clickable area for traditional operations (move, focus, raise) on each title bar is now of variable width. If you're accustomed to a title bar being for handling the window and nothing else, it's very easy to misclick and activate an application feature you didn't intend to. Oh, and the little Visual Studio Code logo on the second title bar from the top? Nope, not an icon. Purely decorative.
</p>

<p>
What's perhaps most jarring about this is that four of the six applications are made by Microsoft themselves, thus setting the standard for this kind of erratic design. We can already see the effects: the taking over of window title bars seems to get worse with time. Consider the latest version of Slack (click for a larger image):
</p>


<p><a href="https://datagubbe.se/decusab/slackhotspot.png"><img src="https://datagubbe.se/decusab/slackhotspot_s.png" alt="Screenshot of slack window title with UI hotspots marked in red and blue"></a></p>

<p>
Since Windows 2 (not 2000 - I'm really talking about Windows 2), users have been able to resize windows by dragging their top border and corners. Not so with Slack, anymore. The red lines in the image denote the remaining hotspots available for resizing. The blue lines denote the remaining hotspots available for moving the window. The rest is now taken up by a non-standard concoction of widgets that most users will either soon learn keyboard shortcuts for or that could very easily be incorporated into a more traditional UI.
</p>

<p>
Instead, some usability whizkid at some point decided to completely nullify the single most fundamental way of managing the window of an application mostly running on platforms where stacking, floating window management is not only the norm but pretty much the only available option.
</p>

<p><i>(Update 2020-04-22: It seems that Slack today pushed an update of their desktop version that dims the title bar slightly when the window is inactive.)</i></p>

<h3>Browsers</h3>

<p>
Microsoft and Slack aren't the only culprits. Google, for example, have gotten increasingly into some kind of A/B testing of late and their Chrome browser now features this type of tooltip when hovering on tabs:
</p>

<p><img src="https://datagubbe.se/decusab/hovertab.png" alt="Screenshot of Google Chrome tab tooltip"></p>

<p>
Usually, a browser tab will display a small, floating tooltip after having been hovered for a bit of time. This massive monstrosity pops up without delay and covers a large area of the underlying UI. The usefulness of browser tab tooltips can be discussed in itself, but this is no doubt both pointless and distracting.
</p>

<p>
Google aren't the only ones capable of producing distracting UI:s, though. The newly released Firefox version 75 features what has become known as "the megabar":
</p>

<p><img src="https://datagubbe.se/decusab/megabar.png" alt="Screenshot of Firefox URL megabar"></p>

<p>
This new take on the URL bar pops up when you least expect it, is very hard to get rid of and, as a bonus, covers the tried, tested and highly usable bookmarks toolbar below it. Just like widgets in title bars, this breaks the behavior of a UI concept in such a major way it's hard to begin describing: text input fields are ubiquitous, ancient and their basic concept has been the same since at least the early 1980:s.
</p>

<h3>Scroll bars</h3>

<p>
Another blow against recognizability and usability is harder to take a screenshot of, namely auto-hiding scroll bars. On a smartphone, it's a great invention because you can free up real estate on a small display and you've usually got your thumb resting close to the screen, ready to do a test scroll in your full screen app to see if more content is available.
</p>

<p>
On the desktop, however, a scroll bar is very useful for determining your current position in the content without having to break away from what you're presently doing and reach for the mouse. It's also useful for doing the same in windows that are currently not in focus. For example, in a tailing log file reader or command prompt with a debug stream, you might be interested in knowing if you're looking at the latest output or not. With auto-hiding scroll bars, this becomes much harder and you have to resort to other, often less apparent or more cumbersome methods.
</p>

<p>
In lieu of screenshots of hidden scroll bars, let's look at how QT5 renders them by default:
</p>

<p><img src="https://datagubbe.se/decusab/sbar.png" alt="Screenshot of QT5 scroll bar"></p>

<p>
Which part of this is the bar and which part is the tray? I know by now that the slightly brighter part is the bar, yet I frequently misclick, because the flat design makes them so hard to tell apart. Worse still is the infinitesimal contrast, so low that on older, cheaper laptop screens, it's downright impossible to tell the difference between bar and tray. New users probably don't know that with the right tools, QT5 can be configured to sport a more traditional look, so the default look should be geared towards them. Those intent on customizing the appearance of their personal desktop will usually find a way to do so anyway.
</p>

<h3>Missing Menu Bars</h3>

<p>
Another apparently unfashionable UI standard is the menu bar. It used to be a lowest common denominator between platforms and, when still present, it works basically the same on Windows, Mac and Unix-likes. For the most part, it even keeps the traditional "File, Edit, View" approach to things. The Gnome designers, however, have decided that such menus are apparently a bad feature and they should probably never have been used in the first place. To rectify more than three decades of such folly, they have created... something I'm not sure what to call.
</p>

<p>
One of the tricks up their sleeve is the hamburger menu. On smartphones, it's a great feature, but on the desktop, it's unnecessary: If there's anything we have on today's wide screen displays, it's horizontal space. In Gnome, it seems to be a catch-all for UI operations that didn't end up somewhere else. Like in Evince:
</p>

<p><img src="https://datagubbe.se/decusab/ev_menu3.png" alt="Screenshot of Evince hamburger menu"></p>

<p>
Open, Save, Print, Close. All of them reasonable tasks, except there's no adherence to standards. In Gnome-MPV, the hamburger menu looks like this:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu3.png" alt="Screenshot of Gnome-MPV hamburger menu"></p>


<p>
No Open or Close here, you silly user! What did you expect? Some kind of coherent thought? If you want to open a file, just click the little icon to the left featuring a plus sign:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu2.png" alt="Screenshot of Gnome-MPV plus sign menu"></p>

<p>
There's also a button with the Gnome-MPV icon on it. One might assume this button would contain features specific to Gnome-MPV, such as the ones found in the hamburger menu, but no. Instead it looks like this, containing options for preferences and quitting:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu1.png" alt="Screenshot of Gnome-MPV logo menu"></p>

<p>
In Evince, the button featuring an Evince icon produces this menu:
</p>

<p><img src="https://datagubbe.se/decusab/ev_menu1.png" alt="Screenshot of Evince logo menu"></p>

<p>
Bummer! In Evince, you clearly have to look somewhere else to find in-app preferences and a quit option: things are wildly inconsistent between applications, creating confusion and frustration for users. I also can't find a way to navigate these menus using the keyboard once they're open, as opposed to normal drop-down menus and other similar hamburger menus.
</p>

<h3>More Gnome</h3>

<p>
There are so many more examples in just these two Gnome applications alone that it's bordering on parodical. For example, they are designed for Gnome's new paradigm of incorporating toolbars into the window title bar, thus institutionalizing the crimes of the Windows applications mentioned above. The difference is of course that if you're running another window manager, it just looks silly, for example leaving you with two close gadgets. It also means that to keep a reasonably large area free for moving the window (At least that's better than Slack!), widgets that could previously have been fitted into a toolbar below the title bar now needs to be opened separately, such as this search box in Evince (click for a larger image):
</p>

<p><a href="https://datagubbe.se/decusab/ev_search.png"><img src="https://datagubbe.se/decusab/ev_search_s.png" alt="Screenshot of Evince search bar"></a></p><p>

Or this little extra toolbar for making annotations, containing a whopping total of two icons. That's one whole icon more than is used to open the toolbar itself, clearly warranting this particular design approach:

</p><p><img src="https://datagubbe.se/decusab/ev_extratoolbar.png" alt="Screenshot of Evince annotate toolbar"></p>

<h2>Wrapping up</h2>

<p>
These are just a few examples of crimes against basic concepts of desktop UI design. There are plenty more and they're present on all platforms. They are also, it seems, growing increasingly common: the times of coherency and industry standards seem to be over. I hope that with this little rant, I can plant a seed to bring them back. If not, it was at least good to blow off some steam.
</p>

<p>
I'm going to end by discussing some counter arguments I've come across when discussing modern UI design on various online forums:
</p>

<p>
<b>Technology is progressing! You can't stop change! Just deal with it!</b><br>
These and similar truisms and platitudes are commonly used when no real argument is available. It's people like you and me who decide to change UI design, not an unstoppable force of nature. Changing things doesn't necessarily imply improving them and it's improvement we should strive for, otherwise change is pointless.
</p>

<p>
<b>You're living in the past!</b><br>
Considering the apparent anachronisms in the above screenshots, I can't argue with the fact that I am.  However, that doesn't automatically mean I'm wrong. It also doesn't mean I think all modern desktop environments should look like Windows 95 or CDE. There are other roads forward and other ways to improve the look and feel of UI:s without breaking fundamental concepts.
</p>

<p>
<b>Electron apps can't follow a single platform's standard!</b><br>
Multi-platform applications will of course never fully incorporate into the host environment the way native ones do. But because of this, it's of extra importance that they at least adhere to the paradigms that are translatable between all the common target platforms of today. Drop-down menus, clean title bars and a clear indication of window focus aren't hard to implement, even if they don't look exactly like their surroundings. In fact, a multi-platform framework should make it easy for developers to implement these concepts and hard, if not impossible, to work around them.
</p>

<p>
<b>We shouldn't complain about free software! It's free!</b><br>
Yes. Yes we should. Don't get me wrong - I have a massive amount of respect and admiration for the time, skill and effort people put into FOSS projects. They are improving my personal quality of life significantly and for that I'm very grateful.
</p>

<p>
It's true that Gnome and KDE are FOSS, which is a thing of wonder. But they are also large enough to, just like Microsoft and Google, have a significant impact not only on normal end users but on aspiring designers and programmers as well. We should be able to share our views and discuss what that impact might result in.
</p>

<p>
In short: Anyone setting an example should also be held to a standard.
</p>

<p>
<b>Putting things in the title bar saves screen real estate!</b><br>
This is true to some extent, but screen real estate in general isn't much of a problem anymore. If this had been done in the days of 640x480 VGA, it could maybe have been a viable argument. Today, anyone working enough with computers to worry about a few pixels extra can buy a screen the size of a small TV with a 2560x1440 pixel resolution for around US$200. Even the cheapest of laptops come with at least a 1366x768 resolution, which is en par with the famed megapixel displays of yesteryear's professional workstations, coveted precisely for their generous amount of screen real estate.
</p>

<p>
If anything, the problem with screen real estate comes from the current trend of UI design with so much white space between elements that what used to be a simple requester is now a full-screen application, as evident in this example (click for larger image):
</p>

<p><a href="https://datagubbe.se/decusab/winpara2.png"><img src="https://datagubbe.se/decusab/winpara2_s.png" alt="Screenshot of Windows power settings"></a></p>

<p>
For those spending all their workdays coding on a 13" laptop, my tip is to stop worrying about screen real estate and start worrying about your back, neck, hands and shoulders a bit more. Trust me, RSI is a serious thing.
</p>

<p>
<b>Designing UI:s is hard and application software can't please everyone all the time!</b><br>
This is true and, as a software developer of more than 20 years, I have a huge amount of respect for the complexity of UI design. I also happen to know that such complexity is not a valid excuse for willingly and knowingly breaking UI concepts that have been proven and working for, in some cases, more than four decades. In fact, a lot of the examples above introduce more complexity for the user to cope with. The intricacies of each application and window decoration must be learned separately and time and energy is spent by repeatedly parsing the differences.
</p>

<p>
<b>What about Apple?</b><br>
I can't comment on the current state of MacOS since the time I've spent actually using a Mac during the last 8 years or so probably totals to a few hours. Apple used to be good at this, and I hear they still do a decent job at keeping things sane, even post-Jobs.
</p>

<p>
<b>You're old and angry!</b><br>
You bet! Now get off my lawn, punk.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZF makes magnet-free electric motor uniquely compact and competitive (204 pts)]]></title>
            <link>https://press.zf.com/press/en/releases/release_60480.html</link>
            <guid>37453465</guid>
            <pubDate>Sun, 10 Sep 2023 06:41:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://press.zf.com/press/en/releases/release_60480.html">https://press.zf.com/press/en/releases/release_60480.html</a>, See on <a href="https://news.ycombinator.com/item?id=37453465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>This advanced variant of a separately excited synchronous motor is thus an alternative to permanent-magnet synchronous machines (PSM). The latter are currently the motors most frequently used in electric vehicles, but they are based on magnets which require rare earth materials for their production. With the I<sup>2</sup>SM, ZF is setting a new standard for making e-motors both extremely sustainable in production and highly powerful and efficient in operation.</p><p>“With this magnet-free e-motor without rare earth materials, we have another innovation with which we are consistently improving our electric drive portfolio to create even more sustainable, efficient and resource-saving mobility,” said Dr. Holger Klein, CEO of ZF. “This is our guiding principle for all new products. And we currently see no competitor that masters this technology as well as ZF.” Compared to common SESM systems, the inductive exciter can reduce losses for the energy transmission into the rotor by 15 percent. In addition, the CO<sub>2</sub> footprint in production, which arises with PSM e-motors in particular due to magnets including rare earth materials, can be reduced by up to 50 percent.</p><p>“This uniquely compact electric motor without magnets is impressive evidence of our strategy to make e-drives more resource-efficient and sustainable, primarily through efficiency improvements,” said Stephan von Schuckmann, Member of the Board of Management of the ZF Group.</p><p>In addition to the benefits of eliminating rare earth materials in a compact and powerful package, the I<sup>2</sup>SM eliminates the drag losses created in traditional PSM e-motors. This enables better efficiency at certain operating points such as long highway trips at high speed. </p><p><b>Advanced rotor design makes e-motor very compact</b></p><p>To ensure that the magnetic field in the rotor is built up by current instead of magnets, the conventional SESM concepts currently still require sliding or brush elements in most cases, which force compromises: A dry installation space, i.e. not accessible for oil cooling and with additional seals, is necessary. As a result, conventional SESMs take up around 90 mm more space axially. As a result, manufacturers generally cannot flexibly vary between PSM and SESM variants in their model planning without additional effort.</p><p>In order to offer the advantages of separately excited synchronous machines competitively, ZF has succeeded in compensating for the design-related disadvantages of common separately excited synchronous machines. In particular, the torque density has been significantly increased compared to the state of the art thanks to an innovative rotor design. The space-neutral integration of the exciter into the rotor means that there are no axial space disadvantages. In addition, an increase in power density in the rotor leads to an improvement in performance.</p><p><b>Inductive excitation as a key technology</b></p><p>The technological prerequisite for the ZF innovation is that energy is transferred inductively, i.e. without mechanical contact, into the rotor, generating a magnetic field by means of coils. Thus, the I<sup>2</sup>SM does not require any brush elements or slip rings. Furthermore, there is no longer any need to keep this area dry by means of seals. As with permanently magnetized synchronous motor, the rotor is efficiently cooled by circulating oil. Compared to common separately excited synchronous motor, the ZF innovation requires up to 90 millimeters less axial installation space. In terms of power and torque density, however, the ZF innovation operates at the level of a PSM.</p><p>ZF plans to develop the I<sup>2</sup>SM technology to production maturity and offer it as an option within its own e-drive platform. Customers from the passenger car and commercial vehicle segments can then choose between a variant with 400-volt architecture or with 800-volt architecture for their respective applications. The latter relies on silicon carbide chips in the power electronics.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Wrote a String Type (169 pts)]]></title>
            <link>https://mcyoung.xyz/2023/08/09/yarns/</link>
            <guid>37451913</guid>
            <pubDate>Sun, 10 Sep 2023 01:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mcyoung.xyz/2023/08/09/yarns/">https://mcyoung.xyz/2023/08/09/yarns/</a>, See on <a href="https://news.ycombinator.com/item?id=37451913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><span> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> </span> <span> 2023-08-09 </span> </span></p> <p>I write compilers for fun. I can’t help it. Consequently, I also write a lot of parsers. In systems programming, it’s usually a good idea to try to share memory rather than reuse it, so as such my AST types tend to look like this.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>enum</span> <span>Expr</span><span>&lt;</span><span>'src</span><span>&gt;</span> <span>{</span>
  <span>Int</span><span>(</span><span>u32</span><span>)</span>
  <span>Ident</span><span>(</span><span>&amp;</span><span>'src</span> <span>str</span><span>),</span>
  <span>// ...</span>
<span>}</span></code></pre></figure></div> <p>Whenever we parse an identifier, rather than copy its name into a fresh <code>String</code>, we borrow from the input source string. This avoids an extra allocation, an extra copy, and saves a word in the representation. Compilers can be memory-hungry, so it helps to pick a lean representation.</p> <p>Unfortunately, it’s not so easy for quoted strings. Most strings, like <code>"all my jelly babies"</code>, are “literally” in the original source, like an identifier. But strings with escapes aren’t: <code>\n</code> is encoded in the source code with the bytes <code>[0x5c, 0x6e]</code>, but the actual “decoded” value of a string literal replaces each escape with a single <code>0x0a</code>.</p> <p>The usual solution is a <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow&lt;str&gt;</code></a>. In the more common, escape-less verison, we can use <code>Cow::Borrowed</code>, which avoids the extra allocation and copy, and in the escaped version, we decode the escapes into a <code>String</code> and wrap it in a <code>Cow::Owned</code>.</p> <p>For example, suppose that we’re writing a parser for a language that has quoted strings with escapes. The string <code>"all my jelly babies"</code> can be represented as a byte string that borrows the input source code, so we’d use the <code>Cow::Borrowed</code> variant. This is most strings in any language: escapes tend to be rare.</p> <p>For example, if we have the string <code>"not UTF-8 \xff"</code>, the actual byte string value is different from that in the source code.</p> <div><figure><pre><code data-lang="text">// Bytes in the source.
hex:   6e 6f 74 20 55 54 46 2d 38 20 5c 78 66 66
ascii: n  o  t     U  T  F  -  8     \  x  f  f

// Bytes represented by the string.
hex:   6e 6f 74 20 55 54 46 2d 38 20 ff
ascii: n  o  t     U  T  F  -  8</code></pre></figure></div> <p>Escapes are relatively rare, so most strings processed by the parser do not need to pay for an allocation.</p> <p>However, we still pay for that extra word, since <code>Cow&lt;str&gt;</code> is 24 bytes (unless otherwise specified, all byte counts assume a 64-bit system), which is eight more than our <code>&amp;str</code>. Even worse, this is bigger than the string data itself, which is 11 bytes.</p> <p>If most of your strings are small (which is not uncommon in an AST parser), you will wind up paying for significant overhead.</p> <p>Over the years I’ve implemented various optimized string types to deal with this use-case, in various contexts. I finally got around to putting all of the tricks I know into a library, which I call <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code>byteyarn</code></a>. It advertises the following nice properties.</p> <blockquote> <p>A <code>Yarn</code> is a highly optimized string type that provides a number of useful properties over <code>String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code>Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code>'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>I’d like to share how these properties are achieved through careful layout optimization.</p> <h2 id="assumptions"><a href="#assumptions">Assumptions</a></h2> <p>We’re going to start by stating assumptions about how our strings will be used:</p> <ol> <li>Most strings are not mutated most of the time.</li> <li>Most strings are small.</li> <li>Most strings are substrings.</li> </ol> <h3 id="most-strings-are-immutable"><a href="#most-strings-are-immutable">Most Strings are Immutable</a></h3> <p><code>String</code> is modeled after C++’s <code>std::string</code>, which is a growable buffer that implements amortized linear-time append. This means that if we are appending <code>n</code> bytes to the buffer, we only pay for <code>n</code> bytes of <code>memcpy</code>.</p> <p>This is a useful but often unnecessary property. For example, Go strings are immutable, and when building up a large string, you are expected to use <code>strings.Builder</code>, which is implemented as essentially a Rust <code>String</code>. Java also as a similar story for strings, which allows for highly compact representations of <code>java.lang.String</code>s.</p> <p>In Rust, this kind of immutable string is represented by a <code>Box&lt;str&gt;</code>, which is eight bytes smaller than <code>String</code>. Converting from <code>String</code> to <code>Box&lt;str&gt;</code> is just a call to <code>realloc()</code> to resize the underlying allocation (which is often cheap<sup id="fnref:size-classes" role="doc-noteref"><a href="#fn:size-classes" rel="footnote">1</a></sup>) from being <code>capacity</code> bytes long to <code>len</code> bytes long.</p> <p>Thus, this assumption means we only need to store a pointer and a length, which puts our memory footprint floor at 16 bytes.</p> <h3 id="most-strings-are-substrings"><a href="#most-strings-are-substrings">Most Strings are Substrings</a></h3> <p>Suppose again that we’re parsing some textual format. Many structural elements will be verbatim references into the textual input. Not only string literals without escapes, but also identifiers.</p> <p><code>Box&lt;str&gt;</code> cannot hold borrowed data, because it will always instruct the allocator to free its pointer when it goes out of scope. <code>Cow&lt;str&gt;</code>, as we saw above, allows us to handle maybe-owned data uniformly, but has a minimum 24 byte overhead. This can’t be made any smaller, because a <code>Cow&lt;str&gt;</code> can contain a 24-byte <code>String</code> value.</p> <p>But, we don’t want to store a capacity. Can we avoid the extra word of overhead in <code>Cow&lt;str&gt;</code>?</p> <h3 id="most-strings-are-small"><a href="#most-strings-are-small">Most Strings are Small</a></h3> <p>Consider a string that is not a substring but which is small. For example, when parsing a string literal like <code>"Hello, world!\n"</code>, the trailing <code>\n</code> (bytes <code>0x5c 0x6e</code>) must be replaced with a newline byte (<code>0x0a</code>). This means we must handle a tiny heap allocation, 14 bytes long, that is smaller than a <code>&amp;str</code> referring to it.</p> <p>This is worse for single character<sup id="fnref:character" role="doc-noteref"><a href="#fn:character" rel="footnote">2</a></sup> strings. The overhead for a <code>Box&lt;str&gt;</code> is large.</p> <ul> <li>The <code>Box&lt;str&gt;</code> struct itself has a pointer field (eight bytes), and a length field (also eight bytes). Spelled out to show all the stored bits, the length is <code>0x0000_0000_0000_0001</code>. That’s a lot of zeroes!</li> <li>The pointer itself points to a heap allocation, which will not be a single byte! Allocators are not in the business of handing out such small pieces of memory. Instead, the allocation is likely costing us another eight bytes!</li> </ul> <p>So, the string <code>"a"</code>, whose data is just a <em>single byte</em>, instead takes up 24 bytes of memory.</p> <p>It turns out that for really small strings we can avoid the allocation altogether, <em>and</em> make effective use of all those zeroes in the <code>len</code> field.</p> <h2 id="stealing-bits"><a href="#stealing-bits">Stealing Bits</a></h2> <p>Let’s say we want to stick to a budget of 16 bytes for our <code>Yarn</code> type. Is there any extra space left for data in a <code>(*mut u8, usize)</code> pair?</p> <p><em>*cracks Fermi estimation knuckles*</em></p> <p>A <code>usize</code> is 64 bits, which means that the length of an <code>&amp;str</code> can be anywhere from zero to 18446744073709551615, or around 18 exabytes. For reference, “hundreds of exabytes” is a reasonable ballpark guess for how much RAM exists in 2023 (consider: 4 billion smartphones with 4GB each). More practically, the largest quantity of RAM you can fit in a server blade is measured in terabytes (much more than your measly eight DIMs on your gaming rig).</p> <p>If we instead use one less bit, 63 bits, this halves the maximum representable memory to nine exabytes. If we take another, it’s now four exabytes. Much more memory than you will ever <em>ever</em> want to stick in a string. <a href="https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database">Wikpedia asserts</a> that Wikimedia Commons contains around 428 terabytes of media (the articles’ text with history is a measly 10 TB).</p> <p>Ah, but you say you’re programming for a 32-bit machine (today, this likely means either a low-end mobile phone, an embedded micro controller, or WASM).</p> <p>On a 32-bit machine it’s a little bit harrier: Now <code>usize</code> is 32 bits, for a maximum string size of 4 gigabytes (if you remember the 32-bit era, this limit may sound familiar). “Gigabytes” is an amount of memory that you can actually imagine having in a string.</p> <p>Even then, 1 GB of memory (if we steal two bits) on a 32-bit machine is a lot of data. You can only have four strings that big in a single address space, and every 32-bit allocator in the universe will refuse to serve an allocation of that size. If your strings are comparable in size to the whole address space, you should build your own string type.</p> <p>The upshot is that every <code>&amp;str</code> contains two bits we can reasonably assume are not used. <em>Free real-estate.</em><sup id="fnref:isize" role="doc-noteref"><a href="#fn:isize" rel="footnote">3</a></sup></p> <h3 id="a-hand-written-niche-optimization"><a href="#a-hand-written-niche-optimization">A Hand-Written Niche Optimization</a></h3> <p>Rust has the concept of <em>niches</em>, or invalid bit-patterns of a particular type, which it uses for automatic layout optimization of <code>enum</code>s. For example, references cannot be null, so the pointer bit-pattern of <code>0x0000_0000_0000_0000</code> is never used; this bit-pattern is called a “niche”. Consider:</p> <div><figure><pre><code data-lang="rust"><span>enum</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>First</span><span>(</span><span>&amp;</span><span>'a</span> <span>T</span><span>),</span>
  <span>Second</span>
<span>}</span></code></pre></figure></div> <p>An <code>enum</code> of this form will not need any “extra” space to store the value that discriminates between the two variants: if a <code>Foo</code>’s bits are all zero, it’s <code>Foo::Second</code>; otherwise it’s a <code>Foo::First</code> and the payload is formed from <code>Foo</code>’s bit-pattern. This, incidentally, is what makes <code>Option&lt;&amp;T&gt;</code> a valid representation for a “nullable pinter”.</p> <p>There are more general forms of this: <code>bool</code> is represented as a single byte, of which two bit are valid; the other 254 potential bit-patterns are niches. In Recent versions of Rust, <code>RawFd</code> has a niche for the all-ones bit-pattern, since POSIX file descriptors are always non-negative <code>int</code>s.</p> <p>By stealing two bits off of the length, we have given ourselves four niches, which essentially means we’ll have a hand-written version of something like this <code>enum</code>.</p> <div><figure><pre><code data-lang="rust"><span>enum</span> <span>Yarn</span> <span>{</span>
  <span>First</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Second</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Third</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Fourth</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
<span>}</span></code></pre></figure></div> <p>For reasons that will become clear later, we will specifically steal the <em>high</em> bits of the length, so that to recover the length, we do two shifts<sup id="fnref:two-shifts" role="doc-noteref"><a href="#fn:two-shifts" rel="footnote">4</a></sup> to shift in two high zero bits. Here’s some code that actually implements this for the low level type our string type will be built on.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>,</span>
  <span>len</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a length, and a pointer.</span>
  <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>,</span>
      <span>len</span><span>:</span> <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the kind back out.</span>
  <span>fn</span> <span>kind</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>(</span><span>self</span><span>.len</span> <span>&gt;&gt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>))</span> <span>as</span> <span>u8</span>
  <span>}</span>

  <span>/// Extracts the slice out (regardless of kind).</span>
  <span>unsafe</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span> <span>{</span>
    <span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>self</span><span>.ptr</span><span>,</span> <span>(</span><span>self</span><span>.len</span> <span>&lt;&lt;</span> <span>2</span><span>)</span> <span>&gt;&gt;</span> <span>2</span><span>)</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>Note that I’ve made this type <code>Copy</code>, and some functions take it by value. This is for two reasons.</p> <ol> <li> <p>There is a type of <code>Yarn</code> that is itself <code>Copy</code>, although I’m not covering it in this article.</p> </li> <li> <p>It is a two-word struct, which means that on most architectures it is eligible to be passed in a pair of registers. Passing it by value in the low-level code helps promote keeping it in registers. This isn’t always possible, as we will see when we discuss “SSO”.</p> </li> </ol> <p>Let’s chose kind <code>0</code> to mean “this is borrowed data”, and kind <code>1</code> to be “this is heap-allocated data”. We can use this to remember whether we need to call a destructor.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>struct</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>raw</span><span>:</span> <span>RawYarn</span><span>,</span>
  <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>&lt;&amp;</span><span>'a</span> <span>str</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>const</span> <span>BORROWED</span><span>:</span> <span>u8</span> <span>=</span> <span>0</span><span>;</span>
<span>const</span> <span>HEAP</span><span>:</span> <span>u8</span> <span>=</span> <span>1</span><span>;</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>borrowed</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'a</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>BORROWED</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Create a new yarn from owned data.</span>
  <span>pub</span> <span>fn</span> <span>owned</span><span>(</span><span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>HEAP</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the data.</span>
  <span>pub</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>str</span> <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>// SAFETY: initialized either from uniquely-owned data,</span>
      <span>// or borrowed data of lifetime 'a that outlives self.</span>
      <span>str</span><span>::</span><span>from_utf8</span><span>(</span><span>self</span><span>.as_slice</span><span>())</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>impl</span> <span>Drop</span> <span>for</span> <span>Yarn</span><span>&lt;</span><span>'_</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>drop</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>{</span>
    <span>if</span> <span>self</span><span>.raw</span><span>.kind</span><span>()</span> <span>==</span> <span>HEAP</span> <span>{</span>
      <span>let</span> <span>dropped</span> <span>=</span> <span>unsafe</span> <span>{</span>
        <span>// SAFETY: This is just reconstituting the box we dismantled</span>
        <span>// in Yarn::owned().</span>
        <span>Box</span><span>::</span><span>from_raw</span><span>(</span><span>self</span><span>.as_slice</span><span>())</span>
      <span>};</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This gives us a type that strongly resembles <code>Cow&lt;str&gt;</code> with only half of the bytes. We can even write code to extend the lifetime of a <code>Yarn</code>:</p> <div><figure><pre><code data-lang="rust"><span>impl</span> <span>Yarn</span><span>&lt;</span><span>'_</span><span>&gt;</span> <span>{</span>
  <span>/// Removes the bound lifetime from the yarn, allocating if</span>
  <span>/// necessary.</span>
  <span>pub</span> <span>fn</span> <span>immortalize</span><span>(</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Yarn</span><span>&lt;</span><span>'static</span><span>&gt;</span> <span>{</span>
    <span>if</span> <span>self</span><span>.raw</span><span>.kind</span><span>()</span> <span>==</span> <span>BORROWED</span> <span>{</span>
      <span>let</span> <span>copy</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span> <span>=</span> <span>self</span><span>.as_slice</span><span>()</span><span>.into</span><span>();</span>
      <span>self</span> <span>=</span> <span>Yarn</span><span>::</span><span>owned</span><span>(</span><span>copy</span><span>);</span>
    <span>}</span>

    <span>// We need to be careful that we discard the old yarn, since its</span>
    <span>// destructor may run and delete the heap allocation we created</span>
    <span>// above.</span>
    <span>let</span> <span>raw</span> <span>=</span> <span>self</span><span>.raw</span><span>;</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>self</span><span>);</span>
    <span>Yarn</span><span>::</span><span>&lt;</span><span>'static</span><span>&gt;</span> <span>{</span>
      <span>raw</span><span>,</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The remaining two niches can be put to use for optimizing small strings.</p> <h2 id="small-string-optimization"><a href="#small-string-optimization">Small String Optimization</a></h2> <p>C++’s <code>std::string</code> also makes the “most strings are small” assumption. In the <code>libc++</code> implementation of the standard library, <code>std::string</code>s of up to 23 bytes never hit the heap!</p> <p>C++ implementations do this by using most of the pointer, length, and capacity fields as a storage buffer for small strings, the so-called “small string optimization” (SSO). In <code>libc++</code>, in SSO mode, a <code>std::string</code>’s length fits in one byte, so the other 23 bytes can be used as storage. The capacity isn’t stored at all: an SSO string always has a capacity of 23.</p> <p><code>RawYarn</code> still has another two niches, so let’s dedicate one to a “small” representation. In small mode, the kind will be 2, and only the 16th byte will be the length.</p> <p>This is why we used the two <em>high</em> bits of <code>len</code> for our scratch space: no matter what mode it’s in, we can easily extract these bits<sup id="fnref:big-endian" role="doc-noteref"><a href="#fn:big-endian" rel="footnote">5</a></sup>. Some of the existing <code>RawYarn</code> methods need to be updated, though.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>&lt;*</span><span>mut</span> <span>u8</span><span>&gt;</span><span>,</span>
  <span>len</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>const</span> <span>SMALL</span><span>:</span> <span>u8</span> <span>=</span> <span>2</span><span>;</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a length, and a pointer.</span>
  <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>kind</span> <span>!=</span> <span>SMALL</span><span>);</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>new</span><span>(</span><span>ptr</span><span>),</span>
      <span>len</span><span>:</span> <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the slice out (regardless of kind).</span>
  <span>unsafe</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span> <span>{</span>
    <span>let</span> <span>(</span><span>ptr</span><span>,</span> <span>adjust</span><span>)</span> <span>=</span> <span>match</span> <span>self</span><span>.kind</span><span>()</span> <span>{</span>
      <span>SMALL</span> <span>=&gt;</span> <span>(</span><span>self</span> <span>as</span> <span>*</span><span>const</span> <span>Self</span> <span>as</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>8</span><span>),</span>
      <span>_</span> <span>=&gt;</span> <span>(</span><span>self</span><span>.ptr</span><span>.assume_init</span><span>(),</span> <span>0</span><span>),</span>
    <span>};</span>

    <span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ptr</span><span>,</span> <span>(</span><span>self</span><span>.len</span> <span>&lt;&lt;</span> <span>2</span><span>)</span> <span>&gt;&gt;</span> <span>(</span><span>2</span> <span>+</span> <span>adjust</span><span>))</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>In the non-<code>SMALL</code> case, we shift twice as before, but in the <code>SMALL</code> case, we need to get the high byte of the <code>len</code> field, so we need to shift down by an additional <code>usize::BITS - 8</code>. No matter what we’ve scribbled on the low bytes of <code>len</code>, we will always get just the length this way.</p> <p>We also need to use a different pointer value depending on whether we’re in <code>SMALL</code> mode. This is why <code>as_slice</code> needs to take a reference argument, since the slice data may be <em>directly</em> in <code>self</code>!</p> <p>Also, <code>ptr</code> is a <code>MaybeUninit</code> now, which will become clear in the next code listing.</p> <p>We should also provide a way to construct small strings.</p> <div><figure><pre><code data-lang="rust"><span>const</span> <span>SSO_LEN</span><span>:</span> <span>usize</span> <span>=</span> <span>size_of</span><span>::</span><span>&lt;</span><span>usize</span><span>&gt;</span><span>()</span> <span>*</span> <span>2</span> <span>-</span> <span>1</span><span>;</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Create a new small yarn. `data` must be valid for `len` bytes</span>
  <span>/// and `len` must be smaller than `SSO_LEN`.</span>
  <span>unsafe</span> <span>fn</span> <span>from_small</span><span>(</span><span>data</span><span>:</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>RawYarn</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>SSO_LEN</span><span>);</span>

    <span>// Create a yarn with an uninitialized pointer value (!!)</span>
    <span>// and a length whose high byte is packed with `small` and</span>
    <span>// `len`.</span>
    <span>let</span> <span>mut</span> <span>yarn</span> <span>=</span> <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>uninit</span><span>(),</span>
      <span>len</span><span>:</span> <span>(</span><span>SMALL</span> <span>as</span> <span>usize</span> <span>&lt;&lt;</span> <span>6</span> <span>|</span> <span>len</span><span>)</span>
          <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>8</span><span>),</span>
    <span>};</span>

    <span>// Memcpy the data to the new yarn.</span>
    <span>// We write directly onto the `yarn` variable. We won't</span>
    <span>// overwrite the high-byte length because `len` will</span>
    <span>// never be &gt;= 16.</span>
    <span>ptr</span><span>::</span><span>copy_nonoverlapping</span><span>(</span>
      <span>data</span><span>,</span>
      <span>&amp;</span><span>mut</span> <span>yarn</span> <span>as</span> <span>*</span><span>mut</span> <span>RawYarn</span> <span>as</span> <span>*</span><span>mut</span> <span>u8</span><span>,</span>
      <span>data</span><span>,</span>
    <span>);</span>

    <span>yarn</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The precise maximum size of an SSO string is a bit more subtle than what’s given above, but it captures the spirit. The <code>RawYarn::from_small</code> illustrates why the pointer value is hidden in a <code>MaybeUninit</code>: we’re above to overwrite it with garbage, and in that case it won’t be a pointer at all.</p> <p>We can update our public <code>Yarn</code> type to use the new small representation whenever possible.</p> <div><figure><pre><code data-lang="rust"><span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>borrowed</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'a</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>

    <span>if</span> <span>len</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>BORROWED</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Create a new yarn from owned data.</span>
  <span>pub</span> <span>fn</span> <span>owned</span><span>(</span><span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>if</span> <span>data</span><span>.len</span><span>()</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>data</span><span>.len</span><span>(),</span> <span>data</span><span>.as_ptr</span><span>())</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>HEAP</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>It’s also possible to construct a <code>Yarn</code> directly from a character now, too!</p> <div><figure><pre><code data-lang="rust"><span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>from_char</span><span>(</span><span>data</span><span>:</span> <span>char</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>buf</span> <span>=</span> <span>[</span><span>0u8</span><span>;</span> <span>4</span><span>];</span>
    <span>let</span> <span>data</span> <span>=</span> <span>data</span><span>.encode_utf8</span><span>(</span><span>&amp;</span><span>mut</span> <span>buf</span><span>);</span>
    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>(Note that we do not need to update <code>Yarn::immortalize()</code>; why?)</p> <p>What we have now is a maybe-owned string that does not require an allocation for small strings. However, we still have an extra niche…</p> <h2 id="string-constants"><a href="#string-constants">String Constants</a></h2> <p>String constants in Rust are interesting, because we can actually detect them at compile-time<sup id="fnref:leaks" role="doc-noteref"><a href="#fn:leaks" rel="footnote">6</a></sup>.</p> <p>We can use the last remaining niche, 3, to represent data that came from a string constant, which means that it does not need to be boxed to be immortalized.</p> <div><figure><pre><code data-lang="rust"><span>const</span> <span>STATIC</span><span>:</span> <span>u8</span> <span>=</span> <span>3</span><span>;</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>from_static</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'static</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>

    <span>if</span> <span>len</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>STATIC</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This function is identical to <code>Yarn::borrowed</code>, except that <code>data</code> most now have a static lifetime, and we pass <code>STATIC</code> to <code>RawYarn::from_raw_parts()</code>.</p> <p>Because of how we’ve written all of the prior code, this does not require any special support in <code>Yarn::immortalize()</code> or in the low-level <code>RawYarn</code> code.</p> <p>The actual <code>byteyarn</code> library provides a <code>yarn!()</code> macro that has the same syntax as <code>format!()</code>. This is the primary way in which yarns are created. It is has been carefully written so that <code>yarn!("this is a literal")</code> always produces a <code>STATIC</code> string, rather than a heap-allocated string.</p>  <p>Unfortunately, because of how we’ve written it, <code>Option&lt;Yarn&gt;</code> is 24 bytes, a whole word larger than a <code>Yarn</code>. However, there’s still a little gap where we can fit the <code>None</code> variant. It turns out that because of how we’ve chosen the discriminants, <code>len</code> is zero if and only if it is an empty <code>BORROWED</code> string. But this is not the only zero: if the high byte is <code>0x80</code>, this is an empty <code>SMALL</code> string. If we simply require that no other empty string is ever constructed (by marking <code>RawYarn::from_raw_parts()</code> as unsafe and specifying it should not be passed a length of zero), we can guarantee that <code>len</code> is <em>never</em> zero.</p> <p>Thus, we can update <code>len</code> to be a <code>NonZeroUsize</code>.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>&lt;*</span><span>mut</span> <span>u8</span><span>&gt;</span><span>,</span>
  <span>len</span><span>:</span> <span>NonZeroUsize</span><span>,</span>  <span>// (!!)</span>
<span>}</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a *nonzero* length, and a pointer.</span>
  <span>unsafe</span> <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>kind</span> <span>!=</span> <span>SMALL</span><span>);</span>
    <span>debug_assert!</span><span>(</span><span>len</span> <span>!=</span> <span>0</span><span>);</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>new</span><span>(</span><span>ptr</span><span>),</span>
      <span>len</span><span>:</span> <span>NonZeroUsize</span><span>::</span><span>new_unchecked</span><span>(</span>
        <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>),</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This is a type especially known to the Rust compiler to have a niche bit-pattern of all zeros, which allows <code>Option&lt;Yarn&gt;</code> to be 16 bytes too. This also has the convenient property that the all zeros bit-pattern for <code>Option&lt;Yarn&gt;</code> is <code>None</code>.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>The <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code>byteyarn</code></a> blurb describes what we’ve built:</p> <blockquote> <p>A <code>Yarn</code> is a highly optimized string type that provides a number of useful properties over <code>String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code>Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code>'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>There are, of course, some trade-offs. Not only do we need the assumptions we made originally to hold, but we also need to relatively care more about memory than cycle-count performance, since basic operations like reading the length of the string require more math (but no extra branching).</p> <p>The actual implementation of <code>Yarn</code> is a bit more complicated, partly to keep all of the low-level book-keeping in one place, and partly to offer an ergonomic API that makes <code>Yarn</code> into a mostly-drop-in replacement for <code>Box&lt;str&gt;</code>.</p> <p>I hope this peek under the hood has given you a new appreciation for what can be achieved by clever layout-hacking. ◼</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coffee in a Can (286 pts)]]></title>
            <link>https://one-from-nippon.ghost.io/coffee-in-a-can/</link>
            <guid>37451728</guid>
            <pubDate>Sun, 10 Sep 2023 00:30:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://one-from-nippon.ghost.io/coffee-in-a-can/">https://one-from-nippon.ghost.io/coffee-in-a-can/</a>, See on <a href="https://news.ycombinator.com/item?id=37451728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Life’s inconveniences, when they happen to you and me, are just that. Inconveniences.</p>
<p>When they happen to some people though they end up becoming multi-billion dollar businesses.</p>
<p>This is the story of Japan’s canned coffee.</p>
<hr>
<p>One finds at least one vending machine in almost every street in Japan. In every vending machine one row is dedicated to just one product: canned coffee.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/6158690399_cea99906b1_k.jpg" alt="" loading="lazy" width="2000" height="1500" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/6158690399_cea99906b1_k.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/6158690399_cea99906b1_k.jpg 1000w, https://one-from-nippon.ghost.io/content/images/size/w1600/2023/09/6158690399_cea99906b1_k.jpg 1600w, https://one-from-nippon.ghost.io/content/images/2023/09/6158690399_cea99906b1_k.jpg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>The bottom row on this vending machine is all coffee. Blue buttons are cold coffee and red ones are hot </span><i><em>Source: </em></i><a href="https://flic.kr/p/aodU6e?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Kevin Dooley</em></i></a></figcaption></figure>
<p>Canned coffee, as it says on the tin, is ready-to-drink coffee in a can.</p>
<p>There are hundreds of variations of canned coffee and some can’t even legally be called “coffee” in Japan.</p>
<h2 id="inconveniences-and-thrifty-entrepreneurs">Inconveniences and thrifty entrepreneurs</h2>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/20200221_154959629--2-.jpg" alt="" loading="lazy" width="1600" height="900" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/20200221_154959629--2-.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/20200221_154959629--2-.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/20200221_154959629--2-.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Bottled milk coffee </span><i><em>Source: </em></i><a href="https://chemlover-musician.blogspot.com/?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>こやまうんてん</em></i></a></figcaption></figure>
<p>The year was 1969. Tadao Ueshima was at the train station.</p>
<p>In the sweltering heat of the Japanese summer he got himself a bottle of cold “coffee milk” (コーヒー牛乳) from the station’s convenience store, figuring he had a few minutes till the train left.</p>
<p>In those days you would buy your drink, drink it on the spot, and return the bottle. As luck would have it, he mistimed his coffee and his train started to pull out of the station. He hurriedly returned his half-finished bottle and ran to his train.</p>
<p>Now, Tadao had somewhat of a reputation as a frugal man. He hated seeing things go to waste. And he couldn’t shake off the frustration of the coffee. “If only there was a way I could buy and carry my coffee with me…” he reasoned.</p>
<p>Fate couldn’t have chosen a better person for this encounter.</p>
<p>Tadao Ueshima was the CEO of UCC Coffee, which sold coffee and tea in bulk to restaurants. He assembled a team at UCC and gave them an impossible mission: to create a coffee he could buy and walk away with.</p>
<p>Such a thing was unheard of.</p>
<p>The team quickly landed on using steel cans for the coffee. This way people could buy coffee anywhere there was a vending machine. This was probably the easy part.</p>
<p>After all, how hard could it be to make canned coffee? You make coffee, pour it into a can, and seal it, right?</p>
<p>That is what the team started with, but they ran into one problem after the other: the coffee and milk would separate when they left the can sit; the coffee reacted with the steel can and turned into an unappetizing black liquid; the coffee tasted weird when they sterilized the sealed cans.</p>
<p>One by one, they experimented their way out of these problems and finally in April 1969 their first mass-produced canned coffee was ready.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/12638279044_822fc073f1_k-2.jpg" alt="" loading="lazy" width="377" height="700"><figcaption><span>UCC Canned Milk Coffee </span><i><em>Source: </em></i><a href="https://flic.kr/p/kfNu3Q?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Like_the_Grand_Canyon</em></i></a></figcaption></figure>
<p>Remember I said this thing was unheard of? Well, their buyers hadn’t heard of it either and had zero faith that people would want to drink coffee out of a steel can instead of choosing a nice, cold bottle of coffee.</p>
<p>Some people even called it blasphemy to stuff coffee in a can. (<em>Yes, I know many of you think adding milk and sugar to coffee is blasphemy already.</em>)</p>
<p>UCC’s employees went store by store, opening the cold canned coffee and inviting owners to try it for themselves. But it did not move the needle much.</p>
<p>They then changed strategy and focused on the <a href="https://en.wikipedia.org/wiki/Expo_%2770?ref=one-from-nippon.ghost.io" rel="noreferrer">1970 Osaka World Fair</a>, where companies from across the world came to showcase the latest and greatest from their countries. This was a massive, 6-month long event, which over 64 million people attended.</p>
<p>UCC targeted the restaurants and shops around the 330-hectare venue and this is where they got their first taste of success. In just a few weeks, people were clamoring for the cold milk coffee to quench them in the heat of the Japanese summer.</p>
<p>This newfound recognition from the World Fair catapulted UCC and in just one year, their revenues exceeded 10 billion yen.</p>
<h2 id="%E2%80%9Creal%E2%80%9D-canned-coffee">“Real” Canned Coffee</h2>
<p>While UCC was busy taking over the world, there existed people who couldn’t take  “coffee milk” seriously. One such people was Toshikage Tanida, the CEO of a company called Pokka Lemon that made synthetic lemon juice.</p>
<p>In 1972, Toshikage stopped at a service area on the highway after a long drive and wanted a cup of coffee to freshen up. There was a long line at the service area's only coffee shop and it took him 30 minutes to get his coffee.</p>
<p>You and I would have grumbled and moved on. But not Toshikage.</p>
<p>The experience annoyed him so much that he set about looking for a way to have <em>real</em> canned coffee. Pure coffee, unadulterated by sugar and milk. <em>Hot</em> coffee.</p>
<p>By 1972 vending machines were the main channel of selling canned coffee, but most vending machines only had one mode: cold. Pokka collaborated with a vending machine manufacturer to build a “hot-and-cold” vending machine which could sell both hot and cold beverages simultaneously.</p>
<p>It took them a year to build this, but in 1973, Pokka could legitimately lay claim to creating the first canned hot <em>actually-coffee</em> coffee.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/2804520553_90a6cdc92f_k.jpg" alt="" loading="lazy" width="1536" height="2048" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/2804520553_90a6cdc92f_k.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/2804520553_90a6cdc92f_k.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/2804520553_90a6cdc92f_k.jpg 1536w" sizes="(min-width: 720px) 720px"><figcaption><span>Pokka Aromax sugarless coffee </span><i><em>Source: </em></i><a href="https://flic.kr/p/5gPUfD?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>David Pursehouse</em></i></a></figcaption></figure>
<p>I am drinking a freshly brewed cup of coffee as I write this, and I can only imagine how much of thought, work, and failed experiments went into canning something as sensitive as coffee.</p>
<p>Especially so, when you realize this coffee is heated constantly, for an indefinite amount of time in a vending machine, and <em>still</em> tastes the way it was supposed to taste! Mad respect for the people who pulled this off.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/13973225107_ea2056fb4d_h.jpg" alt="" loading="lazy" width="1600" height="1067" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/13973225107_ea2056fb4d_h.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/13973225107_ea2056fb4d_h.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/13973225107_ea2056fb4d_h.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Translation: "Actually, this was canned coffee. Georgia European". Seen at a coffee workshop. </span><i><em>Source: </em></i><a href="https://flic.kr/p/nhLr1g?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Hideya HAMANO</em></i></a></figcaption></figure>
<h2 id="enter-coca-cola-and-tommy-lee-jones">Enter Coca Cola and Tommy Lee Jones</h2>
<p>Most canned coffee was sold through vending machines and thanks to Pokka, Japan now had hot-and-cold vending machines. Guess who had more vending machines than everyone else in Japan? Coca Cola.</p>
<p>In 1975 Coca Cola entered the game with their “Georgia” canned coffee, named after the home state of the Coca Cola Corporation. Coca Cola’s sheer brand might and vending machine network gave it meteoric growth. So meteoric, that to this day, Coca Cola Japan’s best selling product is not Coca Cola. It’s Georgia coffee!</p>
<p>Suntory, another beverage maker jumped into the fray and took the world by storm with their brilliant advertising campaign.</p>
<p>They called their coffee “BOSS” and hired Tommy Lee Jones to be the face of the brand. Tommy was cast as an alien exploring earth, trying to understand the life of everyday humans.</p>
<p>Suntory wanted to paint BOSS as a coffee for the hardworking people on the street and with their ad campaign they succeeded <em>spectacularly</em>. Watch with the subtitles turned on and I think you will see why.</p>
<figure><iframe width="200" height="113" src="https://www.youtube.com/embed/videoseries?list=PL4F3C1016A2216AB3" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></figure>
<hr>
<p>The success of canned coffee rests on two pillars – cans and vending machines. How these coffee cans are made is a <a href="http://www.chymist.com/Aluminum%20can.pdf?ref=one-from-nippon.ghost.io" rel="noreferrer">rabbit hole</a> of its own if you’re into the sheet metal forming kind of thing. The vending machines too deserve a whole other article of their own. In fact, if you think we should write about Japanese vending machines next, comment down below!</p>
<p>To the people still shaking your head that coffee in a can can’t <em>possibly</em> be good, it can. </p>
<p>I will leave you with this video of a guy who flew to Italy and recorded the reactions of strangers (including a pair of baristas) drinking canned coffee:</p>
<figure><iframe width="200" height="113" src="https://www.youtube.com/embed/LjpMEu_IHKo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="「日本の缶コーヒー」をカフェの本場・イタリアの人たちが飲んだらこうなった"></iframe></figure>
<hr>

<p>

We hope you enjoyed this article! If you haven't already, we would love it if you subscribed to our newsletter. It would encourage us <b>greatly</b> to create more interesting posts like this. Sign up from <a href="https://one-from-nippon.ghost.io/">here</a>.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[School of SRE: Curriculum for onboarding non-traditional hires and new grads (164 pts)]]></title>
            <link>https://github.com/linkedin/school-of-sre</link>
            <guid>37451715</guid>
            <pubDate>Sun, 10 Sep 2023 00:27:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/linkedin/school-of-sre">https://github.com/linkedin/school-of-sre</a>, See on <a href="https://news.ycombinator.com/item?id=37451715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">School of SRE</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/linkedin/school-of-sre/blob/main/img/sos.png"><img src="https://github.com/linkedin/school-of-sre/raw/main/img/sos.png" width="200"></a></p>
<p dir="auto">Site Reliability Engineers (SREs)  sits at the intersection of software engineering and systems engineering. While there are potentially infinite permutations and combinations of how infrastructure and software components can be put together to achieve an objective, focusing on foundational skills allows SREs to work with complex systems and software, regardless of whether these systems are proprietary, 3rd party, open systems, run on cloud/on-prem infrastructure, etc. Particularly important is to gain a deep understanding of how these areas of systems and infrastructure relate to each other and interact with each other. The combination of software and systems engineering skills is rare and is generally built over time with exposure to a wide variety of infrastructure, systems, and software.</p>
<p dir="auto">SREs bring in engineering practices to keep the site up. Each distributed system is an agglomeration of many components. SREs validate business requirements, convert them to SLAs for each of the components that constitute the distributed system, monitor and measure adherence to SLAs, re-architect or scale out to mitigate or avoid SLA breaches, add these learnings as feedback to new systems or projects and thereby reduce operational toil. Hence SREs play a vital role right from the day 0 design of the system.</p>
<p dir="auto">In early 2019, we started visiting campuses across India to recruit the best and brightest minds to make sure LinkedIn, and all the services that make up its complex technology stack are always available for everyone. This critical function at LinkedIn falls under the purview of the Site Engineering team and Site Reliability Engineers (SREs) who are Software Engineers, specialized in reliability.</p>
<p dir="auto">As we continued on this journey we started getting a lot of questions from these campuses on what exactly the site reliability engineering role entails? And, how could someone learn the skills and the disciplines involved to become a successful site reliability engineer? Fast forward a few months, and a few of these campus students had joined LinkedIn either as interns or as full-time engineers to become a part of the Site Engineering team; we also had a few lateral hires who joined our organization who were not from a traditional SRE background. That's when a few of us got together and started to think about how we can onboard new graduate engineers to the Site Engineering team.</p>
<p dir="auto">There are very few resources out there guiding someone on the basic skill sets one has to acquire as a beginner SRE. Because of the lack of these resources, we felt that individuals have a tough time getting into open positions in the industry. We created the School Of SRE as a starting point for anyone wanting to build their career as an SRE.
In this course, we are focusing on building strong foundational skills. The course is structured in a way to provide more real life examples and how learning each of these topics can play an important role in day to day job responsibilities of an SRE. Currently we are covering the following topics under the School Of SRE:</p>
<ul dir="auto">
<li>
<p dir="auto">Level 101</p>
<ul dir="auto">
<li>Fundamentals Series
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level101/linux_basics/intro/" rel="nofollow">Linux Basics</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/git/git-basics/" rel="nofollow">Git</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/linux_networking/intro/" rel="nofollow">Linux Networking</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/python_web/intro/" rel="nofollow">Python and Web</a></li>
<li>Data
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level101/databases_sql/intro/" rel="nofollow">Relational databases(MySQL)</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/databases_nosql/intro/" rel="nofollow">NoSQL concepts</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/big_data/intro/" rel="nofollow">Big Data</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/systems_design/intro/" rel="nofollow">Systems Design</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/" rel="nofollow">Metrics and Monitoring</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/security/intro/" rel="nofollow">Security</a></li>
</ul>
</li>
<li>
<p dir="auto">Level 102</p>
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level102/linux_intermediate/introduction/" rel="nofollow">Linux Intermediate</a></li>
<li>Linux Advanced
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level102/containerization_and_orchestration/intro/" rel="nofollow">Containers and orchestration</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_calls_and_signals/intro/" rel="nofollow">System Calls and Signals</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/networking/introduction/" rel="nofollow">Networking</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_design/intro/" rel="nofollow">System Design</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_troubleshooting_and_performance/introduction/" rel="nofollow">System troubleshooting and performance improvements</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/continuous_integration_and_continuous_delivery/introduction/" rel="nofollow">Continuous Integration and Continuous Delivery</a></li>
</ul>
</li>
</ul>
<p dir="auto">We believe continuous learning will help in acquiring deeper knowledge and competencies in order to expand your skill sets, every module has added references that could be a guide for further learning. Our hope is that by going through these modules we should be able to build the essential skills required for a Site Reliability Engineer.</p>
<p dir="auto">At LinkedIn, we are using this curriculum for onboarding our non-traditional hires and new college grads into the SRE role. We had multiple rounds of successful onboarding experiences with new employees and the course helped them be productive in a very short period of time. This motivated us to open source the content for helping other organizations in onboarding new engineers into the role and provide guidance for aspiring individuals to get into the role. We realize that the initial content we created is just a starting point and we hope that the community can help in the journey of refining and expanding the content. Check out <a href="https://github.com/linkedin/school-of-sre/blob/main/CONTRIBUTING.md">the contributing guide</a> to get started.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Computer Science from the Bottom Up (111 pts)]]></title>
            <link>https://www.bottomupcs.com/</link>
            <guid>37451551</guid>
            <pubDate>Sun, 10 Sep 2023 00:00:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bottomupcs.com/">https://www.bottomupcs.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37451551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h3><span><span>Ian</span> <span>Wienand</span></span></h3></p><p><span>
      A PDF version is available at <a href="https://www.bottomupcs.com/csbu.pdf">https://www.bottomupcs.com/csbu.pdf</a>.
      A EPUB version is available at <a href="https://www.bottomupcs.com/csbu.epub">https://www.bottomupcs.com/csbu.epub</a>
      The original souces are available at <a href="https://github.com/ianw/bottomupcs">https://github.com/ianw/bottomupcs</a>
    </span></p><p>This work is licensed under the Creative Commons
      Attribution-ShareAlike License. To view a copy of this license,
      visit <a href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>
      or send a letter to Creative Commons, 559 Nathan Abbott Way,
      Stanford, California 94305, USA.
      </p><p>Copyright © <span><span>2004</span>–<span>2022</span></span> <span>Ian Wienand</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memories from Old LAN Parties (413 pts)]]></title>
            <link>https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html</link>
            <guid>37451518</guid>
            <pubDate>Sat, 09 Sep 2023 23:54:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html">https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html</a>, See on <a href="https://news.ycombinator.com/item?id=37451518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I participated in a lot of LANs in the 2000s, sometimes at private homes and sometimes at dedicated LAN venues. Many strange and wonderful things happened at these events that wouldn’t make a lick of sense today. Here is a collection of unrelated memories which may be altered to protect the guilty.</p>

<hr>

<p>A man who runs a LAN facility will generally not give you a Windows 98 SE CD key, even if you need to reinstall Windows on your PC during an event.</p>

<p>A LAN isn’t legitimate unless at least one person has to reinstall Windows along the way.</p>

<p>Multi-round tournaments seem like a good idea but you will never get anybody into their allocated matches at the times they’re supposed to be there.</p>

<p>If you mod your ATX case so that the power button is gigantic and illuminated with a red LED, someone will come along while you’re gaming and wonder out loud “what does this button do?” while pressing it.</p>

<p>Having a PC with a window in the side of the case does in fact give you credibility.</p>

<p>If you take a 500 GB drive to a public LAN where the average drive size is 80 GB then it is possible that it will be stolen from your box while you’re taking a break go-karting.</p>

<p>If you use a crack that generates malicious traffic from your IP then you may be forced to reinstall Windows before you can reconnect to the network.</p>

<p>If you don’t have enough warez to reach the minimum share limit for the DC++ server you can always add the directories for your games installed under Program Files.</p>

<p>The desk you’re seated at may have a badge at the back telling you which static IP to use, but you can ignore that if the venue has upgraded to DHCP.</p>

<p>If you’re using a 10 Mbit hub and copy the same directory to two Windows SMB hosts simultaneously it is somehow smart enough to make the transfers coincide so it can transmit the same data to both at once. To this day I have no idea what heuristic it used but honest to god, it slowed down the earlier transfer and then went in lockstep file by file for the remainder.</p>

<p>If you throw an old motherboard onto the 11 kV power lines on a nearby pole it will toast some components but probably not cause a power outage.</p>

<p>Windows 98 SE requires that you reboot after changing your IP address settings.</p>

<p>Windows 2000 is quite good for gaming and has the added benefit that you will be prompted to press Ctrl-Alt-Del to logon, which feels corporate (or school-like) and cool.</p>

<p>If a pirated game comes with a crack.exe then you run the crack.exe. What could go wrong?</p>

<p>There were websites which aggregated downloads of keygens for various games. These worked more often than you would expect.</p>

<p>In an attempt to reduce piracy for multiplayer, game producers such as Blizzard let you install “spawn” copies of the software which could only participate in a multiplayer game and didn’t require the CD to be in the drive.</p>

<p>Alcohol 120% was the free tool of choice to emulate a CD drive for ISOs of games which required the CD to be inserted for copy protection, or rip a CD for that purpose. This only became popular once hard drives became big enough for people to spend many gigabytes imaging their CDs.</p>

<p>The cool kids had a Barton Athlon XP 2500+ and a Radeon 9600. The rich kids had a 9800.</p>

<p>Internet access wasn’t a thing until the later years. LANs which tried to provide internet had strict quotas or bandwidth limits and generally found it difficult to manage.</p>

<p>If you had the right ICQ number you could repeat it multiple times to generate a valid Starcraft CD key.</p>

<p>Sometimes LANs would get terrible sponsorship deals and nerds would fight over bounty like a CD of <a href="https://archive.org/details/X04-63221">Visual C++ 6 Enterprise Edition</a>.</p>

<p>A man who runs a LAN facility might sell you an RTL8139 PCI card for $15 if you want to upgrade to 100 Mbps. This card might work great for a decade+ after.</p>

<p>If you’re a poor high school student who wants to upgrade your home network from a hub to a switch, you could pay the lion’s share of the $55 for the right to keep it at your house between LANs.</p>

<p>WINE can basically only run Starcraft.</p>

<p>If someone has shared their installation of Warcraft III over SMB it will run much faster if you copy it to your local machine first rather than execute it directly from the network folder.</p>

<p>Motherboards had headers to connect USB ports built into the case but they were completely unstandardised so you had to slot them in pin-by-pin in the correct locations following your motherboard manual. If you got this wrong you could short out your PSU through thin wires by plugging in a USB mouse, which would create an awful whirring sound.</p>

<p>A commercial LAN venue would advertise itself on a local pop music radio station by having a dialogue of people arguing about which IP addresses to use.</p>

<p>If you had the oldest PC in your group, you might be connecting to the hub via coax and a BNC connector while everyone else is using CAT5.</p>

<p>What’s WiFi?</p>

  </div></div>]]></description>
        </item>
    </channel>
</rss>