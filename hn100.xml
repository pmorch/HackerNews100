<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 18 Dec 2024 18:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cultural Evolution of Cooperation Among LLM Agents (118 pts)]]></title>
            <link>https://arxiv.org/abs/2412.10270</link>
            <guid>42450950</guid>
            <pubDate>Wed, 18 Dec 2024 15:00:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.10270">https://arxiv.org/abs/2412.10270</a>, See on <a href="https://news.ycombinator.com/item?id=42450950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.10270">View PDF</a>
    <a href="https://arxiv.org/html/2412.10270v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) provide a compelling foundation for building generally-capable AI agents. These agents may soon be deployed at scale in the real world, representing the interests of individual humans (e.g., AI assistants) or groups of humans (e.g., AI-accelerated corporations). At present, relatively little is known about the dynamics of multiple LLM agents interacting over many generations of iterative deployment. In this paper, we examine whether a "society" of LLM agents can learn mutually beneficial social norms in the face of incentives to defect, a distinctive feature of human sociality that is arguably crucial to the success of civilization. In particular, we study the evolution of indirect reciprocity across generations of LLM agents playing a classic iterated Donor Game in which agents can observe the recent behavior of their peers. We find that the evolution of cooperation differs markedly across base models, with societies of Claude 3.5 Sonnet agents achieving significantly higher average scores than Gemini 1.5 Flash, which, in turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an additional mechanism for costly punishment to achieve yet higher scores, while Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also observe variation in emergent behavior across random seeds, suggesting an understudied sensitive dependence on initial conditions. We suggest that our evaluation regime could inspire an inexpensive and informative new class of LLM benchmarks, focussed on the implications of LLM agent deployment for the cooperative infrastructure of society.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Edward Hughes [<a href="https://arxiv.org/show-email/857833b1/2412.10270" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 13 Dec 2024 16:45:49 UTC (1,544 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jaguar Land Rover electric car whistleblower sacked (104 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c20nr3zdppjo</link>
            <guid>42450080</guid>
            <pubDate>Wed, 18 Dec 2024 12:58:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c20nr3zdppjo">https://www.bbc.com/news/articles/c20nr3zdppjo</a>, See on <a href="https://news.ycombinator.com/item?id=42450080">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p data-component="headline-block"><h2>Jaguar Land Rover electric car whistleblower sacked<!-- --></h2></p><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/77ef/live/f664fbe0-bd19-11ef-a0f2-fd81ae5962f4.jpg.webp" alt="BBC A man in a white shirt and black suit jacket sitting in a darkened room with the blind drawn. He has dark short hair and a dark beard."><span>BBC</span></p></div><p data-component="caption-block"><figcaption>Mechanical engineer Hazar Denli says he was sacked after raising safety concerns<!-- --></figcaption></p></figure><div data-component="text-block"><p>The BBC has seen evidence the multinational corporation that owns Jaguar Land Rover (JLR) arranged for a whistleblower to be sacked for raising concerns about the safety of electric cars it designed.<!-- --></p><p>Confidential emails between executives at Tata Group reveal they retaliated against mechanical engineer Hazar Denli for posting concerns on Reddit that lives were being put at risk. He was then blacklisted.<!-- --></p><p>US authorities are now investigating an earlier model of the same car after 28 reports of safety defects and a crash in which a family-of-four were killed.<!-- --></p><p>In response to a detailed right of reply letter from the BBC, both JLR and Tata Group declined to comment.<!-- --></p></div><div data-component="text-block"><p>Mr Denli, from Milton Keynes, first raised concerns internally while working at a different division of Tata Group, its global engineering consultancy Tata Technologies.<!-- --></p><p>He told the BBC that in test-driving prototypes, designed by Tata Technologies for Vietnamese car maker Vinfast, he identified improperly designed components in the car's chassis, including its suspension system. <!-- --></p><p>At low mileages, some of them were snapping off, he said.<!-- --></p><p>That created a risk that under stress, such as hitting a pothole at speed, the wheels could become misaligned, causing the car to veer to the left or right without prompting, and the driver could lose control, Mr Denli added.<!-- --></p><p>"We saw, for example, the front strut-to-knuckle connection was loosening, which could be extremely dangerous," he said. "It could cause a loosening of the entire structure that could cause wheels to come off.<!-- --></p><p>"In a crash scenario, it could be completely unsafe. It could cause the vehicle to lose control."<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/1a18/live/5b27b8a0-bbd6-11ef-96a6-9d05544d8e20.png.webp" alt="Getty Images A black car in a showroom with the letters VF8 on the number plate and two black scooters and a blue car in the background"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>US authorities have started an investigation into the VinFast VF8 after drivers reported flaws<!-- --></figcaption></p></figure><p data-component="subheadline-block"><h2>'Alarm bells'<!-- --></h2></p><div data-component="text-block"><p>Mr Denli, a specialist in chassis design, was appointed to lead the engineering team working on the car's front suspension and chassis from September 2022, halfway through a design and testing phase he says had an unusually tight timetable.<!-- --></p><p>He soon became concerned VinFast was cutting corners with safety, keeping costs down by employing a small team of inexperienced engineers.<!-- --></p><p>His concerns grew when he heard three of his predecessors had quit after short spells on the project.<!-- --></p><p>He says in February and March 2023, while running vigorous testing on VinFast cars at the Mira Technology Park near Nuneaton, two components snapped off and another two failed. <!-- --></p><p>He reported the "extremely concerning" incidents to colleagues at Tata Technologies Limited (TTL), the consultancy's UK division, based in Leamington Spa, Warwickshire.<!-- --></p><p>In subsequent testing, he alleges further components failed. <!-- --></p><p>Mr Denli said they were failing after fewer than 25,000 km (15,534 miles), when normally they would be expected to last for at least 150,000 km (93,205 miles).<!-- --></p><p>"In the drive units, some of the brackets were completely failing and falling out on to the road," he said. "We're talking one or two kilograms worth of aluminium. <!-- --></p><p>"These [incidents] started causing alarm bells to go off just a short time before we we went into production."<!-- --></p></div><div data-component="text-block"><p>He escalated his concerns to senior executives at TTL and VinFast and said he  had recommended they redesign the faulty components and manufacture safer, higher quality parts.<!-- --></p><p>That would have sharply boosted costs and required VinFast Group to postpone production of the car, he added.<!-- --></p><p>But VinFast, which was preparing to sell shares in itself and raise funds by floating on the New York Stock Exchange, instead pushed ahead with production.<!-- --></p><p>Mr Denli asked Tata Technologies to reassign him to another project but senior managers refused. <!-- --></p><p>Unhappy to be associated with the VinFast car, he says, in May last year he resigned.<!-- --></p></div><div data-component="text-block"><p>With his skills as a consultant engineer in demand, Mr Denli later found new work via an agency at JLR in Gaydon, also owned by the Tata Group.<!-- --></p><p>But he said he kept seeing reports online appearing to show serious safety defects in earlier models of the same VinFast car – including a video that appeared to show a car reversing with no driver in it – and crashed cars where the wheels had come off. <!-- --></p><p>In another report, a VinFast car at a showroom in Germany caught fire.<!-- --></p><p>The same components he was testing in VinFast's VF6 and VF7 models had been carried over from two earlier models already on sale in the United States, Vietnam and Europe - the VF8 and VF9.<!-- --></p><p>Then on 24 April this year, <!-- --><a target="_blank" href="https://www.latimes.com/california/story/2024-05-23/federal-agency-investigates-fiery-ev-crash-that-killed-california-family">a family-of-four was killed in a crash<!-- --></a> in Pleasanton, California. Police reported the vehicle lost control, veered off the road, hit a pole and caught fire. <!-- --></p><p>The following month, US safety regulator the National Highway Traffic Safety Administration (NHTSA), announced it was reviewing the VinFast VF8. VinFast said it was cooperating with the investigation.<!-- --></p><p>The reports of the crash prompted Mr Denli to publish the posts <!-- --><a target="_blank" href="https://www.reddit.com/r/VinFastCommunity/comments/1d3be8z/i_designed_major_sections_of_vinfast_ask_me/?rdt=62979">on a Reddit account<!-- --></a> saying he had worked on the design of the car and it was a vehicle he believed endangered lives.<!-- --></p><p>"I would get into every other vehicle I have designed from other brands… and every vehicle has flaws… But Vinfast, I wouldn't get into one… never will and I won't let my loved ones get into one either," he wrote.<!-- --></p><p>Two months later, on 18 July this year, Mr Denli's contract at JLR was terminated.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/61dd/live/247e3830-bc97-11ef-8d74-9336f9cf2a33.jpg.webp" alt="Getty Images A bright blue VinFast electric car plugged in at an outdoor charging station. Only the rear of the vehicle can be seen, with the charging hatch open. A picture of a grey version of the vehicle can be seen next to the car."><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>VinFast is a client of Jaguar Land Rover owner Tata Group<!-- --></figcaption></p></figure><div data-component="text-block"><p>Internal documents obtained through a Data Subject Access Request (DSAR) reveal a senior executive at his former employer Tata Technologies had been in touch with JLR executives to seek his dismissal.<!-- --></p><p>After he saw the Reddit posts, Tata Technologies HR director Patrick Flood discussed his company's wish to have Mr Denli's new employment terminated with JLR's HR director and board member Dave Williams.<!-- --></p><p>Mr Flood told Mr Williams that Tata Group's client VinFast had conducted its own investigation and identified Mr Denli as the author of the Reddit posts: "The concern is if he has done this now, he could do the same at JLR."<!-- --></p><p>The same day he was sacked, Mr Denli was blacklisted on industry recruitment platform Magnit, which told JLR he had been "red-flagged" so any applications from him for other work via the platform would be automatically declined.<!-- --></p><p>On 19 July, Mr Flood emailed JLR corporate investigators: "I just wanted to check whether the individual's services have been terminated with JLR?" The investigator confirmed they had.<!-- --></p><p>The internal documents show another Tata Technologies engineer had also told JLR there were problems with components Mr Denli had warned about on Reddit.<!-- --></p><p>Mr Denli said his bosses at JLR knew he had done nothing wrong in his JLR employment and told him he had been dismissed because Tata Group was embarrassed by his postings about its client, VinFast. <!-- --></p><p>He is now taking JLR to an employment tribunal.<!-- --></p><p>"I was distressed as to what was happening around the world where innocent people were paying the price - a very high price," he said.<!-- --></p><p>"I thought that if some people would start to speak up about it, they would actually be forced to make some changes. Unfortunately, their response was not to make these improvements, but, 'Hey, who said this? Let's go and shut him up'."<!-- --></p></div><div data-component="text-block"><p>On 12 September, the NHTSA launched an investigation into the Vinfast VF8.<!-- --></p><p><a target="_blank" href="https://www.reuters.com/business/autos-transportation/us-opens-probe-into-around-3118-vinfast-vehicles-2024-09-12">It announced it was looking into 3,118 VinFast vehicles<!-- --></a> sold in the US after 14 drivers reported the Lane Keep Assist systems were flawed in VF8 cars bought in 2023 and 2024.<!-- --></p><p>The NHTSA said the drivers reported the system "has difficulty detecting lanes on the roadway, provides improper steering inputs and is difficult to override by the driver". <!-- --></p><p>VinFast said it would cooperate fully with the NHTSA throughout this process.<!-- --></p><p>"We take all safety concerns seriously and will continue to monitor the situation closely," VinFast told Reuters, expressing the company's confidence in its safety standards.<!-- --></p><p>The number of reports of safety issues received by the NHTSA has now <!-- --><a target="_blank" href="https://www.nhtsa.gov/vehicle/2023/VINFAST/VF8#investigations">grown to 28<!-- --></a>.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/d65b/live/58494960-bc9d-11ef-8d74-9336f9cf2a33.jpg.webp" alt="Getty Images A close up on a man's hands using a mobile phone. He is wearing a cream jumper and brown trousers and sitting in a room with a grey rug and carpet."><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Stronger protections are needed for whistleblowers, supporters say<!-- --></figcaption></p></figure><p data-component="subheadline-block"><h2>Parliamentary bill to support whistleblowers<!-- --></h2></p><div data-component="text-block"><p>In UK employment law, workers have some protection from employer retaliation if they disclose information they reasonably believe shows the health and safety of any individual is likely to be endangered. <!-- --></p><p>Under the Public Interest Disclosure at Work Act 1998, any clause in a contract that seeks to bind them to silence is void.<!-- --></p><p>However, there is growing pressure in Parliament for stronger safeguards for whistleblowers amid concerns existing protections are too weak. <!-- --></p><p>A bill will be introduced on Wednesday proposing to set up an Office of the Whistleblower to protect workers who speak up.<!-- --></p><p>Supporters such as Baroness Susan Kramer, a former transport minister, says Mr Denli's case is not exceptional and underlines why the bill is needed.<!-- --></p><p>"Whistleblowers very typically find themselves fired, blacklisted for future jobs and they pay a huge price in terms of their personal career," she said.<!-- --></p><p>"It is not acceptable, because we need whistleblowers to deter wrongdoing and to expose wrongdoing."<!-- --></p><p>Georgina Halford-Hall, chief executive of Whistleblowers UK, said: "This story is one of hundreds we hear every year from whistleblowers who have been rewarded for doing the right thing with retaliation.  <!-- --></p><p>"Currently whistleblowers have to decide between speaking up and their personal wellbeing. The best incentive that MPs can deliver is to ensure whistleblowers are properly protected and that wrongdoing will be investigated."<!-- --></p><p>The BBC offered both Tata Group and JLR the opportunity to comment in detail. <!-- --></p><p>Tata Group, the multinational corporation that owns JLR, did not respond. <!-- --></p><p>JLR said it did not comment on ongoing legal proceedings.<!-- --></p><p>VinFast said: "We do not interfere in the recruitment or HR activities of the Tata Group or its companies. We have no further comment on the matter."<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/d0cc/live/7dc13690-bbd4-11ef-96a6-9d05544d8e20.png.webp" alt="Getty Images The front of a car showroom with black-framed windows and the words Vinfast in silver lettering above the doors"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>VinFast has denied it interferes with HR activities of the Tata Group<!-- --></figcaption></p></figure><!--$!--><!--/$--></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The unbearable slowness of being: Why do we live at 10 bits/s? (130 pts)]]></title>
            <link>https://www.cell.com/neuron/abstract/S0896-6273(24)00808-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627324008080%3Fshowall%3Dtrue</link>
            <guid>42449602</guid>
            <pubDate>Wed, 18 Dec 2024 11:14:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cell.com/neuron/abstract/S0896-6273(24)00808-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627324008080%3Fshowall%3Dtrue">https://www.cell.com/neuron/abstract/S0896-6273(24)00808-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627324008080%3Fshowall%3Dtrue</a>, See on <a href="https://news.ycombinator.com/item?id=42449602">Hacker News</a></p>
Couldn't get https://www.cell.com/neuron/abstract/S0896-6273(24)00808-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627324008080%3Fshowall%3Dtrue: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Trying to Recreate iOS on the Web (144 pts)]]></title>
            <link>https://homescreen.app/</link>
            <guid>42449588</guid>
            <pubDate>Wed, 18 Dec 2024 11:11:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://homescreen.app/">https://homescreen.app/</a>, See on <a href="https://news.ycombinator.com/item?id=42449588">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Silver amulet is the oldest evidence of Christianity north of the Alps (189 pts)]]></title>
            <link>https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/</link>
            <guid>42448939</guid>
            <pubDate>Wed, 18 Dec 2024 08:31:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/">https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/</a>, See on <a href="https://news.ycombinator.com/item?id=42448939">Hacker News</a></p>
Couldn't get https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ImPlot3D – A 3D Plotting Library for Dear ImGui (131 pts)]]></title>
            <link>https://github.com/brenocq/implot3d</link>
            <guid>42448913</guid>
            <pubDate>Wed, 18 Dec 2024 08:24:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/brenocq/implot3d">https://github.com/brenocq/implot3d</a>, See on <a href="https://news.ycombinator.com/item?id=42448913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ImPlot3D</h2><a id="user-content-implot3d" aria-label="Permalink: ImPlot3D" href="#implot3d"></a></p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294009-359473d2-73a9-452c-a5f3-cb96e3785dc2.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDktMzU5NDczZDItNzNhOS00NTJjLWE1ZjMtY2I5NmUzNzg1ZGMyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyMDA2NzBkNzgwMTQ2Yzc5OTc4NTBmNTk1MjEzOWZiMDZjN2FjZTc5Y2RjOWEwYjU1ZTE4Mzg5MTdmYzVjNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VTIOZATWNCgfD9jqrN7I2sf9sDEgaKQTbL4eeXp-XKM"><img src="https://private-user-images.githubusercontent.com/17342434/396294009-359473d2-73a9-452c-a5f3-cb96e3785dc2.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDktMzU5NDczZDItNzNhOS00NTJjLWE1ZjMtY2I5NmUzNzg1ZGMyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyMDA2NzBkNzgwMTQ2Yzc5OTc4NTBmNTk1MjEzOWZiMDZjN2FjZTc5Y2RjOWEwYjU1ZTE4Mzg5MTdmYzVjNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VTIOZATWNCgfD9jqrN7I2sf9sDEgaKQTbL4eeXp-XKM" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293920-97ec8be4-50f9-428b-b357-25e2479409b8.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5MjAtOTdlYzhiZTQtNTBmOS00MjhiLWIzNTctMjVlMjQ3OTQwOWI4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRiMTUzYTk0ODFhYmFlMDZhMTQ0MjBjMGEzMTRmZTk3MWE0YmI5YzNiYThlMTE1NDhmMDVlODgxZWYxYjJkYmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.6N4RUAIZHGzToq6YEnD1ScvJrxb_1Mjnz7jARKrcuNw"><img src="https://private-user-images.githubusercontent.com/17342434/396293920-97ec8be4-50f9-428b-b357-25e2479409b8.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5MjAtOTdlYzhiZTQtNTBmOS00MjhiLWIzNTctMjVlMjQ3OTQwOWI4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRiMTUzYTk0ODFhYmFlMDZhMTQ0MjBjMGEzMTRmZTk3MWE0YmI5YzNiYThlMTE1NDhmMDVlODgxZWYxYjJkYmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.6N4RUAIZHGzToq6YEnD1ScvJrxb_1Mjnz7jARKrcuNw" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293963-c212039b-4853-4d26-95a5-5470bf97555e.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5NjMtYzIxMjAzOWItNDg1My00ZDI2LTk1YTUtNTQ3MGJmOTc1NTVlLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNGQyY2E0NmVkZDBkODQ0OTc2NTI1MGU4ZmQxYWIzMGRlN2VlZmNhNmMzODZkYWFjMGUyMTc4ZWZlMmRkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.x_iGhu2SickTdn2e7szGsTwFikjZpoOcg_4a_RZWBjQ"><img src="https://private-user-images.githubusercontent.com/17342434/396293963-c212039b-4853-4d26-95a5-5470bf97555e.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5NjMtYzIxMjAzOWItNDg1My00ZDI2LTk1YTUtNTQ3MGJmOTc1NTVlLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNGQyY2E0NmVkZDBkODQ0OTc2NTI1MGU4ZmQxYWIzMGRlN2VlZmNhNmMzODZkYWFjMGUyMTc4ZWZlMmRkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.x_iGhu2SickTdn2e7szGsTwFikjZpoOcg_4a_RZWBjQ" width="270" data-animated-image=""></a>
</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293851-ec7ec42a-3c62-44bf-9275-f735f0304c95.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM4NTEtZWM3ZWM0MmEtM2M2Mi00NGJmLTkyNzUtZjczNWYwMzA0Yzk1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmM2IzNTc5MDhkZGJiMzc4YzM2NzBjMGEyNjZlNzkyZTNjODU5NDE2OTU2YTAwZDQ5ZDY5Mzk4MzM4ZjFhMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.SlPrGpoBjv1WRxHJib3NG5vYWNjPnaCIWpxhrpK5xxY"><img src="https://private-user-images.githubusercontent.com/17342434/396293851-ec7ec42a-3c62-44bf-9275-f735f0304c95.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM4NTEtZWM3ZWM0MmEtM2M2Mi00NGJmLTkyNzUtZjczNWYwMzA0Yzk1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmM2IzNTc5MDhkZGJiMzc4YzM2NzBjMGEyNjZlNzkyZTNjODU5NDE2OTU2YTAwZDQ5ZDY5Mzk4MzM4ZjFhMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.SlPrGpoBjv1WRxHJib3NG5vYWNjPnaCIWpxhrpK5xxY" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294038-e6bd03fa-6d76-4f3e-8d15-c24a05a5f714.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMzgtZTZiZDAzZmEtNmQ3Ni00ZjNlLThkMTUtYzI0YTA1YTVmNzE0LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5NGU5Y2U2ODBhMjQzZmM4ZjlkYmQ3OWQ3ZjUwZTFjMTkzNjE1OTY5MDFjMzhjY2YwZDk1ZTc3N2RhMjcyYjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.xTf-jYLyBnhWwTX76H9-wop8XuLmE-OEoP_ewOhxXwI"><img src="https://private-user-images.githubusercontent.com/17342434/396294038-e6bd03fa-6d76-4f3e-8d15-c24a05a5f714.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMzgtZTZiZDAzZmEtNmQ3Ni00ZjNlLThkMTUtYzI0YTA1YTVmNzE0LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5NGU5Y2U2ODBhMjQzZmM4ZjlkYmQ3OWQ3ZjUwZTFjMTkzNjE1OTY5MDFjMzhjY2YwZDk1ZTc3N2RhMjcyYjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.xTf-jYLyBnhWwTX76H9-wop8XuLmE-OEoP_ewOhxXwI" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294001-b66ff296-7fbf-4644-9129-37daecca0b62.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDEtYjY2ZmYyOTYtN2ZiZi00NjQ0LTkxMjktMzdkYWVjY2EwYjYyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyZjk1ODNjYzRhZTk4ZjQ4OGFiNTNmNTllYTk5MGFkYWE0MTg1MmY5NDkxYmI0NGIyZGFjNDBlMmRjNzJjY2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hOSL_5rAcg5LWYmJ6cZE7Gb6bFi4Up3vQIV5QBLYcxY"><img src="https://private-user-images.githubusercontent.com/17342434/396294001-b66ff296-7fbf-4644-9129-37daecca0b62.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDEtYjY2ZmYyOTYtN2ZiZi00NjQ0LTkxMjktMzdkYWVjY2EwYjYyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyZjk1ODNjYzRhZTk4ZjQ4OGFiNTNmNTllYTk5MGFkYWE0MTg1MmY5NDkxYmI0NGIyZGFjNDBlMmRjNzJjY2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hOSL_5rAcg5LWYmJ6cZE7Gb6bFi4Up3vQIV5QBLYcxY" width="270" data-animated-image=""></a>
</p>
<p dir="auto">ImPlot3D is an extension of <a href="https://github.com/ocornut/imgui">Dear ImGui</a> that provides easy-to-use, high-performance 3D plotting functionality. Inspired by <a href="https://github.com/epezent/implot">ImPlot</a>, it brings a familiar and intuitive API for developers already acquainted with ImPlot. ImPlot3D is designed for rendering 3D plots with customizable markers, lines, surfaces, and meshes, providing an ideal solution for applications requiring visual representation of 3D data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Features</h2><a id="user-content--features" aria-label="Permalink: 🚀 Features" href="#-features"></a></p>
<ul dir="auto">
<li>GPU-accelerated rendering</li>
<li>Multiple plot types:
<ul dir="auto">
<li>Line plots</li>
<li>Scatter plots</li>
<li>Surface plots</li>
<li>Quad plots</li>
<li>Triangle plots</li>
<li>Mesh plots</li>
<li>Text plots</li>
</ul>
</li>
<li>Rotate, pan, and zoom 3D plots interactively</li>
<li>Several plot styling options: 10 marker types, adjustable marker sizes, line weights, outline colors, fill colors, etc.</li>
<li>16 built-in colormaps and support for and user-added colormaps</li>
<li>Optional plot titles, axis labels, and grid labels</li>
<li>Optional and configurable legends with toggle buttons to quickly show/hide plot items</li>
<li>Default styling based on the current ImGui theme, or completely custom plot styles</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ Usage</h2><a id="user-content-️-usage" aria-label="Permalink: 🛠️ Usage" href="#️-usage"></a></p>
<p dir="auto">The ImPlot3D API is designed to feel very similar to Dear ImGui and ImPlot. You start by calling <code>ImPlot3D::BeginPlot()</code> to initialize a 3D plot, followed by plotting various data using the <code>PlotX</code> functions (e.g., <code>PlotLine()</code> , <code>PlotScatter()</code> , <code>PlotSurface()</code> ). Finally, you end the plot with <code> ImPlot3D::EndPlot()</code> .</p>
<div dir="auto" data-snippet-clipboard-copy-content="float x_data[1000] = ...;
float y_data[1000] = ...;
float z_data[1000] = ...;

ImGui::Begin(&quot;My Window&quot;);
if (ImPlot3D::BeginPlot(&quot;My Plot&quot;)) {
    ImPlot3D::PlotLine(&quot;My Line Plot&quot;, x_data, y_data, z_data, 1000);
    ImPlot3D::PlotScatter(&quot;My Scatter Plot&quot;, x_data, y_data, z_data, 1000);
    ...
    ImPlot3D::EndPlot();
}
ImGui::End();"><pre><span>float</span> x_data[<span>1000</span>] = ...;
<span>float</span> y_data[<span>1000</span>] = ...;
<span>float</span> z_data[<span>1000</span>] = ...;

<span>ImGui::Begin</span>(<span><span>"</span>My Window<span>"</span></span>);
<span>if</span> (ImPlot3D::BeginPlot(<span><span>"</span>My Plot<span>"</span></span>)) {
    <span>ImPlot3D::PlotLine</span>(<span><span>"</span>My Line Plot<span>"</span></span>, x_data, y_data, z_data, <span>1000</span>);
    <span>ImPlot3D::PlotScatter</span>(<span><span>"</span>My Scatter Plot<span>"</span></span>, x_data, y_data, z_data, <span>1000</span>);
    ...
    <span>ImPlot3D::EndPlot</span>();
}
<span>ImGui::End</span>();</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎨 Demos</h2><a id="user-content--demos" aria-label="Permalink: 🎨 Demos" href="#-demos"></a></p>
<p dir="auto">A comprehensive example showcasing ImPlot3D features can be found in <code>implot3d_demo.cpp</code>. Add this file to your project and call <code>ImPlot3D::ShowDemoWindow()</code> in your update loop. This demo provides a wide variety of 3D plotting examples, serving as a reference for creating different types of 3D plots. The demo is regularly updated to reflect new features and plot types, so be sure to revisit it with each release!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Integration</h2><a id="user-content-️-integration" aria-label="Permalink: ⚙️ Integration" href="#️-integration"></a></p>
<p dir="auto">To integrate ImPlot3D into your application, follow these steps:</p>
<ol dir="auto">
<li>Ensure you have a working Dear ImGui environment. ImPlot3D requires only Dear ImGui to function and does not depend on ImPlot.</li>
<li>Add the following source files to your project: <code>implot3d.h</code>, <code>implot3d.cpp</code>, <code>implot3d_internal.h</code>, <code>implot3d_items.cpp</code>. Optionally, include <code>implot3d_demo.cpp</code> for examples and <code>implot3d_meshes.cpp</code> to support pre-loaded meshes.</li>
<li>Create and destroy an ImPlot3DContext alongside your ImGuiContext:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="ImGui::CreateContext();
ImPlot3D::CreateContext();
...
ImPlot3D::DestroyContext();
ImGui::DestroyContext();"><pre><span>ImGui::CreateContext</span>();
<span>ImPlot3D::CreateContext</span>();
...
<span>ImPlot3D::DestroyContext</span>();
<span>ImGui::DestroyContext</span>();</pre></div>
<p dir="auto">You're now ready to start plotting in 3D!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Extremely Important Note</h2><a id="user-content-️-extremely-important-note" aria-label="Permalink: ⚠️ Extremely Important Note" href="#️-extremely-important-note"></a></p>
<p dir="auto">Dear ImGui, by default, uses 16-bit indexing, which might cause issues with high-density 3D visualizations such as complex surfaces or meshes. This can lead to assertion failures, data truncation, or visual glitches. To avoid these problems, it's recommended to:</p>
<ul dir="auto">
<li>Option 1: Enable 32-bit indices by uncommenting <code>#define ImDrawIdx unsigned int</code> in your ImGui imconfig.h file.</li>
<li>Option 2: Ensure your renderer supports the <code>ImGuiBackendFlags_RendererHasVtxOffset</code> flag. Many official ImGui backends already support this functionality.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">💬 FAQ</h2><a id="user-content--faq" aria-label="Permalink: 💬 FAQ" href="#-faq"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why ImPlot3D?</h4><a id="user-content-why-implot3d" aria-label="Permalink: Why ImPlot3D?" href="#why-implot3d"></a></p>
<p dir="auto">While ImGui excels at building UI, it lacks tools for 3D data visualization. ImPlot3D fills this gap, offering a lightweight, real-time library for 3D plotting, designed with interactivity and ease of use in mind.</p>
<p dir="auto">Inspired by ImPlot, ImPlot3D provides a similar API, making it easy for existing ImPlot users to adopt. It focuses on real-time, application-level 3D visualizations for debugging, simulations, and data analysis, with performance as a priority.</p>
<p dir="auto">ImPlot is great for 2D visualizations; ImPlot3D extends this power to 3D, offering the same simplicity and speed.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Where can I find documentation?</h4><a id="user-content-where-can-i-find-documentation" aria-label="Permalink: Where can I find documentation?" href="#where-can-i-find-documentation"></a></p>
<p dir="auto">The API for ImPlot3D is thoroughly commented in <code>implot3d.h</code>, and a comprehensive demo file, <code>implot3d_demo.cpp</code>, showcases all the features. You are encouraged to explore the demo file as it is regularly updated to reflect new functionality. Additionally, if you're familiar with ImPlot, you'll notice many similarities in usage patterns.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How is ImPlot3D different from ImPlot?</h4><a id="user-content-how-is-implot3d-different-from-implot" aria-label="Permalink: How is ImPlot3D different from ImPlot?" href="#how-is-implot3d-different-from-implot"></a></p>
<p dir="auto">ImPlot3D is highly inspired by ImPlot, so if you're already familiar with ImPlot, you'll feel right at home. However, ImPlot3D is specifically built for 3D visualizations, offering interactive 3D rotations, panning, and scaling.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Do I need ImPlot to use ImPlot3D?</h3><a id="user-content-do-i-need-implot-to-use-implot3d" aria-label="Permalink: Do I need ImPlot to use ImPlot3D?" href="#do-i-need-implot-to-use-implot3d"></a></p>
<p dir="auto">No. ImPlot3D is a standalone library and does not depend on ImPlot. You only need Dear ImGui to get started.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Does ImPlot3D support 2D plots?</h4><a id="user-content-does-implot3d-support-2d-plots" aria-label="Permalink: Does ImPlot3D support 2D plots?" href="#does-implot3d-support-2d-plots"></a></p>
<p dir="auto">While you can rotate the 3D view to align with a 2D plane, ImPlot is far better suited for visualizing 2D data. ImPlot3D is specifically designed for 3D plotting and interaction, so we recommend using ImPlot for all your 2D visualization needs.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I customize the appearance of plots?</h4><a id="user-content-can-i-customize-the-appearance-of-plots" aria-label="Permalink: Can I customize the appearance of plots?" href="#can-i-customize-the-appearance-of-plots"></a></p>
<p dir="auto">Absolutely. ImPlot3D allows you to modify plot styles, including line colors, thickness, fill opacity, and marker sizes. You can also use colormaps for surfaces and customize axis labels, grid styles, and background colors.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I export 3D plots to an image?</h4><a id="user-content-can-i-export-3d-plots-to-an-image" aria-label="Permalink: Can I export 3D plots to an image?" href="#can-i-export-3d-plots-to-an-image"></a></p>
<p dir="auto">Not currently. You can use your OS's screen capturing tools to save a plot. ImPlot3D is designed for real-time visualization and interaction, not for creating publication-quality renders. For publication-quality output, consider exporting your data to a dedicated 3D rendering tool.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Is ImPlot3D suitable for publication-quality visuals?</h4><a id="user-content-is-implot3d-suitable-for-publication-quality-visuals" aria-label="Permalink: Is ImPlot3D suitable for publication-quality visuals?" href="#is-implot3d-suitable-for-publication-quality-visuals"></a></p>
<p dir="auto">ImPlot3D prioritizes interactivity and real-time performance. If you need high-quality visualizations, use ImPlot3D for initial exploration and then switch to tools like <a href="https://www.mathworks.com/products/matlab.html" rel="nofollow">MATLAB</a>, <a href="https://matplotlib.org/" rel="nofollow">matplotlib</a>, or <a href="https://www.paraview.org/" rel="nofollow">ParaView</a> for the final output.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - check <a href="https://github.com/brenocq/implot3d/blob/main/LICENSE">LICENSE</a> for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lou's Pseudo 3D Page (2013) (133 pts)]]></title>
            <link>http://www.extentofthejam.com/pseudo/</link>
            <guid>42448184</guid>
            <pubDate>Wed, 18 Dec 2024 04:45:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.extentofthejam.com/pseudo/">http://www.extentofthejam.com/pseudo/</a>, See on <a href="https://news.ycombinator.com/item?id=42448184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<table><tbody><tr><td>
<img src="http://www.extentofthejam.com/pseudo/images/curves1.png"></td><td>
</td></tr></tbody></table>

<br><a href="http://www.extentofthejam.com/pseudo/espanol.html">Pseudo 3d en español aqui! Gracias a Luis Peña!</a>

<br>(C) 2013 Louis Gorenfeld, updated May 3, 2013<p>
<b>NEW:</b> Important details on the segmented road system and some additional links
<br><b>NEW:</b> An (optional) explanation of finding field-of-view for the 3d projection formula
<br><b>NEW:</b> An analysis of S.T.U.N. Runner
<br><b>NEW:</b> General writing improvements

</p><div><p>Previous update:</p><p>
An explanation of 3d projection mathematics (under Road Basics) and analysis of Activision's Enduro (under Case Studies)!
<br>Thanks to everyone for all the e-mail!  Keep it coming :)
Sorry, I can't answer questions about when I'll post source code, but I'm 
always happy to answer anything else about these engines!
<br>Official material on the Road Rash graphics engine and more detailed explanation of curves and a generalized curve equation
</p><p>
Is this information inaccurate?  Am I way off?  Don't hesitate to write me at louis.gorenfeld at gmail dot com!
</p></div><hr noshade="">
<h2>Table of Contents</h2>
<a href="#intro">
Introduction<br>
</a>
<a href="#basics">
Road Basics<br>
</a>
<a href="#curves">
Curves and Steering<br>
</a>
<a href="#sprites">
Sprites and Data<br>
</a>
<a href="#hills">
Hills<br>
</a>
<a href="#wrapup">Taking Raster Roads Farther<br></a>
<a href="#proj3d">True 3d-Projected Segments<br></a>
<a href="#enhancements">
Enhancements<br>
</a>
<a href="#related">
Related Effects<br>
</a>
<a href="#hw">
Case Studies<br>
</a>
<a href="#stuff">
Code Stuff<br>
</a>
<a href="#glossary">
Glossary<br>
</a>
<a href="#gallery">
The Gallery
</a>
<hr noshade="">

<a name="intro">

<h2>Introduction</h2>

</a><p><a name="intro"><u><b>Why Pseudo 3d?</b></u><br>
</a>
Now that every system can produce graphics consisting of a zillion polygons on the fly, why would you want to do a road the old way?  Aren't polygons the exact same thing, only better?  Well, no.  It's true that polygons lead to less distortion, but it is the warping in these old engines that give the surreal, exhillerating sense of speed found in many pre-polygon games.  Think of the view as being controlled by a camera.  As you take a curve in a game which uses one of these engines, it seems to look around the curve.  Then, as the road straightens, the view straightens.  As you go over a blind curve, the camera would seem to peer down over the ridge.  And, since these games do not use a traditional track format with perfect spatial relationships, it is possible to effortlessly create tracks large enough that the player can go at ridiculous speeds-- without worrying about an object appearing on the track faster than the player can possibly react since the physical reality of the game can easily be tailored to the gameplay style.
</p><p>But they have plenty of drawbacks as well.  The depth of physics found in more simulation-like games tends to be lost, and so these engines aren't suited to every purpose.  They are, however, easy to implement, run quickly, and are generally a lot of fun to play with!
</p><p>It is worth noting that not every older racing game used these techniques.  In fact, the method outlined here is only one possible way to do a pseudo 3d road.  Some used projected and scaled sprites, others seem to involve varying degrees of real projection for the road.  How you blend real mathematics with trickery is up to you.  
I hope you have as much fun exploring this special effect as I did.

</p><p><u><b>How Much Math Do I Need?</b></u><br>
If you...
<br>
...have Trigonometry knowledge, that's the most math you'll need for the entire tutorial<br>
...have just Algebra and Geometry, skip the field-of-view explanation<br>
...want to avoid as much math as possible, read: The Simplest Road, Curves and Steering, Sprites and Data, and Hills<br>
</p><p>This is a very flexible technique, and you can actually get by with just addition! With more advanced math, it can look better, but
with just arithmetic, you can get up to the level of detail seen in games like Pole Position or the first OutRun.

</p><p><u><b>How Much Programming Knowledge Do I Need?</b></u><br>
It helps a lot to understand raster graphics: Know what a scanline is, and that each line is made of a row of pixels. 
The programming examples are written in pseudocode, so you don't need experience in any specific language to understand them.
</p><p>
Ready? Let's begin!

</p><p><u><b>Raster Effects - Some Background</b></u><br>
A pseudo 3d road is just a variation of a more general class of effects called raster effects.  
One of the best-known examples of a raster effect is in Street Fighter II:  
As the fighters move left and right, the ground scrolls in perspective.  This actually isn't 3d.  Instead, the ground
graphic is stored as an extremely wide-angle perspective shot.  When the view scrolls, the lines of the screen which are supposed to be farther away scroll more slowly than the lines which
are closer.  That is, each line of the screen scrolls independently of each other.  
Shown below is both the end result and the ground graphic as it is stored in memory.
</p><center>
<img src="http://www.extentofthejam.com/pseudo/images/sf2.png">
<br>
<img src="http://www.extentofthejam.com/pseudo/images/sf2ground_rom.png">
</center>


<a name="basics">
<u>
<h2>Road Basics</h2></u>
</a>
<p><u><b>Introduction to Raster Roads</b></u><br>
We are used to thinking of 3d effects in terms of polygons whose vertices are
suspended in 3d space.  Older systems, however, were not powerful enough to
make a large number of 3d calculations.  Many older effects, in general,
fall into the category of raster effects.  These are special effects which
are done by changing some variable per line.  Most commonly, this means changing
the color or palette per line, or scrolling per line.  This is well-suited to
old graphics hardware which had acceleration for scrolling and used an indexed
color mode.
</p><p>
The pseudo raster road effect actually works similarly to the Street Fighter
II perspective effect in that it warps a static image to create the illusion
of 3d.  Here's how they do it:
</p><p>
Most raster roads start off with an image of a flat road.  This is essentially
a graphic of two parallel lines on the ground retreating into the distance.
As they get farther into the distance, the lines appear to the viewer to
be closer 
together.  This is a basic rule of perspective.  
Now, in order to give the illusion 
of motion, most arcade racing games have stripes on the road.
Moving these stripes on the road forwards is
generally either achieved by color cycling or by changing the palette every line.
Curves and steering are done by scrolling each line independently of one
another, just like in Street Fighter II.  
</p><p>
We will get into curves and steering
in the next chapter.  For now, let's put that aside and concentrate on 
making the road appear to scroll forwards.  

</p><p><u><b>The Simplest Road</b></u><br>
Take the image of a road described above:  Two parallel lines demarcating the left and right edges of the road
retreat into the distance.  As they move into the distance, they appear to the viewer to be closer together.
Below is what this might look like:<br>
<img src="http://www.extentofthejam.com/pseudo/images/nolines.png">
</p><p>
What is missing from this picture are road markings to give a good impression of distance.  Games use alternating light and dark strips, among other road markings, for this effect.  
To help accomplish this, let's define a "texture position" variable.  This variable starts at zero at the bottom of the screen and increases
each line going up the screen.  When this is below a certain amount, the road is drawn in one shade.  When it is above that amount, it is drawn in the other shade.  The position variable then wraps back to zero when it exceeds the maximum amount, causing a repeating pattern.  
</p><p>It is not enough to change this by a set amount each line though, because then you'll just see several strips of different colors which are not getting smaller as the road goes into the distance.  That means you need another variable which will change by a set amount, add it to another variable each line, and then add the last one to the texture position change.
</p><p>Here's an example which shows, from the bottom of the screen, what the Z value will be for each line as it 
recedes into the distance.  After the variables, I print what is added to get the values for the next line.  I've named the values DDZ (delta delta Z), DZ
(delta Z), and Z.  DDZ remains constant, DZ changes in a linear fashion, and Z's value curves.  You can think of Z as
representing the Z position, DZ as holding the velocity of the position, and DDZ as being the acceleration of
the position (the change in acceleration).
Note that the value I chose, four, is arbitrary and was just convinient for this example.
</p><p>
<code>
<span size="-1">
DDZ = 4   DZ = 0   Z = 0  : dz += 4, z += 4<br>
DDZ = 4   DZ = 4   Z = 4  : dz += 4, z += 8<br>
DDZ = 4   DZ = 8   Z = 12 : dz += 4, z += 12<br>
DDZ = 4   DZ = 12  Z = 24 : dz += 4, z += 16<br>
DDZ = 4   DZ = 16  Z = 40 : etc...<br>
</span>
</code>
</p><p>
Noice that DZ is modified first, and then that is used to modify Z.  To sum it up, say you are moving through the texture at speed 4.  That means that after line one, you are reading the texture at position 4.  The next line will be 12.  After that, 24.  So, this way it reads through the texture faster and faster.  This is why I like to refer to these variables as the texture position (where in the texture we are reading), the texture speed (how quickly we read through the texture), and the texture acceleration (how quickly the texture speed increases).
</p><p>A similar method will also be used to draw curves and hills without too much number crunching.  Now, 
to make the road appear to move, just change where the texture position starts at the bottom of the screen for each frame.
</p><p>Now, you may notice a shortcoming with this trick:  the zooming rate is inaccurate.  
This causes a distortion that I will refer to as the "oatmeal effect".  It is a warping effect present in early pseudo games such as OutRun in which objects, including the stripes on the road,
appear to slow down as they move outwards from the center of the screen.
</p><p>This method for finding the Z value has another disadvantage: It's not easily predictable what the value is in the very distance, especially
when hills are involved. We will learn a more advanced method which I will call the Z-map. This is a table that calculates what the Z distance is
for every scanline of the screen. But first, we need a little more math...

</p><p><u><b>A Mathematical Detour: 3d Perspective Projection</b></u><br>
There are ways to get rid of the oatmeal effect.  However, some traditional 3d mathematics are needed to make them possible.  What we need is a way of translating
3d coordinates so that they fit onto a 2d surface. 
</p><p><img src="http://www.extentofthejam.com/pseudo/images/project.png">
</p><p>In the picture above, an eyeball (lower left) is looking through the screen (the blue vertical line) at an object in our 3d world ("y_world").  The eyeball is
a distance "dist" from the screen, and a distance "z_world" from the object.  Now, one thing you might have noticed if you've spent some time with geometry or
trigonometry is that there are not one but two triangles in the picture.  The first triangle is the largest one, from the eyeball over to the ground on the right side
and up to the object we're looking at.  The second triangle I've colored yellow.  This is from the eyeball to where on the screen we'll see our object, down to the
ground, and back.  
</p><p>These two triangles' hypoteneuses (the line from the eye to the object) are at the same angle even though one is longer than the other.  They are essentially 
the same triangle, but the smaller one is just scaled down.  What this implies is that the ratio of the horizontal and vertical sides must be the same!  In math terms:
</p><p><code>y_screen/dist = y_world/z_world</code>
</p><p>What we need to do now is juggle the equation to get y_screen.  This gives us:
</p><p><code>y_screen = (y_world*dist)/z_world</code>
</p><p>In summary, to find the y coordinate of an object on the screen, we take the y world coordinate, multiply that by the distance we are to the screen, and then divide
it by the distance it is in the world.  Of course, if we just do that, the center of our view is going to be the upper-left corner of the screen!  Just plug in y_world=0 to
see this.  What we can do to center it is add half of our screen resolution to the result to put it right in the middle.  The equation can also be simplified a little bit
by pretending that our noses are right up to the screen.  In this case, dist=1.  The final equation then is:
</p><p><code>y_screen = (y_world/z_world) + (y_resolution/2)</code>
</p><p>There is a relationship between the ratios and the viewing angle, as well as scaling the image so that it is resolution-neutral, but we won't really need any of that to fix our road problem.  
If you are curious, try looking at the diagram from the top view:  the angle to the edge of the screen is the field of view and the same relationships hold!

</p><p><u><b>More Math: Adding Field-of-View to 3d Projection</b></u><br>
Now, this is <b>largely unnecessary</b> for most road engine cases. But, it's useful for making projection parameters
resolution-independent, or for objects that need to rotate or for integration with true 3d effects.
</p><p>Let's go back to the original projection formula. The "dist" from the explanation above will now be called "scaling":
</p><p><code>y_screen = (y_world*scaling)/z_world + (y_resolution/2)</code>
</p><p>The idea is that we need to scale all the points on the screen by some value which lets points within a certain
field-of-view (FOV) remain visible. You'll need a constant for the x FOV and a constant for the y FOV.
</p><p>As an example, let's assume we're working in 640x480 resolution and we want a FOV of 60 degrees. We've seen a diagram of
3d projection from the side view. For this, let's look at this
top view of the projection space instead:<br>
<img src="http://www.extentofthejam.com/pseudo/images/TopView.png"><br>
One way to think about the problem is that if an object is at the right edge of our FOV, it needs to appear on the screen
at x=640 (since we're at 640x480). Looking at the chart, our FOV can be split into two right triangles where the angle
of each is fov_angle/2 (a/2). And since our FOV is a cone, an object is on the right edge of its FOV if its x=R*sin(a/2) and
z=R*cos(a/2), where R is any radius value we want. We might as well make R=1. And we need the object to appear at
x_screen=640.
That gives us this (starting from the basic projection formula):
</p><p><code>
	x_screen=640 &nbsp; fov_angle=60 &nbsp; y_world=sin(60/2) &nbsp;  z_world=(60/2) &nbsp;  x_resolution/2=320 &nbsp;  scaling=?<p>
	
x_screen = (y_world*scaling)/z_world + (x_resolution/2)<br>
640 = (sin(30)*scaling/cos(30)) + 320<br>
320 = tan(30)*scaling<br>
320/tan(30) = scaling</p><p>
In generic terms: scaling = (x_resolution/2) / tan(fov_angle/2)
</p></code>
</p><p>
We've replaced a/2 by 30 (half of 60 degrees), recognized that sin/cos = tan, and voila! We should be able to test this
by placing an object at the right edge of the field-of-view, plugging these values into the original projection equation,
and ensuring that the X value winds up as 640. For example, an (x, z) point at (20, 34.64) will wind up at X=640 because 20 is
40*sin(30) and 34.64 is 40*cos(30).
</p><p>
Note that you'll have different FOV values for horizontal (x) and vertical (y) for a standard or widescreen monitor that's in
horizontal orientation.

</p><p><u><b>A More Accurate Road - Using a Z Map</b></u><br>
What we want to do to fix our perspective problem is to precompute a list of distances for each line of the screen.  In short, the problem is how to describe a flat plane in 3d. 
To understand how this works, first think of the 2d equivalent: a line!  To describe a horizontal line in 2d, you would say that for every (x, y) coordinate the y is the same. 
If we extend this into 3d, it becomes a plane: for every x and z distance, the y is the same!  When it comes to a flat horizontal surface, it doesn't matter how far from the camera it is, the
y is always the same.  Likewise, it doesn't matter how much to the left or right the point is, the y will still be the same.

Back to figuring out the distance of each line of the screen:  let's call this a Z Map.  Calculating the Z Map is just a matter of rearranging the 3d 
projection formula to find a Z value for each screen Y!
</p><p>
First, take the equation from the last section:
</p><p>
<code>
Y_screen = (Y_world / Z) + (y_resolution / 2)
</code>
</p><p>
Now, since we're given Y_screen (each line), juggle the equation so that we're finding the Z:
</p><p>
<code>Z = Y_world / (Y_screen - (height_screen / 2))</code>
</p><p>
Y_world is basically the difference between the ground and the camera height, which is going to be negative.  This is the same for each line because, as described in the introductory paragraph,
we're interested in a flat road for the time-being.  
In addition to looking much more accurate and avoiding the "oatmeal effect", it has the advantage that it is easy to compute what the maximum draw distance is.  
</p><p>The road is mapped onto the screen by reading through this buffer:  For each distance, you must figure out what part of the road texture belongs there by noting how many units each stripe or pixel of the texture take up.  
</p><div><p> 
Though we now know the distance of each row of the screen, it may also be useful to cache either the width of the road or scale factor for each line.  The scaling factor would just be the
inverse of the distance, adjusted so that the value is 1 on the line which the player's car graphic spends the most time.  This can then be used to scale sprites which are on a given line, or to
find what the width of the road is.  
</p><a name="curves">
<u>
</u></a></div><h2><a name="curves"><u>Curves and Steering</u></a></h2><a name="curves">
</a>

<p><u><b>Making it Curve</b></u><br>
To curve a road, you just need to change the position of the center-line in a curve shape.  There are a couple ways to do this.  
One way is to do it the way the Z positions were done in "The Simplest Road": with three variables.  That is, starting at the bottom of the screen, the amount that the center of the road shifts left or right per line steadily increases.  Like with the texture reads, we can refer to these variables as the center line (curve) position, the curve velocity, and the curve acceleration.
</p><p>There are some problems with this method though.  One is that S-curves are not very convinient.  Another limitation that going into a turn looks the same as coming out of a turn: The road bends, and simply unbends. <br>
</p><p>To improve the situation, we'll introduce the idea of road segments.  A road segment is a partition which is invisible to the player.
Think of it as an invisible horizontal divide which sets the curve of the road above that line.  At any given time, one of these segment dividers is at the bottom of the screen and another is travelling down at a steady rate towards the bottom of the screen.  Let's call the one at the bottom the base segment, because it sets the initial curve of the road.  Here's how it works:
</p><p>
When we start drawing the road, the first thing we do is look at the base point and set the parameters for drawing accordingly. 
As a turn approaches, the segment line for that would start in the distance and come towards the player kind of like any other road object, except it needs to drift down the screen at a steady rate. That is, for a specific speed that the player is traveling, the segment divider travels down the
screen at so many lines per frame. Or, if you're using a Z-Map, so many z-map entries per frame. If the segment were to 'accelerate' at the player
the way 3d objects on the track do, the road would swing too wildly.
</p><p>
Let's see how this works. Suppose the segment line for a left curve is halfway down the road and the base segment is just a straight road.  As the road is drawn, it doesn't even start curving until it hits the "left curve" segment.  Then the curve of the road begins to change at the rate specified by that point.  As the moving segment hits the bottom of the screen, it becomes the new base segment and what was previously the base segment goes to the top of the road.

</p><p>Shown below are two roads:  One is a straightaway followed by a left turn, and one is a left turn followed by a straightaway.  In both these cases, the segment position is halfway down the
Z Map (or, halfway down the screen).  In other words, the road begins to curve or straighten halfway down the road, and the camera is entering the turn in the first picture and leaving the turn in the second.

</p><p><img src="http://www.extentofthejam.com/pseudo/images/straight-then-left.png"> <img src="http://www.extentofthejam.com/pseudo/images/left-then-straight.png"> 

</p><p>And this is the same technique and same segment position applied to an S-curve:<br>
<img src="http://www.extentofthejam.com/pseudo/images/left-then-right.png">

</p><p>The best way to keep track of the segment position is in terms of where on the Z Map it is.  That is, instead of tying the 
segment position to a screen y position, tie it to a position in the Z Map.  This way, it will still start at the road's
horizon, but will more gracefully be able to handle hills.  Note that on a flat road that the two methods of tracking
the segment position are equivalent.

<!-- One possibility is that Final Lap does its complex track visuals by using more than two segments. -->
</p><p>Let's illustrate this with some code:
</p><p><code>
<span size="-1">
current_x = 160  // Half of a 320 width screen<br>
dx = 0 // Curve amount, constant per segment<br>
ddx = 0 // Curve amount, changes per line<p>
for each line of the screen from the bottom to the top:<br>
&nbsp;&nbsp;if line of screen's Z Map position is below segment.position:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dx = bottom_segment.dx<br>
&nbsp;&nbsp;else if line of screen's Z Map position is above segment.position:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dx = segment.dx<br>
&nbsp;&nbsp;end if<br>
&nbsp;&nbsp;ddx += dx<br>
&nbsp;&nbsp;current_x += ddx<br>
&nbsp;&nbsp;this_line.x = current_x<br>
end for</p><p>
// Move segments<br>
segment_y += constant * speed // Constant makes sure the segment doesn't move too fast<br>
if segment.position &lt; 0 // 0 is nearest<br>
&nbsp;&nbsp;bottom_segment = segment<br>
&nbsp;&nbsp;segment.position = zmap.length - 1 // Send segment position to farthest distance<br>
&nbsp;&nbsp;segment.dx = GetNextDxFromTrack() // Fetch next curve amount from track data<br>
end if</p></span>
</code>

</p><p>One big advantage of doing the curves this way is that if you have a curve followed by a straightaway, you can see the straightaway as you come
out of the curve.  Likewise, if you have a curve followed by a curve in the opposite direction (or even a steeper curve the same direction), you can
see that next piece of track coming around the bend before you hit it.

</p><p>To complete the illusion, you need to have a horizon graphic.  As the curve approaches, the horizon doesn't change (or scrolls only slightly).  Then when the curve is completely drawn, it is assumed that the car is going around it, and the horizon scrolls quickly in the opposite direction that the curve is pointing.  As the curve straightens out again, the background continues to scroll until the curve is complete.  If you are using segments, you can just scroll the horizon according to the settings on the base segment.

</p><p><u><b>General Curve Formula</b></u><br>
There is one interesting observation we can make about the curve technique detailed in the section "The Simplest
Road".  This observation is more mathematical than the above-material, and can be safely skipped as long as your
graphics engine either does not have to be resolution-independent or is using the "3d projected segments" technique
discussed in the chapter on hills.
</p><p>Looking at the curve example using "Z" from the section "The Simplest Road", we can see that the z-position (or x-position) at a given line is the sum of an increasing series of numbers (e.g. 1 + 2 + 3 + 4).  This is
what's called an arithmetic series, or an arithmetic progression.  Instead of 1 + 2 + 3 + 4, a sharper curve can be produced by adding 2 + 4 + 6 + 8, or 2*1 + 2*2 + 2*3 + 2*4.  The "2" in this case is the 
variable segment.dx from above.  It can also be factored out to get 2(1 + 2 + 3 + 4)!  Now all that has to be done is to find a formula to describe 1 + 2 + ... + N, where N is the number of lines making up the curve.
It turns out that the sum of an arithmetic series is equal to N(N+1)/2.  So, the formula can be written as s = A * [ N(N+1)/2 ] where A is the sharpness of the curve and s is the sum.  This can be further modified
to add a starting point, for instance, the center of the road at the bottom of the screen.  If we call this 'x', we now have s = x + A * [ N(N+1)/2 ].
</p><p>We now have a formula to describe our curve.  The question that we want to ask it is, "given a starting point x and N lines of the curve, what should A be to make the curve reach x-position 's' by the end?"  Juggling
the equation to solve for A gets us A = 2(s - x)/[n(n+1)].  This means that the sharpness of a given curve may be 
stored in terms of the endpoint's X position, making the graphics engine resolution-independent.

</p><div><u><b>Perspective-style Steering</b></u><p>
It's much less interesting looking to have a game in which when you
steer, it only moves the car sprite.  So, instead of moving the player's car sprite, you keep it in the center of the screen and move the road-- more importantly, you move the position of the center-line at the front (bottom) of the screen.  Now, you want to assume that the player is going to be looking at the road always, so make the road end at the center of the screen.  You'll need an angle-of-road variable for this.  So, calculate the difference between the center of the screen and the position of the front of the road, and divide by
the height of the road's graphic.  That will give you the amount to
move the center of the road each line.

</p><a name="sprites">
<u>
</u></a></div><h2><a name="sprites"><u>Sprites and Data</u></a></h2><a name="sprites">
</a>

<p><u><b>Placing Objects and Scaling</b></u><br>
Sprites should be drawn back-to-front.  This is sometimes referred to as the Painter's Algorithm.  To do this, you'll have to note in advance where on the screen each object should be drawn, and then draw them in a different step.
The way I do this is as follows:  As I go through the Z Map while drawing the road, I like to also note at that time which line of the screen each sprite
will be associated with.  If you've kept your sprites sorted by Z, this is trivial:  Each time a new Z Map value is read,
check to see whether the next sprite's Z position is closer to the camera than the current Z Map value, or whether it's
equal.  If so, note that sprite's screen Y position as belonging to the current line.  Then check the next sprite the
same way.  Keep doing this until you take a sprite off the list which has a farther Z position than the current one.
</p><p>The X position of the object should be kept track of relative to the center of the road.  The easiest way then to position
the sprite horizontally is just to multiply it by the scaling factor for the current line (inverse of Z) and add that to the road's center.

</p><p><b><u>Storing Track Data</u></b><br>
When I did my first road demo, I stored the level information as a list of events which would happen at specified distances.  The distances are, of course, in terms of texture position units.  The events would consist of commands to begin and stop curves.  Now, as far as I can tell, the speed at which the road starts and stops curving is arbitrary.  The only rule seems to be that it must correlate to the speed of the player vehicle.
</p><p>If, however, you are using a segmented system, you can just use a list of commands.  The distance that each command takes is equivalent to how
quickly the invisible segment line drifts down the screen.  This also frees you up to create a track format which works on a tile map, for representing
somewhat realistic track geography.  That is, each tile could be one segment.  A sharp turn could turn the track 90 degrees, while a more mild turn
would come out at 45 degrees.

</p><p><b><u>Texturing the Road</u></b><br>
Now, you probably would like a real graphical texture on your road
instead of the alternating lines and such that you have at the moment.
There are a couple ways to do this.  A cheap and easy way to do it is this:  You have a couple of textures for the road (for the alternating line effect).
When each horizontal line of the road is drawn, you stretch the texture to fit the width of that line.  Or, if you can't stretch, pick a line out of one of two complete road
bitmaps (ala Outrunners).
</p><p>
If you want the road to look more accurate, make the Z for each line correspond to a row number on a texture graphic.  Voila!  One textured road!
</p><div><p>However, if you only want strips of alternating color, the answer is even simpler-- especially when using fixed point.  For each Z, make one of the bits
represent the shade of the road (dark or light). Then, just draw the appropriate road pattern or colors for that bit.
</p><a name="hills">
<u>
</u></a></div><h2><a name="hills"><u>Hills</u></a></h2><a name="hills">
</a>

<p>
<u><b>Varieties of Hills</b></u><br>
It seems there are a near-infinite number of ways to produce hill effects.  Hill effects have a wide range of geometric accuracy, with some of the
less accurate techniques being more convincing than others.  Here we will examine two possible methods.

</p><p>
<u><b>Faked Hills</b></u>
<br>After much experimentation, I've come up with a flexible method for faking hills which uses little in the way of
calculations.  Additionally, it accurately tracks objects which are beneath the horizon.  It is a scaling
and warping effect which vertically stretches and compresses the road.   It uses the same addition trick
used to draw the curves to generate the curvature of the hill.
</p><p>
Here's how it's done:  First of all, the drawing loop would start at the beginning of the Z Map (nearest) and stop when it gets to the end
(farthest).  If we are to decrement the drawing position each line by 1, the road will be drawn flat.  However, if we decrement
the drawing position each line by 2, doubling lines as we go, the road will be drawn twice as high.  Finally, by varying the
amount we decrement the drawing position each line, we can draw a hill which starts flat and curves upwards.  If the next drawing
position is more than one line from the current drawing position, the current Z Map line is repeated until we get there,
producing a scaling effect. 
</p><p>Downhills are similar:  If the drawing position is incremented instead of decremented, it will move beneath the last line
drawn.  Of course, lines which are below the horizon will not be visible on-screen-- only lines which are 1 or more pixels
above the last line should be drawn.  However, we'll still want to keep track of objects which are beneath the horizon.  To
do this, note the screen Y position of each sprite as the Z Map is traversed. 
It may help to make the Z Map larger
than needed for a flat road.  This way, as the buffer stretches, it won't become too pixellated.

</p><p>Now, we have to move the horizon to convince the player.  I like to 
use a Lotus-style background in which the horizon doesn't just consist 
of just a skyline, but also a distant ground graphic.  When the hill curves
upwards (elongating the view), the horizon should move downwards slightly relative to
the top of the road.  When the hill curves downwards as the camera crests
the hill (shortening the view), the horizon should move upwards.
</p><p>
This is what the effect looks like for a downhill and an uphill-- minus the horizon graphic of course:</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/downhill1.png">
<img src="http://www.extentofthejam.com/pseudo/images/uphill1.png">
</p><p>
<b>Pros</b>
</p><ul>
<li>Inexpensive in terms of calculations: No multiplies or divides necessary
</li><li>Objects on the back side of the hill are tracked
</li><li>The view's angle appears to follow the player over hills
</li></ul>
<b>Cons</b>
<ul>
<li>Accurate 3d geometry is impossible
</li><li>Tweaking is required to create a convincing effect
</li></ul>

<h2><a name="wrapup"><u>Wrap-up: Taking Raster Roads Farther</u></a></h2>
These accumulation-style curve formulas can be used verbatim if you don't need crazy curves or huge, rolling hills. Many games which use these
kinds of tricks scroll the road so fast that even a slight curve can be convincing.
<p>However, you may want to exaggerate
the effect in order to get a more dramatic road. One thing that can be done with any of these curve formulas
is to use high ddx or ddy values, but not allow dx or dy to exceed a sane value. And a user on YouTube, Foppygames,
has discovered another trick for getting more severe curves out of these accumulation formulas: multiply the dx or dy value by the 
z value for each line! This makes the curve more severe in the distance than it is in the foreground, and it creates 
a <a href="http://www.youtube.com/watch?v=mL5yJ5K13po">pretty convincing effect</a>.
</p><p>And, the experimentation doesn't stop there. In fact, the best thing about these engines is that there's no "right" way of doing it. Anything
that creates curves and warpage which is pleasing to the eye is allowed! In my earliest road engines, I used a sinewave lookup table to bend the
road.
</p><p>You can also use multiplication: To shift the road right, you might multiply the x position by, for example, 1.01 each line.
To move it left the same amount, you'd multiply it by 0.99, or 1/1.01 (reciprocal of 1.01). However, armed with the knowledge
that many old processors did not have multiplication or were slow at it, I settled upon using
the accumulation technique because it only uses addition. It seemed the most likley "authentic" way of curving the road.
</p><p>
Some games, like OutRun, even use a simple spline system-- at least judging by the great reverse-engineered open-source C++ port,
<a href="http://reassembler.blogspot.com/p/cannonball-open-source-outrun-engine.html">Cannonball</a>.
</p><p>So, play around and experiment, and see what technique you like best!
</p><div><p>...or, read on for a description of a clever trick that mixes 3d polygons, is nearly as fast, is even more convincing, 
and can be displayed with the same oldschool raster hardware. Intrigued?




</p></div><h2><a name="proj3d"><u>True 3d-Projected Segments</u></a></h2>
<p>
<b><u>3d-Projected Segments vs. Raster Roads</u></b><br>
As nice as raster roads are, they can be made even more impressive by involving a simple form of polygon rendering. This form of rendering
can actually be pulled off using the same limited raster hardware. However, it involves more calculations.
</p><p>
This trick is known to have been used in games such as <b>Road Rash</b> and <b>Test Drive II: The Duel</b>. Here's what it is: The track is
made of polygonal segments. However, rather than moving in full 3d space, it still only moves towards the camera. For curves, the road still
just skews left and right in almost an identical way to the raster road: There is no actual rotation when going around
curves as there would be in a full polygonal engine.
</p><p>Here's a rundown:
</p><ul>
<li>Since we are still faking curves and road angles, that means expensive rotation calculations still won't be needed
</li><li>The road is essentially a strip of quads: each section of the road is attached to the next section.  This means
we can calculate whether part of the road is visible or not based solely on its screen Y position relative to its previous neighbor.
</li><li>The relationship of these quads to one another will never change.  That is, the angle never actually changes, so
the quads are always and automatically sorted by Z.
</li></ul>

<p>
<b><u>The Basic 3d Road</u></b><br>
First, break the road into polygonal quads. Each of these will be called a segment. Just like a segment in a purely raster
road, each segment here still has a curve amount (ddx), and either a hill amount (ddy) or a y-position that determines how high
up it is. Of course, these can also have other attributes as well such as terrain changes.
</p><p>
Pictured below is a segmented road made of very few polygons so we can easily see the boundaries between the segments and how
it affects the curvature of the road:<br>
<img src="http://www.extentofthejam.com/pseudo/images/SegmentedRoad.png">
</p><p>
When rendering, first find the screen y location of each 3d segment by using the screen_y = world_y/z formula.  Or, if division
is too slow,
you could find the height off the ground of a given segment by multiplying the segment's height by the scaling factor for that
line. That could then be subtracted that from a reverse z-map (this map would be: for every z position of a flat road, what is the 
y?) to find
the final position on screen.
</p><p>
Then, you would
linearly interpolate the road widths and texture (if desired) between these heights.  Deciding which 3d segments to draw and which not to can be
determined easily:  From the front of the screen back, a 3d segment whose screen_y is projected as lower than the last-drawn 3d segment would not be shown (however, its sprites may still be visible because they stick up-- keep that in mind).
</p><p>
<u><b>Scrolling the Road</b></u><br>
Now, we also need to learn how to scroll these segments. Move the entire mess of polygons which make up the road towards the camera. As the frontmost segment's polygon passes through the camera, move the entire road back to its starting point so that it loops. 
This is akin to how a scolling 2d tilefield can be made by scrolling up to one tile-worth, and when that is hit all the tiles are
shifted over and new tilemap data is pulled in. In this, we scroll up to one segment-worth, and when that is hit, we move the road
back and pull in new road data.
</p><p>
But there is one last very important detail: Let's say the road is a sharp curve. You might have noticed that as
you go around this polygonal curve that it jitters as you cross the segment boundary and the road is subsequently reset. One obvious thing that is happening to cause this is that
as you traverse a skewed segment, the camera's center relative to the road changes. That is, by the time you get to the end of that segment, the road is no longer centered.
It's as if you're driving on the road at an angle. 
You might be tempted to fix it by moving the road to center it just as objects' x-positions are linearly interpolated.
</p><p>However, this is <b>wrong</b> and does not completely solve our problem: If the road were skewed in a straight line, this would be fine. The problem is that our road curves, so the polygons in the distance still are not lined up! Another way to think about it is this: We are approximating a curve using polygonal segments. We want the shape of the curve to be 
more or less constant even as it scrolls.
</p><p>Jake over at <a href="http://www.codeincomplete.com/">codeincomplete.com</a> has a <a href="http://codeincomplete.com/posts/2012/6/24/javascript_racer_v2_curves/">great solution</a> for this. Instead of changing the x position as the road as you move across the segment, what about changing the
initial dx value from 0 to something that keeps the road in line as you move through the segment? The formula used is this:
</p><p>
<code>
	dx = -percentage_of_segment_traversed * ddx</code>
</p><p>The percentage of the segment has to go from 0 to 1.0 and back as the camera crosses the segments.
</p><p>In mathematical terms, doing this makes the X of the road a function of its Z. In other terms, we're keeping the curve the same shape regardless of how the points which
approximate it scroll. The frontmost segment is "pulled into position" with the rest of the road, which then means that the subsequent
segments' X position are placed correctly. You can see this clearly if you test it with a road made of few polygons. It solves the following problems as the segment is traversed (assuming the curve's shape
does not change):
</p><ul><li>It keeps the center of the road (x position) constant
</li><li>It adjusts dx so that the next segment starts at an appropriate x-location regardless of the scroll position of the road
</li></ul>
<p>This video demonstrates the technique. I've used very few segments and a very sharp curve to demonstrate how this looks. Notice
that as the polygons move towards the player that they carve out a perfect curve shape. This is most apparent if you watch the
right side of the road.
</p><p>
<iframe width="420" height="236" src="http://www.youtube.com/embed/E1PEOg50Zn4?rel=0" frameborder="0" allowfullscreen=""></iframe>


</p><p>
<u><b>Placing Sprites</b></u><br>
The sprites on that 3d segment would still need to be shown and properly cropped, however-- assuming you're making a custom
renderer and not using a Z-buffer.  We can actually draw the sprites as the last step:  If a sprite is on a segment which is completely visible, 
it does not need to be cropped since it sticks straight up from the ground, which is our only polygon.
</p><p>But if a sprite
is on a segment which is either not visible or partially visible, we can easily crop it.  First, find the
top of the sprite.  Then, every line of the sprite will be drawn until it hits the last visible segment's screen Y position.
That is, if there is a segment behind the sprite which is supposed to cover part of it,  you stop drawing the sprite when you hit 
that line. And if the top of the sprite is below the last segment's Y position, the sprite 
won't be visible at all and will be skipped.

</p><p>
<u><b>Variations and Rendering Technologies</b></u><br>
Now, since we're throwing around the term <i>polygon</i>, you may be tempted to think that you need polygonal rendering routines
to pull this off. Using technologies like OpenGL or a simple trapezoidal drawing routine definitely do work. But even tile and
sprite-based 2d hardware are perfectly capable of pulling this off. 
</p><p>
Observe that each road segment's beginning and end are perfectly horizontal. This means that they always start and end on a specific
scanline. Much the way the purely pseudo-3d road is rendered on tile hardware by scrolling the flat road graphic as it's being
drawn, we can do exactly the same with these 3d segments. For further reading, check out the section called <u>Dedicated
	Road Hardware</u>. Though it discusses arcade hardware designed from scratch to draw road effects, the same technique
can be achieved with basic 2d sprite-tile systems through scrolling the road graphic vertically as well as horizontally.

</p><p>
<u><b>Further Reading on 3d-Projected Segments</b></u><br>
Since my mock-up of this specific variation is underdeveloped, I will point you to <a href="http://codeincomplete.com/posts/2012/6/23/javascript_racer_v1_straight/">Code inComplete's amazing tutorial</a> if you're interested in further details on this technique.
</p><p>
<b>Pros</b>
</p><ul>
<li>Real 3d geometry can be used for the hills, adding greatly to the amount of detail possible
</li><li>The system is more consistent: Terrain and road width changes don't need to be done using a separate technique
</li></ul>
<b>Cons</b>
<ul>
	<li>There are more calculations involved
	</li><li>A decent number of segments must be used or the road will look jagged and polygonal
</li></ul>


<h2><u>Enhancements</u></h2>
<p><u><b>Multiple Roads</b></u><br>
Most arcade racing games handle multiple roads at a time.  Though the most obvious reason to do this is to have more than one road on the screen at a time,
other effects can be achieved as well.  For example, OutRun uses more than one road to form its six lane freeway.  This lets the game widen and narrow
the road easily, as well as convincingly fork.  They do this by overlapping the two roads and giving one drawing priority over the other.  Here is the
familiar beginning of OutRun both with and without two roads (look to the right of the bushes):
</p><p><img src="http://www.extentofthejam.com/pseudo/images/or-road1.png"> <img src="http://www.extentofthejam.com/pseudo/images/or-noroad1.png">
</p><p>And, even more dramatic, below is the freeway after the two roads are overlapped to form six lanes, both with and without the second road:
</p><p><a name="enhancements"><img src="http://www.extentofthejam.com/pseudo/images/or-road2.png"> <img src="http://www.extentofthejam.com/pseudo/images/or-noroad2.png">

</a><a name="related">
<u>
</u></a></p><h2><a name="related"><u>Related Effects</u></a></h2><a name="related">
<p><u><b>Endless Checkerboard</b></u><br>
The endless checkerboard in the arcade game Space Harrier is just a variation on the road technique.  Like
a road, the game contains graphics of lines coming at the player in perspective.  In fact, Space Harrier
uses the same hardware as Hang-On.
</p><p>
 Pictured below is the Space Harrier checkerboard effect with and without the palette changes.  To turn this
into a checkerboard, all that has to be done is to flip the color palette every few lines.  Think of it as analogous to the 
light and dark strips on a road.
</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/sh-pal.png"> <img src="http://www.extentofthejam.com/pseudo/images/sh-nopal.png"><br>
 
</p></a><p><a name="related">
So, how then does it scroll left and right?  This is just a variation on perspective-style steering:  As the
player moves to the left or right, the ground graphic is skewed.  After a few pixels have scrolled past, the ground
"resets" or "wraps" its position.  This is how it appears to scroll endlessly to the left and right.
</a><a name="hw">
<u>
</u></a></p><h2><a name="hw"><u>Case Studies</u></a></h2><a name="hw">
<p>
<u><b>Dedicated Road Hardware</b></u><br>
Although there are many ways to render roads, it is interesting to note that many arcade games used hardware designed for this specific purpose.
These chips automate the basics of road drawing, but not the road calculations themselves.  As a typical example, I will take Sega's OutRun road
chip, used in games such as Super Hang-on, Outrun and Space Harrier.
</p><p>First off, the chip has its own graphics memory.  What is stored in this road ROM is nearly a perspective view of the road, given that it is flat,
centered, and not curving.
Then, for each line of the screen, the programmer specifies roughly which line of the perspective graphic to draw there.
Each line also has an X offset (for curving the road) and each line can also have a different color palette (to draw road markings and simulate movement). 
To show an example, here are some images taken from Sega racing game road graphics side-by-side with the road as seen in-game 
(special thanks to Charles MacDonald for his road viewing application):

</p><p>The first thing you might notice is that the road graphics are much higher resolution than the in-game graphics.  In these particular
games, the road is up to 512x256 resolution while the game's display resolution is only 320x224.  This gives the graphics engine plenty
of graphic to play with, which cuts down on the amount of jaggies.  Another thing which might pop out at you is that the perspective of
the road stored in the ROM is completely different from the perspective shown in-game.  This is because the graphic in the ROM merely
stores what the road might look like for various road widths.  It is the job of the program to select the correct lines out of this
large graphic for each line of the screen.
</p><p>The hardware supports two
roads at a time, and so you can assign priority to the left or right road.  This is for the parts of the game in which the road branches,
or when there is a center divider between lanes of traffic.
</p><p>For you ROM hackers out there, check out MAME's src/mame/video/segaic16.c and src/mame/video/taitoic.c files for examples of road chips.
Note that the Sega road graphics are stored in a 2-bit planar format, with the center of the graphic able to sport a fourth color (this
is the yellow line shown in the graphics above).  
<!-- <P>I mentioned that only the drawing is taken care of by the road chip, but not the technique.  A dramatic illustration of this is the difference
between Chase H.Q. and Top Speed.  Both of these games run on the same hardware with the same road chip, but Chase H.Q. is much more convincing.
Top Speed's hills for example look to be less accurate, and there are sprite clipping issues at times.  Also see MAME's src/mame/video/taitoic.c file
for a more detailed explanation of this specific road chip. -->



</p><p>
<u><b>Enduro</b></u><br>
Enduro is a remarkable game.  Released in 1983 for an incredibly
underpowered 70's gaming console, Enduro still manages to produce a
convincing road effect complete with changing weather and day-night
cycles.  On top of that, it manages to be an exciting game even 
25 years after its release!

</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/enduro-2.png" width="50%"><br>Screenshot of Enduro
</p><p>As you can see here, Enduro looks a little different from other
road engines we've seen so far.  Immediately apparant is that the
road is only drawn in outline:  The terrain to the sides of the road are not drawn
in a different color from the pavement.  There are also no roadside obstacles.  
Once you start to play Enduro, you might also notice that the road doesn't move in
perspective.  Instead, the player car sprite and road both shift left and right 
to give the illusion of steering.

</p><p>In order to better understand why Enduro looks the way it does, 
let's take a peek at the Atari 2600's limitations.  The Atari 2600 was designed
primarily to play Combat-like games (tank games) and Pong-like games.  So,
it was capable of displaying: two sprites, two squares representing missiles 
for each player, a square representing a ball, and a very blocky background.  And that's it.  

</p><p>But what's notable about the Atari's video hardware is that it's essentially
one-dimensional:  the software must update the graphics for each scanline itself.  For
example, to show a sprite, the programmer has to upload a new line of
graphics to display at the beginning of each scanline.  To draw the ball
object, the programmer would turn on the ball when the TV's beam got to the right
line, and turn off the ball when the beam got to a line where the ball should 
no longer be visible.

</p><p>This leaves an important side-effect:  a solid vertical line can be drawn down the screen by turning on
the ball or missiles and then never turning them off!  If the programmer moves
these objects each line, diagonal lines may be drawn.  

</p><p>Now, back to the task at hand.  We could draw the road using the background
blocks, but the resolution is much too low to be effective.  What Atari driving
games did instead was use the two missile or ball graphic objects to draw the left
and right sides of the road, much in the same way they can be used to draw
lines.  Enduro in particular uses the first player's missile sprite and the
ball sprite in order to draw the left and right sides.  Pole Position, on the other hand, uses
both missile sprites for the sides of the road and then uses the ball sprite
to draw a dotted line down the center.

</p><p><br>
<img src="http://www.extentofthejam.com/pseudo/images/polepsn.png" width="50%">
<br>Screenshot of Pole Position on 2600 for comparison

</p><p>One thing I haven't discussed is how you move objects per-line on an Atari 2600.  The
Atari's graphic chip has a facility called HMOVE (horizontal move).  This allows the
programmer to set up moves each line for all the different objects very easily.  All the
programmer has to do is set how many pixels to move for the various objects, and then call
HMOVE and voila-- they all move according to what was set!

</p><p>Enduro exploits this in order to draw curves.  In short, what Enduro does create a
table in memory of how the HMOVE values of the left and right sides vary as the screen
is drawn.  This uses almost half of the Atari 2600's available memory.  Since the Atari's
memory is so tiny, this value is only read every 4 lines.  There is a different table for
the left and the right sides of the road. 

</p><p>When the road is straight, the array for the right side of the road is all 8's.  The
HMOVE only uses the upper 4 bits, so 8 loaded into HMOVE wouldn't move the sides
of the road at all.  The lower 4 bits are used for a crude form
of fixed point.

</p><p>As an example, here's what a curve looks like in memory as it approaches (the
horizon is the end of the array):<br>
<code><span size="-1">
08,08,08,08,08,08,0a,0a,0b,0c,0e,0d,0e,0e,0f,10,13,11,12,13,14,17,16,17
</span></code>

</p><p>And the next frame:<br>
<code><span size="-1">
08,08,09,09,0a,0a,0b,0b,0c,0d,0d,0e,0f,0f,10,11,12,12,13,14,15,16,17,18
</span></code>

</p><p>Note that the higher curve values progressively write over the lower values, shifting
down towards the front of the screen to provide the illusion that the curve is coming towards
the player.  And what does
Enduro do with this data?  Here's some of the code used to write out the curve for the
right side of the road
</p><p>
For each scanline of the road:<br>
<code><span size="-1">
LDA $be      ; Load what's in address $be<br>
AND #$0f     ; Blow away the upper 4 bits (the bits HMOVE uses)<br>
ADC $e4,x    ; Add the value from the curve table (X is how far towards the front of the screen we are)<br>
STA $be      ; Save the value again (so we can load it again next scanline like we did above)<br>
STA HMBL     ; Also shove it into the Horizontal Motion - Ball register<br></span>
</code>

</p><p>
So what's this doing?  Well, $be is a counter for the curve amount which increments.  When it's loaded, the upper 4 bits are tossed
overboard, leaving a range of 0 to 16 ($0-F).  Then, the curve table entry for that particular scanline is loaded and added in.
Finally, it's stored back to the counter and also loaded into the horizontal move register for the ball object (the right side of the road).

</p><p>
This does a few things.  First, it only results in the sides of the road moving every two lines when the road is straight:  If the array is
all 8s and $be contains 0 on the first line, the next line will contain 8 (the upper nybble is still 0).  The next line after that will
contain $10.  But when $10 is loaded back into the register A on the next scanline, the upper nybble is discarded leaving 0 again!  This
causes the counter to flip between $10 and 8.  Since the HMOVE values only use the upper 4 bytes, the line moves 0 positions or 1 positions
alternating.

</p><p>
OK, but what if the array is all 9s instead of 8s?  Here's what happens:  On the first scanline, 9 is stored into the ball HMOVE register and
written back to the counter.  The next line, 9 is again added to the value from the table making $12 (18 decimal).  This will move the ball
by 1 (upper 4 bits is 1).  On the line after that, the upper nybble is discarded leaving 2.  Adding 9 from the table makes $B.  Let's look
at one more scanline.  B is loaded.  There is no upper nybble.  Adding 9 makes $14 (20).  

</p><p>The sequence described above is 09,12,0b,14.  This is still only going to cause the ball to move every other line for these 4 lines.
But, eventually the lower nybble is going to become high enough that it will cause the routine to move the ball sprite left two lines
in a row.  The pattern will then wrap, but after a few more lines, the side of the road will move two lines in a row again.  In essence, this
is a simple and blazing fast form of fixed point math.

</p><p>There is another hurdle in implementing a road system on such limited hardware:
positioning sprites.  On more sophisticated systems, sprites can be positioned horizontally on the
road as a percentage of the road width.  But this requires either fixed point or floating point
multiplication, both of which are extremely slow on a 6502.  In contrast, Enduro only has three possible
positions for the cars, which saves some calculation.



</p><p>
<u><b>Road Rash</b></u><br>
Road Rash and 3do Road Rash both have amazing graphics engines.  The original Genesis version of the game pulled off
a relatively accurate 3d sensation on the Genesis' 7.25mhz 68000 processor, complete with realtime scaling of the
roadside objects.  The 3do follow-up is no less fascinating, as it turns out to be a mixture of 3d and pseudo
technique artistically combined to give the player an amazing sensation of speed.
</p><p>
As I mentioned above, both the Road Rash and 3do Road Rash engines are a mixture of 3d and pseudo 3d trickery.  They use
a technique similar to the one described in the "Realistic Hills Using 3d-Projected Segments" chapter in which the
hills are in 3d space, but the road's curves are not.
Road Rash's curves use the same method described in this
article, and each road segment has its own DDX or "x acceleration" value.  Each segment also has a height
which is relative to the last segment's height.  There are roughly 50 segments
on-screen at once.
</p><p>But where the 3do Road Rash is really interesting is that the programmers added warping which increases the sensation of speed that the player experiences:
Objects far from the camera move more slowly, and objects near the camera move
more quickly.
</p><p>
The 3do Road Rash also adds polygonal 
roadside objects whose X coordinates are still relative to the road.  These are
used to create hills, buildings, and other relatively complex scenery.  
This uses a fair amount of data, so the geometry and textures both are
streamed from
the disc as the track is traversed.

</p>
<u><b>S.T.U.N. Runner: Arcade vs. Lynx</b></u><br>
S.T.U.N. Runner was a marvelous game when it debuted at arcades in 1989. It made great use of fully 3d filled polygon technology, 
allowing the player to take control of a futuristic race craft barreling down twisting, turning corridors at breakneck speed. 

Not long after,
I saw a version for the Atari Lynx. The Atari Lynx was a handheld system which came out about the time of the original Game Boy. Like the
Game Boy, it had a 4MHz 8-bit processor. So, the port was horrible, right? Well, check out the footage below:
<p>
<iframe width="420" height="236" src="http://www.youtube.com/embed/_7tv5gtjun8?rel=0" frameborder="0" allowfullscreen=""></iframe>


</p><p>Actually, the port was fantastic! It came close to perfectly capturing what made the arcade game so thrilling. With Game Boy-era portable hardware,
how on earth was it done? 
</p><p>It turns out that the Lynx had one important weapon in its arsenal: hardware scaling. But this isn't a huge help in rendering
polygonal graphics. It turns out that it wasn't just the Lynx that had some tricks up its sleeve: The author who ported it had some tricks of
his own.

</p><p>To recreate the speed of the arcade machine, the Lynx version of S.T.U.N. Runner resorted to a pseudo-3d road engine. The polygon slices that make up the tunnel walls are
actually sprites.  These are essentially trackside objects which are glued to the road, much like the roadside objects in any other pseudo
3d racing game, and are drawn using the painter's algorithm (back-to-front). This convincingly creates the illusion of polygon graphics while still playing to the strengths of the hardware. And to save
space on the cartridge, one sprite wasn't a full ring of the tunnel graphic. Not only does this save on the number of blank, transparent pixels, but it's arranged
so that horizontal flipping of the graphics hardware could be used.

</p><p>One interesting problem that the author had to solve was when the tunnel branches. You can also see this in the video above. The 
branching tunnel is actually a big sprite which
scales at the player. After the player has chosen their new path, the split graphic goes away. According to the author, sometimes you can
spot vehicles driving right through this sprite!

</p></a><p><a name="hw">If you're interested in reading more, the conversation on AtariAge with the original author can be found </a><a href="http://atariage.com/forums/topic/194231-lynx-stun-runner-3d-techniques/">here</a>.



</p><p><a name="hw">
<u><b>Roads on the Commodore 64</b></u><br>
This information is courtesy of </a><a href="http://caspianit.co.uk/index.cfm">Simon Nicol</a>, who figured out a great technique for fast roads
on the C64.
</p><p>
First, some background:  On many console systems, a pseudo-3d road can be done by drawing a straight road with tiles and scrolling per-line to make it appear to curve.  However, this turned
out to be too slow for a full-framerate game on the Commodore 64.  
</p><p>Simon's engine instead uses C64's bitmap mode and uses a fast-fill algorithm.  His fast-fill algorithm uses self-modifying code to speed up draws:  Each line is a series of per-pixel
stores which specify an address in video memory.  
At the point though that the color has to change, the code is altered.  The store command is turned into a load command, and what was the address for the store is turned into 
the literal number of the new color.
</p><p>One major advantage of this technique is that sprite multiplexing techniques to show more than eight sprites on the screen can still be used.  In Simon's words:
"Offsetting the horizontal scroll to get a stable raster effect would involve manipulating register $D011.  
The raster IRQ at $D012 would flicker badly otherwise depending on the number of sprites 
on that particular raster line.  To have any sort of smooth display would involve locking up the processor to get the timing just right, or by not using the screen graphics and just changing the 
border colour.  This which would be solid and flicker free, but there wouldn't be road visible on the screen because it would have to be switched off. 
These smooth, per-line border colour changes were used 
chasing the raster down the screen, and it could also be used to 'hold off' where the top of the screen could be displayed. It was called $D011 hold-off or sometimes FLD for flexible line distancing
(the technique used to eliminate VIC's bad lines).

</p><p>
<u><b>Other Engines</b></u><br>
</p><p>
<b>Power Drift</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/pdrift_a.png"><img src="http://www.extentofthejam.com/pseudo/images/pdrift_b.png"><br>
Power Drift is interesting because it is one of the few games I know of which use sprite-based 3d.  Each chunk of the track is a small sprite blob,
and the flyby is Sega's way of showing it off.  I don't have proof, but I believe games such as F1 Exhaust Heat and RadMobile use a similar system.
It is also worth noting that the deluxe cabinet of Power Drift tilted almost 45 degrees, making it somewhat important to wear that seatbelt for once.
Screenshots from system16.com.
</p><p>
<b>Racin' Force</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/rforce_a.jpg"><img src="http://www.extentofthejam.com/pseudo/images/rforce_b.jpg"><br>
Racin' Force was reverse-engineered by the intrepid Charles MacDonald.  Racin' Force runs on the Konami GX board, which features a daughterboard 
with a voxel engine capability.  This hardware is based upon older hardware which could only draw a SNES mode 7-like floormap.  It was extended
to do a heightmap through this clever technique:  It projects not just the tilemap onto a flat 3d plane, but also the height information for
each pixel onto its own separate 3d plane.  Then, for each pixel of the screen, it looks up the height information on the projected heightmap, and extrudes each pixel
upwards as necessary.  Screenshots from system16.com.
</p><h2><u>Further Exploration</u></h2>
Here are some sites which may be useful for learning more about pseudo 3d roads:<br>
<ul>
	<li><a href="http://reassembler.blogspot.com/p/cannonball-open-source-outrun-engine.html">Cannonball: Open source OutRun port</a>
	</li><li><a href="http://www.extentofthejam.com/pseudo/codeincomplete.com/posts/2012/6/23/javascript_racer_v1_straight/">Code inComplete JavaScript Racer</a>
</li></ul>



<a name="stuff">
<u>
</u></a><h2><a name="stuff"><u>Code Stuff</u></a></h2><a name="stuff">
</a>
<b><u>Formulas and Tips</u></b><p>
<b>3d Projection</b><br>
<code>
	y_screen = (y_world*scale / z) + (screen_height &gt;&gt; 1)<br>
</code>
or:<br>
<code>
z = (y_world*scale) / (y_screen - (screen_height &gt;&gt; 1))<br>
</code><br>
This formula takes the x or y world coordinates of an object, the z of the object, and returns the x or y
pixel location.  Or, alternately, given the world and screen coordinates, returns the z location.
</p><p>
The scale determines the field-of-view (FOV), and can be found by:
</p><p><code>
	scale_x = x_resolution/tan(x_angle/2)<br>
	scale_y = y_resolution/tan(y_angle/2)
</code></p><p>
<b>Fast Linear Interpolation</b><br>
<code>
  o(x) = y1 + ((d * (y2-y1)) &gt;&gt; 16)
</code><br>
This assumes that all the numbers are in 16.16 fixed point.  <b>y1</b> and <b>y2</b> are the two values
to interpolate between, and <b>d</b> is the 16-bit fractional distance between the two points.  For example,
if <b>d</b>=$7fff, that would be halfway between the two values.  This is useful
for finding where between two segments a value is.
</p><p>

<b>Fixed Point Arithmetic</b><br>
Floating point is very expensive for old systems which did not have specialized math hardware.  Instead, a 
system called fixed point was used.  This reserved a certain number of bits for the fractional part of the number.
For a test case, say you only reserve one bit for the fractional amount, leaving seven bits for the whole
number amounts.   That fraction bit would represent one half (because
a half plus a half equals a whole).  To obtain the whole number value stored in that byte, the number is shifted
right once.  This can be expanded to use any number of bits for the fractional and whole portions of the number.
</p><div><p>Fixed point multiplcation is trickier than addition.  In this operation, you would multiply the two numbers and
then shift right by however many bits are reserved for fractions.  Due to overflow, sometimes you may need to shift
before multiplication instead of after.  See "Fast Linear Interpolation" for an example of fixed point multiplcation.
</p><p>

<b>Point Rotation</b><br>
<code>
x' = x*cos(a) - y*sin(a)<br>
y' = x*sin(a) + y*cos(a)<br>
</code>
Mentioned briefly in the tutorial as being an expensive operation, here is the basic point rotation
formula.  As you can see, it's at least 2 table lookups, 4 multiplications, and two additions, but the sine and cosine values can be reused for each point.
Rotating for the purpose of hills would mean rotating the Z and Y coordinates, not the X and Y
coordinates.  To find the derivation of this formula, look up <i>Rotation of Axes</i>.
</p><p>

<b>Avoid Division</b><br>
Instead of dividing by the z of an object in the standard projection formulas, you can take advantage of some
properties of the road to speed up calculations.  Say you have a 3d segment z position and a y position, and you
want to find which line of the screen it belongs on.  First, read through the z-map until you get to the 
3d segment's z position.  Then, multiply the height of the segment by the corresponding scaling value.
The result is the number of pixels above the road that the segment belongs. 

</p><p>
<b>Use Z as Scaling Value</b><br>
Scaling routines work by slowing or speeding up the speed at which 
a draw routine reads through graphics data.  For example, if you were
to set the read speed to half, this would draw a sprite double the size.
This is because for each time a pixel is drawn, the read position in the
sprite data is only incremented by half, causing the read position to only
increment by a whole number every two pixels.
</p></div><div><p>Usually, a scaling routine has parameters like x, y, and scaling factor.
But since a scaling factor is just 1/z, we can just reuse the Z value of that
sprite!  We will still need the scaling factor though to determine the
boundaries of the sprite so that we can keep it centered as it scales.


</p><a name="glossary">
<u>
</u></a></div><h2><a name="glossary"><u>Glossary</u></a></h2><a name="glossary">
</a>
<p><b>Bad Line</b> - In the C64's VIC II graphics chip, at the first pixel of every background tile, the VIC takes over the processor to pull in more data such as colors.  Since there are fewer cycles left for a program to do computations, these are refered to as bad lines
</p><p><b>Height Map</b> - A height map is an array of height values.  In a
polygon or voxel landscape engine, this might be a 2d array (think of a 
landscape viewed from the top).
However, in a road engine, a height map would only need to be one-dimensional
(think of a landscape viewed from the side).
</p><p><b>Indexed Color Mode</b> - Older systems which feature few colors on the screen at a time are generally
in indexed color modes.  Some of the most common indexed color modes are the 256-color VGA modes.  In these
modes, each pixel is represented by a byte.  Each byte stores an index value from 0 to 255.  When the screen
is drawn, the index number for each pixel is looked up in the palette.  Each entry in the palette can be one of
VGA's 262,144 possible colors.  In summary, even though only 256 colors can be on screen at a time, the user can
choose each color from a much larger palette.  
</p><p><b>Linear Interpolation</b> - The process of obtaining in-between values from a data set by drawing lines between
the points
</p><p><b>Painter's Algorithm</b> - The <i>Painter's Algorithm</i> is the practice
of drawing overlapping objects from far to near.  This ensures that closer
objects always appear on top of farther ones.
</p><p><b>Planar Graphics Mode</b> - A <i>Planar graphics mode</i> is one in which an N-bit image is made up of N 1-bit images
which are combined to produce the final image.
This is opposed to most graphics modes, sometimes referred to as <i>chunky</i>, in which an N-bit image is made up of
N-bit pixel values.
</p><p><b>Raster Effect</b> - A <i>raster effect</i> is a graphical trick which takes advantage of the scanline-based nature of
most computer, or raster, displays.
</p><p><b>Scaling Factor</b> - The reciprocal of Z.  This gives you the amount by which to scale an object at a given Z distance.
</p><p><b>Segment (Road)</b> - I am using the term <i>segment</i> to mean a position below which the road acts one way, and above a
different way.  For example, the segment could divide a left turn on the lower half of the screen from a right turn on
the upper half.  As the segment makes its way towards the player, the road will appear to snake left then right.
</p><p><b>Segment, 3d (Road)</b> - I am using the term <i>3d segment</i> to mean a horizontal line which has both a Z distance
and a world Y height.  Unlike a vertex, which could be a 3d point, a 3d segment would be a 3d line with the left and right
X-axis endpoints at positive and negative infinity.
</p><p><b>Voxel</b> - A 3d pixel.  Raycast/landscape voxel engines were popularized in the game Commanche: Maximum Overkill.
</p><div><p><b>Z Map</b> - A lookup table which associates each line of the screen with a Z distance.


</p><a name="gallery">
<u></u></a></div><h2><a name="gallery"><u>The Gallery</u></a></h2><a name="gallery">
</a>
Here is a collection of screenshots that show various ways to do unorthodox road engines.  Take a look!
<p><b>Cisco Heat</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/cischeat.png">
<br>The hills in this game come at you like a solid wall.  The turns are also very exaggerated.  The engine seems quite flexible and deals with multiple roads simultaneously, as well as being able to show the height of one road relative to another.
</p><p><b>Pole Position</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/polepos.png">
<br>This is the first smoothly running pseudo game I remember.  Not extremely impressive today graphically.
</p><p><b>Hydra</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/hydra.gif">
<br>This is another Atari shoot em up along the lines of Roadblasters.  It features a very nice jumping effect in which the road layer's perspective tips, causing the closest objects to fall off the screen.  It also nicely projects objects of varying distances above the ground.
</p><p><b>Outrunners</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/outrunner2.png">
<br>This sequel to Outrun is a prime example of rollercoaster-like hills in a racing game.  Everything is quite exaggerated in this, and the result is one of the most blinding fast yet nicely controllable racing games ever.
</p><p><b>Road Rash</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/rash1.jpg">
<br>In the 32-bit generation version of Road Rash, everything was textured and buildings were cleverly drawn next to the roadside, leaving some people with the impression that it was a purely polygonal game running fast on the 3do.  However, the way objects whip around the corners, buildings warp, and that you can't go backwards would seem to give away that it's not really a polygon engine.  The sharp lines on the pavement do hint at some sort of projected segment system though.  The tracks have a lot of detail and variety.
The 16-bit generation Road Rash was also no slouch, also featuring a flexible engine with a tiny bit of faked texuring (but was slow).</p><p><b>Turbo</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/turbo.png">
<br>This predates Pole Position and also features hills and bridges.  The drawback?  There are no transitions from hill to bridge to curve.  This used analog graphics scaling hardware.
</p><p><b>Spy Hunter II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/spyhunt2.gif">
<br>I don't know what the makers of Spy Hunter II were thinking.  Nice idea, bad execution.  The road effects seem very similar to Turbo's with a little more in the way of transitions.
</p><p><b>Pitstop II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/pitstop2.gif">
<br>This technique is so quick that on the lowly Commodore 64, people were able to pull off a split screen racing game.
</p><p><b>Enduro</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/enduro.gif">
<br>Enduro demonstrates the use of pseudo 3d on the Atari 2600.
</p><p><b>Enduro Racer</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/enduroracer.png">
<br>Not to be confused with Enduro, this was a sort of 3d Excitebike-like game.  The screenshot shows off the hill technique.  Hills are rather sharp, flexible, but generally don't affect the horizon's position, so I'm guessing interpolated points.
</p><p><b>Lotus</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/lotus.gif">
<br>Lotus comes through with the perfectly curved hill technique.  One interesting thing is that Lotus will draw the road's top below the horizon and then fill the gap with a solid color to imply a downhill.
</p><p><b>Test Drive II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/tdrive2.gif">
<br>I'm not sure exactly what to make of Test Drive 2's graphics.  While clearly not a polygon racer, it tries very hard to realistically represent a variety of roads.  The game is similar to the Need for Speed series but predates it by several years.
</p><p><b>Speed Buggy</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/speedbuggy.png">
<br>When you steer in this, in addition to shifting the perspective, the road also slides left and right a little.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How We Centralized and Structured Error Handling in Golang (138 pts)]]></title>
            <link>https://olivernguyen.io/w/namespace.error/</link>
            <guid>42447762</guid>
            <pubDate>Wed, 18 Dec 2024 03:04:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olivernguyen.io/w/namespace.error/">https://olivernguyen.io/w/namespace.error/</a>, See on <a href="https://news.ycombinator.com/item?id=42447762">Hacker News</a></p>
Couldn't get https://olivernguyen.io/w/namespace.error/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ergo Chat – A modern IRC server written in Go (243 pts)]]></title>
            <link>https://github.com/ergochat/ergo</link>
            <guid>42447071</guid>
            <pubDate>Wed, 18 Dec 2024 00:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ergochat/ergo">https://github.com/ergochat/ergo</a>, See on <a href="https://news.ycombinator.com/item?id=42447071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ergochat/ergo/blob/master/docs/logo.png"><img src="https://github.com/ergochat/ergo/raw/master/docs/logo.png" alt="Ergo logo"></a></p>
<p dir="auto">Ergo (formerly known as Oragono) is a modern IRC server written in Go. Its core design principles are:</p>
<ul dir="auto">
<li>Being simple to set up and use</li>
<li>Combining the features of an ircd, a services framework, and a bouncer (integrated account management, history storage, and bouncer functionality)</li>
<li>Bleeding-edge <a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a>, suitable for use as an IRCv3 reference implementation</li>
<li>High customizability via a rehashable (i.e., reloadable at runtime) YAML config</li>
</ul>
<p dir="auto">Ergo is a fork of the <a href="https://github.com/jlatt/ergonomadic">Ergonomadic</a> IRC daemon &lt;3</p>
<hr>
<p dir="auto"><a href="https://goreportcard.com/report/github.com/ergochat/ergo" rel="nofollow"><img src="https://camo.githubusercontent.com/715dca1ef407679efd095c0f7e6bb84af1a4f3578777ba0e6fee876767360a3b/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6572676f636861742f6572676f" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/ergochat/ergo"></a>
<a href="https://github.com/ergochat/ergo/actions/workflows/build.yml"><img src="https://github.com/ergochat/ergo/actions/workflows/build.yml/badge.svg" alt="build"></a>
<a href="https://github.com/ergochat/ergo/releases/latest"><img src="https://camo.githubusercontent.com/a7f0ce32dfcb5a49fb515fc9f9c17fbf695f17c1f9453ae88ded4f7be1e45a32/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f6164732d6c617465737425323072656c656173652d677265656e2e737667" alt="Download Latest Release" data-canonical-src="https://img.shields.io/badge/downloads-latest%20release-green.svg"></a>
<a href="https://crowdin.com/project/ergochat" rel="nofollow"><img src="https://camo.githubusercontent.com/1b32d58517ce51950670a25e3273d77513044ac8c502648e76d0afe7e1b8b7d2/68747470733a2f2f64333232637174353834626f346f2e636c6f756466726f6e742e6e65742f6572676f636861742f6c6f63616c697a65642e737667" alt="Crowdin" data-canonical-src="https://d322cqt584bo4o.cloudfront.net/ergochat/localized.svg"></a></p>
<p dir="auto">If you want to take a look at a running Ergo instance or test some client code, feel free to play with <a href="https://testnet.ergo.chat/" rel="nofollow">testnet.ergo.chat</a> (TLS on port 6697 or plaintext on port 6667).</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>integrated services: NickServ for user accounts, ChanServ for channel registration, and HostServ for vanity hosts</li>
<li>bouncer-like features: storing and replaying history, allowing multiple clients to use the same nickname</li>
<li>native TLS/SSL support, including support for client certificates</li>
<li><a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a></li>
<li><a href="https://yaml.org/" rel="nofollow">yaml</a> configuration</li>
<li>updating server config and TLS certificates on-the-fly (rehashing)</li>
<li>SASL authentication</li>
<li><a href="https://github.com/ergochat/ergo-ldap">LDAP support</a></li>
<li>supports <a href="https://crowdin.com/project/ergochat" rel="nofollow">multiple languages</a> (you can also set a default language for your network)</li>
<li>optional support for UTF-8 nick and channel names with RFC 8265 (PRECIS)</li>
<li>advanced security and privacy features (support for requiring SASL for all logins, cloaking IPs, and running as a Tor hidden service)</li>
<li>an extensible privilege system for IRC operators</li>
<li>ident lookups for usernames</li>
<li>automated client connection limits</li>
<li>passwords stored with <a href="https://godoc.org/golang.org/x/crypto" rel="nofollow">bcrypt</a></li>
<li><code>UBAN</code>, a unified ban system that can target IPs, networks, masks, and registered accounts (<code>KLINE</code> and <code>DLINE</code> are also supported)</li>
<li>a focus on developing with <a href="https://ergo.chat/specs.html" rel="nofollow">specifications</a></li>
</ul>
<p dir="auto">For more detailed information on Ergo's functionality, see:</p>
<ul dir="auto">
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md">MANUAL.md, the operator manual</a></li>
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/USERGUIDE.md">USERGUIDE.md, the guide for end users</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start guide</h2><a id="user-content-quick-start-guide" aria-label="Permalink: Quick start guide" href="#quick-start-guide"></a></p>
<p dir="auto">Download the latest release from this page: <a href="https://github.com/ergochat/ergo/releases/latest">https://github.com/ergochat/ergo/releases/latest</a></p>
<p dir="auto">Extract it into a folder, then run the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cp default.yaml ircd.yaml
vim ircd.yaml  # modify the config file to your liking
./ergo mkcerts
./ergo run     # server should be ready to go!"><pre>cp default.yaml ircd.yaml
vim ircd.yaml  <span><span>#</span> modify the config file to your liking</span>
./ergo mkcerts
./ergo run     <span><span>#</span> server should be ready to go!</span></pre></div>
<p dir="auto"><strong>Note:</strong> See the <a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md#productionizing-with-systemd">productionizing guide in our manual</a> for recommendations on how to run a production network, including obtaining valid TLS certificates.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Platform Packages</h3><a id="user-content-platform-packages" aria-label="Permalink: Platform Packages" href="#platform-packages"></a></p>
<p dir="auto">Some platforms/distros also have Ergo packages maintained for them:</p>
<ul dir="auto">
<li>Arch Linux <a href="https://aur.archlinux.org/packages/ergochat/" rel="nofollow">AUR</a> - Maintained by <a href="https://github.com/vith">Jason Papakostas (@vith)</a>.</li>
<li><a href="https://packages.gentoo.org/packages/net-irc/ergo" rel="nofollow">Gentoo Linux</a> - Maintained by <a href="https://github.com/thesamesam">Sam James (@thesamesam)</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Docker</h3><a id="user-content-using-docker" aria-label="Permalink: Using Docker" href="#using-docker"></a></p>
<p dir="auto">A Dockerfile and example docker-compose recipe are available in the <code>distrib/docker</code> directory. Ergo is automatically published
to the GitHub Container Registry at <a href="https://ghcr.io/ergochat/ergo" rel="nofollow">ghcr.io/ergochat/ergo</a>. For more information, see the distrib/docker
<a href="https://github.com/ergochat/ergo/blob/master/distrib/docker/README.md">README file</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Source</h3><a id="user-content-from-source" aria-label="Permalink: From Source" href="#from-source"></a></p>
<p dir="auto">You can also clone this repository and build from source. Typical deployments should use the <code>stable</code> branch, which points to the latest stable release. In general, <code>stable</code> should coincide with the latest published tag that is not designated as a beta or release candidate (for example, <code>v2.7.0-rc1</code> was an unstable release candidate and <code>v2.7.0</code> was the corresponding stable release), so you can also identify the latest stable release tag on the <a href="https://github.com/ergochat/ergo/releases">releases page</a> and build that.</p>
<p dir="auto">The <code>master</code> branch is not recommended for production use since it may contain bugs, and because the forwards compatibility guarantees for the config file and the database that apply to releases do not apply to master. That is to say, running master may result in changes to your database that end up being incompatible with future versions of Ergo.</p>
<p dir="auto">For information on contributing to Ergo, see <a href="https://github.com/ergochat/ergo/blob/master/DEVELOPING.md">DEVELOPING.md</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Building</h4><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">You'll need an <a href="https://golang.org/dl/" rel="nofollow">up-to-date distribution of the Go language for your OS and architecture</a>. Once that's installed (check the output of <code>go version</code>), just check out your desired branch or tag and run <code>make</code>. This will produce an executable binary named <code>ergo</code> in the base directory of the project. (Ergo vendors all its dependencies, so you will not need to fetch any dependencies remotely.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">The default config file <a href="https://github.com/ergochat/ergo/blob/master/default.yaml"><code>default.yaml</code></a> helps walk you through what each option means and changes.</p>
<p dir="auto">You can use the <code>--conf</code> parameter when launching Ergo to control where it looks for the config file. For instance: <code>ergo run --conf /path/to/ircd.yaml</code>. The configuration file also stores where the log, database, certificate, and other files are opened. Normally, all these files use relative paths, but you can change them to be absolute (such as <code>/var/log/ircd.log</code>) when running Ergo as a service.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Logs</h3><a id="user-content-logs" aria-label="Permalink: Logs" href="#logs"></a></p>
<p dir="auto">By default, logs go to stderr only. They can be configured to go to a file, or you can use systemd to direct the stderr to the system journal (see the manual for details). The configuration format of logs is designed to be easily pluggable, and is inspired by the logging config provided by InspIRCd.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passwords</h3><a id="user-content-passwords" aria-label="Permalink: Passwords" href="#passwords"></a></p>
<p dir="auto">Passwords (for both <code>PASS</code> and oper logins) are stored using bcrypt. To generate encrypted strings for use in the config, use the <code>genpasswd</code> subcommand as such:</p>

<p dir="auto">With this, you receive a blob of text which you can plug into your configuration file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nickname and channel registration</h3><a id="user-content-nickname-and-channel-registration" aria-label="Permalink: Nickname and channel registration" href="#nickname-and-channel-registration"></a></p>
<p dir="auto">Ergo relies heavily on user accounts to enable its distinctive features (such as allowing multiple clients per nickname). As a user, you can register your current nickname as an account using <code>/msg NickServ register &lt;password&gt;</code>. Once you have done so, you should <a href="https://libera.chat/guides/sasl" rel="nofollow">enable SASL in your clients</a>, ensuring that you will be automatically logged into your account on each connection. This will prevent <a href="https://github.com/ergochat/ergo/blob/master/docs/MANUAL.md#nick-equals-account">problems claiming your registered nickname</a>.</p>
<p dir="auto">Once you have registered your nickname, you can use it to register channels:</p>
<ol dir="auto">
<li>Join the channel with <code>/join #channel</code></li>
<li>Register the channel with <code>/CS REGISTER #channel</code></li>
</ol>
<p dir="auto">After this, your channel will remember the fact that you're the owner, the topic, and any modes set on it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Jeremy Latt (2012-2014)</li>
<li>Edmund Huber (2014-2015)</li>
<li>Daniel Oaks (2016-present)</li>
<li>Shivaram Lingamneni (2017-present)</li>
<li><a href="https://github.com/ergochat/ergo/blob/master/CHANGELOG.md">Many other contributors and friends of the project &lt;3</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The XOR Texture (2004) (195 pts)]]></title>
            <link>https://lodev.org/cgtutor/xortexture.html</link>
            <guid>42447053</guid>
            <pubDate>Wed, 18 Dec 2024 00:43:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lodev.org/cgtutor/xortexture.html">https://lodev.org/cgtutor/xortexture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42447053">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Lode's Computer Graphics Tutorial</h2>

<h2>Table of Contents</h2>
<ul>
<li><a href="#Introduction_">Introduction</a></li>
<li><a href="#The_XOR_Texture">The XOR Texture</a></li>
<li><a href="#Colors">Colors</a></li>
<li><a href="#AND_and_OR">AND and OR</a></li>
<li><a href="#Conclusion">Conclusion</a><br></li>
</ul>
<a href="https://lodev.org/cgtutor/index.html">Back to index</a><br>
<h2><a name="Introduction_" id="Introduction_"></a>Introduction<br></h2>
The XOR texture is a very easy to generate texture that looks fine.
However, it's so overused that it's not a good choice to use in in
a demo or intro release. It isn't useful for games either, unless
you want some fancy floor tiles. What it's useful for, is for
testing a texture mapper you just wrote, in case you want to
quickly test out a pattern without having to load an image file or
write more complex texture generation code.<p>

This is an extremely small article, but the XOR Texture just
couldn't be left out in a series of texture generation
articles.</p><h2><a name="The_XOR_Texture" id="The_XOR_Texture"></a>The XOR
Texture</h2>
The XOR texture is simply generated by xor-ing the x and y
coordinate of the current pixel. The '^' operator in C++ is the XOR
operator.<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = x ^ y;
    pset(x, y, ColorRGB(c, c, c));
  }

  redraw();
  sleep();
  return 0;
}</span></pre>
</div>
</center>
<br>
That's it, if you run it, you see the XOR texture:<p>

<img alt="The XOR Texture" src="https://lodev.org/cgtutor/images/xortexture.gif"></p><p>

There are 3 things you should keep in mind though:</p><p>

<b>1)</b> The sizes of the texture should be a power of two, if
they aren't, the texture doesn't look as good:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturesize.gif"></p><p>

<b>2)</b> Color component values range from 0 to 255. The maximum
color value generated by the XOR operation is the same as the
dimensions of the texture if its size is a power of two. So if the
size of your XOR pattern is smaller than 256, for example only 64,
it'll be too dark (image on the left). Multiply the color with 4 to
make it bright again (image on the right):</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturedark.gif"> <img alt="" src="https://lodev.org/cgtutor/images/xortexturebright.gif"></p><p>

<b>3)</b> On the other hand, if the size is larger than 256, for
example 512, you have to make sure the color is limited to a
maximum value of 256. You can either modulo divide it through 256,
but then it isn't a real XOR pattern anymore. Better is to divide
it through 2. In any case, using a XOR texture larger than 256x256
doesn't increase the quality because there aren't enough distinct
color values, unless you're using a color mode that allows more
bits per channel. But who'd want to generate a 1024x1024 XOR
texture anyway.</p><p>

The XOR operator takes the binary values of both integers, and does
a binary XOR on every two corresponding bits. XOR or eXclusive OR
returns 1 if both bits are different, and returns 0 if both bits
are the same: "Bit a is 1 OR bit 2 is 1, but <i>not</i> both". In
other words, it applies the following truth table to every two
corresponding bits:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
This is done on every bit of the integer, creating the many
possible resulting values.<p>

For example, 5 XOR 13 = 8, because in binary 0101 XOR 1101 =
1000.</p><h2><a name="Colors" id="Colors"></a>Colors</h2>
You can also try the XOR texture with different colors, by using
different value for R, G and B. For example:<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color.r = 255 - c;
    color.g = c;
    color.b = c % 128;
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturecolor.gif"><p>

You can even use the xor value as hue for the HSVtoRGB
function...</p><center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color = HSVtoRGB(ColorHSV(c, 255, 255));
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturehsv.gif"><h2><a name="AND_and_OR" id="AND_and_OR"></a>AND and OR</h2>
The AND and the OR operator also generate a similar texture.<p>

The XOR operator returns 1 if both bits are different:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
The AND operator, only returns 1 if both bits are 1 (bit a AND bit
b are true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>AND</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The OR operator returns 1 if any or both of the bits are 1 (bit a
OR bit b is true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>OR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The AND operator is denoted '&amp;' in C++, and the OR operator
'|', replace the '^' operator with those to use the new operators.
Here's the result of XOR, AND and OR respectively:<p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexture.gif"> <img alt="" src="https://lodev.org/cgtutor/images/andtexture.gif">
<img alt="" src="https://lodev.org/cgtutor/images/ortexture.gif"></p><p>

It makes sense that the AND texture is darker, because it returns 1
only in a single case. The OR texture is brighter, because it
returns 1 very often. The sum of the XOR texture and the AND
texture is the OR texture.</p><h2><a name="Conclusion" id="Conclusion"></a>Conclusion</h2>
It was shown how easy it is to create a XOR texture, which makes
the XOR texture useful to test if a texture renderer is working.
However, it's not suitable for applications such as art or
games.<p>

Here, the XOR pattern was used as a 3D texture (x ^ y ^ z) to test
if a planet texture renderer was working correctly:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xorplanet.gif"></p><hr>
Last edited: 2004
<p>
Copyright (c) 2004-2007 by Lode Vandevenne. All rights reserved.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ad: An Adaptable Text Editor (117 pts)]]></title>
            <link>https://github.com/sminez/ad</link>
            <guid>42447012</guid>
            <pubDate>Wed, 18 Dec 2024 00:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sminez/ad">https://github.com/sminez/ad</a>, See on <a href="https://news.ycombinator.com/item?id=42447012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ad :: an adaptable text editor</h2><a id="user-content-ad--an-adaptable-text-editor" aria-label="Permalink: ad :: an adaptable text editor" href="#ad--an-adaptable-text-editor"></a></p>
<p dir="auto"><a href="https://github.com/sminez/ad/actions?query=workflow%3ABuild"><img src="https://github.com/sminez/ad/workflows/Build/badge.svg" alt="Build"></a> <a href="https://crates.io/crates/ad-editor" rel="nofollow"><img src="https://camo.githubusercontent.com/b85e95578041b718fb667b6a6ba2eb44d11b18a44ea76d66d5a25140515e4619/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f61642d656469746f72" alt="crates.io version" data-canonical-src="https://img.shields.io/crates/v/ad-editor"></a> <a href="https://docs.rs/ad-editor" rel="nofollow"><img src="https://camo.githubusercontent.com/159a3447fa97d7e50e8d27dc7765f54fcd62b826c6e97a1d064fd2f1db655e81/68747470733a2f2f696d672e736869656c64732e696f2f646f637372732f61642d656469746f723f6c6f676f3d72757374" alt="docs.rs" data-canonical-src="https://img.shields.io/docsrs/ad-editor?logo=rust"></a></p>
<p dir="auto"><code>ad</code> (pronounced A.D.) is an attempt at combining a modal editing interface of likes of <code>vi</code>
and <code>kakoune</code> with the approach to extensibility of Plan9's <code>Acme</code>. Inside of <code>ad</code> text is
something you can execute as well as edit.</p>
<p dir="auto">It is primarily intended as playground for experimenting with implementing various text editor
features and currently is not at all optimised or feature complete enough for use as your main
text editor.</p>
<p dir="auto">That said, if this sounds like something you might find interesting then please to take a
look and see what you think! For now there isn't a whole lot of user facing documentation so
you will need to read through the source code to learn about what is and is not implemented.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Status</h2><a id="user-content-project-status" aria-label="Permalink: Project Status" href="#project-status"></a></p>
<p dir="auto"><code>ad</code> is stable enough and feature complete enough that you can try it out and see what you
think. That said, there is currently very little documentation and there are likely to be
a variety of bugs and crashes in places that I've not managed to fully track down yet. If
you do try it out and spot something that is broken, please raise an issue on GitHub so I
can look into it.</p>
<p dir="auto">You have been warned!</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=jb2pAi5hLUg" rel="nofollow"><img src="https://camo.githubusercontent.com/b24964ea9f911479b4354f1637a37d47c5c3ea0c09022100d1c80d870df4be29/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f6a623270416935684c55672f302e6a7067" alt="tour" data-canonical-src="https://img.youtube.com/vi/jb2pAi5hLUg/0.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The design of ad</h2><a id="user-content-the-design-of-ad" aria-label="Permalink: The design of ad" href="#the-design-of-ad"></a></p>
<p dir="auto"><code>ad</code> is aiming to be a hybrid of the pieces of various editors that I find most useful:</p>
<ul dir="auto">
<li>vim style modal editing to allow for convenient key bindings</li>
<li>convenient text navigation and selection from vim/kakoune</li>
<li>mini-buffer based user defined minor modes from emacs</li>
<li>sam/acme style editing commands for larger editing actions</li>
<li>acme style extension through exposing editor state and functionality for
external client programs.</li>
<li>support for mouse based navigation and selection but not requiring that as the main
way of using the editor like in acme. That's fine for desktop but most of the time
I'm working with a laptop which makes that far too clunky.</li>
</ul>
<p dir="auto"><code>ad</code> is <em>not</em> trying to replace vim (or kakoune, or emacs) in terms of being a massively
hackable editor. Rather it is trying to follow the philosophy of acme in being an
integrat<strong>ing</strong> development environment (rather than integrat<strong>ed</strong>). By which I mean
that the aim is to provide a comfortable editing environment to work in that supports
direct interaction with external tools and programs from the outside rather than pulling
everything <strong>in</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Repo structure</h2><a id="user-content-repo-structure" aria-label="Permalink: Repo structure" href="#repo-structure"></a></p>
<p dir="auto">Given the (arguably questionable) goal of implementing everything from scratch, there is a fair amount
of functionality included in <code>ad</code> which in turn is split out into a number of modules within the crate.
For now, I'm not structuring things as individual crates but that may change in future.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Modules</h3><a id="user-content-modules" aria-label="Permalink: Modules" href="#modules"></a></p>
<p dir="auto"><em>This is a non-exhaustive list of some of the more interesting parts of the internals of <code>ad</code></em></p>
<ul dir="auto">
<li><strong>buffer/internal</strong>: a <a href="https://en.wikipedia.org/wiki/Gap_buffer" rel="nofollow">gap buffer</a> implementation for the
internal state of a Buffer.</li>
<li><strong>dot</strong>: manipulation of the current selection in a given buffer (including vim-like motions)</li>
<li><strong>exec</strong>: minimal implementation of the core of the <a href="http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf" rel="nofollow">sam editing language</a></li>
<li><strong>fsys</strong>: virtual filesystem interface to the editor state in the style of <a href="http://acme.cat-v.org/" rel="nofollow">acme</a></li>
<li><strong>ninep</strong>: <a href="http://9p.cat-v.org/" rel="nofollow">9p protocol</a> implementation that backs the fsys module
<ul dir="auto">
<li>Now moved out to its own crate with source code available <a href="https://github.com/sminez/ad/crates/ninep">here</a>.</li>
</ul>
</li>
<li><strong>regex</strong>: custom regex engine that is able to work on character streams. This is nowhere near as performant as
the <a href="https://github.com/rust-lang/regex">regex crate</a> (obviously) but it allows for some flexability in tinkering
with the exec command language.</li>
<li><strong>trie</strong>: <a href="https://en.wikipedia.org/wiki/Trie" rel="nofollow">trie</a> data structure for handling sequence based keybindings</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">I've used <a href="https://www.vim.org/" rel="nofollow">vim</a> for years now (more recently <a href="https://neovim.io/" rel="nofollow">neovim</a> and <a href="https://github.com/mawww/kakoune">kakoune</a>) and I really love the
core editor itself. A while back I discovered <a href="https://en.wikipedia.org/wiki/Acme_(text_editor)" rel="nofollow">acme</a> through a fantastic <a href="https://www.youtube.com/watch?v=dP1xVpMPn8M" rel="nofollow">screencast</a> from
Russ Cox, showing how you could interface with it via plan filesystem protocol, allowing you to run
pretty much whatever you want inside of the editor (in any language) so long as you can interact with
that protocol. <em>That</em> I absolutely love, but the lack of modal editing and requirement to use the mouse
when I'm sat with my laptop is proving hard to get used to, so I set about looking at how to port
over some of the acme ideas into vim (namely the load/execute semantics via the plumber and the
idea of exposing the editor state in a really simple way to client programs).</p>
<p dir="auto">Turns out, vim has a <em>lot</em> more built into it that I was previously aware (and I've been hacking on
my vimrc for years now) which was more than a little scary. What I want is a small, usable editor
that I can hack on.</p>
<p dir="auto">So...How hard could it be?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simplicity</h2><a id="user-content-simplicity" aria-label="Permalink: Simplicity" href="#simplicity"></a></p>
<p dir="auto">For things that are going to be core parts of the experience (bindings, per-filetype configuration)
I'm just going to hard code stuff. I'll try to do it in a way that makes it easy to update / change
but the whole thing will be a lot easier to write if there isn't too much config parsing.</p>
<p dir="auto">That said, the more I work on this, the more I wonder if it might be interesting to structure <code>ad</code>
in the same way as <a href="https://github.com/sminez/penrose">penrose</a> and have it as a library for writing
your own text editor? That would require some restructuring but might be interesting to explore...</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Goals</h2><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<ul dir="auto">
<li>Simple modal editing to the extent that I use VIM</li>
<li>Sed/Sam style edit commands</li>
<li>Acme style use of external commands rather than an embedded language:
<ul dir="auto">
<li>Exposing current buffer / window state to external programs</li>
<li>Exposing events to external programs</li>
<li>Accepting events from other programs</li>
</ul>
</li>
<li>Virtual buffers for command output that can be hidden</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sam style structural regular expressions</h2><a id="user-content-sam-style-structural-regular-expressions" aria-label="Permalink: Sam style structural regular expressions" href="#sam-style-structural-regular-expressions"></a></p>
<p dir="auto">One aim of this project is to provide an implementation of "Structural Regular Expressions" as first
presented (to my knowledge) in the <a href="http://doc.cat-v.org/plan_9/4th_edition/papers/sam/" rel="nofollow">Sam text editor</a> from plan9 by Rob Pike. <a href="http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf" rel="nofollow">This tutorial</a>
from Pike covers the command language of Sam which I am using as a starting point for the command
language for <code>ad</code>. So far I'm not aiming for a perfect match with the functionality of Sam or Acme
but I <em>am</em> looking to make use of the pieces that feel particularly useful. As the project develops
I may well end up pulling in more but for now I'm happy to have a decent starting point for an
implementation of the structural regular expression engine.</p>
<p dir="auto">There is still a fair amount to do but so far the idea is to allow for repeated narrowing and looping
over sub-matches within a buffer or file loaded from disk. (A streaming interface working over stdin
is coming but I need to have a think about how best to buffer the input and track partial matches in
the regex engine to avoid slowing things down too much or requiring the engine to buffer and collect
<em>all</em> of its standard input before matching).</p>
<p dir="auto">The current engine can be used via the <code>-e</code> and <code>-f</code> flags to run <code>ad</code> in headless mode, but hooking
things into the interactive editor directly should be coming soon. For now, here is a demo of some
simple functionality of the engine:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat examples/exec_scripts/result_fns.ad
,                              # set dot to be the full input (not required as this is the default)
x/fn@*?\{/                     # select all Rust function signatures up to the opening brace
g/->.*Result.*\{/              # keep those that return some form of Result
x/fn (\w+)@*?-> (.*?) \{/      # extract the function name and return type from the signature
p/($FILENAME) $1 returns $2/   # print them along with the filename using a template


$ ad -f examples/exec_scripts/result_fns.ad src/**/*.rs | head
(src/buffer/buffers.rs) open_or_focus returns io::Result<()>
(src/buffer/dot/cur.rs) fmt returns fmt::Result
(src/buffer/dot/mod.rs) fmt returns fmt::Result
(src/buffer/dot/range.rs) fmt returns fmt::Result
(src/buffer/edit.rs) fmt returns fmt::Result
(src/buffer/mod.rs) new_from_canonical_file_path returns io::Result<Self>
(src/exec/parse.rs) execute returns Result<(usize, usize), Error>
(src/exec/parse.rs) step returns Result<(usize, usize), Error>
(src/exec/parse.rs) try_parse returns Result<Self, Error>
(src/exec/parse.rs) validate returns Result<(), Error>"><pre>$ cat examples/exec_scripts/result_fns.ad
,                              <span><span>#</span> set dot to be the full input (not required as this is the default)</span>
x/fn@<span>*?</span><span>\{</span>/                     <span><span>#</span> select all Rust function signatures up to the opening brace</span>
g/-<span>&gt;</span>.<span>*</span>Result.<span>*</span><span>\{</span>/              <span><span>#</span> keep those that return some form of Result</span>
x/fn (<span>\w</span>+)@<span>*?</span>-<span>&gt;</span> (.<span>*?</span>) <span>\{</span>/      <span><span>#</span> extract the function name and return type from the signature</span>
p/(<span>$FILENAME</span>) <span>$1</span> returns <span>$2</span>/   <span><span>#</span> print them along with the filename using a template</span>


$ ad -f examples/exec_scripts/result_fns.ad src/<span>**</span>/<span>*</span>.rs <span>|</span> head
(src/buffer/buffers.rs) open_or_focus returns <span>io::Result&lt;</span>()<span>&gt;</span>
(src/buffer/dot/cur.rs) fmt returns fmt::Result
(src/buffer/dot/mod.rs) fmt returns fmt::Result
(src/buffer/dot/range.rs) fmt returns fmt::Result
(src/buffer/edit.rs) fmt returns fmt::Result
(src/buffer/mod.rs) new_from_canonical_file_path returns io::Result<span>&lt;</span>Self<span>&gt;</span>
(src/exec/parse.rs) execute returns Result<span><span>&lt;(</span>usize, usize<span>)</span></span>, Error<span>&gt;</span>
(src/exec/parse.rs) step returns Result<span><span>&lt;(</span>usize, usize<span>)</span></span>, Error<span>&gt;</span>
(src/exec/parse.rs) try_parse returns Result<span>&lt;</span>Self, Error<span>&gt;</span>
(src/exec/parse.rs) validate returns <span>Result&lt;</span>(), Error<span>&gt;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Built the Saturn V (2017) (119 pts)]]></title>
            <link>https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/</link>
            <guid>42446889</guid>
            <pubDate>Wed, 18 Dec 2024 00:17:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/">https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/</a>, See on <a href="https://news.ycombinator.com/item?id=42446889">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing Ruby's JSON, Part 1 (185 pts)]]></title>
            <link>https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html</link>
            <guid>42446846</guid>
            <pubDate>Wed, 18 Dec 2024 00:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html">https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html</a>, See on <a href="https://news.ycombinator.com/item?id=42446846">Hacker News</a></p>
Couldn't get https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Design Token-Based UI Architecture (149 pts)]]></title>
            <link>https://martinfowler.com/articles/design-token-based-ui-architecture.html</link>
            <guid>42445834</guid>
            <pubDate>Tue, 17 Dec 2024 22:04:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martinfowler.com/articles/design-token-based-ui-architecture.html">https://martinfowler.com/articles/design-token-based-ui-architecture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Design tokens, or “tokens” are fundamental design decisions represented
    as data. They are the foundational building blocks of design systems.</p>

<p>Since the release of the <a href="https://second-editors-draft.tr.designtokens.org/format/">second editor’s
    draft</a> of the
    design token specification in 2022 and the <a href="https://www.w3.org/community/design-tokens/2022/06/14/call-to-implement-the-second-editors-draft-and-share-feedback/">call for tool
    makers</a>
    to start implementing and providing feedback, the landscape of design token
    tools has evolved rapidly. Tools like code generators, documentation
    systems, and UI design software are now better equipped to support design
    tokens, underscoring their growing importance in modern UI architecture.</p>

<p>In this article, I'll explain what design tokens are, when they are useful and how to apply
    them effectively. We'll focus on key architectural decisions that are often difficult to change later, including:</p>

<ol>
<li>How to organize design tokens in layers to balance scalability, maintainability and developer experience.</li>

<li>Whether all tokens should be made available to product teams or just a subset.</li>

<li>How to automate the distribution process of tokens across teams.</li>
</ol>

<section id="RoleOfDesignTokens">
<h2>Role of design tokens</h2>

<p>Around 2017, I was involved in a large project that used the <a href="https://martinfowler.com/articles/micro-frontends.html">Micro
      Frontend
      Architecture</a> to
      scale development teams. In this setup, different teams were responsible
      for different parts of the user interface, which could be even on the same
      page. Each team could deploy its micro-frontend independently.</p>

<p>There were various cases where components would be displayed on top of
      each other (such as dialogs or toasts appearing on top of content areas),
      which were not part of the same micro frontend. Teams used the CSS
      property <code>z-index</code> to control the stacking order, often relying on magic
      numbers—arbitrary values that weren’t documented or standardized. This approach
      did not scale as the project grew. It led to issues that took effort to
      fix, as cross-team collaboration was needed.</p>

<p>The issue was eventually addressed with design tokens and I think makes
      a good example to introduce the concept. The respective token file might
      have looked similar to this:</p>

<pre>{
  "z-index": {
    "$type": "number",
    "default": {
      "$value": 1
    },
    "sticky": {
      "$value": 100
    },
    "navigation": {
      "$value": 200
    },
    "spinner": {
      "$value": 300
    },
    "toast": {
      "$value": 400
    },
    "modal": {
      "$value": 500
    }
  }
}
</pre>

<p>The design tokens above represent the set of <code>z-index</code> values that can
      be used in the application and the name gives developers a good idea of
      where to use them. A token file like this can be integrated into the
      designers’ workflow and also be used to generate code, in a format that
      each team requires. For example, in this case, the token file might have
      been used to generate CSS or SCSS variables:</p>

<div>
<div>
<p>css
</p>

<pre>  :root {
    --z-index-default: 1;
    --z-index-sticky: 100;
    --z-index-navigation: 200;
    --z-index-spinner: 300;
    --z-index-toast: 400;
    --z-index-modal: 500;
  }</pre>
</div>

<div>
<p>scss
</p>

<pre>  
  $z-index-default: 1;
  $z-index-sticky: 100;
  $z-index-navigation: 200;
  $z-index-spinner: 300;
  $z-index-toast: 400;
  $z-index-modal: 500;</pre>
</div>
</div>

<section id="WhatAreDesignTokens">
<h3>What are design tokens?</h3>

<p>Salesforce <a href="https://www.smashingmagazine.com/2019/11/smashing-podcast-episode-3/">originally introduced design tokens</a> to streamline design
      updates to multiple
      platforms.</p>

<p>The Design Tokens Community Group <a href="https://second-editors-draft.tr.designtokens.org/format/#introduction">describes design tokens</a> as “a
      methodology for expressing design decisions in a platform-agnostic way so
      that they can be shared across different <b>disciplines</b>, <b>tools</b>, and
      <b>technologies</b></p>

<p>Let’s break this down:</p>

<ul>
<li><b>Cross-Disciplinary Collaboration:</b> Design tokens act as a common language
        that aligns designers, developers, product managers, and other disciplines. By
        offering a single source of truth for design decisions, they ensure that
        everyone involved in the product life cycle is on the same page, leading to more
        efficient workflows.</li>

<li><b>Tool integration:</b> Design tokens can be integrated into various design
        and development tools, including UI design software, token editors, translation
        tools (code generators), and documentation systems. This enables design updates
        to be quickly reflected in the code base and are synchronized across teams.</li>

<li><b>Technology adaptability:</b> Design tokens can be translated into different
        technologies like CSS, SASS, and JavaScript for the web, and even used on native
        platforms like Android and iOS. This flexibility enables design consistency
        across a variety of platforms and devices.</li>
</ul>
</section>
</section>

<section id="EstablishingASingleSourceOfTruth">
<h2>Establishing a single source of truth</h2>

<p>A key benefit of design tokens is their ability to serve as a single
      source of truth for both design and engineering teams. This ensures that
      multiple products or services maintain visual and functional
      consistency.</p>

<p>A <a href="https://tr.designtokens.org/format/#translation-tool">translation
      tool</a> takes one or
      more design token files as input and generates platform-specific code as
      output. Some translation tools can also produce documentation for the
      design tokens in the form of HTML. At the time of writing, popular
      translation tools include ﻿<a href="https://styledictionary.com/">Style
      Dictionary</a>,
      ﻿<a href="https://github.com/salesforce-ux/theo">Theo</a>, ﻿<a href="https://diez.org/">Diez</a>
      or ﻿<a href="https://specifyapp.com/">Specify App</a>.</p>




</section>

<section id="AutomatedDesignTokenDistribution">
<h2>Automated design token distribution</h2>

<p>In this section, we’ll explore how to automate the distribution of
      design tokens to product teams.</p>

<p>Let’s assume our goal is to provide teams with updated, tech-specific
      design tokens immediately after a designer makes a change. To achieve
      this, we can automate the translation and distribution process using a
      deployment pipeline for design tokens. Besides platform-specific code
      artifacts (like CSS for the web, XML for Android etc.), the pipeline might
      also deploy the documentation for the design tokens.</p>

<p>One crucial requirement is keeping design tokens under version control.
      Thankfully, plugins for popular design tools like Figma already integrate
      with Git providers like GitHub. It's considered best practice to use the
      Git repository as the single source of truth for design tokens—not the
      design tool itself. However, this requires the plugin to support syncing
      both ways between the repository and the design tool, which not all
      plugins do. As of now, Tokens Studio is a plugin that offers this
      bidirectional syncing. For detailed guidance on integrating Tokens Studio
      with different Git providers, please refer to their
      <a href="https://docs.tokens.studio/token-storage-and-sync/sync-provider-overview">documentation</a>.
      The tool enables you to configure a target branch and supports a
      trunk-based as well as a pull-request-based workflow.</p>

<p>Once the tokens are under version control, we can set up a deployment
      pipeline to build and deploy the artifacts needed by the product teams,
      which include platform-specific source code and documentation. The source
      code is typically packaged as a library and distributed via an artifact
      registry. This approach gives product teams control over the upgrade
      cycle. They can adopt updated styles by simply updating their
      dependencies. These updates may also be applied indirectly through updates of component
      libraries that use the token-based styles.</p>

<div id="token-distribution.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/token-distribution.svg"></p><p>Figure 2: Automated design token distribution</p>
</div>



<p>This overall setup has allowed teams at Thoughtworks to roll out
      smaller design changes across multiple front-ends and teams in a single
      day.</p>

<section id="FullyAutomatedPipeline">
<h3>Fully automated pipeline</h3>

<p>The most straightforward way to design the pipeline would be a
          fully automated trunk-based workflow. In this setup, all changes
          pushed to the main branch will be immediately deployed as long as they
          pass the automated quality gates.</p>

<p>Such a pipeline might consist of the following jobs:</p>

<ol>
<li><b>Check:</b> Validate the design token files using a design token validator
            or a JSON validator.</li>

<li><b>Build:</b> Use a translation tool like <a href="https://styledictionary.com/">Style
            Dictionary</a> to convert design token files into
            platform-specific formats. This job might also build the docs using the
            translation tool or by integrating a dedicated documentation tool.</li>

<li><b>Test:</b> This job is highly dependent on the testing strategy. Although
            some tests can be done using the design token file directly (like checking the
            color contrast), a common approach is to test the generated code using a
            documentation tool such as Storybook. Storybook has excellent <a href="https://storybook.js.org/docs/writing-tests">test
            support</a> for visual regression
            tests, accessibility tests, interaction tests, and other test types.</li>

<li><b>Publish:</b> Publish updated tokens to a package manager (for example,
            npm). The release process and versioning can be fully automated with a package
            publishing tool that is based on <a href="https://www.conventionalcommits.org/">Conventional
            Commits</a> like
            <a href="https://github.com/semantic-release/semantic-release">semantic-release</a>.
            semantic-release also allows the deployment of packages to multiple platforms.
            The publish job might also deploy documentation for the design tokens.</li>

<li><b>Notify:</b> Inform teams of the new token version via email or chat, so
            that they can update their dependencies.</li>
</ol>

<div id="pipeline-fully-automated.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-fully-automated.svg"></p><p>Figure 3: Fully automated deployment pipeline</p>
</div>


</section>

<section id="PipelineIncludingManualApproval">
<h3>Pipeline including manual approval</h3>

<p>Sometimes fully automated quality gates are not sufficient. If a
          manual review is required before publishing, a common approach is to
          deploy an updated version of the documentation with the latest design
          token to a preview environment (a temporary environment).</p>

<p>If a tool like Storybook is used, this preview might contain not
          only the design tokens but also show them integrated with the
          components used in the application.</p>

<p>An approval process can be implemented via a pull-request workflow.
          Or, it can be a manual approval / deployment step in the pipeline.</p>

<div id="pipeline-incl-review.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-incl-review.svg"></p><p>Figure 4: Deployment pipeline with manual approval</p>
</div>


</section>
</section>

<section id="OrganizingTokensInLayers">
<h2>Organizing tokens in layers</h2>

<p>As discussed earlier, design tokens represent design decisions as data.
      However, not all decisions operate at the same level of detail. Instead,
      ideally, general design decisions guide more specific ones. Organizing
      tokens (or design decisions) into layers allows designers to make
      decisions at the right level of abstraction, supporting consistency and
      scalability.</p>

<p>For instance, making individual color choices for every new component isn’t practical.
      Instead, it’s more efficient to define a foundational color palette and then
      decide how and where those colors are applied. This approach reduces the
      number of decisions while maintaining a consistent look and feel.</p>

<p>There are three key types of design decisions for which design tokens
      are used. They build on top of one another:</p>

<ul>
<li><b>What</b> design options are available to use?</li>

<li><b>How</b> are those styles applied across the user interface?</li>

<li><b>Where</b> exactly are those styles applied (in which components)?</li>
</ul>

<p>There are various names for these three types of tokens (as usual,
      naming is the hard part). In this article, we’ll use the terms <a href="https://samiamdesigns.substack.com/p/a-new-approach-to-naming-design-tokens">proposed
      by Samantha
      Gordashko</a>:
      option tokens, decision tokens and component tokens.</p>

<p>Let’s use our color example to illustrate how design tokens can
      answer the three questions above.</p>

<section id="OptionTokensDefiningWhatDesignOptionsAreProvided">
<h3>Option tokens: defining what design options are provided</h3>

<p><i>Option tokens</i> (also called <i>primitive tokens</i>, <i>base tokens</i>, <i>core
      tokens</i>, <i>foundation tokens</i> or <i>reference tokens</i>) define <b>what</b>
      styles can be used in the application. They define things like color
      palettes, spacing/sizing scales or font families. Not all of them are
      necessarily used in the application, but they present reasonable
      options.</p>

<p>Using our example, let’s assume we have a color palette with 9 shades for each color,
      ranging from very light to highly saturated. Below, we define the blue tones and grey tones as option-tokens:</p>

<pre>{
  "color": {
    "$type": "color",
    "options": {
      "blue-100": {"$value": "#e0f2ff"},
      "blue-200": {"$value": "#cae8ff"},
      "blue-300": {"$value": "#b5deff"},
      "blue-400": {"$value": "#96cefd"},
      "blue-500": {"$value": "#78bbfa"},
      "blue-600": {"$value": "#59a7f6"},
      "blue-700": {"$value": "#3892f3"},
      "blue-800": {"$value": "#147af3"},
      "blue-900": {"$value": "#0265dc"},
      "grey-100": {"$value": "#f8f8f8"},
      "grey-200": {"$value": "#e6e6e6"},
      "grey-300": {"$value": "#d5d5d5"},
      "grey-400": {"$value": "#b1b1b1"},
      "grey-500": {"$value": "#909090"},
      "grey-600": {"$value": "#6d6d6d"},
      "grey-700": {"$value": "#464646"},
      "grey-800": {"$value": "#222222"},
      "grey-900": {"$value": "#000000"},
      "white": {"$value": "#ffffff"}
    }
  }
}</pre>

<p>Although it’s highly useful to have reasonable options, option tokens fall short
      of being sufficient for guiding developers on how and where to apply them.</p>
</section>

<section id="DecisionTokensDefiningHowStylesAreApplied">
<h3>Decision tokens: defining how styles are applied</h3>

<p><i>Decision tokens</i> (also called <i>semantic tokens</i> or <i>system tokens</i>)
      specify <b>how</b> those style options should be applied contextually across
      the UI.</p>

<p>In the context of our color example, they might include decisions like the following:</p>

<ul>
<li>grey-100 is used as a surface color.</li>

<li>grey-200 is used for the background of disabled elements.</li>

<li>grey-400 is used for the text of disabled elements.</li>

<li>grey-900 is used as a default color for text.</li>

<li>blue-900 is used as an accent color.</li>

<li>white is used for text on accent color backgrounds.</li>
</ul>

<p>The corresponding decision token file would look like this:</p>

<pre>{
  "color": {
    "$type": "color",
    "decisions": {
      "surface": {
        "$value": "{color.options.grey-100}",
        "description": "Used as a surface color."
      },
      "background-disabled": {
        "$value": "{color.options.grey-200}",
        "description":"Used for the background of disabled elements."
      },
      "text-disabled": {
        "$value": "{color.options.grey-400}",
        "description": "Used for the text of disabled elements."
      },
      "text": {
        "$value": "{color.options.grey-900}",
        "description": "Used as default text color."
      },
      "accent": {
        "$value": "{color.options.blue-900}",
        "description": "Used as an accent color."
      },
      "text-on-accent": {
        "$value": "{color.options.white}",
        "description": "Used for text on accent color backgrounds."
      }
    }
  }
}</pre>

<p>As a developer, I would mostly be interested in the decisions, not the
      options. For example, color tokens typically contain a long list of options (a
      color palette), while very few of those options are actually used in
      the application. The tokens that are actually relevant when deciding which
      styles to apply, would be usually the decision tokens.</p>

<p>Decision tokens use
      <a href="https://tr.designtokens.org/format/#alias-reference">references</a> to the
      option tokens. I think of organizing tokens this way as a layered
      architecture. In other articles, I have often seen the term <i>tier</i> being
      used, but I think <i>layer</i> is the better word, as there is no physical
      separation implied. The diagram below visualizes the two layers we talked
      about so far:</p>

<div id="2-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/2-layer.svg"></p><p>Figure 5: 2-layer pattern</p>
</div>


</section>

<section id="ComponentTokensDefiningWhereStylesAreApplied">
<h3>Component tokens: defining where styles are applied</h3>

<p><i>Component tokens</i> (or <i>component-specific tokens</i>) map the <i>decision
      tokens</i> to specific parts of the UI. They show <b>where</b> styles are
      applied.</p>

<p>The term <i>component</i> in the context of design tokens does not always
      map to the technical term component. For example, a button might be
      implemented as a UI component in some applications, while other
      applications just use the <code>button</code> HTML element instead. <i>Component
      tokens</i> could be used in both cases.</p>

<p>Component tokens can be organised in a <a href="https://tr.designtokens.org/format/#group"><i>group</i></a> referencing multiple decision tokens. In our example, this references
      might include text- and background-colors for different variants of the button (primary, secondary) as well as disabled buttons.
      They might also include references to tokens of other types (spacing/sizing, borders etc.) which I'll omit in the
      following example:</p>

<pre>{
  "button": {
    "primary": {
      "background": {
        "$value": "{color.decisions.accent}"
      },
      "text": {
        "$value": "{color.decisions.text-on-accent}"
      }
    },
    "secondary": {
      "background": {
        "$value": "{color.decisions.surface}"
      },
      "text": {
        "$value": "{color.decisions.text}"
      }
    },
    "background-disabled": {
      "$value": "{color.decisions.background-disabled}"
    },
    "text-disabled": {
      "$value": "{color.decisions.text-disabled}"
    }
  }
}</pre>

<p>To some degree, component tokens are simply the result of applying
      decisions to specific components. However, as this
      example shows, this process isn’t always straightforward—especially for
      developers without design experience. While decision tokens can offer a
      general sense of which styles to use in a given context, component tokens
      provide additional clarity.</p>

<div id="3-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/3-layer.svg"></p><p>Figure 6: 3-layer pattern</p>
</div>



<p><b>Note:</b> there may be “snowflake” situations where layers are skipped.
      For example, it might not be possible to define a general decision for
      every single component token, or those decisions might not have been made
      yet (for example at the beginning of a project).</p>
</section>


</section>

<section id="TokenScope">
<h2>Token scope</h2>

<p>I already mentioned that while option tokens are very helpful to
    designers, they might not be relevant for application developers using the
    platform-specific code artifacts. Application developers will typically be
    more interested in the decision/component tokens.</p>

<p>Although token scope is not yet included in the design token
    spec, some design
    systems already separate tokens into private (also called <i>internal</i>) and
    public (also called <i>global</i>) tokens. For example, the Salesforce Lightning
    Design System introduced <a href="https://www.lightningdesignsystem.com/design-tokens/">a flag for each
    token</a>. There are
    various reasons why this can be a good idea:</p>

<ul>
<li>it guides developers on which tokens to use</li>

<li>fewer options provide a better developer experience</li>

<li>it reduces the file size as not all tokens need to be included</li>

<li>private/internal tokens can be changed or removed without breaking
      changes</li>
</ul>

<p>A downside of making option tokens private is that developers would rely
    on designers to always make those styles available as decision or component
    tokens. This could become an issue in case of limited availability of the
    designers or if not all decisions are available, for example at the start of
    a project.</p>

<p>Unfortunately, there is no standardized solution yet for implementing
    scope for design tokens. So the approach depends on the tool-chain of the
    project and will most likely need some custom code.</p>

<section id="File-basedScope">
<h3>File-based scope</h3>

<p>Using Style Dictionary, we can use a
      <a href="https://styledictionary.com/reference/hooks/filters/"><i>filter</i></a> to
      expose only public tokens. The most straightforward approach would be to
      filter on the file ending. If we use different file endings for component,
      decision and option tokens, we can use a filter on the file path, for
      example, to make the option tokens layer private.</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": token =&gt; !token.filePath.endsWith('options.json'),</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>The resulting CSS variables would contain
      only these decision tokens, and not the option tokens.</p>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>
</section>

<section id="AMoreFlexibleApproach">
<h3>A more flexible approach</h3>

<p>If more flexibility is needed, it might be preferable to add a scope
      flag to each token and to filter based on this flag:</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": {
              "public": true
            },</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>If we then add the flag to the decision tokens, the resulting CSS would
      be the same as above:</p>

<p>Tokens with scope flag
</p>

<pre>  {
    "color": {
      "$type": "color",
      "decisions": {
        "surface": {
          "$value": "{color.options.grey-100}",
          "description": "Used as a surface color.",
<span>          "public": true</span>
        },
        "background-disabled": {
          "$value": "{color.options.grey-200}",
          "description":"Used for the background of disabled elements.",
<span>          "public": true</span>
        },
        "text-disabled": {
          "$value": "{color.options.grey-400}",
          "description": "Used for the text of disabled elements.",
<span>          "public": true</span>
        },
        "text": {
          "$value": "{color.options.grey-900}",
          "description": "Used as default text color.",
<span>          "public": true</span>
        },
        "accent": {
          "$value": "{color.options.blue-900}",
          "description": "Used as an accent color.",
<span>          "public": true</span>
        },
        "text-on-accent": {
          "$value": "{color.options.white}",
          "description": "Used for text on accent color backgrounds.",
<span>          "public": true</span>
        }
      }
    }
  }</pre>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>

<p>Such flags can now also be set <a href="https://help.figma.com/hc/en-us/articles/360039238193-Hide-styles-components-and-variables-when-publishing#h_01HD20M7HS9044NHB2YBJNE9C2">through the Figma
      UI</a>
      (if using Figma variables as a source of truth for design tokens). It is
      available as
      <a href="https://www.figma.com/plugin-docs/api/properties/Variable-hiddenfrompublishing/"><code>hiddenFromPublishing</code></a>
      flag via the Plugins API.</p>
</section>
</section>

<section id="ShouldIUseDesignTokens">
<h2>Should I use design tokens?</h2>

<p>Design tokens offer significant benefits for modern UI architecture,
      but they may not be the right fit for every project.</p>

<div>
<div>
<p><b>Benefits</b> include:</p>

<ul>
<li>Improved lead time for design changes</li>

<li>Consistent design language and UI architecture across platforms and
            technologies</li>

<li>Design tokens being relatively lightweight from an implementation point of
            view</li>
</ul>
</div>

<div>
<p><b>Drawbacks</b> include:</p>

<ul>
<li>Initial effort for automation</li>

<li>Designers might have to (to some degree) interact with Git</li>

<li>Standardization is still in progress</li>
</ul>
</div>
</div>

<p>Consider the following when deciding whether to adopt design
      tokens:</p>

<section id="WhenToUseDesignTokens">
<h3>When to use design tokens</h3>

<ol>
<li><b>Multi-Platform or Multi-Application Environments:</b> When working across
          multiple platforms (web, iOS, Android…) or maintaining several applications or
          frontends, design tokens ensure a consistent design language across all of
          them.</li>

<li><b>Frequent Design Changes</b>: For environments with regular design
          updates, design tokens provide a structured way to manage and propagate changes
          efficiently.</li>

<li><b>Large Teams</b>: For teams with many designers and developers, design
          tokens facilitate collaboration.</li>

<li><b>Automated Workflows</b>: If you’re familiar with CI/CD pipelines, the
          effort to add a design token pipeline is relatively low. There are also
          commercial offerings.</li>
</ol>
</section>

<section id="WhenDesignTokensMightNotBeNecessary">
<h3>When design tokens might not be necessary</h3>

<ol>
<li><b>Small projects:</b> For smaller projects with limited scope and minimal
          design complexity, the overhead of managing design tokens might not be worth the
          effort.</li>

<li><b>No issue with design changes:</b> If the speed of design changes,
          consistency and collaboration between design and engineering are not an issue,
          then you might also not need design tokens.</li>
</ol>
</section>
</section>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Includeable minimal operating system for C++ (169 pts)]]></title>
            <link>https://www.includeos.org/</link>
            <guid>42445508</guid>
            <pubDate>Tue, 17 Dec 2024 21:29:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.includeos.org/">https://www.includeos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42445508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content"><p>IncludeOS allows you to run your application in the cloud without an operating system. IncludeOS adds operating system functionality to your application allowing you to create performant, secure and resource efficient virtual machines.</p>

<p>IncludeOS applications boot in tens of milliseconds and require only a few megabytes of disk and memory.</p>

<p><a href="https://github.com/includeos/IncludeOS">[View on Github]</a>
<a href="https://join.slack.com/t/includeos/shared_invite/zt-5z7ts29z-_AX0kZNiUNE7eIMUP60GmQ">[Chat on Slack]</a>
<a href="https://www.includeos.org/technology.html">[Tell me more]</a></p>

<p>To run a service with IncludeOS on Linux or macOS you do not need to install IncludeOS, however you need to install a few dependencies depending on the service you will run. You can start by trying out our simplest hello_world service. For this service you will need the following dependencies.</p>

<ul>
  <li>Conan package manager</li>
  <li>cmake, make, nasm</li>
  <li>clang, or alternatively gcc on linux. Prebuilt packages are available for clang 6.0 and gcc 7.3</li>
  <li>qemu</li>
  <li>python3 packages: psutil, jsonschema</li>
</ul>

<p>With the above dependencies you should be able to build an application within minutes.</p>
<p><a target="_blank" href="https://buffett.online/">buffett.online</a><a target="_blank" href="https://songdonkey.ai/">songdonkey.ai</a></p>
<div><pre><code><span>$ </span>conan config <span>install </span>https://github.com/includeos/conan_config.git
<span>$ </span>git clone https://github.com/includeos/hello_world.git
<span>$ </span><span>mkdir </span>build_hello_world
<span>$ </span><span>cd </span>build_hello_world
<span>$ </span>conan <span>install</span> ../hello_world <span>-pr</span> 
<span>$ </span><span>source</span> ./activate.sh
<span>$ </span>cmake ../hello_world
<span>$ </span>cmake <span>--build</span> <span>.</span>
<span>$ </span>boot hello
</code></pre></div>

<p>The hello world booted service should look like this:</p>

<div><pre><code>================================================================================
 IncludeOS 0.14.1-1093 (x86_64 / 64-bit)
 +--&gt; Running [ Hello world - OS included ]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hello world
    [ main ] returned with status 0
</code></pre></div>

<p>For detailed instructions see the <a href="https://github.com/includeos/IncludeOS/blob/master/README.md">GitHub README</a>. Once installed we suggest looking at and booting a few of the demo-examples to familarize yourself with the system.</p>

<p>We strive to make it easy to create fast and useful services. The below code will set up a simple TCP echo service and happily talk to anyone connecting.</p>

<div><pre><code><span>#include &lt;os&gt;
#include &lt;iostream&gt;
#include &lt;net/interfaces&gt;
</span>
<span>void</span> <span>Service</span><span>::</span><span>start</span><span>()</span>
<span>{</span>
  <span>// Get the IP stack thats already been automatically configured</span>
  <span>auto</span><span>&amp;</span> <span>inet</span> <span>=</span> <span>net</span><span>::</span><span>Interfaces</span><span>::</span><span>get</span><span>(</span><span>0</span><span>);</span>
  <span>// Setup a TCP echo server on port 7 (echo port)</span>
  <span>auto</span><span>&amp;</span> <span>server</span> <span>=</span> <span>inet</span><span>.</span><span>tcp</span><span>().</span><span>listen</span><span>(</span><span>7</span><span>);</span>

  <span>server</span><span>.</span><span>on_connect</span><span>([]</span> <span>(</span><span>auto</span> <span>conn</span><span>)</span> <span>{</span>
    <span>// Log incomming connections on the console:</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Connection "</span> <span>&lt;&lt;</span> <span>conn</span><span>-&gt;</span><span>to_string</span><span>()</span> <span>&lt;&lt;</span> <span>" established</span><span>\n</span><span>"</span><span>;</span>
    <span>// When data is received, echo back</span>
    <span>conn</span><span>-&gt;</span><span>on_read</span><span>(</span><span>1024</span><span>,</span> <span>[</span><span>conn</span><span>]</span> <span>(</span><span>auto</span> <span>buf</span><span>)</span> <span>{</span>
      <span>conn</span><span>-&gt;</span><span>write</span><span>(</span><span>buf</span><span>);</span>
    <span>});</span>
  <span>});</span>
<span>}</span>
</code></pre></div>

<p>The network configuration of the virtual machine can reside in a JSON file, named config.json, placed in the same folder. It should look something like this, depending on your need:</p>
<div><pre><code><span>{</span><span>
  </span><span>"net"</span><span> </span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"iface"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
      </span><span>"config"</span><span>:</span><span> </span><span>"dhcp-with-fallback"</span><span>,</span><span>
      </span><span>"address"</span><span>:</span><span> </span><span>"10.0.0.42"</span><span>,</span><span>
      </span><span>"netmask"</span><span>:</span><span> </span><span>"255.255.255.0"</span><span>,</span><span>
      </span><span>"gateway"</span><span>:</span><span> </span><span>"10.0.0.1"</span><span>
    </span><span>}</span><span>
  </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div>

<h2 id="security">Security</h2>

<p>For security related inquires please send email to security@includeos.org. You can use our <a href="https://pgp.mit.edu/pks/lookup?search=security@includeos.org&amp;op=index">PGP key</a> to encrypt the email.</p>

<p>This project is maintained by Alfred Bratterud.</p>

<h2>Recommendations</h2>

<p>4K Download regularly updates their app named <a href="https://www.4kdownload.com/products/youtubetomp3/6">YouTube to MP3</a>. We strongly recommend it if you need to download audio from YouTube.</p>


 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FastVideo: a lightweight framework for accelerating large video diffusion models (109 pts)]]></title>
            <link>https://github.com/hao-ai-lab/FastVideo</link>
            <guid>42445239</guid>
            <pubDate>Tue, 17 Dec 2024 20:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hao-ai-lab/FastVideo">https://github.com/hao-ai-lab/FastVideo</a>, See on <a href="https://news.ycombinator.com/item?id=42445239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/hao-ai-lab/FastVideo/blob/main/assets/logo.jpg"><img src="https://github.com/hao-ai-lab/FastVideo/raw/main/assets/logo.jpg" width="30%"></a>
</p>
<p dir="auto">FastVideo is a lightweight framework for accelerating large video diffusion models.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastMochi-Demo.mp4">FastMochi-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">
    🤗 <a href="https://huggingface.co/FastVideo/FastMochi-diffusers" rel="nofollow">FastMochi</a> | 🤗 <a href="https://huggingface.co/FastVideo/FastHunyuan" rel="nofollow">FastHunyuan</a>  | 🔍 <a href="https://discord.gg/REBzDQTWWt" rel="nofollow"> Discord </a>
</p> 
<p dir="auto">FastVideo currently offers: (with more to come)</p>
<ul dir="auto">
<li>FastHunyuan and FastMochi: consistency distilled video diffusion models for 8x inference speedup.</li>
<li>First open distillation recipes for video DiT, based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>.</li>
<li>Support distilling/finetuning/inferencing state-of-the-art open video DiTs: 1. Mochi 2. Hunyuan.</li>
<li>Scalable training with FSDP, sequence parallelism, and selective activation checkpointing, with near linear scaling to 64 GPUs.</li>
<li>Memory efficient finetuning with LoRA, precomputed latent, and precomputed text embeddings.</li>
</ul>
<p dir="auto">Dev in progress and highly experimental.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎥 More Demos</h2><a id="user-content--more-demos" aria-label="Permalink: 🎥 More Demos" href="#-more-demos"></a></p>
<p dir="auto">Fast-Hunyuan comparison with original Hunyuan, achieving an 8X diffusion speed boost with the FastVideo framework.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastHunyuan-Demo.mp4">FastHunyuan-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Comparison between OpenAI Sora, original Hunyuan and FastHunyuan</p>
<details open="">
  <summary>
    
    <span aria-label="Video description sora-verse-fasthunyuan.mp4.mp4">sora-verse-fasthunyuan.mp4.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Change Log</h2><a id="user-content-change-log" aria-label="Permalink: Change Log" href="#change-log"></a></p>
<ul dir="auto">
<li><code>2024/12/17</code>: <code>FastVideo</code> v0.1 is released.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🔧 Installation" href="#-installation"></a></p>
<p dir="auto">The code is tested on Python 3.10.0, CUDA 12.1 and H100.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Inference</h2><a id="user-content--inference" aria-label="Permalink: 🚀 Inference" href="#-inference"></a></p>
<p dir="auto">We recommend using a GPU with 80GB of memory. To run the inference, use the following command:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastHunyuan</h3><a id="user-content-fasthunyuan" aria-label="Permalink: FastHunyuan" href="#fasthunyuan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
# CLI inference
sh scripts/inference/inference_hunyuan.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
<span><span>#</span> CLI inference</span>
sh scripts/inference/inference_hunyuan.sh</pre></div>
<p dir="auto">You can also inference FastHunyuan in the <a href="https://github.com/Tencent/HunyuanVideo">official Hunyuan github</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastMochi</h3><a id="user-content-fastmochi" aria-label="Permalink: FastMochi" href="#fastmochi"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
# CLI inference
bash scripts/inference/inference_mochi_sp.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
<span><span>#</span> CLI inference</span>
bash scripts/inference/inference_mochi_sp.sh</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Distill</h2><a id="user-content--distill" aria-label="Permalink: 🎯 Distill" href="#-distill"></a></p>
<p dir="auto">Our distillation recipe is based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">Phased Consistency Model</a>. We did not find significant improvement using multi-phase distillation, so we keep the one phase setup similar to the original latent consistency model's recipe.
We use the <a href="https://huggingface.co/datasets/LanguageBind/Open-Sora-Plan-v1.1.0/tree/main/all_mixkit" rel="nofollow">MixKit</a> dataset for distillation. To avoid running the text encoder and VAE during training, we preprocess all data to generate text embeddings and VAE latents.
Preprocessing instructions can be found <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide preprocessed data that can be downloaded directly using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset</pre></div>
<p dir="auto">Next, download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">To launch the distillation process, use the following commands:</p>
<div data-snippet-clipboard-copy-content="bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan"><pre><code>bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan
</code></pre></div>
<p dir="auto">We also provide an optional script for distillation with adversarial loss, located at <code>fastvideo/distill_adv.py</code>. Although we tried adversarial loss, we did not observe significant improvements.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Finetune</h2><a id="user-content-finetune" aria-label="Permalink: Finetune" href="#finetune"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Full Finetune</h3><a id="user-content--full-finetune" aria-label="Permalink: ⚡ Full Finetune" href="#-full-finetune"></a></p>
<p dir="auto">Ensure your data is prepared and preprocessed in the format specified in <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide a mochi preprocessed Black Myth Wukong data that can be downloaded directly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset</pre></div>
<p dir="auto">Download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">Then you can run the finetune with:</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi.sh # for mochi"><pre><code>bash scripts/finetune/finetune_mochi.sh # for mochi
</code></pre></div>
<p dir="auto"><strong>Note that for finetuning, we did not tune the hyperparameters in the provided script</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Lora Finetune</h3><a id="user-content--lora-finetune" aria-label="Permalink: ⚡ Lora Finetune" href="#-lora-finetune"></a></p>
<p dir="auto">Currently, we only provide Lora Finetune for Mochi model, the command for Lora Finetune is</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi_lora.sh"><pre><code>bash scripts/finetune/finetune_mochi_lora.sh
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Minimum Hardware Requirement</h3><a id="user-content-minimum-hardware-requirement" aria-label="Permalink: Minimum Hardware Requirement" href="#minimum-hardware-requirement"></a></p>
<ul dir="auto">
<li>40 GB GPU memory each for 2 GPUs with lora</li>
<li>30 GB GPU memory each for 2 GPUs with CPU offload and lora.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Finetune with Both Image and Video</h3><a id="user-content-finetune-with-both-image-and-video" aria-label="Permalink: Finetune with Both Image and Video" href="#finetune-with-both-image-and-video"></a></p>
<p dir="auto">Our codebase support finetuning with both image and video.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh"><pre>bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh</pre></div>
<p dir="auto">For Image-Video Mixture Fine-tuning, make sure to enable the --group_frame option in your script.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📑 Development Plan</h2><a id="user-content--development-plan" aria-label="Permalink: 📑 Development Plan" href="#-development-plan"></a></p>
<ul dir="auto">
<li>More distillation methods
<ul>
<li> Add Distribution Matching Distillation</li>
</ul>
</li>
<li>More models support
<ul>
<li> Add CogvideoX model</li>
</ul>
</li>
<li>Code update
<ul>
<li> fp8 support</li>
<li> faster load model and save model support</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">We learned and reused code from the following projects: <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>, <a href="https://github.com/huggingface/diffusers">diffusers</a>, <a href="https://github.com/PKU-YuanGroup/Open-Sora-Plan">OpenSoraPlan</a>, and <a href="https://github.com/xdit-project/xDiT">xDiT</a>.</p>
<p dir="auto">We thank MBZUAI and Anyscale for their support throughout this project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC bans hidden junk fees in hotel, event ticket prices (464 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</link>
            <guid>42445037</guid>
            <pubDate>Tue, 17 Dec 2024 20:36:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html">https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107257869" data-test="InlineImage"><p>U.S. President Joe Biden delivers remarks on protecting consumers from hidden junk fees during an event at the South Court Auditorium at Eisenhower Executive Office Building on June 15, 2023 in Washington, DC.</p><p>Alex Wong | Getty Images</p></div><div><p>The U.S. Federal Trade Commission passed a rule on Tuesday requiring ticket sellers, hotels and vacation rental sites to disclose total prices, including fees upfront, prohibiting them from concealing add-on charges until the last minute.</p><p>The rule is one of the final pieces of President Joe Biden's wide-ranging crackdown on junk fees that drive up consumer costs without providing visible benefits.</p><p>"We all know the experience of encountering a hidden fee at the very last stage of checkout — these junk fees sneak onto your bill and companies end up making you pay more because they can. Those fees add up, taking real money out of the pockets of Americans," Biden said in a statement.</p><p>President-elect Donald Trump could seek to withdraw the rule for further review, and Republicans who will have control of Congress could seek to vacate it by law.</p><p>The rule would require service fees, resort fees, and other charges commonly added to bookings to be included in advertised prices. The rule is narrower than what the FTC proposed in 2023 that would have broadly banned hidden and deceptive fees regardless of industry.</p><p>"I urge enforcers to continue cracking down on these unlawful fees and encourage state and federal policymakers to build on this success with legislation that bans unfair and deceptive junk fees across the economy," FTC Chair Lina Khan said in a statement.</p><p>The FTC estimates the rule would save U.S. consumers 53 million hours per year they would not have to spend sleuthing out total costs before making purchases.</p><p>Biden's regulators have taken aim at inflated and hidden fees, though their efforts have met with lawsuits by businesses and corporate interest groups.</p><p>A judge in Texas blocked a rule that would cap credit card late fees, and an appeals court in New Orleans blocked a requirement that airlines disclose baggage and other fees upfront. The cases are ongoing.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A pilot crashed a full passenger jet into the bay, didn't lose his job (2021) (106 pts)]]></title>
            <link>https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</link>
            <guid>42443987</guid>
            <pubDate>Tue, 17 Dec 2024 18:40:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php">https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</a>, See on <a href="https://news.ycombinator.com/item?id=42443987">Hacker News</a></p>
Couldn't get https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>